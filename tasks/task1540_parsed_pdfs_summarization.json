{
    "Contributors": [
        "Mamatha Juluru"
    ],
    "Source": [
        "peer_read"
    ],
    "URL": [
        "https://huggingface.co/datasets/peer_read"
    ],
    "Categories": [
        "Title Generation"
    ],
    "Reasoning": [],
    "Definition": [
        "In this task, you are given a part of an article. Your task is to generate headline (title) for this text. Preferred headlines are under fifteen words."
    ],
    "Input_language": [
        "English"
    ],
    "Output_language": [
        "English"
    ],
    "Instruction_language": [
        "English"
    ],
    "Domains": [
        "Computer Science"
    ],
    "Positive Examples": [
        {
            "input": "We propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range entity transitions along with entity-specific features without loosing generalization, thanks to the power of distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our model achieves state of the art results outperforming existing models by a good margin.",
            "output": "A Neural Local Coherence Model",
            "explanation": "This statement \"A Neural Local Coherence Model\" is taken from the subtext \"convolutional neural network\" and its explanation in the passage. This is a positive example because the title belongs to the mentions in the passage"
        },
        {
            "input": "We present four methods for recovering the epipolar geometry from images of smooth surfaces. In the existing methods for recovering epipolar geometry corresponding feature points are used that cannot be found in such images. The first method is based on finding corresponding characteristic points created by illumination (ICPM illumination characteristic points method). The second method is based on correspondent tangency points created by tangents from epipoles to outline of smooth bodies (OTPM outline tangent points method). These two methods are exact and give correct results for real images, because positions of the corresponding illumination characteristic points and corresponding outline are known with small errors. But the second method is limited either to special type of scenes or to restricted camera motion. We also consider two more methods which are termed CCPM (curve characteristic points method, green curves are used for this method on Figures) and CTPM (curve tangent points method, red curves are used for this method on Figures), for searching epipolar geometry for images of smooth bodies based on a set of level curves (isophoto curves) with a constant illumination intensity. The CCPM method is based on searching correspondent points on isophoto curves with the help of correlation of curvatures between these lines. The CTPM method is based on property of the tangential to isophoto curve epipolar line to map into the tangential to correspondent isophoto curves epipolar line. The standard method termed SM (standard method, blue curves are used for this method on Figures) and based on knowledge of pairs of the almost exact correspondent points, has been used for testing of these two methods. The main technical contributions of our CCPM method are following. The first of them consists of bounding the search space for epipole locations. On the face of it, this space is infinite and unbounded. We suggest a method to partition the infinite plane into a finite number of regions. This partition is based on the desired accuracy and maintains properties that yield an efficient search over the infinite plane. The second is an efficient method for finding correspondence between points of two closed isophoto curves and finding homography, mapping between these two isophoto curves. Then this homography is corrected for all possible epipole positions with the help of evaluation function. A finite subset of solution is chosen from the full set given by all possible epipole positions. This subset includes fundamental matrices giving local minimums of evaluating function close to global minimum. Epipoles of this subset lie almost on straight line directed parallel to parallax shift. CTPM method was used to find the best solution from this subset. Our method is applicable to any pair of images of smooth objects taken under perspective projection models, as long as assumption of the constant brightness is taken for granted. The methods have",
            "output": "Recovering Epipolar Geometry from Images of Smooth Surfaces",
            "explanation": "This statement \"Recovering Epipolar Geometry from Images of Smooth Surfaces\" is taken from the part of the passage \"recovering the epipolar geometry\" and its process description in the passage. This is a positive example because the title indicates the description mentioned in the passage."
        },
        {
            "input": "Word sense disambiguation (WSD) is a problem in the field of computational linguistics given as finding the intended sense of a word (or a set of words) when it is activated within a certain context. WSD was recently addressed as a combinatorial optimization problem in which the goal is to find a sequence of senses that maximize the semantic relatedness among the target words. In this article, a novel algorithm for solving the WSD problem called D-Bees is proposed which is inspired by bee colony optimization (BCO) where artificial bee agents collaborate to solve the problem. The D-Bees algorithm is evaluated on a standard dataset (SemEval 2007 coarse-grained English all-words task corpus) and is compared to simulated annealing, genetic algorithms, and two ant colony optimization techniques (ACO). It will be observed that the BCO and ACO approaches are on par. 1 ar X iv :1 40 5. 14 06 v1 [ cs .C L ] 6 M ay 2 01 4",
            "output": "D-Bees: A Novel Method Inspired by Bee Colony Optimization for Solving Word Sense Disambiguation",
            "explanation": "This statement \"D-Bees: A Novel Method Inspired by Bee Colony Optimization for Solving Word Sense Disambiguation\" is an inference from the part of the passage \" a novel algorithm for solving the WSD problem called D-Bees is proposed which is inspired by bee colony optimization (BCO)\" and its description in the passage. This is a positive example because the title references to the explanation mentioned in the passage."
        }
    ],
    "Negative Examples": [
        {
            "input": "Semantic role labelling (SRL) is a task in natural language processing which detects and classifies the semantic arguments associated with the predicates of a sentence. It is an important step towards understanding the meaning of a natural language. There exists SRL systems for well-studied languages like English, Chinese or Japanese but there is not any such system for the Vietnamese language. In this paper, we present the first SRL system for Vietnamese with encouraging accuracy. We first demonstrate that a simple application of SRL techniques developed for English could not give a good accuracy for Vietnamese. We then introduce a new algorithm for extracting candidate syntactic constituents, which is much more accurate than the common node-mapping algorithm usually used in the identification step. Finally, in the classification step, in addition to the common linguistic features, we propose novel and useful features for use in SRL. Our SRL system achieves an F1 score of 73.53% on the Vietnamese PropBank corpus. This system, including software and corpus, is available as an open source project and we believe that it is a good baseline for the development of future Vietnamese SRL systems.",
            "output": "History of Vietnamese language",
            "explanation": "The statement \"History of Vietnamese language\" is a negative example because it does not infer from the passage. It indicates that the passage is about the history of Vietnamese language but is infact about Semantic role labelling and its importance. "
        },
        {
            "input": "This article presents the top-level of an ontology categorizing and generalizing best practices and quality criteria or measures for Linked Data. It permits to compare these techniques and have a synthetic organized view of what can or should be done for knowledge sharing purposes. This ontology is part of a general knowledge base that can be accessed and complemented by any Web user. Thus, it can be seen as a cooperatively built library for the above cited elements. Since they permit to evaluate information objects and create better ones, these elements also permit knowledgebased tools and techniques – as well as knowledge providers – to be evaluated and categorized based on their input/output information objects. One top-level distinction permitting to organize this ontology is the one between content, medium and containers of descriptions. Various structural, ontological, syntactical and lexical distinctions are then used.",
            "output": "Organization of Data",
            "explanation": "This statement \"Organization of Lined Data\" indicates that the passage is about ways to organize data. This is a negative example because the passage informs about ontology categrizing and generalizing and not about organization of data."
        }
    ],
    "Instances": [
        {
            "id": "task1540-191d8e8b688c45e4897c4993e2a6ef3f",
            "input": "We adress the problem of dueling bandits defined on partially ordered sets, or posets. In this setting, arms may not be comparable, and there may be several (incomparable) optimal arms. We propose an algorithm, UnchainedBandits, that efficiently finds the set of optimal arms of any poset even when pairs of comparable arms cannot be distinguished from pairs of incomparable arms, with a set of minimal assumptions. This algorithm relies on the concept of decoys, which stems from social psychology. For the easier case where the incomparability information may be accessible, we propose a second algorithm, SlicingBandits, which takes advantage of this information and achieves a very significant gain of performance compared to UnchainedBandits. We provide theoretical guarantees and experimental evaluation for both algorithms.",
            "output": [
                "Decoy Bandits Dueling on a Poset"
            ]
        },
        {
            "id": "task1540-01f34d9ee6cd4c6b8baa29bd8fc1cd7e",
            "input": "We present a new model for prediction markets, in which we use risk measures to model agents and introduce a market maker to describe the trading process. This specific choice on modelling tools brings us mathematical convenience. The analysis shows that the whole market effectively approaches a global objective, despite that the market is designed such that each agent only cares about its own goal. Additionally, the market dynamics provides a sensible algorithm for optimising the global objective. An intimate connection between machine learning and our markets is thus established, such that we could 1) analyse a market by applying machine learning methods to the global objective, and 2) solve machine learning problems by setting up and running certain markets.",
            "output": [
                "Multi-period Trading Prediction Markets with Connections to Machine Learning"
            ]
        },
        {
            "id": "task1540-5dfaaae27d804500abaae8a5321ccea8",
            "input": "Recently deep neural networks (DNNs) have been used to learn speaker features. However, the quality of the learned features is not sufficiently good, so a complex back-end model, either neural or probabilistic, has to be used to address the residual uncertainty when applied to speaker verification, just as with raw features. This paper presents a convolutional timedelay deep neural network structure (CT-DNN) for speaker feature learning. Our experimental results on the Fisher database demonstrated that this CT-DNN can produce highquality speaker features: even with a single feature (0.3 seconds including the context), the EER can be as low as 7.68%. This effectively confirmed that the speaker trait is largely a deterministic short-time property rather than a long-time distributional pattern, and therefore can be extracted from just dozens of frames.",
            "output": [
                "Deep Speaker Feature Learning for Text-independent Speaker Verification"
            ]
        },
        {
            "id": "task1540-3f2dda70e3e7434abc5de1102c3736f1",
            "input": "We present a deep hierarchical recurrent neural network for sequence tagging. Given a sequence of words, our model employs deep gated recurrent units on both character and word levels to encode morphology and context information, and applies a conditional random field layer to predict the tags. Our model is task independent, language independent, and feature engineering free. We further extend our model to multi-task and crosslingual joint training by sharing the architecture and parameters. Our model achieves state-of-the-art results in multiple languages on several benchmark tasks including POS tagging, chunking, and NER. We also demonstrate that multi-task and cross-lingual joint training can improve the performance in various cases.",
            "output": [
                "Multi-Task Cross-Lingual Sequence Tagging from Scratch"
            ]
        },
        {
            "id": "task1540-be75d7112fd44d87958fe3d8aa34f558",
            "input": "This manuscript presents a trust computation for international relations and its calculus, which related to Bayesian inference, Dempster-Shafer theory and subjective logic. We proposed a method that allows a trust computation which is previously subjective and incomputable. An example of case study for the trust computation is the United States of America–Great Britain relations. The method supports decision makers in a government such as foreign ministry, defense ministry, presidential or prime minister office. The Department of Defense (DoD) may use our method to determine a nation that can be known as a friendly, neutral or hostile nation.",
            "output": [
                "A Mathematical Trust Algebra for International Nation Relations Computation and Evaluation"
            ]
        },
        {
            "id": "task1540-d072b2dc576941288943867497088077",
            "input": "Syllogism is a type of deductive reasoning involving quantified statements. The syllogistic reasoning scheme in the classical Aristotelian framework involves three crisp term sets and four linguistic quantifiers, for which the main support is the linguistic properties of the quantifiers. A number of fuzzy approaches for defining an approximate syllogism have been proposed for which the main support is cardinality calculus. In this paper we analyze fuzzy syllogistic models previously described by Zadeh and Dubois et al. and compare their behavior with that of the classical Aristotelian framework to check which of the 24 classical valid syllogistic reasoning patterns (called moods) are particular crisp cases of these fuzzy approaches. This allows us to assess to what extent these approaches can be considered as either plausible extensions of the classical crisp syllogism or a basis for a general approach to the problem of approximate syllogism.",
            "output": [
                "On the analysis of set-based fuzzy quantified reasoning using classical syllogistics"
            ]
        },
        {
            "id": "task1540-949339e9a46f4bff8f41252d8997dcdc",
            "input": "The family of temporal difference (TD) methods span a spectrum from computationally frugal linear methods like TD(λ) to data efficient least squares methods. Least square methods make the best use of available data directly computing the TD solution and thus do not require tuning a typically highly sensitive learning rate parameter, but require quadratic computation and storage. Recent algorithmic developments have yielded several sub-quadratic methods that use an approximation to the least squares TD solution, but incur bias. In this paper, we propose a new family of accelerated gradient TD (ATD) methods that (1) provide similar data efficiency benefits to least-squares methods, at a fraction of the computation and storage (2) significantly reduce parameter sensitivity compared to linear TD methods, and (3) are asymptotically unbiased. We illustrate these claims with a proof of convergence in expectation and experiments on several benchmark domains and a large-scale industrial energy allocation domain.",
            "output": [
                "Accelerated Gradient Temporal Difference Learning"
            ]
        },
        {
            "id": "task1540-b0c5e478669d43e0b816d44f9a0ddf6c",
            "input": "Linear Discriminant Analysis (LDA) on Electronic Health Records (EHR) data is widely-used for early detection of diseases. Classical LDA for EHR data classification, however, suffers from two handicaps: the ill-posed estimation of LDA parameters (e.g., covariance matrix), and the “linear inseparability” of EHR data. To handle these two issues, in this paper, we propose a novel classifier FWDA — Fast Wishart Discriminant Analysis, that makes predictions in an ensemble way. Specifically, FWDA first surrogates the distribution of inverse covariance matrices using a Wishart distribution estimated from the training data, then “weightedaverages” the classification results of multiple LDA classifiers parameterized by the sampled inverse covariance matrices via a Bayesian Voting scheme. The weights for voting are optimally updated to adapt each new input data, so as to enable the nonlinear classification. Theoretical analysis indicates that FWDA possesses a fast convergence rate and a robust performance on high dimensional data. Extensive experiments on large-scale EHR dataset show that our approach outperforms stateof-the-art algorithms by a large margin.",
            "output": [
                "FWDA: a Fast Wishart Discriminant Analysis with its Application to Electronic Health Records Data Classification"
            ]
        },
        {
            "id": "task1540-d3456466c16647029187eb4068c5ef70",
            "input": "We propose a method for learning expressive energy-based policies for continuous states and actions, which has been feasible only in tabular domains before. We apply our method to learning maximum entropy policies, resulting into a new algorithm, called soft Q-learning, that expresses the optimal policy via a Boltzmann distribution. We use the recently proposed amortized Stein variational gradient descent to learn a stochastic sampling network that approximates samples from this distribution. The benefits of the proposed algorithm include improved exploration and compositionality that allows transferring skills between tasks, which we confirm in simulated experiments with swimming and walking robots. We also draw a connection to actorcritic methods, which can be viewed performing approximate inference on the corresponding energy-based model.",
            "output": [
                "Reinforcement Learning with Deep Energy-Based Policies"
            ]
        },
        {
            "id": "task1540-40f122b87c7e402098700f4c7d73f4a8",
            "input": "Colorization of grayscale images has been a hot topic in computer vision. Previous research mainly focuses on producing a colored image to match the original one. However, since many colors share the same gray value, an input grayscale image could be diversely colored while maintaining its reality. In this paper, we design a novel solution for unsupervised diverse colorization. Specifically, we leverage conditional generative adversarial networks to model the distribution of real-world item colors, in which we develop a fully convolutional generator with multi-layer noise to enhance diversity, with multi-layer condition concatenation to maintain reality, and with stride 1 to keep spatial information. With such a novel network architecture, the model yields highly competitive performance on the open LSUN bedroom dataset. The Turing test of 80 humans further indicates our generated color schemes are highly convincible.",
            "output": [
                "Unsupervised Diverse Colorization via Generative Adversarial Networks"
            ]
        },
        {
            "id": "task1540-19b78eb552004c75879c5a2981b53d58",
            "input": "This paper tests the hypothesis that distinctive feature classifiers anchored at phonetic landmarks can be transferred crosslingually without loss of accuracy. Three consonant voicing classifiers were developed: (1) manually selected acoustic features anchored at a phonetic landmark, (2) MFCCs (either averaged across the segment or anchored at the landmark), and (3) acoustic features computed using a convolutional neural network (CNN). All detectors are trained on English data (TIMIT), and tested on English, Turkish, and Spanish (performance measured using F1 and accuracy). Experiments demonstrate that manual features outperform all MFCC classifiers, while CNN features outperform both. MFCC-based classifiers suffer an overall error rate increase of up to 96.1% when generalized from English to other languages. Manual features suffer only an up to 35.2% relative error rate increase, and CNN features actually perform the best on Turkish and Spanish, demonstrating that features capable of representing long-term spectral dynamics (CNN and landmark-based features) are able to generalize cross-lingually with little or no loss of accuracy.",
            "output": [
                "LANDMARK-BASED CONSONANT VOICING DETECTION ON MULTILINGUAL CORPORA"
            ]
        },
        {
            "id": "task1540-cb71fdd1c45e445a89d3804dcea78b83",
            "input": "We present the EpiReader, a novel model for machine comprehension of text. Machine comprehension of unstructured, real-world text is a major research goal for natural language processing. Current tests of machine comprehension pose questions whose answers can be inferred from some supporting text, and evaluate a model’s response to the questions. The EpiReader is an end-to-end neural model comprising two components: the first component proposes a small set of candidate answers after comparing a question to its supporting text, and the second component formulates hypotheses using the proposed candidates and the question, then reranks the hypotheses based on their estimated concordance with the supporting text. We present experiments demonstrating that the EpiReader sets a new state-of-the-art on the CNN and Children’s Book Test machine comprehension benchmarks, outperforming previous neural models by a significant margin.",
            "output": [
                "Natural Language Comprehension with the EpiReader"
            ]
        },
        {
            "id": "task1540-63ec1b56dbb04fbc97d9ef4d4176d192",
            "input": "We study the skip-thought model proposed by Kiros et al. (2015) with neighborhood information as weak supervision. More specifically, we propose a skip-thought neighbor model to consider the adjacent sentences as a neighborhood. We train our skip-thought neighbor model on a large corpus with continuous sentences, and then evaluate the trained model on 7 tasks, which include semantic relatedness, paraphrase detection, and classification benchmarks. Both quantitative comparison and qualitative investigation are conducted. We empirically show that, our skip-thought neighbor model performs as well as the skip-thought model on evaluation tasks. In addition, we found that, incorporating an autoencoder path in our model didn’t aid our model to perform better, while it hurts the performance of the skip-thought model.",
            "output": [
                "Rethinking Skip-thought: A Neighborhood based Approach"
            ]
        },
        {
            "id": "task1540-e2ca987482dd43e7938c8e9bb86fa857",
            "input": "As a general and thus popular model for autonomous systems, partially observable Markov decision process (POMDP) can capture uncertainties from different sources like sensing noises, actuation errors, and uncertain environments. However, its comprehensiveness makes the planning and control in POMDP difficult. Traditional POMDP planning problems target to find the optimal policy to maximize the expectation of accumulated rewards. But for safety critical applications, guarantees of system performance described by formal specifications are desired, which motivates us to consider formal methods to synthesize supervisor for POMDP. With system specifications given by Probabilistic Computation Tree Logic (PCTL), we propose a supervisory control framework with a type of deterministic finite automata (DFA), za-DFA, as the controller form. While the existing work mainly relies on optimization techniques to learn fixed-size finite state controllers (FSCs), we develop an L∗ learning based algorithm to determine both space and transitions of za-DFA. Membership queries and different oracles for conjectures are defined. The learning algorithm is sound and complete. An example is given in detailed steps to illustrate the supervisor synthesis algorithm.",
            "output": [
                "Supervisor Synthesis of POMDP based on Automata Learning"
            ]
        },
        {
            "id": "task1540-d812fa8fc5dc4f1893997e3e8c63f81f",
            "input": "In this paper, we propose ELF, an Extensive, Lightweight and Flexible platform for fundamental reinforcement learning research. Using ELF, we implement a highly customizable real-time strategy (RTS) engine with three game environments (Mini-RTS, Capture the Flag and Tower Defense). Mini-RTS, as a miniature version of StarCraft, captures key game dynamics and runs at 40K frame-persecond (FPS) per core on a Macbook Pro notebook. When coupled with modern reinforcement learning methods, the system can train a full-game bot against builtin AIs end-to-end in one day with 6 CPUs and 1 GPU. In addition, our platform is flexible in terms of environment-agent communication topologies, choices of RL methods, changes in game parameters, and can host existing C/C++-based game environments like ALE [4]. Using ELF, we thoroughly explore training parameters and show that a network with Leaky ReLU [16] and Batch Normalization [10] coupled with long-horizon training and progressive curriculum beats the rule-based built-in AI more than 70% of the time in the full game of Mini-RTS. Strong performance is also achieved on the other two games. In game replays, we show our agents learn interesting strategies. ELF, along with its RL platform, will be open-sourced.",
            "output": [
                "ELF: An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games"
            ]
        },
        {
            "id": "task1540-d60d067c1c4f46ba830fdcccc285672c",
            "input": "We show a new lower bound on the sample complexity of (ε,δ)-differentially private algorithms that accurately answer statistical queries on high-dimensional databases. The novelty of our bound is that it depends optimally on the parameter δ, which loosely corresponds to the probability that the algorithm fails to be private, and is the first to smoothly interpolate between approximate differential privacy (δ > 0) and pure differential privacy (δ = 0). Specifically, we consider a database D ∈ {±1}n×d and its one-way marginals, which are the d queries of the form “What fraction of individual records have the i-th bit set to +1?” We show that in order to answer all of these queries to within error ±α (on average) while satisfying (ε,δ)-differential privacy, it is necessary that n ≥Ω √d log(1/δ) αε  , which is optimal up to constant factors. To prove our lower bound, we build on the connection between fingerprinting codes and lower bounds in differential privacy (Bun, Ullman, and Vadhan, STOC’14). In addition to our lower bound, we give new purely and approximately differentially private algorithms for answering arbitrary statistical queries that improve on the sample complexity of the standard Laplace and Gaussian mechanisms for achieving worst-case accuracy guarantees by a logarithmic factor. ∗Harvard University School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616. Email: tsteinke@seas.harvard.edu. †Columbia University Department of Computer Science. Supported by a Junior Fellowship from the Simons Society of Fellows. Email: jullman@cs.columbia.edu. ar X iv :1 50 1. 06 09 5v 1 [ cs .D S] 2 4 Ja n 20 15",
            "output": [
                "Between Pure and Approximate Differential Privacy"
            ]
        },
        {
            "id": "task1540-8c934a14c1034bcc90fbfefdee44ac47",
            "input": "We describe here a methodology to identify a list of ambiguous Malay words that are commonly being used in Malay documentations such as Requirement Specification. We compiled several relevant and appropriate requirement quality attributes and sentence rules from previous literatures and adopt it to come out with a set of ambiguity attributes that most suit Malay words. The extracted Malay ambiguous words (potential) are then being mapped onto the constructed ambiguity attributes to confirm their vagueness. The list is then verified by Malay linguist experts. This paper aims to identify a list of potential ambiguous words in Malay as an attempt to assist writers to avoid using the vague words while documenting Malay Requirement Specification as well as to any other related Malay documentation. The result of this study is a list of 120 potential ambiguous Malay words that could act as guidelines in writing Malay sentences.",
            "output": [
                "MAPPING: AN EXPLORATORY STUDY"
            ]
        },
        {
            "id": "task1540-079c8b63d69046cba0e93bc77ab2625d",
            "input": "The rapid growth of emerging information technologies and application patterns in modern society, e.g., Internet, Internet of Things, Cloud Computing and Tri-network Convergence, has caused the advent of the era of big data. Big data contains huge values, however, mining knowledge from big data is a tremendously challenging task because of data uncertainty and inconsistency. Attribute reduction (also known as feature selection) can not only be used as an effective preprocessing step, but also exploits the data redundancy to reduce the uncertainty. However, existing solutions are designed 1) either for a single machine that means the entire data must fit in the main memory and the parallelism is limited; 2) or for the Hadoop platform which means that the data have to be loaded into the distributed memory frequently and therefore become inefficient. In this paper, we overcome these shortcomings for maximum efficiency possible, and propose a unified framework for Parallel Large-scale Attribute Reduction, termed PLAR, for big data analysis. PLAR consists of three components: 1) Granular Computing (GrC)-based initialization: it converts a decision table (i.e. original data representation) into a granularity representation which reduces the amount of space and hence can be easily cached in the distributed memory: 2) model-parallelism: it simultaneously evaluates all feature candidates and makes attribute reduction highly parallelizable; 3) dataparallelism: it computes the significance of an attribute in parallel using a MapReduce-style manner. We implement PLAR with four representative heuristic feature selection algorithms on SPARK, and evaluate them on various huge datasets, including UCI and astronomical datasets, finding our method’s advantages beyond existing solutions.",
            "output": [
                "Parallel Large-Scale Attribute Reduction on Cloud Systems"
            ]
        },
        {
            "id": "task1540-68e8a229a66e4b5892786e6ec8abdb7d",
            "input": "Decentralized POMDPs provide an expressive framework for multi-agent sequential decision making. While finite-horizon DECPOMDPs have enjoyed significant success, progress remains slow for the infinite-horizon case mainly due to the inherent complexity of optimizing stochastic controllers representing agent policies. We present a promising new class of algorithms for the infinite-horizon case, which recasts the optimization problem as inference in a mixture of DBNs. An attractive feature of this approach is the straightforward adoption of existing inference techniques in DBNs for solving DEC-POMDPs and supporting richer representations such as factored or continuous states and actions. We also derive the Expectation Maximization (EM) algorithm to optimize the joint policy represented as DBNs. Experiments on benchmark domains show that EM compares favorably against the state-of-the-art solvers.",
            "output": [
                "Anytime Planning for Decentralized POMDPs using Expectation Maximization"
            ]
        },
        {
            "id": "task1540-bdc75fc77cfe40a8ab6a3baf79e412af",
            "input": "Vector space models have become popular in distributional semantics, despite the challenges they face in capturing various semantic phenomena. We propose a novel probabilistic framework which draws on both formal semantics and recent advances in machine learning. In particular, we separate predicates from the entities they refer to, allowing us to perform Bayesian inference based on logical forms. We describe an implementation of this framework using a combination of Restricted Boltzmann Machines and feedforward neural networks. Finally, we demonstrate the feasibility of this approach by training it on a parsed corpus and evaluating it on established similarity datasets.",
            "output": [
                "Functional Distributional Semantics"
            ]
        },
        {
            "id": "task1540-d37c0a84a36146c48ce8fdb879700633",
            "input": "The AGM theory of belief revision has be­ come an important paradigm for investigat­ ing rational belief changes. Unfortunately, researchers working in this paradigm have re­ stricted much of their attention to rather sim­ ple representations of belief states, namely logically closed sets of propositional sen­ tences. In our opinion, this has resulted in a too abstract categorisation of belief change operations: expansion, revision, or contrac­ tion. Occasionally, in the AGM paradigm, also probabilistic belief changes have been considered, and it is widely accepted that the probabilistic version of expansion is con­ ditioning. However, we argue that it may be more correct to view conditioning and expan­ sion as two essentially different kinds of belief change, and that what we call constraining is a better candidate for being considered prob­ abilistic expansion.",
            "output": [
                "Probabilistic Belief Change: Expansion, Conditioning and Constraining"
            ]
        },
        {
            "id": "task1540-add3e88a4a504e17956f0e8511c56a2d",
            "input": "Although traditionally used in the machine translation field, the encoder-decoder framework has been recently applied for the generation of video and image descriptions. The combination of Convolutional and Recurrent Neural Networks in these models has proven to outperform the previous state of the art, obtaining more accurate video descriptions. In this work we propose pushing further this model by introducing two contributions into the encoding stage. First, producing richer image representations by combining object and location information from Convolutional Neural Networks and second, introducing Bidirectional Recurrent Neural Networks for capturing both forward and backward temporal relationships in the input frames.",
            "output": [
                "Video Description using Bidirectional Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-cec10bf29ceb42a09ad00a1d7206690c",
            "input": "We propose a new zero-shot Event Detection method by Multi-modal Distributional Semantic embedding of videos. Our model embeds object and action concepts as well as other available modalities from videos into a distributional semantic space. To our knowledge, this is the first Zero-Shot event detection model that is built on top of distributional semantics and extends it in the following directions: (a) semantic embedding of multimodal information in videos (with focus on the visual modalities), (b) automatically determining relevance of concepts/attributes to a free text query, which could be useful for other applications, and (c) retrieving videos by free text event query (e.g., ”changing a vehicle tire”) based on their content. We embed videos into a distributional semantic space and then measure the similarity between videos and the event query in a free text form. We validated our method on the large TRECVID MED (Multimedia Event Detection) challenge. Using only the event title as a query, our method outperformed the state-of-the-art that uses big descriptions from 12.6% to 13.5% with MAP metric and 0.73 to 0.83 with ROC-AUC metric. It is also an order of magnitude faster.",
            "output": [
                "Zero-Shot Event Detection by Multimodal Distributional Semantic Embedding of Videos"
            ]
        },
        {
            "id": "task1540-ee84939b383649edb0ea91b5f6ef42a0",
            "input": "This paper develops upper and lower bounds for the probability of Boolean functions by treating multiple occurrences of variables as independent and assigning them new individual probabilities. We call this approach dissociation and give an exact characterization of optimal oblivious bounds, i.e. when the new probabilities are chosen independent of the probabilities of all other variables. Our motivation comes from the weighted model counting problem (or, equivalently, the problem of computing the probability of a Boolean function), which is #P-hard in general. By performing several dissociations, one can transform a Boolean formula whose probability is difficult to compute, into one whose probability is easy to compute, and which is guaranteed to provide an upper or lower bound on the probability of the original formula by choosing appropriate probabilities for the dissociated variables. Our new bounds shed light on the connection between previous relaxation-based and model-based approximations and unify them as concrete choices in a larger design space. We also show how our theory allows a standard relational database management system (DBMS) to both upper and lower bound hard probabilistic queries in guaranteed polynomial time.",
            "output": [
                "Oblivious Bounds on the Probability of Boolean Functions"
            ]
        },
        {
            "id": "task1540-dda9ddc2550c4f299b48d9042c8a2cea",
            "input": "In the fashion industry, order scheduling focuses on the assignment of production orders to appropriate production lines. In reality, before a new order can be put into production, a series of activities known as pre-production events need to be completed. In addition, in real production process, owing to various uncertainties, the daily production quantity of each order is not always as expected. In this research, by considering the pre-production events and the uncertainties in the daily production quantity, robust order scheduling problems in the fashion industry are investigated with the aid of a multi-objective evolutionary algorithm (MOEA) called nondominated sorting adaptive differential evolution (NSJADE). The experimental results illustrate that it is of paramount importance to consider pre-production events in order scheduling problems in the fashion industry. We also unveil that the existence of the uncertainties in the daily production quantity heavily affects the order scheduling.",
            "output": [
                "Robust Order Scheduling in the Fashion Industry: A Multi-Objective Optimization Approach"
            ]
        },
        {
            "id": "task1540-c4033d90e4c740b7a0e669147550f111",
            "input": "We provide a systematic analysis of levels of integration between discrete high-level reasoning and continuous low-level reasoning to address hybrid planning problems in robotics. We identify four distinct strategies for such an integration: (i) low-level checks are done for all possible cases in advance and then this information is used during plan generation, (ii) low-level checks are done exactly when they are needed during the search for a plan, (iii) first all plans are computed and then infeasible ones are filtered, and (iv) by means of replanning, after finding a plan, low-level checks identify whether it is infeasible or not; if it is infeasible, a new plan is computed considering the results of previous lowlevel checks. We perform experiments on hybrid planning problems in robotic manipulation and legged locomotion domains considering these four methods of integration, as well as some of their combinations. We analyze the usefulness of levels of integration in these domains, both from the point of view of computational efficiency (in time and space) and from the point of view of plan quality relative to its feasibility. We discuss advantages and disadvantages of each strategy in the light of experimental results and provide some guidelines on choosing proper strategies for a given domain.",
            "output": [
                "Levels of Integration between Low-Level Reasoning and Task Planning"
            ]
        },
        {
            "id": "task1540-e02ffe11163d4ee0b6e87e65f0e3bc5a",
            "input": "Neural machine translation (NMT) aims at solving machine translation (MT) problems with purely neural networks and exhibits promising results in recent years. However, most of the existing NMT models are of shallow topology and there is still a performance gap between the single NMT model and the best conventional MT system. In this work, we introduce a new type of linear connections, named fast-forward connections, based on deep Long Short-Term Memory (LSTM) network, together with the interleaved bidirectional way for stacking them. Fastforward connections play an essential role to propagate the gradients in building the deep topology of depth 16. On WMT’14 Englishto-French task, we achieved BLEU=37.7 with single attention model, which outperforms the corresponding single shallow model by 6.2 BLEU points. It is the first time that a single NMT model achieves state-of-the-art performance and outperforms the best conventional model by 0.7 BLEU points. Even without considering attention mechanism, we can still achieve BLEU=36.3. After the special handling for unknown words and the model ensembling, we obtained the best score on this task with BLEU=40.4. Our models are also verified on the more difficult WMT’14 English-to-German task.",
            "output": [
                "Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-f67492689bf54838824bb58eab8c6b4e",
            "input": "State-space models are successfully used in many areas of science, engineering and economics to model time series and dynamical systems. We present a fully Bayesian approach to inference and learning (i.e. state estimation and system identification) in nonlinear nonparametric state-space models. We place a Gaussian process prior over the state transition dynamics, resulting in a flexible model able to capture complex dynamical phenomena. To enable efficient inference, we marginalize over the transition dynamics function and infer directly the joint smoothing distribution using specially tailored Particle Markov Chain Monte Carlo samplers. Once a sample from the smoothing distribution is computed, the state transition predictive distribution can be formulated analytically. Our approach preserves the full nonparametric expressivity of the model and can make use of sparse Gaussian processes to greatly reduce computational complexity.",
            "output": [
                "Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC"
            ]
        },
        {
            "id": "task1540-9569434b45f04920af90a346a072e114",
            "input": "In this study, we introduce an ensemble-based approach for online machine learning. The ensemble of base classifiers in our approach is obtained by learning Naïve Bayes classifiers on different training sets which are generated by projecting the original training set to lower dimensional space. We propose a mechanism to learn sequences of data using data chunks paradigm. The experiments conducted on a number of UCI datasets and one synthetic dataset demonstrate that the proposed approach performs significantly better than some well-known online learning algorithms.",
            "output": [
                "An ensemble-based online learning algorithm for streaming data"
            ]
        },
        {
            "id": "task1540-973a9c421b184a0b81a8bf0c9065a331",
            "input": "Recent works on word representations mostly rely on predictive models. Distributed word representations (aka word embeddings) are trained to optimally predict the contexts in which the corresponding words tend to appear. Such models have succeeded in capturing word similarities as well as semantic and syntactic regularities. Instead, we aim at reviving interest in a model based on counts. We present a systematic study of the use of the Hellinger distance to extract semantic representations from the word co-occurrence statistics of large text corpora. We show that this distance gives good performance on word similarity and analogy tasks, with a proper type and size of context, and a dimensionality reduction based on a stochastic low-rank approximation. Besides being both simple and intuitive, this method also provides an encoding function which can be used to infer unseen words or phrases. This becomes a clear advantage compared to predictive models which must train these new words.",
            "output": [
                "Rehabilitation of Count-based Models for Word Vector Representations"
            ]
        },
        {
            "id": "task1540-d510f8f7d6ec49f19ef67f769dbc568f",
            "input": "In this paper, we implicitly incorporate morpheme information into word embedding. Based on the strategy we utilize the morpheme information, three models are proposed. To test the performances of our models, we conduct the word similarity and syntactic analogy. The results demonstrate the effectiveness of our methods. Our models beat the comparative baselines on both tasks to a great extent. On the golden standard Wordsim-353 and RG-65, our models approximately outperform CBOW for 5 and 7 percent, respectively. In addition, 7 percent advantage is also achieved by our models on syntactic analysis. According to parameter analysis, our models can increase the semantic information in the corpus and our performances on the smallest corpus are similar to the performance of CBOW on the corpus which is five times ours. This property of our methods may have some positive effects on NLP researches about the corpus-limited languages.",
            "output": [
                "Implicitly Incorporating Morphological Information into Word Embedding"
            ]
        },
        {
            "id": "task1540-2479aee0207845029a47031141ee29fb",
            "input": "I propose a framework for an agent to change its probabilistic beliefs when a new piece of propositional information α is observed. Traditionally, belief change occurs by either a revision process or by an update process, depending on whether the agent is informed with α in a static world or, respectively, whether α is a ‘signal’ from the environment due to an event occurring. Boutilier suggested a unified model of qualitative belief change, which “combines aspects of revision and update, providing a more realistic characterization of belief change.” In this paper, I propose a unified model of quantitative belief change, where an agent’s beliefs are represented as a probability distribution over possible worlds. As does Boutilier, I take a dynamical systems perspective. The proposed approach is evaluated against several rationality postulated, and some properties of the approach are worked out. Information acquired can be due to evolution of the world or revelation about the world. That is, one may notice via some ‘signal’ generated by the changing environment that the environment has changed, or, one may be informed by an independent agent in a static environment that some ‘fact’ holds. In the present work, I deal with belief change of agents who handle uncertainty by maintaining a probability distribution over possible situations. The agents in this framework also have models for nondeterministic events, and noisy observations. Noisy observation models can model imperfect sensory equipment for receiving environmental signals, but they can also model untrustworthy informants in a static world. In this paper, I provide the work of Boutilier (1998) as background, because it has several connections with and was the seed for the present work. However, I do not intend simply to give a probabilistic version of his Generalized Update Semantics. Whereas Boutilier (1998) presents a model for unifying qualitative belief revision and update, I build on his work to present a unified model of belief revision and update in a stochastic (probabilistic) setting. I also take a dynamical systems perspective, like him. Due to my quantitative approach, an agent can maintain a probability distribution Copyright c © 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. over the worlds it believes possible, using an expectation semantics of change. This is in contrast to Boutilier’s “generalized update” approach, which takes a most-plausible event and most-plausible world approach. Finally, my proposal requires a trade-off factor to mix the changes in probability distribution over possible worlds brought about due to the probabilistic belief revision process and, respectively, the probabilistic belief update process. Boutilier’s model has revision and update more tightly coupled. For this reason, his approach is better called “unified” while mine is called “hybrid”. The belief change community does not study probabilistic belief update; it is studied almost exclusively in frameworks employing Bayesian conditioning – for modeling events and actions in dynamical domains (e.g., DBNs, MDPs, POMDPs) (Koller and Friedman, 2009; Poole and Mackworth, 2010, e.g.). The part of my approach responsible for updating stays within the Bayesian framework, but combines the essential elements of belief update with unobservable events and belief update as partially observable Markov decision process (POMDP) state estimation. On the other hand, there is plenty of literature on probabilistic belief revision (Voorbraak, 1999; Grove and Halpern, 1998; Kern-Isberner, 2008; Yue and Liu, 2008, e.g.). The subject is both deep and broad. There is no one accepted approach and to argue which is the best is not the focus of this paper. I shall choose one reasonable method for probabilistic belief revision suitable to the task at hand. In the first section, Boutilier’s ‘generalized update’ is reviewed. Then, in the next section, I introduce stochastic update and stochastic revision, culminating in the ‘hybrid stochastic belief change’ (HSBC) approach. The final section presents an example inspired by Boutilier’s article (1998) and analyses the results. Some proofs of propositions are omitted to save space; they are available on request. Boutilier’s Generalized Update I use Boutilier’s notation and descriptions, except that I am more comfortable with α and β to represent sentences, instead of A and B. It is assumed that an agent has a deductively closed belief set K, a set of sentences drawn from some logical language reflecting the agent’s beliefs about the current state of the world. For ease of presentation, I assume ar X iv :1 60 4. 02 12 6v 1 [ cs .A I] 7 A pr 2 01 6 a logically finite, classical propositional language, denoted L (LCPL in Boutilier (1998)), and consequence operation Cn . The belief set K will often be generated by some finite knowledge base KB (i.e., K = Cn(KB)). The identically true and false propositions are denoted > and ⊥, respectively. Given a set of possible worlds W (or valuations over L) and α ∈ L, the set of α-worlds, that is, the elements of W satisfying α, is denoted by ||α||. The worlds satisfying all sentences in a set K is denoted ||K||.",
            "output": [
                "On Stochastic Belief Revision and Update and their Combination"
            ]
        },
        {
            "id": "task1540-10c9071f442f48dfb69993492584097c",
            "input": "Detecting a small number of outliers from a set of data observations is always challenging. This problem is more difficult in the setting of multiple network samples, where computing the anomalous degree of a network sample is generally not sufficient. In fact, explaining why the network is exceptional, expressed in the form of subnetwork, is also equally important. In this paper, we develop a novel algorithm to address these two key problems. We treat each network sample as a potential outlier and identify subnetworks that mostly discriminate it from nearby regular samples. The algorithm is developed in the framework of network regression combined with the constraints on both network topology and L1-norm shrinkage to perform subnetwork discovery. Our method thus goes beyond subspace /subgraph discovery and we show that it converges to a global optimum. Evaluation on various real-world network datasets demonstrates that our algorithm not only outperforms baselines in both network and high dimensional setting, but also discovers highly relevant and interpretable local subnetworks, further enhancing our understanding of anomalous networks.",
            "output": [
                "Outlier Detection from Network Data with Subnetwork Interpretation"
            ]
        },
        {
            "id": "task1540-921d9509f4904984b1e10daaab677fde",
            "input": "The Gumbel trick is a method to sample from a discrete probability distribution, or to estimate its normalizing partition function. The method relies on repeatedly applying a random perturbation to the distribution in a particular way, each time solving for the most likely configuration. We derive an entire family of related methods, of which the Gumbel trick is one member, and show that the new methods have superior properties in several settings with minimal additional computational cost. In particular, for the Gumbel trick to yield computational benefits for discrete graphical models, Gumbel perturbations on all configurations are typically replaced with socalled low-rank perturbations. We show how a subfamily of our new methods adapts to this setting, proving new upper and lower bounds on the log partition function and deriving a family of sequential samplers for the Gibbs distribution. Finally, we balance the discussion by showing how the simpler analytical form of the Gumbel trick enables additional theoretical results.",
            "output": [
                "Lost Relatives of the Gumbel Trick"
            ]
        },
        {
            "id": "task1540-88f380c99a7242fb833b0b966b9c69e7",
            "input": "In this paper, we investigate whether an a priori disambiguation of word senses is strictly necessary or whether the meaning of a word in context can be disambiguated through composition alone. We evaluate the performance of off-the-shelf singlevector and multi-sense vector models on a benchmark phrase similarity task and a novel task for word-sense discrimination. We find that single-sense vector models perform as well or better than multi-sense vector models despite arguably less clean elementary representations. Our findings furthermore show that simple composition functions such as pointwise addition are able to recover sense specific information from a single-sense vector model remark-",
            "output": [
                "One Representation per Word — Does it make Sense for Composition?"
            ]
        },
        {
            "id": "task1540-abcebdf6e6bb4559ab3ed74f45d85dae",
            "input": "While there has been substantial progress in factoid question-answering (QA), answering complex questions remains challenging, typically requiring both a large body of knowledge and inference techniques. Open Information Extraction (Open IE) provides a way to generate semi-structured knowledge for QA, but to date such knowledge has only been used to answer simple questions with retrievalbased methods. We overcome this limitation by presenting a method for reasoning with Open IE knowledge, allowing more complex questions to be handled. Using a recently proposed support graph optimization framework for QA, we develop a new inference model for Open IE, in particular one that can work effectively with multiple short facts, noise, and the relational structure of tuples. Our model significantly outperforms a state-of-the-art structured solver on complex questions of varying difficulty, while also removing the reliance on manually curated knowledge.",
            "output": [
                "Answering Complex Questions Using Open Information Extraction"
            ]
        },
        {
            "id": "task1540-ba35066d206c457bb526b7383e8fd8d3",
            "input": "Constraint-based causal discovery from limited data is a notoriously difficult challenge due to the many borderline independence test decisions. Several approaches to improve the reliability of the predictions by exploiting redundancy in the independence information have been proposed recently. Though promising, existing approaches can still be greatly improved in terms of accuracy and scalability. We present a novel method that reduces the combinatorial explosion of the search space by using a more coarse-grained representation of causal information, drastically reducing computation time. Additionally, we propose a method to score causal predictions based on their confidence. Crucially, our implementation also allows one to easily combine observational and interventional data and to incorporate various types of available background knowledge. We prove soundness and asymptotic consistency of our method and demonstrate that it can outperform the state-ofthe-art on synthetic data, achieving a speedup of several orders of magnitude. We illustrate its practical feasibility by applying it on a challenging protein data set.",
            "output": [
                "Ancestral Causal Inference"
            ]
        },
        {
            "id": "task1540-844c9ebbeffc48059e5b53999223dbef",
            "input": "We study embedded Binarized Neural Networks (eBNNs) with the aim of allowing current binarized neural networks (BNNs) in the literature to perform feedforward inference efficiently on small embedded devices. We focus on minimizing the required memory footprint, given that these devices often have memory as small as tens of kilobytes (KB). Beyond minimizing the memory required to store weights, as in a BNN, we show that it is essential to minimize the memory used for temporaries which hold intermediate results between layers in feedforward inference. To accomplish this, eBNN reorders the computation of inference while preserving the original BNN structure, and uses just a single floating-point temporary for the entire neural network. All intermediate results from a layer are stored as binary values, as opposed to floating-points used in current BNN implementations, leading to a 32x reduction in required temporary space. We provide empirical evidence that our proposed eBNN approach allows efficient inference (10s of ms) on devices with severely limited memory (10s of KB). For example, eBNN achieves 95% accuracy on the MNIST dataset running on an Intel Curie with only 15 KB of usable memory with an inference runtime of under 50 ms per sample. To ease the development of applications in embedded contexts, we make our source code available that allows users to train and discover eBNN models for a learning task at hand, which fit within the memory constraint of the target device.",
            "output": [
                "Embedded Binarized Neural Networks"
            ]
        },
        {
            "id": "task1540-d856f0c5548f4323b0e1eeb0dcb94b53",
            "input": "This paper formulates a novel problem on graphs: find the minimal subset of edges in a fully connected graph, such that the resulting graph contains all spanning trees for a set of specified subgraphs. This formulation is motivated by an unsupervised grammar induction problem from computational linguistics. We present a reduction to some known problems and algorithms from graph theory, provide computational complexity results, and describe an approximation algorithm.",
            "output": [
                "Matroids Hitting Sets and Unsupervised Dependency Grammar Induction"
            ]
        },
        {
            "id": "task1540-2b03e8d43fbf40a2821152c44deb1859",
            "input": "Inspired by biological vision systems, the over-complete local features with huge cardinality are increasingly used for face recognition during the last decades. Accordingly, feature selection has become more and more important and plays a critical role for face data description and recognition. In this paper, we propose a trainable feature selection algorithm based on the regularized frame for face recognition. By enforcing a sparsity penalty term on the minimum squared error (MSE) criterion, we cast the feature selection problem into a combinatorial sparse approximation problem, which can be solved by greedy methods or convex relaxation methods. Moreover, based on the same frame, we propose a sparse Ho-Kashyap (HK) procedure to obtain simultaneously the optimal sparse solution and the corresponding margin vector of the MSE criterion. The proposed methods are used for selecting the most informative Gabor features of face images for recognition and the experimental results on benchmark face databases demonstrate the effectiveness of the",
            "output": [
                "Feature Selection via Sparse Approximation for Face Recognition"
            ]
        },
        {
            "id": "task1540-7c99258a91cc49f0b8487ecf9d013ab2",
            "input": "The Aviation Safety Reporting System collects voluntarily submitted reports on aviation safety incidents to facilitate research work aiming to reduce such incidents. To effectively reduce these incidents, it is vital to accurately identify why these incidents occurred. More precisely, given a set of possible causes, or shaping factors, this task of cause identification involves identifying all and only those shaping factors that are responsible for the incidents described in a report. We investigate two approaches to cause identification. Both approaches exploit information provided by a semantic lexicon, which is automatically constructed via Thelen and Riloff’s Basilisk framework augmented with our linguistic and algorithmic modifications. The first approach labels a report using a simple heuristic, which looks for the words and phrases acquired during the semantic lexicon learning process in the report. The second approach recasts cause identification as a text classification problem, employing supervised and transductive text classification algorithms to learn models from incident reports labeled with shaping factors and using the models to label unseen reports. Our experiments show that both the heuristic-based approach and the learning-based approach (when given sufficient training data) outperform the baseline system significantly.",
            "output": [
                "Cause Identification from Aviation Safety Incident Reports via Weakly Supervised Semantic Lexicon Construction"
            ]
        },
        {
            "id": "task1540-62ffdc104a164f2cb0966d7a2d99efc0",
            "input": "Matrix factorization (MF) and Autoencoder (AE) are among the most successful approaches of unsupervised learning. While MF based models have been extensively exploited in the graph modeling and link prediction literature, the AE family has not gained much attention. In this paper we investigate both MF and AE’s application to the link prediction problem in sparse graphs. We show the connection between AE and MF from the perspective of multiview learning, and further propose MF+AE: a model training MF and AE jointly with shared parameters. We apply dropout to training both the MF and AE parts, and show that it can significantly prevent overfitting by acting as an adaptive regularization. We conduct experiments on six real world sparse graph datasets, and show that MF+AE consistently outperforms the competing methods, especially on datasets that demonstrate strong non-cohesive structures.",
            "output": [
                "Dropout Training of Matrix Factorization and Autoencoder for Link Prediction in Sparse Graphs"
            ]
        },
        {
            "id": "task1540-34abd95b88b445fc9e23ea2f9778988f",
            "input": "We develop a new model for Interactive Question Answering (IQA), using GatedRecurrent-Unit recurrent networks (GRUs) as encoders for statements and questions, and another GRU as a decoder for outputs. Distinct from previous work, our approach employs context-dependent word-level attention for more accurate statement representations and question-guided sentence-level attention for better context modeling. Employing these mechanisms, our model accurately understands when it can output an answer or when it requires generating a supplementary question for additional input. When available, user’s feedback is encoded and directly applied to update sentence-level attention to infer the answer. Extensive experiments on QA and IQA datasets demonstrate quantitatively the effectiveness of our model with significant improvement over conventional QA models.",
            "output": [
                "A CONTEXT-AWARE ATTENTION NETWORK FOR INTERACTIVE QUESTION ANSWERING"
            ]
        },
        {
            "id": "task1540-bd5de377b5ef404faf3704e08cb98acc",
            "input": "The field of Distributed Constraint Optimization has gained momentum in recent years, thanks to its ability to address various applications related to multi-agent cooperation. Nevertheless, solving Distributed Constraint Optimization Problems (DCOPs) optimally is NP-hard. Therefore, in large-scale, complex applications, incomplete DCOP algorithms are necessary. Current incomplete DCOP algorithms suffer of one or more of the following limitations: they (a) find local minima without providing quality guarantees; (b) provide loose quality assessment; or (c) are unable to benefit from the structure of the problem, such as domain-dependent knowledge and hard constraints. Therefore, capitalizing on strategies from the centralized constraint solving community, we propose a Distributed Large Neighborhood Search (D-LNS) framework to solve DCOPs. The proposed framework (with its novel repair phase) provides guarantees on solution quality, refining upper and lower bounds during the iterative process, and can exploit domain-dependent structures. Our experimental results show that D-LNS outperforms other incomplete DCOP algorithms on both structured and unstructured problem instances.",
            "output": [
                "Solving DCOPs with Distributed Large Neighborhood Search"
            ]
        },
        {
            "id": "task1540-464cb6c27f7040e5ada67176b17fd7f4",
            "input": "We present Deep Speaker, a neural speaker embedding system that maps utterances to a hypersphere where speaker similarity is measured by cosine similarity. The embeddings generated by Deep Speaker can be used for many tasks, including speaker identification, verification, and clustering. We experiment with ResCNN and GRU architectures to extract the acoustic features, then mean pool to produce utterance-level speaker embeddings, and train using triplet loss based on cosine similarity. Experiments on three distinct datasets suggest that Deep Speaker outperforms a DNN-based i-vector baseline. For example, Deep Speaker reduces the verification equal error rate by 50% (relatively) and improves the identification accuracy by 60% (relatively) on a text-independent dataset. We also present results that suggest adapting from a model trained with Mandarin can improve accuracy for English speaker recognition.",
            "output": [
                "Deep Speaker: an End-to-End Neural Speaker Embedding System"
            ]
        },
        {
            "id": "task1540-0c737af2fe464dfb9f43baf2d971b906",
            "input": "Shannon’s information entropy measures of the uncertainty of an event’s outcome. If learning about a system reflects a decrease in uncertainty, then a plausible intuition is that learning should be accompanied by a decrease in the entropy of the organism’s actions and/or perceptual states. To address whether this intuition is valid, I examined an artificial organism – a simple robot – that learned to navigate in an arena and analyzed the entropy of the outcome variables action, state, and reward. Entropy did indeed decrease in the initial stages of learning, but two factors complicated the scenario: (1) the introduction of new options discovered during the learning process and (2) the shifting patterns of perceptual and environmental states resulting from changes to the robot’s learned movement strategies. These factors lead to a subsequent increase in entropy as the agent learned. I end with a discussion of the utility of information-based characterizations of learning.",
            "output": [
                "Does Learning Imply a Decrease in the Entropy of Behavior?"
            ]
        },
        {
            "id": "task1540-18633a974e0743ed909d0ae9d54d92ca",
            "input": "We study the problem of structured output learning from a regression perspective. We first provide a general formulation of the kernel dependency estimation (KDE) approach to this problem using operator-valued kernels. Our formulation overcomes the two main limitations of the original KDE approach, namely the decoupling between outputs in the image space and the inability to use a joint feature space. We then propose a covariance-based operator-valued kernel that allows us to take into account the structure of the kernel feature space. This kernel operates on the output space and only encodes the interactions between the outputs without any reference to the input space. To address this issue, we introduce a variant of our KDE method based on the conditional covariance operator that in addition to the correlation between the outputs takes into account the effects of the input variables. Finally, we evaluate the performance of our KDE approach on three structured output problems, and compare it to the state-of-the-art kernelbased structured output regression methods.",
            "output": [
                "A Generalized Kernel Approach to Structured Output Learning"
            ]
        },
        {
            "id": "task1540-c00e6a074c234485892fb3dd2c62fb7b",
            "input": "In the perspective of a sustainable urban planning, it is necessary to investigate cities in a holistic way and to accept surprises in the response of urban environments to a particular set of strategies. For example, the process of inner-city densification may limit air pollution, carbon emissions, and energy use through reduced transportation; on the other hand, the resulting street canyons could lead to local levels of pollution that could be higher than in a low-density urban setting. The holistic approach to sustainable urban planning implies using different models in an integrated way that is capable of simulating the urban system. As the interconnection of such models is not a trivial task, one of the key elements that may be applied is the description of the urban geometric properties in an “interoperable” way. Focusing on air quality as one of the most pronounced urban problems, the geometric aspects of a city may be described by objects such as those defined in CityGML, so that an appropriate air quality model can be applied for estimating the quality of the urban air on the basis of atmospheric flow and chemistry equations. It is generally admitted that an ontology-based approach can provide a generic and robust way to interconnect different models. However, a direct approach, that consists in establishing correspondences between concepts, is not sufficient in the present situation. One has to take into account, among other things, the computations involved in the correspondences between concepts. In this paper we first present theoretical background and motivations for the interconnection of 3D city models and other models related to sustainable development and urban planning. Then we present a practical experiment based on the interconnection of CityGML with an air quality model. Our approach is based on the creation of an ontology of air quality models and on the extension of an ontology of urban planning process (OUPP) that acts as an ontology mediator.",
            "output": [
                "Ontologies for the Integration of Air Quality Models and 3D City Models"
            ]
        },
        {
            "id": "task1540-818d6dca97b64b32b33e3d0d6e002985",
            "input": "We study a semi-supervised learning method based on the similarity graph and Regularized Laplacian. We give convenient optimization formulation of the Regularized Laplacian method and establish its various properties. In particular, we show that the kernel of the method can be interpreted in terms of discrete and continuous time random walks and possesses several important properties of proximity measures. Both optimization and linear algebra methods can be used for efficient computation of the classification functions. We demonstrate on numerical examples that the Regularized Laplacian method is competitive with respect to the other state of the art semi-supervised learning methods. Key-words: Semi-supervised learning, Graph-based learning, Regularized Laplacian, Proximity measure, Wikipedia article classification ∗ Corresponding author. K. Avrachenkov is with Inria Sophia Antipolis, 2004 Route des Lucioles, 06902, Sophia Antipolis, France k.avrachenkov@inria.fr † P. Chebotarev is with Trapeznikov Institute of Control Sciences of the Russian Academy of Sciences, 65 Profsoyuznaya Str., Moscow, 117997, Russia ‡ A. Mishenin is with St. Petersburg State University, Faculty of Applied Mathematics and Control Processes, Peterhof, 198504, Russia § This work was partially supported by Campus France, Alcatel-Lucent Inria Joint Lab, EU Project Congas FP7-ICT-2011-8-317672, and RFBR grant No. 13-07-00990. L’Apprentissage Semi-supervisé avec Laplacian Régularisé Résumé : Nous étudions une méthode d’apprentissage semi-supervisé, basé sur le graphe de similarité et Laplacian régularisé. Nous formalisons la méthode comme un problème d’optimisation convexe et quadratique et nous établissons ses diverses propriétés. En particulier, nous montrons que le noyau de la méthode peut être interprété en termes des marches aléatoires en temps discret et continu et possède plusieurs propriétés importantes des mesures de proximité. Les techniques d’optimisation ainsi que les techniques d’algébre linéaire peuvent être utilisé pour un calcul efficace des fonctions de classification. Nous démontrons sur des exemples numériques que la méthode de Laplacian régularisé est concurrentiel par rapport aux autres état de l’art méthodes d’apprentissage semi-supervisé. Mots-clés : Apprentissage Semi-supervisé, Apprentissage basé sur le graphe de similarité, Laplacian régularisé, mesure de proximité, classification des articles Wikipedia Semi-supervised Learning with Regularized Laplacian 3",
            "output": [
                "Semi-supervised Learning with Regularized Laplacian"
            ]
        },
        {
            "id": "task1540-d6b9052a731b40c7ae878109d93b63dc",
            "input": "Slot Filling (SF) aims to extract the values of certain types of attributes (or slots, such as person:cities of residence) for a given entity from a large collection of source documents. In this paper we propose an effective DNN architecture for SF with the following new strategies: (1). Take a regularized dependency graph instead of a raw sentence as input to DNN, to compress the wide contexts between query and candidate filler; (2). Incorporate two attention mechanisms: local attention learned from query and candidate filler, and global attention learned from external knowledge bases, to guide the model to better select indicative contexts to determine slot type. Experiments show that this framework outperforms state-of-the-art on both relation extraction (16% absolute F-score gain) and slot filling validation for each individual system (up to 8.5% absolute Fscore gain).",
            "output": [
                "Improving Slot Filling Performance with Attentive Neural Networks on Dependency Structures"
            ]
        },
        {
            "id": "task1540-8b56d0a230964ae9a29a4913fcfc0723",
            "input": "Conventional dependency parsers rely on a statistical model and a transition system or graph algorithm to enforce tree-structured outputs during training and inference. In this work we formalize dependency parsing as the problem of selecting the head (a.k.a. parent) of each word in a sentence. Our model which we call DENSE (as shorthand for Dependency Neural Selection) employs bidirectional recurrent neural networks for the head selection task. Without enforcing any structural constraints during training, DENSE generates (at inference time) trees for the overwhelming majority of sentences (95% on an English dataset), while remaining non-tree outputs can be adjusted with a maximum spanning tree algorithm. We evaluate DENSE on four languages (English, Chinese, Czech, and German) with varying degrees of non-projectivity. Despite the simplicity of our approach, experiments show that the resulting parsers are on par with or outperform the state of the art.",
            "output": [
                "Dependency Parsing as Head Selection"
            ]
        },
        {
            "id": "task1540-6c51b494ad164c9c872cba92a43fc445",
            "input": "We propose a probabilistic video model, the Video Pixel Network (VPN), that estimates the discrete joint distribution of the raw pixel values in a video. The model and the neural architecture reflect the time, space and color structure of video tensors and encode it as a four-dimensional dependency chain. The VPN approaches the best possible performance on the Moving MNIST benchmark, a leap over the previous state of the art, and the generated videos show only minor deviations from the ground truth. The VPN also produces detailed samples on the action-conditional Robotic Pushing benchmark and generalizes to the motion of novel objects.",
            "output": [
                "Video Pixel Networks"
            ]
        },
        {
            "id": "task1540-7ea5a452459d4758a18d0622db9b2d0f",
            "input": "We introduce utility-directed procedures for mediating the flow of potentially distract­ ing alerts and communications to computer users. We present models and inference pro­ cedures that balance the context-sensitive costs of deferring alerts with the cost of in­ terruption. We describe the challenge of rea­ soning about such costs under uncertainty via an analysis of user activity and the content of notifications. After introducing principles of attention-sensitive alerting, we focus on the problem of guiding alerts about email mes­ sages. We dwell on the problem of inferring the expected criticality of email and discuss work on the PRIORITIES system, centering on prioritizing email by criticality and modu­ lating the communication of notifications to users about the presence and nature of in­ coming email.",
            "output": [
                "Attention-Sensitive Alerting"
            ]
        },
        {
            "id": "task1540-239ad8397412402e8a9fbafb2e2c7720",
            "input": "In this paper, we investigate the cross-media retrieval between images and text, i.e., using image to search text (I2T) and using text to search images (T2I). Existing cross-media retrieval methods usually learn one couple of projections, by which the original features of images and text can be projected into a common latent space to measure the content similarity. However, using the same projections for the two different retrieval tasks (I2T and T2I) may lead to a tradeoff between their respective performances, rather than their best performances. Different from previous works, we propose a modality-dependent cross-media retrieval (MDCR) model, where two couples of projections are learned for different cross-media retrieval tasks instead of one couple of projections. Specifically, by jointly optimizing the correlation between images and text and the linear regression from one modal space (image or text) to the semantic space, two couples of mappings are learned to project images and text from their original feature spaces into two common latent subspaces (one for I2T and the other for T2I). Extensive experiments show the superiority of the proposed MDCR compared with other methods. In particular, based the 4,096 dimensional convolutional neural network (CNN) visual feature and 100 dimensional LDA textual feature, the mAP of the proposed method achieves 41.5%, which is a new state-of-the-art performance on the Wikipedia dataset.",
            "output": [
                "A Modality-dependent Cross-media Retrieval"
            ]
        },
        {
            "id": "task1540-af2951272f23498ca304c2cb6ddf12ea",
            "input": "We propose a technique for learning representations of parser states in transitionbased dependency parsers. Our primary innovation is a new control structure for sequence-to-sequence neural networks— the stack LSTM. Like the conventional stack data structures used in transitionbased parsing, elements can be pushed to or popped from the top of the stack in constant time, but, in addition, an LSTM maintains a continuous space embedding of the stack contents. This lets us formulate an efficient parsing model that captures three facets of a parser’s state: (i) unbounded look-ahead into the buffer of incoming words, (ii) the complete history of actions taken by the parser, and (iii) the complete contents of the stack of partially built tree fragments, including their internal structures. Standard backpropagation techniques are used for training and yield state-of-the-art parsing performance.",
            "output": [
                "Transition-Based Dependency Parsing with Stack Long Short-Term Memory"
            ]
        },
        {
            "id": "task1540-a8f1e045fa7e47d48dd2275182833a99",
            "input": "This paper proposes a framework dedicated to the construction of what we call discrete elastic inner product allowing one to embed sets of non-uniformly sampled multivariate time series or sequences of varying lengths into inner product space structures. This framework is based on a recursive definition that covers the case of multiple embedded time elastic dimensions. We prove that such inner products exist in our general framework and show how a simple instance of this inner product class operates on some prospective applications, while generalizing the Euclidean inner product. Classification experimentations on time series and symbolic sequences datasets demonstrate the benefits that we can expect by embedding time series or sequences into elastic inner spaces rather than into classical Euclidean spaces. These experiments show good accuracy when compared to the euclidean distance or even dynamic programming algorithms while maintaining a linear algorithmic complexity at exploitation stage, although a quadratic indexing phase beforehand is required.",
            "output": [
                "Discrete Elastic Inner Vector Spaces with Application to Time Series and Sequence Mining"
            ]
        },
        {
            "id": "task1540-dce2bcd7beed4379af01a8d2ea92aeb3",
            "input": "Robotic commands in natural language usually contain various spatial descriptions that are semantically similar but syntactically different. Mapping such syntactic variants into semantic concepts that can be understood by robots is challenging due to the high flexibility of natural language expressions. To tackle this problem, we collect robotic commands for navigation and manipulation tasks using crowdsourcing. We further define a robot language and use a generative machine translation model to translate robotic commands from natural language to robot language. The main purpose of this paper is to simulate the interaction process between human and robots using crowdsourcing platforms, and investigate the possibility of translating natural language to robot language with paraphrases.",
            "output": [
                "Learning Lexical Entries for Robotic Commands using Crowdsourcing"
            ]
        },
        {
            "id": "task1540-337548099326456f8f19045e9c2e5e35",
            "input": "We used MetaMap and YTEX as a basis for the construction of two separate systems to participate in the 2013 ShARe/CLEF eHealth Task 1[9], the recognition of clinical concepts. No modifications were directly made to these systems, but output concepts were filtered using stop concepts, stop concept text and UMLS semantic type. Concept boundaries were also adjusted using a small collection of rules to increase precision on the strict task. Overall MetaMap had better performance than YTEX on the strict task, primarily due to a 20% performance improvement in precision. In the relaxed task YTEX had better performance in both precision and recall giving it an overall F-Score 4.6% higher than MetaMap on the test data. Our results also indicated a 1.3% higher accuracy for YTEX in UMLS CUI mapping.",
            "output": [
                "Evaluation of YTEX and MetaMap for clinical concept recognition"
            ]
        },
        {
            "id": "task1540-0e5785abbbce450086c1a19dac7627e9",
            "input": "When approximating binary similarity using the hamming distance between short binary hashes, we show that even if the similarity is symmetric, we can have shorter and more accurate hashes by using two distinct code maps. I.e. by approximating the similarity between x and x′ as the hamming distance between f(x) and g(x′), for two distinct binary codes f, g, rather than as the hamming distance between f(x) and f(x′).",
            "output": [
                "The Power of Asymmetry in Binary Hashing"
            ]
        },
        {
            "id": "task1540-9a99451c17d54622a5f058d794e590ee",
            "input": "The Particle Swarm Optimization Policy (PSO-P)<lb>has been recently introduced and proven to produce remarkable<lb>results on interacting with academic reinforcement learning<lb>benchmarks in an off-policy, batch-based setting. To further<lb>investigate the properties and feasibility on real-world applica-<lb>tions, this paper investigates PSO-P on the so-called Industrial<lb>Benchmark (IB), a novel reinforcement learning (RL) benchmark<lb>that aims at being realistic by including a variety of aspects found<lb>in industrial applications, like continuous state and action spaces,<lb>a high dimensional, partially observable state space, delayed<lb>effects, and complex stochasticity.<lb>The experimental results of PSO-P on IB are compared to<lb>results of closed-form control policies derived from the model-<lb>based Recurrent Control Neural Network (RCNN) and the<lb>model-free Neural Fitted Q-Iteration (NFQ).<lb>Experiments show that PSO-P is not only of interest for<lb>academic benchmarks, but also for real-world industrial appli-<lb>cations, since it also yielded the best performing policy in our IB<lb>setting. Compared to other well established RL techniques, PSO-<lb>P produced outstanding results in performance and robustness,<lb>requiring only a relatively low amount of effort in finding<lb>adequate parameters or making complex design decisions.",
            "output": [
                "Batch Reinforcement Learning on the Industrial Benchmark: First Experiences"
            ]
        },
        {
            "id": "task1540-001094e72c21467c9854e5d83b7cb8a9",
            "input": "We propose zoneout, a novel method for regularizing RNNs. At each timestep, zoneout stochastically forces some hidden units to maintain their previous values. Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving generalization. But by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. We perform an empirical investigation of various RNN regularizers, and find encouraging results: zoneout gives significant performance improvements across tasks, yielding state-ofthe-art results in character-level language modeling on the Penn Treebank dataset and competitive results on word-level Penn Treebank and permuted sequential MNIST classification tasks.",
            "output": [
                "Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations"
            ]
        },
        {
            "id": "task1540-1fdb059df3b74d2e91d84910fc9fac98",
            "input": "Deep learning models, which learn high-level feature representations from raw data, have become popular for machine learning and artificial intelligence tasks that involve images, audio, and other forms of complex data. A number of software “frameworks” have been developed to expedite the process of designing and training deep neural networks, such as Caffe [11], Torch [4], and Theano [1]. Currently, these frameworks can harness multiple GPUs on the same machine, but are unable to use GPUs that are distributed across multiple machines; because even average-sized deep networks can take days to train on a single GPU when faced with 100s of GBs to TBs of data, distributed GPUs present a prime opportunity for scaling up deep learning. However, the limited inter-machine bandwidth available on commodity Ethernet networks presents a bottleneck to distributed GPU training, and prevents its trivial realization. To investigate how existing software frameworks can be adapted to efficiently support distributed GPUs, we propose Poseidon, a scalable system architecture for distributed inter-machine communication in existing deep learning frameworks. In order to assess Poseidon’s effectiveness, we integrate Poseidon into the Caffe [11] framework and evaluate its performance at training convolutional neural networks for object recognition in images. Poseidon features three key contributions that improve the training speed of deep neural networks on clusters: (i) a three-level hybrid architecture that allows Poseidon to support both CPU-only clusters as well as GPU-equipped clusters, (ii) a distributed wait-free backpropagation (DWBP) algorithm to improve GPU utilization and to balance communication, and (iii) a dedicated structure-aware communication protocol (SACP) to minimize communication overheads. We empirically show that Poseidon converges to the same objective value as a single machine, and achieves state-of-the-art training speedup across multiple models and well-established datasets, using a commodity GPU cluster of 8 nodes (e.g. 4.5× speedup on AlexNet, 4× on GoogLeNet, 4× on CIFAR-10). On the much larger ImageNet 22K dataset, Poseidon with 8 nodes achieves better speedup and competitive accuracy to recent CPU-based distributed deep learning systems such as Adam [2] and Le et al. [16], which use 10s to 1000s of nodes.",
            "output": [
                "Poseidon: A System Architecture for Efficient GPU-based Deep Learning on Multiple Machines"
            ]
        },
        {
            "id": "task1540-b67935c1df5b483da68cf226bac9d656",
            "input": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.",
            "output": [
                "Generating Sequences With Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-002a1bf58151426eb9a8e6e630f69d75",
            "input": "We study the connection between the highly<lb>non-convex loss function of a simple model of<lb>the fully-connected feed-forward neural net-<lb>work and the Hamiltonian of the spherical<lb>spin-glass model under the assumptions of:<lb>i) variable independence, ii) redundancy in<lb>network parametrization, and iii) uniformity.<lb>These assumptions enable us to explain the<lb>complexity of the fully decoupled neural net-<lb>work through the prism of the results from<lb>the random matrix theory. We show that for<lb>large-size decoupled networks the lowest crit-<lb>ical values of the random loss function are<lb>located in a well-defined narrow band lower-<lb>bounded by the global minimum. Further-<lb>more, they form a layered structure. We<lb>show that the number of local minima out-<lb>side the narrow band diminishes exponen-<lb>tially with the size of the network. We em-<lb>pirically demonstrate that the mathemati-<lb>cal model exhibits similar behavior as the<lb>computer simulations, despite the presence<lb>of high dependencies in real networks. We<lb>conjecture that both simulated annealing and<lb>SGD converge to the band containing the<lb>largest number of critical points, and that<lb>all critical points found there are local min-<lb>ima and correspond to the same high learn-<lb>ing quality measured by the test error. This<lb>emphasizes a major difference between large-<lb>and small-size networks where for the lat-<lb>ter poor quality local minima have non-zero<lb>probability of being recovered. Simultane-<lb>ously we prove that recovering the global<lb>minimum becomes harder as the network size<lb>increases and that it is in practice irrelevant<lb>as global minimum often leads to overfitting.<lb>",
            "output": [
                "The Loss Surface of Multilayer Networks"
            ]
        },
        {
            "id": "task1540-619696e14ce54c26a6aba2b8ad329ac1",
            "input": "In this paper, we extend the deep long short-term memory (DLSTM) recurrent neural networks by introducing gated direct connections between memory cells in adjacent layers. These direct links, called highway connections, enable unimpeded information flow across different layers and thus alleviate the gradient vanishing problem when building deeper LSTMs. We further introduce the latency-controlled bidirectional LSTMs (BLSTMs) which can exploit the whole history while keeping the latency under control. Efficient algorithms are proposed to train these novel networks using both frame and sequence discriminative criteria. Experiments on the AMI distant speech recognition (DSR) task indicate that we can train deeper LSTMs and achieve better improvement from sequence training with highway LSTMs (HLSTMs). Our novel model obtains 43.9/47.7% WER on AMI (SDM) dev and eval sets, outperforming all previous works. It beats the strong DNN and DLSTM baselines with 15.7% and 5.3% relative improvement respectively.",
            "output": [
                "HIGHWAY LONG SHORT-TERM MEMORY RNNS FOR DISTANT SPEECH RECOGNITION"
            ]
        },
        {
            "id": "task1540-86fe51e8f61240519b6c55867aa6fce2",
            "input": "In this paper, we correct an upper bound, presented in [4], on the generalisation error of classifiers learned through multiple kernel learning. The bound in [4] uses Rademacher complexity and has anadditive dependence on the logarithm of the number of kernels and the margin achieved by the classifier. However, there are some errors in parts of the proof which are corrected in this paper. Unfortunately, the final result turns out to be a risk bound which has a multiplicative dependence on the logarithm of the number of kernels and the margin achieved by the classifier.",
            "output": [
                "A Note on Improved Loss Bounds for Multiple Kernel Learning"
            ]
        },
        {
            "id": "task1540-52ad377eccfd4615935ac2fef102e8ff",
            "input": "Skip connections made the training of very deep neural networks possible and have become an indispendable component in a variety of neural architectures. A satisfactory explanation for their success remains elusive. Here, we present an explanation for the benefits of skip connections in training very deep neural networks. We argue that skip connections help break symmetries inherent in the loss landscapes of deep networks, leading to drastically simplified landscapes. In particular, skip connections between adjacent layers in a multilayer network break the permutation symmetry of nodes in a given layer, and the recently proposed DenseNet architecture, where each layer projects skip connections to every layer above it, also breaks the rescaling symmetry of connectivity matrices between different layers. This hypothesis is supported by evidence from a toy model with binary weights and from experiments with fully-connected networks suggesting (i) that skip connections do not necessarily improve training unless they help break symmetries and (ii) that alternative ways of breaking the symmetries also lead to significant performance improvements in training deep networks, hence there is nothing special about skip connections in this respect. We find, however, that skip connections confer additional benefits over and above symmetry-breaking, such as the ability to deal effectively with the vanishing gradients problem.",
            "output": [
                "Skip Connections as Effective Symmetry-Breaking"
            ]
        },
        {
            "id": "task1540-397bdd63ae954ac681acd5fc0c59442e",
            "input": "Recent progress in randomized motion planners has led to the development of a new class of samplingbased algorithms that provide asymptotic optimality guarantees, notably the RRT∗ and the PRM∗ algorithms. Careful analysis reveals that the so-called “rewiring” step in these algorithms can be interpreted as a local policy iteration (PI) step (i.e., a local policy evaluation step followed by a local policy improvement step) so that asymptotically, as the number of samples tend to infinity, both algorithms converge to the optimal path almost surely (with probability 1). Policy iteration, along with value iteration (VI) are common methods for solving dynamic programming (DP) problems. Based on this observation, recently, the RRT algorithm has been proposed, which performs, during each iteration, Bellman updates (aka“backups”) on those vertices of the graph that have the potential of being part of the optimal path (i.e., the “promising” vertices). The RRT algorithm thus utilizes dynamic programming ideas and implements them incrementally on randomly generated graphs to obtain high quality solutions. In this work, and based on this key insight, we explore a different class of dynamic programming algorithms for solving shortest-path problems on random graphs generated by iterative sampling methods. These class of algorithms utilize policy iteration instead of value iteration, and thus are better suited for massive parallelization. Contrary to the RRT∗ algorithm, the policy improvement during the rewiring step is not performed only locally but rather on a set of vertices that are classified as “promising” during the current iteration. This tends to speed-up the whole process. The resulting algorithm, aptly named Policy Iteration-RRT (PI-RRT) is the first of a new class of DP-inspired algorithms for randomized motion planning that utilize PI methods.",
            "output": [
                "Incremental Sampling-based Motion Planners Using Policy Iteration Methods"
            ]
        },
        {
            "id": "task1540-65085d065ea84a489bc76a7659a78f5d",
            "input": "Academic researchers often need to face with a large collection of research papers in the literature. This problem may be even worse for postgraduate students who are new to a field and may not know where to start. To address this problem, we have developed an online catalog of research papers where the papers have been automatically categorized by a topic model. The catalog contains 7719 papers from the proceedings of two artificial intelligence conferences from 2000 to 2015. Rather than the commonly used Latent Dirichlet Allocation, we use a recently proposed method called hierarchical latent tree analysis for topic modeling. The resulting topic model contains a hierarchy of topics so that users can browse the topics from the top level to the bottom level. The topic model contains a manageable number of general topics at the top level and allows thousands of fine-grained topics at the bottom level. It also can detect topics that have emerged recently.",
            "output": [
                "Topic Browsing for Research Papers with Hierarchical Latent Tree Analysis"
            ]
        },
        {
            "id": "task1540-93fb814c935040cb99340cf9e2da52f5",
            "input": "We present WIKIREADING, a large-scale natural language understanding task and publicly-available dataset with 18 million instances. The task is to predict textual values from the structured knowledge base Wikidata by reading the text of the corresponding Wikipedia articles. The task contains a rich variety of challenging classification and extraction sub-tasks, making it well-suited for end-to-end models such as deep neural networks (DNNs). We compare various state-of-the-art DNNbased architectures for document classification, information extraction, and question answering. We find that models supporting a rich answer space, such as word or character sequences, perform best. Our best-performing model, a word-level sequence to sequence model with a mechanism to copy out-of-vocabulary words, obtains an accuracy of 71.8%.",
            "output": [
                "WIKIREADING: A Novel Large-scale Language Understanding Task over Wikipedia"
            ]
        },
        {
            "id": "task1540-ab9c809b82ad4b009ac9de83d16585f2",
            "input": "Recently, there have been several promising methods to generate realistic imagery from deep convolutional networks. These methods sidestep the traditional computer graphics rendering pipeline and instead generate imagery at the pixel level by learning from large collections of photos (e.g. faces or bedrooms). However, these methods are of limited utility because it is difficult for a user to control what the network produces. In this paper, we propose a deep adversarial image synthesis architecture that is conditioned on coarse sketches and sparse color strokes to generate realistic cars, bedrooms, or faces. We demonstrate a sketch based image synthesis system which allows users to scribble over the sketch to indicate preferred color for objects. Our network can then generate convincing images that satisfy both the color and the sketch constraints of user. The network is feed-forward which allows users to see the effect of their edits in real time. We compare to recent work on sketch to image synthesis and show that our approach can generate more realistic, more diverse, and more controllable outputs. The architecture is also effective at user-guided colorization of grayscale images.",
            "output": [
                "Scribbler: Controlling Deep Image Synthesis with Sketch and Color"
            ]
        },
        {
            "id": "task1540-8506f887f27f435b816703c7697f1745",
            "input": "Lossy image compression algorithms are pervasively used to reduce the size of images transmitted over the web and recorded on data storage media. However, we pay for their high compression rate with visual artifacts degrading the user experience. Deep convolutional neural networks have become a widespread tool to address high-level computer vision tasks very successfully. Recently, they have found their way into the areas of low-level computer vision and image processing to solve regression problems mostly with relatively shallow networks. We present a novel 12-layer deep convolutional network for image compression artifact suppression with hierarchical skip connections and a multi-scale loss function. We achieve a boost of up to 1.79 dB in PSNR over ordinary JPEG and an improvement of up to 0.36 dB over the best previous ConvNet result. We show that a network trained for a specific quality factor (QF) is resilient to the QF used to compress the input image—a single network trained for QF 60 provides a PSNR gain of more than 1.5 dB over the wide QF range from 40 to 76.",
            "output": [
                "CAS-CNN: A Deep Convolutional Neural Network for Image Compression Artifact Suppression"
            ]
        },
        {
            "id": "task1540-707d120900bf4b528dfac0e241d70023",
            "input": "The distinction between strong negation and default negation has been useful in answer set programming. We present an alternative account of strong negation, which lets us view strong negation in terms of the functional stable model semantics by Bartholomew and Lee. More specifically, we show that, under complete interpretations, minimizing both positive and negative literals in the traditional answer set semantics is essentially the same as ensuring the uniqueness of Boolean function values under the functional stable model semantics. The same account lets us view Lifschitz’s two-valued logic programs as a special case of the functional stable model semantics. In addition, we show how non-Boolean intensional functions can be eliminated in favor of Boolean intensional functions, and furthermore can be represented using strong negation, which provides a way to compute the functional stable model semantics using existing ASP solvers. We also note that similar results hold with the functional stable model semantics by Cabalar.",
            "output": [
                "A Functional View of Strong Negation in Answer Set Programming"
            ]
        },
        {
            "id": "task1540-06f7b0b89e454da1b32f4f5afbf91451",
            "input": "We tackle the problem of inferring node labels in a partially labeled graph where each node in the graph has multiple label types and each label type has a large number of possible labels. Our primary example, and the focus of this paper, is the joint inference of label types such as hometown, current city, and employers, for users connected by a social network. Standard label propagation fails to consider the properties of the label types and the interactions between them. Our proposed method, called EDGEEXPLAIN, explicitly models these, while still enabling scalable inference under a distributed message-passing architecture. On a billion-node subset of the Facebook social network, EDGEEXPLAIN significantly outperforms label propagation for several label types, with lifts of up to 120% for recall@1 and 60% for recall@3.",
            "output": [
                "Joint Inference of Multiple Label Types in Large Networks"
            ]
        },
        {
            "id": "task1540-775dd81d3f3249d1a91caf1ec106bbb0",
            "input": "In this paper we present REG, a graph-based approach for study a fundamental problem of Natural Language Processing (NLP): the automatic text summarization. The algorithm maps a document as a graph, then it computes the weight of their sentences. We have applied this approach to summarize documents in three languages.",
            "output": [
                "Un résumeur à base de graphes, indépéndant de la langue"
            ]
        },
        {
            "id": "task1540-503a2cbf26c442d1ac89d5805c206630",
            "input": "Neural machine translation has shown very promising results lately. Most NMT models follow the encoder-decoder framework. To make encoder-decoder models more flexible, attention mechanism was introduced to machine translation and also other tasks like speech recognition and image captioning. We observe that the quality of translation by attention-based encoder-decoder can be significantly damaged when the alignment is incorrect. We attribute these problems to the lack of distortion and fertility models. Aiming to resolve these problems, we propose new variations of attention-based encoderdecoder and compare them with other models on machine translation. Our proposed method achieved an improvement of 2 BLEU points over the original attentionbased encoder-decoder.",
            "output": [
                "Implicit Distortion and Fertility Models for Attention-based Encoder-Decoder NMT Model"
            ]
        },
        {
            "id": "task1540-1c096accd05842719c5a6820fe250a4f",
            "input": "Common statistical practice has shown that the full power of Bayesian methods is not realized until hierarchical priors are used, as these allow for greater “robustness” and the ability to “share statistical strength.” Yet it is an ongoing challenge to provide a learning-theoretically sound formalism of such notions that: offers practical guidance concerning when and how best to utilize hierarchical models; provides insights into what makes for a good hierarchical prior; and, when the form of the prior has been chosen, can guide the choice of hyperparameter settings. We present a set of analytical tools for understanding hierarchical priors in both the online and batch learning settings. We provide regret bounds under log-loss, which show how certain hierarchical models compare, in retrospect, to the best single model in the model class. We also show how to convert a Bayesian log-loss regret bound into a Bayesian risk bound for any bounded loss, a result which may be of independent interest. Risk and regret bounds for Student’s t and hierarchical Gaussian priors allow us to formalize the concepts of “robustness” and “sharing statistical strength.” Priors for feature selection are investigated as well. Our results suggest that the learning-theoretic benefits of using hierarchical priors can often come at little cost on practical problems.",
            "output": [
                "Risk and Regret of Hierarchical Bayesian Learners"
            ]
        },
        {
            "id": "task1540-5a3867e1930149e1a3073e73d104936d",
            "input": "In state-of-the-art Neural Machine Translation, an attention mechanism is used during decoding to enhance the translation. At every step, the decoder uses this mechanism to focus on different parts of the source sentence to gather the most useful information before outputting its target word. Recently, the effectiveness of the attention mechanism has also been explored for multimodal tasks, where it becomes possible to focus both on sentence parts and image regions. Approaches to pool two modalities usually include element-wise product, sum or concatenation. In this paper, we evaluate the more advanced Multimodal Compact Bilinear pooling method, which takes the outer product of two vectors to combine the attention features for the two modalities. This has been previously investigated for visual question answering. We try out this approach for multimodal image caption translation and show improvements compared to basic combination methods.",
            "output": [
                "MULTIMODAL NEURAL MACHINE TRANSLATION"
            ]
        },
        {
            "id": "task1540-01ad07e55c694cf8b07544e099b8f556",
            "input": "Let us envision a new class of IT systems, the “Support Systems for Knowledge Works” or SSKW. An SSKW can be defined as a system built for providing comprehensive support to human knowledge-workers while performing instances of complex knowledge-works of a particular type within a particular domain of professional activities. To get an idea what an SSKW-enabled work environment can be like, let us look into a hypothetical scenario that depicts the interaction between a physician and a patient-care SSKW during the activity of diagnosing a patient. The patient-care task is practiced by health-care professionals, typically within organizational setups like hospitals. An instance of the task, known as a case, is carried out by a group of professionals (physicians, surgeons, nurses, laboratory technicians etc.) led by a physician (often known as the lead physician for the case) with the primary goal of restoring an ailing patient to state of health. However, the performance also serves various secondary goals achieved through capture and reuse of information about the case. The overall task is usually divided into subtasks or activities such as examination, identification of possible diseases, clinical tests, diagnosis, treatment, follow-up etc. The actions taken during these activities and their results have complex interrelationships. The patient-care SSKW realizes an integrated IT-based system platform which supports all the constituent activities in ways consistent with their interrelationships. Our hypothetical scenario depicts a particular activity by the lead physician (shall be referred as LP hereafter), i.e., diagnosing a patient P with the help of a patient-care SSKW. Making a diagnosis results in identifying a particular disease based on available evidence (e.g., symptoms, signs and medical history of the patient, results of various clinical tests conducted) for which the patient will be treated. Such a scenario is described below. For diagnosing P , LP opens the case in SSKW and the following interactions take place:",
            "output": [
                "Enhancing Support for Knowledge Works: A relatively unexplored vista of computing research"
            ]
        },
        {
            "id": "task1540-9e192a9d66d74d27a818c8e535a4abe0",
            "input": "Despite the successes in capturing continuous distributions, the application of generative adversarial networks (GANs) to discrete settings, like natural language tasks, is rather restricted. The fundamental reason is the difficulty of backpropagation through discrete random variables combined with the inherent instability of the GAN training objective. To address these problems, we propose Maximum-Likelihood Augmented Discrete Generative Adversarial Networks. Instead of directly optimizing the GAN objective, we derive a novel and low-variance objective using the discriminator’s output that follows corresponds to the log-likelihood. Compared with the original, the new objective is proved to be consistent in theory and beneficial in practice. The experimental results on various discrete datasets demonstrate the effectiveness of the proposed approach.",
            "output": [
                "Maximum-Likelihood Augmented Discrete Generative Adversarial Networks"
            ]
        },
        {
            "id": "task1540-5dabf77d143949c89740249eda0ba663",
            "input": "We develop a streaming (one-pass, boundedmemory) word embedding algorithm based on the canonical skip-gram with negative sampling algorithm implemented in word2vec. We compare our streaming algorithm to word2vec empirically by measuring the cosine similarity between word pairs under each algorithm and by applying each algorithm in the downstream task of hashtag prediction on a two-month interval of the Twitter sample stream. We then discuss the results of these experiments, concluding they provide partial validation of our approach as a streaming replacement for word2vec. Finally, we discuss potential failure modes and suggest directions for future work.",
            "output": [
                "Streaming Word Embeddings with the Space-Saving Algorithm"
            ]
        },
        {
            "id": "task1540-118cdaaa22884c5f9d778516d4396248",
            "input": "We propose a simple, scalable, fully generative model for transition-based dependency parsing with high accuracy. The model, parameterized by Hierarchical Pitman-Yor Processes, overcomes the limitations of previous generative models by allowing fast and accurate inference. We propose an efficient decoding algorithm based on particle filtering that can adapt the beam size to the uncertainty in the model while jointly predicting POS tags and parse trees. The UAS of the parser is on par with that of a greedy discriminative baseline. As a language model, it obtains better perplexity than a n-gram model by performing semi-supervised learning over a large unlabelled corpus. We show that the model is able to generate locally and syntactically coherent sentences, opening the door to further applications in language generation.",
            "output": [
                "A Bayesian Model for Generative Transition-based Dependency Parsing"
            ]
        },
        {
            "id": "task1540-70e96eff7f67406292efb506f8d2a870",
            "input": "This paper studies the trade-off between two different kinds of pure exploration: breadth versus depth. The most biased coin problem asks how many total coin flips are required to identify a “heavy” coin from an infinite bag containing both “heavy” coins with mean θ1 ∈ (0, 1), and “light” coins with mean θ0 ∈ (0, θ1), where heavy coins are drawn from the bag with probability α ∈ (0, 1/2). The key difficulty of this problem lies in distinguishing whether the two kinds of coins have very similar means, or whether heavy coins are just extremely rare. This problem has applications in crowdsourcing, anomaly detection, and radio spectrum search. Chandrasekaran and Karp (2014) recently introduced a solution to this problem but it required perfect knowledge of θ0, θ1, α. In contrast, we derive algorithms that are adaptive to partial or absent knowledge of the problem parameters. Moreover, our techniques generalize beyond coins to more general instances of infinitely many armed bandit problems. We also prove lower bounds that show our algorithm’s upper bounds are tight up to log factors, and on the way characterize the sample complexity of differentiating between a single parametric distribution and a mixture of two such distributions. As a result, these bounds have surprising implications both for solutions to the most biased coin problem and for anomaly detection when only partial information about the parameters is known.",
            "output": [
                "On the Detection of Mixture Distributions with applications to the Most Biased Coin Problem"
            ]
        },
        {
            "id": "task1540-4da0f039d55f4c418565628c678405d2",
            "input": "Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real-world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI-friendly environment for people and a people-friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre-set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers’ awareness on AI safety as another related research interest.",
            "output": [
                "Ethical Artificial Intelligence - An Open Question"
            ]
        },
        {
            "id": "task1540-61cebf6c0b754d72806d3ca29e994fb0",
            "input": "Non-maximum suppression (NMS) is used in virtually all state-of-the-art object detection pipelines. While essential object detection ingredients such as features, classifiers, and proposal methods have been extensively researched surprisingly little work has aimed to systematically address NMS. The de-facto standard for NMS is based on greedy clustering with a fixed distance threshold, which forces to trade-off recall versus precision. We propose a convnet designed to perform NMS of a given set of detections. We report experiments on a synthetic setup, and results on crowded pedestrian detection scenes. Our approach overcomes the intrinsic limitations of greedy NMS, obtaining better recall and precision.",
            "output": [
                "A CONVNET FOR NON-MAXIMUM SUPPRESSION"
            ]
        },
        {
            "id": "task1540-0c385306784948f5ae57d6abc81feec4",
            "input": "(To appear in Theory and Practice of Logic Programming (TPLP)) ESmodels is designed and implemented as an experiment platform to investigate the semantics, language, related reasoning algorithms, and possible applications of epistemic specifications. We first give the epistemic specification language of ESmodels and its semantics. The language employs only one modal operator K but we prove that it is able to represent luxuriant modal operators by presenting transformation rules. Then, we describe basic algorithms and optimization approaches used in ESmodels. After that, we discuss possible applications of ESmodels in conformant planning and constraint satisfaction. Finally, we conclude with perspectives.",
            "output": [
                "ESmodels: An Epistemic Specification Solver"
            ]
        },
        {
            "id": "task1540-6130dad97f7a429181f65055befa7c8c",
            "input": "We present DEFEXT, an easy to use semi supervised Definition Extraction Tool. DEFEXT is designed to extract from a target corpus those textual fragments where a term is explicitly mentioned together with its core features, i.e. its definition. It works on the back of a Conditional Random Fields based sequential labeling algorithm and a bootstrapping approach. Bootstrapping enables the model to gradually become more aware of the idiosyncrasies of the target corpus. In this paper we describe the main components of the toolkit as well as experimental results stemming from both automatic and manual evaluation. We release DEFEXT as open source along with the necessary files to run it in any Unix machine. We also provide access to training and test data for immediate use.",
            "output": [
                "DEFEXT: A Semi Supervised Definition Extraction Tool"
            ]
        },
        {
            "id": "task1540-4ded55397a204932b8bbae216bfd8cf4",
            "input": "Graphs are a useful abstraction of image content. Not only can graphs represent details about individual objects in a scene but they can capture the interactions between pairs of objects. We present a method for training a convolutional neural network such that it takes in an input image and produces a full graph. This is done end-to-end in a single stage with the use of associative embeddings. The network learns to simultaneously identify all of the elements that make up a graph and piece them together. We benchmark on the Visual Genome dataset, and report a Recall@50 of 9.7% compared to the prior state-of-the-art at 3.4%, a nearly threefold improvement on the challenging task of scene graph generation.",
            "output": [
                "Pixels to Graphs by Associative Embedding"
            ]
        },
        {
            "id": "task1540-01c881ac4a7b429d90c2b67f034c117b",
            "input": "In this paper, we model the trajectory of sea vessels and provide a service that predicts in near-real time the position of any given vessel in 4’, 10’, 20’ and 40’ time intervals. We explore the necessary tradeoffs between accuracy, performance and resource utilization are explored given the large volume and update rates of input data. We start with building models based on well-established machine learning algorithms using static datasets and multi-scan training approaches and identify the best candidate to be used in implementing a single-pass predictive approach, under real-time constraints. The results are measured in terms of accuracy and performance and are compared against the baseline kinematic equations. Results show that it is possible to efficiently model the trajectory of multiple vessels using a single model, which is trained and evaluated using an adequately large, static dataset, thus achieving a significant gain in terms of resource usage while not compromising accuracy.",
            "output": [
                "Employing traditional machine learning algorithms for big data streams analysis: the case of object trajectory prediction"
            ]
        },
        {
            "id": "task1540-fb2056a239514997a462550215f4e0c7",
            "input": "In this study, the problem of shallow parsing of Hindi-English code-mixed social media text (CSMT) has been addressed. We have annotated the data, developed a language identifier, a normalizer, a part-of-speech tagger and a shallow parser. To the best of our knowledge, we are the first to attempt shallow parsing on CSMT. The pipeline developed has been made available to the research community with the goal of enabling better text analysis of Hindi English CSMT. The pipeline is accessible at 1.",
            "output": [
                "Shallow Parsing Pipeline for Hindi-English Code-Mixed Social Media Text"
            ]
        },
        {
            "id": "task1540-774a099de40d4e57a845a84ed14a5859",
            "input": "We introduce a novel validation framework to measure the true robustness of learning models for real-world applications by creating sourceinclusive and source-exclusive partitions in a dataset via clustering. We develop a robustness metric derived from source-aware lower and upper bounds of model accuracy even when data source labels are not readily available. We clearly demonstrate that even on a well-explored dataset like MNIST, challenging training scenarios can be constructed under the proposed assessment framework for two separate yet equally important applications: i) more rigorous learning model comparison and ii) dataset adequacy evaluation. In addition, our findings not only promise a more complete identification of trade-offs between model complexity, accuracy and robustness but can also help researchers optimize their efforts in data collection by identifying the less robust and more challenging class labels.",
            "output": [
                "Clustering-based Source-aware Assessment of True Robustness for Learning Models"
            ]
        },
        {
            "id": "task1540-786c909d74f148abab2b9f613ded821d",
            "input": "We tackle a task where an agent learns to navigate in a 2D maze-like environment called XWORLD. In each session, the agent perceives a sequence of raw-pixel frames, a natural language command issued by a teacher, and a set of rewards. The agent learns the teacher’s language from scratch in a grounded and compositional manner, such that after training it is able to correctly execute zero-shot commands: 1) the combination of words in the command never appeared before, and/or 2) the command contains new object concepts that are learned from another task but never learned from navigation. Our deep framework for the agent is trained end to end: it learns simultaneously the visual representations of the environment, the syntax and semantics of the language, and the action module that outputs actions. The zero-shot learning capability of our framework results from its compositionality and modularity with parameter tying. We visualize the intermediate outputs of the framework, demonstrating that the agent truly understands how to solve the problem. We believe that our results provide some preliminary insights on how to train an agent with similar abilities in a 3D environment.",
            "output": [
                "A Deep Compositional Framework for Human-like Language Acquisition in Virtual Environment"
            ]
        },
        {
            "id": "task1540-2f75d54056ee401fa17d15ef873163da",
            "input": "The payload of communications satellites must go through a series of tests to assert their ability to survive in space. Each test involves some equipment of the payload to be active, which has an impact on the temperature of the payload. Sequencing these tests in a way that ensures the thermal stability of the payload and minimizes the overall duration of the test campaign is a very important objective for satellite manufacturers. The problem can be decomposed in two sub-problems corresponding to two objectives: First, the number of distinct configurations necessary to run the tests must be minimized. This can be modeled as packing the tests into configurations, and we introduce a set of implied constraints to improve the lower bound of the model. Second, tests must be sequenced so that the number of times an equipment unit has to be switched on or off is minimized. We model this aspect using the constraint Switch, where a buffer with limited capacity represents the currently active equipment units, and we introduce an improvement of the propagation algorithm for this constraint. We then introduce a search strategy in which we sequentially solve the sub-problems (packing and sequencing). Experiments conducted on real and random instances show the respective interest of our contributions.",
            "output": [
                "Constraint Programming for Planning Test Campaigns of Communications Satellites"
            ]
        },
        {
            "id": "task1540-38b52bd3318242159db68b841413a07d",
            "input": "Many intelligent user interfaces employ applica­ tion and user models to determine the user's pref­ erences, goals and likely future actions. Such models require application analysis, adaptation and expansion. Building and maintaining such models adds a substantial amount of time and labour to the application development cycle. We present a system that observes the interface of an unmodified application and records users' inter­ actions with the application. From a history of such observations we build a coarse state space of observed interface states and actions between them. To refine the space, we hypothesize sub­ states based upon the histories that led users to a given state. We evaluate the information gain of possible state splits, varying the length of the histories considered in such splits. In this way, we automatically produce a stochastic dynamic model of the application and of how it is used. To evaluate our approach, we present models de­ rived from real-world application usage data.",
            "output": [
                "Building a Stochastic Dynamic Model of Application Use"
            ]
        },
        {
            "id": "task1540-9cada47c194e4129bf154c28885b8e2d",
            "input": "Collaborative filtering or recommender sys­ tems use a database about user preferences to predict additional topics or products a new user might like. In this paper we describe several algorithms designed for this task, in­ cluding techniques based on correlation coef­ ficients, vector-based similarity calculations, and statistical Bayesian methods. We com­ pare the predictive accuracy of the various methods in a set of representative problem domains. We use two basic classes of evalua­ tion metrics. The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation. The second esti­ mates the utility of a ranked list of suggested items. This metric uses an estimate of the probability that a user will see a recommen­ dation in an ordered list. Experiments were run for datasets associ­ ated with 3 application areas, 4 experimen­ tal protocols, and the 2 evaluation met­ rics for the various algorithms. Results indicate that for a wide range of con­ ditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vector­ similarity methods. Between correlation and Bayesian networks, the preferred method de­ pends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions. Other con­ siderations include the size of database, speed of predictions, and learning time.",
            "output": [
                "Empirical Analysis of Predictive Algorithms for Collaborative Filtering"
            ]
        },
        {
            "id": "task1540-bd4fae7320eb447582d379c33f404a86",
            "input": "A common phenomena in modern recommendation systems is the use of feedback from one user to infer the ‘value’ of an item to other users. This results in an exploration vs. exploitation trade-off, in which items of possibly low value have to be presented to users in order to ascertain their value. Existing approaches to solving this problem focus on the case where the number of items are small, or admit some underlying structure – it is unclear, however, if good recommendation is possible when dealing with content-rich settings with unstructured content. We consider this problem under a simple natural model, wherein the number of items and the number of item-views are of the same order, and an ‘access-graph’ constrains which user is allowed to see which item. Our main insight is that the presence of the access-graph in fact makes good recommendation possible – however this requires the exploration policy to be designed to take advantage of the access-graph. Our results demonstrate the importance of ‘serendipity’ in exploration, and how higher graph-expansion translates to a higher quality of recommendations; it also suggests a reason why in some settings, simple policies like Twitter’s ‘Latest-First’ policy achieve a good performance. From a technical perspective, our model presents a way to study exploration-exploitation tradeoffs in settings where the number of ‘trials’ and ‘strategies’ are large (potentially infinite), and more importantly, of the same order. Our algorithms admit competitive-ratio guarantees which hold for the worst-case user, under both finite-population and infinite-horizon settings, and are parametrized in terms of properties of the underlying graph. Conversely, we also demonstrate that improperly-designed policies can be highly sub-optimal, and that in many settings, our results are order-wise optimal.",
            "output": [
                "Online Collaborative Filtering on Graphs"
            ]
        },
        {
            "id": "task1540-6b24b25669a54ee5a550bcc3044c09ed",
            "input": "Existing algorithms for subgroup discovery with numerical targets do not optimize the error or target variable dispersion of the groups they find. This often leads to unreliable or inconsistent statements about the data, rendering practical applications, especially in scientific domains, futile. Therefore, we here extend the optimistic estimator framework for optimal subgroup discovery to a new class of objective functions: we show how tight estimators can be computed efficiently for all functions that are determined by subgroup size (non-decreasing dependence), the subgroup median value, and a dispersion measure around the median (nonincreasing dependence). In the important special case when dispersion is measured using the mean absolute deviation from the median, this novel approach yields a linear time algorithm. Empirical evaluation on a wide range of datasets shows that, when used within branch-and-bound search, this approach is highly efficient and indeed discovers subgroups with much smaller errors.",
            "output": [
                "Identifying Consistent Statements about Numerical Data with Dispersion-Corrected Subgroup Discovery"
            ]
        },
        {
            "id": "task1540-4e3609fe661e4228a4d59f95f90af888",
            "input": "Vertex Separation Minimization Problem (VSMP) consists of finding a layout of a graph G = (V,E) which minimizes the maximum vertex cut or separation of a layout. It is an NPcomplete problem in general for which metaheuristic techniques can be applied to find near optimal solution. VSMP has applications in VLSI design, graph drawing and computer language compiler design. VSMP is polynomially solvable for grids, trees, permutation graphs and cographs. Construction heuristics play a very important role in the metaheuristic techniques as they are responsible for generating initial solutions which lead to fast convergence. In this paper, we have proposed three construction heuristics H 1, H 2 and H 3 and performed experiments on Grids, Small graphs, Trees and Harwell Boeing graphs, totaling 248 instances of graphs. Experiments reveal that H 1, H 2 and H 3 are able to achieve best results for 88.71%, 43.5% and 37.1% of the total instances respectively while the best construction heuristic in the literature achieves the best solution for 39.9% of the total instances. We have also compared the results with the state-of-the-art metaheuristic GVNS and observed that the proposed construction heuristics improves the results for some of the input instances. It was found that GVNS obtained best results for 82.9% instances of all input instances and the heuristic H 1 obtained best results for 82.3% of all input instances.",
            "output": [
                "Polynomial Time Efficient Construction Heuristics for Vertex Separation Minimization Problem"
            ]
        },
        {
            "id": "task1540-72d0a52dac9544bc992c110889df2ba6",
            "input": "Learning tasks such as those involving genomic data often poses a serious challenge: the number of input features can be orders of magnitude larger than the number of training examples, making it difficult to avoid overfitting, even when using the known regularization techniques. We focus here on tasks in which the input is a description of the genetic variation specific to a patient, the single nucleotide polymorphisms (SNPs), yielding millions of ternary inputs. Improving the ability of deep learning to handle such datasets could have an important impact in medical research, more specifically in precision medicine, where highdimensional data regarding a particular patient is used to make predictions of interest. Even though the amount of data for such tasks is increasing, this mismatch between the number of examples and the number of inputs remains a concern. Naive implementations of classifier neural networks involve a huge number of free parameters in their first layer (number of input features times number of hidden units): each input feature is associated with as many parameters as there are hidden units. We propose a novel neural network parametrization which considerably reduces the number of free parameters. It is based on the idea that we can first learn or provide a distributed representation for each input feature (e.g. for each position in the genome where variations are observed in data), and then learn (with another neural network called the parameter prediction network) how to map a feature’s distributed representation (based on the feature’s identity not its value) to the vector of parameters specific to that feature in the classifier neural network (the weights which link the value of the feature to each of the hidden units). This approach views the problem of producing the parameters associated with each feature as a multi-task learning problem. We show experimentally on a population stratification task of interest to medical studies that the proposed approach can significantly reduce both the number of parameters and the error rate of the classifier.",
            "output": [
                "DIET NETWORKS: THIN PARAMETERS FOR FAT GENOMICS"
            ]
        },
        {
            "id": "task1540-18597cbdd7ba4d61bde5f470279ead81",
            "input": "LetF be a set of boolean functions. We present an algorithm for learningF∨ := {∨f∈Sf | S ⊆ F} from membership queries. Our algorithm asks at most |F| ·OPT(F∨) membership queries where OPT(F∨) is the minimum worst case number of membership queries for learning F∨. When F is a set of halfspaces over a constant dimension space or a set of variable inequalities, our algorithm runs in polynomial time. The problem we address has practical importance in the field of program synthesis, where the goal is to synthesize a program that meets some requirements. Program synthesis has become popular especially in settings aiming to help end users. In such settings, the requirements are not provided upfront and the synthesizer can only learn them by posing membership queries to the end user. Our work enables such synthesizers to learn the exact requirements while bounding the number of membership queries.",
            "output": [
                "Learning Disjunctions of Predicates"
            ]
        },
        {
            "id": "task1540-2002f174e2e04ac6a4c0121b76b48a41",
            "input": "Humans comprehend the meanings and relations of discourses heavily relying on their semantic memory that encodes general knowledge about concepts and facts. Inspired by this, we propose a neural recognizer for implicit discourse relation analysis, which builds upon a semantic memory that stores knowledge in a distributed fashion. We refer to this recognizer as SeMDER. Starting from word embeddings of discourse arguments, SeMDER employs a shallow encoder to generate a distributed surface representation for a discourse. A semantic encoder with attention to the semantic memory matrix is further established over surface representations. It is able to retrieve a deep semantic meaning representation for the discourse from the memory. Using the surface and semantic representations as input, SeMDER finally predicts implicit discourse relations via a neural recognizer. Experiments on the benchmark data set show that SeMDER benefits from the semantic memory and achieves substantial improvements of 2.56% on average over current state-of-the-art baselines in terms of F1-score.",
            "output": [
                "Neural Discourse Relation Recognition with Semantic Memory"
            ]
        },
        {
            "id": "task1540-f6167917d9a149c294c860aacf8e38b5",
            "input": "Pretraining is widely used in deep neutral network and one of the most famous pretraining models is Deep Belief Network (DBN). The optimization formulas are different during the pretraining process for different pretraining models. In this paper, we pretrained deep neutral network by different pretraining models and hence investigated the difference between DBN and Stacked Denoising Autoencoder (SDA) when used as pretraining model. The experimental results show that DBN get a better initial model. However the model converges to a relatively worse model after the finetuning process. Yet after pretrained by SDA for the second time the model converges to a better model if finetuned.",
            "output": [
                "Multi-pretrained Deep Neural Network"
            ]
        },
        {
            "id": "task1540-191902fac8294c32bbf30e6fda5d418a",
            "input": "With a weighting scheme proportional to t, a traditional stochastic gradient descent (SGD) algorithm achieves a high probability convergence rate of O(κ/T ) for strongly convex functions, instead of O(κ ln(T )/T ). We also prove that an accelerated SGD algorithm also achieves a rate of O(κ/T ).",
            "output": [
                "Stochastic gradient descent algorithms for strongly convex functions at O(1/T ) convergence rates"
            ]
        },
        {
            "id": "task1540-c362c9df88474f3a85b1e279627c1128",
            "input": "This paper contains analysis and extension of exploiters-based knowledge extraction methods, which allow generation of new knowledge, based on the basic ones. The main achievement of the paper is useful features of some universal exploiters proof, which allow extending set of basic classes and set of basic relations by finite set of new classes of objects and relations among them, which allow creating of complete lattice. Proposed approach gives an opportunity to compute quantity of new classes, which can be generated using it, and quantity of different types, which each of obtained classes describes; constructing of defined hierarchy of classes with determined subsumption relation; avoidance of some problems of inheritance and more efficient restoring of basic knowledge within the database.",
            "output": [
                "Object-Oriented Knowledge Extraction using Universal Exploiters"
            ]
        },
        {
            "id": "task1540-c6ade02f06364d30a6d9979382618e7e",
            "input": "This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.",
            "output": [
                "A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING"
            ]
        },
        {
            "id": "task1540-596a744c074c4af594ca9c281a56f20c",
            "input": "Contemporary research on computational processing of linguistic metaphors is divided into two main branches: metaphor recognition and metaphor interpretation. We take a different line of research and present an automated method for generating conceptual metaphors from linguistic data. Given the generated conceptual metaphors, we find corresponding linguistic metaphors in corpora. In this paper, we describe our approach and its evaluation using English and Russian data.",
            "output": [
                "Generating Conceptual Metaphors from Proposition Stores"
            ]
        },
        {
            "id": "task1540-cf4f1587aec7427c8700d6bcb07ef20d",
            "input": "Recently, attempts have been made to remove Gaussian mixture models (GMM) from the training process of deep neural network-based hidden Markov models (HMM/DNN). For the GMM-free training of a HMM/DNN hybrid we have to solve two problems, namely the initial alignment of the frame-level state labels and the creation of context-dependent states. Although flat-start training via iteratively realigning and retraining the DNN using a frame-level error function is viable, it is quite cumbersome. Here, we propose to use a sequencediscriminative training criterion for flat start. While sequencediscriminative training is routinely applied only in the final phase of model training, we show that with proper caution it is also suitable for getting an alignment of context-independent DNN models. For the construction of tied states we apply a recently proposed KL-divergence-based state clustering method, hence our whole training process is GMM-free. In the experimental evaluation we found that the sequence-discriminative flat start training method is not only significantly faster than the straightforward approach of iterative retraining and realignment, but the word error rates attained are slightly better as well.",
            "output": [
                "GMM-Free Flat Start Sequence-Discriminative DNN Training"
            ]
        },
        {
            "id": "task1540-ec44d46c0532483092a2d81e15a6bae5",
            "input": "We consider the question of extending propositional logic to a logic of plausible reasoning, and posit four requirements that any such extension should satisfy. Each is a requirement that some property of classical propositional logic be preserved in the extended logic; as such, the requirements are simpler and less problematic than those used in Cox’s Theorem and its variants. As with Cox’s Theorem, our requirements imply that the extended logic must be isomorphic to (finite-set) probability theory. We also obtain specific numerical values for the probabilities, recovering the classical definition of probability as a theorem, with truth assignments that satisfy the premise playing the role of the “possible cases.”",
            "output": [
                "From Propositional Logic to Plausible Reasoning: A Uniqueness Theorem"
            ]
        },
        {
            "id": "task1540-882605f965784277b31edb392b8ad700",
            "input": "There are many declarative frameworks that allow us to implement code formatters relatively easily for any specific language, but constructing them is cumbersome. The first problem is that “everybody” wants to format their code differently, leading to either many formatter variants or a ridiculous number of configuration options. Second, the size of each implementation scales with a language’s grammar size, leading to hundreds of rules. In this paper, we solve the formatter construction problem using a novel approach, one that automatically derives formatters for any given language without intervention from a language expert. We introduce a code formatter called CODEBUFF that uses machine learning to abstract formatting rules from a representative corpus, using a carefully designed feature set. Our experiments on Java, SQL, and ANTLR grammars show that CODEBUFF is efficient, has excellent accuracy, and is grammar invariant for a given language. It also generalizes to a 4th language tested during manuscript preparation.",
            "output": [
                "Technical Report: Towards a Universal Code Formatter through Machine Learning"
            ]
        },
        {
            "id": "task1540-4b0a7b961ade425f90a6142bd2bae971",
            "input": "In this paper we present a novel iterative multiphase clustering technique for efficiently clustering high dimensional data points. For this purpose we implement clustering feature (CF) tree on a real data set and a Gaussian density distribution constraint on the resultant CF tree. The post processing by the application of Gaussian density distribution function on the micro-clusters leads to refinement of the previously formed clusters thus improving their quality. This algorithm also succeeds in overcoming the inherent drawbacks of conventional hierarchical methods of clustering like inability to undo the change made to the dendogram of the data points. Moreover, the constraint measure applied in the algorithm makes this clustering technique suitable for need driven data analysis. We provide veracity of our claim by evaluating our algorithm with other similar clustering algorithms.",
            "output": [
                "Using Gaussian Measures for Efficient Constraint Based Clustering"
            ]
        },
        {
            "id": "task1540-b3d5c02b9a9a48eaa918a6c44212c628",
            "input": "How do news sources tackle controversial issues? In this work, we take a data-driven approach to understand how controversy interplays with emotional expression and biased language in the news. We begin by introducing a new dataset of controversial and noncontroversial terms collected using crowdsourcing. Then, focusing on 15 major U.S. news outlets, we compare millions of articles discussing controversial and non-controversial issues over a span of 7 months. We find that in general, when it comes to controversial issues, the use of negative affect and biased language is prevalent, while the use of strong emotion is tempered. We also observe many differences across news sources. Using these findings, we show that we can indicate to what extent an issue is controversial, by comparing it with other issues in terms of how they are portrayed across different media.",
            "output": [
                "Controversy and Sentiment in Online News"
            ]
        },
        {
            "id": "task1540-fa4098943dbe40eb9eff7555c3e13c6f",
            "input": "Due to the intractable nature of exact lifted inference, research has recently focused on the discovery of accurate and efficient approximate inference algorithms in Statistical Relational Models (SRMs), such as Lifted First-Order Belief Propagation. FOBP simulates propositional factor graph belief propagation without constructing the ground factor graph by identifying and lifting over redundant message computations. In this work, we propose a generalization of FOBP called Lifted Generalized Belief Propagation, in which both the region structure and the message structure can be lifted. This approach allows more of the inference to be performed intra-region (in the exact inference step of BP), thereby allowing simulation of propagation on a graph structure with larger region scopes and fewer edges, while still maintaining tractability. We demonstrate that the resulting algorithm converges in fewer iterations to more accurate results on a variety of SRMs.",
            "output": [
                "Lifted Region-Based Belief Propagation"
            ]
        },
        {
            "id": "task1540-6a340965ef7f43f5a7bfbe789a3071c8",
            "input": "In this paper, we describe a methodology to infer Bullish or Bearish sentiment towards companies/brands. More specifically, our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company. Such architecture was used and evaluated in the context of the SemEval 2017 challenge (task 5, subtask 2), in which it obtained the best performance.",
            "output": [
                "Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring Sentiment towards Brands from Financial News Headlines"
            ]
        },
        {
            "id": "task1540-060be754058148df86792f075b2e02d1",
            "input": "In last few years there are major changes and evolution has been done on classification of data. As the application area of technology is increases the size of data also increases. Classification of data becomes difficult because of unbounded size and imbalance nature of data. Class imbalance problem become greatest issue in data mining. Imbalance problem occur where one of the two classes having more sample than other classes. The most of algorithm are more focusing on classification of major sample while ignoring or misclassifying minority sample. The minority samples are those that rarely occur but very important. There are different methods available for classification of imbalance data set which is divided into three main categories, the algorithmic approach, datapreprocessing approach and feature selection approach. Each of this technique has their own advantages and disadvantages. In this paper systematic study of each approach is define which gives the right direction for research in class imbalance problem.",
            "output": [
                "Class Imbalance Problem in Data Mining: Review"
            ]
        },
        {
            "id": "task1540-7387a5cd905244019aff1e101ee22894",
            "input": "Words in natural language follow a Zipfian distribution whereby some words are frequent but most are rare. Learning representations for words in the “long tail” of this distribution requires enormous amounts of data. Representations of rare words trained directly on end-tasks are usually poor, requiring us to pre-train embeddings on external data, or treat all rare words as out-of-vocabulary words with a unique representation. We provide a method for predicting embeddings of rare words on the fly from small amounts of auxiliary data with a network trained against the end task. We show that this improves results against baselines where embeddings are trained on the end task in a reading comprehension task, a recognizing textual entailment task, and in language modelling.",
            "output": [
                "Learning to Compute Word Embeddings On the Fly"
            ]
        },
        {
            "id": "task1540-5bd07d37c056460dbbfc77dd9d2da280",
            "input": "We present a system for online monitoring of maritime activity over streaming positions from numerous vessels sailing at sea. It employs an online tracking module for detecting important changes in the evolving trajectory of each vessel across time, and thus can incrementally retain concise, yet reliable summaries of its recent movement. In addition, thanks to its complex event recognition module, this system can also offer instant notification to marine authorities regarding emergency situations, such as risk of collisions, suspicious moves in protected zones, or package picking at open sea. Not only did our extensive tests validate the performance, efficiency, and robustness of the system against scalable volumes of real-world and synthetically enlarged datasets, but its deployment against online feeds from vessels has also confirmed its capabilities for effective, real-time maritime surveillance.",
            "output": [
                "Online Event Recognition from Moving Vessel Trajectories"
            ]
        },
        {
            "id": "task1540-3a2c99b998a040f4a841faaa15214ddc",
            "input": "Prosody affects the naturalness and intelligibility of speech. However, automatic prosody prediction from text for Chinese speech synthesis is still a great challenge and the traditional conditional random fields (CRF) based method always heavily relies on feature engineering. In this paper, we propose to use neural networks to predict prosodic boundary labels directly from Chinese characters without any feature engineering. Experimental results show that stacking feed-forward and bidirectional long short-term memory (BLSTM) recurrent network layers achieves superior performance over the CRF-based method. The embedding features learned from raw text further enhance the performance.",
            "output": [
                "AUTOMATIC PROSODY PREDICTION FOR CHINESE SPEECH SYNTHESIS USING BLSTM-RNN AND EMBEDDING FEATURES"
            ]
        },
        {
            "id": "task1540-97315894fc9d41b7988da13c80f11446",
            "input": "Replacing a portion of current light duty vehicles (LDV) with plug-in hybrid electric vehicles (PHEVs) offers the possibility to reduce the dependence on petroleum fuels together with environmental and economic benefits. The charging activity of PHEVs will certainly introduce new load to the power grid. In the framework of the development of a smarter grid, the primary focus of the present study is to propose a model for the electrical daily demand in presence of PHEVs charging. Expected PHEV demand is modeled by the PHEV charging time and the starting time of charge according to real world data. A normal distribution for starting time of charge is assumed. Several distributions for charging time are considered: uniform distribution, Gaussian with positive support, Rician distribution and a non-uniform distribution coming from driving patterns in real-world data. We generate daily demand profiles by using real-world residential profiles throughout 2014 in the presence of different expected PHEV demand models. Support vector machines (SVMs), a set of supervised machine learning models, are employed in order to find the best model to fit the data. SVMs with radial basis function (RBF) and polynomial kernels were tested. Model performances are evaluated by means of mean squared error (MSE) and mean absolute percentage error (MAPE). Best results are obtained with RBF kernel: maximum (worst) values for MSE and MAPE were about 2.89 10 and 0.023, respectively. Keywords—Energy demand, plug-in hybrid electric vehicle (PHEV), smart grids, support vector machines.",
            "output": [
                "Modeling Electrical Daily Demand in Presence of PHEVs in Smart Grids with Supervised Learning"
            ]
        },
        {
            "id": "task1540-b839eb50ec7142378927ab6219205811",
            "input": "Multimedia or spoken content presents more attractive information than plain text content, but it’s more difficult to display on a screen and be selected by a user. As a result, accessing large collections of the former is much more difficult and time-consuming than the latter for humans. It’s highly attractive to develop a machine which can automatically understand spoken content and summarize the key information for humans to browse over. In this endeavor, we propose a new task of machine comprehension of spoken content. We define the initial goal as the listening comprehension test of TOEFL, a challenging academic English examination for English learners whose native language is not English. We further propose an Attention-based Multi-hop Recurrent Neural Network (AMRNN) architecture for this task, achieving encouraging results in the initial tests. Initial results also have shown that word-level attention is probably more robust than sentence-level attention for this task with ASR errors.",
            "output": [
                "Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine"
            ]
        },
        {
            "id": "task1540-878ce6f6ca1344e7a131c1ebfb0a9833",
            "input": "Language models for agglutinative languages have always been hindered in past due to myriad of agglutinations possible to any given word through various affixes.We propose a method to diminish the problem of out-of-vocabulary words by introducing an embedding derived from syllables and morphemes which leverages the agglutinative property. Our model outperforms character-level embedding in perplexity by 16.87 with 9.50M parameters. Proposed method achieves state of the art performance over existing input prediction methods in terms of Key Stroke Saving and has been commercialized.",
            "output": [
                "Syllable-level Neural Language Model for Agglutinative Language"
            ]
        },
        {
            "id": "task1540-da3b7c005f214116acc59ad82c9a9c51",
            "input": "The efficiency of inference in both the Hugin and, most notably, the Shafer-Shenoy archi­ tectures can be improved by exploiting the independence relations induced by the incom­ ing messages of a clique. That is, the mes­ sage to be sent from a clique can be com­ puted via a factorization of the clique poten­ tial in the form of a junction tree. In this pa­ per we show that by exploiting such nested junction trees in the computation of messages both space and time costs of the conventional propagation methods may be reduced. The paper presents a structured way of exploit­ ing the nested junction trees technique to achieve such reductions. The usefulness of the method is emphasized through a thor­ ough empirical evaluation involving ten large real-world Bayesian networks and the Hugin inference algorithm.",
            "output": [
                "Nested Junction Trees"
            ]
        },
        {
            "id": "task1540-43bc67e07e68491ca8ec1f08fd512d5b",
            "input": "Mobile edge computing (a.k.a. fog computing) has recently emerged to enable in-situ processing of delay-sensitive applications at the edge of mobile networks. Providing grid power supply in support of mobile edge computing, however, is costly and even infeasible (in certain rugged or under-developed areas), thus mandating on-site renewable energy as a major or even sole power supply in increasingly many scenarios. Nonetheless, the high intermittency and unpredictability of renewable energy make it very challenging to deliver a high quality of service to users in energy harvesting mobile edge computing systems. In this paper, we address the challenge of incorporating renewables into mobile edge computing and propose an efficient reinforcement learning-based resource management algorithm, which learns on-the-fly the optimal policy of dynamic workload offloading (to the centralized cloud) and edge server provisioning to minimize the long-term system cost (including both service delay and operational cost). Our online learning algorithm uses a decomposition of the (offline) value iteration and (online) reinforcement learning, thus achieving a significant improvement of learning rate and runtime performance when compared to standard reinforcement learning algorithms such as Q-learning. We prove the convergence of the proposed algorithm and analytically show that the learned policy has a simple monotone structure amenable to practical implementation. Our simulation results validate the efficacy of our algorithm, which significantly improves the edge computing performance compared to fixed or myopic optimization schemes and conventional reinforcement learning algorithms. J. Xu and L. Chen are with the Department of Electrical and Computer Engineering, University of Miami. Email: jiexu@miami.edu, lx.chen@miami.edu. S. Ren is with the Department of Electrical and Computer Engineering, University of California, Riverside. Email: sren@ece.ucr.edu",
            "output": [
                "Online Learning for Offloading and Autoscaling in Energy Harvesting Mobile Edge Computing"
            ]
        },
        {
            "id": "task1540-9cc4f43463ac4b5ca705ba350a4afa38",
            "input": "There is a vast amount of unstructured Arabic information on the Web, this data is always organized in semi-structured text and cannot be used directly. This research proposes a semi-supervised technique that extracts binary relations between two Arabic named entities from the Web. Several works have been performed for relation extraction from Latin texts and as far as we know, there isn’t any work for Arabic text using a semi-supervised technique. The goal of this research is to extract a large list or table from named entities and relations in a specific domain. A small set of a handful of instance relations are required as input from the user. The system exploits summaries from Google search engine as a source text. These instances are used to extract patterns. The output is a set of new entities and their relations. The results from four experiments show that precision and recall varies according to relation type. Precision ranges from 0.61 to 0.75 while recall ranges from 0.71 to 0.83. The best result is obtained for (player, club) relationship, 0.72 and 0.83 for precision and recall respectively.",
            "output": [
                "EXTRACTING ARABIC RELATIONS FROM THE WEB"
            ]
        },
        {
            "id": "task1540-93ea1e1e77bb46a493b872c5ddb38c9d",
            "input": "We discuss relations between Residual Networks (ResNet), Recurrent Neural Networks (RNNs) and the primate visual cortex. We begin with the observation that a shallow RNN is exactly equivalent to a very deep ResNet with weight sharing among the layers. A direct implementation of such a RNN, although having orders of magnitude fewer parameters, leads to a performance similar to the corresponding ResNet. We propose 1) a generalization of both RNN and ResNet architectures and 2) the conjecture that a class of moderately deep RNNs is a biologically-plausible model of the ventral stream in visual cortex. We demonstrate the effectiveness of the architectures by testing them on the CIFAR-10 dataset. This work was supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF 1231216. 1 ar X iv :1 60 4. 03 64 0v 1 [ cs .L G ] 1 3 A pr 2 01 6",
            "output": [
                "Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex"
            ]
        },
        {
            "id": "task1540-cb7e158a340941dcb5e13a44e3a4027c",
            "input": "Despite recent advances, the remaining bottlenecks in deep generative models are necessity of extensive training and difficulties with generalization from small number of training examples. Both problems may be addressed by conditional generative models that are trained to adapt the generative distribution to additional input data. So far this idea was explored only under certain limitations such as restricting the input data to be a single object or multiple objects representing the same concept. In this work we develop a new class of deep generative model called generative matching networks which is inspired by the recently proposed matching networks for one-shot learning in discriminative tasks and the ideas from meta-learning. By conditioning on the additional input dataset, generative matching networks may instantly learn new concepts that were not available during the training but conform to a similar generative process, without explicit limitations on the number of additional input objects or the number of concepts they represent. Our experiments on the Omniglot dataset demonstrate that generative matching networks can significantly improve predictive performance on the fly as more additional data is available to the model and also adapt the latent space which is beneficial in the context of feature extraction.",
            "output": [
                "GENERATIVE MATCHING NETWORKS"
            ]
        },
        {
            "id": "task1540-a42b973c58784a34acf1a75c20f80ddb",
            "input": "We develop a general duality between neural networks and compositional kernels, striving towards a better understanding of deep learning. We show that initial representations generated by common random initializations are sufficiently rich to express all functions in the dual kernel space. Hence, though the training objective is hard to optimize in the worst case, the initial weights form a good starting point for optimization. Our dual view also reveals a pragmatic and aesthetic perspective of neural networks and underscores their expressive power. ∗Email: amitdaniely@google.com †Email: rf@cs.stanford.edu. Work performed at Google. ‡Email: singer@google.com ar X iv :1 60 2. 05 89 7v 1 [ cs .L G ] 1 8 Fe b 20 16",
            "output": [
                "Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity"
            ]
        },
        {
            "id": "task1540-24e4652415cf46f98768850aa6034679",
            "input": "This research applies ideas from argumentation theory in the context of semantic wikis, aiming to provide support for structured-large scale argumentation between human agents. The implemented prototype is exemplified by modelling the MMR vaccine controversy.",
            "output": [
                "Using Semantic Wikis for Structured Argument in Medical Domain"
            ]
        },
        {
            "id": "task1540-21d6f08bfcd64a36a2c2aff6bab3db18",
            "input": "We propose k-means, a new clustering method which efficiently copes with large numbers of clusters and achieves low energy solutions. k-means builds upon the standard k-means (Lloyd’s algorithm) and combines a new strategy to accelerate the convergence with a new low time complexity divisive initialization. The accelerated convergence is achieved through only looking at kn nearest clusters and using triangle inequality bounds in the assignment step while the divisive initialization employs an optimal 2-clustering along a direction. The worst-case time complexity per iteration of our k-means is O(nknd+ kd), where d is the dimension of the n data points and k is the number of clusters and usually n k kn. Compared to k-means’ O(nkd) complexity, our k-means complexity is significantly lower, at the expense of slightly increasing the memory complexity by O(nkn + k). In our extensive experiments k-means is order(s) of magnitude faster than standard methods in computing accurate clusterings on several standard datasets and settings with hundreds of clusters and high dimensional data. Moreover, the proposed divisive initialization generally leads to clustering energies comparable to those achieved with the standard k-means++ initialization, while being significantly faster.",
            "output": [
                "k-means for fast and accurate large scale clustering"
            ]
        },
        {
            "id": "task1540-34f125e15f064521949404bf9d41dba9",
            "input": "We investigate evaluation metrics for endto-end dialogue systems where supervised labels, such as task completion, are not available. Recent works in end-to-end dialogue systems have adopted metrics from machine translation and text summarization to compare a model’s generated response to a single target response. We show that these metrics correlate very weakly or not at all with human judgements of the response quality in both technical and non-technical domains. We provide quantitative and qualitative results highlighting specific weaknesses in existing metrics, and provide recommendations for future development of better automatic evaluation metrics for dialogue systems.",
            "output": [
                "How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation"
            ]
        },
        {
            "id": "task1540-e7b7b95bd04845e28a6ed131b6a7bcd4",
            "input": "This paper presents results of our experiments using the Ubuntu Dialog Corpus –<lb>the largest publicly available multi-turn dialog corpus. First, we use an in-house<lb>implementation of previously reported models to do an independent evaluation<lb>using the same data. Second, we evaluate the performances of various LSTMs,<lb>Bi-LSTMs and CNNs on the dataset. Third, we create an ensemble by averaging<lb>predictions of multiple models. The ensemble further improves the performance<lb>and it achieves a state-of-the-art result for this dataset. Finally, we discuss our<lb>future plans using this corpus.",
            "output": [
                "Improved Deep Learning Baselines for Ubuntu Corpus Dialogs"
            ]
        },
        {
            "id": "task1540-4d5948af680e40739e884a95f40c590c",
            "input": "Eliminating the negative effect of highly non-stationary environmental noise is a long-standing research topic for speech recognition but remains an important challenge nowadays. To address this issue, traditional unsupervised signal processing methods seem to have touched the ceiling. However, data-driven based supervised approaches, particularly the ones designed with deep learning, have recently emerged as potential alternatives. In this light, we are going to comprehensively summarise the recently developed and most representative deep learning approaches to deal with the raised problem in this article, with the aim of providing guidelines for those who are going deeply into the field of environmentally robust speech recognition. To better introduce these approaches, we categorise them into singleand multi-channel techniques, each of which is specifically described at the front-end, the back-end, and the joint framework of speech recognition systems. In the meanwhile, we describe the pros and cons of these approaches as well as the relationships among them, which can probably benefit future research.",
            "output": [
                "Deep Learning for Environmentally Robust Speech Recognition: An Overview of Recent Developments"
            ]
        },
        {
            "id": "task1540-5b7e62e30ed149f8803f00fd8e4e9b80",
            "input": "Recent works have shown that synthetic parallel data automatically generated by translation models can be effective for various neural machine translation (NMT) issues. In this study, we build NMT systems using only synthetic parallel data. As an efficient alternative to real parallel data, we also present a new type of synthetic parallel corpus. The proposed pseudo parallel data are distinct from previous works in that ground truth and synthetic examples are mixed on both sides of sentence pairs. Experiments on Czech-German and French-German translations demonstrate the efficacy of the proposed pseudo parallel corpus, which shows not only enhanced results for bidirectional translation tasks but also substantial improvement with the aid of a ground truth real parallel corpus.",
            "output": [
                "Building a Neural Machine Translation System Using Only Synthetic Parallel Data"
            ]
        },
        {
            "id": "task1540-e10d0734c1c7464ba7e844697cfcfc59",
            "input": "In this paper, we present a system to visualize RDF knowledge graphs. These graphs are obtained from a knowledge extraction system designed by GEOLSemantics. This extraction is performed using natural language processing and trigger detection. The user can visualize subgraphs by selecting some ontology features like concepts or individuals. The system is also multilingual, with the use of the annotated ontology in English, French, Arabic and Chinese.",
            "output": [
                "RDF Knowledge Graph Visualization From a Knowledge Extraction System"
            ]
        },
        {
            "id": "task1540-6efbcd3f295e4fd5ad2611958678e029",
            "input": "Deep learning is a branch of artificial intelligence employing deep neural network architectures that has significantly advanced the state-of-the-art in computer vision, speech recognition, natural language processing and other domains. In November 2015, Google released TensorFlow, an open source deep learning software library for defining, training and deploying machine learning models. In this paper, we review TensorFlow and put it in context of modern deep learning concepts and software. We discuss its basic computational paradigms and distributed execution model, its programming interface as well as accompanying visualization toolkits. We then compare TensorFlow to alternative libraries such as Theano, Torch or Caffe on a qualitative as well as quantitative basis and finally comment on observed use-cases of TensorFlow in academia and industry.",
            "output": [
                "A Tour of TensorFlow"
            ]
        },
        {
            "id": "task1540-9f2836218d22426898975da1cd84fc7a",
            "input": "Each year, millions of motor vehicle traffic accidents all over the world cause a large number of fatalities, injuries and significant material loss. Automated Driving (AD) has potential to drastically reduce such accidents. In this work, we focus on the technical challenges that arise from AD in urban environments. We present the overall architecture of an AD system and describe in detail the perception and planning modules. The AD system, built on a modified Acura RLX, was demonstrated in a course in GoMentum Station in California. We demonstrated autonomous handling of 4 scenarios: traffic lights, cross-traffic at intersections, construction zones and pedestrians. The AD vehicle displayed safe behavior and performed consistently in repeated demonstrations with slight variations in conditions. Overall, we completed 44 runs, encompassing 110km of automated driving with only 3 cases where the driver intervened the control of the vehicle, mostly due to error in GPS positioning. Our demonstration showed that robust and consistent behavior in urban scenarios is possible, yet more investigation is necessary for full scale rollout on public roads.",
            "output": [
                "Towards Full Automated Drive in Urban Environments: A Demonstration in GoMentum Station, California"
            ]
        },
        {
            "id": "task1540-2c6bf4b5d6e14c29ac8ad8482ae4bf82",
            "input": "Bio-inspired optimization algorithms have been gaining more popularity recently. One of the most important of these algorithms is particle swarm optimization (PSO). PSO is based on the collective intelligence of a swam of particles. Each particle explores a part of the search space looking for the optimal position and adjusts its position according to two factors; the first is its own experience and the second is the collective experience of the whole swarm. PSO has been successfully used to solve many optimization problems. In this work we use PSO to improve the performance of a well-known representation method of time series data which is the symbolic aggregate approximation (SAX). As with other time series representation methods, SAX results in loss of information when applied to represent time series. In this paper we use PSO to propose a new minimum distance WMD for SAX to remedy this problem. Unlike the original minimum distance, the new distance sets different weights to different segments of the time series according to their information content. This weighted minimum distance enhances the performance of SAX as we show through experiments using different time series datasets.",
            "output": [
                "Particle Swarm Optimization of Information-Content Weighting of Symbolic Aggregate Approximation"
            ]
        },
        {
            "id": "task1540-10c53693d5694de8adff70a944f2e5b7",
            "input": "N-tuple networks have been successfully used as position evaluation functions for board games such as Othello or Connect Four. The effectiveness of such networks depends on their architecture, which is determined by the placement of constituent n-tuples, sequences of board locations, providing input to the network. The most popular method of placing ntuples consists in randomly generating a small number of long, snake-shaped board location sequences. In comparison, we show that learning n-tuple networks is significantly more effective if they involve a large number of systematically placed, short, straight n-tuples. Moreover, we demonstrate that in order to obtain the best performance and the steepest learning curve for Othello it is enough to use n-tuples of size just 2, yielding a network consisting of only 288 weights. The best such network evolved in this study has been evaluated in the online Othello League, obtaining the performance of nearly 96% — more than any other player to date.",
            "output": [
                "Systematic N-tuple Networks for Position Evaluation: Exceeding 90% in the Othello League"
            ]
        },
        {
            "id": "task1540-7f2419c4f60040839b12cbc034f178cd",
            "input": "We present a neural network architecture to predict a point in color space from the sequence of characters in the color’s name. Using large scale color–name pairs obtained from an online color design forum, we evaluate our model on a “color Turing test” and find that, given a name, the colors predicted by our model are preferred by annotators to color names created by humans. Our datasets and demo system are available online at http://colorlab.us.",
            "output": [
                "Character Sequence Models for Colorful Words"
            ]
        },
        {
            "id": "task1540-a1e25f13e5694cf9aee847f285d8a3a5",
            "input": "Despite the remarkable progress recently made in distant speech recognition, state-of-the-art technology still suffers from a lack of robustness, especially when adverse acoustic conditions characterized by non-stationary noises and reverberation are met. A prominent limitation of current systems lies in the lack of matching and communication between the various technologies involved in the distant speech recognition process. The speech enhancement and speech recognition modules are, for instance, often trained independently. Moreover, the speech enhancement normally helps the speech recognizer, but the output of the latter is not commonly used, in turn, to improve the speech enhancement. To address both concerns, we propose a novel architecture based on a network of deep neural networks, where all the components are jointly trained and better cooperate with each other thanks to a full communication scheme between them. Experiments, conducted using different datasets, tasks and acoustic conditions, revealed that the proposed framework can overtake other competitive solutions, including recent joint training approaches.",
            "output": [
                "A NETWORK OF DEEP NEURAL NETWORKS FOR DISTANT SPEECH RECOGNITION"
            ]
        },
        {
            "id": "task1540-de2f6f8d2f834264bb1310fbc16ce996",
            "input": "In Computer Vision, problem of identifying or classifying the objects present in an image is called Object Categorization. It is a challenging problem, especially when the images have clutter background, occlusions or different lighting conditions. Many vision features have been proposed which aid object categorization even in such adverse conditions. Past research has shown that, employing multiple features rather than any single features leads to better recognition. Multiple Kernel Learning (MKL) framework has been developed for learning an optimal combination of features for object categorization. Existing MKL methods use linear combination of base kernels which may not be optimal for object categorization. Real-world object categorization may need to consider complex combination of kernels(non-linear) and not only linear combination. Evolving non-linear functions of base kernels using Genetic Programming is proposed in this report. Experiment results show that non-kernel generated using genetic programming gives good accuracy as compared to linear combination of kernels.",
            "output": [
                "Finding Optimal Combination of Kernels using Genetic Programming"
            ]
        },
        {
            "id": "task1540-899a286ce110410fb8f2976c685e0907",
            "input": "In this work we present a method for using Deep Q-Networks (DQNs) in multi-objective tasks. Deep Q-Networks provide remarkable performance in single objective tasks learning from high-level visual perception. However, in many scenarios (e.g in robotics), the agent needs to pursue multiple objectives simultaneously. We propose an architecture in which separate DQNs are used to control the agent’s behaviour with respect to particular objectives. In this architecture we use signal suppression, known from the (Brooks) subsumption architecture, to combine outputs of several DQNs into a single action. Our architecture enables the decomposition of the agent’s behaviour into controllable and replaceable sub-behaviours learned by distinct modules. To evaluate our solution we used a game-like simulator in which an agent provided with high-level visual input pursues multiple objectives in a 2D world. Our solution provides benefits of modularity, while its performance is comparable to the monolithic approach.",
            "output": [
                "Multi-Objective Deep Q-Learning with Subsumption Architecture"
            ]
        },
        {
            "id": "task1540-f13b803a37514caf8c2e64167ef46331",
            "input": "Nowadays ontologies present a growing interest in Data Fusion applications. As a matter of fact, the ontologies are seen as a semantic tool for describing and reasoning about sensor data, objects, relations and general domain theories. In addition, uncertainty is perhaps one of the most important characteristics of the data and information handled by Data Fusion. However, the fundamental nature of ontologies implies that ontologies describe only asserted and veracious facts of the world. Different probabilistic, fuzzy and evidential approaches already exist to fill this gap; this paper recaps the most popular tools. However none of the tools meets exactly our purposes. Therefore, we constructed a Dempster-Shafer ontology that can be imported into any specific domain ontology and that enables us to instantiate it in an uncertain manner. We also developed a Java application that enables reasoning about these uncertain ontological instances.",
            "output": [
                "Uncertainty in Ontologies: Dempster-Shafer Theory for Data Fusion Applications"
            ]
        },
        {
            "id": "task1540-96a8f4dd2f9042f586f14595628befe3",
            "input": "Scientists often run experiments to distinguish competing theories. This requires patience, rigor, and ingenuity—there is often a large space of possible experiments one could run. But we need not comb this space by hand—if we represent our theories as formal models and explicitly declare the space of experiments, we can automate the search for good experiments, looking for those with high expected information gain. Here, we present a general and principled approach to experiment design based on probabilistic programming languages (PPLs). PPLs offer a clean separation between declaring problems and solving them, which means that the scientist can automate experiment design by simply declaring her model and experiment spaces in the PPL without having to worry about the details of calculating information gain. We demonstrate our system in two case studies drawn from cognitive psychology, where we use it to design optimal experiments in the domains of sequence prediction and categorization. We find strong empirical validation that our automatically designed experiments were indeed optimal. We conclude by discussing a number of interesting questions for future research.",
            "output": [
                "Practical optimal experiment design with probabilistic programs"
            ]
        },
        {
            "id": "task1540-ee1d059d4fde4af2acf1c12f2beaac0d",
            "input": "Speech analysis had been taken to a new level with the discovery of Reverse Speech (RS). RS is the discovery of hidden messages, referred as reversals, in normal speech. Works are in progress for exploiting the relevance of RS in different real world applications such as investigation, medical field etc. In this paper we represent an innovative method for preparing a reliable Software Requirement Specification (SRS) document with the help of reverse speech. As SRS act as the backbone for the successful completion of any project, a reliable method is needed to overcome the inconsistencies. Using RS such a reliable method for SRS documentation was developed. Keywords— Reverse Speech, Software Requirement Specification (SRS), Speech Enhancement, Speech Recognition.",
            "output": [
                "Software Requirement Specification Using Reverse Speech Technology"
            ]
        },
        {
            "id": "task1540-90d598abf88843c48841672870daced6",
            "input": "We simulate the training of a set of state of the art neural networks, the Maxout networks (Goodfellow et al., 2013a), on three benchmark datasets: the MNIST, CIFAR10 and SVHN, with three distinct arithmetics: floating point, fixed point and dynamic fixed point. For each of those datasets and for each of those arithmetics, we assess the impact of the precision of the computations on the final error of the training. We find that very low precision computation is sufficient not just for running trained networks but also for training them. For example, almost state-of-the-art results were obtained on most datasets with around 10 bits for computing activations and gradients, and 12 bits for storing updated parameters.",
            "output": [
                "LOW PRECISION ARITHMETIC FOR DEEP LEARNING"
            ]
        },
        {
            "id": "task1540-a8d1f8d57c9f4b08a7ad994ba13cb4e3",
            "input": "Wit is a quintessential form of rich interhuman interaction, and is often grounded in a specific situation (e.g., a comment in response to an event). In this work, we attempt to build computational models that can produce witty descriptions for a given image. Inspired by a cognitive account of humor appreciation, we employ linguistic wordplay, specifically puns. We compare our approach against meaningful baseline approaches via human studies. In a Turing test style evaluation, people find our model’s description for an image to be wittier than a human’s witty description 55% of the time!",
            "output": [
                "Punny Captions: Witty Wordplay in Image Descriptions"
            ]
        },
        {
            "id": "task1540-082dd847a0c048f997da6441c7bd0cbe",
            "input": "This paper addresses how a recursive neural network model can automatically leave out useless information and emphasize important evidence, in other words, to perform “weight tuning” for higher-level representation acquisition. We propose two models, Weighted Neural Network (WNN) and Binary-Expectation Neural Network (BENN), which automatically control how much one specific unit contributes to the higher-level representation. The proposed model can be viewed as incorporating a more powerful compositional function for embedding acquisition in recursive neural networks. Experimental results demonstrate the significant improvement over standard neural models.",
            "output": [
                "Feature Weight Tuning for Recursive Neural Networks"
            ]
        },
        {
            "id": "task1540-202c077790794c83a955566676982a75",
            "input": "We propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU nonlinearity is the expected transformation of a stochastic process which randomly applies the identity or zero map, combining the intuitions of dropout and zoneout while respecting neuron values. This connection suggests a new probabilistic understanding of nonlinearities. We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all tasks.",
            "output": [
                "Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units"
            ]
        },
        {
            "id": "task1540-02db4c4791c64027a10c58e77942d1ac",
            "input": "We argue that the optimization plays a crucial role in generalization of deep learning models through implicit regularization. We do this by demonstrating that generalization ability is not controlled by network size but rather by some other implicit control. We then demonstrate how changing the empirical optimization procedure can improve generalization, even if actual optimization quality is not affected. We do so by studying the geometry of the parameter space of deep networks, and devising an optimization algorithm attuned to this geometry.",
            "output": [
                "Geometry of Optimization and Implicit Regularization in Deep Learning"
            ]
        },
        {
            "id": "task1540-d0de5041b24446768cff747c68e8b80e",
            "input": "We develop new representations for the Lévy measures of the beta and gamma processes. These representations are manifested in terms of an infinite sum of well-behaved (proper) beta and gamma distributions. Further, we demonstrate how these infinite sums may be truncated in practice, and explicitly characterize truncation errors. We also perform an analysis of the characteristics of posterior distributions, based on the proposed decompositions. The decompositions provide new insights into the beta and gamma processes (and their generalizations), and we demonstrate how the proposed representation unifies some properties of the two. This paper is meant to provide a rigorous foundation for and new perspectives on Lévy processes, as these are of increasing importance in machine learning.",
            "output": [
                "Lévy Measure Decompositions for the Beta and Gamma Processes"
            ]
        },
        {
            "id": "task1540-f17c31bb37694959bd6e80bb06f43c59",
            "input": "Modelling problems containing a mixture of Boolean and numerical variables<lb>is a long-standing interest of Artificial Intelligence. However, performing<lb>inference and learning in hybrid domains is a particularly daunting task.<lb>The ability to model this kind of domains is crucial in “learning to design”<lb>tasks, that is, learning applications where the goal is to learn from examples<lb>how to perform automatic de novo design of novel objects. In this paper we<lb>present Structured Learning Modulo Theories, a max-margin approach for<lb>learning in hybrid domains based on Satisfiability Modulo Theories, which<lb>allows to combine Boolean reasoning and optimization over continuous linear<lb>arithmetical constraints. We validate our method on artificial and real world<lb>scenarios.<lb>",
            "output": [
                "Structured Learning Modulo Theories"
            ]
        },
        {
            "id": "task1540-3e2bc2449dcb44c183ae1db177c21dc3",
            "input": "We investigate the pertinence of methods from algebraic topology for text data analysis. These methods enable the development of mathematically-principled isometric-invariant mappings from a set of vectors to a document embedding, which is stable with respect to the geometry of the document in the selected metric space. In this work, we evaluate the utility of these topology-based document representations in traditional NLP tasks, specifically document clustering and sentiment classification. We find that the embeddings do not benefit text analysis. In fact, performance is worse than simple techniques like tf-idf, indicating that the geometry of the document does not provide enough variability for classification on the basis of topic or sentiment in the chosen datasets.",
            "output": [
                "Does the Geometry of Word Embeddings Help Document Classification? A Case Study on Persistent Homology Based Representations"
            ]
        },
        {
            "id": "task1540-bda3792257fa48d0ad3b58f9b41f5d4e",
            "input": "Microarrays are made it possible to simultaneously monitor the expression profiles of thousands of genes under various experimental conditions. It is used to identify the co-expressed genes in specific cells or tissues that are actively used to make proteins. This method is used to analysis the gene expression, an important task in bioinformatics research. Cluster analysis of gene expression data has proved to be a useful tool for identifying co-expressed genes, biologically relevant groupings of genes and samples. In this paper we applied K-Means with Automatic Generations of Merge Factor for ISODATAAGMFI. Though AGMFI has been applied for clustering of Gene Expression Data, this proposed Enhanced Automatic Generations of Merge Factor for ISODATAEAGMFI Algorithms overcome the drawbacks of AGMFI in terms of specifying the optimal number of clusters and initialization of good cluster centroids. Experimental results on Gene Expression Data show that the proposed EAGMFI algorithms could identify compact clusters with perform well in terms of the Silhouette Coefficients cluster measure.",
            "output": [
                "Performance Analysis of Enhanced Clustering Algorithm for Gene Expression Data"
            ]
        },
        {
            "id": "task1540-79ac5a82201645fe8ee129523ff9ccca",
            "input": "In this paper, we present algorithms that perform gradient ascent of the average reward in a partially observable Markov decision process (POMDP). These algorithms are based on GPOMDP, an algorithm introduced in a companion paper (Baxter & Bartlett, 2001), which computes biased estimates of the performance gradient in POMDPs. The algorithm’s chief advantages are that it uses only one free parameter 2 [0; 1), which has a natural interpretation in terms of bias-variance trade-off, it requires no knowledge of the underlying state, and it can be applied to infinite state, control and observation spaces. We show how the gradient estimates produced by GPOMDP can be used to perform gradient ascent, both with a traditional stochastic-gradient algorithm, and with an algorithm based on conjugate-gradients that utilizes gradient information to bracket maxima in line searches. Experimental results are presented illustrating both the theoretical results of Baxter and Bartlett (2001) on a toy problem, and practical aspects of the algorithms on a number of more realistic problems.",
            "output": [
                "Experiments with Infinite-Horizon, Policy-Gradient Estimation"
            ]
        },
        {
            "id": "task1540-b897672ecf784c0c800967cf87d510ac",
            "input": "The choice of architecture of artificial neuron network (ANN) is still a challenging task that users face every time. It greatly affects the accuracy of the built network. In fact there is no optimal method that is applicable to various implementations at the same time. In this paper we propose a method to construct ANN based on clustering, that resolves the problems of random and ad’hoc approaches for multilayer ANN architecture. Our method can be applied to regression problems. Experimental results obtained with different datasets, reveals the efficiency of our method.",
            "output": [
                "Towards a constructive multilayer perceptron for regression task using non-parametric clustering. A case study of Photo-Z redshift reconstruction"
            ]
        },
        {
            "id": "task1540-58f8ce7c39944b4d988455d99de10622",
            "input": "Unsupervised models of dependency parsing typically require large amounts of clean, unlabeled data plus gold-standard part-of-speech tags. Adding indirect supervision (e.g. language universals and rules) can help, but we show that obtaining small amounts of direct supervision—here, partial dependency annotations—provides a strong balance between zero and full supervision. We adapt the unsupervised ConvexMST dependency parser to learn from partial dependencies expressed in the Graph Fragment Language. With less than 24 hours of total annotation, we obtain 7% and 17% absolute improvement in unlabeled dependency scores for English and Spanish, respectively, compared to the same parser using only universal grammar constraints.",
            "output": [
                "Fill it up: Exploiting partial dependency annotations in a minimum spanning tree parser"
            ]
        },
        {
            "id": "task1540-b0f6c8a6a515433db7ca1ced3015f157",
            "input": "One of the benefits of belief networks and influence diagrams is that so much knowl­ edge is captured in the graphical structure. In particular, statements of conditional irrel­ evance (or independence) can be verified in time linear in the size of the graph. To re­ solve a particular inference query or decision problem, only some of the possible states and probability distributions must be specified, the \"requisite information.\" This paper presents a new, simple, and effi­ cient \"Bayes-ball\" algorithm which is well­ suited to both new students of belief net­ works and state of the art implementations. The Bayes-ball algorithm determines irrele­ vant sets and requisite information more ef­ ficiently than existing methods, and is linear in the size of the graph for belief networks and influence diagrams.",
            "output": [
                "Bayes-Ball: The Rational Pastime (for Determining Irrelevance and Requisite Information in Belief Networks and Influence Diagrams)"
            ]
        },
        {
            "id": "task1540-03faaf76750142eabfd9e4d2b1804e47",
            "input": "We describe a novel non-parametric statistical hypothesis test of relative dependence between a source variable and two candidate target variables. Such a test enables us to determine whether one source variable is significantly more dependent on a first target variable or a second. Dependence is measured via the HilbertSchmidt Independence Criterion (HSIC), resulting in a pair of empirical dependence measures (source-target 1, source-target 2). We test whether the first dependence measure is significantly larger than the second. Modeling the covariance between these HSIC statistics leads to a provably more powerful test than the construction of independent HSIC statistics by subsampling. The resulting test is consistent and unbiased, and (being based on U-statistics) has favorable convergence properties. The test can be computed in quadratic time, matching the computational complexity of standard empirical HSIC estimators. The effectiveness of the test is demonstrated on several real-world problems: we identify language groups from a multilingual corpus, and we prove that tumor location is more dependent on gene expression than chromosomal imbalances. Source code is available for download at https://github. com/wbounliphone/reldep. Proceedings of the 32 International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).",
            "output": [
                "A low variance consistent test of relative dependency"
            ]
        },
        {
            "id": "task1540-197633d2289b492486ca6ee2a26f3d00",
            "input": "The increase in the use of microblogging came along with the rapid growth on short linguistic data. On the other hand deep learning is considered to be the new frontier to extract meaningful information out of large amount of raw data in an automated manner. In this study, we engaged these two emerging fields to come up with a robust language identifier on demand, namely Language Identification Engine (LIDE). As a result, we achieved 95.12% accuracy in Discriminating between Similar Languages (DSL) Shared Task 2015 dataset, which is comparable to the maximum reported accuracy of 95.54% achieved so far.",
            "output": [
                "LIDE: Language Identification from Text Documents"
            ]
        },
        {
            "id": "task1540-b7f85b9e18ce409ba612669981b31f6e",
            "input": "We use some of the largest order statistics of the random projections of a reference signal to construct a binary embedding that is adapted to signals correlated with such signal. The embedding is characterized from the analytical standpoint and shown to provide improved performance on tasks such as classification in a reduced-dimensionality space. Keywords—Binary Embeddings, Random projections",
            "output": [
                "Binary adaptive embeddings from order statistics of random projections"
            ]
        },
        {
            "id": "task1540-0e2930c0767949afbab2554294698afa",
            "input": "Query-based video summarization is the task of creating a brief visual trailer, which captures the parts of the video (or a collection of videos) that are most relevant to the user-issued query. In this paper, we propose an unsupervised label propagation approach for this task. Our approach effectively captures the multimodal semantics of queries and videos using state-of-the-art deep neural networks and creates a summary that is both semantically coherent and visually attractive. We describe the theoretical framework of our graph-based approach and empirically evaluate its effectiveness in creating relevant and attractive trailers. Finally, we showcase example video trailers generated by our system.",
            "output": [
                "Semantic Video Trailers"
            ]
        },
        {
            "id": "task1540-87e6ea65df144dcfbcfbb1d64ccbd8c8",
            "input": "We consider the hashing mechanism for constructing binary embeddings, that involves pseudo-random projections followed by nonlinear (sign function) mappings. The pseudorandom projection is described by a matrix, where not all entries are independent random variables but instead a fixed “budget of randomness” is distributed across the matrix. Such matrices can be efficiently stored in sub-quadratic or even linear space, provide reduction in randomness usage (i.e. number of required random values), and very often lead to computational speed ups. We prove several theoretical results showing that projections via various structured matrices followed by nonlinear mappings accurately preserve the angular distance between input highdimensional vectors. To the best of our knowledge, these results are the first that give theoretical ground for the use of general structured matrices in the nonlinear setting. In particular, they generalize previous extensions of the JohnsonLindenstrauss lemma and prove the plausibility of the approach that was so far only heuristically confirmed for some special structured matrices. Consequently, we show that many structured matrices can be used as an efficient information compression mechanism. Our findings build a better understanding of certain deep architectures, which contain randomly weighted and untrained layers, and yet achieve high performance on different learning tasks. We empirically verify our theoretical findings and show the dependence of learning via structured hashed projections on the performance of neural network as well as nearest neighbor classifier. Equal contribution.",
            "output": [
                "Binary embeddings with structured hashed projections"
            ]
        },
        {
            "id": "task1540-ee2e8fdd5c0b4e56b41f7d8f7757cba7",
            "input": "We propose the concept of Action-Related Place (ARPlace) as a powerful and flexible representation of task-related place in the context of mobile manipulation. ARPlace represents robot base locations not as a single position, but rather as a collection of positions, each with an associated probability that the manipulation action will succeed when located there. ARPlaces are generated using a predictive model that is acquired through experience-based learning, and take into account the uncertainty the robot has about its own location and the location of the object to be manipulated. When executing the task, rather than choosing one specific goal position based only on the initial knowledge about the task context, the robot instantiates an ARPlace, and bases its decisions on this ARPlace, which is updated as new information about the task becomes available. To show the advantages of this least-commitment approach, we present a transformational planner that reasons about ARPlaces in order to optimize symbolic plans. Our empirical evaluation demonstrates that using ARPlaces leads to more robust and efficient mobile manipulation in the face of state estimation uncertainty on our simulated robot.",
            "output": [
                "Learning and Reasoning with Action-Related Places for Robust Mobile Manipulation"
            ]
        },
        {
            "id": "task1540-cfb43c18389c4728bde10c41ac2b7a61",
            "input": "The paper studies the problem of recovering a spectrally sparse object from a small number of time domain samples. Specifically, the object of interest with ambient dimension n is assumed to be a mixture of r complex multi-dimensional sinusoids, while the underlying frequencies can assume any value in the unit disk. Conventional compressed sensing paradigms suffer from the basis mismatch issue when imposing a discrete dictionary on the Fourier representation. To address this problem, we develop a novel nonparametric algorithm, called enhanced matrix completion (EMaC), based on structured matrix completion. The algorithm starts by arranging the data into a low-rank enhanced form with multi-fold Hankel structure, then attempts recovery via nuclear norm minimization. Under mild incoherence conditions, EMaC allows perfect recovery as soon as the number of samples exceeds the order of O(r log n). We also show that, in many instances, accurate completion of a low-rank multi-fold Hankel matrix is possible when the number of observed entries is proportional to the information theoretical limits (except for a logarithmic gap). The robustness of EMaC against bounded noise and its applicability to super resolution are further demonstrated by numerical experiments.",
            "output": [
                "Spectral Compressed Sensing via Structured Matrix Completion"
            ]
        },
        {
            "id": "task1540-44e7e7c831914db2848f2ab15bf9e4a2",
            "input": "We discuss the problem of construction of inference procedures which can manipulate with uncertainties measured in ordinal scales and fulfil to the property of strict monotonic­ ity of conclusion. The class of A-valuations of plausibility is considered where operations based only on information about linear or­ dering of plausibility values are used. In this class the modus ponens generating function fulfiling to the property of strict monotonic­ ity of conclusions is introduced. 1 STABILITY OF DECISIONS IN INFERENCE PROCEDURES Human judgements about plausibility, truth, certainty values of premises, rules and facts are usually qualita­ tive and measured in ordinal scales. Representation of these judgements by numbers from interval L = [0, lJ or L = [0, 100] and using over these numbers quanti­ tative operations such as multiplication, addition and so on is not always correct. Let's consider example. Let R1 and R2 are two rules of some expert system: Rl: If At then H1,pv(RI), (1) R2: If A2 then H2,pv(R2), (2) where pv(RI) and pv(R2) are the plausibility, cer­ tainty, truth values of rules measured in some linearly ordered scale L, for example L = [0, 1]. Often plausi­ bilities of conclusions are calculated by: pv(Ht) = pv(Rl) * pv(At), (3) pv(H2) = pv(R2) * pv(A2), (4) where pv(At) and pv(A2} are the plausibilities of premises and * is some T-norm, for example multi­ plication operation (Godo, Lopez de Mantaras et al. 1988; Hall1990; Trillas, Valverde 1985; Valverde, Tril­ las 1985; Forsyth 1984). Generally the plausibility of conclusion can be calculated by means of a modus po­ nens generating function mpgf: pv(HI) = mpgf(p·v(At),pv(Rt)). Let in (1)-( 4) the qualitative information about plau­ sibility values is the next: pv(At) < pv(A2} < pv(R2) < pv(RI), (5) that is the plausibility values of premises are less than the plausibility values of rules, the plausibility value of A1 is less than the plausibility value of A2 and the plausibility value of rule R2 is less than the plausibility value of rule Rl. Let these plausibility values are inter­ preted as the next quantitative values from L = (0, 1]: pv(A1) = 0.3 < pv(A2) = 0. 4 < pv(R2} = 0.6 <",
            "output": [
                "Modus Ponens Generating Function in the Class of A-valuations of Plausibility"
            ]
        },
        {
            "id": "task1540-5b3e5442b78f497dbee9dbbe2e0ebf5a",
            "input": "Verbs play a critical role in the meaning of sentences, but these ubiquitous words have received little attention in recent distributional semantics research. We introduce SimVerb-3500, an evaluation resource that provides human ratings for the similarity of 3,500 verb pairs. SimVerb-3500 covers all normed verb types from the USF free-association database, providing at least three examples for every VerbNet class. This broad coverage facilitates detailed analyses of how syntactic and semantic phenomena together influence human understanding of verb meaning. Further, with significantly larger development and test sets than existing benchmarks, SimVerb-3500 enables more robust evaluation of representation learning architectures and promotes the development of methods tailored to verbs. We hope that SimVerb-3500 will enable a richer understanding of the diversity and complexity of verb semantics and guide the development of systems that can effectively represent and interpret this meaning.",
            "output": [
                "SimVerb-3500: A Large-Scale Evaluation Set of Verb Similarity"
            ]
        },
        {
            "id": "task1540-361d8e77433842a6bced5e6a72533415",
            "input": "We study online boosting, the task of converting any weak online learner into a strong online learner. Based on a novel and natural definition of weak online learnability, we develop two online boosting algorithms. The first algorithm is an online version of boost-by-majority. By proving a matching lower bound, we show that this algorithm is essentially optimal in terms of the number of weak learners and the sample complexity needed to achieve a specified accuracy. This optimal algorithm is not adaptive, however. Using tools from online loss minimization, we derive an adaptive online boosting algorithm that is also parameter-free, but not optimal. Both algorithms work with base learners that can handle example importance weights directly, as well as by rejection sampling examples with probability defined by the booster. Results are complemented with an experimental study.",
            "output": [
                "Optimal and Adaptive Algorithms for Online Boosting"
            ]
        },
        {
            "id": "task1540-2b28d616bf174952a1eb13c0d2869904",
            "input": "This paper presents the systems developed by LIUM and CVC for the WMT16 Multimodal Machine Translation challenge. We explored various comparative methods, namely phrase-based systems and attentional recurrent neural networks models trained using monomodal or multimodal data. We also performed a human evaluation in order to estimate the usefulness of multimodal data for human machine translation and image description generation. Our systems obtained the best results for both tasks according to the automatic evaluation metrics BLEU and METEOR.",
            "output": [
                "Does Multimodality Help Human and Machine for Translation and Image Captioning?"
            ]
        },
        {
            "id": "task1540-693e482e4120406ba17df2b50114926b",
            "input": "We present a system that produces sentential descriptions of video: who did what to whom, and where and how they did it. Action class is rendered as a verb, participant objects as noun phrases, properties of those objects as adjectival modifiers in those noun phrases, spatial relations between those participants as prepositional phrases, and characteristics of the event as prepositional-phrase adjuncts and adverbial modifiers. Extracting the information needed to render these linguistic entities requires an approach to event recognition that recovers object tracks, the track-to-role assignments, and changing body posture.",
            "output": [
                "Video In Sentences Out"
            ]
        },
        {
            "id": "task1540-d9ea70d4c7dd408ca0625be85aaec691",
            "input": "Extracting per-frame features using convolutional neural networks for real-time processing of video data is currently mainly performed on powerful GPU-accelerated workstations and compute clusters. However, there are many applications such as smart surveillance cameras that require or would benefit from on-site processing. To this end, we propose and evaluate a novel algorithm for changebased evaluation of CNNs for video data recorded with a static camera setting, exploiting the spatio-temporal sparsity of pixel changes. We achieve an average speed-up of 8.6× over a cuDNN baseline on a realistic benchmark with a negligible accuracy loss of less than 0.1% and no retraining of the network. The resulting energy efficiency is 10× higher than per-frame evaluation and reaches an equivalent of 328GOp/s/W on the Tegra X1 platform.",
            "output": [
                "CBinfer: Change-Based Inference for Convolutional Neural Networks on Video Data"
            ]
        },
        {
            "id": "task1540-3ae9d6bb878748d8845c61f84966d53b",
            "input": "Non-technical losses (NTL) such as electricity theft cause significant harm to our economies, as in some countries they may range up to 40% of the total electricity distributed. Detecting NTLs requires costly on-site inspections. Accurate prediction of NTLs for customers using machine learning is therefore crucial. To date, related research largely ignore that the two classes of regular and non-regular customers are highly imbalanced, that NTL proportions may change and mostly consider small data sets, often not allowing to deploy the results in production. In this paper, we present a comprehensive approach to assess three NTL detection models for different NTL proportions in large real world data sets of 100Ks of customers: Boolean rules, fuzzy logic and Support Vector Machine. This work has resulted in appreciable results that are about to be deployed in a leading industry solution. We believe that the considerations and observations made in this contribution are necessary for future smart meter research in order to report their effectiveness on imbalanced and large real world data sets.",
            "output": [
                "Large-Scale Detection of Non-Technical Losses in Imbalanced Data Sets"
            ]
        },
        {
            "id": "task1540-dde6666cf7d14a5a8344d1a75d07bf4f",
            "input": "We investigate the problem of sentence-level supporting argument detection from relevant documents for user-specified claims. A dataset containing claims and associated citation articles is collected from online debate website idebate.org. We then manually label sentence-level supporting arguments from the documents along with their types as STUDY, FACTUAL, OPINION, or REASONING. We further characterize arguments of different types, and explore whether leveraging type information can facilitate the supporting arguments detection task. Experimental results show that LambdaMART (Burges, 2010) ranker that uses features informed by argument types yields better performance than the same ranker trained without type information.",
            "output": [
                "Understanding and Detecting Supporting Arguments of Diverse Types"
            ]
        },
        {
            "id": "task1540-972c681f770a43db80faee8533a36003",
            "input": "We study propagation of the RegularGcc global constraint. This ensures that each row of a matrix of decision variables satisfies a Regular constraint, and each column satisfies a Gcc constraint. On the negative side, we prove that propagation is NP-hard even under some strong restrictions (e.g. just 3 values, just 4 states in the automaton, or just 5 columns to the matrix). On the positive side, we identify two cases where propagation is fixed parameter tractable. In addition, we show how to improve propagation over a simple decomposition into separate Regular and Gcc constraints by identifying some necessary but insufficient conditions for a solution. We enforce these conditions with some additional weighted row automata. Experimental results demonstrate the potential of these methods on some standard benchmark problems.",
            "output": [
                "The RegularGcc Matrix Constraint"
            ]
        },
        {
            "id": "task1540-cdac41f58a8f4267ac715a088163a95f",
            "input": "In neural machine translation (NMT), generation of a target word depends on both source and target contexts. We find that source contexts have a direct impact on the adequacy of a translation while target contexts on the fluency. Intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context. Due to lack of effective control on the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations. To address this problem, we propose to use context gates to dynamically control the ratios at which source and target contexts contribute to the generation of target words. In this way, we can enhance the adequacy of NMT while keeping the fluency unchanged. Experiments show that our approach significantly improves upon a standard attention-based NMT system by +2.3 BLEU points.",
            "output": [
                "Context Gates for Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-0a6850bc26464d5fb43bbc132ee8ae8e",
            "input": "Automatic question generation aims to generate questions from a text passage where the generated questions can be answered by certain sub-spans of the given passage. Traditional methods mainly use rigid heuristic rules to transform a sentence into related questions. In this work, we propose to apply the neural encoderdecoder model to generate meaningful and diverse questions from natural language sentences. The encoder reads the input text and the answer position, to produce an answer-aware input representation, which is fed to the decoder to generate an answer focused question. We conduct a preliminary study on neural question generation from text with the SQuAD dataset, and the experiment results show that our method can produce fluent and diverse questions.",
            "output": [
                "Neural Question Generation from Text: A Preliminary Study"
            ]
        },
        {
            "id": "task1540-339c225e4fb748f0989d9822979d037f",
            "input": "Most conventional sentence similarity methods only focus on similar parts of two input sentences, and simply ignore the dissimilar parts, which usually give us some clues and semantic meanings about the sentences. In this work, we propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences. The model represents each word as a vector, and calculates a semantic matching vector for each word based on all words in the other sentence. Then, each word vector is decomposed into a similar component and a dissimilar component based on the semantic matching vector. After this, a twochannel CNN model is employed to capture features by composing the similar and dissimilar components. Finally, a similarity score is estimated over the composed feature vectors. Experimental results show that our model gets the state-of-the-art performance on the answer sentence selection task, and achieves a comparable result on the paraphrase identification task.",
            "output": [
                "Sentence Similarity Learning by Lexical Decomposition and Composition"
            ]
        },
        {
            "id": "task1540-6d56764a9d664dc1836f335245a9158e",
            "input": "To model time-varying nonlinear temporal dynamics in sequential data, a recurrent network capable of varying and adjusting the recurrence depth between input intervals is examined. The recurrence depth is extended by several intermediate hidden state units, and the weight parameters involved in determining these units are dynamically calculated. The motivation behind the paper lies on overcoming a deficiency in Recurrent Highway Networks and improving their performances which are currently at the forefront of RNNs: 1) Determining the appropriate number of recurrent depth in RHN for different tasks is a huge burden and just setting it to a large number is computationally wasteful with possible repercussion in terms of performance degradation and high latency. Expanding on the idea of adaptive computation time (ACT), with the use of an elastic gate in the form of a rectified exponentially decreasing function taking on as arguments as previous hidden state and input, the proposed model is able to evaluate the appropriate recurrent depth for each input. The rectified gating function enables the most significant intermediate hidden state updates to come early such that significant performance gain is achieved early. 2) Updating the weights from that of previous intermediate layer offers a richer representation than the use of shared weights across all intermediate recurrence layers. The weight update procedure is just an expansion of the idea underlying hypernetworks. To substantiate the effectiveness of the proposed network, we conducted three experiments: regression on synthetic data, human activity recognition, and language modeling on the Penn Treebank dataset. The proposed networks showed better performance than other state-of-theart recurrent networks in all three experiments.",
            "output": [
                "Early Improving Recurrent Elastic Highway Network"
            ]
        },
        {
            "id": "task1540-de884ae9d2f642eea2512138c6548453",
            "input": "The zero-shot paradigm exploits vector-based word representations extracted from text corpora with unsupervised methods to learn general mapping functions from other feature spaces onto word space, where the words associated to the nearest neighbours of the mapped vectors are used as their linguistic labels. We show that the neighbourhoods of the mapped elements are strongly polluted by hubs, vectors that tend to be near a high proportion of items, pushing their correct labels down the neighbour list. After illustrating the problem empirically, we propose a simple method to correct it by taking the proximity distribution of potential neighbours across many mapped vectors into account. We show that this correction leads to consistent improvements in realistic zero-shot experiments in the cross-lingual, image labeling and image retrieval domains.",
            "output": [
                "IMPROVING ZERO-SHOT LEARNING BY MITIGATING THE HUBNESS PROBLEM"
            ]
        },
        {
            "id": "task1540-9f6b6bed5517440a959ca45f24bde517",
            "input": "We consider a transfer-learning problem by using the parameter transfer approach, where a suitable parameter of feature mapping is learned through one task and applied to another objective task. Then, we introduce the notion of the local stability of parametric feature mapping and parameter transfer learnability, and thereby derive a learning bound for parameter transfer algorithms. As an application of parameter transfer learning, we discuss the performance of sparse coding in selftaught learning. Although self-taught learning algorithms with plentiful unlabeled data often show excellent empirical performance, their theoretical analysis has not been studied. In this paper, we also provide the first theoretical learning bound for self-taught learning.",
            "output": [
                "Learning Bound for Parameter Transfer Learning"
            ]
        },
        {
            "id": "task1540-f1e9b5ef18d84a1da23a81ae21b932b4",
            "input": "The human intelligence lies in the algorithm, the nature of algorithms lies in the classification, and the classification is equal to outlier detection. This paper is based on its past unpublished edition (2009), which discussed an application of פ (pe) algorithm in outlier detection for time series data. The פ algorithm, also named as RDD algorithm, is originated from the study on general AI. United with it, designed modules can be used to realize kinds of tasks. A primary framework concerned with the mind through פ algorithm has been constructed in prior works. In this concise paper, we neglect background and minor description of the early edition, and directly discuss the main contents include longest k–turn subsequence problem, curve type outliers, futural directions and related comments. In section “Past Present”, we keep all prior conclusions, though a little might be out of date.",
            "output": [
                "פ Algorithm: its past present, futue present and comments"
            ]
        },
        {
            "id": "task1540-f360bfa34c7949f28278144647eac9c5",
            "input": "Information discounting plays an important role in the theory of belief functions and, generally, in information fusion. Nevertheless, neither classical uniform discounting nor contextual cannot model certain use cases, notably temporal discounting. In this article, new contextual discounting schemes, conservative, proportional and optimistic, are proposed. Some properties of these discounting operations are examined. Classical discounting is shown to be a special case of these schemes. Two motivating cases are discussed: modelling of source reliability and application to temporal discounting.",
            "output": [
                "Conservative, Proportional and Optimistic Contextual Discounting in the Belief Functions Theory"
            ]
        },
        {
            "id": "task1540-03af2870434544089a82a1d0c1129a30",
            "input": "We report on our system for the shared task on discrimination of similar languages (DSL 2016). The system uses only byte representations in a deep residual network (ResNet). The system, named ResIdent, is trained only on the data released with the task (closed training). We obtain 84.88% accuracy on subtask A, 68.80% accuracy on subtask B1, and 69.80% accuracy on subtask B2. A large difference in accuracy on development data can be observed with relatively minor changes in our network’s architecture and hyperparameters. We therefore expect fine-tuning of these parameters to yield higher accuracies.",
            "output": [
                "Byte-based Language Identification with Deep Convolutional Networks"
            ]
        },
        {
            "id": "task1540-3c9860fb24b142beb9b71d501bf25604",
            "input": "Recent studies have shown that deep neural networks (DNN) are vulnerable to adversarial samples: maliciously-perturbed samples crafted to yield incorrect model outputs. Such attacks can severely undermine DNN systems, particularly in security-sensitive settings. It was observed that an adversary could easily generate adversarial samples by making a small perturbation on irrelevant feature dimensions that are unnecessary for the current classification task. To overcome this problem, we introduce a defensive mechanism called DeepMask. By identifying and removing unnecessary features in a DNN model, DeepMask limits the capacity an attacker can use generating adversarial samples and therefore increase the robustness against such inputs. Comparing with other defensive approaches, DeepMask is easy to implement and computationally efficient. Experimental results show that DeepMask can increase the performance of state-of-the-art DNN models against adversarial samples.",
            "output": [
                "DEEPMASK: MASKING DNN MODELS FOR ROBUST- NESS AGAINST ADVERSARIAL SAMPLES"
            ]
        },
        {
            "id": "task1540-4b0334d6d105432b8ee1048031131698",
            "input": "In a recent paper, we have shown that Plan Recognition over STRIPS can be formulated and solved using Classical Planning heuristics and algorithms (Ramirez and Geffner 2009). In this work, we show that this formulation subsumes the standard formulation of Plan Recognition over libraries through a compilation of libraries into STRIPS theories. The libraries correspond to AND/OR graphs that may be cyclic and where children of AND nodes may be partially ordered. These libraries include Context-Free Grammars as a special case, where the Plan Recognition problem becomes a parsing with missing tokens problem. Plan Recognition over the standard libraries become Planning problems that can be easily solved by any modern planner, while recognition over more complex libraries, including Context–Free Grammars (CFGs), illustrate limitations of current Planning heuristics and suggest improvements that may be relevant in other Planning problems too.",
            "output": [
                "Heuristics for Planning, Plan Recognition and Parsing (Written: June 2009, Published: May 2016)"
            ]
        },
        {
            "id": "task1540-82363befa41e45808ac49de2c2defdbe",
            "input": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNetlevel accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 1MB (461x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet",
            "output": [
                "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size"
            ]
        },
        {
            "id": "task1540-b1fe68b718524c1b839d6d52084dd231",
            "input": "Continuous-time Bayesian networks is a natural structured representation language for multicomponent stochastic processes that evolve continuously over time. Despite the compact representation, inference in such models is intractable even in relatively simple structured networks. Here we introduce a mean field variational approximation in which we use a product of inhomogeneous Markov processes to approximate a distribution over trajectories. This variational approach leads to a globally consistent distribution, which can be efficiently queried. Additionally, it provides a lower bound on the probability of observations, thus making it attractive for learning tasks. We provide the theoretical foundations for the approximation, an efficient implementation that exploits the wide range of highly optimized ordinary differential equations (ODE) solvers, experimentally explore characterizations of processes for which this approximation is suitable, and show applications to a large-scale realworld inference problem.",
            "output": [
                "Mean Field Variational Approximation for Continuous-Time Bayesian Networks"
            ]
        },
        {
            "id": "task1540-768cd49df94c41b6a2b54a52899aa20d",
            "input": "In most practical problems of classifier learning, the training data suffers from the label noise. Hence, it is important to understand how robust is a learning algorithm to such label noise. This paper presents some theoretical analysis to show that many popular decision tree algorithms are robust to symmetric label noise under large sample size. We also present some sample complexity results which provide some bounds on the sample size for the robustness to hold with a high probability. Through extensive simulations we illustrate this robustness.",
            "output": [
                "On the Robustness of Decision Tree Learning under Label Noise"
            ]
        },
        {
            "id": "task1540-eef3f5334a624f36b4f7efc4d12d2eda",
            "input": "Recurrent neural network (RNN) based character-level language models (CLMs) are extremely useful for modeling unseen words by nature. However, their performance is generally much worse than the word-level language models (WLMs), since CLMs need to consider longer history of tokens to properly predict the next one. We address this problem by proposing hierarchical RNN architectures, which consist of multiple modules with different clock rates. Despite the multiclock structures, the input and output layers operate with the character-level clock, which allows the existing RNN CLM training approaches to be directly applicable without any modifications. Our CLM models show better perplexity than KneserNey (KN) 5-gram WLMs on the One Billion Word Benchmark with only 2% of parameters. Also, we present real-time character-level end-to-end speech recognition examples on the Wall Street Journal (WSJ) corpus, where replacing traditional mono-clock RNN CLMs with the proposed models results in better recognition accuracies even though the number of parameters are reduced to 30%.",
            "output": [
                "Character-Level Language Modeling with Hierarchical Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-dc3fbb7aaf664fde9848150df8a1bd04",
            "input": "With ever-increasing computational demand for deep learning, it is critical to investigate the implications of the numeric representation and precision of DNN model weights and activations on computational efficiency. In this work, we explore unconventional narrow-precision floating-point representations as it relates to inference accuracy and efficiency to steer the improved design of future DNN platforms. We show that inference using these custom numeric representations on production-grade DNNs, including GoogLeNet and VGG, achieves an average speedup of 7.6× with less than 1% degradation in inference accuracy relative to a state-of-the-art baseline platform representing the most sophisticated hardware using single-precision floating point. To facilitate the use of such customized precision, we also present a novel technique that drastically reduces the time required to derive the optimal precision configuration.",
            "output": [
                "DEEP NEURAL NETWORKS"
            ]
        },
        {
            "id": "task1540-9bc5bae4e5124f6ab12d51597008d647",
            "input": "We describe a dynamic programming algorithm for computing the marginal distribution of discrete probabilistic programs. This algorithm takes a functional interpreter for an arbitrary probabilistic programming language and turns it into an efficient marginalizer. Because direct caching of sub-distributions is impossible in the presence of recursion, we build a graph of dependencies between sub-distributions. This factored sum-product network makes (potentially cyclic) dependencies between subproblems explicit, and corresponds to a system of equations for the marginal distribution. We solve these equations by fixed-point iteration in topological order. We illustrate this algorithm on examples used in teaching probabilistic models, computational cognitive science research, and game theory.",
            "output": [
                "A Dynamic Programming Algorithm for Inference in Recursive Probabilistic Programs"
            ]
        },
        {
            "id": "task1540-53079f1ffd5d4b87b730ac6b7bdc0c97",
            "input": "Ontology-based data access is concerned with querying incomplete data sources in the presence of domain-specific knowledge provided by an ontology. A central notion in this setting is that of an ontology-mediated query, which is a database query coupled with an ontology. In this paper, we study several classes of ontology-mediated queries, where the database queries are given as some form of conjunctive query and the ontologies are formulated in description logics or other relevant fragments of first-order logic, such as the guarded fragment and the unary-negation fragment. The contributions of the paper are three-fold. First, we characterize the expressive power of ontology-mediated queries in terms of fragments of disjunctive datalog. Second, we establish intimate connections between ontology-mediated queries and constraint satisfaction problems (CSPs) and their logical generalization, MMSNP formulas. Third, we exploit these connections to obtain new results regarding (i) first-order rewritability and datalogrewritability of ontology-mediated queries, (ii) P/NP dichotomies for ontology-mediated queries, and (iii) the query containment problem for ontology-mediated queries.",
            "output": [
                "Ontology-based Data Access: A Study through Disjunctive Datalog, CSP, and MMSNP"
            ]
        },
        {
            "id": "task1540-28ba2c1cee404b4e9ea719a918c823ce",
            "input": "This paper discusses models for dialogue state tracking using recurrent neural networks (RNN). We present experiments on the standard dialogue state tracking (DST) dataset, DSTC2 [7]. On the one hand, RNN models became the state of the art models in DST, on the other hand, most state-of-the-art DST models are only turn-based and require dataset-specific preprocessing (e.g. DSTC2-specific) in order to achieve such results. We implemented two architectures which can be used in an incremental setting and require almost no preprocessing. We compare their performance to the benchmarks on DSTC2 and discuss their properties. With only trivial preprocessing, the performance of our models is close to the state-ofthe-art results.1",
            "output": [
                "Recurrent Neural Networks for Dialogue State Tracking"
            ]
        },
        {
            "id": "task1540-c09912aef1984f77af50529f61941a4d",
            "input": "People can recognize scenes across many different modalities beyond natural images. In this paper, we investigate how to learn cross-modal scene representations that transfer across modalities. To study this problem, we introduce a new cross-modal scene dataset. While convolutional neural networks can categorize scenes well, they also learn an intermediate representation not aligned across modalities, which is undesirable for cross-modal transfer applications. We present methods to regularize cross-modal convolutional neural networks so that they have a shared representation that is agnostic of the modality. Our experiments suggest that our scene representation can help transfer representations across modalities for retrieval. Moreover, our visualizations suggest that units emerge in the shared representation that tend to activate on consistent concepts independently of the modality.",
            "output": [
                "Cross-Modal Scene Networks"
            ]
        },
        {
            "id": "task1540-4df1c491c41346db94ad787bb7ffb119",
            "input": "The paper analyzes the interaction between humans and computers in terms of response time in solving the image-based CAPTCHA. In particular, the analysis focuses on the attitude of the different Internet users in easily solving four different types of image-based CAPTCHAs which include facial expressions like: animated character, old woman, surprised face, worried face. To pursue this goal, an experiment is realized involving 100 Internet users in solving the four types of CAPTCHAs, differentiated by age, Internet experience, and education level. The response times are collected for each user. Then, association rules are extracted from user data, for evaluating the dependence of the response time in solving the CAPTCHA from age, education level and experience in internet usage by statistical analysis. The results implicitly capture the users’ psychological states showing in what states the users are more sensible. It reveals to be a novelty and a meaningful analysis in the state-of-the-art.",
            "output": [
                "Analysis of the Human-Computer Interaction on the Example of Image-based CAPTCHA by Association Rule Mining"
            ]
        },
        {
            "id": "task1540-063121feb6eb4f0eaf05fa1ae71fcbc7",
            "input": "<lb>Recent price-of-anarchy analyses of games of complete information suggest that coarse correlated<lb>equilibria, which characterize outcomes resulting from no-regret learning dynamics, have near-optimal<lb>welfare. This work provides two main technical results that lift this conclusion to games of incomplete<lb>information, a.k.a., Bayesian games. First, near-optimal welfare in Bayesian games follows directly from<lb>the smoothness-based proof of near-optimal welfare in the same game when the private information<lb>is public. Second, no-regret learning dynamics converge to Bayesian coarse correlated equilibrium in<lb>these incomplete information games. These results are enabled by interpretation of a Bayesian game<lb>as a stochastic game of complete information.",
            "output": [
                "No-Regret Learning in Repeated Bayesian Games"
            ]
        },
        {
            "id": "task1540-2ea1a3fec7774a70b67603cb7d3e8e7a",
            "input": "The introduction of loopy belief propagation (LBP) revitalized the application of graphical models in many domains. Many recent works present improvements on the basic LBP algorithm in an attempt to overcome convergence and local optima problems. Notable among these are convexified free energy approximations that lead to inference procedures with provable convergence and quality properties. However, empirically LBP still outperforms most of its convex variants in a variety of settings, as we also demonstrate here. Motivated by this fact we seek convexified free energies that directly approximate the Bethe free energy. We show that the proposed approximations compare favorably with state-of-the art convex free energy approximations.",
            "output": [
                "Convexifying the Bethe Free Energy"
            ]
        },
        {
            "id": "task1540-c3d3ec9d1add4304a61667fc9dec1cc4",
            "input": "We show that the herding procedure of Welling (2009b) takes exactly the form of a standard convex optimization algorithm— namely a conditional gradient algorithm minimizing a quadratic moment discrepancy. This link enables us to invoke convergence results from convex optimization and to consider faster alternatives for the task of approximating integrals in a reproducing kernel Hilbert space. We study the behavior of the different variants through numerical simulations. Our experiments shed more light on the learning bias of herding: they indicate that while we can improve over herding on the task of approximating integrals, the original herding algorithm approaches more often the maximum entropy distribution.",
            "output": [
                "On the Equivalence between Herding and Conditional Gradient Algorithms"
            ]
        },
        {
            "id": "task1540-fa30a59569b145998d9e13bd7955904f",
            "input": "One of the key issues in both natural language understanding and generation is the appropriate processing of Multiword Expressions (MWEs). MWEs pose a huge problem to the precise language processing due to their idiosyncratic nature and diversity in lexical, syntactical and semantic properties. The semantics of a MWE cannot be expressed after combining the semantics of its constituents. Therefore, the formalism of semantic clustering is often viewed as an instrument for extracting MWEs especially for resource constraint languages like Bengali. The present semantic clustering approach contributes to locate clusters of the synonymous noun tokens present in the document. These clusters in turn help measure the similarity between the constituent words of a potentially candidate phrase using a vector space model and judge the suitability of this phrase to be a MWE. In this experiment, we apply the semantic clustering approach for nounnoun bigram MWEs, though it can be extended to any types of MWEs. In parallel, the well known statistical models, namely Point-wise Mutual Information (PMI), Log Likelihood Ratio (LLR), Significance function are also employed to extract MWEs from the Bengali corpus. The comparative evaluation shows that the 372 Chakraborty et al. semantic clustering approach outperforms all other competing statistical models. As a byproduct of this experiment, we have started developing a standard lexicon in Bengali that serves as a productive Bengali linguistic thesaurus.",
            "output": [
                "Identifying Bengali Multiword Expressions using Semantic Clustering"
            ]
        },
        {
            "id": "task1540-bb684bb84bd7499899ad62af1751bf0f",
            "input": "Agents of general intelligence deployed in real-world scenarios must adapt to ever-changing environmental conditions. While such adaptive agents may leverage engineered knowledge, they will require the capacity to construct and evaluate knowledge themselves from their own experience in a bottom-up, constructivist fashion. This position paper builds on the idea of encoding knowledge as temporally extended predictions through the use of general value functions. Prior work has focused on learning predictions about externally derived signals about a task or environment (e.g. battery level, joint position). Here we advocate that the agent should also predict internally generated signals regarding its own learning process—for example, an agent’s confidence in its learned predictions. Finally, we suggest how such information would be beneficial in creating an introspective agent that is able to learn to make good decisions in a complex, changing world. Predictive Knowledge. The ability to autonomously construct knowledge directly from experience produced by an agent interacting with the world is a key requirement for general intelligence. One particularly promising form of knowledge that is grounded in experience is predictive knowledge—here defined as a collection of multi-step predictions about observable outcomes that are contingent on different ways of behaving. Much like scientific knowledge, predictive knowledge can be maintained and updated by making a prediction, executing a procedure, and observing the outcome and updating the prediction—a process completely independent of human intervention. Experience-grounded predictions are a powerful resource to guide decision making in environments which are too complex or dynamic to be exhaustively anticipated by an engineer [1,2]. A value function from the field of reinforcement learning is one way of representing predictive knowledge. Value functions are a learned or computed mapping from state to the long-term expectation of future reward. Sutton et al. recently introduced a generalization of value functions that makes it possible to specify general predictive questions [1]. These general value functions (GVFs), specify a prediction target as the expected discounted sum of future signals of interest (cumulants) observed while the agent selects actions according to some decision making policy. Temporal discounting is also generalized in GVFs from the conventional exponential weighting of future cumulants to an arbitrary, stateconditional weighting of future cumulants. This enables GVFs to specify a rich ar X iv :1 60 6. 05 59 3v 1 [ cs .A I] 1 7 Ju n 20 16",
            "output": [
                "Introspective Agents: Confidence Measures for General Value Functions"
            ]
        },
        {
            "id": "task1540-9b2639ba0e7e4acca572da73b3804408",
            "input": "Development of a proper names pronunciation lexicon is usually a manual effort which can not be avoided. Grapheme to phoneme (G2P) conversion modules, in literature, are usually rule based and work best for non-proper names in a particular language. Proper names are foreign to a G2P module. We follow an optimization approach to enable automatic construction of proper names pronunciation lexicon. The idea is to construct a small orthogonal set of words (basis) which can span the set of names in a given database. We propose two algorithms for the construction of this basis. The transcription lexicon of all the proper names in a database can be produced by the manual transcription of only the small set of basis words. We first construct a cost function and show that the minimization of the cost function results in a basis. We derive conditions for convergence of this cost function and validate them experimentally on a very large proper name database. Experiments show the transcription can be achieved by transcribing a set of small number of basis words. The algorithms proposed are generic and independent of language; however performance is better if the proper names have same origin, namely, same language or geographical region.",
            "output": [
                "Basis Identification for Automatic Creation of Pronunciation Lexicon for Proper Names"
            ]
        },
        {
            "id": "task1540-31b2f35ceef847b8b2ee9b3eee52c6ee",
            "input": "Type-level word embeddings use the same set of parameters to represent all instances of a word regardless of its context, ignoring the inherent lexical ambiguity in language. Instead, we embed semantic concepts (or synsets) as defined in WordNet and represent a word token in a particular context by estimating a distribution over relevant semantic concepts. We use the new, context-sensitive embeddings in a model for predicting prepositional phrase (PP) attachments and jointly learn the concept embeddings and model parameters. We show that using context-sensitive embeddings improves the accuracy of the PP attachment model by 5.4% absolute points, which amounts to a 34.4% relative reduction in errors.",
            "output": [
                "Using Ontology-Grounded Token Embeddings To Predict Prepositional Phrase Attachments"
            ]
        },
        {
            "id": "task1540-708b5701e72544cb92f61e526f8bd850",
            "input": "We publicly release a new large-scale dataset, called SearchQA, for machine comprehension, or question-answering. Unlike recently released datasets, such as DeepMind CNN/DailyMail and SQuAD, the proposed SearchQA was constructed to reflect a full pipeline of general question-answering. That is, we start not from an existing article and generate a question-answer pair, but start from an existing question-answer pair, crawled from J! Archive, and augment it with text snippets retrieved by Google. Following this approach, we built SearchQA, which consists of more than 140k question-answer pairs with each pair having 49.6 snippets on average. Each question-answer-context tuple of the SearchQA comes with additional meta-data such as the snippet’s URL, which we believe will be valuable resources for future research. We conduct human evaluation as well as test two baseline methods, one simple word selection and the other deep learning based, on the SearchQA. We show that there is a meaningful gap between the human and machine performances. This suggests that the proposed dataset could well serve as a benchmark for question-answering.",
            "output": [
                "SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine"
            ]
        },
        {
            "id": "task1540-a543509e031a4324959d6ff9e8c04cc3",
            "input": "We introduce a new multi-modal task for computer systems, posed as a combined vision-language comprehension challenge: identifying the most suitable text describing a scene, given several similar options. Accomplishing the task entails demonstrating comprehension beyond just recognizing “keywords” (or key-phrases) and their corresponding visual concepts. Instead, it requires an alignment between the representations of the two modalities that achieves a visually-grounded “understanding” of various linguistic elements and their dependencies. This new task also admits an easy-to-compute and wellstudied metric: the accuracy in detecting the true target among the decoys. The paper makes several contributions: an effective and extensible mechanism for generating decoys from (human-created) image captions; an instance of applying this mechanism, yielding a large-scale machine comprehension dataset (based on the COCO images and captions) that we make publicly available; human evaluation results on this dataset, informing a performance upper-bound; and several baseline and competitive learning approaches that illustrate the utility of the proposed task and dataset in advancing both image and language comprehension. We also show that, in a multi-task learning setting, the performance on the proposed task is positively correlated with the end-to-end task of image captioning.",
            "output": [
                "Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task"
            ]
        },
        {
            "id": "task1540-34daf77114af408b9d276f2c9a496399",
            "input": "We envision a machine learning service provider facing a continuous stream of problems with the same input domain, but with output domains that may differ. Clients present the provider with problems implicitly, by labeling a few example inputs, and then ask the provider to train models which reasonably extend their labelings to novel inputs. The provider wants to avoid constraining its users to a set of common labels, so it does not assume any particular correspondence between labels for a new task and labels for previously encountered tasks. To perform well in this setting, the provider needs a representation of the input domain which, in expectation, permits effective models for new problems to be learned efficiently from a small number of examples. While this bears a resemblance to settings considered in previous work on multitask and lifelong learning, our non-assumption of inter-task label correspondence leads to a novel algorithm: Lifelong Learner of Discriminative Representations (LLDR), which explicitly minimizes a proxy for the intra-task small-sample generalization error. We examine the relative benefits of our approach on a diverse set of real-world datasets in three significant scenarios: representation learning, multitask learning and lifelong learning.",
            "output": [
                "Lifelong Learning of Discriminative Representations"
            ]
        },
        {
            "id": "task1540-6934f98acd1a4a5eae6112b98da0800f",
            "input": "The Rao-Blackwell theorem is utilized to analyze and improve the scalability of inference in large probabilistic models that exhibit symmetries. A novel marginal density estimator is introduced and shown both analytically and empirically to outperform standard estimators by several orders of magnitude. The developed theory and algorithms apply to a broad class of probabilistic models including statistical relational models considered not susceptible to lifted probabilistic inference. Introduction Many successful applications of artificial intelligence research are based on large probabilistic models. Examples include Markov logic networks (Richardson and Domingos 2006), conditional random fields (Lafferty, McCallum, and Pereira 2001) and, more recently, deep learning architectures (Hinton, Osindero, and Teh 2006; Bengio and LeCun 2007; Poon and Domingos 2011). Especially the models one encounters in the statistical relational learning (SRL) literature often have joint distributions spanning millions of variables and features. Indeed, these models are so large that, at first sight, inference and learning seem daunting. For numerous of these models, however, scalable approximate and, to a lesser extend, exact inference algorithms do exist. Most notably, there has been a strong focus on lifted inference algorithms, that is, algorithms that group indistinguishable variables and features during inference. For an overview we refer the reader to (Kersting 2012). Lifted algorithms facilitate efficient inference in numerous large probabilistic models for which inference is NP-hard in principle. We are concerned with the estimation of marginal probabilities based on a finite number of sample points. We show that the feasibility of inference and learning in large and highly symmetric probabilistic models can be explained with the Rao-Blackwell theorem from the field of statistics. The theory and algorithms do not directly depend on the syntactical nature of the relational models such as arity of predicates and number of variables per formula but only on the given automorphism group of the probabilistic model, and are applicable to classes of probabilistic models much broader than the class of statistical relational models. Copyright c © 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Consider an experiment where a coin is flipped n times. While a frequentist would assume the flips to be i.i.d., a Bayesian typically makes the weaker assumption of exchangeability – that the probability of an outcome sequence only depends on the number of “heads” in the sequence and not on their order. Under the non-i.i.d. assumption, a possible corresponding graphical model is the fully connected graph with n nodes and high treewidth. The actual number of parameters required to specify the distribution, however, is only n+1, one for each sequence with 0 ≤ k ≤ n “heads.” Bruno de Finetti was the first to realize that such a sequence of random variables can be (re-)parameterized as a unique mixture of n+1 independent urn processes (de Finetti 1938). It is this notion of a parameterization as a mixture of urn processes that is at the heart of our work. A direct application of de Finetti’s results, however, is often impossible since not all variables are exchangeable in realistic probabilistic models. Motivated by the intuition of exchangeability, we show that arbitrary model symmetries allow us to re-paramterize the distribution as a mixture of independent urn processes where each urn consists of isomorphic joint assignments. Most importantly, we develop a novel Rao-Blackwellized estimator that implicitly estimates the fewer parameters of the simpler mixture model and, based on these, computes the marginal densities. We identify situations in which the application of the Rao-Blackwell estimator is tractable. In particular, we show that the Rao-Blackwell estimator is always linear-time computable for single-variable marginal density estimation. By invoking the Rao-Blackwell theorem, we show that the mean squared error of the novel estimator is at least as small as that of the standard estimator and strictly smaller under non-trivial symmetries of the probabilistic model. Moreover, we prove that for estimates based on sample points drawn from a Markov chainM, the bias of the Rao-Blackwell estimator is governed by the mixing time of the quotient Markov chain whose convergence behavior is superior to that ofM. We present empirical results verifying that the RaoBlackwell estimator always outperforms the standard estimator by up to several orders of magnitude, irrespective of the model structure. Indeed, we show that the results of the novel estimator resemble those typically observed in lifted inference papers. For the first time such a performance is shown for an SRL model with a transitivity formula. ar X iv :1 30 4. 26 94 v1 [ cs .A I] 9 A pr 2 01 3",
            "output": [
                "Symmetry-Aware Marginal Density Estimation"
            ]
        },
        {
            "id": "task1540-617d79144c3f40eabc5e08af8aa068b5",
            "input": "In classical machine learning, regression is treated as a black box process of identifying a suitable function from a hypothesis set without attempting to gain insight into the mechanism connecting inputs and outputs. In the natural sciences, however, finding an interpretable function for a phenomenon is the prime goal as it allows to understand and generalize results. This paper proposes a novel type of function learning network, called equation learner (EQL), that can learn analytical expressions and is able to extrapolate to unseen domains. It is implemented as an end-to-end differentiable feed-forward network and allows for efficient gradient based training. Due to sparsity regularization concise interpretable expressions can be obtained. Often the true underlying source expression is identified. INTRODUCTION The quality of a model is typically measured by its ability to generalize from a training set to previously unseen data from the same distribution. In regression tasks generalization essentially boils down to interpolation if the training data is sufficiently dense. As long as models are selected correctly, i. e. in a way to not overfit the data, the regression problem is well understood and can – at least conceptually – be considered solved. However, when working with data from real-world devices, e. g. controlling a robotic arm, interpolation might not be sufficient. It could happen that future data lies outside of the training domain, e. g. when the arm is temporarily operated outside of its specifications. For the sake of robustness and safety it is desirable in such a case to have a regression model that continues to make good predictions, or at least does not fail catastrophically. This setting, which we call extrapolation generalization, is the topic of the present paper. We are particularly interested in regression tasks for systems that can be described by real-valued analytic expression, e. g. mechanical systems such as a pendulum or a robotic arm. These are typically governed by a highly nonlinear function but it is nevertheless possible, in principle, to infer their behavior on an extrapolation domain from their behavior elsewhere. We make two main contributions: 1) a new type of network that can learn analytical expressions and is able to extrapolate to unseen domains and 2) a model selection strategy tailored to the extrapolation setting. The following section describes the setting of regression and extrapolation. Afterwards we introduce our method and discuss the architecture, its training, and its relation to prior art. We present our results in the Section Experimental evaluation and close with conclusions. REGRESSION AND EXTRAPOLATION We consider a multivariate regression problem with a training set {(x1, y1), . . . , (xN , yN )} with x ∈ R, y ∈ R. Because our main interest lies on extrapolation in the context of learning the dynamics of physical systems we assume the data originates from an unknown analytical function (or system of functions), φ : R → R with additive zero-mean noise, ξ, i. e. y = φ(x) + ξ and Eξ = 0. The function φ may, for instance, reflect a system of ordinary differential equations that govern the movements of a robot arm or the like. The general task is to learn a function ψ : R → R that approximates the true functional relation as well as possible in the squared loss sense, i. e. achieves minimal expected error E‖ψ(x) − φ(x)‖2. In practice, we only have particular examples of the function values available and measure the quality of predicting in terms of the empirical error on",
            "output": [
                "EXTRAPOLATION AND LEARNING EQUATIONS"
            ]
        },
        {
            "id": "task1540-2d8d46df2dfc4302aeb46c53aeb4bd03",
            "input": "Multi objective (MO) optimization is an emerging field which is increasingly being implemented in many industries globally. In this work, the MO optimization of the extraction process of bioactive compounds from the Gardenia Jasminoides Ellis fruit was solved. Three swarm-based algorithms have been applied in conjunction with normal-boundary intersection (NBI) method to solve this MO problem. The gravitational search algorithm (GSA) and the particle swarm optimization (PSO) technique were implemented in this work. In addition, a novel Hopfield-enhanced particle swarm optimization was developed and applied to the extraction problem. By measuring the levels of dominance, the optimality of the approximate Pareto frontiers produced by all the algorithms were gauged and compared. Besides, by measuring the levels of convergence of the frontier, some understanding regarding the structure of the objective space in terms of its relation to the level of frontier dominance is uncovered. Detail comparative studies were conducted on all the algorithms employed and developed in this work.",
            "output": [
                "Swarm Intelligence for Multiobjective Optimization of Extraction Process"
            ]
        },
        {
            "id": "task1540-42426d3ccd814aed8c97e834908ce0d0",
            "input": "Rare diseases are very difficult to identify among large number of other possible diagnoses. Better availability of patient data and improvement in machine learning algorithms empower us to tackle this problem computationally. In this paper, we target one such rare disease – cardiac amyloidosis. We aim to automate the process of identifying potential cardiac amyloidosis patients with the help of machine learning algorithms and also learn most predictive factors. With the help of experienced cardiologists, we prepared a gold standard with 73 positive (cardiac amyloidosis) and 197 negative instances. We achieved high average cross-validation F1 score of 0.98 using an ensemble machine learning classifier. Some of the predictive variables were: Age and Diagnosis of cardiac arrest, chest pain, congestive heart failure, hypertension, prim open angle glaucoma, and shoulder arthritis. Further studies are needed to validate the accuracy of the system across an entire health system and its generalizability for other diseases.",
            "output": [
                "A Bootstrap Machine Learning Approach to Identify Rare Disease Patients from Electronic Health Records"
            ]
        },
        {
            "id": "task1540-46539e08d9a3400a81d4fcb26b8df68c",
            "input": "Hidden Markov Models (HMMs) are learning methods for pattern recognition. The probabilistic HMMs have been one of the most used techniques based on the Bayesian model. First-order probabilistic HMMs were adapted to the theory of belief functions such that Bayesian probabilities were replaced with mass functions. In this paper, we present a second-order Hidden Markov Model using belief functions. Previous works in belief HMMs have been focused on the first-order HMMs. We extend them to the second-order model.",
            "output": [
                "Second-order Belief Hidden Markov Models"
            ]
        },
        {
            "id": "task1540-7d015deaaa1147d39a8d5b412dcd3cbe",
            "input": "Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is very challenging. With the availability of large annotated data (Bowman et al., 2015), it has recently become feasible to train neural network based inference models, which have shown to be very effective. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.6% on the Stanford natural language inference dataset. Unlike the previous top models that use very complicated network architectures, we first demonstrate that carefully designing sequential inference models based on chain LSTMs can outperform all previous models. Based on this, we further show that by explicitly considering recursive architectures in both local inference modeling and inference composition, we achieve additional improvement. Particularly, incorporating syntactic parsing information contributes to our best result—it further improves the performance even when added to the already very strong model.",
            "output": [
                "Enhanced LSTM for Natural Language Inference"
            ]
        },
        {
            "id": "task1540-1869881353fd4ccbbdcaf8f1724994fa",
            "input": "Kinect skeleton tracker is able to achieve considerable human body tracking performance in convenient and a low-cost manner. However, The tracker often captures unnatural human poses such as discontinuous and vibrated motions when self-occlusions occur. A majority of approaches tackle this problem by using multiple Kinect sensors in a workspace. Combination of the measurements from different sensors is then conducted in Kalman filter framework or optimization problem is formulated for sensor fusion. However, these methods usually require heuristics to measure reliability of measurements observed from each Kinect sensor. In this paper, we developed a method to improve Kinect skeleton using single Kinect sensor, in which supervised learning technique was employed to correct unnatural tracking motions. Specifically, deep recurrent neural networks were used for improving joint positions and velocities of Kinect skeleton, and three methods were proposed to integrate the refined positions and velocities for further enhancement. Moreover, we suggested a novel measure to evaluate naturalness of captured motions. We evaluated the proposed approach by comparison with the ground truth obtained using a commercial optical maker-based motion capture system.",
            "output": [
                "Tracking Human-like Natural Motion Using Deep Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-5aa229a0810a41bd92c036fc12464a65",
            "input": "We propose a sequence labeling framework with a secondary training objective, learning to predict surrounding words for every word in the dataset. This language modeling objective incentivises the framework to learn general-purpose patterns of semantic and syntactic composition, which are also useful for improving accuracy on different sequence labeling tasks. The architecture was evaluated on 8 datasets, covering the tasks of error detection in learner texts, named entity recognition, chunking and POS-tagging. The novel language modeling objective provided consistent performance improvements on every benchmark, without requiring any additional annotated or unannotated data.",
            "output": [
                "Semi-supervised Multitask Learning for Sequence Labeling"
            ]
        },
        {
            "id": "task1540-ef3fe689762a4169819e5d39b2e5a391",
            "input": "We consider the problem of sparse variable selection in nonparametric additive models, with the prior knowledge of the structure among the covariates to encourage those variables within a group to be selected jointly. Previous works either study the group sparsity in the parametric setting (e.g., group lasso), or address the problem in the nonparametric setting without exploiting the structural information (e.g., sparse additive models). In this paper, we present a new method, called group sparse additive models (GroupSpAM), which can handle group sparsity in additive models. We generalize the `1/`2 norm to Hilbert spaces as the sparsityinducing penalty in GroupSpAM. Moreover, we derive a novel thresholding condition for identifying the functional sparsity at the group level, and propose an efficient block coordinate descent algorithm for constructing the estimate. We demonstrate by simulation that GroupSpAM substantially outperforms the competing methods in terms of support recovery and prediction accuracy in additive models, and also conduct a comparative experiment on a real breast cancer dataset.",
            "output": [
                "Group Sparse Additive Models"
            ]
        },
        {
            "id": "task1540-d7528a61f13a49ffaab0d374de6a0808",
            "input": "Understanding open-domain text is one of the primary challenges in natural language processing (NLP). Machine comprehension benchmarks evaluate the system’s ability to understand text based on the text content only. In this work, we investigate machine comprehension on MCTest, a question answering (QA) benchmark. Prior work is mainly based on feature engineering approaches. We come up with a neural network framework, named hierarchical attention-based convolutional neural network (HABCNN), to address this task without any manually designed features. Specifically, we explore HABCNN for this task by two routes, one is through traditional joint modeling of document, question and answer, one is through textual entailment. HABCNN employs an attention mechanism to detect key phrases, key sentences and key snippets that are relevant to answering the question. Experiments show that HABCNN outperforms prior deep learning approaches by a big margin.",
            "output": [
                "Attention-Based Convolutional Neural Network for Machine Comprehension"
            ]
        },
        {
            "id": "task1540-ff6d79f015cf45aba7557dd6ddfb90d3",
            "input": "Model interpretation is one of the key aspects of the model evaluation process. The explanation of the relationship between model variables and outputs is relatively easy for statistical models, such as linear regressions, thanks to the availability of model parameters and their statistical significance. For “black box” models, such as random forest, this information is hidden inside the model structure. This work presents an approach for computing feature contributions for random forest classification models. It allows for the determination of the influence of each variable on the model prediction for an individual instance. By analysing feature contributions for a training dataset, the most significant variables can be determined and their typical contribution towards predictions made for individual classes, i.e., class-specific feature contribution ”patterns”, are discovered. These patterns represent a standard behaviour of the model and allow for an additional assessment of the model reliability for a new data. Interpretation of feature contributions for two UCI benchmark datasets shows the potential of the proposed methodology. The robustness of results is demonstrated through an extensive analysis of feature contributions calculated for a large number of generated random forest models. ∗a.m.wojak@bradford.ac.uk †j.palczewski@leeds.ac.uk ‡r.l.marcheserobinson@ljmu.ac.uk §d.neagu@bradford.ac.uk 1 ar X iv :1 31 2. 11 21 v1 [ cs .L G ] 4 D ec 2 01 3",
            "output": [
                "Interpreting random forest classification models using a feature contribution method"
            ]
        },
        {
            "id": "task1540-307fab2d9131487694f4d5a40f48dd8a",
            "input": "We present a general-purpose tagger based on convolutional neural networks (CNN), used for both composing word vectors and encoding context information. The CNN tagger is robust across different tagging tasks: without task-specific tuning of hyper-parameters, it achieves state-of-theart results in part-of-speech tagging, morphological tagging and supertagging. The CNN tagger is also robust against the outof-vocabulary problem, it performs well on artificially unnormalized texts.",
            "output": [
                "A General-Purpose Tagger with Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-0a1c71da809e444f9d002b745186dbfc",
            "input": "In this paper we examine the benefit of performing named entity recognition (NER) and co-reference resolution to an English and a Greek corpus used for text segmentation. The aim here is to examine whether the combination of text segmentation and information extraction can be beneficial for the identification of the various topics that appear in a document. NER was performed manually in the English corpus and was compared with the output produced by publicly available annotation tools while, an already existing tool was used for the Greek corpus. Produced annotations from both corpora were manually corrected and enriched to cover four types of named entities. Co-reference resolution i.e., substitution of every reference of the same instance with the same named entity identifier was subsequently performed. The evaluation, using five text segmentation algorithms for the English corpus and four for the Greek corpus leads to the conclusion that, the benefit highly depends on the segment’s topic, the number of named entity instances appearing in it, as well as the segment’s length.",
            "output": [
                "Text Segmentation using Named Entity Recognition and Co-reference Resolution in English and Greek Texts"
            ]
        },
        {
            "id": "task1540-7346ba6d53b74f8988deb9c7dc69d563",
            "input": "Algorithms that generate computer game content require game design knowledge. We present an approach to automatically learn game design knowledge for level design from gameplay videos. We further demonstrate how the acquired design knowledge can be used to generate sections of game levels. Our approach involves parsing video of people playing a game to detect the appearance of patterns of sprites and utilizing machine learning to build a probabilistic model of sprite placement. We show how rich game design information can be automatically parsed from gameplay videos and represented as a set of generative probabilistic models. We use Super Mario Bros. as a proof of concept. We evaluate our approach on a measure of playability and stylistic similarity to the original levels as represented in the gameplay videos.",
            "output": [
                "Toward Game Level Generation from Gameplay Videos"
            ]
        },
        {
            "id": "task1540-58e682c56afb479fb9b03497c8efeb2b",
            "input": "Recently, bidirectional recurrent network language models (biRNNLMs) have been shown to outperform standard, unidirectional, recurrent neural network language models (uni-RNNLMs) on a range of speech recognition tasks. This indicates that future word context information beyond the word history can be useful. However, bi-RNNLMs pose a number of challenges as they make use of the complete previous and future word context information. This impacts both training efficiency and their use within a lattice rescoring framework. In this paper these issues are addressed by proposing a novel neural network structure, succeeding word RNNLMs (suRNNLMs). Instead of using a recurrent unit to capture the complete future word contexts, a feedforward unit is used to model a finite number of succeeding, future, words. This model can be trained much more efficiently than bi-RNNLMs and can also be used for lattice rescoring. Experimental results on a meeting transcription task (AMI) show the proposed model consistently outperformed uni-RNNLMs and yield only a slight degradation compared to bi-RNNLMs in N-best rescoring. Additionally, performance improvements can be obtained using lattice rescoring and subsequent confusion network decoding.",
            "output": [
                "FUTURE WORD CONTEXTS IN NEURAL NETWORK LANGUAGE MODELS"
            ]
        },
        {
            "id": "task1540-6e08d7ab7a9a42348e91167872657c87",
            "input": "In the last two decades, modal and description logics have been applied to numerous areas of computer science, including knowledge representation, formal verification, database theory, distributed computing and, more recently, semantic web and ontologies. For this reason, the problem of automated reasoning in modal and description logics has been thoroughly investigated. In particular, many approaches have been proposed for efficiently handling the satisfiability of the core normal modal logic Km, and of its notational variant, the description logic ALC. Although simple in structure, Km/ALC is computationally very hard to reason on, its satisfiability being PSpace-complete. In this paper we start exploring the idea of performing automated reasoning tasks in modal and description logics by encoding them into SAT, so that to be handled by stateof-the-art SAT tools; as with most previous approaches, we begin our investigation from the satisfiability in Km. We propose an efficient encoding, and we test it on an extensive set of benchmarks, comparing the approach with the main state-of-the-art tools available. Although the encoding is necessarily worst-case exponential, from our experiments we notice that, in practice, this approach can handle most or all the problems which are at the reach of the other approaches, with performances which are comparable with, or even better than, those of the current state-of-the-art tools. 1. Motivations and Goals In the last two decades, modal and description logics have provided an essential framework for many applications in numerous areas of computer science, including artificial intelligence, formal verification, database theory, distributed computing and, more recently, semantic web and ontologies. For this reason, the problem of automated reasoning in modal and description logics has been thoroughly investigated (e.g., Fitting, 1983; Ladner, 1977; Baader & Hollunder, 1991; Halpern & Moses, 1992; Baader, Franconi, Hollunder, Nebel, & Profitlich, 1994; Massacci, 2000). In particular, the research in modal and description logics has followed two parallel routes until the seminal work of Schild (1991), which proved that the core modal logic Km and the core description logic ALC are one a notational variant of the other. Since then, analogous results have been produced for a bunch of other logics, so that, nowadays the two research lines have mostly merged into one research flow. Many approaches have been proposed for efficiently reasoning in modal and description logics, starting from the problem of checking the satisfiability in the core normal modal logic Km and in its notational variant, the description logic ALC (hereafter simply “Km”). We classify them as follows. c ©2009 AI Access Foundation. All rights reserved. Sebastiani & Vescovi • The “classic” tableau-based approach (Fitting, 1983; Baader & Hollunder, 1991; Massacci, 2000) is based on the construction of propositional tableau branches, which are recursively expanded on demand by generating successor nodes in a candidate Kripke model. Kris (Baader & Hollunder, 1991; Baader et al., 1994), Crack (Franconi, 1998), LWB (Balsiger, Heuerding, & Schwendimann, 1998) were among the main representative tools of this approach. • The DPLL-based approach (Giunchiglia & Sebastiani, 1996, 2000) differs from the previous one mostly in the fact that a Davis-Putnam-Logemann-Loveland (DPLL) procedure, which treats the modal subformulas as propositions, is used instead of the classic propositional tableaux procedure at each nesting level of the modal operators. KSAT (Giunchiglia & Sebastiani, 1996), ESAT (Giunchiglia, Giunchiglia, & Tacchella, 2002) and *SAT (Tacchella, 1999), are the representative tools of this approach. These two approaches merged into the “modern” tableaux-based approach, which has been extended to work with more expressive description logics and to provide more sophisticate reasoning functions. Among the tools employing this approach, we recall FaCT/FaCT++ and DLP (Horrocks & Patel-Schneider, 1999), and Racer (Haarslev & Moeller, 2001). 1 • In the translational approach (Hustadt & Schmidt, 1999; Areces, Gennari, Heguiabehere, & de Rijke, 2000) the modal formula is encoded into first-order logic (FOL), and the encoded formula can be decided efficiently by a FOL theorem prover (Areces et al., 2000). Mspass (Hustadt, Schmidt, & Weidenbach, 1999) is the most representative tool of this approach. • The CSP-based approach (Brand, Gennari, & de Rijke, 2003) differs from the tableauxbased and DPLL-based ones mostly in the fact that a CSP (Constraint Satisfaction Problem) engine is used instead of tableaux/DPLL. KCSP is the only representative tool of this approach. • In the Inverse-method approach (Voronkov, 1999, 2001), a search procedure is based on the “inverted” version of a sequent calculus (which can be seen as a modalized version of propositional resolution). K K(Voronkov, 1999) is the only representative tool of this approach. • In the Automata-theoretic approach, (a symbolic representation based on BDDs – Binary Decision Diagrams – of) a tree automaton accepting all the tree models of the input formula is implicitly built and checked for emptiness (Pan, Sattler, & Vardi, 2002; Pan & Vardi, 2003). KBDD (Pan & Vardi, 2003) is the only representative tool of this approach. 1. Notice that there is not an universal agreement on the terminology “tableaux-based” and “DPLL-based”. E.g., tools like FaCT, DLP, and Racer are most often called “tableau-based”, although they use a DPLL-like algorithm instead of propositional tableaux for handling the propositional component of reasoning (Horrocks, 1998; Patel-Schneider, 1998; Horrocks & Patel-Schneider, 1999; Haarslev & Moeller, 2001).",
            "output": [
                "Automated Reasoning in Modal and Description Logics via SAT Encoding: the Case Study of Km/ALC-Satisfiability"
            ]
        },
        {
            "id": "task1540-495050437549449daff7013838f5bad9",
            "input": "Due to its ability to combine multiple base clusterings into a probably better and more robust clustering, the ensemble clustering technique has been attracting increasing attention in recent years. Despite the significant success, one limitation to most of the existing ensemble clustering methods is that they generally treat all base clusterings equally regardless of their reliability, which makes them vulnerable to low-quality base clusterings. Although some efforts have been made to (globally) evaluate and weight the base clusterings, yet these methods tend to view each base clustering as an individual and neglect the local diversity of clusters inside the same base clustering. It remains an open problem how to evaluate the reliability of clusters and exploit the local diversity in the ensemble to enhance the consensus performance, without access to data features or specific assumptions on data distribution. To address this, in this paper, we propose a novel ensemble clustering approach based on ensemble-driven cluster uncertainty estimation and local weighting strategy. In particular, the uncertainty of each cluster is estimated by considering the cluster labels in the entire ensemble via an entropic criterion. A novel ensemble-driven cluster validity measure is introduced, and a locally weighted co-association matrix is presented to serve as a summary for the ensemble of diverse clusters. With the local diversity in ensembles exploited, two novel consensus functions are further proposed. Extensive experiments on a variety of real-world datasets demonstrate the superiority of the proposed approach over the state-of-the-art.",
            "output": [
                "Locally Weighted Ensemble Clustering"
            ]
        },
        {
            "id": "task1540-2f2243639b62431e929c2ac043b34579",
            "input": "Learning effective configurations in computer systems without hand-crafting models for every parameter is a long-standing problem. This paper investigates the use of deep reinforcement learning for runtime parameters of cloud databases under latency constraints. Cloud services serve up to thousands of concurrent requests per second and can adjust critical parameters by leveraging performance metrics. In this work, we use continuous deep reinforcement learning to learn optimal cache expirations for HTTP caching in content delivery networks. To this end, we introduce a technique for asynchronous experience management called delayed experience injection, which facilitates delayed reward and next-state computation in concurrent environments where measurements are not immediately available. Evaluation results show that our approach based on normalized advantage functions and asynchronous CPU-only training outperforms a statistical estimator.",
            "output": [
                "Learning Runtime Parameters in Computer Systems with Delayed Experience Injection"
            ]
        },
        {
            "id": "task1540-a2ba660cd7b943849d352b8d507d7538",
            "input": "As a well-known NP-hard problem, the Three-Index Assignment Problem (AP3) has attracted lots of research efforts for developing heuristics. However, existing heuristics either obtain less competitive solutions or consume too much running time. In this paper, a new heuristic named Approximate Muscle guided Beam Search (AMBS) is developed to achieve a good trade-off between solution quality and running time. By combining the approximate muscle with beam search, the solution space size can be significantly decreased, thus the time for searching the solution can be sharply reduced. Extensive experimental results on the benchmark indicate that the new algorithm is able to obtain solutions with competitive quality and it can be employed on instances with large-scale. Work of this paper not only proposes a new efficient heuristic, but also provides a promising method to improve the efficiency of beam search.",
            "output": [
                "Approximate Muscle Guided Beam Search for Three-Index Assignment Problem"
            ]
        },
        {
            "id": "task1540-73a9eda755074f239e7393e374a261c2",
            "input": "Pattern classification systems are commonly used in adversarial applications, like biometric authentication, network intrusion detection, and spam filtering, in which data can be purposely manipulated by humans to undermine their operation. As this adversarial scenario is not taken into account by classical design methods, pattern classification systems may exhibit vulnerabilities, whose exploitation may severely affect their performance, and consequently limit their practical utility. Extending pattern classification theory and design methods to adversarial settings is thus a novel and very relevant research direction, which has not yet been pursued in a systematic way. In this paper, we address one of the main open issues: evaluating at design phase the security of pattern classifiers, namely, the performance degradation under potential attacks they may incur during operation. We propose a framework for empirical evaluation of classifier security that formalizes and generalizes the main ideas proposed in the literature, and give examples of its use in three real applications. Reported results show that security evaluation can provide a more complete understanding of the classifier’s behavior in adversarial environments, and lead to better design choices.",
            "output": [
                "Security Evaluation of Pattern Classifiers under Attack"
            ]
        },
        {
            "id": "task1540-bfb05f4c26ac41ef8733a1375bb7ae8a",
            "input": "A key part of any evolutionary algorithm is fitness evaluation. When fitness evaluations are corrupted by noise, as happens in many real-world problems as a consequence of various types of uncertainty, a strategy is needed in order to cope with this. Resampling is one of the most common strategies, whereby each solution is evaluated many times in order to reduce the variance of the fitness estimates. When evaluating the performance of a noisy optimisation algorithm, a key consideration is the stopping condition for the algorithm. A frequently used stopping condition in runtime analysis, known as “First Hitting Time”, is to stop the algorithm as soon as it encounters the optimal solution. However, this is unrealistic for real-world problems, as if the optimal solution were already known, there would be no need to search for it. This paper argues that the use of First Hitting Time, despite being a commonly used approach, is significantly flawed and overestimates the quality of many algorithms in real-world cases, where the optimum is not known in advance and has to be genuinely searched for. A better alternative is to measure the quality of the solution an algorithm returns after a fixed evaluation budget, i.e., to focus on final solution quality. This paper argues that focussing on final solution quality is more realistic and demonstrates cases where the results produced by each algorithm evaluation method lead to very different conclusions regarding the quality of each noisy optimisation algorithm.",
            "output": [
                "Evaluating Noisy Optimisation Algorithms: First Hitting Time is Problematic"
            ]
        },
        {
            "id": "task1540-51c269a98d5f4947b926709f1f587716",
            "input": "Item Response Theory (IRT) allows for measuring ability of Machine Learning models as compared to a human population. However, it is difficult to create a large dataset to train the ability of deep neural network models (DNNs). We propose Crowd-Informed Fine-Tuning (CIFT) as a new training process, where a pre-trained model is fine-tuned with a specialized supplemental training set obtained via IRT modelfitting on a large set of crowdsourced response patterns. With CIFT we can leverage the specialized set of data obtained through IRT to inform parameter tuning in DNNs. We experiment with two loss functions in CIFT to represent (i) memorization of fine-tuning items and (ii) learning a probability distribution over potential labels that is similar to the crowdsourced distribution over labels to simulate crowd knowledge. Our results show that CIFT improves ability for a state-of-theart DNN model for Recognizing Textual Entailment (RTE) tasks and is generalizable to a large-scale RTE test set.",
            "output": [
                "CIFT: Crowd-Informed Fine-Tuning to Improve Machine Learning Ability"
            ]
        },
        {
            "id": "task1540-893b13f8bdb94adda9cac7d7888d69c5",
            "input": "We have developed and trained a convolutional neural network to automatically and simultaneously segment optic disc, fovea and blood vessels. Fundus images were normalized before segmentation was performed to enforce consistency in background lighting and contrast. For every effective point in the fundus image, our algorithm extracted three channels of input from the point’s neighbourhood and forwarded the response across the 7-layer network. The output layer consists of four neurons, representing background, optic disc, fovea and blood vessels. In average, our segmentation correctly classified 92.68% of the ground truths (on the testing set from Drive database). The highest accuracy achieved on a single image was 94.54%, the lowest 88.85%. A single convolutional neural network can be used not just to segment blood vessels, but also optic disc and fovea with good accuracy.",
            "output": [
                "Segmentation of optic disc, fovea and retinal vasculature using a single convolutional neural network"
            ]
        },
        {
            "id": "task1540-3b8883ec8e4047338f7d7c1aa9be8790",
            "input": "It is natural and efficient to use Natural Language (NL) for transferring knowledge from a human to a robot. Recently, research on using NL to support human-robot cooperation (HRC) has received increasing attention in several domains such as robotic daily assistance, robotic health caregiving, intelligent manufacturing, autonomous navigation and robot social accompany. However, a high-level review that can reveal the realization process and the latest methodologies of using NL to facilitate HRC is missing. In this review, a comprehensive summary about the methodology development of natural-language-facilitated human-robot cooperation (NLC) has been made. We first analyzed driving forces for NLC developments. Then, with a temporal realization order, we reviewed three main steps of NLC: human NL understanding, knowledge representation, and knowledge-world mapping. Last, based on our paper review and perspectives, potential research trends in NLC were discussed.",
            "output": [
                "Methodologies realizing natural-language-facilitated human-robot cooperation: A review"
            ]
        },
        {
            "id": "task1540-9889796ba8504e44aaf33f6a36bd55db",
            "input": "Kernel-based approaches for sequence classification have been successfully applied to a variety of domains, including the text categorization, image classification, speech analysis, biological sequence analysis, time series and music classification, where they show some of the most accurate results. Typical kernel functions for sequences in these domains (e.g., bag-of-words, mismatch, or subsequence kernels) are restricted to discrete univariate (i.e. one-dimensional) string data, such as sequences of words in the text analysis, codeword sequences in the image analysis, or nucleotide or amino acid sequences in the DNA and protein sequence analysis. However, original sequence data are often of real-valued multivariate nature, i.e. are not univariate and discrete as required by typical k-mer based sequence kernel functions. In this work, we consider the problem of the multivariate sequence classification (e.g., classification of multivariate music sequences, or multidimensional protein sequence representations). To this end, we extend univariate kernel functions typically used in sequence domains and propose efficient multivariate similarity kernel method (MVDFQ-SK) based on (1) a direct feature quantization (DFQ) of each sequence dimension in the original real-valued multivariate sequences and (2) applying novel multivariate discrete kernel measures on these multivariate discrete DFQ sequence representations to more accurately capture similarity relationships among sequences and improve classification performance. Experiments using the proposed MVDFQ-SK kernel method show excellent classification performance on three challenging music classification tasks as well as protein sequence classification with significant 25-40% improvements over univariate kernel methods and existing state-of-the-art sequence classification methods.",
            "output": [
                "Efficient multivariate kernels for sequence classification"
            ]
        },
        {
            "id": "task1540-fd3d0d9cee5641faa80687e1ec5261e6",
            "input": "Contextual bandit learning is an increasingly popular approach to optimizing recommender systems via user feedback, but can be slow to converge in practice due to the need for exploring a large feature space. In this paper, we propose a coarse-to-fine hierarchical approach for encoding prior knowledge that drastically reduces the amount of exploration required. Intuitively, user preferences can be reasonably embedded in a coarse low-dimensional feature space that can be explored efficiently, requiring exploration in the high-dimensional space only as necessary. We introduce a bandit algorithm that explores within this coarse-to-fine spectrum, and prove performance guarantees that depend on how well the coarse space captures the user’s preferences. We demonstrate substantial improvement over conventional bandit algorithms through extensive simulation as well as a live user study in the setting of personalized news recommendation.",
            "output": [
                "Hierarchical Exploration for Accelerating Contextual Bandits"
            ]
        },
        {
            "id": "task1540-bee7571f11fa4ed9a1c0df43bd8b9d53",
            "input": "While the optimization problem behind deep neural networks is highly non-convex, it is frequently observed in practice that training deep networks seems possible without getting stuck in suboptimal points. It has been argued that this is the case as all local minima are close to being globally optimal. We show that this is (almost) true, in fact almost all local minima are globally optimal, for a fully connected network with squared loss and analytic activation function given that the number of hidden units of one layer of the network is larger than the number of training points and the network structure from this layer on is pyramidal.",
            "output": [
                "The Loss Surface of Deep and Wide Neural Networks"
            ]
        },
        {
            "id": "task1540-41b3474fe93b4b24bcc8ec26ff18673f",
            "input": "To appear in Theory and Practice of Logic Programming (TPLP). GNU Prolog is a general-purpose implementation of the Prolog language, which distinguishes itself from most other systems by being, above all else, a native-code compiler which produces standalone executables which don’t rely on any byte-code emulator or meta-interpreter. Other aspects which stand out include the explicit organization of the Prolog system as a multipass compiler, where intermediate representations are materialized, in Unix compiler tradition. GNU Prolog also includes an extensible and highperformance finite domain constraint solver, integrated with the Prolog language but implemented using independent lower-level mechanisms. This article discusses the main issues involved in designing and implementing GNU Prolog: requirements, system organization, performance and portability issues as well as its position with respect to other Prolog system implementations and the ISO standardization initiative.",
            "output": [
                "On the Implementation of GNU Prolog"
            ]
        },
        {
            "id": "task1540-7526ccc63b684d6bba542f800bc95b70",
            "input": "We formulate and study a fundamental search and detection problem, Schedule Optimization, motivated by a variety of real-world applications, ranging from monitoring content changes on the web, social networks, and user activities to detecting failure on large systems with many individual machines. We consider a large system consists of many nodes, where each node has its own rate of generating new events, or items. A monitoring application can probe a small number of nodes at each step, and our goal is to compute a probing schedule that minimizes the expected number of undiscovered items at the system, or equivalently, minimizes the expected time to discover a new item in the system. We study the Schedule Optimization problem both for deterministic and randomized memoryless algorithms. We provide lower bounds on the cost of an optimal schedule and construct close to optimal schedules with rigorous mathematical guarantees. Finally, we present an adaptive algorithm that starts with no prior information on the system and converges to the optimal memoryless algorithms by adapting to observed data.",
            "output": [
                "Optimizing Static and Adaptive Probing Schedules for Rapid Event Detection"
            ]
        },
        {
            "id": "task1540-570df8b3885849448bc315c1a91906dd",
            "input": "User-machine interaction is important for spoken content retrieval. For text content retrieval, the user can easily scan through and select on a list of retrieved item. This is impossible for spoken content retrieval, because the retrieved items are difficult to show on screen. Besides, due to the high degree of uncertainty for speech recognition, the retrieval results can be very noisy. One way to counter such difficulties is through user-machine interaction. The machine can take different actions to interact with the user to obtain better retrieval results before showing to the user. The suitable actions depend on the retrieval status, for example requesting for extra information from the user, returning a list of topics for user to select, etc. In our previous work, some hand-crafted states estimated from the present retrieval results are used to determine the proper actions. In this paper, we propose to use Deep-Q-Learning techniques instead to determine the machine actions for interactive spoken content retrieval. Deep-Q-Learning bypasses the need for estimation of the hand-crafted states, and directly determine the best action base on the present retrieval status even without any human knowledge. It is shown to achieve significantly better performance compared with the previous hand-crafted states.",
            "output": [
                "Interactive Spoken Content Retrieval by Deep Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-f6e29dc59f9245b2ac79f2cdcecd99ea",
            "input": "У статті заманіфестовано проект квантитативної параметризації усіх текстів І. Франка, що можливо реалізувати, створивши частотний словник усіх творів письменника і лише із застосуванням сучаних комп'ютерних розробок. Вказано сфери застосування, етапи, методику, принципи і специфіку укладання частотного словника мови другої половини ХІХ — поч. ХХ ст., якою писав І. Франко. Описано співвідношення частотного словника І. Франка із словником мови письменника та корпусом текстів.",
            "output": [
                "Соломія Бук, Андрій Ровенчак "
            ]
        },
        {
            "id": "task1540-61ddb76475b34061ac5ab48b476b0ce5",
            "input": "In this study, we introduce a new approach for learning language models by training them to estimate word-context pointwise mutual information (PMI), and then deriving the desired conditional probabilities from PMI at test time. Specifically, we show that with minor modifications to word2vec’s algorithm, we get principled language models that are closely related to the well-established Noise Contrastive Estimation (NCE) based language models. A compelling aspect of our approach is that our models are trained with the same simple negative sampling objective function that is commonly used in word2vec to learn word embeddings.",
            "output": [
                "A Simple Language Model based on PMI Matrix Approximations"
            ]
        },
        {
            "id": "task1540-624c8194edd4432e80be4a6045104dda",
            "input": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-ofthe-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.",
            "output": [
                "One-Shot Adaptation of Supervised Deep Convolutional Models"
            ]
        },
        {
            "id": "task1540-945fcd2ac9bf49389cec457a29365a22",
            "input": "In practice, a ranking of objects with respect to given set of criteria is of considerable importance. However, due to lack of knowledge, information of time pressure, decision makers might not be able to provide a (crisp) ranking of objects from the top to the bottom. Instead, some objects might be ranked equally, or better than other objects only to some degree. In such cases, a generalization of crisp rankings to fuzzy rankings can be more useful. The aim of the article is to introduce the notion of a fuzzy ranking and to discuss its several properties, namely orderings, similarity and indecisiveness. The proposed approach can be used both for group decision making or multiple criteria decision making when uncertainty is involved.",
            "output": [
                "Fuzzy Rankings: Properties and Applications"
            ]
        },
        {
            "id": "task1540-9902526cfaf1483abf5bce13f6b0cb53",
            "input": "Participants in recent discussions of AI-related issues ranging from intelligence explosion to technological unemployment have made diverse claims about the nature, pace, and drivers of progress in AI. However, these theories are rarely specified in enough detail to enable systematic evaluation of their assumptions or to extrapolate progress quantitatively, as is often done with some success in other technological domains. After reviewing relevant literatures and justifying the need for more rigorous modeling of AI progress, this paper contributes to that research program by suggesting ways to account for the relationship between hardware speed increases and algorithmic improvements in AI, the role of human inputs in enabling AI capabilities, and the relationships between different sub-fields of AI. It then outlines ways of tailoring AI progress models to generate insights on the specific issue of technological unemployment, and outlines future directions for research on AI progress.",
            "output": [
                "Modeling Progress in AI"
            ]
        },
        {
            "id": "task1540-1bb3c9d8542647718972fa96555d0fa5",
            "input": "Indian languages have long history in World Natural languages. Panini was the first to define Grammar for Sanskrit language with about 4000 rules in fifth century. These rules contain uncertainty information. It is not possible to Computer processing of Sanskrit language with uncertain information. In this paper, fuzzy logic and fuzzy reasoning are proposed to deal to eliminate uncertain information for reasoning with Sanskrit grammar. The Sanskrit language processing is also discussed in this paper. .",
            "output": [
                "Fuzzy Modeling and Natural Language Processing for Panini’s Sanskrit Grammar"
            ]
        },
        {
            "id": "task1540-26ec77117f6940acb5a0f311be8b37f0",
            "input": "Neutrosophic set has the ability to handle uncertain, incomplete, inconsistent, indeterminate information in a more accurate way. In this paper, we proposed a neutrosophic recommender system to predict the diseases based on neutrosophic set which includes single-criterion neutrosophic recommender system (SCNRS) and multi-criterion neutrosophic recommender system (MC-NRS). Further, we investigated some algebraic operations of neutrosophic recommender system such as union, complement, intersection, probabilistic sum, bold sum, bold intersection, bounded difference, symmetric difference, convex linear sum of min and max operators, Cartesian product, associativity, commutativity and distributive. Based on these operations, we studied the algebraic structures such as lattices, Kleen algebra, de Morgan algebra, Brouwerian algebra, BCK algebra, Stone algebra and MV algebra. In addition, we introduced several types of similarity measures based on these algebraic operations and studied some of their theoretic properties. Moreover, we accomplished a prediction formula using the proposed algebraic similarity measure. We also proposed a new algorithm for medical diagnosis based on neutrosophic recommender system. Finally to check the validity of the proposed methodology, we made experiments on the datasets Heart, RHC, Breast cancer, Diabetes and DMD. At the end, we presented the MSE and computational time by comparing the proposed algorithm with the relevant ones such as ICSM, DSM, CARE, CFMD, as well as other variants namely Variant 67, Variant 69, and Varian 71 both in tabular and graphical form to analyze the efficiency and accuracy. Finally we analyzed the strength of all 8 algorithms by ANOVA statistical tool.",
            "output": [
                "A Neutrosophic Recommender System for Medical Diagnosis Based on Algebraic Neutrosophic Measures"
            ]
        },
        {
            "id": "task1540-93e16fb5792d489bbf7708ddada29833",
            "input": "Convolutional Neural Networks (CNNs) are extensively used in image and video recognition, natural language processing and other machine learning applications. The success of CNNs in these areas corresponds with a significant increase in the number of parameters and computation costs. Recent approaches towards reducing these overheads involve pruning and compressing the weights of various layers without hurting the overall CNN performance. However, using model compression to generate sparse CNNs mostly reduces parameters from the fully connected layers and may not significantly reduce the final computation costs. In this paper, we present a compression technique for CNNs, where we prune the filters from CNNs that are identified as having a small effect on the output accuracy. By removing whole planes in the network, together with their connecting convolution kernels, the computational costs are reduced significantly. In contrast to other techniques proposed for pruning networks, this approach does not result in sparse connectivity patterns. Hence, our techniques do not need the support of sparse convolution libraries and can work with the most efficient BLAS operations for matrix multiplications. In our results, we show that even simple filter pruning techniques can reduce inference costs for VGG-16 by up to 34% and ResNet-110 by upto 38% while regaining close to the original accuracy by retraining the networks.",
            "output": [
                "Pruning Filters for Efficient ConvNets"
            ]
        },
        {
            "id": "task1540-5c4b20d7f3504494b9bab707a31f605b",
            "input": "The paper addresses the problem of learning a regression model parameterized by a fixedrank positive semidefinite matrix. The focus is on the nonlinear nature of the search space and on scalability to high-dimensional problems. The mathematical developments rely on the theory of gradient descent algorithms adapted to the Riemannian geometry that underlies the set of fixed-rank positive semidefinite matrices. In contrast with previous contributions in the literature, no restrictions are imposed on the range space of the learned matrix. The resulting algorithms maintain a linear complexity in the problem size and enjoy important invariance properties. We apply the proposed algorithms to the problem of learning a distance function parameterized by a positive semidefinite matrix. Good performance is observed on classical benchmarks.",
            "output": [
                "Regression on fixed-rank positive semidefinite matrices: a Riemannian approach"
            ]
        },
        {
            "id": "task1540-3f7cf499998f44d8baa3b8a9c33f148f",
            "input": "\"Background subtraction\" is an old technique for finding moving objects in a video sequence-for example, cars driving on a freeway. The idea is that subtracting the current image from a time­ averaged background image will leave only non­ stationary objects. It is, however, a crude ap­ proximation to the task of classifying each pixel of the current image; it fails with slow-moving objects and does not distinguish shadows from moving objects. The basic idea of this paper is that we can classify each pixel using a model of how that pixel looks when it is part of different classes. We learn a mixture-of-Gaussians classi­ fication model for each pixel using an unsuper­ vised technique-an efficient, incremental ver­ sion of EM. Unlike the standard image-averaging approach, this automatically updates the mixture component for each class according to likelihood of membership; hence slow-moving objects are handled perfectly. Our approach also identifies and eliminates shadows much more effectively than other techniques such as thresholding. Ap­ plication of this method as part of the Roadwatch traffic surveillance project is expected to result in significant improvements in vehicle identification and tracking.",
            "output": [
                "Image Segmentation in Video Sequences: A Probabilistic Approach"
            ]
        },
        {
            "id": "task1540-75dfc79490324f1e8afbe6662295ecb3",
            "input": "We study the helpful product reviews identification problem in this paper. We observe that the evidence-conclusion discourse relations, also known as arguments, often appear in product reviews, and we hypothesise that some argumentbased features, e.g. the percentage of argumentative sentences, the evidencesconclusions ratios, are good indicators of helpful reviews. To validate this hypothesis, we manually annotate arguments in 110 hotel reviews, and investigate the effectiveness of several combinations of argument-based features. Experiments suggest that, when being used together with the argument-based features, the state-of-the-art baseline features can enjoy a performance boost (in terms of F1) of 11.01% in average.",
            "output": [
                "Using Argument-based Features to Predict and Analyse Review Helpfulness"
            ]
        },
        {
            "id": "task1540-2baf2f7080c6417499839ccdc8fdf520",
            "input": "Currently, criminal’s profile (CP) is obtained from investigator’s or forensic psychologist’s interpretation, linking crime scene characteristics and an offender’s behavior to his or her characteristics and psychological profile. This paper seeks an efficient and systematic discovery of non-obvious and valuable patterns between variables from a large database of solved cases via a probabilistic network (PN) modeling approach. The PN structure can be used to extract behavioral patterns and to gain insight into what factors influence these behaviors. Thus, when a new case is being investigated and the profile variables are unknown because the offender has yet to be identified, the observed crime scene variables are used to infer the unknown variables based on their connections in the structure and the corresponding numerical (probabilistic) weights. The objective is to produce a more systematic and empirical approach to profiling, and to use the resulting PN model as a decision tool. Keywords-component; Modeling, criminal profiling, criminal behavior, probabilistic network, Bayes Rule",
            "output": [
                "Modeling of Human Criminal Behavior using Probabilistic Networks"
            ]
        },
        {
            "id": "task1540-c384ccf5f49a47e7b9e8b9b09b91025c",
            "input": "This paper explores the real-time summarization of scheduled events such as soccer games from torrential flows of Twitter streams. We propose and evaluate an approach that substantially shrinks the stream of tweets in real-time, and consists of two steps: (i) sub-event detection, which determines if something new has occurred, and (ii) tweet selection, which picks a representative tweet to describe each sub-event. We compare the summaries generated in three languages for all the soccer games in Copa America 2011 to reference live reports offered by Yahoo! Sports journalists. We show that simple text analysis methods which do not involve external knowledge lead to summaries that cover 84% of the sub-events on average, and 100% of key types of sub-events (such as goals in soccer). Our approach should be straightforwardly applicable to other kinds of scheduled events such as other sports, award ceremonies, keynote talks, TV shows, etc.",
            "output": [
                "Towards Real-Time Summarization of Scheduled Events from Twitter Streams"
            ]
        },
        {
            "id": "task1540-007ca849493643ed96005456339bfec2",
            "input": "Massive public resume data emerging on the WWW indicates individual-related characteristics in terms of profile and career experiences. Resume Analysis (RA) provides opportunities for many applications, such as talent seeking and evaluation. Existing RA studies based on statistical analyzing have primarily focused on talent recruitment by identifying explicit attributes. However, they failed to discover the implicit semantic information, i.e., individual career progress patterns and social-relations, which are vital to comprehensive understanding of career development. Besides, how to visualize them for better human cognition is also challenging. To tackle these issues, we propose a visual analytics system ResumeVis to mine and visualize resume data. Firstly, a text-mining based approach is presented to extract semantic information. Then, a set of visualizations are devised to represent the semantic information in multiple perspectives. By interactive exploration on ResumeVis performed by domain experts, the following tasks can be accomplished: to trace individual career evolving trajectory; to mine latent social-relations among individuals; and to hold the full picture of massive resumes’ collective mobility. Case studies with over 2500 online officer resumes demonstrate the effectiveness of our system. We provide a demonstration video.",
            "output": [
                "ResumeVis: A Visual Analytics System to Discover Semantic Information in Semi-structured Resume Data"
            ]
        },
        {
            "id": "task1540-79ec45225d974474b2b579904dff6912",
            "input": "Selecting the right web links for a website is important because appropriate links not only can provide high attractiveness but can also increase the website’s revenue. In this work, we first show that web links have an intrinsic multilevel feedback structure. For example, consider a 2-level feedback web link: the 1st level feedback provides the Click-Through Rate (CTR) and the 2nd level feedback provides the potential revenue, which collectively produce the compound 2-level revenue. We consider the context-free links selection problem of selecting links for a homepage so as to maximize the total compound 2-level revenue while keeping the total 1st level feedback above a preset threshold. We further generalize the problem to links with n (n≥2)-level feedback structure. To our best knowledge, we are the first to model the links selection problem as a constrained multi-armed bandit problem and design an effective links selection algorithm by learning the links’ multi-level structure with provable sub-linear regret and violation bounds. We uncover the multi-level feedback structures of web links in two real-world datasets. We also conduct extensive experiments on the datasets to compare our proposed LExp algorithm with two state-of-the-art context-free bandit algorithms and show that LExp algorithm is the most effective in links selection while satisfying the constraint.",
            "output": [
                "Multi-level Feedback Web Links Selection Problem: Learning and Optimization"
            ]
        },
        {
            "id": "task1540-99a00d57de4b4044a65d7061a3cc2478",
            "input": "The Bacterial Foraging Optimization (BFO) is one of the metaheuristics algorithms that most widely used to solve optimization problems. The BFO is imitated from the behavior of the foraging bacteria group such as Ecoli. The main aim of algorithm is to eliminate those bacteria that have weak foraging methods and maintaining those bacteria that have strong foraging methods. In this extent, each bacterium communicates with other bacteria by sending signals such that bacterium change the position in the next step if prior factors have been satisfied. In fact, the process of algorithm allows bacteria to follow up nutrients toward the optimal. In this paper, the BFO is used for the solutions of Quadratic Assignment Problem (QAP), and multiobjective QAP (mQAP) by using updating mechanisms including mutation, crossover, and a local search.",
            "output": [
                "Bacteria Foraging Algorithm with Genetic Operators for the Solution of QAP and mQAP"
            ]
        },
        {
            "id": "task1540-8001e579f4924d738e6658402c9d3c89",
            "input": "Multitask learning algorithms are typically designed assuming some fixed, a priori known latent structure shared by all the tasks. However, it is usually unclear what type of latent task structure is the most appropriate for a given multitask learning problem. Ideally, the “right” latent task structure should be learned in a data-driven manner. We present a flexible, nonparametric Bayesian model that posits a mixture of factor analyzers structure on the tasks. The nonparametric aspect makes the model expressive enough to subsume many existing models of latent task structures (e.g, meanregularized tasks, clustered tasks, low-rank or linear/non-linear subspace assumption on tasks, etc.). Moreover, it can also learn more general task structures, addressing the shortcomings of such models. We present a variational inference algorithm for our model. Experimental results on synthetic and realworld datasets, on both regression and classification problems, demonstrate the effectiveness of the proposed method.",
            "output": [
                "Flexible Modeling of Latent Task Structures in Multitask Learning"
            ]
        },
        {
            "id": "task1540-37f7531d39a842109d966f9ac45fdcc3",
            "input": "We consider the problem of detecting an epidemic in a population where individual diagnoses are extremely noisy. The motivation for this problem is the plethora of examples (influenza strains in humans, or computer viruses in smartphones, etc.) where reliable diagnoses are scarce, but noisy data plentiful. In flu/phone-viruses, exceedingly few infected people/phones are professionally diagnosed (only a small fraction go to a doctor) but less reliable secondary signatures (e.g., people staying home, or greater-than-typical upload activity) are more readily available. These secondary data are often plagued by unreliability: many people with the flu do not stay home, and many people that stay home do not have the flu. This paper identifies the precise regime where knowledge of the contact network enables finding the needle in the haystack: we provide a distributed, efficient and robust algorithm that can correctly identify the existence of a spreading epidemic from highly unreliable local data. Our algorithm requires only local-neighbor knowledge of this graph, and in a broad array of settings that we describe, succeeds even when false negatives and false positives make up an overwhelming fraction of the data available. Our results show it succeeds in the presence of partial information about the contact network, and also when there is not a single “patient zero,” but rather many (hundreds, in our examples) of initial patient-zeroes, spread across the graph.",
            "output": [
                "Localized epidemic detection in networks with overwhelming noise"
            ]
        },
        {
            "id": "task1540-2980ceba15a546f9aeb1f8e65159d734",
            "input": "Rough set theory, a mathematical tool to deal with vague concepts, has originally described the indiscernibility of elements by equivalence relations. Covering rough sets are a natural extension of classical rough sets by relaxing the partitions arising from equivalence relations to covers. Recently, some topological concepts such as neighborhood have been applied to covering rough sets. In this paper, we further investigate the covering rough sets based on neighborhoods by approximation operations. We show that the upper approximation based on neighborhoods can be defined equivalently without using neighborhoods. To analyze the covers themselves, we introduce unary and composition operations on covers. A notion of homomorphism is provided to relate two covering approximation spaces. We also examine the properties of approximations preserved by the operations and homomorphisms, respectively.",
            "output": [
                "Covering rough sets based on neighborhoods"
            ]
        },
        {
            "id": "task1540-b191664f6c1e46658a434c09bbf1e4c5",
            "input": "Automated Theorem Proving (ATP) is an established branch of Artificial Intelligence. The purpose of ATP is to design a system which can automatically figure out an algorithm either to prove or disprove a mathematical claim, on the basis of a set of given premises, using a set of fundamental postulates and following the method of logical inference. In this paper, we propose GraATP, a generalized framework for automated theorem proving in plane geometry. Our proposed method translates the geometric entities into nodes of a graph and the relations between them as edges of that graph. The automated system searches for different ways to reach the conclusion for a claim via graph traversal by which the validity of the geometric theorem is examined.",
            "output": [
                "GraATP: A Graph Theoretic Approach for Automated Theorem Proving in Plane Geometry"
            ]
        },
        {
            "id": "task1540-46e32004ef884698bd6919ffac6cac06",
            "input": "Domain adaptation, and transfer learning more generally, seeks to remedy the problem created when training and testing datasets are generated by different distributions. In this work, we introduce a new unsupervised domain adaptation algorithm for when there are multiple sources available to a learner. Our technique assigns a rough labeling on the target samples, then uses it to learn a transformation that aligns the two datasets before final classification. In this article we give a convenient implementation of our method, show several experiments using it, and compare it to other methods commonly used in the field.",
            "output": [
                "Multi-Source Domain Adaptation Using Approximate Label Matching"
            ]
        },
        {
            "id": "task1540-1bb90619b64c4516a365a36a6e4d47e3",
            "input": "Most existing Neural Machine Translation models use groups of characters or whole words as their unit of input and output. We propose a model with a hierarchical char2word encoder, that takes individual characters both as input and output. We first argue that this hierarchical representation of the character encoder reduces computational complexity, and show that it improves translation performance. Secondly, by qualitatively studying attention plots from the decoder we find that the model learns to compress common words into a single embedding whereas rare words, such as names and places, are represented character by character.",
            "output": [
                "NEURAL MACHINE TRANSLATION WITH CHARACTERS AND HIERARCHICAL ENCODING"
            ]
        },
        {
            "id": "task1540-81aa10499b25465fb230e3bacd17bb02",
            "input": "Despite outstanding success in vision amongst other domains, many of the recent deep learning approaches have evident drawbacks for robots. This manuscript surveys recent work in the literature that pertain to applying deep learning systems to the robotics domain, either as means of estimation or as a tool to resolve motor commands directly from raw percepts. These recent advances are only a piece to the puzzle. We suggest that deep learning as a tool alone is insufficient in building a unified framework to acquire general intelligence. For this reason, we complement our survey with insights from cognitive development and refer to ideas from classical control theory, producing an integrated direction for a lifelong learning architecture.",
            "output": [
                "Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics"
            ]
        },
        {
            "id": "task1540-d9f3d414d59544e89bd042d0120c9d71",
            "input": "A number of visual question answering approaches have been proposed recently, aiming at understanding the visual scenes by answering the natural language questions. While the image question answering has drawn significant attention, video question answering is largely unexplored. Video-QA is different from Image-QA since the information and the events are scattered among multiple frames. In order to better utilize the temporal structure of the videos and the phrasal structures of the answers, we propose two mechanisms: the re-watching and the re-reading mechanisms and combine them into the forgettable-watcher model. Then we propose a TGIF-QA dataset for video question answering with the help of automatic question generation. Finally, we evaluate the models on our dataset. The experimental results show the effectiveness of our proposed models.",
            "output": [
                "The Forgettable-Watcher Model for Video Question Answering"
            ]
        },
        {
            "id": "task1540-4d35058a3d6a4a2cab73e9f9948f57ec",
            "input": "We consider the problem of proper learning a Boolean Halfspace with integer weights {0, 1, . . . , t} from membership queries only. The best known algorithm for this problem is an adaptive algorithm that asks n ) membership queries where the best lower bound for the number of membership queries is n [4]. In this paper we close this gap and give an adaptive proper learning algorithm with two rounds that asks n membership queries. We also give a non-adaptive proper learning algorithm that asks n ) membership queries.",
            "output": [
                "Learning Boolean Halfspaces with Small Weights from Membership Queries"
            ]
        },
        {
            "id": "task1540-031ed59f7a7844f4bc4498808acff441",
            "input": "We present DataGrad, a general back-propagation style training procedure for deep neural architectures that uses regularization of a deep Jacobian-based penalty. It can be viewed as a deep extension of the layerwise contractive auto-encoder penalty. More importantly, it unifies previous proposals for adversarial training of deep neural nets – this list includes directly modifying the gradient, training on a mix of original and adversarial examples, using contractive penalties, and approximately optimizing constrained adversarial objective functions. In an experiment using a Deep Sparse Rectifier Network, we find that the deep Jacobian regularization of DataGrad (which also has L1 and L2 flavors of regularization) outperforms traditional L1 and L2 regularization both on the original dataset as well as on adversarial examples.",
            "output": [
                "Unifying Adversarial Training Algorithms with Flexible Deep Data Gradient Regularization"
            ]
        },
        {
            "id": "task1540-40fb5964c1804bc4b8a95f02902c4904",
            "input": "Syntax-Guided Synthesis (SyGuS) is the computational problem of finding an implementation f that meets both a semantic constraint given by a logical formula φ in a background theory T , and a syntactic constraint given by a grammar G, which specifies the allowed set of candidate implementations. Such a synthesis problem can be formally defined in SyGuS-IF, a language that is built on top of SMT-LIB. The Syntax-Guided Synthesis Competition (SyGuS-Comp) is an effort to facilitate, bring together and accelerate research and development of efficient solvers for SyGuS by providing a platform for evaluating different synthesis techniques on a comprehensive set of benchmarks. In this year’s competition we added a new track devoted to programming by examples. This track consisted of two categories, one using the theory of bit-vectors and one using the theory of strings. This paper presents and analyses the results of SyGuS-Comp’16.",
            "output": [
                "SyGuS-Comp 2016: Results and Analysis"
            ]
        },
        {
            "id": "task1540-18b5f1ea70ef4cc19ea347a864c3c38a",
            "input": "In computing, spell checking is the process of detecting and sometimes providing spelling suggestions for incorrectly spelled words in a text. Basically, a spell checker is a computer program that uses a dictionary of words to perform spell checking. The bigger the dictionary is, the higher is the error detection rate. The fact that spell checkers are based on regular dictionaries, they suffer from data sparseness problem as they cannot capture large vocabulary of words including proper names, domain-specific terms, technical jargons, special acronyms, and terminologies. As a result, they exhibit low error detection rate and often fail to catch major errors in the text. This paper proposes a new context-sensitive spelling correction method for detecting and correcting non-word and real-word errors in digital text documents. The approach hinges around data statistics from Google Web 1T 5-gram data set which consists of a big volume of n-gram word sequences, extracted from the World Wide Web. Fundamentally, the proposed method comprises an error detector that detects misspellings, a candidate spellings generator based on a character 2-gram model that generates correction suggestions, and an error corrector that performs contextual error correction. Experiments conducted on a set of text documents from different domains and containing misspellings, showed an outstanding spelling error correction rate and a drastic reduction of both non-word and real-word errors. In a further study, the proposed algorithm is to be parallelized so as to lower the computational cost of the error detection and correction processes.",
            "output": [
                "Context-sensitive Spelling Correction Using Google Web 1T 5-Gram Information"
            ]
        },
        {
            "id": "task1540-4dba947acef94c33961e9c31886aaca5",
            "input": "LTL synthesis – the construction of a function to satisfy a logical specification formulated in Linear Temporal Logic – is a 2EXPTIME-complete problem with relevant applications in controller synthesis and a myriad of artificial intelligence applications. In this research note we consider De Giacomo and Vardi’s variant of the synthesis problem for LTL formulas interpreted over finite rather than infinite traces. Rather surprisingly, given the existing claims on complexity, we establish that LTL synthesis is EXPTIME-complete for the finite interpretation, and not 2EXPTIME-complete as previously reported. Our result coincides nicely with the planning perspective where non-deterministic planning with full observability is EXPTIME-complete and partial observability increases the complexity to 2EXPTIME-complete; a recent related result for LTL synthesis shows that in the finite case with partial observability, the problem is 2EXPTIME-complete.",
            "output": [
                "Finite LTL Synthesis is EXPTIME-complete"
            ]
        },
        {
            "id": "task1540-3583ccd47b4a4d53bd2779c8695c6558",
            "input": "Nowadays, neural networks play an important role in the task of relation classification. By designing different neural architectures, researchers have improved the performance to a large extent, compared with traditional methods. However, existing neural networks for relation classification are usually of shallow architectures (e.g., one-layer convolution neural networks or recurrent networks). They may fail to explore the potential representation space in different abstraction levels. In this paper, we propose deep recurrent neural networks (DRNNs) to tackle this challenge. Further, we propose a data augmentation method by leveraging the directionality of relations. We evaluate our DRNNs on the SemEval-2010 Task 8, and achieve an F1score of 85.81%, outperforming state-of-theart recorded results.",
            "output": [
                "Improved Relation Classification by Deep Recurrent Neural Networks with Data Augmentation"
            ]
        },
        {
            "id": "task1540-5d4ff9a3a4fa488487700d021ce51d62",
            "input": "The generation of political event data has remained much the same since the mid-1990s, both in terms of data acquisition and the process of coding text into data. Since the 1990s, however, there have been significant improvements in open-source natural language processing software and in the availability of digitized news content. This paper presents a new, next-generation event dataset, named Phoenix, that builds from these and other advances. This dataset includes improvements in the underlying news collection process and event coding software, along with the creation of a general processing pipeline necessary to produce daily-updated data. This paper provides a face validity checks by briefly examining the data for the conflict in Syria, and a comparison between Phoenix and the Integrated Crisis Early Warning System data. 1 Moving Event Data Forward Automated coding of political event data, or the record of who-did-what-towhom within the context of political actions, has existed for roughly two decades. The approach has remained largely the same during this time, with the underlying coding procedures not updating to reflect changes in natural language processing (NLP) technology. These NLP technologies have now advanced to such a level, and with accompanying open-source software implementations, that their inclusion in the event-data coding process comes as an obvious advancement. When combined with changes in how news content is obtained, the ability to store and process large amounts of text, and enhancements based on two decades worth of event-data experience, it becomes clear that political event data is ready for a next generation dataset. In this chapter, I provide the technical details for creating such a nextgeneration dataset. The technical details lead to a pipeline for the production of the Phoenix event dataset. The Phoenix dataset is a daily updated, nearreal-time political event dataset. The coding process makes use of open-source NLP software, an abundance of online news content, and other technical advances made possible by open-source software. This enables a dataset that is transparent and replicable, while providing a more accurate coding process than previously possible. Additionally, the dataset’s near-real-time nature also enables many applications that were previously impossible with batchupdated datasets, such as monitoring of ongoing events. Thus, this dataset",
            "output": [
                "Creating a Real-Time, Reproducible Event Dataset"
            ]
        },
        {
            "id": "task1540-c5161b9824264450a4b7603519d83dad",
            "input": "Multiclass prediction is the problem of classifying an object into a relevant target class. We consider the problem of learning a multiclass predictor that uses only few features, and in particular, the number of used features should increase sub-linearly with the number of possible classes. This implies that features should be shared by several classes. We describe and analyze the ShareBoost algorithm for learning a multiclass predictor that uses few shared features. We prove that ShareBoost efficiently finds a predictor that uses few shared features (if such a predictor exists) and that it has a small generalization error. We also describe how to use ShareBoost for learning a non-linear predictor that has a fast evaluation time. In a series of experiments with natural data sets we demonstrate the benefits of ShareBoost and evaluate its success relatively to other state-of-the-art approaches.",
            "output": [
                "ShareBoost: Efficient Multiclass Learning with Feature Sharing"
            ]
        },
        {
            "id": "task1540-c617bfa1faf546c4bb033c8426447e8c",
            "input": "Quantifying the degree of spatial dependence for linguistic variables is a key task for analyzing dialectal variation. However, existing approaches have important drawbacks. First, they make unjustified assumptions about the nature of spatial variation: some assume that the geographical distribution of linguistic variables is Gaussian, while others assume that linguistic variation is aligned to pre-defined geopolitical units such as states or counties. Second, they are not applicable to all types of linguistic data: some approaches apply only to frequencies, others to boolean indicators of whether a linguistic variable is present. We present a new method for measuring geographical language variation, which solves both of these problems. Our approach builds on reproducing kernel Hilbert space (RKHS) representations for nonparametric statistics, and takes the form of a test statistic that is computed from pairs of individual geotagged observations without aggregation into predefined geographical bins. We compare this test with prior work using synthetic data as well as a diverse set of real datasets: a corpus of Dutch tweets, a Dutch syntactic atlas, and a dataset of letters to the editor in North American newspapers. Our proposed test is shown to support robust inferences across a broad range of scenarios and types of data.",
            "output": [
                "A Kernel Independence Test for Geographical Language Variation"
            ]
        },
        {
            "id": "task1540-91f1d6bb74c744d087dec4264c32f596",
            "input": "This position paper advocates a communicationsinspired approach to the design of machine learning systems on energy-constrained embedded ‘always-on’ platforms. The communicationsinspired approach has two versions 1) a deterministic version where existing low-power communication IC design methods are repurposed, and 2) a stochastic version referred to as Shannon-inspired statistical information processing employing information-based metrics, statistical error compensation (SEC), and retraining-based methods to implement ML systems on stochastic circuit/device fabrics operating at the limits of energy-efficiency. The communications-inspired approach has the potential to fully leverage the opportunities afforded by ML algorithms and applications in order to address the challenges inherent in their deployment on energy-constrained platforms.",
            "output": [
                "Energy-efficient Machine Learning in Silicon: A Communications-inspired Approach"
            ]
        },
        {
            "id": "task1540-2192e5d24a3a4afd94f0228193e1b967",
            "input": "In security-sensitive applications, the success of machine learning depends on a thorough vetting of their resistance to adversarial data. In one pertinent, well-motivated attack scenario, an adversary may attempt to evade a deployed system at test time by carefully manipulating attack samples. In this work, we present a simple but effective gradientbased approach that can be exploited to systematically assess the security of several, widely-used classification algorithms against evasion attacks. Following a recently proposed framework for security evaluation, we simulate attack scenarios that exhibit different risk levels for the classifier by increasing the attacker’s knowledge of the system and her ability to manipulate attack samples. This gives the classifier designer a better picture of the classifier performance under evasion attacks, and allows him to perform a more informed model selection (or parameter setting). We evaluate our approach on the relevant security task of malware detection in PDF files, and show that such systems can be easily evaded. We also sketch some countermeasures suggested by our analysis.",
            "output": [
                "Evasion attacks against machine learning at test time"
            ]
        },
        {
            "id": "task1540-79240c6c277c48cd8240fb8d8f36f592",
            "input": "Denoising autoencoders (DAs) are typically applied to relatively large datasets for unsupervised learning of representative data encodings; they rely on the idea of making the learned representations robust to partial corruption of the input pattern, and perform learning using stochastic gradient descent with relatively large datasets. In this paper, we present a fully Bayesian DA architecture that allows for the application of DAs even when data is scarce. Our novel approach formulates the signal encoding problem under a nonparametric Bayesian regard, considering a Gaussian process prior over the latent input encodings generated given the (corrupt) input observations. Subsequently, the decoder modules of our model are formulated as large-margin regression models, treated under the Bayesian inference paradigm, by exploiting the maximum entropy discrimination (MED) framework. We exhibit the effectiveness of our approach using several datasets, dealing with both classification and transfer learning applications.",
            "output": [
                "Maximum Entropy Discrimination Denoising Autoencoders"
            ]
        },
        {
            "id": "task1540-01043a0481ec4d47b87fc5156282ecf6",
            "input": "The subpath planning problem is a branch of the path planning problem, which has widespread applications in automated manufacturing process as well as vehicle and robot navigation. This problem is to find the shortest path or tour subject for travelling a set of given subpaths. The current approaches for dealing with the subpath planning problem are all based on meta-heuristic approaches. It is well-known that meta-heuristic based approaches have several deficiencies. To address them, we propose a novel approximation algorithm in the O(n3) time complexity class, which guarantees to solve any subpath planning problem instance with the fixed ratio bound of 2. Beside the formal proofs of the claims, our empirical evaluation shows that our approximation method acts much better than a state-of-the-art method, both in result and execution time. Note to Practitioners—In some real world applications such as robot and vehicle navigation in structured and industrial environments as well as some of the manufacturing processes such as electronic printing and polishing, it is required for the agent to travel a set of predefined paths. Automating this process includes three steps: 1) capturing the environment of the actual problem and formulating it as a subpath planning problem; 2) solving subpath planning problem to find the near optimal path or tour; 3) command the robot to follow the output. The most challenging phase is the second one that this paper tries to tackle it. To design an effective automation for the aforementioned applications, it is essential to make use of methods with low computational cost but near optimal outputs in the second phase. According to the fact that the length of the final output has a direct effect on the cost of performing the task, it is desirable to incorporate methods with low complexity that can guarantee a bound for the difference between length of the optimal path and 1 ar X iv :1 60 3. 06 21 7v 1 [ cs .R O ] 2 0 M ar 2 01 6 the output. Current approaches for solving subpath planning problem are all meta-heuristic based. These methods do not provide such a bound. And plus, they are usually very time consuming. They may find promising results for some instances of problems, but there is no guarantee that they always exhibit such a good behaviour. In this paper, in order to avoid the issues of metaheuristics methods, we present an approximation algorithm, which provides an appropriate bound for the optimality of its solution. To gauge the performance of proposed methods, we conducted a set of experiments the results of which show that our proposed method finds shorter paths in less time in comparison with a state-of-the-art method.",
            "output": [
                "An Approximation Approach for Solving the Subpath Planning Problem"
            ]
        },
        {
            "id": "task1540-f5a6012c387045849d299600693c37c7",
            "input": "In many settings, we have multiple data sets (also called views) that capture different and overlapping aspects of the same phenomenon. We are often interested in finding patterns that are unique to one or to a subset of the views. For example, we might have one set of molecular observations and one set of physiological observations on the same group of individuals, and we want to quantify molecular patterns that are uncorrelated with physiology. Despite being a common problem, this is highly challenging when the correlations come from complex distributions. In this paper, we develop the general framework of Rich Component Analysis (RCA) to model settings where the observations from different views are driven by different sets of latent components, and each component can be a complex, highdimensional distribution. We introduce algorithms based on cumulant extraction that provably learn each of the components without having to model the other components. We show how to integrate RCA with stochastic gradient descent into a meta-algorithm for learning general models, and demonstrate substantial improvement in accuracy on several synthetic and real datasets in both supervised and unsupervised tasks. Our method makes it possible to learn latent variable models when we don’t have samples from the true model but only samples after complex perturbations.",
            "output": [
                "Rich Component Analysis"
            ]
        },
        {
            "id": "task1540-b690024170b04e42aca0c37f635b5513",
            "input": "In this paper, we address the problem of data description using a Bayesian framework. The goal of data description is to draw a boundary around objects of a certain class of interest to discriminate that class from the rest of the feature space. Data description is also known as one-class learning and has a wide range of applications. The proposed approach uses a Bayesian framework to precisely compute the class boundary and therefore can utilize domain information in form of prior knowledge in the framework. It can also operate in the kernel space and therefore recognize arbitrary boundary shapes. Moreover, the proposed method can utilize unlabeled data in order to improve accuracy of discrimination. We evaluate our method using various real-world datasets and compare it with other state of the art approaches of data description. Experiments show promising results and improved performance over other data description and one-class learning algorithms.",
            "output": [
                "A Bayesian Approach to the Data Description Problem"
            ]
        },
        {
            "id": "task1540-fbcf44aee7ec463abff8447bb8be3076",
            "input": "Mixed Integer Optimization has been a topic of active research in past decades. It has been used to solve Statistical problems of classification and regression involving massive data. However, there is an inherent degree of vagueness present in huge real life data. This impreciseness is handled by Fuzzy Sets. In this Paper, Fuzzy Mixed Integer Optimization Method (FMIOM) is used to find solution to Regression problem. The methodology exploits discrete character of problem. In this way large scale problems are solved within practical limits. The data points are separated into different polyhedral regions and each region has its own distinct regression coefficients. In this attempt, an attention is drawn to Statistics and Data Mining community that Integer Optimization can be significantly used to revisit different Statistical problems. Computational experimentations with generated and real data sets show that FMIOM is comparable to and often outperforms current leading methods. The results illustrate potential for significant impact of Fuzzy Integer Optimization methods on Computational Statistics and Data Mining. Keywords–Mixed Integer Optimization; Fuzzy Sets; Regression; Polyhedral Regions",
            "output": [
                "Fuzzy Mixed Integer Optimization Model for Regression Approach"
            ]
        },
        {
            "id": "task1540-37e049ec0e4d46d0ac5ab7741c063dd3",
            "input": "When faced with complex choices, users refine their own preference criteria as they explore the catalogue of options. In this paper we propose an approach to preference elicitation suited for this scenario. We extend Coactive Learning, which iteratively collects manipulative feedback, to optionally query example critiques. User critiques are integrated into the learning model by dynamically extending the feature space. Our formulation natively supports constructive learning tasks, where the option catalogue is generated on-the-fly. We present an upper bound on the average regret suffered by the learner. Our empirical analysis highlights the promise of",
            "output": [
                "Coactive Critiquing: Elicitation of Preferences and Features"
            ]
        },
        {
            "id": "task1540-c5ba7a132fcf4ff3abc3a3a217e42d07",
            "input": "A hierarchical clustering method is stable if small perturbations on the data set produce small perturbations in the result. This perturbations<lb>are measured using the Gromov-Hausdorff metric. We study the problem of stability on linkage-based hierarchical clustering methods. We obtain that, under some basic conditions, standard linkage-based methods are semi-stable.<lb>This means that they are stable if the input data is close enough to an ultrametric space. We prove that, apart from exotic examples, introducing any unchaining condition in the algorithm always produces unstable methods.",
            "output": [
                "GROMOV-HAUSDORFF STABILITY OF LINKAGE-BASED HIERARCHICAL CLUSTERING METHODS"
            ]
        },
        {
            "id": "task1540-1f98ee92fc5f46e29a8eebdff14e9ffd",
            "input": "We introduce a compact graph-theoretic repre­ sentation for multi-party game theory. Our main result is a provably correct and efficient algo­ rithm for computing approximate Nash equilibria in one-stage games represented by trees or sparse graphs.",
            "output": [
                "Graphical Models for Game Theory"
            ]
        },
        {
            "id": "task1540-ad6d0ae3396441218265febb85158da4",
            "input": "Several large cloze-style context-questionanswer datasets have been introduced recently: the CNN and Daily Mail news data and the Children’s Book Test. Thanks to the size of these datasets, the associated text comprehension task is well suited for deep-learning techniques that currently seem to outperform all alternative approaches. We present a new, simple model that uses attention to directly pick the answer from the context as opposed to computing the answer using a blended representation of words in the document as is usual in similar models. This makes the model particularly suitable for question-answering problems where the answer is a single word from the document. Our model outperforms models previously proposed for these tasks by a large margin.",
            "output": [
                "Text Understanding with the Attention Sum Reader Network"
            ]
        },
        {
            "id": "task1540-0ed3daa6e0fb4eacb7d6a935dae459c7",
            "input": "The ICDM Challenge 2013 is to apply machine learning to the problem of hotel ranking, aiming to maximize purchases according to given hotel characteristics, location attractiveness of hotels, users aggregated purchase history and competitive online travel agency (OTA) information for each potential hotel choice. This paper describes the solution of team ”binghsu & MLRush & BrickMover”. We conduct simple feature engineering work and train different models by each individual team member. Afterwards, we use listwise ensemble method to combine each model’s output. Besides describing effective model and features, we will discuss about the lessons we learned while using deep learning in this competition.",
            "output": [
                "Combination of Diverse Ranking Models for Personalized Expedia Hotel Searches"
            ]
        },
        {
            "id": "task1540-94556b76a7a9428abc3f518b91162203",
            "input": "The rapid advancement of machine learning techniques has re-energized research into general artificial intelligence. While the idea of domain-agnostic meta-learning is appealing, this emerging field must come to terms with its relationship to human cognition and the statistics and structure of the tasks humans perform. The position of this article is that only by aligning our agents’ abilities and environments with those of humans do we stand a chance at developing general artificial intelligence (GAI).",
            "output": [
                "Minimally Naturalistic Artificial Intelligence"
            ]
        },
        {
            "id": "task1540-2c2401e97fe841818edb136988e8dbf3",
            "input": "Normalized graph cut (NGC) has become a popular research topic due to its wide applications in a large variety of areas like machine learning and very large scale integration (VLSI) circuit design. Most of traditional NGC methods are based on pairwise relationships (similarities). However, in real-world applications relationships among the vertices (objects) may be more complex than pairwise, which are typically represented as hyperedges in hypergraphs. Thus, normalized hypergraph cut (NHC) has attracted more and more attention. Existing NHC methods cannot achieve satisfactory performance in real applications. In this paper, we propose a novel relaxation approach, which is called relaxed NHC (RNHC), to solve the NHC problem. Our model is defined as an optimization problem on the Stiefel manifold. To solve this problem, we resort to the Cayley transformation to devise a feasible learning algorithm. Experimental results on a set of large hypergraph benchmarks for clustering and partitioning in VLSI domain show that RNHC can outperform the state-of-the-art methods.",
            "output": [
                "A New Relaxation Approach to Normalized Hypergraph Cut"
            ]
        },
        {
            "id": "task1540-505c1ec3a4de477f83df50183b125d57",
            "input": "We study the problem of identifying the best action among a set of possible options when the value of each action is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting. Our main motivation is the application to the minimax game search, which has been a major topic of interest in artificial intelligence. In this paper we introduce an abstract setting to clearly describe the essential properties of the problem. While previous work only considered a two-move game tree search problem, our abstract setting can be applied to the general minimax games where the depth can be non-uniform and arbitrary, and transpositions are allowed. We introduce a new algorithm (LUCB-micro) for the abstract setting, and give its lower and upper sample complexity results. Our bounds recover some previous results, which were only available in more limited settings, while they also shed further light on how the structure of minimax problems influence sample complexity.",
            "output": [
                "Structured Best Arm Identification with Fixed Confidence"
            ]
        },
        {
            "id": "task1540-9041e4e341ff49ecb742d9f19341d75e",
            "input": "Opinion mining aims at extracting useful subjective information from reliable amounts of text. Opinion mining holder recognition is a task that has not been considered yet in Arabic Language. This task essentially requires deep understanding of clauses structures. Unfortunately, the lack of a robust, publicly available, Arabic parser further complicates the research. This paper presents a leading research for the opinion holder extraction in Arabic news independent from any lexical parsers. We investigate constructing a comprehensive feature set to compensate the lack of parsing structural outcomes. The proposed feature set is tuned from English previous works coupled with our proposed semantic field and named entities features. Our feature analysis is based on Conditional Random Fields (CRF) and semi-supervised pattern recognition techniques. Different research models are evaluated via cross-validation experiments achieving 54.03 F-measure. We publicly release our own research outcome corpus and lexicon for opinion mining community to encourage further research.",
            "output": [
                "A MACHINE LEARNING APPROACH FOR OPINION HOLDER EXTRACTION IN ARABIC LANGUAGE"
            ]
        },
        {
            "id": "task1540-266b9eb0f82e4e00a9538f26c1c4c814",
            "input": "Plagiarism is one of the growing issues in academia and is always a concern in Universities and other academic institutions. The situation is becoming even worse with the availability of ample resources on the web. This paper focuses on creating an effective and fast tool for plagiarism detection for text based electronic assignments. Our plagiarism detection tool named AntiPlag is developed using the tri-gram sequence matching technique. Three sets of text based assignments were tested by AntiPlag and the results were compared against an existing commercial plagiarism detection tool. AntiPlag showed better results in terms of false positives compared to the commercial tool due to the pre-processing steps performed in AntiPlag. In addition, to improve the detection latency, AntiPlag applies a data clustering technique making it four times faster than the commercial tool considered. AntiPlag could be used to isolate plagiarized text based assignments from non-plagiarised assignments easily. Therefore, we present AntiPlag, a fast and effective tool for plagiarism detection on text based electronic assignments.",
            "output": [
                "AntiPlag: Plagiarism Detection on Electronic Submissions of Text Based Assignments"
            ]
        },
        {
            "id": "task1540-240710ada1514d109403627fb6c5e0af",
            "input": "Most past work on social network link fraud detection tries to separate genuine users from fraudsters, implicitly assuming that there is only one type of fraudulent behavior. But is this assumption true? And, in either case, what are the characteristics of such fraudulent behaviors? In this work, we set up honeypots, (“dummy” social network accounts), and buy fake followers (after careful IRB approval). We report the signs of such behaviors including oddities in local network connectivity, account attributes, and similarities and differences across fraud providers. Most valuably, we discover and characterize several types of fraud behaviors. We discuss how to leverage our insights in practice by engineering strongly performing entropy-based features and demonstrating high classification accuracy. Our contributions are (a) instrumentation: we detail our experimental setup and carefully engineered data collection process to scrape Twitter data while respecting API rate-limits, (b) observations on fraud multimodality: we analyze our honeypot fraudster ecosystem and give surprising insights into the multifaceted behaviors of these fraudster types, and (c) features: we propose novel features that give strong (>0.95 precision/recall) discriminative power on ground-truth Twitter data.",
            "output": [
                "The Many Faces of Link Fraud"
            ]
        },
        {
            "id": "task1540-39ea820350b3401795f2a9ccff5ac52f",
            "input": "We consider the adaptive shortest-path routing problem in wireless networks under unknown and stochastically varying link states. In this problem, we aim to optimize the quality of communication between a source and a destination through adaptive path selection. Due to the randomness and uncertainties in the network dynamics, the quality of each link varies over time according to a stochastic process with unknown distributions. After a path is selected for communication, the aggregated quality of all links on this path (e.g., total path delay) is observed. The quality of each individual link is not observable. We formulate this problem as a multi-armed bandit with dependent arms. We show that by exploiting arm dependencies, a regret polynomial with network size can be achieved while maintaining the optimal logarithmic order with time. This is in sharp contrast with the exponential regret order with network size offered by a direct application of the classic MAB policies that ignore arm dependencies. Furthermore, our results are obtained under a general model of link-quality distributions (including heavy-tailed distributions) and find applications in cognitive radio and ad hoc networks with unknown and dynamic communication environments.",
            "output": [
                "Adaptive Shortest-Path Routing under Unknown and Stochastically Varying Link States"
            ]
        },
        {
            "id": "task1540-62b73e0358664ac2b460ac6f150731f4",
            "input": "Domain knowledge is crucial for effective performance in autonomous control systems. Typically, human effort is required to encode this knowledge into a control algorithm. In this paper, we present an approach to language grounding which automatically interprets text in the context of a complex control application, such as a game, and uses domain knowledge extracted from the text to improve control performance. Both text analysis and control strategies are learned jointly using only a feedback signal inherent to the application. To effectively leverage textual information, our method automatically extracts the text segment most relevant to the current game state, and labels it with a task-centric predicate structure. This labeled text is then used to bias an action selection policy for the game, guiding it towards promising regions of the action space. We encode our model for text analysis and game playing in a multi-layer neural network, representing linguistic decisions via latent variables in the hidden layers, and game action quality via the output layer. Operating within the Monte-Carlo Search framework, we estimate model parameters using feedback from simulated games. We apply our approach to the complex strategy game Civilization II using the official game manual as the text guide. Our results show that a linguistically-informed game-playing agent significantly outperforms its language-unaware counterpart, yielding a 34% absolute improvement and winning over 65% of games when playing against the built-in AI of Civilization.",
            "output": [
                "Learning to Win by Reading Manuals in a Monte-Carlo Framework"
            ]
        },
        {
            "id": "task1540-849f075d54a1476a815744f9ac7653f3",
            "input": "We address a challenging fine-grain classification problem: recognizing a font style from an image of text. In this task, it is very easy to generate lots of rendered font examples but very hard to obtain real-world labeled images. This realto-synthetic domain gap caused poor generalization to new real data in previous methods (Chen et al. (2014)). In this paper, we refer to Convolutional Neural Networks, and use an adaptation technique based on a Stacked Convolutional AutoEncoder that exploits unlabeled real-world images combined with synthetic data. The proposed method achieves an accuracy of higher than 80% (top-5) on a realworld dataset.",
            "output": [
                "REAL-WORLD FONT RECOGNITION USING DEEP NET-"
            ]
        },
        {
            "id": "task1540-02e822b61fac4514a437ffe587223d9b",
            "input": "Recently, triggered by the impressive results in TV-games or game of Go by Google DeepMind, end-to-end reinforcement learning (RL) is collecting attentions. Although little is known, the author’s group has propounded this framework for around 20 years and already has shown a variety of functions that emerge in a neural network (NN) through RL. In this paper, they are introduced again at this timing. “Function Modularization” approach is deeply penetrated subconsciously. The inputs and outputs for a learning system can be raw sensor signals and motor commands. “State space” or “action space” generally used in RL show the existence of functional modules. That has limited reinforcement learning to learning only for the action-planning module. In order to extend reinforcement learning to learning of the entire function on a huge degree of freedom of a massively parallel learning system and to explain or develop human-like intelligence, the author has believed that end-to-end RL from sensors to motors using a recurrent NN (RNN) becomes an essential key. Especially in the higher functions, since their inputs or outputs are difficult to decide, this approach is very effective by being free from the need to decide them. The functions that emerge, we have confirmed, through RL using a NN cover a broad range from real robot learning with raw camera pixel inputs to acquisition of dynamic functions in a RNN. Those are (1)image recognition, (2)color constancy (optical illusion), (3)sensor motion (active recognition), (4)hand-eye coordination and hand reaching movement, (5)explanation of brain activities, (6)communication, (7)knowledge transfer, (8)memory, (9)selective attention, (10)prediction, (11)exploration. The end-to-end RL enables the emergence of very flexible comprehensive functions that consider many things in parallel although it is difficult to give the boundary of each function clearly.",
            "output": [
                "Functions that Emerge through End-to-endReinforcement Learning"
            ]
        },
        {
            "id": "task1540-617dfc145f40436893d6cb79491050a1",
            "input": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18× faster, requires 75× less FLOPs, has 79× less parameters, and provides similar or better accuracy to existing models. We have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.",
            "output": [
                "ENET: A DEEP NEURAL NETWORK ARCHITECTURE FOR REAL-TIME SEMANTIC SEGMENTATION"
            ]
        },
        {
            "id": "task1540-59e59f8107a747429708559a7a35bfe5",
            "input": "We discuss methodological issues related to the evaluation of unsupervised binary code construction methods for nearest neighbor search. These issues have been widely ignored in literature. These coding methods attempt to preserve either Euclidean distance or angular (cosine) distance in the binary embedding space. We explain why when comparing a method whose goal is preserving cosine similarity to one designed for preserving Euclidean distance, the original features should be normalized by mapping them to the unit hypersphere before learning the binary mapping functions. To compare a method whose goal is to preserves Euclidean distance to one that preserves cosine similarity, the original feature data must be mapped to a higher dimension by including a bias term in binary mapping functions. These conditions ensure the fair comparison between different binary code methods for the task of nearest neighbor search. Our experiments show under these conditions the very simple methods (e.g. LSH and ITQ) often outperform recent state-of-the-art methods (e.g. MDSH and OK-means).",
            "output": [
                "Comparing apples to apples in the evaluation of binary coding methods"
            ]
        },
        {
            "id": "task1540-a3c3c647cc7f43aca7ad32d49f2e7aaa",
            "input": "We introduce a method for constructing skills capable of solving tasks drawn from a distribution of parameterized reinforcement learning problems. The method draws example tasks from a distribution of interest and uses the corresponding learned policies to estimate the topology of the lower-dimensional piecewise-smooth manifold on which the skill policies lie. This manifold models how policy parameters change as task parameters vary. The method identifies the number of charts that compose the manifold and then applies non-linear regression in each chart to construct a parameterized skill by predicting policy parameters from task parameters. We evaluate our method on an underactuated simulated robotic arm tasked with learning to accurately throw darts at a parameterized target location.",
            "output": [
                "Learning Parameterized Skills"
            ]
        },
        {
            "id": "task1540-f1c760d4bc354caf9d636abd48e34c5c",
            "input": "The commonly used Q-learning algorithm combined with function approximation induces systematic overestimations of state-action values. These systematic errors might cause instability, poor performance and sometimes divergence of learning. In this work, we present the AVERAGED TARGET DQN (ADQN) algorithm, an adaptation to the DQN class of algorithms which uses a weighted average over past learned networks to reduce generalization noise variance. As a consequence, this leads to reduced overestimations, more stable learning process and improved performance. Additionally, we analyze ADQN variance reduction along trajectories and demonstrate the performance of ADQN on a toy Gridworld problem, as well as on several of the Atari 2600 games from the Arcade Learning Environment.",
            "output": [
                "Deep Reinforcement Learning with Averaged Target DQN"
            ]
        },
        {
            "id": "task1540-7488c483258440298aa4ca7a8fca8483",
            "input": "Studying characters plays a vital role in computationally representing and interpreting narratives. Unlike previous work, which has focused on inferring character roles, we focus on the problem of modeling their relationships. Rather than assuming a fixed relationship for a character pair, we hypothesize that relationships are dynamic and temporally evolve with the progress of the narrative, and formulate the problem of relationship modeling as a structured prediction problem. We propose a semisupervised framework to learn relationship sequences from fully as well as partially labeled data. We present a Markovian model capable of accumulating historical beliefs about the relationship and status changes. We use a set of rich linguistic and semantically motivated features that incorporate world knowledge to investigate the textual content of narrative. We empirically demonstrate that such a framework outperforms competitive baselines.",
            "output": [
                "Modeling Dynamic Relationships Between Characters in Literary Novels"
            ]
        },
        {
            "id": "task1540-84d3201b2c494b96a7ec7bb71a18e456",
            "input": "To coordinate with other agents in its envi­ ronment, an agent needs models of what the other agents are trying to do. When com­ munication is impossible or expensive, this information must be acquired indirectly via plan recognition. Typical approaches to plan recognition start with a specification of the possible plans the other agents may be follow­ ing, and develop special techniques for dis­ criminating among the possibilities. Perhaps more desirable would be a uniform procedure for mapping plans to general structures sup­ porting inference based on uncertain and in­ complete observations. In this paper, we de­ scribe a set of methods for converting plans represented in a flexible procedural language to observation models represented as proba­ bilistic belief networks.",
            "output": [
                "The Automated Mapping of Plans for Plan Recognition*"
            ]
        },
        {
            "id": "task1540-927c2320ca6e4ec7977cb9db4315cd0a",
            "input": "This work proposes a novel support vector machine (SVM) based robust automatic speech recognition (ASR) front-end that operates on an ensemble of the subband components of high-dimensional acoustic waveforms. The key issues of selecting the appropriate SVM kernels for classification in frequency subbands and the combination of individual subband classifiers using ensemble methods are addressed. The proposed front-end is compared with state-of-the-art ASR front-ends in terms of robustness to additive noise and linear filtering. Experiments performed on the TIMIT phoneme classification task demonstrate the benefits of the proposed subband based SVM front-end: it outperforms the standard cepstral front-end in the presence of noise and linear filtering for signal-to-noise ratio (SNR) below 12-dB. A combination of the proposed front-end with a conventional front-end such as MFCC yields further improvements over the individual front ends across the full range of noise levels.",
            "output": [
                "A Subband-Based SVM Front-End for Robust ASR"
            ]
        },
        {
            "id": "task1540-8049792c34e14d97bbf46bf531661476",
            "input": "<lb>We analyze online [6] and mini-batch [20] k-means variants. Both<lb>scale up the widely used Lloyd’s algorithm via stochastic approximation,<lb>and have become popular for large-scale clustering and unsupervised<lb>feature learning. We show, for the first time, that they have global<lb>convergence towards “local optima” at rate<lb>O(1t ) under general condi-<lb>tions. In addition, we show if the dataset is clusterable, with suitable<lb>initialization, mini-batch k-means converges to an optimal k-means<lb>solution at rate<lb>O(1t ) with high probability. The k-means objective is<lb>non-convex and non-differentiable: we exploit ideas from non-convex<lb>gradient-based optimization by providing a novel characterization of the<lb>trajectory of k-means algorithm on its solution space, and circumvent<lb>its non-differentiability via geometric insights about k-means update.",
            "output": [
                "Convergence rate of stochastic k-means"
            ]
        },
        {
            "id": "task1540-7254dbcfa26c4d83b1d6e8fdcc9f5956",
            "input": "We investigate the use of temporally abstract actions, or macro-actions, in the solution of Markov decision processes. Unlike current mod­ els that combine both primitive actions and macro-actions and leave the state space un­ changed, we propose a hierarchical model (using an abstract MDP) that works with macro-actions only, and that significantly reduces the size of the state space. This is achieved by treating macro­ actions as local policies that act in certain regions of state space, and by restricting states in the ab­ stract MDP to those at the boundaries of regions. The abstract MDP approximates the original and can be solved more efficiently. We discuss sev­ eral ways in which macro-actions can be gen­ erated to ensure good solution quality. Finally, we consider ways in which macro-actions can be reused to solve multiple, related MDPs; and we show that this can justify the computational over­ head of macro-action generation.",
            "output": [
                "Hierarchical Solution of Markov Decision Processes using Macro-actions"
            ]
        },
        {
            "id": "task1540-1aa34cff49fa4908bbf2d2dab9267c16",
            "input": "Many real-world applications require robust algorithms to learn point processes based on a type of incomplete data — the so-called short doublycensored (SDC) event sequences. We study this critical problem of quantitative asynchronous event sequence analysis under the framework of Hawkes processes by leveraging the idea of data synthesis. Given SDC event sequences observed in a variety of time intervals, we propose a sampling-stitching data synthesis method — sampling predecessors and successors for each SDC event sequence from potential candidates and stitching them together to synthesize long training sequences. The rationality and the feasibility of our method are discussed in terms of arguments based on likelihood. Experiments on both synthetic and real-world data demonstrate that the proposed data synthesis method improves learning results indeed for both timeinvariant and time-varying Hawkes processes.",
            "output": [
                "Learning Hawkes Processes from Short Doubly-Censored Event Sequences"
            ]
        },
        {
            "id": "task1540-5832db8e13f94799b4ba558ec85e95e5",
            "input": "Recent work has proposed several generative neural models for constituency parsing that achieve state-of-the-art results. Since direct search in these generative models is difficult, they have primarily been used to rescore candidate outputs from base parsers in which decoding is more straightforward. We first present an algorithm for direct search in these generative models. We then demonstrate that the rescoring results are at least partly due to implicit model combination rather than reranking effects. Finally, we show that explicit model combination can improve performance even further, resulting in new state-of-the-art numbers on the PTB of 94.25 F1 when training only on gold data and 94.66 F1 when using external data.",
            "output": [
                "Improving Neural Parsing by Disentangling Model Combination and Reranking Effects"
            ]
        },
        {
            "id": "task1540-db639f97c7d14ce5b117c98235a2be03",
            "input": "Parkinson’s disease (PD) is one of the major public health problems in the world. It is a well-known fact that around one million people suffer from Parkinson’s disease in the United States whereas the number of people suffering from Parkinson’s disease worldwide is around 5 millions. Thus, it is important to predict Parkinson’s disease in early stages so that early plan for the necessary treatment can be made. People are mostly familiar with the motor symptoms of Parkinson’s disease, however an increasing amount of research is being done to predict the Parkinson’s disease from non-motor symptoms that precede the motor ones. If early and reliable prediction is possible then a patient can get a proper treatment at the right time. Nonmotor symptoms considered are Rapid Eye Movement (REM) sleep Behaviour Disorder (RBD) and olfactory loss. Developing machine learning models that can help us in predicting the disease can play a vital role in early prediction. In this paper we extend a work which used the non-motor features such as RBD and olfactory loss. Along with this the extended work also uses important biomarkers. In this paper we try to model this classifier using different machine learning models that have not been used before. We developed automated diagnostic models using Multilayer Perceptron, BayesNet, Random Forest and Boosted Logistic Regression. It has been observed that Boosted Logistic Regression provides the best performance with an impressive accuracy of 97.159 % and the area under the ROC curve was 98.9%. Thus, it is concluded that this models can be used for early prediction of Parkinson’s disease. Keywords—Improved Accuracy, Prediction of Parkinson’s Disease, Non Motor Features, Biomarkers, Machine Learning Techniques, Boosted Logistic Regression, BayesNet, Multilayer Perceptron,",
            "output": [
                "An Improved Approach for Prediction of Parkinson’s Disease using Machine Learning Techniques"
            ]
        },
        {
            "id": "task1540-ac10e645ad684298af2b1c8fa19a6ba6",
            "input": "Program authorship attribution has implications for the privacy of programmers who wish to contribute code anonymously. While previous work has shown that complete files that are individually authored can be attributed, we show here for the first time that accounts belonging to open source contributors containing short, incomplete, and typically uncompilable fragments can also be effectively attributed. We propose a technique for authorship attribution of contributor accounts containing small source code samples, such as those that can be obtained from version control systems or other direct comparison of sequential versions. We show that while application of previous methods to individual small source code samples yields an accuracy of about 73% for 106 programmers as a baseline, by ensembling and averaging the classification probabilities of a sufficiently large set of samples belonging to the same author we achieve 99% accuracy for assigning the set of samples to the correct author. Through these results, we demonstrate that attribution is an important threat to privacy for programmers even in real-world collaborative environments such as GitHub. Additionally, we propose the use of calibration curves to identify samples by unknown and previously unencountered authors in the open world setting. We show that we can also use these calibration curves in the case that we do not have linking information and thus are forced to classify individual samples directly. This is because the calibration curves allow us to identify which samples are more likely to have been correctly attributed. Using such a curve can help an analyst choose a cut-off point which will prevent most misclassifications, at the cost of causing the rejection of some of the more dubious correct attributions.",
            "output": [
                "Git Blame Who?: Stylistic Authorship Attribution of Small, Incomplete Source Code Fragments"
            ]
        },
        {
            "id": "task1540-ce02e08394684c038e9e5505e42d7c58",
            "input": "Software design is crucial to successful software development, yet is a demanding multi-objective problem for software engineers. In an attempt to assist the software designer, interactive (i.e. human in-the-loop) meta-heuristic search techniques such as evolutionary computing have been applied and show promising results. Recent investigations have also shown that Ant Colony Optimization (ACO) can outperform evolutionary computing as a potential search engine for interactive software design. With a limited computational budget, ACO produces superior candidate design solutions in a smaller number of iterations. Building on these findings, we propose a novel interactive ACO (iACO) approach to assist the designer in early lifecycle software design, in which the search is steered jointly by subjective designer evaluation as well as machine fitness functions relating the structural integrity and surrogate elegance of software designs. Results show that iACO is speedy, responsive and highly effective in enabling interactive, dynamic multi-objective search in early lifecycle software design. Study participants rate the iACO search experience as compelling. Results of machine learning of fitness measure weightings indicate that software design elegance does indeed play a significant role in designer evaluation of candidate software design. We conclude that the evenness of the number of attributes and methods among classes (NAC) is a significant surrogate elegance measure, which in turn suggests that this evenness of distribution, when combined with structural integrity, is an implicit but crucial component of effective early lifecycle software design.",
            "output": [
                "Interactive Ant Colony Optimization (iACO) for Early Lifecycle Software Design"
            ]
        },
        {
            "id": "task1540-feb14178636c4a138dc8e3df349d806b",
            "input": "An evaluation of distributed word representation is generally conducted using a word similarity task and/or a word analogy task. There are many datasets readily available for these tasks in English. However, evaluating distributed representation in languages that do not have such resources (e.g., Japanese) is difficult. Therefore, as a first step toward evaluating distributed representations in Japanese, we constructed a Japanese word similarity dataset. To the best of our knowledge, our dataset is the first resource that can be used to evaluate distributed representations in Japanese. Moreover, our dataset contains various parts of speech and includes rare words in addition to common words.",
            "output": [
                "Construction of a Japanese Word Similarity Dataset"
            ]
        },
        {
            "id": "task1540-4f5b114cabd643ce806d9a8a80eb768a",
            "input": "When you need to enable deep learning on low-cost embedded SoCs, is it better to port an existing deep learning framework or should you build one from scratch? In this paper, we share our practical experiences of building an embedded inference engine using ARM Compute Library (ACL). The results show that, contradictory to conventional wisdoms, for simple models, it takes much less development time to build an inference engine from scratch compared to porting existing frameworks. In addition, by utilizing ACL, we managed to build an inference engine that outperforms TensorFlow by 25%. Our conclusion is that, on embedded devices, we most likely will use very simple deep learning models for inference, and with well-developed building blocks such as ACL, it may be better in both performance and development time to build the engine from scratch.",
            "output": [
                "Enabling Embedded Inference Engine with ARM Compute Library"
            ]
        },
        {
            "id": "task1540-331665ed7bf54e829f9fbab78b4d0876",
            "input": "We introduce a globally normalized transition-based neural network model that achieves state-of-the-art part-ofspeech tagging, dependency parsing and sentence compression results. Our model is a simple feed-forward neural network that operates on a task-specific transition system, yet achieves comparable or better accuracies than recurrent models. The key insight is based on a novel proof illustrating the label bias problem and showing that globally normalized models can be strictly more expressive than locally normalized models.",
            "output": [
                "Globally Normalized Transition-Based Neural Networks"
            ]
        },
        {
            "id": "task1540-3ca0b32d199c4910907512abb7a06762",
            "input": "The large scale of Q&A archives accumulated in community based question answering (CQA) servivces are important information and knowledge resource on the web. Question and answer matching task has been attached much importance to for its ability to reuse knowledge stored in these systems: it can be useful in enhancing user experience with recurrent questions. In this paper, a Word Embedding based Correlation (WEC) model is proposed by integrating advantages of both the translation model and word embedding. Given a random pair of words, WEC can score their co-occurrence probability in Q&A pairs, while it can also leverage the continuity and smoothness of continuous space word representation to deal with new pairs of words that are rare in the training parallel text. An experimental study on Yahoo! Answers dataset and Baidu Zhidao dataset shows this new method’s promising",
            "output": [
                "Word Embedding Based Correlation Model for Question/Answer Matching"
            ]
        },
        {
            "id": "task1540-6e79e43701bb4dea86151fdff95d305c",
            "input": "We describe a general framework for online adaptation of optimization hyperparameters by ‘hot swapping’ their values during learning. We investigate this approach in the context of adaptive learning rate selection using an explore-exploit strategy from the multi-armed bandit literature. Experiments on a benchmark neural network show that the hot swapping approach leads to consistently better solutions compared to well-known alternatives such as AdaDelta and stochastic gradient with exhaustive hyperparameter search.",
            "output": [
                "OPTIMIZATION HYPERPARAMETERS"
            ]
        },
        {
            "id": "task1540-fd3b0ae144e84d06bae97a1621cc080f",
            "input": "So-called combined approaches answer a conjunctive query over a description logic ontology in three steps: first, they materialise certain consequences of the ontology and the data; second, they evaluate the query over the data; and third, they filter the result of the second phase to eliminate unsound answers. Such approaches were developed for various members of the DL-Lite and the EL families of languages, but none of them can handle ontologies containing nominals. In our work, we bridge this gap and present a combined query answering approach for ELHO ⊥—a logic that contains all features of the OWL 2 EL standard apart from transitive roles and complex role inclusions. This extension is nontrivial because nominals require equality reasoning, which introduces complexity into the first and the third step. Our empirical evaluation suggests that our technique is suitable for practical application, and so it provides a practical basis for conjunctive query answering in a large fragment of OWL 2 EL.",
            "output": [
                "Introducing Nominals to the Combined Query Answering Approaches for EL"
            ]
        },
        {
            "id": "task1540-c4a726047b6c40038399ca2623167ddf",
            "input": "Despite the prevalence of collaborative filtering in recommendation systems, there has been little theoretical development on why and how well it works, especially in the “online” setting, where items are recommended to users over time. We address this theoretical gap by introducing a model for online recommendation systems, cast item recommendation under the model as a learning problem, and analyze the performance of a cosine-similarity collaborative filtering method. In our model, each of n users either likes or dislikes each of m items. We assume there to be k types of users, and all the users of a given type share a common string of probabilities determining the chance of liking each item. At each time step, we recommend an item to each user, where a key distinction from related bandit literature is that once a user consumes an item (e.g., watches a movie), then that item cannot be recommended to the same user again. The goal is to maximize the number of likable items recommended to users over time. Our main result establishes that after nearly log(km) initial learning time steps, a simple collaborative filtering algorithm achieves essentially optimal performance without knowing k. The algorithm has an exploitation step that uses cosine similarity and two types of exploration steps, one to explore the space of items (standard in the literature) and the other to explore similarity between users (novel to this work).",
            "output": [
                "A Latent Source Model for Online Collaborative Filtering"
            ]
        },
        {
            "id": "task1540-45a95bd033174b5b93b23742f4c80e63",
            "input": "The speech feature extraction has been a key focus in robust speech recognition research; it significantly affects the recognition performance. In this paper, we first study a set of different features extraction methods such as linear predictive coding (LPC), mel frequency cepstral coefficient (MFCC) and perceptual linear prediction (PLP) with several features normalization techniques like rasta filtering and cepstral mean subtraction (CMS). Based on this, a comparative evaluation of these features is performed on the task of text independent speaker identification using a combination between gaussian mixture models (GMM) and linear and non-linear kernels based on support vector machine (SVM).",
            "output": [
                "On the Use of Different Feature Extraction Methods for Linear and Non Linear kernels"
            ]
        },
        {
            "id": "task1540-3cf3b6ff1e824caea849084a71f83a35",
            "input": "The paper analyzes dynamic epistemic logic from a topological perspective. The main contribution consists of a framework in which dynamic epistemic logic satisfies the requirements for being a topological dynamical system thus interfacing discrete dynamic logics with continuous mappings of dynamical systems. The setting is based on a notion of logical convergence, demonstratively equivalent with convergence in Stone topology. Presented is a flexible, parametrized family of metrics inducing the latter, used as an analytical aid. We show maps induced by action model transformations continuous with respect to the Stone topology and present results on the recurrent behavior of said maps.",
            "output": [
                "Convergence, Continuity and Recurrence in Dynamic Epistemic Logic"
            ]
        },
        {
            "id": "task1540-393c88577c3c46598f1045bc5d784b5b",
            "input": "Cross-document coreference, the problem of resolving entity mentions across multi-document collections, is crucial to automated knowledge base construction and data mining tasks. However, the scarcity of large labeled data sets has hindered supervised machine learning research for this task. In this paper we develop and demonstrate an approach based on “distantly-labeling” a data set from which we can train a discriminative cross-document coreference model. In particular we build a dataset of more than a million people mentions extracted from 3.5 years of New York Times articles, leverage Wikipedia for distant labeling with a generative model (and measure the reliability of such labeling); then we train and evaluate a conditional random field coreference model that has factors on cross-document entities as well as mention-pairs. This coreference model obtains high accuracy in resolving mentions and entities that are not present in the training data, indicating applicability to non-Wikipedia data. Given the large amount of data, our work is also an exercise demonstrating the scalability of our approach.",
            "output": [
                "Distantly Labeling Data for Large Scale Cross-Document Coreference"
            ]
        },
        {
            "id": "task1540-9143184e439647edb267c1baac771c15",
            "input": "We explore the use of segments learnt using Byte Pair Encoding (referred to as BPE units) as basic units for statistical machine translation between related languages and compare it with orthographic syllables, which are currently the best performing basic units for this translation task. BPE identifies the most frequent character sequences as basic units, while orthographic syllables are linguistically motivated pseudo-syllables. We show that BPE units outperform orthographic syllables as units of translation, showing up to 11% increase in BLEU scores. In addition, BPE can be applied to any writing system, while orthographic syllables can be used only for languages whose writing systems use vowel representations. We show that BPE units outperform word and morpheme level units for translation involving languages like Urdu, Japanese whose writing systems do not use vowels (either completely or partially). Across many language pairs, spanning multiple language families and types of writing systems, we show that translation with BPE segments outperforms orthographic syllables, especially for morphologically rich languages.",
            "output": [
                "Learning variable length units for SMT between related languages via Byte Pair Encoding"
            ]
        },
        {
            "id": "task1540-324df8a3f8da4f869d0b800919d511cc",
            "input": "One of the main challenges in Grid systems is designing an adaptive, scalable, and model-independent method for job scheduling to achieve a desirable degree of load balancing and system efficiency. Centralized job scheduling methods have some drawbacks, such as single point of failure and lack of scalability. Moreover, decentralized methods require a coordination mechanism with limited communications. In this paper, we propose a multi-agent approach to job scheduling in Grid, named Centralized Learning Distributed Scheduling (CLDS), by utilizing the reinforcement learning framework. The CLDS is a model free approach that uses the information of jobs and their completion time to estimate the efficiency of resources. In this method, there are a learner agent and several scheduler agents that perform the task of learning and job scheduling with the use of a coordination strategy that maintains the communication cost at a limited level. We evaluated the efficiency of the CLDS method by designing and performing a set of experiments on a simulated Grid system under different system scales and loads. The results show that the CLDS can effectively balance the load of system even in large scale and heavy loaded Grids, while maintains its adaptive performance and scalability.",
            "output": [
                "A centralized reinforcement learning method for multi-agent job scheduling in Grid"
            ]
        },
        {
            "id": "task1540-3114dcccaa3646fcb79535600ced2486",
            "input": "A fundamental challenge in developing semantic parsers is the paucity of strong supervision in the form of language utterances annotated with logical form. In this paper, we propose to exploit structural regularities in language in different domains, and train semantic parsers over multiple knowledge-bases (KBs), while sharing information across datasets. We find that we can substantially improve parsing accuracy by training a single sequence-tosequence model over multiple KBs, when providing an encoding of the domain at decoding time. Our model achieves state-ofthe-art performance on the OVERNIGHT dataset (containing eight domains), improves performance over a single KB baseline from 75.6% to 79.6%, while obtaining a 7x reduction in the number of model parameters.",
            "output": [
                "Neural Semantic Parsing over Multiple Knowledge-bases"
            ]
        },
        {
            "id": "task1540-fcff62c80b2f49e494bb4dcd06283236",
            "input": "This paper concerns the probabilistic evalu­ ation of the effects of actions in the presence of unmeasured variables. We show that the identification of causal effect between a sin­ gleton variable X and a set of variables Y can be accomplished systematically, in time polynomial in the number of variables in the graph. When the causal effect is identifiable, a closed-form expression can be obtained for the probability that the action will achieve a specified goal, or a set of goals.",
            "output": [
                "Testing Identifiability of Causal Effects"
            ]
        },
        {
            "id": "task1540-fbe8e9ff297c4d3c81d1ba1befe03aeb",
            "input": "Reactive (memoryless) policies are sufficient in completely observable Markov decision pro­ cesses (MDPs), but some kind of memory is usually necessary for optimal control of a par­ tially observable MDP. Policies with finite mem­ ory can be represented as finite-state automata. In this paper, we extend Baird and Moore's YAPS algorithm to the problem of learning gen­ eral finite-state automata. Because it performs stochastic gradient descent, this algorithm can be shown to converge to a locally optimal finite­ state controller. We provide the details of the algorithm and then consider the question of un­ der what conditions stochastic gradient descent will outperform exact gradient descent. We con­ clude with empirical results comparing the per­ formance of stochastic and exact gradient de­ scent, and showing the ability of our algorithm to extract the useful information contained in the sequence of past observations to compensate for the lack of observability at each time-step.",
            "output": [
                "Learning Finite-State Controllers for Partially Observable Environments"
            ]
        },
        {
            "id": "task1540-9cc313135c4343779eb3181b90258d3a",
            "input": "The objective of machine learning is to extract useful information from data, while privacy is preserved by concealing information. Thus it seems hard to reconcile these competing interests. However, they frequently must be balanced when mining sensitive data. For example, medical research represents an important application where it is necessary both to extract useful information and protect patient privacy. One way to resolve the conflict is to extract general characteristics of whole populations without disclosing the private information of individuals. In this paper, we consider differential privacy, one of the most popular and powerful definitions of privacy. We explore the interplay between machine learning and differential privacy, namely privacy-preserving machine learning algorithms and learning-based data release mechanisms. We also describe some theoretical results that address what can be learned differentially privately and upper bounds of loss functions for differentially",
            "output": [
                "Differential Privacy and Machine Learning: a Survey and Review"
            ]
        },
        {
            "id": "task1540-b66d049484834f4f98a166a8ad860e20",
            "input": "There are two main approaches to the distributed representation of words: lowdimensional deep learning embeddings and high-dimensional distributional models, in which each dimension corresponds to a context word. In this paper, we combine these two approaches by learning embeddings based on distributionalmodel vectors – as opposed to one-hot vectors as is standardly done in deep learning. We show that the combined approach has better performance on a word relatedness judgment task.",
            "output": [
                "Distributional Models and Deep Learning Embeddings: Combining the Best of Both Worlds"
            ]
        },
        {
            "id": "task1540-677ef07a21a54ff08f0a1a13b9b53c38",
            "input": "This paper studies single-image depth perception in the wild, i.e., recovering depth from a single image taken in unconstrained settings. We introduce a new dataset “Depth in the Wild” consisting of images in the wild annotated with relative depth between pairs of random points. We also propose a new algorithm that learns to estimate metric depth using annotations of relative depth. Compared to the state of the art, our algorithm is simpler and performs better. Experiments show that our algorithm, combined with existing RGB-D data and our new relative depth annotations, significantly improves single-image depth perception in the wild. Deep Network with Pixel-wise Prediction Metric Depth RGB-D Data Relative Depth Annotations",
            "output": [
                "Single-Image Depth Perception in the Wild"
            ]
        },
        {
            "id": "task1540-03e4a2096b71434d9f5e4a98b5d6f86f",
            "input": "Deep Neural Network architectures with external memory components allow the model to perform inference and capture long term dependencies, by storing information explicitly. In this paper, we generalize Key-Value Memory Networks to a multimodal setting, introducing a novel keyaddressing mechanism to deal with sequence-to-sequence models. The advantages of the framework are demonstrated on the task of video captioning, i.e generating natural language descriptions for videos. Conditioning on the previous time-step attention distributions for the key-value memory slots, we introduce a temporal structure in the memory addressing schema. The proposed model naturally decomposes the problem of video captioning into vision and language segments, dealing with them as key-value pairs. More specifically, we learn a semantic embedding (v) corresponding to each frame (k) in the video, thereby creating (k, v) memory slots. This allows us to exploit the temporal dependencies at multiple hierarchies (in the recurrent keyaddressing; and in the language decoder). Exploiting this flexibility of the framework, we additionally capture spatial dependencies while mapping from the visual to semantic embedding. Extensive experiments on the Youtube2Text dataset demonstrate usefulness of recurrent key-addressing, while achieving competitive scores on BLEU@4, METEOR metrics against state-of-the-art models.",
            "output": [
                "Recurrent Memory Addressing for describing videos"
            ]
        },
        {
            "id": "task1540-332eea059df84cba917a835087070c40",
            "input": "This paper presents a novel approach for enhancing the multiple sets of acoustic patterns automatically discovered from a given corpus. In a previous work it was proposed that different HMM configurations (number of states per model, number of distinct models) for the acoustic patterns form a two-dimensional space. Multiple sets of acoustic patterns automatically discovered with the HMM configurations properly located on different points over this two-dimensional space were shown to be complementary to one another, jointly capturing the characteristics of the given corpus. By representing the given corpus as sequences of acoustic patterns on different HMM sets, the pattern indices in these sequences can be relabeled considering the context consistency across the different sequences. Good improvements were observed in preliminary experiments of pattern spoken term detection (STD) performed on both TIMIT and Mandarin Broadcast News with such enhanced patterns.",
            "output": [
                "ENHANCING AUTOMATICALLY DISCOVERED MULTI-LEVEL ACOUSTIC PATTERNS CONSIDERING CONTEXT CONSISTENCY WITH APPLICATIONS IN SPOKEN TERM DETECTION"
            ]
        },
        {
            "id": "task1540-a1e9097d07e6490fba9c69ad3ced1dc6",
            "input": "In this paper, we consider the problem of predicting demographics of geographic units given geotagged Tweets that are composed within these units. Traditional survey methods that offer demographics estimates are usually limited in terms of geographic resolution, geographic boundaries, and time intervals. Thus, it would be highly useful to develop computational methods that can complement traditional survey methods by offering demographics estimates at finer geographic resolutions, with flexible geographic boundaries (i.e. not confined to administrative boundaries), and at different time intervals. While prior work has focused on predicting demographics and health statistics at relatively coarse geographic resolutions such as the county-level or state-level, we introduce an approach to predict demographics at finer geographic resolutions such as the blockgroup-level. For the task of predicting gender and race/ethnicity counts at the blockgrouplevel, an approach adapted from prior work to our problem achieves an average correlation of 0.389 (gender) and 0.569 (race) on a held-out test dataset. Our approach outperforms this prior approach with an average correlation of 0.671 (gender) and 0.692 (race).",
            "output": [
                "Predicting Demographics of High-Resolution Geographies with Geotagged Tweets"
            ]
        },
        {
            "id": "task1540-f1ddf0fb9d0949cc9216263c9c2cfa64",
            "input": "We propose a statistical model applicable to character level language modeling and show that it is a good fit for both, program source code and English text. The model is parameterized by a program from a domain-specific language (DSL) that allows expressing non-trivial data dependencies. Learning is done in two phases: (i) we synthesize a program from the DSL, essentially learning a good representation for the data, and (ii) we learn parameters from the training data – the process is done via counting, as in simple language models such as n-gram. Our experiments show that the precision of our model is comparable to that of neural networks while sharing a number of advantages with n-gram models such as fast query time and the capability to quickly add and remove training data samples. Further, the model is parameterized by a program that can be manually inspected, understood and updated, addressing a major problem of neural networks.",
            "output": [
                "PROGRAM SYNTHESIS FOR CHARACTER LEVEL LANGUAGE MODELING"
            ]
        },
        {
            "id": "task1540-adde2cc6c63945a79101600380050ac1",
            "input": "We seek decision rules for prediction-time cost reduction, where complete data is available for training, but during prediction-time, each feature can only be acquired for an additional cost. We propose a novel random forest algorithm to minimize prediction error for a user-specified average feature acquisition budget. While random forests yield strong generalization performance, they do not explicitly account for feature costs and furthermore require low correlation among trees, which amplifies costs. Our random forest grows trees with low acquisition cost and high strength based on greedy minimax cost-weighted-impurity splits. Theoretically, we establish near-optimal acquisition cost guarantees for our algorithm. Empirically, on a number of benchmark datasets we demonstrate superior accuracy-cost curves against state-of-the-art prediction-time algorithms.",
            "output": [
                "Feature-Budgeted Random Forest"
            ]
        },
        {
            "id": "task1540-44f3e11b850a4762a09681a4d7a84a6a",
            "input": "Subjective questions such as ‘does neymar dive’, or ‘is clinton lying’, or ‘is trump a fascist’, are popular queries to web search engines, as can be seen by autocompletion suggestions on Google, Yahoo and Bing. In the era of cognitive computing, beyond search, they could be handled as hypotheses issued for evaluation. Our vision is to leverage on unstructured data and metadata of the rich user-generated multimedia that is often shared as material evidence in favor or against hypotheses in social media platforms. In this paper we present two preliminary experiments along those lines and discuss challenges for a cognitive computing system that collects material evidence from user-generated multimedia towards aggregating it into some form of collective decision on the hypothesis. Keywords-Material evidence; User-generated multimedia; Social media hypothesis management; Cognitive computing. In: Proc. of the 1st Workshop on Multimedia Support for Decision-Making Processes, at IEEE Intl. Symposium on Multimedia (ISM’16), San Jose, CA, 2016.",
            "output": [
                "Show me the material evidence — Initial experiments on evaluating hypotheses from user-generated multimedia data"
            ]
        },
        {
            "id": "task1540-138ecd7cd85d41e19fa8d785126dd8ab",
            "input": "This paper describes our solution to the multi-modal learning challenge of ICML. This solution comprises constructing threelevel representations in three consecutive stages and choosing correct tag words with a data-specific strategy. Firstly, we use typical methods to obtain level-1 representations. Each image is represented using MPEG-7 and gist descriptors with additional features released by the contest organizers. And the corresponding word tags are represented by bag-of-words model with a dictionary of 4000 words. Secondly, we learn the level-2 representations using two stacked RBMs for each modality. Thirdly, we propose a bimodal auto-encoder to learn the similarities/dissimilarities between the pairwise image-tags as level-3 representations. Finally, during the test phase, based on one observation of the dataset, we come up with a data-specific strategy to choose the correct tag words leading to a leap of an improved overall performance. Our final average accuracy on the private test set is 100%, which ranks the first place in this challenge.",
            "output": [
                "Constructing Hierarchical Image-tags Bimodal Representations  for Word Tags Alternative Choice"
            ]
        },
        {
            "id": "task1540-5a7a0815f9c44f319e0a5900aa76316b",
            "input": "We present Exponentiated Gradient LINUCB, an algorithm for contextual multi-armed bandits. This algorithm uses Exponentiated Gradient to find the optimal exploration of the LINUCB. Within a deliberately designed offline simulation framework we conduct evaluations with real online event log data. The experimental results demonstrate that our algorithm outperforms surveyed algorithms.",
            "output": [
                "Exponentiated Gradient LINUCB for Contextual Multi- Armed Bandits"
            ]
        },
        {
            "id": "task1540-c9a0d8a9616d4d15b5affc2d0841824a",
            "input": "Organ transplants can improve the life expectancy and quality of life for the recipient but carries the risk of serious post-operative complications, such as septic shock and organ rejection. The probability of a successful transplant depends in a very subtle fashion on compatibility between the donor and the recipient – but current medical practice is short of domain knowledge regarding the complex nature of recipient-donor compatibility. Hence a data-driven approach for learning compatibility has the potential for significant improvements in match quality. This paper proposes a novel system (ConfidentMatch) that is trained using data from electronic health records. ConfidentMatch predicts the success of an organ transplant (in terms of the 3-year survival rates) on the basis of clinical and demographic traits of the donor and recipient. ConfidentMatch captures the heterogeneity of the donor and recipient traits by optimally dividing the feature space into clusters and constructing different optimal predictive models to each cluster. The system controls the complexity of the learned predictive model in a way that allows for assuring more granular and confident predictions for a larger number of potential recipient-donor pairs, thereby ensuring that predictions are “personalized” and tailored to individual characteristics to the finest possible granularity. Experiments conducted on the UNOS heart transplant dataset show the superiority of the prognostic value of ConfidentMatch to other competing benchmarks; ConfidentMatch can provide predictions of success with 95% confidence for 5,489 patients of a total population of 9,620 patients, which corresponds to 410 more patients than the most competitive benchmark algorithm (DeepBoost).",
            "output": [
                "Personalized Donor-Recipient Matching for Organ Transplantation"
            ]
        },
        {
            "id": "task1540-173244dff343471c940d214d53e04777",
            "input": "This paper investigates two feature-scoring criteria that make use of estimated class probabilities: one method proposed by Shen et al. (2008) and a complementary approach proposed below. We develop a theoretical framework to analyze each criterion and show that both estimate the spread (across all values of a given feature) of the probability that an example belongs to the positive class. Based on our analysis, we predict when each scoring technique will be advantageous over the other and give empirical results validating our predictions.",
            "output": [
                "Feature Selection via Probabilistic Outputs"
            ]
        },
        {
            "id": "task1540-9f3c08437edd4842a8b40117e357be23",
            "input": "Standard belief change assumes an underlying logic containing full classical propositional logic. However, there are good reasons for considering belief change in less expressive logics as well. In this paper we build on recent investigations by Delgrande on contraction for Horn logic. We show that the standard basic form of contraction, partial meet, is too strong in the Horn case. This result stands in contrast to Delgrande’s conjecture that orderly maxichoice is the appropriate form of contraction for Horn logic. We then define a more appropriate notion of basic contraction for the Horn case, influenced by the convexity property holding for full propositional logic and which we refer to as infra contraction. The main contribution of this work is a result which shows that the construction method for Horn contraction for belief sets based on our infra remainder sets corresponds exactly to Hansson’s classical kernel contraction for belief sets, when restricted to Horn logic. This result is obtained via a detour through contraction for belief bases. We prove that kernel contraction for belief bases produces precisely the same results as the belief base version of infra contraction. The use of belief bases to obtain this result provides evidence for the conjecture that Horn belief change is best viewed as a ‘hybrid’ version of belief set change and belief base change. One of the consequences of the link with base contraction is the provision of a representation result for Horn contraction for belief sets in which a version of the Core-retainment postulate features.",
            "output": [
                "On the Link between Partial Meet, Kernel, and Infra Contraction and its Application to Horn Logic"
            ]
        },
        {
            "id": "task1540-4a289445d79645e380a912a091b6cc65",
            "input": "We study sequential prediction of real-valued, arbitrary and unknown sequences under the squared error loss as well as the best parametric predictor out of a large, continuous class of predictors. Inspired by recent results from computational learning theory, we refrain from any statistical assumptions and define the performance with respect to the class of general parametric predictors. In particular, we present generic lower and upper bounds on this relative performance by transforming the prediction task into a parameter learning problem. We first introduce the lower bounds on this relative performance in the mixture of experts framework, where we show that for any sequential algorithm, there always exists a sequence for which the performance of the sequential algorithm is lower bounded by zero. We then introduce a sequential learning algorithm to predict such arbitrary and unknown sequences, and calculate upper bounds on its total squared prediction error for every bounded sequence. We further show that in some scenarios we achieve matching lower and upper bounds demonstrating that our algorithms are optimal in a strong minimax sense such that their performances cannot be improved further. As an interesting result we also prove that for the worst case scenario, the performance of randomized algorithms can be achieved by sequential algorithms so that randomized algorithms does not improve the performance.",
            "output": [
                "A Unified Approach to Universal Prediction: Generalized Upper and Lower Bounds"
            ]
        },
        {
            "id": "task1540-079ef59de16749da80f17d00ce0755ac",
            "input": "In natural speech, the speaker does not pause between words, yet a human listener somehow perceives this continuous stream of phonemes as a series of distinct words. The detection of boundaries between spoken words is an instance of a general capability of the human neocortex to remember and to recognize recurring sequences. This paper describes a computer algorithm that is designed to solve the problem of locating word boundaries in blocks of English text from which the spaces have been removed. This problem avoids the complexities of processing speech but requires similar capabilities for detecting recurring sequences. The algorithm that is described in this paper relies entirely on statistical relationships between letters in the input stream to infer the locations of word boundaries. The source code for a C++ version of this algorithm is presented in an appendix.",
            "output": [
                "A Statistical Learning Algorithm for Word Segmentation"
            ]
        },
        {
            "id": "task1540-86d45b3cb2954e7b94a4851ad1a3bb41",
            "input": "We propose a soft attention based model for the task of action recognition in videos. We use multi-layered Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units which are deep both spatially and temporally. Our model learns to focus selectively on parts of the video frames and classifies videos after taking a few glimpses. The model essentially learns which parts in the frames are relevant for the task at hand and attaches higher importance to them. We evaluate the model on UCF-11 (YouTube Action), HMDB-51 and Hollywood2 datasets and analyze how the model focuses its attention depending on the scene and the action being performed.",
            "output": [
                "ACTION RECOGNITION USING VISUAL ATTENTION"
            ]
        },
        {
            "id": "task1540-58dc4e7de9f947eaafe6d69d1f798050",
            "input": "Recent applications of neural language models have led to an increased interest in the automatic generation of natural language. However impressive, the evaluation of neurally generated text has so far remained rather informal and anecdotal. Here, we present an attempt at the systematic assessment of one aspect of the quality of neurally generated text. We focus on a specific aspect of neural language generation: its ability to reproduce authorial writing styles. Using established models for authorship attribution, we empirically assess the stylistic qualities of neurally generated text. In comparison to conventional language models, neural models generate fuzzier text that is relatively harder to attribute correctly. Nevertheless, our results also suggest that neurally generated text offers more valuable perspectives for the augmentation of training data.",
            "output": [
                "Assessing the Stylistic Properties of Neurally Generated Text in Authorship Attribution"
            ]
        },
        {
            "id": "task1540-0d6c349d9b4940bbaf4861f739f9f5d9",
            "input": "It is well known that different solution strategies work well for different types of instances of hard combinatorial problems. As a consequence, most solvers for the propositional satisfiability problem (SAT) expose parameters that allow them to be customized to a particular family of instances. In the international SAT competition series, these parameters are ignored: solvers are run using a single default parameter setting (supplied by the authors) for all benchmark instances in a given track. While this competition format rewards solvers with robust default settings, it does not reflect the situation faced by a practitioner who only cares about performance on one particular application and can invest some time into tuning solver parameters for this application. The new Configurable SAT Solver Competition (CSSC) compares solvers in this latter setting, scoring each solver by the performance it achieved after a fully automated configuration step. This article describes the CSSC in more detail, and reports the results obtained in its two instantiations so far, CSSC 2013 and 2014.",
            "output": [
                "The Configurable SAT Solver Challenge (CSSC)"
            ]
        },
        {
            "id": "task1540-fe34e45d3c11488b80e822851f8b2255",
            "input": "Belief revision is an operation that aims at modifying old beliefs so that they become consistent with new ones. The issue of belief revision has been studied in various formalisms, in particular, in qualitative algebras (QAs) in which the result is a disjunction of belief bases that is not necessarily representable in a QA. This motivates the study of belief revision in formalisms extending QAs, namely, their propositional closures: in such a closure, the result of belief revision belongs to the formalism. Moreover, this makes it possible to define a contraction operator thanks to the Harper identity. Belief revision in the propositional closure of QAs is studied, an algorithm for a family of revision operators is designed, and an opensource implementation is made freely available on the web.",
            "output": [
                "Belief revision in the propositional closure of a qualitative algebra"
            ]
        },
        {
            "id": "task1540-abad74fe9d5949e19057fd48eca6745c",
            "input": "In search engines, online marketplaces and other human–computer interfaces large collectives of individuals sequentially interact with numerous alternatives of varying quality. In these contexts, individual trial and error (exploration) is crucial for uncovering novel high-quality items or solutions, but entails a high cost for individual agents [Frazier et al. 2014]. Self-interested decision makers, we will show, are often better off imitating the choices of individuals who have already incurred the costs of exploration. Although imitation makes sense at the individual level, it deprives the group of additional information that could have been gleaned by individual explorers [Rogers 1988]. Under these grim circumstances, certain non-monetary mechanisms can keep imitation forces in check and allow the collective to reap some of the benefits of the independent collection of information. For example, in simultaneous exploration problems, a natural equilibrium evolves between explorers and imitators [Conlisk 1980; Kameda and Nakanishi 2002]. Further, in some collective exploration settings, barriers to communication such as a sparser communication network among individuals can prove beneficial at the collective level. They encourage people to explore more, thus supplying useful information to the group [Fang et al. 2010; Lazer and Friedman 2007; Mason et al. 2008; Toyokawa et al. 2014]. Diversity is known to be a blessing for groups and collectives, as they can leverage the wealth of information possessed by different individuals [Conradt et al. 2013; Davis-Stober et al. 2014; MüllerTrede et al. 2017] or take advantage of the complementarities between group members to solve complex problems [Clearwater et al. 1991; Hong and Page 2004]. Could some preference diversity be beneficial in problems where collectives sequentially explore numerous alternatives, and thus despite reducing the immediate value of social learning lead to an increase in collective welfare?",
            "output": [
                "Diversity of preferences can increase collective welfare in sequential exploration problems"
            ]
        },
        {
            "id": "task1540-a6a57f98ae3e41899af98da64eeb026f",
            "input": "This paper presents capabilities of using genetic algorithms to find approximations of function extrema, which cannot be found using analytic ways. To enhance effectiveness of calculations, algorithm has been parallelized using OpenMP library. We gained much increase in speed on platforms using multithreaded processors with shared memory free access. During analysis we used different modifications of genetic operator, using them we obtained varied evolution process of potential solutions. Results allow to choose best methods among many applied in genetic algorithms and observation of acceleration on Yorkfield, Bloomfield, Westmere-EX and most recent Sandy Bridge cores.",
            "output": [
                "GENERATING EXTREMA APPROXIMATION OF ANALYTICALLY INCOMPUTABLE FUNCTIONS THROUGH USAGE OF PARALLEL COMPUTER AIDED GENETIC ALGORITHMS"
            ]
        },
        {
            "id": "task1540-d5ea925d494740f894dea02142b0df9c",
            "input": "The genetic selection of keywords set, the text frequencies of which are considered as attributes in text classification analysis, has been analyzed. The genetic optimization was performed on a set of words, which is the fraction of the frequency dictionary with given frequency limits. The frequency dictionary was formed on the basis of analyzed text array of texts of English fiction. As the fitness function which is minimized by the genetic algorithm, the error of nearest k neighbors classifier was used. The obtained results show high precision and recall of texts classification by authorship categories on the basis of attributes of keywords set which were selected by the genetic algorithm from the frequency dictionary.",
            "output": [
                "Genetic Optimization of Keywords Subset in the Classification Analysis of Texts Authorship"
            ]
        },
        {
            "id": "task1540-735622b2f1384fa0b9a2b10b8f2342b5",
            "input": "An important use of machine learning is to learn what people value. What posts or photos should a user be shown? Which jobs or activities would a person find rewarding? In each case, observations of people’s past choices can inform our inferences about their likes and preferences. If we assume that choices are approximately optimal according to some utility function, we can treat preference inference as Bayesian inverse planning. That is, given a prior on utility functions and some observed choices, we invert an optimal decision-making process to infer a posterior distribution on utility functions. However, people often deviate from approximate optimality. They have false beliefs, their planning is sub-optimal, and their choices may be temporally inconsistent due to hyperbolic discounting and other biases. We demonstrate how to incorporate these deviations into algorithms for preference inference by constructing generative models of planning for agents who are subject to false beliefs and time inconsistency. We explore the inferences these models make about preferences, beliefs, and biases. We present a behavioral experiment in which human subjects perform preference inference given the same observations of choices as our model. Results show that human subjects (like our model) explain choices in terms of systematic deviations from optimal behavior and suggest that they take such deviations into account when inferring preferences.",
            "output": [
                "Learning the Preferences of Ignorant, Inconsistent Agents"
            ]
        },
        {
            "id": "task1540-9940fe62ddbb462dab9f35a680c5135a",
            "input": "Probabilistic independence can dramatically sim­ plify the task of eliciting, representing, and com­ puting with probabilities in large domains. A key technique in achieving these benefits is the idea of graphical modeling. We survey existing no­ tions of independence for utility functions in a multi-attribute space, and suggest that these can be used to achieve similar advantages. Our new results concern conditional additive in­ dependence, which we show always has a per­ fect representation as separation in an undirected graph (a Markov network). Conditional addi­ tive independencies entail a particular functional form for the utility function that is analogous to a product decomposition of a probability function, and confers analogous benefits. This functional form has been utilized in the Bayesian network and influence diagram literature, but generally without an explanation in terms of independence. The functional form yields a decomposition of the utility function that can greatly speed up expected utility calculations, particularly when the utility graph has a similar topology to the probabilistic network being used.",
            "output": [
                "Graphical models for preference and utility"
            ]
        },
        {
            "id": "task1540-eed93479b11942fcab3a7d5105e505c7",
            "input": "This paper considers the problem of knowledge­ based model construction in the presence of uncertainty about the association of domain entities to random variables. Multi-entity Bayesian networks (MEBNs) are defined as a representation for knowledge in domains characterized by uncertainty in the number of relevant entities, their interrelationships, and their association with observables. An MEBN implicitly specifies a probability distribution in terms of a hierarchically structured collection of Bayesian network fragments that together encode a joint probability distribution over arbitrarily many interrelated hypotheses. Although a finite query-complete model can always be constructed, association uncertainty typically makes exact model construction and evaluation intractable. The objective of hypothesis management is to balance tractability against accuracy. We describe an approach to hypothesis management, present an application to the problem of military situation awareness, and compare our approach to related work in the tracking and fusion literature.",
            "output": [
                "Hypothesis Management in Situation-Specific Network Construction"
            ]
        },
        {
            "id": "task1540-106d77a62a6348389d320bf42d28379e",
            "input": "This paper presents an ontology-based approach for the design of a collaborative business process model (CBP). This CBP is considered as a specification of needs in order to build a collaboration information system (CIS) for a network of organisations. The study is a part of a model driven engineering approach of the CIS in a specific enterprise interoperability framework that will be summarised. An adaptation of the Business Process Modeling Notation (BPMN) is used to represent the CBP model. We develop a knowledge-based system (KbS) which is composed of three main parts: knowledge gathering, knowledge representation and reasoning, and collaborative business process modelling. The first part starts from a high abstraction level where knowledge from business partners is captured. A collaboration ontology is defined in order to provide a structure to store and use the knowledge captured. In parallel, we try to reuse generic existing knowledge about business processes from the MIT Process Handbook repository. This results in a collaboration process ontology that is also described. A set of rules is defined in order to extract knowledge about fragments of the CBP model from the two previous ontologies. These fragments are finally assembled in the third part of the KbS. A prototype of the KbS has been developed in order to implement and support this approach. The prototype is a computer-aided design tool of the CBP. In this paper, we will present the theoretical aspects of each part of this KbS as well as the tools that we developed and used in order to support its functionalities.",
            "output": [
                "Knowledge-based system for collaborative process specification"
            ]
        },
        {
            "id": "task1540-dedad2d8cb994e61ba33df269cd9af63",
            "input": "Dung’s abstract argumentation framework consists of a set of interacting arguments and a series of semantics for evaluating them. Those semantics partition the powerset of the set of arguments into two classes: extensions and nonextensions. In order to reason with a specific semantics, one needs to take a credulous or skeptical approach, i.e. an argument is eventually accepted, if it is accepted in one or all extensions, respectively. In our previous work [1], we have proposed a novel semantics, called counting semantics, which allows for a more fine-grained assessment to arguments by counting the number of their respective attackers and defenders based on argument graph and argument game. In this paper, we continue our previous work by presenting some supplementaries about how to choose the damaging factor for the counting semantics, and what relationships with some existing approaches, such as Dung’s classical semantics, generic gradual valuations. Lastly, an axiomatic perspective on the ranking semantics induced by our counting semantics are presented. Keywords—abstract argumentation; argument game; graded assessment; counting semantics; ranking-based semantics;",
            "output": [
                "Some Supplementaries to The Counting Semantics for Abstract Argumentation"
            ]
        },
        {
            "id": "task1540-3aa96c7df9684eea84e49358d6803a0e",
            "input": "In principle, reinforcement learning and policy search methods can enable robots to learn highly complex and general skills that may allow them to function amid the complexity and diversity of the real world. However, training a policy that generalizes well across a wide range of realworld conditions requires far greater quantity and diversity of experience than is practical to collect with a single robot. Fortunately, it is possible for multiple robots to share their experience with one another, and thereby, learn a policy collectively. In this work, we explore distributed and asynchronous policy learning as a means to achieve generalization and improved training times on challenging, real-world manipulation tasks. We propose a distributed and asynchronous version of Guided Policy Search and use it to demonstrate collective policy learning on a vision-based door opening task using four robots. We show that it achieves better generalization, utilization, and training times than the single robot alternative.",
            "output": [
                "Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search"
            ]
        },
        {
            "id": "task1540-affd8d316c014445b516abc6fc483ed8",
            "input": "Classification involves the learning of the mapping function that associates input samples to corresponding target label. There are two major categories of classification problems: Single-label classification and Multi-label classification. Traditional binary and multi-class classifications are subcategories of single-label classification. Several classifiers are developed for binary, multi-class and multi-label classification problems, but there are no classifiers available in the literature capable of performing all three types of classification. In this paper, a novel online universal classifier capable of performing all the three types of classification is proposed. Being a high speed online classifier, the proposed technique can be applied to streaming data applications. The performance of the developed classifier is evaluated using datasets from binary, multi-class and multi-label problems. The results obtained are compared with state-of-the-art techniques from each of the classification types. Keywords—Universal, Classification, Binary, Multi-class, Multi-label, Online, Extreme learning machines, Data stream.",
            "output": [
                "An Online Universal Classifier for Binary, Multi- class and Multi-label Classification"
            ]
        },
        {
            "id": "task1540-272a36d6f1034245a5c41666fd7592b5",
            "input": "We propose a novel fully-automated approach towards inducing multilingual taxonomies from Wikipedia. Given an English taxonomy, our approach first leverages the interlanguage links of Wikipedia to automatically construct training datasets for the is-a relation in the target language. Character-level classifiers are trained on the constructed datasets, and used in an optimal path discovery framework to induce high-precision, high-coverage taxonomies in other languages. Through experiments, we demonstrate that our approach significantly outperforms the state-of-the-art, heuristics-heavy approaches for six languages. As a consequence of our work, we release presumably the largest and the most accurate multilingual taxonomic resource spanning over 280 languages.",
            "output": [
                "280 Birds with One Stone: Inducing Multilingual Taxonomies from Wikipedia Using Character-level Classification"
            ]
        },
        {
            "id": "task1540-c8407ec657c64e6b846149173d0cea46",
            "input": "Present incremental learning methods are limited in the ability to achieve reliable credit assignment over a large number time steps (or events). However, this situation is typical for cases where the dynamical system to be controlled requires relatively frequent control updates in order to maintain stability or robustness yet has some action/consequences which must be established over relatively long periods of time. To address this problem, the learning capabilities of a control architecture comprised of two Backpropagated Adaptive Critics (BAC’s) in a two-level hierarchy with continuous actions are explored. The high-level BAC updates less frequently than the low-level BAC and controls the latter to some degree. The response of the low-level to high-level signals can either be determined a priori or it can emerge during learning. A general approach called Response Induction Learning is introduced to address the latter case.",
            "output": [
                "Reinforcement Control with Hierarchical Backpropagated Adaptive Critics∗"
            ]
        },
        {
            "id": "task1540-1e86420250e047849dcc3c8b4742e268",
            "input": "The main goal of this paper is to describe a new pruning method for solving decision trees and game trees. The pruning method for decision trees suggests a slight variant of decision trees that we call scenario trees. In scenario trees, we do not need a conditional probability for each edge emanating from a chance node. Instead, we require a joint probability for each path from the root node to a leaf node. We compare the pruning method to the traditional rollback method for decision trees and game trees. For problems that require Bayesian revision of probabilities, a scenario tree representation with the pruning method is more efficient than a decision tree representation with the rollback method. For game trees, the pruning method is more efficient than the rollback method.",
            "output": [
                "A New Pruning Method for Solving Decision Trees and Game Trees"
            ]
        },
        {
            "id": "task1540-2357b84c9e534caea841eb83bd6f6e2a",
            "input": "Theano is a linear algebra compiler that optimizes a user’s symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano’s performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks.",
            "output": [
                "Theano: new features and speed improvements"
            ]
        },
        {
            "id": "task1540-094fa39d61cf4ad0a6c26b4fee9a9a28",
            "input": "In this work, we build a generic architecture of Convolutional Neural Networks to discover empirical properties of neural networks. Our first contribution is to introduce a state-of-the-art framework that depends upon few hyper parameters and to study the network when we vary them. It has no max pooling, no biases, only 13 layers, is purely convolutional and yields up to 95.4% and 79.6% accuracy respectively on CIFAR10 and CIFAR100. We show that the nonlinearity of a deep network does not need to be continuous, non expansive or point-wise, to achieve good performance. We show that increasing the width of our network permits being competitive with very deep networks. Our second contribution is an analysis of the contraction and separation properties of this network. Indeed, a 1-nearest neighbor classifier applied on deep features progressively improves with depth, which indicates that the representation is progressively more regular. Besides, we defined and analyzed local support vectors that separate classes locally. All our experiments are reproducible and code is available online, based on TensorFlow.",
            "output": [
                "Building a Regular Decision Boundary with Deep Networks"
            ]
        },
        {
            "id": "task1540-f956da5f1ee04a47a2fe289a17ea641d",
            "input": "Knowledge representation is a popular research field in IT. As mathematical knowledge is most formalized, its representation is important and interesting. Mathematical knowledge consists of various mathematical theories. In this paper we consider a deductive system that derives mathematical notions, axioms and theorems. All these notions, axioms and theorems can be considered a small mathematical theory. This theory will be represented as a semantic net. We start with the signature <Set; > where Set is the support set, is the membership predicate. Using the MathSem program we build the signature <Set;  where is set intersection,  is set union, -is the Cartesian product of sets, and is the subset relation.",
            "output": [
                "Building the Signature of Set Theory Using the MathSem Program"
            ]
        },
        {
            "id": "task1540-8df1d98271264c0f9c10b329f750d361",
            "input": "Wikipedia is a useful knowledge source that benefits many applications in language processing and knowledge representation. An important feature of Wikipedia is that of categories. Wikipedia pages are assigned different categories according to their contents as human-annotated labels which can be used in information retrieval, ad hoc search improvements, entity ranking and tag recommendations. However, important pages are usually assigned too many categories, which makes it difficult to recognize the most important ones that give the best descriptions. In this paper, we propose an approach to recognize the most descriptive Wikipedia categories. We observe that historical figures in a precise category presumably are mutually similar and such categorical coherence could be evaluated via texts or Wikipedia links of corresponding members in the category. We rank descriptive level of Wikipedia categories according to their coherence and our ranking yield an overall agreement of 88.27% compared with human wisdom.",
            "output": [
                "Recognizing Descriptive Wikipedia Categories for Historical Figures"
            ]
        },
        {
            "id": "task1540-c6f8cc2e183446ccbc01015fb6fd4545",
            "input": "<lb>This paper addresses the problem of ad hoc microphone array calibration where only partial<lb>information about the distances between microphones is available. We construct a matrix<lb>consisting of the pairwise distances and propose to estimate the missing entries based on a novel<lb>Euclidean distance matrix completion algorithm by alternative low-rank matrix completion and<lb>projection onto the Euclidean distance space. This approach confines the recovered matrix to the<lb>EDM cone at each iteration of the matrix completion algorithm. The theoretical guarantees of<lb>the calibration performance are obtained considering the random and locally structured missing<lb>entries as well as the measurement noise on the known distances. This study elucidates the links<lb>between the calibration error and the number of microphones along with the noise level and the<lb>ratio of missing distances. Thorough experiments on real data recordings and simulated setups<lb>are conducted to demonstrate these theoretical insights. A significant improvement is achieved<lb>by the proposed Euclidean distance matrix completion algorithm over the state-of-the-art<lb>techniques for ad hoc microphone array calibration.",
            "output": [
                "Ad Hoc Microphone Array Calibration: Euclidean Distance Matrix Completion Algorithm and Theoretical Guarantees"
            ]
        },
        {
            "id": "task1540-e1a63f17d2474168bd4720a212397fe8",
            "input": "We introduce Discriminative BLEU (∆BLEU), a novel metric for intrinsic evaluation of generated text in tasks that admit a diverse range of possible outputs. Reference strings are scored for quality by human raters on a scale of [−1, +1] to weight multi-reference BLEU. In tasks involving generation of conversational responses, ∆BLEU correlates reasonably with human judgments and outperforms sentence-level and IBM BLEU in terms of both Spearman’s ρ and Kendall’s τ .",
            "output": [
                "∆BLEU: A Discriminative Metric for Generation Tasks with Intrinsically Diverse Targets∗"
            ]
        },
        {
            "id": "task1540-b81f06c60fa94326afb7c59edba36bc9",
            "input": "Recent works on end-to-end neural network-based architectures for machine translation have shown promising results for English-French and English-German translation. Unlike these language pairs, however, in the majority of scenarios, there is a lack of high quality parallel corpora. In this work, we focus on applying neural machine translation to challenging/low-resource languages Turkish and low-resource domains such as parallel corpora of Chinese chat messages. In particular, we investigated how to leverage abundant monolingual data for these low-resource translation tasks. Without the use of external alignment tools, we obtained up to a 1.96 BLEU score improvement with our proposed method compared to the previous best result in Turkish-to-English translation on the IWLST 2014 dataset. On Chinese-toEnglish translation by using the OpenMT 2015 dataset, we were able to obtain up to a 1.59 BLEU score improvement over phrase-based and hierarchical phrase-based baselines.",
            "output": [
                "On Using Monolingual Corpora in Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-438c1183deb74e049f12e0e5c9489889",
            "input": "Energy-based models are popular in machine learning due to the elegance of their formulation and their relationship to statistical physics. Among these, the Restricted Boltzmann Machine (RBM) has been the prototype for some recent advancements in the unsupervised training of deep neural networks. However, the contrastive divergence training algorithm, so often used for such models, has a number of drawbacks and ineligancies both in theory and in practice. Here, we investigate the performance of Minimum Probability Flow learning for training RBMs. This approach reconceptualizes the nature of the dynamics defined over a model, rather than thinking about Gibbs sampling, and derives a simple, tractable, and elegant objective function using a Taylor expansion, allowing one to learn the parameters of any distribution over visible states. In the paper, we expound the Minimum Probability Flow learning algorithm under various dynamics. We empirically analyze its performance on these dynamics and demonstrate that MPF algorithms outperform CD on various RBM configurations.",
            "output": [
                "UNDERSTANDING MINIMUM PROBABILITY FLOW FOR RBMS UNDER VARIOUS KINDS OF DYNAMICS"
            ]
        },
        {
            "id": "task1540-9e7cba2ac51b4e798c3f153f53f3a396",
            "input": "High precision assembly of mechanical parts requires accuracy exceeding the robot precision. Conventional part mating methods used in the current manufacturing requires tedious tuning of numerous parameters before deployment. We show how the robot can successfully perform a tight clearance peg-in-hole task through training a recurrent neural network with reinforcement learning. In addition to saving the manual effort, the proposed technique also shows robustness against position and angle errors for the peg-in-hole task. The neural network learns to take the optimal action by observing the robot sensors to estimate the system state. The advantages of our proposed method is validated experimentally on a 7-axis articulated robot arm.",
            "output": [
                "Deep Reinforcement Learning for High Precision Assembly Tasks"
            ]
        },
        {
            "id": "task1540-0533f0df126c4bf1815dfc19a95f4662",
            "input": "Artificial Neural Network (ANN) s has widely been used for recognition of optically scanned character, which partially emulates human thinking in the domain of the Artificial Intelligence. But prior to recognition, it is necessary to segment the character from the text to sentences, words etc. Segmentation of words into individual letters has been one of the major problems in handwriting recognition. Despite several successful works all over the work, development of such tools in specific languages is still an ongoing process especially in the Indian context. This work explores the application of ANN as an aid to segmentation of handwritten characters in Assamesean important language in the North Eastern part of India. The work explores the performance difference obtained in applying an ANN-based dynamic segmentation algorithm compared to projectionbased static segmentation. The algorithm involves, first training of an ANN with individual handwritten characters recorded from different individuals. Handwritten sentences are separated out from text using a static segmentation method. From the segmented line, individual characters are separated out by first over segmenting the entire line. Each of the segments thus obtained, next, is fed to the trained ANN. The point of segmentation at which the ANN recognizes a segment or a combination of several segments to be similar to a handwritten character, a segmentation boundary for the character is assumed to exist and segmentation performed. The segmented character is next compared to the best available match and the segmentation boundary confirmed.",
            "output": [
                "ANN-based Innovative Segmentation Method for Handwritten text in Assamese"
            ]
        },
        {
            "id": "task1540-8505e94d534f40e6a607584271666583",
            "input": "Distantly supervised relation extraction has been widely used to find novel relational facts from plain text. To predict the relation between a pair of two target entities, existing methods solely rely on those direct sentences containing both entities. In fact, there are also many sentences containing only one of the target entities, which provide rich and useful information for relation extraction. To address this issue, we build inference chains between two target entities via intermediate entities, and propose a path-based neural relation extraction model to encode the relational semantics from both direct sentences and inference chains. Experimental results on realworld datasets show that, our model can make full use of those sentences containing only one target entity, and achieves significant and consistent improvements on relation extraction as compared with baselines.",
            "output": [
                "Incorporating Relation Paths in Neural Relation Extraction"
            ]
        },
        {
            "id": "task1540-413b88af89ab44dfb6b23c357919d216",
            "input": "We study the design of interactive clustering algorithms for data sets satisfying natural stability assumptions. Our algorithms start with any initial clustering and only make local changes in each step; both are desirable features in many applications. We show that in this constrained setting one can still design provably efficient algorithms that produce accurate clusterings. We also show that our algorithms perform well on real-world data.",
            "output": [
                "Local algorithms for interactive clustering"
            ]
        },
        {
            "id": "task1540-b624aa33000148439c482fa4b3967c6e",
            "input": "Online sequence prediction is the problem of predicting the next element of a sequence given previous elements. This problem has been extensively studied in the context of individual sequence prediction, where no prior assumptions are made on the origin of the sequence. Individual sequence prediction algorithms work quite well for long sequences, where the algorithm has enough time to learn the temporal structure of the sequence. However, they might give poor predictions for short sequences. A possible remedy is to rely on the general model of prediction with expert advice, where the learner has access to a set of r experts, each of which makes its own predictions on the sequence. It is well known that it is possible to predict almost as well as the best expert if the sequence length is order of log(r). But, without firm prior knowledge on the problem, it is not clear how to choose a small set of good experts. In this paper we describe and analyze a new algorithm that learns a good set of experts using a training set of previously observed sequences. We demonstrate the merits of our approach by applying it on the task of click prediction on the web.",
            "output": [
                "Learning the Experts for Online Sequence Prediction"
            ]
        },
        {
            "id": "task1540-d6879b74ddaf4c29bf392690b143cc3b",
            "input": "The aim of this paper is to investigate the interplay between knowledge shared by a group of agents and its coalition ability. We characterize this relation in the standard context of imperfect information concurrent game. We assume that whenever a set of agents form a coalition to achieve a goal, they share their knowledge before acting. Based on this assumption, we propose new semantics for alternating-time temporal logic with imperfect information and perfect recall. It turns out that this semantics is sufficient to preserve all the desirable properties of coalition ability in traditional coalition logics. Meanwhile, we investigate how knowledge sharing within a group of agents contributes to its coalitional ability through the interplay of epistemic and coalition modalities. This work provides a partial answer to the question: which kind of group knowledge is required for a group to achieve their goals in the context of imperfect information.",
            "output": [
                "Knowledge Sharing in Coalitions"
            ]
        },
        {
            "id": "task1540-69a18977854e4cbbac5f28622517cd52",
            "input": "We develop a novel bi-directional attention model for dependency parsing, which learns to agree on headword predictions from the forward and backward parsing directions. The parsing procedure for each direction is formulated as sequentially querying the memory component that stores continuous headword embeddings. The proposed parser makes use of soft headword embeddings, allowing the model to implicitly capture high-order parsing history without dramatically increasing the computational complexity. We conduct experiments on English, Chinese, and 12 other languages from the CoNLL 2006 shared task, showing that the proposed model achieves state-of-the-art unlabeled attachment scores on 6 languages.1",
            "output": [
                "Bi-directional Attention with Agreement for Dependency Parsing"
            ]
        },
        {
            "id": "task1540-a879c357c4e04d2ebdc2b37e4b46c7ae",
            "input": "This paper covers a number of approaches that leverage Artificial Intelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle (UCAV) autonomy. An analysis of current approaches to autonomous control is provided followed by an exploration of how these techniques can be extended and enriched with AI techniques including Artificial Neural Networks (ANN), Ensembling and Reinforcement Learning (RL) to evolve control strategies for UCAVs.",
            "output": [
                "Artificial Intelligence Approaches To UCAV Autonomy"
            ]
        },
        {
            "id": "task1540-8770c24e3b8b4b63ad29ff37d0b30cd1",
            "input": "Recommendation system is a common demand in daily life and matrix completion is a widely adopted technique for this task. However, most matrix completion methods lack semantic interpretation and usually result in weak-semantic recommendations. To this end, this paper proposes a Semantic Analysis approach for Recommendation systems (SAR), which applies a two-level hierarchical generative process that assigns semantic properties and categories for user and item. SAR learns semantic representations of users/items merely from user ratings on items, which offers a new path to recommendation by semantic matching with the learned representations. Extensive experiments demonstrate SAR outperforms other state-of-the-art baselines substantially.",
            "output": [
                "SAR: A Semantic Analysis Approach for Recommendation"
            ]
        },
        {
            "id": "task1540-491c52031eac41da9ae2fa36219153ae",
            "input": "This paper investigates the mining of class association rules with rough set approach. In data mining, an association occurs between two set of elements when one element set happen together with another. A class association rule set (CARs) is a subset of association rules with classes specified as their consequences. We present an efficient algorithm for mining the finest class rule set inspired form Apriori algorithm, where the support and confidence are computed based on the elementary set of lower approximation included in the property of rough set theory. Our proposed approach has been shown very effective, where the rough set approach for class association discovery is much simpler than the classic association method. Data Mining, RST, CAR, ARM, NAR, Bitmap, class association rules, Rough Set Theory",
            "output": [
                "Class Association Rules Mining based Rough Set Method"
            ]
        },
        {
            "id": "task1540-144c4db3bff6473cbed47514f1728c32",
            "input": "Label propagation is a powerful and flexible semi-supervised learning technique on graphs. Neural network architectures, on the other hand, have proven track records in many supervised learning tasks. In this work, we propose a training objective for neural networks, Neural Graph Machines, for combining the power of neural networks and label propagation. The new objective allows the neural networks to harness both labeled and unlabeled data by: (a) allowing the network to train using labeled data as in the supervised setting, (b) biasing the network to learn similar hidden representations for neighboring nodes on a graph, in the same vein as label propagation. Such architectures with the proposed objective can be trained efficiently using stochastic gradient descent and scaled to large graphs. The proposed method is experimentally validated on a wide range of tasks (multilabel classification on social graphs, news categorization and semantic intent classification) using different architectures (NNs, CNNs, and LSTM RNNs).",
            "output": [
                "NEURAL GRAPH MACHINES: LEARNING NEURAL NETWORKS USING GRAPHS"
            ]
        },
        {
            "id": "task1540-94788841ecce409dbd8ceeb740e7b455",
            "input": "Variational Autoencoders (VAEs) are expressive latent variable models that can be used to learn complex probability distributions from training data. However, the quality of the resulting model crucially relies on the expressiveness of the inference model used during training. We introduce Adversarial Variational Bayes (AVB), a technique for training Variational Autoencoders with arbitrarily expressive inference models. We achieve this by introducing an auxiliary discriminative network that allows to rephrase the maximum-likelihood-problem as a two-player game, hence establishing a principled connection between VAEs and Generative Adversarial Networks (GANs). We show that in the nonparametric limit our method yields an exact maximumlikelihood assignment for the parameters of the generative model, as well as the exact posterior distribution over the latent variables given an observation. Contrary to competing approaches which combine VAEs with GANs, our approach has a clear theoretical justification, retains most advantages of standard Variational Autoencoders and is easy to implement.",
            "output": [
                "Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks"
            ]
        },
        {
            "id": "task1540-efd04e09199e4d08b48ef7f682b50775",
            "input": "The comparison of heterogeneous samples extensively exists in many applications, especially in the task of image classification. In this paper, we propose a simple but effective coupled neural network, called Deeply Coupled Autoencoder Networks (DCAN), which seeks to build two deep neural networks, coupled with each other in every corresponding layers. In DCAN, each deep structure is developed via stacking multiple discriminative coupled auto-encoders, a denoising auto-encoder trained with maximum margin criterion consisting of intra-class compactness and inter-class penalty. This single layer component makes our model simultaneously preserve the local consistency and enhance its discriminative capability. With increasing number of layers, the coupled networks can gradually narrow the gap between the two views. Extensive experiments on cross-view image classification tasks demonstrate the superiority of our method over state-of-the-art methods.",
            "output": [
                "Deeply Coupled Auto-encoder Networks for Cross-view Classification"
            ]
        },
        {
            "id": "task1540-40c860633eb04f199bd3054f021e8a30",
            "input": "Based on a new atomic norm, we propose a new convex formulation for sparse matrix factorization problems in which the number of nonzero elements of the factors is assumed fixed and known. The formulation counts sparse PCA with multiple factors, subspace clustering and low-rank sparse bilinear regression as potential applications. We compute slow rates and an upper bound on the statistical dimension Amelunxen et al. (2013) of the suggested norm for rank 1 matrices, showing that its statistical dimension is an order of magnitude smaller than the usual l1-norm, trace norm and their combinations. Even though our convex formulation is in theory hard and does not lead to provably polynomial time algorithmic schemes, we propose an active set algorithm leveraging the structure of the convex problem to solve it and show promising numerical results.",
            "output": [
                "Tight convex relaxations for sparse matrix factorization"
            ]
        },
        {
            "id": "task1540-473f1ac8376b47428978adc81b27b8b1",
            "input": "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the Owner/Author. Copyright is held by the owner/author(s). CSCW’16 Companion, February 27 March 02, 2016, San Francisco, CA, USA ACM 978-1-4503-3950-6/16/02. http://dx.doi.org/10.1145/2818052.2869110 Abstract Language in social media is mostly driven by new words and spellings that are constantly entering the lexicon thereby polluting it and resulting in high deviation from the formal written version. The primary entities of such language are the out-of-vocabulary (OOV) words. In this paper, we study various sociolinguistic properties of the OOV words and propose a classification model to categorize them into at least six categories. We achieve 81.26% accuracy with high precision and recall. We observe that the content features are the most discriminative ones followed by lexical and context features.",
            "output": [
                "WASSUP? LOL : Characterizing Out-of-Vocabulary Words in Twitter"
            ]
        },
        {
            "id": "task1540-e217a70d61f44722929d5a225f011f68",
            "input": "The Dialog State Tracking Challenge 4 (DSTC 4) differentiates itself from the previous three editions as follows: the number of slot-value pairs present in the ontology is much larger, no spoken language understanding output is given, and utterances are labeled at the subdialog level. This paper describes a novel dialog state tracking method designed to work robustly under these conditions, using elaborate string matching, coreference resolution tailored for dialogs and a few other improvements. The method can correctly identify many values that are not explicitly present in the utterance. On the final evaluation, our method came in first among 7 competing teams and 24 entries. The F1-score achieved by our method was 9 and 7 percentage points higher than that of the runner-up for the utterance-level evaluation and for the subdialog-level evaluation, respectively.",
            "output": [
                "Robust Dialog State Tracking for Large Ontologies"
            ]
        },
        {
            "id": "task1540-c326160908a941af84402c58a0d9367b",
            "input": "We study the representation and encoding of phonemes in a recurrent neural network model of grounded speech. We use a model which processes images and their spoken descriptions, and projects the visual and auditory representations into the same semantic space. We perform a number of analyses on how information about individual phonemes is encoded in the MFCC features extracted from the speech signal, and the activations of the layers of the model. Via experiments with phoneme decoding and phoneme discrimination we show that phoneme representations are most salient in the lower layers of the model, where low-level signals are processed at a fine-grained level, although a large amount of phonological information is retain at the top recurrent layer. We further find out that the attention mechanism following the top recurrent layer significantly attenuates encoding of phonology and makes the utterance embeddings much more invariant to synonymy. Moreover, a hierarchical clustering of phoneme representations learned by the network shows an organizational structure of phonemes similar to those proposed in linguistics.",
            "output": [
                "Encoding of phonology in a recurrent neural model of grounded speech"
            ]
        },
        {
            "id": "task1540-d9df579ad09c4faf8c028cea05f789a2",
            "input": "Tree-structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences. However, they suffer from two key technical problems that make them slow and unwieldy for large-scale NLP tasks: they can only operate on parsed sentences and they do not directly support batched computation. We address these issues by introducing the Stackaugmented Parser-Interpreter Neural Network (SPINN), which combines parsing and interpretation within a single treesequence hybrid model by integrating treestructured sentence interpretation into the linear sequential structure of a shift-reduce parser. Our model supports batched computation for a speedup of up to 25x over other tree-structured models, and its integrated parser allows it to operate on unparsed data with little loss of accuracy. We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models.",
            "output": [
                "A Fast Unified Model for Parsing and Sentence Understanding"
            ]
        },
        {
            "id": "task1540-771ec19f3da34513b81519b0b7f55bed",
            "input": "Markov chain Monte Carlo (MCMC) is one of the main workhorses of probabilistic inference, but it is notoriously hard to measure the quality of approximate posterior samples. This challenge is particularly salient in black box inference methods, which can hide details and obscure inference failures. In this work, we extend the recently introduced bidirectional Monte Carlo [GGA15] technique to evaluate MCMC-based posterior inference algorithms. By running annealed importance sampling (AIS) chains both from prior to posterior and vice versa on simulated data, we upper bound in expectation the symmetrized KL divergence between the true posterior distribution and the distribution of approximate samples. We present Bounding Divergences with REverse Annealing (BREAD), a protocol for validating the relevance of simulated data experiments to real datasets, and integrate it into two probabilistic programming languages: WebPPL [GS] and Stan [CGHL+ p]. As an example of how BREAD can be used to guide the design of inference algorithms, we apply it to study the effectiveness of different model representations in both WebPPL and Stan.",
            "output": [
                "Measuring the reliability of MCMC inference with bidirectional Monte Carlo"
            ]
        },
        {
            "id": "task1540-cb8bec27c17a403db27e0827c4ad8daa",
            "input": "The Support Vector Machine using Privileged Information (SVM+) has been proposed to train a classifier to utilize the additional privileged information that is only available in the training phase but not available in the test phase. In this work, we propose an efficient solution for SVM+ by simply utilizing the squared hinge loss instead of the hinge loss as in the existing SVM+ formulation, which interestingly leads to a dual form with less variables and in the same form with the dual of the standard SVM. The proposed algorithm is utilized to leverage the additional web knowledge that is only available during training for the image categorization tasks. The extensive experimental results on both Caltech101 and WebQueries datasets show that our proposed method can achieve a factor of up to hundred times speedup with the comparable accuracy when compared with the existing SVM+ method.",
            "output": [
                "Simple and Efficient Learning using Privileged Information"
            ]
        },
        {
            "id": "task1540-46138a5e9a7641ae8fc0ec58da0032c3",
            "input": "Many tasks in AI require the collaboration of multiple agents. Typically, the communication protocol between agents is manually specified and not altered during training. In this paper we explore a simple neural model, called CommNN, that uses continuous communication for fully cooperative tasks. The model consists of multiple agents and the communication between them is learned alongside their policy. We apply this model to a diverse set of tasks, demonstrating the ability of the agents to learn to communicate amongst themselves, yielding improved performance over non-communicative agents and baselines. In some cases, it is possible to interpret the language devised by the agents, revealing simple but effective strategies for solving the task at hand.",
            "output": [
                "Learning Multiagent Communication with Backpropagation"
            ]
        },
        {
            "id": "task1540-042b4e172cda4d179df8d06d83fe76c9",
            "input": "A totally semantic measure is presented which is able to calculate a similarity value between concept descriptions and also between concept description and individual or between individuals expressed in an expressive description logic. It is applicable on symbolic descriptions although it uses a numeric approach for the calculus. Considering that Description Logics stand as the theoretic framework for the ontological knowledge representation and reasoning, the proposed measure can be effectively used for agglomerative and divisional clustering task applied to the semantic web domain.",
            "output": [
                "A Semantic Similarity Measure for Expressive Description Logics"
            ]
        },
        {
            "id": "task1540-e0cbe898f9694977aed903f939326910",
            "input": "Independent Component Analysis (ICA) is the problem of learning a square matrix A, given samples of X = AS, where S is a random vector with independent coordinates. Most existing algorithms are provably efficient only when each Si has finite and moderately valued fourth moment. However, there are practical applications where this assumption need not be true, such as speech and finance. Algorithms have been proposed for heavy-tailed ICA, but they are not practical, using random walks and the full power of the ellipsoid algorithm multiple times. The main contributions of this paper are: (1) A practical algorithm for heavy-tailed ICA that we call HTICA. We provide theoretical guarantees and show that it outperforms other algorithms in some heavy-tailed regimes, both on real and synthetic data. Like the current state-of-the-art, the new algorithm is based on the centroid body (a first moment analogue of the covariance matrix). Unlike the state-of-the-art, our algorithm is practically efficient. To achieve this, we use explicit analytic representations of the centroid body, which bypasses the use of the ellipsoid method and random walks. (2) We study how heavy tails affect different ICA algorithms, including HTICA. Somewhat surprisingly, we show that some algorithms that use the covariance matrix or higher moments can successfully solve a range of ICA instances with infinite second moment. We study this theoretically and experimentally, with both synthetic and real-world heavy-tailed data.",
            "output": [
                "Heavy-Tailed Analogues of the Covariance Matrix for ICA"
            ]
        },
        {
            "id": "task1540-dff8907153f74b5aa0b312e1bfa6da59",
            "input": "With the recent proliferation of large-scale learning problems, there have been a lot of interest on distributed machine learning algorithms, particularly those that are based on stochastic gradient descent (SGD) and its variants. However, existing algorithms either suffer from slow convergence due to the inherent variance of stochastic gradients, or have a fast linear convergence rate but at the expense of poorer solution quality. In this paper, we combine their merits together by proposing a distributed asynchronous SGD-based algorithm with variance reduction. A constant learning rate can be used, and it is also guaranteed to converge linearly to the optimal solution. Experiments on the Google Cloud Computing Platform demonstrate that the proposed algorithm outperforms state-of-the-art distributed asynchronous algorithms in terms of both wall clock time and solution quality.",
            "output": [
                "Fast Distributed Asynchronous SGD with Variance Reduction"
            ]
        },
        {
            "id": "task1540-2f71949c95684b1ea4d6330edd39f7e5",
            "input": "We propose a protocol for intrusion detection in distributed systems based on a relatively recent theory in immunology called danger theory. Based on danger theory, immune response in natural systems is a result of sensing corruption as well as sensing unknown substances. In contrast, traditional self-nonself discrimination theory states that immune response is only initiated by sensing nonself (unknown) patterns. Danger theory solves many problems that could only be partially explained by the traditional model. Although the traditional model is simpler, such problems result in high false positive rates in immune-inspired intrusion detection systems. We believe using danger theory in a multi-agent environment that computationally emulates the behavior of natural immune systems is effective in reducing false positive rates. We first describe a simplified scenario of immune response in natural systems based on danger theory and then, convert it to a computational model as a network protocol. In our protocol, we define several immune signals and model cell signaling via message passing between agents that emulate cells. Most messages include application-specific patterns that must be meaningfully extracted from various system properties. We finally provide a few rules of thumb to simplify the task of pattern extraction in most distributed systems. “Do not just declare things to be irreducibly complex...” Richard Dawkins",
            "output": [
                "A Danger-Based Approach to Intrusion Detection"
            ]
        },
        {
            "id": "task1540-674cda1aa7784e3b85c5ed0b6707f836",
            "input": "The paper presents a knowledge representation language A log which extends ASP with aggregates. The goal is to have a language based on simple syntax and clear intuitive and mathematical semantics. We give some properties of A log, an algorithm for computing its answer sets, and comparison with other approaches.",
            "output": [
                "Vicious Circle Principle and Logic Programs with Aggregates"
            ]
        },
        {
            "id": "task1540-9e1ec38334d146aaa7fe5159485536ef",
            "input": "Recently deeplearning models have been shown to be capable of making remarkable performance in sentences and documents classification tasks. In this work, we propose a novel framework called AC-BLSTM for modeling sentences and documents, which combines the asymmetric convolution neural network (ACNN) with the Bidirectional Long ShortTerm Memory network (BLSTM). Experiment results demonstrate that our model achieves state-ofthe-art results on five tasks, including sentiment analysis, question type classification, and subjectivity classification. In order to further improve the performance of AC-BLSTM, we propose a semi-supervised learning framework called G-AC-BLSTM for text classification by combining the generative model with AC-BLSTM.",
            "output": [
                "AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification"
            ]
        },
        {
            "id": "task1540-2561053cc9a24d098c6745701cca78f2",
            "input": "Unsupervised dictionary learning has been a key component in state-of-the-art computer vision recognition architectures. While highly effective methods exist for patchbased dictionary learning, these methods may learn redundant features after the pooling stage in a given early vision architecture. In this paper, we offer a novel dictionary learning scheme to efficiently take into account the invariance of learned features after the spatial pooling stage. The algorithm is built on simple clustering, and thus enjoys efficiency and scalability. We discuss the underlying mechanism that justifies the use of clustering algorithms, and empirically show that the algorithm finds better dictionaries than patch-based methods with the same dictionary size.",
            "output": [
                "Pooling-Invariant Image Feature Learning"
            ]
        },
        {
            "id": "task1540-dbeba065b6184d899d718a18f5c83789",
            "input": "Interval temporal logics (ITLs) are logics for reasoning about temporal statements expressed over intervals, i.e., periods of time. The most famous ITL studied so far is Halpern and Shoham’s HS, which is the logic of the thirteen Allen’s interval relations. Unfortunately, HS and most of its fragments have an undecidable satisfiability problem. This discouraged the research in this area until recently, when a number non-trivial decidable ITLs have been discovered. This paper is a contribution towards the complete classification of all different fragments of HS. We consider different combinations of the interval relations begins (B), after (A), later (L) and their inverses A, B and L. We know from previous works that the combinationABBA is decidable only when finite domains are considered (and undecidable elsewhere), and thatABB is decidable over the natural numbers. We extend these results by showing that decidability of ABB can be further extended to capture the language ABBL, which lies in between ABB and ABBA, and that turns out to be maximal w.r.t decidability over strongly discrete linear orders (e.g. finite orders, the naturals, the integers). We also prove that the proposed decision procedure is optimal with respect to the EXPSPACE complexity class.",
            "output": [
                "Begin, After, and Later: a Maximal Decidable Interval Temporal Logic"
            ]
        },
        {
            "id": "task1540-55960529e7164a23a3f5df29ccac43aa",
            "input": "Sentiment analysis predicts the presence of positive or negative emotions in a text document. In this paper, we consider higher dimensional extensions of the sentiment concept, which represent a richer set of human emotions. Our approach goes beyond previous work in that our model contains a continuous manifold rather than a finite set of human emotions. We investigate the resulting model, compare it to psychological observations, and explore its predictive capabilities.",
            "output": [
                "The Manifold of Human Emotions"
            ]
        },
        {
            "id": "task1540-e26dde3acae143a396d90259ee0310db",
            "input": "Consider a weighted or unweighted k-nearest neighbor graph that has been built on n data points drawn randomly according to some density p on R. We study the convergence of the shortest path distance in such graphs as the sample size tends to infinity. We prove that for unweighted kNN graphs, this distance converges to an unpleasant distance function on the underlying space whose properties are detrimental to machine learning. We also study the behavior of the shortest path distance in weighted kNN graphs.",
            "output": [
                "Shortest path distance in random k-nearest neighbor graphs"
            ]
        },
        {
            "id": "task1540-bc49b878b0b741a197b0eaf23b4db559",
            "input": "Statistical topic models efficiently facilitate the exploration of large-scale data sets. Many models have been developed and broadly used to summarize the semantic structure in news, science, social media, and digital humanities. However, a common and practical objective in data exploration tasks is not to enumerate all existing topics, but to quickly extract representative ones that broadly cover the content of the corpus, i.e., a few topics that serve as a good summary of the data. Most existing topic models fit exactly the same number of topics as a user specifies, which have imposed an unnecessary burden to the users who have limited prior knowledge. We instead propose new models that are able to learn fewer but more representative topics for the purpose of data summarization. We propose a reinforced random walk that allows prominent topics to absorb tokens from similar and smaller topics, thus enhances the diversity among the top topics extracted. With this reinforced random walk as a general process embedded in classical topic models, we obtain diverse topic models that are able to extract the most prominent and diverse topics from data. The inference procedures of these diverse topic models remain as simple and efficient as the classical models. Experimental results demonstrate that the diverse topic models not only discover topics that better summarize the data, but also require minimal prior knowledge of the users.",
            "output": [
                "Less is More: Learning Prominent and Diverse Topics for Data Summarization"
            ]
        },
        {
            "id": "task1540-5c5ba9b98ce141bc87f595272a64a291",
            "input": "Most real-world data can be modeled as heterogeneous information networks (HINs) consisting of vertices of multiple types and their relationships. Search for similar vertices of the same type in large HINs, such as bibliographic networks and business-review networks, is a fundamental problem with broad applications. Although similarity search in HINs has been studied previously, most existing approaches neither explore rich semantic information embedded in the network structures nor take user’s preference as a guidance. In this paper, we re-examine similarity search in HINs and propose a novel embedding-based framework. It models vertices as low-dimensional vectors to explore network structureembedded similarity. To accommodate user preferences at defining similarity semantics, our proposed framework, ESim, accepts user-defined meta-paths as guidance to learn vertex vectors in a user-preferred embedding space. Moreover, an efficient and parallel sampling-based optimization algorithm has been developed to learn embeddings in large-scale HINs. Extensive experiments on real-world large-scale HINs demonstrate a significant improvement on the effectiveness of ESim over several state-of-the-art algorithms as well as its scalability.",
            "output": [
                "Meta-Path Guided Embedding for Similarity Search in Large-Scale Heterogeneous Information Networks"
            ]
        },
        {
            "id": "task1540-34e1997cf25042609fb1c7aa5dedae4a",
            "input": "e proliferation of social media in communication and information dissemination has made it an ideal platform for spreading rumors. Automatically debunking rumors at their stage of diusion is known as early rumor detection, which refers to dealing with sequential posts regarding disputed factual claims with certain variations and highly textual duplication over time. us, identifying trending rumors demands an ecient yet exible model that is able to capture long-range dependencies among postings and produce distinct representations for the accurate early detection. However, it is a challenging task to apply conventional classication algorithms to rumor detection in earliness since they rely on hand-craed features which require intensive manual eorts in the case of large amount of posts. is paper presents a deep aention model on the basis of recurrent neural networks (RNN) to learn selectively temporal hidden representations of sequential posts for identifying rumors. e proposed model delves so-aention into the recurrence to simultaneously pool out distinct features with particular focus and produce hidden representations that capture contextual variations of relevant posts over time. Extensive experiments on real datasets collected from social media websites demonstrate that (1) the deep aention based RNN model outperforms state-of-thearts that rely on hand-craed features; (2) the introduction of so aention mechanism can eectively distill relevant parts to rumors from original posts in advance; (3) the proposed method detects rumors more quickly and accurately than competitors.",
            "output": [
                "Call Attention to Rumors: Deep Attention Based Recurrent Neural Networks for Early Rumor Detection"
            ]
        },
        {
            "id": "task1540-c229a5ab14194ae1a541fe8ead184f3a",
            "input": "As historically acknowledged in the Reasoning about Actions and Change community, intuitiveness of a logical domain description cannot be fully automated. Moreover, like any other logical theory, action theories may also evolve, and thus knowledge engineers need revision methods to help in accommodating new incoming information about the behavior of actions in an adequate manner. The present work is about changing action domain descriptions in multimodal logic. Its contribution is threefold: first we revisit the semantics of action theory contraction proposed in previous work, giving more robust operators that express minimal change based on a notion of distance between Kripke-models. Second we give algorithms for syntactical action theory contraction and establish their correctness with respect to our semantics for those action theories that satisfy a principle of modularity investigated in previous work. Since modularity can be ensured for every action theory and, as we show here, needs to be computed at most once during the evolution of a domain description, it does not represent a limitation at all to the method here studied. Finally we state AGM-like postulates for action theory contraction and assess the behavior of our operators with respect to them. Moreover, we also address the revision counterpart of action theory change, showing that it benefits from our semantics for contraction.",
            "output": [
                "On Action Theory Change"
            ]
        },
        {
            "id": "task1540-8cd3e436d35b474780c427ae0db3fb90",
            "input": "We introduce a novel algorithmic approach to content recommendation based on adaptive clustering of exploration-exploitation (“bandit”) strategies. We provide a sharp regret analysis of this algorithm in a standard stochastic noise setting, demonstrate its scalability properties, and prove its effectiveness on a number of artificial and real-world datasets. Our experiments show a significant increase in prediction performance over state-of-the-art methods for bandit problems.",
            "output": [
                "Online Clustering of Bandits"
            ]
        },
        {
            "id": "task1540-4dfaac1b3ff74cbebb6f1aa7f9fd0045",
            "input": "Financial fraud detection is an important problem with a number of design aspects to consider. Issues such as algorithm selection and performance analysis will affect the perceived ability of proposed solutions, so for auditors and researchers to be able to sufficiently detect financial fraud it is necessary that these issues be thoroughly explored. In this paper we will revisit the key performance metrics used for financial fraud detection with a focus on credit card fraud, critiquing the prevailing ideas and offering our own understandings. There are many different performance metrics that have been employed in prior financial fraud detection research. We will analyse several of the popular metrics and compare their effectiveness at measuring the ability of detection mechanisms. We further investigated the performance of a range of computational intelligence techniques when applied to this problem domain, and explored the efficacy of several binary classification methods. Keywords—Financial fraud detection, credit card fraud; data mining; computational intelligence; performance metric",
            "output": [
                "Some Experimental Issues in Financial Fraud Detection: An Investigation"
            ]
        },
        {
            "id": "task1540-8c09b77460834f0abda512e246f558ec",
            "input": "This paper investigates the validity of Kleinberg’s axioms for clustering functions with respect to the quite popular clustering algorithm called k-means.We suggest that the reason why this algorithm does not fit Kleinberg’s axiomatic system stems from missing match between informal intuitions and formal formulations of the axioms. While Kleinberg’s axioms have been discussed heavily in the past, we concentrate here on the case predominantly relevant for k-means algorithm, that is behavior embedded in Euclidean space. We point at some contradictions and counter intuitiveness aspects of this axiomatic set within R that were evidently not discussed so far. Our results suggest that apparently without defining clearly what kind of clusters we expect we will not be able to construct a valid axiomatic system. In particular we look at the shape and the gaps between the clusters. Finally we demonstrate that there exist several ways to reconcile the formulation of the axioms with their intended meaning and that under this reformulation the axioms stop to be contradictory and the real-world k-means algorithm conforms to this axiomatic system.",
            "output": [
                "On the Discrepancy Between Kleinberg’s Clustering Axioms and k-Means Clustering Algorithm Behavior"
            ]
        },
        {
            "id": "task1540-12e394c379534287aa7e41c07df55c12",
            "input": "This paper presents a systematic evaluation of Neural Network (NN) for classification of real-world data. In the field of machine learning, it is often seen that a single parameter that is ‘predictive accuracy’ is being used for evaluating the performance of a classifier model. However, this parameter might not be considered reliable given a dataset with very high level of skewness. To demonstrate such behavior, seven different types of datasets have been used to evaluate a Multilayer Perceptron (MLP) using twelve(12) different parameters which include microand macro-level estimation. In the present study, the most common problem of prediction called ‘multiclass’ classification has been considered. The results that are obtained for different parameters for each of the dataset could demonstrate interesting findings to support the usability of these set of performance evaluation parameters.",
            "output": [
                "Reliable Evaluation of Neural Network for Multiclass Classification of Real-world Data"
            ]
        },
        {
            "id": "task1540-ecb03bd404e746e4af8c6a18b1417e4e",
            "input": "We showed in this work how the Hassanat distance metric enhances the performance of the nearest neighbour classifiers. The results demonstrate the superiority of this distance metric over the traditional and most-used distances, such as Manhattan distance and Euclidian distance. Moreover, we proved that the Hassanat distance metric is invariant to data scale, noise and outliers. Throughout this work, it is clearly notable that both ENN and IINC performed very well with the distance investigated, as their accuracy increased significantly by 3.3% and 3.1% respectively, with no significant advantage of the ENN over the IINC in terms of accuracy. Correspondingly, it can be noted from our results that there is no optimal algorithm that can solve all reallife problems perfectly; this is supported by the no-free-lunch theorem.",
            "output": [
                "ON ENHANCING THE PERFORMANCE OF NEAREST NEIGHBOUR CLASSIFIERS USING HASSANAT DISTANCE METRIC"
            ]
        },
        {
            "id": "task1540-3d9ba913cdc64ffa9d06b50c838b6e00",
            "input": "Major advances in Question Answering technology were needed for IBM Watson to play Jeopardy! at championship level – the show requires rapid-fire answers to challenging natural language questions, broad general knowledge, high precision, and accurate confidence estimates. In addition, Jeopardy! features four types of decision making carrying great strategic importance: (1) Daily Double wagering; (2) Final Jeopardy wagering; (3) selecting the next square when in control of the board; (4) deciding whether to attempt to answer, i.e., “buzz in.” Using sophisticated strategies for these decisions, that properly account for the game state and future event probabilities, can significantly boost a player’s overall chances to win, when compared with simple “rule of thumb” strategies. This article presents our approach to developing Watson’s game-playing strategies, comprising development of a faithful simulation model, and then using learning and MonteCarlo methods within the simulator to optimize Watson’s strategic decision-making. After giving a detailed description of each of our game-strategy algorithms, we then focus in particular on validating the accuracy of the simulator’s predictions, and documenting performance improvements using our methods. Quantitative performance benefits are shown with respect to both simple heuristic strategies, and actual human contestant performance in historical episodes. We further extend our analysis of human play to derive a number of valuable and counterintuitive examples illustrating how human contestants may improve their performance on the show.",
            "output": [
                "Analysis of Watson’s Strategies for Playing Jeopardy!"
            ]
        },
        {
            "id": "task1540-d4a90ac5c6d6491fa61203ddc8ef2553",
            "input": "The linear layer is one of the most pervasive modules in deep learning representations. However, it requiresO(N) parameters and O(N) operations. These costs can be prohibitive in mobile applications or prevent scaling in many domains. Here, we introduce a deep, differentiable, fully-connected neural network module composed of diagonal matrices of parameters, A and D, and the discrete cosine transform C. The core module, structured as ACDC, has O(N) parameters and incurs O(N logN) operations. We present theoretical results showing how deep cascades of ACDC layers approximate linear layers. ACDC is, however, a stand-alone module and can be used in combination with any other types of module. In our experiments, we show that it can indeed be successfully interleaved with ReLU modules in convolutional neural networks for image recognition. Our experiments also study critical factors in the training of these structured modules, including initialization and depth. Finally, this paper also provides a connection between structured linear transforms used in deep learning and the field of Fourier optics, illustrating how ACDC could in principle be implemented with lenses and diffractive elements.",
            "output": [
                "ACDC: A STRUCTURED EFFICIENT LINEAR LAYER"
            ]
        },
        {
            "id": "task1540-f6574241ad664c72ba8f41e26902f2e4",
            "input": "Opinions about the 2016 U.S. Presidential Candidates have been expressed in millions of tweets that are challenging to analyze automatically. Crowdsourcing the analysis of political tweets effectively is also difficult, due to large inter-rater disagreements when sarcasm is involved. Each tweet is typically analyzed by a fixed number of workers and majority voting. We here propose a crowdsourcing framework that instead uses a dynamic allocation of the number of workers. We explore two dynamic-allocation methods: (1) The number of workers queried to label a tweet is computed offline based on the predicted difficulty of discerning the sentiment of a particular tweet. (2) The number of crowd workers is determined online, during an iterative crowd sourcing process, based on inter-rater agreements between labels. We applied our approach to 1,000 twitter messages about the four U.S. presidential candidates Clinton, Cruz, Sanders, and Trump, collected during February 2016. We implemented the two proposed methods using decision trees that allocate more crowd efforts to tweets predicted to be sarcastic. We show that our framework outperforms the traditional static allocation scheme. It collects opinion labels from the crowd at a much lower cost while maintaining labeling accuracy.",
            "output": [
                "Dynamic Allocation of Crowd Contributions for Sentiment Analysis during the 2016 U.S. Presidential Election"
            ]
        },
        {
            "id": "task1540-6220b21842814665a67d37c8ee137556",
            "input": "The deep Boltzmann machine (DBM) has been an important development in the quest for powerful “deep” probabilistic models. To date, simultaneous or joint training of all layers of the DBM has been largely unsuccessful with existing training methods. We introduce a simple regularization scheme that encourages the weight vectors associated with each hidden unit to have similar norms. We demonstrate that this regularization can be easily combined with standard stochastic maximum likelihood to yield an effective training strategy for the simultaneous training of all layers of the deep Boltzmann machine.",
            "output": [
                "On Training Deep Boltzmann Machines"
            ]
        },
        {
            "id": "task1540-80befd21acfa41f7aeb11ce7b4488dd8",
            "input": "In this paper, we analyze a generic algorithm scheme for sequential global optimization using Gaussian processes. The upper bounds we derive on the cumulative regret for this generic algorithm improve by an exponential factor the previously known bounds for algorithms like GP-UCB. We also introduce the novel Gaussian Process Mutual Information algorithm (GP-MI), which significantly improves further these upper bounds for the cumulative regret. We confirm the efficiency of this algorithm on synthetic and real tasks against the natural competitor, GP-UCB, and also the Expected Improvement heuristic. Preprint for the 31st International Conference on Machine Learning (ICML 2014) 1 ar X iv :1 31 1. 48 25 v3 [ st at .M L ] 8 J un 2 01 5 Erratum After the publication of our article, we found an error in the proof of Lemma 1 which invalidates the main theorem. It appears that the information given to the algorithm is not sufficient for the main theorem to hold true. The theoretical guarantees would remain valid in a setting where the algorithm observes the instantaneous regret instead of noisy samples of the unknown function. We describe in this page the mistake and its consequences. Let f : X → R be the unknown function to be optimized, which is a sample from a Gaussian process. Let’s fix x, x1, . . . , xT ∈ X and the observations yt = f(xt)+ t where the noise variables t are independent Gaussian noise N (0, σ). We define the instantaneous regret rt = f(x?)− f(xt) and, MT = T ∑",
            "output": [
                "Gaussian Process Optimization with Mutual Information"
            ]
        },
        {
            "id": "task1540-df921296060540fa8eb285a40b314b4f",
            "input": "In this paper we present the greedy step averaging(GSA) method, a parameter-free stochastic optimization algorithm for a variety of machine learning problems. As a gradient-based optimization method, GSA makes use of the information from the minimizer of a single sample’s loss function, and takes average strategy to calculate reasonable learning rate sequence. While most existing gradient-based algorithms introduce an increasing number of hyper parameters or try to make a trade-off between computational cost and convergence rate, GSA avoids the manual tuning of learning rate and brings in no more hyper parameters or extra cost. We perform exhaustive numerical experiments for logistic and softmax regression to compare our method with the other state of the art ones on 16 datasets. Results show that GSA is robust on various scenarios.",
            "output": [
                "Greedy Step Averaging: A parameter-free stochastic optimization method"
            ]
        },
        {
            "id": "task1540-0b62fe1528b646a885f23d623d98ac0c",
            "input": "Deep neural networks have proved very successful in domains where large training sets are available, but when the number of training samples is small, their performance suffers from overfitting. Prior methods of reducing overfitting such as weight decay, Dropout and DropConnect are data-independent. This paper proposes a new method, GraphConnect, that is data-dependent, and is motivated by the observation that data of interest lie close to a manifold. The new method encourages the relationships between the learned decisions to resemble a graph representing the manifold structure. Essentially GraphConnect is designed to learn attributes that are present in data samples in contrast to weight decay, Dropout and DropConnect which are simply designed to make it more difficult to fit to random error or noise. Empirical Rademacher complexity is used to connect the generalization error of the neural network to spectral properties of the graph learned from the input data. This framework is used to show that GraphConnect is superior to weight decay. Experimental results on several benchmark datasets validate the theoretical analysis, and show that when the number of training samples is small, GraphConnect is able to significantly improve performance over weight decay.",
            "output": [
                "GraphConnect: A Regularization Framework for Neural Networks"
            ]
        },
        {
            "id": "task1540-5803ff6634574041b0ea6a1694f109a7",
            "input": "The Weighted Constraint Satisfaction Problem (WCSP) framework allows representing and solving problems involving both hard constraints and cost functions. It has been applied to various problems, including resource allocation, bioinformatics, scheduling, etc. To solve such problems, solvers usually rely on branch-and-bound algorithms equipped with local consistency filtering, mostly soft arc consistency. However, these techniques are not well suited to solve problems with very large domains. Motivated by the resolution of an RNA gene localization problem inside large genomic sequences, and in the spirit of bounds consistency for large domains in crisp CSPs, we introduce soft bounds arc consistency, a new weighted local consistency specifically designed for WCSP with very large domains. Compared to soft arc consistency, BAC provides significantly improved time and space asymptotic complexity. In this paper, we show how the semantics of cost functions can be exploited to further improve the time complexity of BAC. We also compare both in theory and in practice the efficiency of BAC on a WCSP with bounds consistency enforced on a crisp CSP using cost variables. On two different real problems modeled as WCSP, including our RNA gene localization problem, we observe that maintaining bounds arc consistency outperforms arc consistency and also improves over bounds consistency enforced on a constraint model with cost variables.",
            "output": [
                "Bounds Arc Consistency for Weighted CSPs"
            ]
        },
        {
            "id": "task1540-1b772fa288ee4363a92c90277c63fc1e",
            "input": "Robots will eventually be part of every household. It is thus critical to enable algorithms to learn from and be guided by non-expert users. In this paper, we bring a human in the loop, and enable a human teacher to give feedback to a learning agent in the form of natural language. We argue that a descriptive sentence can provide a much stronger learning signal than a numeric reward in that it can easily point to where the mistakes are and how to correct them. We focus on the problem of image captioning in which the quality of the output can easily be judged by non-experts. We propose a hierarchical phrase-based captioning model trained with policy gradients, and design a feedback network that provides reward to the learner by conditioning on the human-provided feedback. We show that by exploiting descriptive feedback our model learns to perform better than when given independently written human captions.",
            "output": [
                "Teaching Machines to Describe Images via Natural Language Feedback"
            ]
        },
        {
            "id": "task1540-24a82da2a2ac4e85bc7a548189b8f1c1",
            "input": "Accurate prediction of suitable discourse connectives (however, furthermore, etc.) is a key component of any system aimed at building coherent and fluent discourses from shorter sentences and passages. As an example, a dialog system might assemble a long and informative answer by sampling passages extracted from different documents retrieved from the web. We formulate the task of discourse connective prediction and release a dataset of 2.9M sentence pairs separated by discourse connectives for this task. Then, we evaluate the hardness of the task for human raters, apply a recently proposed decomposable attention (DA) model to this task and observe that the automatic predictor has a higher F1 than human raters (32 vs. 30). Nevertheless, under specific conditions the raters still outperform the DA model, suggesting that there is headroom for future improvements. Finally, we further demonstrate the usefulness of the connectives dataset by showing that it improves implicit discourse relation prediction when used for model pre-training.",
            "output": [
                "Automatic Prediction of Discourse Connectives"
            ]
        },
        {
            "id": "task1540-e9f0a382b5704ebd94e1d6a6dc5cf14e",
            "input": "The efficiency of algorithms using sec­ ondary structures for probabilistic inference in Bayesian networks can be improved by ex­ ploiting independence relations induced by evidence and the direction of the links in the original network. In this paper we present an algorithm that on-line exploits indepen­ dence relations induced by evidence and the direction of the links in the original network to reduce both time and space costs. In­ stead of multiplying the conditional proba­ bility distributions for the various cliques, we determine on-line which potentials to multi­ ply when a message is to be produced. The performance improvement of the algorithm is emphasized through empirical evaluations in­ volving large real world Bayesian networks, and we compare the method with the HUGIN and Shafer-Shenoy inference algorithms.",
            "output": [
                "Lazy Propagation in Junction Trees"
            ]
        },
        {
            "id": "task1540-7ee48d5039c947e985f746a3037a0a2c",
            "input": "In many combinatorial problems one may need to model the diversity or similarity of sets of assignments. For example, one may wish to maximise or minimise the number of distinct values in a solution. To formulate problems of this type we can use soft variants of the well known AllDifferent and AllEqual constraints. We present a taxonomy of six soft global constraints, generated by combining the two latter ones and the two standard cost functions, which are either maximised or minimised. We characterise the complexity of achieving arc and bounds consistency on these constraints, resolving those cases for which NP-hardness was neither proven nor disproven. In particular, we explore in depth the constraint ensuring that at least k pairs of variables have a common value. We show that achieving arc consistency is NP-hard, however bounds consistency can be achieved in polynomial time through dynamic programming. Moreover, we show that the maximum number of pairs of equal variables can be approximated by a factor of 12 with a linear time greedy algorithm. Finally, we provide a fixed parameter tractable algorithm with respect to the number of values appearing in more than two distinct domains. Interestingly, this taxonomy shows that enforcing equality is harder than enforcing difference.",
            "output": [
                "Soft Constraints of Difference and Equality"
            ]
        },
        {
            "id": "task1540-3e9b80a8a15f4adf9163f7e6d413a2fe",
            "input": "De nos jours, l’utilisation de l’Internet pour la recherche de définitions est de plus en plus importante. Wikipédia et Medline sont devenu les sites les plus consultés de la Web. Or, il existe un énorme nombre de définitions qui sont parfois inaccessibles aux utilisateurs. Celles-ci peuvent se trouver dans des sites non encyclopédiques ou dans de documents divers. Dans cette perspective nous avons développé le moteur de recherche Describe, qui permet de trouver des définitions en espagnol (Sierra et al., 2009). Une caractéristique de ce moteur est qu’il regroupe les résultats des recherches (définitions liées à un terme). Cet article présente la méthodologie de regroupement et l’évaluation des résultats. Ceux-ci sont encourageants du point de vue qualitatif. Par contre, l’évaluation quantitative pose des contraintes car il est compliqué d’évaluer la sémantique. Cet article est organisé comme suit : dans la section 2 nous introduisons les contextes définitoires (CD), dans la section 3 nous présentons des stratégies de regroupement des définitions. Le corpus utilisé dans nos expériences est présenté en section 4. Des évaluations avec des analyses quantitative et qualitative sont présentées au chapitre 5 avant de conclure et de donner quelques perspectives.",
            "output": [
                "Regroupement sémantique de définitions en espagnol"
            ]
        },
        {
            "id": "task1540-aa0134a0621b4e7db53deb557d3ce78c",
            "input": "For an artificial creative agent, an essential driver of the search for novelty is a value function which is often provided by the system designer or users. We argue that an important barrier for progress in creativity research is the inability of these systems to develop their own notion of value for novelty. We propose a notion of knowledge-driven creativity that circumvent the need for an externally imposed value function, allowing the system to explore based on what it has learned from a set of referential objects. The concept is illustrated by a specific knowledge model provided by a deep generative autoencoder. Using the described system, we train a knowledge model on a set of digit images and we use the same model to build coherent sets of new digits that do not belong to known",
            "output": [
                "Digits that are not: Generating new types through deep neural nets"
            ]
        },
        {
            "id": "task1540-e0d7d009b4444c2cba6f24ce6fa018e7",
            "input": "SNOMED Clinical Terms (SNOMED CT) is one of the most widespread ontologies in the life sciences, with more than 300,000 concepts and relationships, but is distributed with no associated software tools. In this paper we present MySNOM, a web-based SNOMED CT browser. MySNOM allows organizations to browse their own distribution of SNOMED CT under a controlled environment, focuses on navigating using the structure of SNOMED CT, and has diagramming capabilities.",
            "output": [
                "Are SNOMED CT Browsers Ready for Institutions? Introducing MySNOM"
            ]
        },
        {
            "id": "task1540-213a040036e74167801102f6cb62071f",
            "input": "Deep CCA is a recently proposed deep neural network extension to the traditional canonical correlation analysis (CCA), and has been successful for multi-view representation learning in several domains. However, stochastic optimization of the deep CCA objective is not straightforward, because it does not decouple over training examples. Previous optimizers for deep CCA are either batch-based algorithms or stochastic optimization using large minibatches, which can have high memory consumption. In this paper, we tackle the problem of stochastic optimization for deep CCA with small minibatches, based on an iterative solution to the CCA objective, and show that we can achieve as good performance as previous optimizers and thus alleviate the memory requirement.",
            "output": [
                "Stochastic Optimization for Deep CCA via Nonlinear Orthogonal Iterations"
            ]
        },
        {
            "id": "task1540-7a7c3c5b9e474aba8d92d7a75ccc63d3",
            "input": "Besides spoken words, speech signals also carry information about speaker gender, age, and emotional state which can be used in a variety of speech analysis applications. In this paper, a divide and conquer strategy for ensemble classification has been proposed to recognize emotions in speech. Intrinsic hierarchy in emotions has been utilized to construct an emotions tree, which assisted in breaking down the emotion recognition task into smaller sub tasks. The proposed framework generates predictions in three phases. Firstly, emotions are detected in the input speech signal by classifying it as neutral or emotional. If the speech is classified as emotional, then in the second phase, it is further classified into positive and negative classes. Finally, individual positive or negative emotions are identified based on the outcomes of the previous stages. Several experiments have been performed on a widely used benchmark dataset. The proposed method was able to achieve improved recognition rates as compared to several other approaches.",
            "output": [
                "Divide-and-Conquer based Ensemble to Spot Emotions in Speech using MFCC and Random Forest"
            ]
        },
        {
            "id": "task1540-de8ed1ab765542f3b0cdb15937435f0a",
            "input": "We study the stability vis a vis adversarial noise of matrix factorization algorithm for matrix completion. In particular, our results include: (I) we bound the gap between the solution matrix of the factorization method and the ground truth in terms of root mean square error; (II) we treat the matrix factorization as a subspace fitting problem and analyze the difference between the solution subspace and the ground truth; (III) we analyze the prediction error of individual users based on the subspace stability. We apply these results to the problem of collaborative filtering under manipulator attack, which leads to useful insights and guidelines for collaborative filtering system design.",
            "output": [
                "Stability of Matrix Factorization for Collaborative Filtering"
            ]
        },
        {
            "id": "task1540-7e654e1ee6864df98c16777d454773ba",
            "input": "Content on the Internet is heterogeneous and arises from various domains like News, Entertainment, Finance and Technology. Understanding such content requires identifying named entities (persons, places and organizations) as one of the key steps. Traditionally Named Entity Recognition (NER) systems have been built using available annotated datasets (like CoNLL, MUC) and demonstrate excellent performance. However, these models fail to generalize onto other domains like Sports and Finance where conventions and language use can differ significantly. Furthermore, several domains do not have large amounts of annotated labeled data for training robust Named Entity Recognition models. A key step towards this challenge is to adapt models learned on domains where large amounts of annotated training data are available to domains with scarce annotated data. In this paper, we propose methods to effectively adapt models learned on one domain onto other domains using distributed word representations. First we analyze the linguistic variation present across domains to identify key linguistic insights that can boost performance across domains. We propose methods to capture domain specific semantics of word usage in addition to global semantics. We then demonstrate how to effectively use such domain specific knowledge to learn NER models that outperform previous baselines in the domain adaptation setting. ∗This work was done when the author was a research intern at Yahoo. ∗© 2016 This is the authors draft of the work. It is posted here for your personal use. Not for redistribution.",
            "output": [
                "Domain Adaptation for Named Entity Recognition in Online Media with Word Embeddings"
            ]
        },
        {
            "id": "task1540-a3eede37103044a7ab9ae32e0eaec414",
            "input": "Humans can ground natural language commands to tasks at both abstract and fine-grained levels of specificity. For instance, a human forklift operator can be instructed to perform a high-level action, like “grab a pallet” or a lowlevel action like “tilt back a little bit.” While robots are also capable of grounding language commands to tasks, previous methods implicitly assume that all commands and tasks reside at a single, fixed level of abstraction. Additionally, those approaches that do not use abstraction experience inefficient planning and execution times due to the large, intractable state-action spaces, which closely resemble real world complexity. In this work, by grounding commands to all the tasks or subtasks available in a hierarchical planning framework, we arrive at a model capable of interpreting language at multiple levels of specificity ranging from coarse to more granular. We show that the accuracy of the grounding procedure is improved when simultaneously inferring the degree of abstraction in language used to communicate the task. Leveraging hierarchy also improves efficiency: our proposed approach enables a robot to respond to a command within one second on 90% of our tasks, while baselines take over twenty seconds on half the tasks. Finally, we demonstrate that a real, physical robot can ground commands at multiple levels of abstraction allowing it to efficiently plan different subtasks within the same planning hierarchy.",
            "output": [
                "Accurately and Efficiently Interpreting Human-Robot Instructions of Varying Granularities"
            ]
        },
        {
            "id": "task1540-0e1527ee31384fefa8a923f1401cf050",
            "input": "Many real-world machine learning applications involve several learning tasks which are inter-related. For example, in healthcare domain, we need to learn a predictive model of a certain disease for many hospitals. The models for each hospital may be different because of the inherent differences in the distributions of the patient populations. However, the models are also closely related because of the nature of the learning tasks modeling the same disease. By simultaneously learning all the tasks, multi-task learning (MTL) paradigm performs inductive knowledge transfer among tasks to improve the generalization performance. When datasets for the learning tasks are stored at different locations, it may not always be feasible to transfer the data to provide a data-centralized computing environment due to various practical issues such as high data volume and privacy. In this paper, we propose a principled MTL framework for distributed and asynchronous optimization to address the aforementioned challenges. In our framework, gradient update does not wait for collecting the gradient information from all the tasks. Therefore, the proposed method is very efficient when the communication delay is too high for some task nodes. We show that many regularized MTL formulations can benefit from this framework, including the low-rank MTL for shared subspace learning. Empirical studies on both synthetic and realworld datasets demonstrate the efficiency and effectiveness of the proposed framework.",
            "output": [
                "Asynchronous Multi-Task Learning"
            ]
        },
        {
            "id": "task1540-9a7d1cfe81dc445ea1813f85c874e9a3",
            "input": "This is a working paper summarizing results of an ongoing research project whose aim is to uniquely characterize the uncertainty mea­ sure for the Dempster-Shafer Theory. A set of intuitive axiomatic requirements is pre­ sented, some of their implications are shown, and the proof is given of the minimality of re­ cently proposed measure AU among all mea­ sures satisfying the proposed requirements.",
            "output": [
                "Toward a Characterization of Uncertainty Measure for the Dempster-Shafer Theory"
            ]
        },
        {
            "id": "task1540-8aa7c4c51f6b4b5b9ea890d7d1ff93e3",
            "input": "Estimators of information theoretic measures such as entropy and mutual information are a basic workhorse for many downstream applications in modern data science. State of the art approaches have been either geometric (nearest neighbor (NN) based) or kernel based (with a globally chosen bandwidth). In this paper, we combine both these approaches to design new estimators of entropy and mutual information that outperform state of the art methods. Our estimator uses local bandwidth choices of k-NN distances with a finite k, independent of the sample size. Such a local and data dependent choice improves performance in practice, but the bandwidth is vanishing at a fast rate, leading to a non-vanishing bias. We show that the asymptotic bias of the proposed estimator is universal; it is independent of the underlying distribution. Hence, it can be precomputed and subtracted from the estimate. As a byproduct, we obtain a unified way of obtaining both kernel and NN estimators. The corresponding theoretical contribution relating the asymptotic geometry of nearest neighbors to order statistics is of independent mathematical interest.",
            "output": [
                "Breaking the Bandwidth Barrier: Geometrical Adaptive Entropy Estimation"
            ]
        },
        {
            "id": "task1540-29c6a144f3644b2e84024d9bd1c4e0b5",
            "input": "The basic features of some of the most versatile and popular open source frameworks for machine learning (TensorFlow, Deep Learning4j, and H2O) are considered and compared. Their comparative analysis was performed and conclusions were made as to the advantages and disadvantages of these platforms. The performance tests for the de facto standard MNIST data set were carried out on H2O framework for deep learning algorithms designed for CPU and GPU platforms for single-threaded and multithreaded modes of operation. Keywords—machine learning; deep learning; TensorFlow; Deep Learning4j; H2O; MNIST; multicore CPU; GPU.",
            "output": [
                "Comparative Analysis of Open Source Frameworks for Machine Learning with Use Case in Single- Threaded and Multi-Threaded Modes"
            ]
        },
        {
            "id": "task1540-5a65673632194dee84c3c297cd626a79",
            "input": "We study the problem of learning the best Bayesian network structure with respect to a decomposable score such as BDe, BIC or AIC. This problem is known to be NP-hard, which means that solving it becomes quickly infeasible as the number of variables increases. Nevertheless, in this paper we show that it is possible to learn the best Bayesian network structure with over 30 variables, which covers many practically interesting cases. Our algorithm is less complicated and more efficient than the techniques presented earlier. It can be easily parallelized, and offers a possibility for efficient exploration of the best networks consistent with different variable orderings. In the experimental part of the paper we compare the performance of the algorithm to the previous state-of-the-art algorithm. Free source-code and an online-demo can be found at http://b-course.hiit.fi/bene.",
            "output": [
                "A Simple Approach for Finding the Globally Optimal Bayesian Network Structure"
            ]
        },
        {
            "id": "task1540-b313b960926245eba5596843820578a1",
            "input": "State-of-the-art answer set programming (ASP) solvers rely on a program called a grounder to convert non-ground programs containing variables into variable-free, propositional programs. The size of this grounding depends heavily on the size of the non-ground rules, and thus, reducing the size of such rules is a promising approach to improve solving performance. To this end, in this paper we announce lpopt, a tool that decomposes large logic programming rules into smaller rules that are easier to handle for current solvers. The tool is specifically tailored to handle the standard syntax of the ASP language (ASP-Core) and makes it easier for users to write efficient and intuitive ASP programs, which would otherwise often require significant hand-tuning by expert ASP engineers. It is based on an idea proposed by Morak and Woltran (2012) that we extend significantly in order to handle the full ASP syntax, including complex constructs like aggregates, weak constraints, and arithmetic expressions. We present the algorithm, the theoretical foundations on how to treat these constructs, as well as an experimental evaluation showing the viability of our approach.",
            "output": [
                "lpopt: A Rule Optimization Tool for Answer Set Programming Author=Manuel Bichler, Michael Morak, and Stefan Woltran"
            ]
        },
        {
            "id": "task1540-9ca8eaa6cf814a9eb7feb9681a2bc61c",
            "input": "We introduce AI rationalization, an approach for generating explanations of autonomous system behavior as if a human had done the behavior. We describe a rationalization technique that uses neural machine translation to translate internal state-action representations of the autonomous agent into natural language. We evaluate our technique in the Frogger game environment. The natural language is collected from human players thinking out loud as they play the game. We motivate the use of rationalization as an approach to explanation generation, show the results of experiments on the accuracy of our rationalization technique, and describe future research agenda.",
            "output": [
                "Rationalization: A Neural Machine Translation Approach to Generating Natural Language Explanations"
            ]
        },
        {
            "id": "task1540-11e1da6761c345b7ad20be120a49e043",
            "input": "Cumulative prospect theory (CPT) is known to model human decisions well, with substantial empirical evidence supporting this claim. CPT works by distorting probabilities and is more general than the classic expected utility and coherent risk measures. We bring this idea to a risk-sensitive reinforcement learning (RL) setting and design algorithms for both estimation and control. The estimation scheme that we propose uses the empirical distribution in order to estimate the CPT-value of a random variable. We then use this scheme in the inner loop of policy optimization procedures for a Markov decision process (MDP). We propose both gradient-based as well as gradient-free policy optimization algorithms. The former includes both first-order and second-order methods that are based on the well-known simulation optimization idea of simultaneous perturbation stochastic approximation (SPSA), while the latter is based on a reference distribution that concentrates on the global optima. Using an empirical distribution over the policy space in conjunction with Kullback-Leibler (KL) divergence to the reference distribution, we get a global policy optimization scheme. We provide theoretical convergence guarantees for all the proposed algorithms.",
            "output": [
                "Cumulative Prospect Theory Meets Reinforcement Learning: Estimation and Control"
            ]
        },
        {
            "id": "task1540-549c48e7e22e41f585800d8cf7c63a86",
            "input": "5",
            "output": [
                "Leveraging over priors for boosting control of prosthetic hands"
            ]
        },
        {
            "id": "task1540-8e99ced076a24016b60c90df3b5d7d58",
            "input": "<lb>We study the problem of adaptive control of a high dimensional linear quadratic<lb>(LQ) system. Previous work established the asymptotic convergence to an optimal<lb>controller for various adaptive control schemes. More recently, for the average<lb>cost LQ problem, a regret bound of O(<lb>√<lb>T ) was shown, apart form logarithmic<lb>factors. However, this bound scales exponentially with p, the dimension of the<lb>state space. In this work we consider the case where the matrices describing the<lb>dynamic of the LQ system are sparse and their dimensions are large. We present<lb>an adaptive control scheme that achieves a regret bound of O(p<lb>√<lb>T ), apart from<lb>logarithmic factors. In particular, our algorithm has an average cost of (1 + ǫ)<lb>times the optimum cost after T = polylog(p)O(1/ǫ). This is in comparison to<lb>previous work on the dense dynamics where the algorithm requires time that scales<lb>exponentially with dimension in order to achieve regret of ǫ times the optimal cost.<lb>We believe that our result has prominent applications in the emerging area of<lb>computational advertising, in particular targeted online advertising and advertising<lb>in social networks.",
            "output": [
                "Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems"
            ]
        },
        {
            "id": "task1540-587368394f2949fe97b94b4c3ebe0f21",
            "input": "Along with data on the web increasing dramatically, hashing is becoming more and more popular as a method of approximate nearest neighbor search. Previous supervised hashing methods utilized similarity/dissimilarity matrix to get semantic information. But the matrix is not easy to construct for a new dataset. Rather than to reconstruct the matrix, we proposed a straightforward CNN-based hashing method, i.e. binarilizing the activations of a fully connected layer with threshold 0 and taking the binary result as hash codes. This method achieved the best performance on CIFAR-10 and was comparable with the state-ofthe-art on MNIST. And our experiments on CIFAR-10 suggested that the signs of activations may carry more information than the relative values of activations between samples, and that the co-adaption between feature extractor and hash functions is important for hashing.",
            "output": [
                "CNN Based Hashing for Image Retrieval"
            ]
        },
        {
            "id": "task1540-d1f2de787f344d129360a76ad2a890b0",
            "input": "Separable Bayesian Networks, or the Influence Model, are dynamic Bayesian Networks in which the conditional probability distribution can be separated into a function of only the marginal distribution of a node’s parents, instead of the joint distributions. We describe the connection between an arbitrary Conditional Probability Table (CPT) and separable systems using linear algebra. We give an alternate proof to [Pfeffer00] on the equivalence of sufficiency and separability. We present a computational method for testing whether a given CPT is separable.",
            "output": [
                "Linear Algebra Approach to Separable Bayesian Networks"
            ]
        },
        {
            "id": "task1540-b0ddad2a938045888a8eef35d98a6964",
            "input": "In this thesis, we study the problem of recognizing video sequences of fingerspelled letters in American Sign Language (ASL). Fingerspelling comprises a significant but relatively understudied part of ASL, and recognizing it is challenging for a number of reasons: It involves quick, small motions that are often highly coarticulated; it exhibits significant variation between signers; and there has been a dearth of continuous fingerspelling data collected. In this work, we propose several types of recognition approaches, and explore the signer variation problem. Our best-performing models are segmental (semi-Markov) conditional random fields using deep neural network-based features. In the signer-dependent setting, our recognizers achieve up to about 8% letter error rates. The signer-independent setting is much more challenging, but with neural network adaptation we achieve up to 17% letter error rates. Thesis Supervisor: Karen Livescu Title: Assistant Professor",
            "output": [
                "American Sign Language fingerspelling recognition from video: Methods for unrestricted recognition and signer-independence"
            ]
        },
        {
            "id": "task1540-f266720ef1ab4cd2a76b14133fdbbc15",
            "input": "Finite chase, or alternatively chase termination, is an important condition to ensure the decidability of existential rule languages. In the past few years, a number of rule languages with finite chase have been studied. In this work, we propose a novel approach for classifying the rule languages with finite chase. Using this approach, a family of decidable rule languages, which extend the existing languages with the finite chase property, are naturally defined. We then study the complexity of these languages. Although all of them are tractable for data complexity, we show that their combined complexity can be arbitrarily high. Furthermore, we prove that all the rule languages with finite chase that extend the weakly acyclic language are of the same expressiveness as the weakly acyclic one, while rule languages with higher combined complexity are in general more succinct than those with lower combined complexity.",
            "output": [
                "Existential Rule Languages with Finite Chase: Complexity and Expressiveness"
            ]
        },
        {
            "id": "task1540-ba90e1c2121d4cc39c4983a9200018e2",
            "input": "Derivational morphology is a fundamental and complex characteristic of language. In this paper we propose the new task of predicting the derivational form of a given base-form lemma that is appropriate for a given context. We present an encoder– decoder style neural network to produce a derived form character-by-character, based on its corresponding character-level representation of the base form and the context. We demonstrate that our model is able to generate valid context-sensitive derivations from known base forms, but is less accurate under a lexicon agnostic setting.",
            "output": [
                "Context-Aware Prediction of Derivational Word-forms"
            ]
        },
        {
            "id": "task1540-3519a685880d42bc9399c0c4698be355",
            "input": "The large and growing amounts of online scholarly data present both challenges and opportunities to enhance knowledge discovery. One such challenge is to automatically extract a small set of keyphrases from a document that can accurately describe the document’s content and can facilitate fast information processing. In this paper, we propose PositionRank, an unsupervised model for keyphrase extraction from scholarly documents that incorporates information from all positions of a word’s occurrences into a biased PageRank. Our model obtains remarkable improvements in performance over PageRank models that do not take into account word positions as well as over strong baselines for this task. Specifically, on several datasets of research papers, PositionRank achieves improvements as high as 29.09%.",
            "output": [
                "PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents"
            ]
        },
        {
            "id": "task1540-ad6503b23a59475d88b9aa2a41bbe6b2",
            "input": "Generative model has been one of the most common approaches for solving the Dialog State Tracking Problem with the capabilities to model the dialog hypotheses in an explicit manner. The most important task in such Bayesian networks models is constructing the most reliable user models by learning and reflecting the training data into the probability distribution of user actions conditional on networks’ states. This paper provides an overall picture of the learning process in a Bayesian framework with an emphasize on the state-of-the-art theoretical analyses of the Expectation Maximization learning algorithm.",
            "output": [
                "The Dialog State Tracking Challenge with Bayesian Approach"
            ]
        },
        {
            "id": "task1540-68393b5ecf4d4f26b9de0ef7f0cb64df",
            "input": "The problem of sparse rewards is one of the hardest challenges in contemporary reinforcement learning. Hierarchical reinforcement learning (HRL) tackles this problem by using a set of temporally-extended actions, or options, each of which has its own subgoal. These subgoals are normally handcrafted for specific tasks. Here, though, we introduce a generic class of subgoals with broad applicability in the visual domain. Underlying our approach (in common with work using “auxiliary tasks”) is the hypothesis that the ability to control aspects of the environment is an inherently useful skill to have. We incorporate such subgoals in an end-to-end hierarchical reinforcement learning system and test two variants of our algorithm on a number of games from the Atari suite. We highlight the advantage of our approach in one of the hardest games – Montezuma’s revenge – for which the ability to handle sparse rewards is key. Our agent learns several times faster than the current state-of-the-art HRL agent in this game, reaching a similar level of performance.",
            "output": [
                "Feature Control as Intrinsic Motivation for Hierarchical Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-de19b3b9f027427f905b78d09975a2a3",
            "input": "Modeling spike firing assumes that spiking statistics is Poisson, but real data violates this assumption. To capture non-Poissonian features, in order to fix the inevitable inherent irregularity, researchers rescale the time axis with tedious computational overhead instead of searching for another distribution! Spikes or action potentials are precisely-timed changes in the ionic transport through synapses adjusting the synaptic weight, successfully modeled and developed as a memristor. Memristance value is multiples of initial resistance. This reminds us with the foundations of quantum mechanics. We try to quantize potential and resistance, as done with energy. After reviewing Planck curve for blackbody radiation, we propose the quantization equations. We introduce and prove a theorem that quantizes the resistance. Then we define the tyke showing its basic characteristics. Finally we give the basic transformations to model spiking and link an energy quantum to a tyke. Investigation shows how this perfectly models the neuron spiking., with over 97% match. All MATLA codes used are supplemented in the appendix.",
            "output": [
                "Spike and Tyke, the Quantized Neuron Model"
            ]
        },
        {
            "id": "task1540-94ec42701a804e0385714ed126e89234",
            "input": "Quality assurance remains a key topic in human computation research. Prior work indicates that majority voting is effective for low difficulty tasks, but has limitations for harder tasks. This paper explores two methods of addressing this problem: tournament selection and elimination selection, which exploit 2-, 3and 4-way comparisons between different answers to human computation tasks. Our experimental results and statistical analyses show that both methods produce the correct answer in noisy human computation environment more often than majority voting. Furthermore, we find that the use of 4-way comparisons can significantly reduce the cost of quality assurance relative to the use of 2-way comparisons.",
            "output": [
                "WHEN MAJORITY VOTING FAILS: COMPARINGQUALITY ASSURANCE METHODS FOR NOISY HUMAN COMPUTATION ENVIRONMENT"
            ]
        },
        {
            "id": "task1540-4bc568b01a9f429eb7c8c8b438464e02",
            "input": "In the a posteriori approach of multiobjective optimization the Pareto front is approximated by a finite set of solutions in the objective space. The quality of the approximation can be measured by different indicators that take into account the approximation’s closeness to the Pareto front and its distribution along the Pareto front. In particular, the averaged Hausdorff indicator prefers an almost uniform distribution. An observed drawback of multiobjective estimation of distribution algorithms (MEDAs) is that as common for randomized metaheuristics the final population usually is not uniformly distributed along the Pareto front. Therefore, we propose a postprocessing strategy which consists of applying the averaged Hausdorff indicator to the complete archive of generated solutions after optimization in order to select a uniformly distributed subset of nondominated solutions from the archive. In this paper, we put forward a strategy for extracting the above described subset. The effectiveness of the proposal is contrasted in a series of experiments that involve different MEDAs and filtering techniques. ar X iv :1 50 3. 07 84 5v 1 [ cs .A I] 2 6 M ar 2 01 5",
            "output": [
                "Averaged Hausdorff Approximations of Pareto Fronts based on Multiobjective Estimation of Distribution Algorithms 2015"
            ]
        },
        {
            "id": "task1540-71ffe28cc07d4531b01a7d8ae3ba4cb4",
            "input": "In machine learning, there is a fundamental trade-off between ease of optimization and expressive power. Neural Networks, in particular, have enormous expressive power and yet are notoriously challenging to train. The nature of that optimization challenge changes over the course of learning. Traditionally in deep learning, one makes a static trade-off between the needs of early and late optimization. In this paper, we investigate a novel framework, GradNets, for dynamically adapting architectures during training to get the benefits of both. For example, we can gradually transition from linear to non-linear networks, deterministic to stochastic computation, shallow to deep architectures, or even simple downsampling to fully differentiable attention mechanisms. Benefits include increased accuracy, easier convergence with more complex architectures, solutions to test-time execution of batch normalization, and the ability to train networks of up to 200 layers.",
            "output": [
                "GRADNETS: DYNAMIC INTERPOLATION BETWEEN NEURAL ARCHITECTURES"
            ]
        },
        {
            "id": "task1540-989015f2063d48ec80e5ae81928887b0",
            "input": "The vocabulary mismatch problem is a long-standing problem in information retrieval. Semantic matching holds the promise of solving the problem. Recent advances in language technology have given rise to unsupervised neural models for learning representations of words as well as bigger textual units. Such representations enable powerful semantic matching methods. This survey is meant as an introduction to the use of neural models for semantic matching. To remain focused we limit ourselves to web search. We detail the required background and terminology, a taxonomy grouping the rapidly growing body of work in the area, and then survey work on neural models for semantic matching in the context of three tasks: query suggestion, ad retrieval, and document retrieval. We include a section on resources and best practices that we believe will help readers who are new to the area. We conclude with an assessment of the state-of-the-art and suggestions for future work.",
            "output": [
                "Getting Started with Neural Models for Semantic Matching in Web Search"
            ]
        },
        {
            "id": "task1540-495519577ce44e3db44483bfbd9e0ddd",
            "input": "This software project based paper is for a vision of the near future in which computer interaction is characterised by natural face-to-face conversations with lifelike characters that speak, emote, and gesture. The first step is speech. The dream of a true virtual reality, a complete human-computer interaction system will not come true unless we try to give some perception to machine and make it perceive the outside world as humans communicate with each other. This software project is under development for “listening and replying machine (Computer) through speech”. The Speech interface is developed to convert speech input into some parametric form (Speech-to-Text) for further processing and the results, text output to speech synthesis (Text-to-Speech)",
            "output": [
                "Speech_Urmila"
            ]
        },
        {
            "id": "task1540-37ca63b5c86d4fd794e97bca0c592041",
            "input": "Empirical risk minimization (ERM) is a fundamental learning rule for statistical learning problems where the data is generated according to some unknown distribution P and returns a hypothesis f chosen from a fixed class F with small loss `. In the parametric setting, depending upon (`,F ,P) ERM can have slow (1/ √ n) or fast (1/n) rates of convergence of the excess risk as a function of the sample size n. There exist several results that give sufficient conditions for fast rates in terms of joint properties of `, F , and P, such as the margin condition and the Bernstein condition. In the non-statistical prediction with expert advice setting, there is an analogous slow and fast rate phenomenon, and it is entirely characterized in terms of the mixability of the loss ` (there being no role there for F or P). The notion of stochastic mixability builds a bridge between these two models of learning, reducing to classical mixability in a special case. The present paper presents a direct proof of fast rates for ERM in terms of stochastic mixability of (`,F ,P), and in so doing provides new insight into the fast-rates phenomenon. The proof exploits an old result of Kemperman on the solution to the general moment problem. We also show a partial converse that suggests a characterization of fast rates for ERM in terms of stochastic mixability is possible.",
            "output": [
                "From Stochastic Mixability to Fast Rates"
            ]
        },
        {
            "id": "task1540-a02be19c44754ff3be64afbb76f43342",
            "input": "We present a novel neural model HyperVec to learn hierarchical embeddings for hypernymy detection and directionality. While previous embeddings have shown limitations on prototypical hypernyms, HyperVec represents an unsupervised measure where embeddings are learned in a specific order and capture the hypernym–hyponym distributional hierarchy. Moreover, our model is able to generalize over unseen hypernymy pairs, when using only small sets of training data, and by mapping to other languages. Results on benchmark datasets show that HyperVec outperforms both state-of-theart unsupervised measures and embedding models on hypernymy detection and directionality, and on predicting graded lexical entailment.",
            "output": [
                "Hierarchical Embeddings for Hypernymy Detection and Directionality"
            ]
        },
        {
            "id": "task1540-4fcda61fa20e4f16913f00d8c0a49e8f",
            "input": "We train a generative convolutional neural network<lb>which is able to generate images of objects given object<lb>type, viewpoint, and color. We train the network in a su-<lb>pervised manner on a dataset of rendered 3D chair mod-<lb>els. Our experiments show that the network does not merely<lb>learn all images by heart, but rather finds a meaningful<lb>representation of a 3D chair model allowing it to assess<lb>the similarity of different chairs, interpolate between given<lb>viewpoints to generate the missing ones, or invent new chair<lb>styles by interpolating between chairs from the training set.<lb>We show that the network can be used to find correspon-<lb>dences between different chairs from the dataset, outper-<lb>forming existing approaches on this task.",
            "output": [
                "Learning to Generate Chairs with Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-e35c42c5c4274d2a91f43091256158ab",
            "input": "In this paper, the continuity and strong continuity in domain-free information algebras and labeled information algebras are introduced respectively. A more general concept of continuous function which is defined between two domain-free continuous information algebras is presented. It is shown that, with the operations combination and focusing, the set of all continuous functions between two domain-free s-continuous information algebras forms a new s-continuous information algebra. By studying the relationship between domain-free information algebras and labeled information algebras, it is demonstrated that they do correspond to each other on s-compactness.",
            "output": [
                "CONTINUITY IN INFORMATION ALGEBRAS: A SURVEY ON THE RELATIONSHIP BETWEEN TWO TYPES OF INFORMATION ALGEBRAS"
            ]
        },
        {
            "id": "task1540-3c860ab81ba74ec994cd316fb29e6406",
            "input": "We present a language complexity analysis of World of Warcraft (WoW) community texts, which we compare to texts from a general corpus of web English. Results from several complexity types are presented, including lexical diversity, density, readability and syntactic complexity. The language of WoW texts is found to be comparable to the general corpus on some complexity measures, yet more specialized on other measures. Our findings can be used by educators willing to include game-related activities into school curricula.",
            "output": [
                "An investigation into language complexity of World-of-Warcraft game-external texts"
            ]
        },
        {
            "id": "task1540-600395fb736b48f895a6567400e18772",
            "input": "The sparse, hierarchical and modular processing of natural signals are characteristics that relate to the ability of humans to recognise objects with high accuracy. In this paper, we report a sparse feature processing and encoding method targeted at improving the recognition performance of automated object recognition system. Randomly distributed selection of localised gradient enhanced features followed by the application of aggregate functions represents a modular and hierarchical approach to detect the object features. These object features, in combination with minimum distance classifier, results in object recognition system accuracies of 93% using ALOI, 92% using COIL-100 databases and 69% using PASCAL visual object challenge 2007 database, respectively. Robustness of object recognition performance is tested for variations in noise, object scaling and object shifts. Finally, a comparison with 8 existing object recognition methods indicated an improvement in recognition accuracy of 10% in ALOI, 8% in case of COIL-100 databases and 10% in PASCAL visual object challenge 2007 database.",
            "output": [
                "Sparse distributed localised gradient fused features of objects"
            ]
        },
        {
            "id": "task1540-7ed4265567b7442bbaff00eefe84d415",
            "input": "This is an overview paper written in style of research proposal. In recent years we introduced a general framework for large-scale unconstrained optimization – Sequential Subspace Optimization (SESOP) and demonstrated its usefulness for sparsity-based signal/image denoising, deconvolution, compressive sensing, computed tomography, diffraction imaging, support vector machines. We explored its combination with Parallel Coordinate Descent and Separable Surrogate Function methods, obtaining state of the art results in above-mentioned areas. There are several methods, that are faster than plain SESOP under specific conditions: Trust region Newton method for problems with easily invertible Hessian matrix; Truncated Newton method when fast multiplication by Hessian is available; Stochastic optimization methods for problems with large stochastic-type data; Multigrid methods for problems with nested multilevel structure. Each of these methods can be further improved by merge with SESOP. One can also accelerate Augmented Lagrangian method for constrained optimization problems and Alternating Direction Method of Multipliers for problems with separable objective function and non-separable constraints.",
            "output": [
                "Speeding-Up Convergence via Sequential Subspace Optimization: Current State and Future Directions"
            ]
        },
        {
            "id": "task1540-cb2a0e74b82f4cf4b047a39b5d8e7435",
            "input": "This paper presents a new 3D point cloud classification benchmark data set with over four billion manually labelled points, meant as input for data-hungry (deep) learning methods. We also discuss first submissions to the benchmark that use deep convolutional neural networks (CNNs) as a work horse, which already show remarkable performance improvements over state-of-the-art. CNNs have become the de-facto standard for many tasks in computer vision and machine learning like semantic segmentation or object detection in images, but have no yet led to a true breakthrough for 3D point cloud labelling tasks due to lack of training data. With the massive data set presented in this paper, we aim at closing this data gap to help unleash the full potential of deep learning methods for 3D labelling tasks. Our semantic3D.net data set consists of dense point clouds acquired with static terrestrial laser scanners. It contains 8 semantic classes and covers a wide range of urban outdoor scenes: churches, streets, railroad tracks, squares, villages, soccer fields and castles. We describe our labelling interface and show that our data set provides more dense and complete point clouds with much higher overall number of labelled points compared to those already available to the research community. We further provide baseline method descriptions and comparison between methods submitted to our online system. We hope semantic3D.net will pave the way for deep learning methods in 3D point cloud labelling to learn richer, more general 3D representations, and first submissions after only a few months indicate that this might indeed be the case.",
            "output": [
                "SEMANTIC3D.NET: A NEW LARGE-SCALE POINT CLOUD CLASSIFICATION BENCHMARK"
            ]
        },
        {
            "id": "task1540-4f6d6a7fd01a4e2780a50ecda4acc256",
            "input": "Bound Founded Answer Set Programming (BFASP) is an extension of Answer Set Programming (ASP) that extends stable model semantics to numeric variables. While the theory of BFASP is defined on ground rules, in practice BFASP programs are written as complex non-ground expressions. Flattening of BFASP is a technique used to simplify arbitrary expressions of the language to a small and well defined set of primitive expressions. In this paper, we first show how we can flatten arbitrary BFASP rule expressions, to give equivalent BFASP programs. Next, we extend the bottom-up grounding technique and magic set transformation used by ASP to BFASP programs. Our implementation shows that for BFASP problems, these techniques can significantly reduce the ground program size, and improve subsequent solving.",
            "output": [
                "Grounding Bound Founded Answer Set Programs"
            ]
        },
        {
            "id": "task1540-e16577736b5349ddbc1c14fbaae27712",
            "input": "We introduce an online neural sequence to sequence model that learns to alternate between encoding and decoding segments of the input as it is read. By independently tracking the encoding and decoding representations our algorithm permits exact polynomial marginalization of the latent segmentation during training, and during decoding beam search is employed to find the best alignment path together with the predicted output sequence. Our model tackles the bottleneck of vanilla encoder-decoders that have to read and memorize the entire input sequence in their fixedlength hidden states before producing any output. It is different from previous attentive models in that, instead of treating the attention weights as output of a deterministic function, our model assigns attention weights to a sequential latent variable which can be marginalized out and permits online generation. Experiments on abstractive sentence summarization and morphological inflection show significant performance gains over the baseline encoder-decoders.",
            "output": [
                "Online Segment to Segment Neural Transduction"
            ]
        },
        {
            "id": "task1540-cb8ad0b30e7a409c9d5c287d88c7dbf4",
            "input": "There is an increasing consensus among researchers that making a computer emotionally intelligent with the ability to decode human affective states would allow a more meaningful and natural way of human-computer interactions (HCIs). One unobtrusive and non-invasive way of recognizing human affective states entails the exploration of how physiological signals vary under different emotional experiences. In particular, this paper explores the correlation between autonomically-mediated changes in multimodal body signals and discrete emotional states. In order to fully exploit the information in each modality, we have provided an innovative classification approach for three specific physiological signals including Electromyogram (EMG), Blood Volume Pressure (BVP) and Galvanic Skin Response (GSR). These signals are analyzed as inputs to an emotion recognition paradigm based on fusion of a series of weak learners. Our proposed classification approach showed 88.1% recognition accuracy, which outperformed the conventional Support Vector Machine (SVM) classifier with 17% accuracy improvement. Furthermore, in order to avoid information redundancy and the resultant over-fitting, a feature reduction method is proposed based on a correlation analysis to optimize the number of features required for training and validating each weak learner. Results showed that despite the feature space dimensionality reduction from 27 to 18 features, our methodology preserved the recognition accuracy of about 85.0%. This reduction in complexity will get us one step closer towards embedding this human emotion encoder in the wireless and wearable HCI platforms.",
            "output": [
                "Decoding Emotional Experience through Physiological Signal Processing"
            ]
        },
        {
            "id": "task1540-2a4aed0ebce14ea2ba33731dba1f02bf",
            "input": "Hybrid Probabilistic Programs (HPPs) are logic programs that allow the programmer to explicitly encode his knowledge of the de­ pendencies between events being described in the program. In this paper, we classify HPPs into three classes called H P P1, H P P2 and H P Pr, r 2: 3. For these classes, we pro­ vide three types of results for HPPs. First, we develop algorithms to compute the set of all ground consequences of an HPP. Then we provide algorithms and complexity results for the problems of entailment (\"Given an HPP P and a query Q as input, is Q a logical con­ sequence of P?\") and consistency (\"Given an HPP Pas input, is P consistent?\"). Our re­ sults provide a fine characterization of when polynomial algorithms exist for the above problems, and when these problems become intractable.",
            "output": [
                "Hybrid Probabilistic Programs: Algorithms and Complexity"
            ]
        },
        {
            "id": "task1540-8d057725f6ce4af29a8fcb71f6849833",
            "input": "How to build a machine learning method that can continuously gain structured visual knowledge by learning structured facts? Our goal in this paper is to address this question by proposing a problem setting, where training data comes as structured facts in images with different types including (1) objects(e.g., <boy>), (2) attributes (e.g., <boy,tall>), (3) actions (e.g., <boy, playing>), (4) interactions (e.g., <boy, riding, a horse >). Each structured fact has a semantic language view (e.g., < boy, playing>) and a visual view (an image with this fact). A human is able to efficiently gain visual knowledge by learning facts in a never ending process, and as we believe in a structured way (e.g., understanding “playing” is the action part of < boy, playing>, and hence can generalize to recognize <girl, playing > if just learn <girl> additionally). Inspired by human visual perception, we propose a model that is (1) able to learn a representation, we name as wild-card, which covers different types of structured facts, (2) could flexibly get fed with structured fact language-visual view pairs in a never ending way to gain more structured knowledge, (3) could generalize to unseen facts, and (4) allows retrieval of both the fact language view given the visual view (i.e., image) and vice versa. We also propose a novel method to generate hundreds of thousands of structured fact pairs from image caption data, which are necessary to train our model and can be useful for other applications.",
            "output": [
                "SHERLOCK: MODELING STRUCTURED KNOWLEDGE IN IMAGES"
            ]
        },
        {
            "id": "task1540-d341db7f48dc4f66b8906f1ee12f0de9",
            "input": "The paper introduces a new modular action language, ALM, and illustrates the methodology of its use. It is based on the approach of Gelfond and Lifschitz (1993; 1998) in which a high-level action language is used as a front end for a logic programming system description. The resulting logic programming representation is used to perform various computational tasks. The methodology based on existing action languages works well for small and even medium size systems, but is not meant to deal with larger systems that require structuring of knowledge. ALM is meant to remedy this problem. Structuring of knowledge in ALM is supported by the concepts of module (a formal description of a specific piece of knowledge packaged as a unit), module hierarchy, and library, and by the division of a system description of ALM into two parts: theory and structure. A theory consists of one or more modules with a common theme, possibly organized into a module hierarchy based on a dependency relation. It contains declarations of sorts, attributes, and properties of the domain together with axioms describing them. Structures are used to describe the domain’s objects. These features, together with the means for defining classes of a domain as special cases of previously defined ones, facilitate the stepwise development, testing, and readability of a knowledge base, as well as the creation of knowledge representation libraries.",
            "output": [
                "Modular Action Language ALM"
            ]
        },
        {
            "id": "task1540-e2995ae9cda94df498f340e8e237106e",
            "input": "Modern distributed cyber-physical systems encounter a large variety of anomalies and in many cases, they are vulnerable to catastrophic fault propagation scenarios due to strong connectivity among the sub-systems. In this regard, root-cause analysis becomes highly intractable due to complex fault propagation mechanisms in combination with diverse operating modes. This paper presents a new data-driven framework for root-cause analysis for addressing such issues. The framework is based on a spatiotemporal feature extraction scheme for multivariate time series built on the concept of symbolic dynamics for discovering and representing causal interactions among subsystems of a complex system. We propose sequential state switching (S) and artificial anomaly association (A) methods to implement rootcause analysis in an unsupervised and semi-supervised manner respectively. Synthetic data from cases with failed pattern(s) and anomalous node are simulated to validate the proposed approaches, then compared with the performance of vector autoregressive (VAR) model-based root-cause analysis. The results show that: (1) S andA approaches can obtain high accuracy in root-cause analysis and successfully handle multiple nominal operation modes, and (2) the proposed tool-chain is shown to be scalable while maintaining high accuracy.",
            "output": [
                "Root-cause analysis for time-series anomalies via spatiotemporal causal graphical modeling"
            ]
        },
        {
            "id": "task1540-78b6b6504ab94b88ac658b699c39f550",
            "input": "To improve user satisfaction, mobile app developers are interested in relevant user opinions such as complaints or suggestions. An important source for such opinions is user reviews on online app markets. However, manual review analysis for useful opinions is often challenging due to the large amount and the noisy-nature of user reviews. To address this problem, we propose M.A.R.K, a keyword-based framework for semiautomated review analysis. The key task of M.A.R.K is to analyze reviews for keywords of potential interest which developers can use to search for useful opinions. We have developed several techniques for that task including: 1) keyword extracting with customized regularization algorithms; 2) keyword grouping with distributed representation; and 3) keyword ranking with ratings and frequencies analysis. Our empirical evaluation and case studies show that M.A.R.K can identify keywords of high interest and provide developers with useful user opinions. Keywords—App Review, Opinion Mining, Keyword",
            "output": [
                "Mining User Opinions in Mobile App Reviews: A Keyword-based Approach"
            ]
        },
        {
            "id": "task1540-b1077466d0f14ff38ff0d025289f7288",
            "input": "This paper develops automated testing and debugging techniques for answer set solver development. We describe a flexible grammar-based black-box ASP fuzz testing tool which is able to reveal various defects such as unsound and incomplete behavior, i.e. invalid answer sets and inability to find existing solutions, in state-of-the-art answer set solver implementations. Moreover, we develop delta debugging techniques for shrinking failureinducing inputs on which solvers exhibit defective behavior. In particular, we develop a delta debugging algorithm in the context of answer set solving, and evaluate two different elimination strategies for the algorithm.",
            "output": [
                "Testing and Debugging Techniques for Answer Set Solver Development"
            ]
        },
        {
            "id": "task1540-81d00ac0ae754b91b3b550bb37f44064",
            "input": "The key issues pertaining to collection of epidemic disease data for our analysis purposes are that it is a labour intensive, time consuming and expensive process resulting in availability of sparse sample data which we use to develop prediction models. To address this sparse data issue, we present novel Incremental Transductive methods to circumvent the data collection process by applying previously acquired data to provide consistent, confidence-based labelling alternatives to field survey research. We investigated various reasoning approaches for semisupervised machine learning including Bayesian models for labelling data. The results show that using the proposed methods, we can label instances of data with a class of vector density at a high level of confidence. By applying the Liberal and Strict Training Approaches, we provide a labelling and classification alternative to standalone algorithms. The methods in this paper are components in the process of reducing the proliferation of the Schistosomiasis disease and its effects.",
            "output": [
                "Incremental Transductive Learning Approaches to Schistosomiasis Vector Classification"
            ]
        },
        {
            "id": "task1540-219a6e8b615c466bbe7fe93714ef2ef5",
            "input": "Assessing uncertainty is an important step towards ensuring the safety and reliability of machine learning systems. Existing uncertainty estimation techniques may fail when their modeling assumptions are not met, e.g. when the data distribution differs from the one seen at training time. Here, we propose techniques that assess a classification algorithm’s uncertainty via calibrated probabilities (i.e. probabilities that match empirical outcome frequencies in the long run) and which are guaranteed to be reliable (i.e. accurate and calibrated) on out-of-distribution input, including input generated by an adversary. This represents an extension of classical online learning that handles uncertainty in addition to guaranteeing accuracy under adversarial assumptions. We establish formal guarantees for our methods, and we validate them on two real-world problems: question answering and medical diagnosis from genomic data.",
            "output": [
                "Estimating Uncertainty Online Against an Adversary"
            ]
        },
        {
            "id": "task1540-14a51577e706408890dbdbcf715f0f8d",
            "input": "The goal of argumentation mining, an evolving research field in computational linguistics, is to design methods capable of analyzing people’s argumentation. In this article, we go beyond the state of the art in several ways. (i) We deal with actual Web data and take up the challenges given by the variety of registers, multiple domains, and unrestricted noisy user-generated Web discourse. (ii) We bridge the gap between normative argumentation theories and argumentation phenomena encountered in actual data by adapting an argumentation model tested in an extensive annotation study. (iii) We create a new gold standard corpus (90k tokens in 340 documents) and experiment with several machine learning methods to identify argument components. We offer the data, source codes, and annotation guidelines to the community under free licenses. Our findings show that argumentation mining in user-generated Web discourse is a feasible but challenging task.",
            "output": [
                "Argumentation Mining in User-Generated Web Discourse"
            ]
        },
        {
            "id": "task1540-efdae6f7317849db9a1341aef15fbeac",
            "input": "Researches have shown accent classification can be improved by integrating semantic information into pure acoustic approach. In this work, we combine phonetic knowledge, such as vowels, with enhanced acoustic features to build an improved accent classification system. The classifier is based on Gaussian Mixture Model-Universal Background Model (GMM-UBM), with normalized Perceptual Linear Predictive (PLP) features. The features are further optimized by Principle Component Analysis (PCA) and Hetroscedastic Linear Discriminant Analysis (HLDA). Using 7 major types of accented speech from the Foreign Accented English (FAE) corpus, the system achieves classification accuracy 54% with input test data as short as 20 seconds, which is competitive to the state of the art in this field.",
            "output": [
                "Improved Accent Classification Combining Phonetic Vowels with Acoustic Features"
            ]
        },
        {
            "id": "task1540-cec49fb48ebf4acc881015fc818a0f33",
            "input": "Solving sequential decision making problems, such as text parsing, robotic<lb>control, and game playing, requires a combination of planning policies and gen-<lb>eralisation of those plans. In this paper, we present Expert Iteration, a novel al-<lb>gorithm which decomposes the problem into separate planning and generalisation<lb>tasks. Planning new policies is performed by tree search, while a deep neural net-<lb>work generalises those plans. In contrast, standard Deep Reinforcement Learning<lb>algorithms rely on a neural network not only to generalise plans, but to discover<lb>them too. We show that our method substantially outperforms Policy Gradients in<lb>the board game Hex, winning 84.4% of games against it when trained for equal<lb>time.",
            "output": [
                "Thinking Fast and Slow with Deep Learning and Tree Search"
            ]
        },
        {
            "id": "task1540-8f45a16c58104cbe9f846685c94e8d8c",
            "input": "Structured learning has found many applications in computer vision recently. Analogues to structured support vector machines (SSVM), here we propose boosting algorithms for predicting multivariate or structured outputs, which is referred to as StructBoost. As SSVM generalizes SVM, our StructBoost generalizes standard boosting such as AdaBoost, or LPBoost to structured learning. AdaBoost, LPBoost and many other conventional boosting methods arise as special cases of StructBoost. The resulting optimization problem of StructBoost is more challenging than SSVM in the sense that the problem of StructBoost can involve exponentially many variables and constraints. In contrast, for SSVM one usually has an exponential number of constraints and a cutting-plane method is used. In order to efficiently solve StructBoost, we propose an equivalent 1-slack formulation and solve it using a combination of cutting planes and column generation. We show the versatility and usefulness of StructBoost on a few problems such as hierarchical multi-class classification, robust visual tracking and image segmentation. In particular, we train a tracking-by-detection based object tracker using the proposed structured boosting. Tracking is implemented as structured output prediction by maximizing the Pascal image area overlap criterion. We show that the structural tracker not only significantly outperforms conventional classification based trackers that do not directly optimize the Pascal image overlap criterion, but also outperforms many other state-of-the-art trackers on the tested videos.",
            "output": [
                "StructBoost: Boosting Methods for Predicting Structured Output Variables"
            ]
        },
        {
            "id": "task1540-685ee749a5d7459482ff8e95a855a266",
            "input": "In situ hybridisation gene expression information helps biologists identify where a gene is expressed. However, the databases that republish the experimental information are often both incomplete and inconsistent. This paper examines a system, Argudas, designed to help tackle these issues. Argudas is an evolution of an existing system, and so that system is reviewed as a means of both explaining and justifying the behaviour of Argudas. Throughout the discussion of Argudas a number of issues will be raised including the appropriateness of argumentation in biology and the challenges faced when integrating apparently similar online biological databases.",
            "output": [
                "Argudas: arguing with gene expression information"
            ]
        },
        {
            "id": "task1540-5caf74f763274ee6a8e787123a5b3c82",
            "input": "Intrusion detection systems (IDSs) fall into two high-level categories: network-based systems (NIDS) that monitor network behaviors, and host-based systems (HIDS) that monitor system calls. In this work, we present a general technique for both systems. We use anomaly detection, which identifies patterns not conforming to a historic norm. In both types of systems, the rates of change vary dramatically over time (due to burstiness) and over components (due to service difference). To efficiently model such systems, we use continuous time Bayesian networks (CTBNs) and avoid specifying a fixed update interval common to discrete-time models. We build generative models from the normal training data, and abnormal behaviors are flagged based on their likelihood under this norm. For NIDS, we construct a hierarchical CTBN model for the network packet traces and use Rao-Blackwellized particle filtering to learn the parameters. We illustrate the power of our method through experiments on detecting real worms and identifying hosts on two publicly available network traces, the MAWI dataset and the LBNL dataset. For HIDS, we develop a novel learning method to deal with the finite resolution of system log file time stamps, without losing the benefits of our continuous time model. We demonstrate the method by detecting intrusions in the DARPA 1998 BSM dataset.",
            "output": [
                "Intrusion Detection using Continuous Time Bayesian Networks"
            ]
        },
        {
            "id": "task1540-2075d92d561743e5b35810b16a71e579",
            "input": "Motivated by applications in computational advertising and systems biology, we consider the problem of identifying the best out of several possible soft interventions at a source node V in an acyclic causal directed graph, to maximize the expected value of a target node Y (located downstream of V ). Our setting imposes a fixed total budget for sampling under various interventions, along with cost constraints on different types of interventions. We pose this as a best arm identification bandit problem with K arms where each arm is a soft intervention at V, and leverage the information leakage among the arms to provide the first gap dependent error and simple regret bounds for this problem. Our results are a significant improvement over the traditional best arm identification results. We empirically show that our algorithms outperform the state of the art in the Flow Cytometry data-set, and also apply our algorithm for model interpretation of the Inception-v3 deep net that classifies images.",
            "output": [
                "Identifying Best Interventions through Online Importance Sampling"
            ]
        },
        {
            "id": "task1540-84b3a122e1bf41f39ae66ae261b7861f",
            "input": "Semantic parsing has made significant progress, but most current semantic parsers are extremely slow (CKY-based) and rather primitive in representation. We introduce three new techniques to tackle these problems. First, we design the first linear-time incremental shift-reduce-style semantic parsing algorithm which is more efficient than conventional cubic-time bottom-up semantic parsers. Second, our parser, being type-driven instead of syntax-driven, uses type-checking to decide the direction of reduction, which eliminates the need for a syntactic grammar such as CCG. Third, to fully exploit the power of type-driven semantic parsing beyond simple types (such as entities and truth values), we borrow from programming language theory the concepts of subtype polymorphism and parametric polymorphism to enrich the type system in order to better guide the parsing. Our system learns very accurate parses in GEOQUERY, JOBS and ATIS domains.",
            "output": [
                "Type-Driven Incremental Semantic Parsing with Polymorphism"
            ]
        },
        {
            "id": "task1540-bcef4e0abb0043e5b2d0e2e391b39eb5",
            "input": "Minimum vertex cover problem is an NP-Hard problem with the aim of finding minimum number of vertices to cover graph. In this paper, a learning automaton based algorithm is proposed to find minimum vertex cover in graph. In the proposed algorithm, each vertex of graph is equipped with a learning automaton that has two actions in the candidate or noncandidate of the corresponding vertex cover set. Due to characteristics of learning automata, this algorithm significantly reduces the number of covering vertices of graph. The proposed algorithm based on learning automata iteratively minimize the candidate vertex cover through the update its action probability. As the proposed algorithm proceeds, a candidate solution nears to optimal solution of the minimum vertex cover problem. In order to evaluate the proposed algorithm, several experiments conducted on DIMACS dataset which compared to conventional methods. Experimental results show the major superiority of the proposed algorithm over the other methods. Keywords— Minimum Vertex Cover; NP-Hard problems; Learning Automata; Distributed learning automata.",
            "output": [
                "Solving Minimum Vertex Cover Problem Using Learning Automata"
            ]
        },
        {
            "id": "task1540-1e7c0143fb1d4a7f9ec213986fcb12b6",
            "input": "Citation texts are sometimes not very informative or in some cases inaccurate by themselves; they need the appropriate context from the referenced paper to re ect its exact contributions. To address this problem, we propose an unsupervised model that uses distributed representation of words as well as domain knowledge to extract the appropriate context from the reference paper. Evaluation results show the e ectiveness of our model by signi cantly outperforming the state-of-the-art. We furthermore demonstrate how an e ective contextualization method results in improving citation-based summarization of the scienti c articles.",
            "output": [
                "Contextualizing Citations for Scientific Summarization using Word Embeddings and Domain Knowledge"
            ]
        },
        {
            "id": "task1540-6492baf7ce264b9f9184a5c02ac446d5",
            "input": "This paper presents complexity analysis and variational methods for inference in probabilistic description logics featuring Boolean operators, quantification, qualified number restrictions, nominals, inverse roles and role hierarchies. Inference is shown to be PEXP-complete, and variational methods are designed so as to exploit logical inference whenever possible.",
            "output": [
                "Complexity Analysis and Variational Inference for Interpretation-based Probabilistic Description Logics"
            ]
        },
        {
            "id": "task1540-f1256fe76da243cab7efac36850f9523",
            "input": "The majority of big data is unstructured and of this majority the largest chunk is text. While data mining techniques are well developed and standardized for structured, numerical data, the realm of unstructured data is still largely unexplored. The general focus lies on “information extraction”, which attempts to retrieve known information from text. The “Holy Grail”, however is “knowledge discovery”, where machines are expected to unearth entirely new facts and relations that were not previously known by any human expert. Indeed, understanding the meaning of text is often considered as one of the main characteristics of human intelligence. The ultimate goal of semantic artificial intelligence is to devise software that can “understand” the meaning of free text, at least in the practical sense of providing new, actionable information condensed out of a body of documents. As a stepping stone on the road to this vision I will introduce a totally new approach to drug research, namely that of identifying relevant information by employing a self-organizing semantic engine to text mine large repositories of biomedical research papers, a technique pioneered by Merck with the InfoCodex software. I will describe the methodology and a first successful experiment for the discovery of new biomarkers and phenotypes for diabetes and obesity on the basis of PubMed abstracts, public clinical trials and Merck internal documents. The reported approach shows much promise and has potential to impact fundamentally pharmaceutical research as a way to shorten time-to-market of novel drugs, and for early recognition of dead ends. Big data: challenges and opportunities Rivers of ink have been poured to describe the data deluge that is increasingly defining our information society. While I do not want to dwell too long on something we all are experiencing daily, the concrete numbers are nonetheless staggering [1]. Here are some examples: Ø In 2007 more data have been accumulated than can fit on all of the world’s available storage. Ø In 2011 this number has reached the limit of twice as much data as can be stored on all of the world’s storage i.e. 1200 billions gigabytes. Ø The CMS detector at the CERN LHC accelerator accumulates data at a rate of 320 terabits/s, which makes it necessary to filter data by hardware “on the way” to reduce to flux to “only” 800 Gbp/s. Ø Wal-Mart feeds 1 million customer transaction/hour into its databases . Ø Internet: 1 trillion unique URLs have been indexed by Google. Ø 12.8 million blogs have been recently recorded, not counting Asia, this number is growing exponentially. Ø The number of emails sent per day in 2010 was 294 billion. Ø In 2008 Google received 85’000 CVs for the one single post of software engineer. These numbers pose huge challenges on both hardware and software. However, as is usually the case, challenges and opportunities go hand in hand. In this paper I shall concentrate on the opportunity side of the equation. Data come in two flavours: structured and unstructured. Structured data consist typically of numbers organized in structures, like tables, charts or series. Unstructured data are essentially everything else and make up around 85% [2] of the data deluge. Of these, the vast majority is text, the rest being pictures, video and sound tracks. In this paper I shall concentrate on text data. There is only one thing you can do with numbers: analyze them to discover relationships and dependencies. The basic method to do this is statistical analysis, whose development was initiated in the 17 century with the works of Pascal, Fermat, de Moivre, Laplace and Legendre and got new impetus in the late 19 and early 20 century from Sir Francis Galton and Karl Pearson [3]. Today, statistical analysis if often complemented by methods from computer science and information theory to detect unsuspected patterns and anomalies in very large databases, a technique that goes under the name of data mining [4]. While statistical analysis and data mining are complex and require trained specialists, unstructured data pose even bigger challenges. First of all there are two things you can do with text: teach machines to understand what the text in a given document means and have them “read” large quantities of text documents to uncover hidden, previously unnoticed correlations pointing to entire new knowledge. Both are very difficult but the latter is far more difficult than the former. Information extraction and knowledge discovery in research papers Understanding written language is a key component of human intelligence. Correspondingly, doing something useful with large quantities of text documents that are out of reach for human analysis requires, unavoidably some form of artificial intelligence [5]. This is why handling unstructured data is harder than analyzing their numerical counterpart, for which well-defined and developed mathematical methods are readily available. Indeed, there is as yet no standard approach to text mining, the unstructured counterpart to data mining. There are several approaches to teach a machine to comprehend text [6-8]. The vast bulk of research and applications focuses on natural language processing (NLP) techniques for information extraction (IE). Information extraction aims to identify mentions of named entities (e.g. “genes” in life science applications) and relationships between these entities (as in “is a” or “is caused by”). Entities and their relations are often called “triples” and databases of identified triples “triple stores”. Such triple stores are the basis of the Web 3.0 vision, in which machines will be able to automatically recognize the meaning of online documents and, correspondingly, interact intelligently with human end users. IE techniques are also the main tool used to curate domain-specific terminologies and ontologies extracted from large document corpora. Information extraction, however, is not thought for discovery. By its very design, it is limited to identifying semantic relationships that are explicitly lexicalized in a document: by definition these relations are known to the human expert who formulated them. The “Holy Grail” [9] of the text mining, instead is knowledge discovery from large corpora of text. Here one expects machines to generate novel hypotheses by uncovering previously unnoticed correlations from information distributed over very large pools of documents. These hypotheses must then be tested experimentally. Knowledge discovery is about unearthing implicit information versus the explicit relations recovered by information extraction. The present paper is about machine knowledge discovery in the biomedical and pharmacogenomics literature. 21 century challenges for pharmaceutical research Pharmaceutical research is undergoing a profound change. The deluge of molecular data and the advent of computational approaches to analyze them have revolutionized the traditional process of discovering drugs by happenstance in natural products or synthetizing and screening large libraries of small molecule compounds. Today, computational methods permeate so many aspects of pharmaceutical research that one can say that drugs are “designed” rather than “discovered” [10,11]. Molecular data found in genomics and proteomics databases are typically structured data. As in other domains, the bulk of the computational effort in the pharmaceutical industry goes into crunching structured molecular data. There is, however another, even larger source of valuable information that can potentially be tapped for discoveries: repositories of research documents. One of the best known of these repositories, PubMed, contains already more than 20 millions citations and these are growing at a once inconceivable rate of almost 2 papers/minute [12]. The value of the information in these repositories of research is huge. Each paper by itself constitutes typically a very focused study on one particular biomedical subject that can be easily comprehended by other experts in the same field. It is to be expected, however that there are also far-reaching correlations between the results of different papers or different groups of papers. Uncovering such hidden correlations by hand borders on the impossible since, first, the quantity of such papers is by now far beyond the reach of human analysis and, secondly, the expertise to understand papers in different areas of research is very hard to find in the same individual in today’s era of ever increasing specialization. The potential competitive advantage for the first companies to succeed in the task of discovering new scientific knowledge this way is considerable, both in speeding up research and in cutting costs. This is why machine knowledge discovery, if successful, has the potential to revolutionize pharmaceutical research. Not only could one test hypotheses in silico but the actual generation of these hypotheses would be in silico, with obvious disruptive advantages. Discovering biomarkers and phenotypes by text mining? To explore if this vision of a new way to generate scientific discovery by machine intelligence is feasible, Merck, in collaboration with Thomson Reuters, devised a pilot experiment in which the InfoCodex semantic engine was used for the specific and concrete task to discover unknown/novel biomarkers and phenotypes for diabetes and/or obesity (D&O) by text mining diverse and numerous biomedical research texts [13]. Here I will summarize the key points of the methods and the main results. The choice fell on biomarkers and phenotypes since these play a paramount role in modern medicine. Drugs of the future will be targeted to populations and groups of individuals with common biological characteristics predictive of drug efficacy and/or toxicity. This practice is called “individualized medicine” or “personalized medicine” [10]. The revealing features are called “biomarkers” and “phenotypes”. A biomarker is a characteristic that is objectively measured and evaluated as an indicator of normal biologic processes, pathogenic processes, or pharmacologic responses to a therapeutic intervention. In other words, a biomarker is any biological or biochemical entity or signal that is predictive, prognostic, or indicative of another entity, in this case, diabetes and/or obesity. A phenotype is an anatomical, physiological and behavioral characteristic observed as an identifiable structure or functional attribute of an organism. Phenotypes are important because phenotype-specific proteins are relevant targets in basic pharmaceutical research. Biomarkers and phenotypes constitute one of the “hot threads” of diagnostic and drug development in pharmaceutical and biomedical research, with applications in early disease identification, identification of potential drug targets, prediction of the response of patients to medications, help in accelerating clinical trials and personalized medicine. The biomarker market generated $13.6 billion in 2011 and is expected to grow to $25 billion by 2016 [14]. The object of the experiment was for the InfoCodex semantic engine to discover unknown/novel biomarkers and phenotypes for diabetes and/or obesity (D&O) by text mining a diverse and sizable corpus of unstructured, free-text biomedical research documents constituted by: • PubMed [15] abstracts with titles: 115,273 documents • Clinical Trials [16] summaries: 8,960 summaries • Internal Merck research documents, about one page in length: 500 documents. The output D&O related biomarkers and phenotypes proposed by the machine were then compared with Merck internal and external vocabularies/databases including UMLS [17], GenBank [18], Gene Ontology [19], OMIM [20], and the Thomson Reuters [21] D&O biomarker databases. By design, the experiment was handled strictly as a “blind experiment”: no expert input about D&O biomarkers/phenotypes was provided and no feedback from preliminary results was used to improve the machine-generated results. The InfoCodex semantic engine InfoCodex is a semantic machine intelligence software designed specifically to analyze very large document collections as a whole and thereby unearth associative, implicit and lexically unspecified relationships. It does so by unsupervised semantic clustering and matching of multi-lingual documents. Its technology is based on a combination of an embedded universal knowledge repository (the InfoCodex Linguistic Database, ILD), statistical analysis and information theory [22], and self-organizing neural networks (SOM) [23]. The ILD contains multi-lingual entries (words/phrases) collected into cross-lingual synonym groups (semantic clouds) and systematically linked to a hypernym (taxon) in a universal 7level taxonomy. With its almost 4 million classified entries, the ILD corresponds to a very large multi-lingual thesaurus (for comparison, the Historical Thesaurus of the English Oxford Dictionary, often considered the largest in the world, has 920,000 entries). Information theory and statistics [22] are used to establish a 100-dimensional content space defined on the ILD that describes the documents in an optimal way. Documents are then modeled as 100-dimensional vectors in this optimal semantic space. Information-theoretic concepts such as entropy and mutual entropy are used together with the ILD to disambiguate the meaning of polysemous words based both on the document-specific context and the collection-wide environment. Finally, the fully automatic, unsupervised categorization on the optimal semantic space is achieved by a proprietary variant of Kohonen’s self-organizing map [23]. In particular, prior to starting the unsupervised learning procedure, a coarse group rebalancing technique is used to construct a reliable initial guess for the SOM. This is a generalization of coarse mesh rebalancing [24] to general iterative procedures, with no reference to spatial equations as in the original application to neutron diffusion and general transport theory in finite element analysis. This procedure considerably accelerates the iteration process and minimizes the risk of getting stuck in a sub-optimal configuration. The SOM creates a thematic landscape according to and optimized for the thematic volume of the entire document collection. Essentially, the combination of the embedded ILD with the self-organized categorization on an automatically determined optimal semantic space correspond to a dynamic ontology, in which vertical “is-a” relations are encoded and horizontal relations like “is-correlated-with” are determined dynamically depending on content. For the comparison of the content of different documents with each other and with queries, a similarity measure is used which is composed of the scalar product of the document vectors in the 100-dimensional semantic space, the reciprocal Kullback–Leibler distance [25] from the main topics, and the weighted score-sum of common synonyms, common hypernyms and common nodes on higher taxonomy levels. As a final result, a document collection is grouped into a two-dimensional array of neurons called an information map. Each neuron corresponds to a semantic class; i.e., documents assigned to the same class are semantically similar. The classes are arranged in such a way that the thematically similar classes are nearby (Figure 1). Figure 1 InfoCodex information map. InfoCodex information map obtained for the approximately 115,000 documents of the PubMed repository used for the present experiment. The size of the dots in the center of each class indicate the number of documents assigned to it. The described InfoCodex algorithm is able to categorize unstructured information. In a recent benchmark, testing the classification of multi-lingual, “noisy” Web pages, InfoCodex reached the high clustering accuracy score F1 = 88% [26]. Moreover, it extracts relevant facts not only from single documents at hand, but it considers document collections as a whole and identifies dispersed and seemingly unrelated facts and relationships like assembling the scattered pieces of a puzzle. Text mining with InfoCodex in search of new biomarkers/phenotypes The text mining procedure involved four steps: Generation of reference models: in this step the software had to determine the meaning of the concept “biomarker/phenotype for D&O”. Since no input by human experts was allowed in the experiment, the only way to do this was by a generic literature search via the autonomous InfoCodex spider agents: 224 reference biomarkers/phenotypes were found. The documents containing these reference terms were then clustered by InfoCodex and for each group a representative feature vector in the optimal semantic space was established. These feature vectors constitute mathematical models on semantic space of what, e.g. “biomarker for diabetes” means. Determination of the meaning of unknown terms: the ILD contained at the time of the experiment about 20,000 genes and proteins (up to around 100’000 presently). Nonetheless it was not guaranteed to identify all possibly relevant candidates by a simple database look-up. Fortunately, the architecture of InfoCodex allows to infer the meaning of unknown terms by combining its “hard-wired” internal knowledge base with the association power of neural networks. Some examples of the meanings inferred by InfoCodex are presented in Table 1. Table 1: InfoCodex computed meanings Unknown Term Constructed Hypernym Associated Descriptor 1 Nn1250 clinical study insuline glargine Tolterodine cavity overactive bladder Ranibizumab drug macular edema Nn5401 clinical study insulin aspart Duloxetine antidepressant personal physician Endocannabinoid receptor enzyme Becaplermin pathology ulcer Candesartan cardiovascular disease high blood pressure Srt2104 medicine placebo Olmesartan cardiovascular medicine amlodipine Hctz diuretic drug hydrochlorothiazide Eslicarbazepine anti nervous Zebinix Zonisamide anti nervous Topiramate Capsules Mk0431 antidiabetic sitagliptin Ziprasidone tranquilizer major tranquilizer Psicofarmcolagia motivation incentive Medoxomil cardiovascular medicine amlodipine InfoCodex computed meanings of some unknown terms from the experimental PubMed collection. The meaning of unknown terms is estimated fully automatically; i.e., no human intervention was necessary and no context-specific vocabularies had to be provided as in most related approaches [27]. The meaning had to be inferred by the semantic engine only based on machine intelligence and its internal generic knowledge base, and this automatism is one of the main innovations of the presented approach. Some of the estimated hypernyms are completely correct: “Hctz” is a diuretic drug and is associated to “hydrochlorothiazide” (actually a synonym). Clearly, not all inferred semantic relations are of the same quality. Generation of a list of potential biomarkers and phenotypes: most of the reference biomarkers and phenotypes found in the literature (see Step 1) were linked to one of the following nodes of the ILD: genes, proteins, causal agents, hormones, phenotypes, metabolic disorders, diabetes, obesity, symptoms. The initial pool of candidates was constructed by considering each term appearing in the experimental document base that points to one of the same taxonomy nodes, whether via explicit hypernym relations in the ILD or via inferred hypernyms. For each of these candidates a group of experimental documents was formed by choosing those documents that contain a synonym of the candidate together with synonyms of “diabetes” or “obesity” and for each of these groups the InfoCodex feature vector in semantic space was constructed. The document group corresponding to one particular initial candidate is compared with the previously derived reference models for D&O biomarkers/phenotypes by computing the semantic distances to the feature vectors of the reference models. A term qualifies as a final candidate for a D&O biomarker or phenotype if the semantic similarity deviation from at least one of the corresponding reference clusters is below a certain threshold. Establishing confidence levels: not all the biomarker/phenotype candidates established this way have the same probability of being relevant. In order to rank the final candidates established in Step 3 an empirical score was devised, representing the confidence level of each term. This confidence measure is based on the average semantic deviation of the feature vector assigned to the candidate from the feature vector of the corresponding reference model and additional information-theoretic measures. Results of the experiment The output of the experiment was a list of potential D&O biomarkers/phenotypes as shown in Table 2. The candidate terms are listed in column A, with their relation to either diabetes or obesity in columns B and C. Columns D and E display the confidence level and the number of documents on which the identification of the candidate was based. Finally, the last columns contain the detailed IDs to these documents so that they can be retrieved and used by human experts for assessment. Note that human expert assessment is actually the only meaningful evaluation of the experiment as far as the novelty aspect of the proposed D&O biomarkers/phenotypes is concerned. Table 2: typical output of the experiment Row Term (A) Relationship (B) Object (C) Conf% (D) #Docs (E) PMIDs (F) 1 glycemic control BiomarkerFor Diabetes 70.3 1122 20110333, 20128112, 20149122, 2 Insulin PhenoTypeOf Diabetes 68.3 5000 19995096, 20017431, 20043582, 3 Proinsulin BiomarkerFor Diabetes 67.8 105 16108846, 9405904, 20139232, 4 TNF alpha inhibitor PhenoTypeOf Diabetes 67.1 245 9506740, 20025835, 20059414, 5 anhydroglucitol BiomarkerFor Diabetes 67.1 10 20424541, 20709052, 21357907, 6 linoleic acid BiomarkerFor Diabetes 67.1 61 20861175, 20846914, 15284064, 7 palmitic acid BiomarkerFor Diabetes 67.1 24 20861175, 20846914, 21437903, 8 pentosidine BiomarkerFor Diabetes 67.1 13 21447665, 21146883, 17898696, 9 uric acid BiomarkerFor Obesity 66.8 433 10726195, 19428063, 10904462, 10 proatrial natriuretic peptide BiomarkerFor Obesity 66.6 4 14769680, 18931036, 17351376, 11 ALT values BiomarkerFor Diabetes 66.3 2 20880180, 19010326 12 adrenomedullin BiomarkerFor Diabetes 64.3 7 21075100, 21408188, 20124980, 13 fructosamin BiomarkerFor Diabetes 64.2 59 20424541, 21054539, 18688079, 14 TNF alpha inhibitor BiomarkerFor Diabetes 62.1 245 9506740, 20025835, 20059414, 15 uric acid BiomarkerFor Diabetes 61.8 259 21431449, 20002472, 20413437, 16 monoclonal antibody BiomarkerFor Obesity 61.7 41 14715842, 21136440, 21042773, 17 Insulin level QTL PhenoTypeOf Obesity 61.2 1167 16614055, 19393079, 11093286, 18 stimulant BiomarkerFor Obesity 61.2 646 18407040, 18772043, 10082070, 19 IL-10 BiomarkerFor Obesity 60.9 120 19798061, 19696761, 20190550, 20 central obesity PhenoTypeOf Diabetes 59.5 530 16099342, 17141913, 15942464, 21 lipid BiomarkerFor Obesity 59.5 4279 11596664, 12059988, 12379160, 22 urine albumin screening BiomarkerFor Diabetes 59.0 95 20886205, 19285607, 20299482, 23 tyrosine kinase inhibitor BiomarkerFor Obesity 58.8 83 18814184, 9538268, 15235125, 24 TNF alpha inhibitor BiomarkerFor Obesity 58.0 785 20143002, 20173393, 10227565, 25 fas BiomarkerFor Obesity 57.7 179 12716789, 17925465, 19301503, 26 leptin PhenoTypeOf Diabetes 57.6 870 11987032, 17372717, 18414479, 27 ALT values BiomarkerFor Obesity 57.4 8 16408483, 19010326, 17255837, 28 lipase BiomarkerFor Obesity 56.8 356 16752181, 17609260, 20512427, 29 insulin resistance PhenoTypeOf Obesity 55.8 5000 20452774, 20816595, 21114489, 30 chronic inflammation PhenoTypeOf Diabetes 55.7 154 15643475, 18673007, 18801863, The details of the evaluation have been published elsewhere [13] and are beyond the scope of the present review. Here I would like to retain the two major conclusions that can be drawn. The negative aspect of the experiment is that too much noise was generated as exemplified by the obviously implausible or incomplete candidates proposed in Table 3. Table 3: implausible and/or incomplete D&O biomarker/phenotype candidates Term Relationship Object Target Conf% #Docs wenqing BiomarkerFor Obesity Obesity 53.5 29 proteomic BiomarkerFor Obesity Obesity 40.8 128 gene expression BiomarkerFor Obesity Obesity 38.9 62 Mouse model BiomarkerFor Obesity Obesity 19.8 17 muise BiomarkerFor Obesity Obesity 17.5 20 atheroBiomarkerFor Obesity Obesity 16.5 6 shrna BiomarkerFor Obesity Obesity 9.6 4 inflammation BiomarkerFor Obesity Obesity 8.2 4 TBD BiomarkerFor Obesity Obesity 7.4 3 body weight PhenoTypeOf Diabetes MGAT2 1 cell line BiomarkerFor Diabetes MGAT2 1 The very positive result, however, is that several candidates of very high quality were proposed by the software. These were considered as “needles in the haystack” by the Merck experts. While the plausibility of these candidates has been judged very high by human experts, a Google search of these terms in conjunction with “diabetes” and/or “obesity” produced extremely low hit rates, near or at zero, compared with hundreds of thousands for known D&O biomarkers/phenotypes. Unfortunately, these terms are considered as valuable proprietary information by Merck and cannot be shown openly, Table 4. Table 4: plausible, novel and very valuable D&O biomarker/phenotype candidates (hidden since considered valuable proprietary information by Merck) Term Relat. Object Target Conf% #Docs xxxxxx PhenoTypeOf\t\r   Obesity Obesity 7.7 4 xxxxxx PhenoTypeOf\t\r   Obesity Obesity 7 6 xxxxxx BiomarkerFor\t\r   Obesity Obesity 4.9 1 xxxxxx BiomarkerFor\t\r   Obesity Obesity 4.9 1 xxxxxx BiomarkerFor\t\r   Obesity Obesity 2.9 2 xxxxxx BiomarkerFor\t\r   Obesity Obesity 2.2 1 xxxxxx BiomarkerFor\t\r   Obesity Obesity 2.2 1 xxxxxx BiomarkerFor\t\r   Obesity Obesity 2.2 1 xxxxxx BiomarkerFor\t\r   Diabetes Diabetes 14.5 1 xxxxxx BiomarkerFor\t\r   Diabetes Diabetes 2.8 2 Compared with recent studies [28-31] aimed at the extraction of drug–gene relations from the pharmacogenomic literature, this experiment introduced three novelties. First, while most related work is based on high-quality, manually curated knowledge bases such as PharmGKB [30] to train the recognition of connections between specific drugs and genes, this experiment’s reference/training set (Step 1) was assembled in an ad hoc way by naïve (nonexpert) PubMed search. Second, aside from the generic taxonomy in the ILD, no contextspecific vocabularies (e.g., UMLS) were provided to inform the semantic engine. The meaning of unrecognized words had to be inferred by the InfoCodex engine based only on its universal internal linguistic database and its association power. Third, the text mining algorithms used here do not use rule-based approaches, or analyze co-occurrences sentence by sentence, or section by section, but rather they extract knowledge from entire documents and their relations with semantically related documents. In view of the requirement of no human assistance, the demonstrated capability of automatically identifying high quality candidates is extremely encouraging and could prove an entirely new way to speed-up pharmaceutical research, with high potential to shorten timeto-market of novel drugs, or for early recognition of dead ends such as prohibitive sideeffects through targeted extraction of relevant information.",
            "output": [
                "Scientific Discovery by Machine Intelligence: A New Avenue for Drug Research"
            ]
        },
        {
            "id": "task1540-dc6936a212c44b12bf7aaea17cc6f4b0",
            "input": "The ability to train large-scale neural networks has resulted in state-of-the-art performance in many areas of computer vision. These results have largely come from computational break throughs of two forms: model parallelism, e.g. GPU accelerated training, which has seen quick adoption in computer vision circles, and data parallelism, e.g. A-SGD, whose large scale has been used mostly in industry. We report early experiments with a system that makes use of both model parallelism and data parallelism, we call GPU A-SGD. We show using GPU A-SGD it is possible to speed up training of large convolutional neural networks useful for computer vision. We believe GPU A-SGD will make it possible to train larger networks on larger training sets in a reasonable amount of time.",
            "output": [
                "GPU Asynchronous Stochastic Gradient Descent to Speed Up Neural Network Training"
            ]
        },
        {
            "id": "task1540-3d4c1a28bec24a7ea9ec50483cff7b5f",
            "input": "Deep learning approaches have been widely used in Automatic Speech Recognition (ASR) and they have achieved a significant accuracy improvement. Especially, Convolutional Neural Networks (CNNs) have been revisited in ASR recently. However, most CNNs used in existing work have less than 10 layers which may not be deep enough to capture all human speech signal information. In this paper, we propose a novel deep and wide CNN architecture denoted as RCNN-CTC, which has residual connections and Connectionist Temporal Classification (CTC) loss function. RCNN-CTC is an endto-end system which can exploit temporal and spectral structures of speech signals simultaneously. Furthermore, we introduce a CTC-based system combination, which is different from the conventional frame-wise senone-based one. The basic subsystems adopted in the combination are different types and thus mutually complementary to each other. Experimental results show that our proposed single system RCNN-CTC can achieve the lowest word error rate (WER) on WSJ and Tencent Chat data sets, compared to several widely used neural network systems in ASR. In addition, the proposed system combination can offer a further error reduction on these two data sets, resulting in relative WER reductions of 14.91% and 6.52% on WSJ dev93 and Tencent Chat data sets respectively. ∗ Equal contribution.",
            "output": [
                "Residual Convolutional CTC Networks for Automatic Speech Recognition"
            ]
        },
        {
            "id": "task1540-b71f8bc65e6f4657b3bcbd12264c69ee",
            "input": "We show how to estimate a model’s test error from unlabeled data, on distributions very different from the training distribution, while assuming only that certain conditional independencies are preserved between train and test. We do not need to assume that the optimal predictor is the same between train and test, or that the true distribution lies in any parametric family. We can also efficiently differentiate the error estimate to perform unsupervised discriminative learning. Our technical tool is the method of moments, which allows us to exploit conditional independencies in the absence of a fully-specified model. Our framework encompasses a large family of losses including the log and exponential loss, and extends to structured output settings such as hidden Markov models.",
            "output": [
                "Unsupervised Risk Estimation Using Only Conditional Independence Structure"
            ]
        },
        {
            "id": "task1540-edc0a00aaaec421bb6b9c842e680e4cb",
            "input": "Instant messaging is one of the major channels of computer mediated communication. However, humans are known to be very limited in understanding others’ emotions via textbased communication. Aiming on introducing emotion sensing technologies to instant messaging, we developed EmotionPush, a system that automatically detects the emotions of the messages end-users received on Facebook Messenger and provides colored cues on their smartphones accordingly. We conducted a deployment study with 20 participants during a time span of two weeks. In this paper, we revealed five challenges, along with examples, that we observed in our study based on both user’s feedback and chat logs, including (i) the continuum of emotions, (ii) multi-user conversations, (iii) different dynamics between different users, (iv) misclassification of emotions, and (v) unconventional content. We believe this discussion will benefit the future exploration of affective computing for instant messaging, and also shed light on research of conversational emotion sensing.",
            "output": [
                "Challenges in Providing Automatic Affective Feedback in Instant Messaging Applications"
            ]
        },
        {
            "id": "task1540-318177eb622642bc9b5e6f6ce460689c",
            "input": "Multiple different approaches of generating adversarial examples have been proposed to attack deep neural networks. These approaches involve either directly computing gradients with respect to the image pixels, or directly solving an optimization on the image pixels. In this work, we present a fundamentally new method for generating adversarial examples that is fast to execute and provides exceptional diversity of output. We efficiently train feed-forward neural networks in a self-supervised manner to generate adversarial examples against a target network or set of networks. We call such a network an Adversarial Transformation Network (ATN). ATNs are trained to generate adversarial examples that minimally modify the classifier’s outputs given the original input, while constraining the new classification to match an adversarial target class. We present methods to train ATNs and analyze their effectiveness targeting a variety of MNIST classifiers as well as the latest state-of-the-art ImageNet classifier Inception ResNet v2.",
            "output": [
                "Adversarial Transformation Networks: Learning to Generate Adversarial Examples "
            ]
        },
        {
            "id": "task1540-a5468a537a1240ad9b69a97f8b5d0f06",
            "input": "We present a probabilistic generative model for inferring a description of coordinated, recursively structured group activities at multiple levels of temporal granularity based on observations of individuals’ trajectories. The model accommodates: (1) hierarchically structured groups, (2) activities that are temporally and compositionally recursive, (3) component roles assigning different subactivity dynamics to subgroups of participants, and (4) a nonparametric Gaussian Process model of trajectories. We present an MCMC sampling framework for performing joint inference over recursive activity descriptions and assignment of trajectories to groups, integrating out continuous parameters. We demonstrate the model’s expressive power in several simulated and complex real-world scenarios from the VIRAT and UCLA Aerial Event video data sets.",
            "output": [
                "Bayesian Inference of Recursive Sequences of Group Activities from Tracks"
            ]
        },
        {
            "id": "task1540-a55aa7849c974f76bd4392e5bb39e051",
            "input": "In practice, pattern recognition applications often suffer from imbalanced data distributions between classes, which may vary during operations w.r.t. the design data. Two-class classification systems designed using imbalanced data tend to recognize the majority (negative) class better, while the class of interest (positive class) often has the smaller number of samples. Several data-level techniques have been proposed to alleviate this issue, where classifier ensembles are designed with balanced data subsets by up-sampling positive samples or under-sampling negative samples. However, some informative samples may be neglected by random under-sampling and adding synthetic positive samples through up-sampling adds to training complexity. In this paper, a new ensemble learning algorithm called Progressive Boosting (PBoost) is proposed that progressively inserts uncorrelated groups of samples into a Boosting procedure to avoid loosing information while generating a diverse pool of classifiers. Base classifiers in this ensemble are generated from one iteration to the next, using subsets from a validation set that grows gradually in size and imbalance. Consequently, PBoost is more robust when the operational data may have unknown and variable levels of skew. In addition, the computation complexity of PBoost is lower than Boosting ensembles in literature that use under-sampling for learning from imbalanced data because not all of the base classifiers are validated on all negative samples. In PBoost algorithm, a new loss factor is proposed to avoid bias of performance towards the negative class. Using this loss factor, the weight update of samples and classifier contribution in final predictions are set based on the ability to recognize both classes. Using the proposed loss factor instead of standard accuracy can avoid biasing performance in any Boosting ensemble. The proposed approach was validated and compared using synthetic data, videos from the Faces In Action dataset that emulates face re-identification applications, and KEEL collection of datasets. Results show that PBoost can outperform state of the art techniques in terms of both accuracy and complexity over different levels of imbalance and overlap between classes.",
            "output": [
                "Progressive Boosting for Class Imbalance"
            ]
        },
        {
            "id": "task1540-255d121a3dac4e74a493eadd6dc4f454",
            "input": "© Scott A. Hale 2016. This is the author’s version of the work. It is posted here for your personal use. Not for redistribution. The definitive version was published in CHI EA 2016, http://dx.doi.org/10.1145/2851581.2892466. Abstract The number of user reviews of tourist attractions, restaurants, mobile apps, etc. is increasing for all languages; yet, research is lacking on how reviews in multiple languages should be aggregated and displayed. Speakers of different languages may have consistently different experiences, e.g., different information available in different languages at tourist attractions or different user experiences with software due to internationalization/localization choices. This paper assesses the similarity in the ratings given by speakers of different languages to London tourist attractions on TripAdvisor. The correlations between different languages are generally high, but some language pairs are more correlated than others. The results question the common practice of computing average ratings from reviews in many languages.",
            "output": [
                "User Reviews and Language: How Language Influences Ratings"
            ]
        },
        {
            "id": "task1540-07fb35dc62394bbfb9139a2c75c43f31",
            "input": "In order for robots to be integrated effectively into human work-flows, it is not enough to address the question of autonomy but also how their actions or plans are being perceived by their human counterparts. When robots generate task plans without such considerations, they may often demonstrate what we refer to as inexplicable behavior from the point of view of humans who may be observing it. This problem arises due to the human observer’s partial or inaccurate understanding of the robot’s deliberative process and/or the model (i.e. capabilities of the robot) that informs it. This may have serious implications on the human-robot work-space, from increased cognitive load and reduced trust in the robot from the human, to more serious concerns of safety in human-robot interactions. In this paper, we propose to address this issue by learning a distance function that can accurately model the notion of explicability, and develop an anytime search algorithm that can use this measure in its search process to come up with progressively explicable plans. As the first step, robot plans are evaluated by human subjects based on how explicable they perceive the plan to be, and a scoring function called explicability distance based on the different plan distance measures is learned. We then use this explicability distance as a heuristic to guide our search in order to generate explicable robot plans, by minimizing the plan distances between the robot’s plan and the human’s expected plans. We conduct our experiments in a toy autonomous car domain, and provide empirical evaluations that demonstrate the usefulness of the approach in making the planning process of an autonomous agent conform to human expectations.",
            "output": [
                "Explicable Robot Planning as Minimizing Distance from Expected Behavior"
            ]
        },
        {
            "id": "task1540-d67f09fffa934b0f902048c0229e4867",
            "input": "We propose a technique to augment network layers by adding a linear gating mechanism, which provides a way to learn identity mappings by optimizing only one parameter. We also introduce a new metric which served as basis for the technique. It captures the difficulty involved in learning identity mappings for different types of network models, and provides a new theoretical intuition for the increased depths of models such as Highway and Residual Networks. We propose a new model, the Gated Residual Network, which is the result when augmenting Residual Networks. Experimental results show that augmenting layers grants increased performance, less issues with depth, and more layer independence – fully removing them does not cripple the model. We evaluate our method on MNIST using fully-connected networks and on CIFAR-10 using Wide ResNets, achieving a relative error reduction of more than 8% in the latter when compared to the original model.",
            "output": [
                "LEARNING IDENTITY MAPPINGS WITH RESIDUAL GATES"
            ]
        },
        {
            "id": "task1540-71b85e37e87b46c29ee7f6c0d2bbb58e",
            "input": "We consider learning a sequence classifier without labeled data by using sequential output statistics. The problem is highly valuable since obtaining labels in training data is often costly, while the sequential output statistics (e.g., language models) could be obtained independently of input data and thus with low or no cost. To address the problem, we propose an unsupervised learning cost function and study its properties. We show that, compared to earlier works, it is less inclined to be stuck in trivial solutions and avoids the need for a strong generative model. Although it is harder to optimize in its functional form, a stochastic primal-dual gradient method is developed to effectively solve the problem. Experiment results on real-world datasets demonstrate that the new unsupervised learning method gives drastically lower errors than other baseline methods. Specifically, it reaches test errors about twice of those obtained by fully supervised learning.",
            "output": [
                "Unsupervised Sequence Classification using Sequential Output Statistics"
            ]
        },
        {
            "id": "task1540-5a6dbea51db44a5681563827bd434b45",
            "input": "Until now, error type performance for Grammatical Error Correction (GEC) systems could only be measured in terms of recall because system output is not annotated. In this paper, we overcome this problem by using a linguisticallyenhanced alignment to automatically extract the edits between parallel original and corrected sentences and then classify them using a new dataset-independent rule-based classifier. As human experts rated the predicted error types as “Good” or “Acceptable” in at least 95% of cases, we applied our approach to the system output produced in the CoNLL-2014 shared task to carry out a detailed analysis of system error type performance for the first time.",
            "output": [
                "Automatic Annotation and Evaluation of Error Types for Grammatical Error Correction"
            ]
        },
        {
            "id": "task1540-5b2f87f17acf4de4824c50dfa1cd5a54",
            "input": "This paper emphasizes the significance to jointly exploit the problem structure and the parameter structure, in the context of deep modeling. As a specific and interesting example, we describe the deep double sparsity encoder (DDSE), which is inspired by the double sparsity model for dictionary learning. DDSE simultaneously sparsities the output features and the learned model parameters, under one unified framework. In addition to its intuitive model interpretation, DDSE also possesses compact model size and low complexity. Extensive simulations compare DDSE with several carefully-designed baselines, and verify the consistently superior performance of DDSE. We further apply DDSE to the novel application domain of brain encoding, with promising preliminary results achieved.",
            "output": [
                "Deep Double Sparsity Encoder: Learning to Sparsify Not Only Features But Also Parameters"
            ]
        },
        {
            "id": "task1540-4abd6330dff94de880bca0ef7a13ba4d",
            "input": "During the last years, Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in image classification. Their architectures have largely drawn inspiration by models of the primate visual system. However, while recent research results of neuroscience prove the existence of non-linear operations in the response of complex visual cells, little effort has been devoted to extend the convolution technique to non-linear forms. Typical convolutional layers are linear systems, hence their expressiveness is limited. To overcome this, various non-linearities have been used as activation functions inside CNNs, while also many pooling strategies have been applied. We address the issue of developing a convolution method in the context of a computational model of the visual cortex, exploring quadratic forms through the Volterra kernels. Such forms, constituting a more rich function space, are used as approximations of the response profile of visual cells. Our proposed second-order convolution is tested on CIFAR-10 and CIFAR-100. We show that a network which combines linear and non-linear filters in its convolutional layers, can outperform networks that use standard linear filters with the same architecture, yielding results competitive with the state-of-the-art on these datasets.",
            "output": [
                "Non-linear Convolution Filters for CNN-based Learning"
            ]
        },
        {
            "id": "task1540-58977a559317436397921c3b76f351d2",
            "input": "In this paper, we present the results obtained by our DKP-AOM system within the OAEI 2015 campaign. DKPAOM is an ontology merging tool designed to merge heterogeneous ontologies. In OAEI, we have participated with its ontology mapping component which serves as a basic module capable of matching large scale ontologies before their merging. This is our first successful participation in the Conference, OA4QA and Anatomy track of OAEI. DKP-AOM is participating with two versions (DKP-AOM and DKP-AOM_lite), DKP-AOM performs coherence analysis. In OA4QA track, DKPAOM out-performed in the evaluation and generated accurate alignments allowed to answer all the queries of the evaluation. We can also see its competitive results for the conference track in the evaluation initiative among other reputed systems. In the anatomy track, it has produced alignments within an allocated time and appeared in the list of systems which produce coherent results. Finally, we discuss some future work towards the development of DKP-AOM.",
            "output": [
                "Initial results for Ontology Matching workshop 2015 DKP-AOM: results for OAEI 2015"
            ]
        },
        {
            "id": "task1540-bf85d4645c494a7493b10866ba93ffbd",
            "input": "We introduce a parametric nonlinear transformation that is well-suited for Gaussianizing data from natural images. After a linear transformation of the data, each component is normalized by a pooled activity measure, computed by exponentiating a weighted sum of rectified and exponentiated components and an additive constant. We optimize the parameters of this transformation (linear transform, exponents, weights, constant) over a database of natural images, directly minimizing the negentropy of the responses. We find that the optimized transformation successfully Gaussianizes the data, achieving a significantly smaller mutual information between transformed components than previous methods including ICA and radial Gaussianization. The transformation is differentiable and can be efficiently inverted, and thus induces a density model on images. We show that samples of this model are visually similar to samples of natural image patches. We also demonstrate the use of the model as a prior density in removing additive noise. Finally, we show that the transformation can be cascaded, with each layer optimized (unsupervised) using the same Gaussianization objective, to capture additional probabilistic structure.",
            "output": [
                "GENERALIZED NORMALIZATION TRANSFORMATION"
            ]
        },
        {
            "id": "task1540-4a18c5cf56d84dee835d27f7d0803343",
            "input": "We introduce the problem of Task Assignment and Sequencing (TAS), which adds the timeline perspective to expert crowdsourcing optimization. Expert crowdsourcing involves macrotasks, like document writing, product design, or web development, which take more time than typical binary microtasks, require expert skills, assume varying degrees of knowledge over a topic, and require crowd workers to build on each other’s contributions. Current works usually assume offline optimization models, which consider worker and task arrivals known and do not take into account the element of time. Realistically however, time is critical: tasks have deadlines, expert workers are available only at specific time slots, and worker/task arrivals are not known a-priori. Our work is the first to address the problem of optimal task sequencing for online, heterogeneous, time-constrained macrotasks. We propose tas-online, an online algorithm that aims to complete as many tasks as possible within budget, required quality and a given timeline, without future input information regarding job release dates or worker availabilities. Results, comparing tas-online to four typical benchmarks, show that it achieves more completed jobs, lower flow times and higher job quality. This work has practical implications for improving the Quality of Service of current crowdsourcing platforms, allowing them to offer cost, quality and time improvements for expert tasks.",
            "output": [
                "It’s about time: Online Macrotask Sequencing in Expert Crowdsourcing"
            ]
        },
        {
            "id": "task1540-54ff6cab8abd46539b5d5474810f168f",
            "input": "Metric learning seeks a transformation of the feature space that enhances prediction quality for the given task at hand. In this work we provide PAC-style sample complexity rates for supervised metric learning. We give matching lowerand upper-bounds showing that the sample complexity scales with the representation dimension when no assumptions are made about the underlying data distribution. However, by leveraging the structure of the data distribution, we show that one can achieve rates that are fine-tuned to a specific notion of intrinsic complexity for a given dataset. Our analysis reveals that augmenting the metric learning optimization criterion with a simple norm-based regularization can help adapt to a dataset’s intrinsic complexity, yielding better generalization. Experiments on benchmark datasets validate our analysis and show that regularizing the metric can help discern the signal even when the data contains high amounts of noise.",
            "output": [
                "Sample Complexity of Learning Mahalanobis Distance Metrics"
            ]
        },
        {
            "id": "task1540-5ebb0caa3dcb4a9bbca6704794e4a848",
            "input": "In this work, we propose a novel recurrent neural network (RNN) architecture. The proposed RNN, gated-feedback RNN (GF-RNN), extends the existing approach of stacking multiple recurrent layers by allowing and controlling signals flowing from upper recurrent layers to lower layers using a global gating unit for each pair of layers. The recurrent signals exchanged between layers are gated adaptively based on the previous hidden states and the current input. We evaluated the proposed GF-RNN with different types of recurrent units, such as tanh, long short-term memory and gated recurrent units, on the tasks of character-level language modeling and Python program evaluation. Our empirical evaluation of different RNN units, revealed that in both tasks, the GF-RNN outperforms the conventional approaches to build deep stacked RNNs. We suggest that the improvement arises because the GFRNN can adaptively assign different layers to different timescales and layer-to-layer interactions (including the top-down ones which are not usually present in a stacked RNN) by learning to gate these interactions.",
            "output": [
                "Gated Feedback Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-3544051dd22140cc950e5a7195d57a73",
            "input": "Recent work in learning vector-space embeddings for multi-relational data has focused on combining relational information derived from knowledge bases with distributional information derived from large text corpora. We propose a simple approach that leverages the descriptions of entities or phrases available in lexical resources, in conjunction with distributional semantics, in order to derive a better initialization for training relational models. Applying this initialization to the TransE model results in significant new stateof-the-art performances on the WordNet dataset, decreasing the mean rank from the previous best of 212 to 51. It also results in faster convergence of the entity representations. We find that there is a tradeoff between improving the mean rank and the hits@10 with this approach. This illustrates that much remains to be understood regarding performance improvements in relational models.",
            "output": [
                "Leveraging Lexical Resources for Learning Entity Embeddings in Multi-Relational Data"
            ]
        },
        {
            "id": "task1540-ef4be55473ac4b068988dec30128a219",
            "input": "Cross-lingual embedding models allow us to project words from different languages into a shared embedding space. This allows us to apply models trained on languages with a lot of data, e.g. English to low-resource languages. In the following, we will survey models that seek to learn cross-lingual embeddings. We will discuss them based on the type of approach and the nature of parallel data that they employ. Finally, we will present challenges and summarize how to evaluate cross-lingual embedding models. In recent years, driven by the success of word embeddings, many models that learn accurate representations of words haven been proposed [Mikolov et al., 2013a, Pennington et al., 2014]. However, these models are generally restricted to capture representations of words in the language they were trained on. The availability of resources, training data, and benchmarks in English leads to a disproportionate focus on the English language and a negligence of the plethora of other languages that are spoken around the world. In our globalised society, where national borders increasingly blur, where the Internet gives everyone equal access to information, it is thus imperative that we do not only seek to eliminate bias pertaining to gender or race [Bolukbasi et al., 2016] inherent in our representations, but also aim to address our bias towards language. To remedy this and level the linguistic playing field, we would like to leverage our existing knowledge in English to equip our models with the capability to process other languages. Perfect machine translation (MT) would allow this. However, we do not need to actually translate examples, as long as we are able to project examples into a common subspace such as the one in Figure 1. Figure 1: A shared embedding space between two languages [Luong et al., 2015] ∗This article originally appeared as a blog post at http://sebastianruder.com/ cross-lingual-embeddings/index.html on 28 November 2016. ar X iv :1 70 6. 04 90 2v 1 [ cs .C L ] 1 5 Ju n 20 17 Ultimately, our goal is to learn a shared embedding space between words in all languages. Equipped with such a vector space, we are able to train our models on data in any language. By projecting examples available in one language into this space, our model simultaneously obtains the capability to perform predictions in all other languages (we are glossing over some considerations here; for these, refer to Section 7. This is the promise of cross-lingual embeddings. Over the course of this survey, we will give an overview of models and algorithms that have been used to come closer to the elusive goal of capturing the relations between words in multiple languages in a common embedding space. Note that while neural MT approaches implicitly learn a shared cross-lingual embedding space by optimizing for the MT objective, we will focus on models that explicitly learn cross-lingual word representations throughout this blog post. These methods generally do so at a much lower cost than MT and can be considered to be to MT what word embedding models [Mikolov et al., 2013a, Pennington et al., 2014] are to language modelling. 1 Types of cross-lingual embedding models In recent years, various models for learning cross-lingual representations have been proposed. In the following, we will order them by the type of approach that they employ. Note that while the nature of the parallel data used is equally discriminatory and has been shown to account for inter-model performance differences [Levy et al., 2017], we consider the type of approach more conducive to understanding the assumptions a model makes and – consequently – its advantages and deficiencies. Cross-lingual embedding models generally use four different approaches: 1. Monolingual mapping: These models initially train monolingual word embeddings on large monolingual corpora. They then learn a linear mapping between monolingual representations in different languages to enable them to map unknown words from the source language to the target language. 2. Pseudo-cross-lingual: These approaches create a pseudo-cross-lingual corpus by mixing contexts of different languages. They then train an off-the-shelf word embedding model on the created corpus. The intuition is that the cross-lingual contexts allow the learned representations to capture cross-lingual relations. 3. Cross-lingual training: These models train their embeddings on a parallel corpus and optimize a cross-lingual constraint between embeddings of different languages that encourages embeddings of similar words to be close to each other in a shared vector space. 4. Joint optimization: These approaches train their models on parallel (and optionally monolingual data). They jointly optimise a combination of monolingual and cross-lingual losses. In terms of parallel data, methods may use different supervision signals that depend on the type of data used. These are, from most to least expensive: 1. Word-aligned data: A parallel corpus with word alignments that is commonly used for machine translation; this is the most expensive type of parallel data to use. 2. Sentence-aligned data: A parallel corpus without word alignments. If not otherwise specified, the model uses the Europarl corpus2 consisting of sentence-aligned text from the proceedings of the European parliament that is generally used for training Statistical Machine Translation models. 3. Document-aligned data: A corpus containing documents in different languages. The documents can be topic-aligned (e.g. Wikipedia) or label/class-aligned (e.g. sentiment analysis and multi-class classification datasets). 4. Lexicon: A bilingual or cross-lingual dictionary with pairs of translations between words in different languages. 5. No parallel data: No parallel data whatsoever. Learning cross-lingual representations from only monolingual resources would enable zero-shot learning across languages. http://www.statmt.org/europarl/",
            "output": [
                "A survey of cross-lingual embedding models∗"
            ]
        },
        {
            "id": "task1540-211785cf25f348048fb9bed0447f38b8",
            "input": "Aiming to unify known results about clustering mixtures of distributions under separation conditions, Kumar and Kannan [KK10] introduced a deterministic condition for clustering datasets. They showed that this single deterministic condition encompasses many previously studied clustering assumptions. More specifically, their proximity condition requires that in the target k-clustering, the projection of a point x onto the line joining its cluster center μ and some other center μ, is a large additive factor closer to μ than to μ. This additive factor can be roughly described as k times the spectral norm of the matrix representing the differences between the given (known) dataset and the means of the (unknown) target clustering. Clearly, the proximity condition implies center separation – the distance between any two centers must be as large as the above mentioned bound. In this paper we improve upon the work of Kumar and Kannan [KK10] along several axes. First, we weaken the center separation bound by a factor of √ k, and secondly we weaken the proximity condition by a factor of k (in other words, the revised separation condition is independent of k). Using these weaker bounds we still achieve the same guarantees when all points satisfy the proximity condition. Under the same weaker bounds, we achieve even better guarantees when only (1−ǫ)-fraction of the points satisfy the condition. Specifically, we correctly cluster all but a (ǫ + O(1/c))-fraction of the points, compared to O(kǫ)-fraction of [KK10], which is meaningful even in the particular setting when ǫ is a constant and k = ω(1). Most importantly, we greatly simplify the analysis of Kumar and Kannan. In fact, in the bulk of our analysis we ignore the proximity condition and use only center separation, along with the simple triangle and Markov inequalities. Yet these basic tools suffice to produce a clustering which (i) is correct on all but a constant fraction of the points, (ii) has k-means cost comparable to the k-means cost of the target clustering, and (iii) has centers very close to the target centers. Our improved separation condition allows us to match the results of the Planted Partition Model of McSherry [McS01], improve upon the results of Ostrovsky et al [ORSS06], and improve separation results for mixture of Gaussian models in a particular setting.",
            "output": [
                "Improved Spectral-Norm Bounds for Clustering"
            ]
        },
        {
            "id": "task1540-3590b7e23f904c33a74a6fd7ed27b574",
            "input": "Abstract. Random Forest (RF) is a powerful ensemble method for classification and regression tasks. It consists of decision trees set. Although, a single tree is well interpretable for human, the ensemble of trees is a black-box model. The popular technique to look inside the RF model is to visualize a RF proximity matrix obtained on data samples with Multidimensional Scaling (MDS) method. Herein, we present a novel method based on Self-Organising Maps (SOM) for revealing intrinsic relationships in data that lay inside the RF used for classification tasks. We propose an algorithm to learn the SOM with the proximity matrix obtained from the RF. The visualization of RF proximity matrix with MDS and SOM is compared. What is more, the SOM learned with the RF proximity matrix has better classification accuracy in comparison to SOM learned with Euclidean distance. Presented approach enables better understanding of the RF and additionally improves accuracy of the SOM.",
            "output": [
                "Visualizing Random Forest with Self-Organising Map"
            ]
        },
        {
            "id": "task1540-9dadb58b55b042ddacc8e7e3dd730685",
            "input": "In this age of information technology, information access in a convenient manner has gained importance. Since speech is a primary mode of communication among human beings, it is natural for people to expect to be able to carry out spoken dialogue with computer [1]. Speech recognition system permits ordinary people to speak to the computer to retrieve information. It is desirable to have a human computer dialogue in local language. Hindi being the most widely spoken Language in India is the natural primary human language candidate for human machine interaction. There are five pairs of vowels in Hindi languages; one member is longer than the other one. This paper describes an overview of speech recognition system. How speech is produced and the properties and characteristics of Hindi",
            "output": [
                "AN OVERVIEW OF HINDI SPEECH RECOGNITION"
            ]
        },
        {
            "id": "task1540-da75f00d31f84af79bf01822014df3cc",
            "input": "Traditional generative adversarial networks (GAN) and many of its variants are trained by minimizing the KL or JS-divergence loss that measures how close the generated data distribution is from the true data distribution. A recent advance called the WGAN based on Wasserstein distance can improve on the KL and JS-divergence based GANs, and alleviate the gradient vanishing, instability, and mode collapse issues that are common in the GAN training. In this work, we aim at improving on the WGAN by first generalizing its discriminator loss to a margin-based one, which leads to a better discriminator, and in turn a better generator, and then carrying out a progressive training paradigm involving multiple GANs to contribute to the maximum margin ranking loss so that the GAN at later stages will improve upon early stages. We call this method Gang of GANs (GoGAN). We have shown theoretically that the proposed GoGAN can reduce the gap between the true data distribution and the generated data distribution by at least half in an optimally trained WGAN. We have also proposed a new way of measuring GAN quality which is based on image completion tasks. We have evaluated our method on four visual datasets: CelebA, LSUN Bedroom, CIFAR-10, and 50K-SSFF, and have seen both visual and quantitative improvement over baseline WGAN.",
            "output": [
                "Gang of GANs: Generative Adversarial Networks with Maximum Margin Ranking"
            ]
        },
        {
            "id": "task1540-55830b4c88f549d5923f6e4e1817984e",
            "input": "We discuss the feasibility of the following learning problem: given unmatched samples from two domains and nothing else, learn a mapping between the two, which preserves semantics. Due to the lack of paired samples and without any definition of the semantic information, the problem might seem ill-posed. Specifically, in typical cases, it seems possible to build infinitely many alternative mappings from every target mapping. This apparent ambiguity stands in sharp contrast to the recent empirical success in solving this problem. A theoretical framework for measuring the complexity of compositions of functions is developed in order to show that the target mapping is of lower complexity than all other mappings. The measured complexity is directly related to the depth of the neural networks being learned and the semantic mapping could be captured simply by learning using architectures that are not much bigger than the minimal architecture.",
            "output": [
                "Unsupervised Learning of Semantic Mappings"
            ]
        },
        {
            "id": "task1540-4e825e7f409049f298e0bf4c1529584d",
            "input": "Recent work exhibited that distributed word representations are good at capturing linguistic regularities in language. This allows vector-oriented reasoning based on simple linear algebra between words. Since many different methods have been proposed for learning document representations, it is natural to ask whether there is also linear structure in these learned representations to allow similar reasoning at document level. To answer this question, we design a new document analogy task for testing the semantic regularities in document representations, and conduct empirical evaluations over several state-of-theart document representation models. The results reveal that neural embedding based document representations work better on this analogy task than conventional methods, and we provide some preliminary explanations over these observations.",
            "output": [
                "Semantic Regularities in Document Representations"
            ]
        },
        {
            "id": "task1540-f77bb7d258a0483e86f4b5cf4563be8f",
            "input": "This paper presents Centre for Development of Advanced Computing Mumbai’s (CDACM) submission to NLP Tools Contest on Statistical Machine Translation in Indian Languages (ILSMT) 2015 (collocated with ICON 2015). The aim of the contest was to collectively explore the effectiveness of Statistical Machine Translation (SMT) while translating within Indian languages and between English and Indian languages. In this paper, we report our work on all five language pairs, namely Bengali-Hindi (bn-hi), Marathi-Hindi (mrhi), Tamil-Hindi (ta-hi), Telugu-Hindi (tehi), and English-Hindi (en-hi) for Health, Tourism and General domains. We have used suffix separation, compound splitting and preordering prior to SMT training and testing.",
            "output": [
                "Statistical Machine Translation for Indian Languages: Mission Hindi 2"
            ]
        },
        {
            "id": "task1540-5f36de3940ae44a4be3978e80009d9a4",
            "input": "Rohit and I go back a long way. We started talking about Dynamic Logic back when I was a graduate student, when we would meet at seminars at MIT (my advisor Albert Meyer was at MIT, although I was at Harvard, and Rohit was then at Boston University). Right from the beginning I appreciated Rohit’s breadth, his quick insights, his wit, and his welcoming and gracious style. Rohit has been interested in the interplay between logic, philosophy, and language ever since I’ve known him. Over the years, both of us have gotten interested in game theory. I would like to dedicate this short note, which discusses issues at the intersection of all these areas, to him.",
            "output": [
                "Why Bother With Syntax?"
            ]
        },
        {
            "id": "task1540-3b92a2280aed4b40b7bd0fd2673786b4",
            "input": "The rapid growth of scientific literature has made it difficult for the researchers to quickly learn about the developments in their respective fields. Scientific document summarization addresses this challenge by providing summaries of the important contributions of scientific papers. We present a framework for scientific summarization which takes advantage of the citations and the scientific discourse structure. Citation texts often lack the evidence and context to support the content of the cited paper and are even sometimes inaccurate. We first address the problem of inaccuracy of the citation texts by finding the relevant context from the cited paper. We propose three approaches for contextualizing citations which are based on query reformulation, word embeddings, and supervised learning. We then train a model to identify the discourse facets for each citation. We finally propose a method for summarizing scientific papers by leveraging the faceted citations and their corresponding contexts. We evaluate our proposed method on two scientific summarization datasets in the biomedical and computational linguistics domains. Extensive evaluation results show that our methods can improve over the state of the art by large margins. ∗ This is a pre-print of an article published on IJDL. The final publication is available at Springer via http://dx.doi.org/10.1007/s00799-017-0216-8 Arman Cohan E-mail: arman@ir.cs.georgetown.edu Nazli Goharian E-mail: nazli@ir.cs.georgetown.edu 1 Information Retrieval Lab, Department of Computer Science, Georgetown University, Washington DC, USA",
            "output": [
                "Scientific document summarization via citation contextualization and scientific discourse"
            ]
        },
        {
            "id": "task1540-9a2eddc1af054c098f9b143c790165bf",
            "input": "The Region Connection Calculus (RCC) [41] is a well-known calculus for representing part-whole and topological relations. It plays an important role in qualitative spatial reasoning, geographical information science, and ontology. The computational complexity of reasoning with RCC5 and RCC8 (two fragments of RCC) as well as other qualitative spatial/temporal calculi has been investigated in depth in the literature. Most of these works focus on the consistency of qualitative constraint networks. In this paper, we consider the important problem of redundant qualitative constraints. For a set Γ of qualitative constraints, we say a constraint (xRy) in Γ is redundant if it is entailed by the rest of Γ. A prime subnetwork of Γ is a subset of Γ which contains no redundant constraints and has the same solution set as Γ. It is natural to ask how to compute such a prime subnetwork, and when it is unique. In this paper, we show that this problem is in general intractable, but becomes tractable if Γ is over a tractable subalgebra S of a qualitative calculus. Furthermore, if S is a subalgebra of RCC5 or RCC8 in which weak composition distributes over nonempty intersections, then Γ has a unique prime subnetwork, which can be obtained in cubic time by removing all redundant constraints simultaneously from Γ. As a byproduct, we show that any path-consistent network over such a distributive subalgebra is weakly globally consistent and minimal. A thorough empirical analysis of the prime subnetwork upon real geographical data sets demonstrates the approach is able to identify significantly more redundant con∗Corresponding Author Email addresses: sanjiang.li@uts.edu.au (Sanjiang Li), zhiguo.long@student.uts.edu.au (Zhiguo Long), liuweiming@baidu.com (Weiming Liu), matt@duckham.org (Matt Duckham), aboth@student.unimelb.edu.au (Alan Both) Preprint submitted to Elsevier February 16, 2015 ar X iv :1 40 3. 06 13 v2 [ cs .A I] 1 3 Fe b 20 15 straints than previously proposed algorithms, especially in constraint networks with larger proportions of partial overlap relations.",
            "output": [
                "On Redundant Topological Constraints"
            ]
        },
        {
            "id": "task1540-3e814ea1f04d48ef8bd9ff534fe89a63",
            "input": "Delay discounting, a behavioral measure of impulsivity, is often used to quantify the human tendency to choose a smaller, sooner reward (e.g., $1 today) over a larger, later reward ($2 tomorrow). Delay discounting and its relation to human decision making is a hot topic in economics and behavior science since pitting the demands of long-term goals against short term desires is among the most difficult tasks in human decision making [Hirsh et al., 2008]. Previously, small-scale studies based on questionnaires were used to analyze an individual’s delay discounting rate (DDR) and his/her realworld behavior (e.g., substance abuse) [Kirby et al., 1999]. In this research, we employ large-scale social media analytics to study DDR and its relation to people’s social media behavior (e.g., Facebook Likes). We also build computational models to automatically infer DDR from Social Media Likes. Our investigation has revealed interesting results.",
            "output": [
                "$1 Today or $2 Tomorrow? The Answer is in Your Facebook Likes"
            ]
        },
        {
            "id": "task1540-51aeeccc70344474a0ba4d1be0eb741c",
            "input": "We carefully study how well minimizing convex surrogate loss functions corresponds to minimizing the misclassification error rate for the problem of binary classification with linear predictors. We consider the agnostic setting, and investigate guarantees on the misclassification error of the loss-minimizer in terms of the margin error rate of the best predictor. We show that, aiming for such a guarantee, the hinge loss is essentially optimal among all convex losses.",
            "output": [
                "Minimizing The Misclassification Error Rate  Using a Surrogate Convex Loss"
            ]
        },
        {
            "id": "task1540-48e72cd2608741448fb0a23f4b18c780",
            "input": "This paper studies convolutional networks that require limited computational resources at test time. We develop a new network architecture that performs on par with state-of-the-art convolutional networks, whilst facilitating prediction in two settings: (1) an anytime-prediction setting in which the network’s prediction for one example is progressively updated, facilitating the output of a prediction at any time; and (2) a batch computational budget setting in which a fixed amount of computation is available to classify a set of examples that can be spent unevenly across “easier” and “harder” examples. Our network architecture uses multi-scale convolutions and progressively growing feature representations, which allows for the training of multiple classifiers at intermediate layers of the network. Experiments on three image-classification datasets demonstrate the efficacy of our architecture, in particular, when measured in terms of classification accuracy as a function of the amount of compute available.",
            "output": [
                "Multi-Scale Dense Convolutional Networks for Efficient Prediction"
            ]
        },
        {
            "id": "task1540-5053987bf1704c4a83948be5aaf7778b",
            "input": "We investigate the use of sparse coding and dictionary learning in the context of multitask and transfer learning. The central assumption of our learning method is that the tasks parameters are well approximated by sparse linear combinations of the atoms of a dictionary on a high or infinite dimensional space. This assumption, together with the large quantity of available data in the multitask and transfer learning settings, allows a principled choice of the dictionary. We provide bounds on the generalization error of this approach, for both settings. Numerical experiments on one synthetic and two real datasets show the advantage of our method over single task learning, a previous method based on orthogonal and dense representation of the tasks and a related method learning task grouping.",
            "output": [
                "Sparse coding for multitask and transfer learning"
            ]
        },
        {
            "id": "task1540-2b43b96f79ff4e77bfd4e8fee4eec30d",
            "input": "Classical Decision Theory provides a norma­ tive framework for representing and reason­ ing about complex preferences. Straightfor­ ward application of this theory to automate decision making is difficult due to high elic­ itation cost. In response to this problem, researchers have recently developed a num­ ber of qualitative, logic-oriented approaches for representing and reasoning about pref­ erences. While effectively addressing some expressiveness issues, these logics have not proven powerful enough for building practical automated decision making systems. In this paper we present a hybrid approach to pref­ erence elicitation and decision making that is grounded in class ical multi-attribute util­ ity theory, but can make effective use of the expressive power of qualitative approaches. Specifically, assuming a partially specified multilinear utility function, we show how comparative statements about class es of deci­ sion alternatives can be used to further con­ strain the utility function and thus identify sup-optimal alternatives. This work demon­ strates that quantitative and qualitative ap­ proaches can be synergistically integrated to provide effective and flexible decision sup­ port.",
            "output": [
                "A Hybrid Approach to Reasoning with Partially Elicited Preference Models"
            ]
        },
        {
            "id": "task1540-9bb1677fec814a4d852004a287b3fa00",
            "input": "We analyze and evaluate an online gradient descent algorithm with adaptive per-coordinate adjustment of learning rates. Our algorithm can be thought of as an online version of batch gradient descent with a diagonal preconditioner. This approach leads to regret bounds that are stronger than those of standard online gradient descent for general online convex optimization problems. Experimentally, we show that our algorithm is competitive with state-of-the-art algorithms for large scale machine learning problems.",
            "output": [
                "Less Regret via Online Conditioning"
            ]
        },
        {
            "id": "task1540-f85c741113da43f7836d6458ecfff5a2",
            "input": "We derive bounds on the sample complexity of empirical risk minimization (ERM) in the context of minimizing non-convex risks that admit the strict saddle property. Recent progress in non-convex optimization has yielded efficient algorithms for minimizing such functions. Our results imply that these efficient algorithms are statistically stable and also generalize well. In particular, we derive fast rates which resemble the bounds that are often attained in the strongly convex setting. We specify our bounds to Principal Component Analysis and Independent Component Analysis. Our results and techniquesmay pave the way for statistical analyses of additional strict saddle problems.",
            "output": [
                "Fast Rates for Empirical Risk Minimization of Strict Saddle Problems"
            ]
        },
        {
            "id": "task1540-f72dd8a4ab5143b7beda54b851306614",
            "input": "User preference integration is of great importance in multi-objective optimization, in particular in many objective optimization. Preferences have long been considered in traditional multicriteria decision making (MCDM) which is based on mathematical programming. Recently, it is integrated in multi-objective metaheuristics (MOMH), resulting in focus on preferred parts of the Pareto front instead of the whole Pareto front. The number of publications on preference-based multiobjective metaheuristics has increased rapidly over the past decades. There already exist various preference handling methods and MOMH methods, which have been combined in diverse ways. This article proposes to use the Web Ontology Language (OWL) to model and systematize the results developed in this field. A review of the existing work is provided, based on which an ontology is built and instantiated with state-of-the-art results. The OWL ontology is made public and open to future extension. Moreover, the usage of the ontology is exemplified for different usecases, including querying for methods that match an engineering application, bibliometric analysis, checking existence of combinations of preference models and MOMH techniques, and discovering opportunities for new research and open research questions.",
            "output": [
                "An Ontology of Preference-Based Multi-objective Metaheuristics"
            ]
        },
        {
            "id": "task1540-d3cd3e178dbd4e0ca5b8bcc7f5a08d21",
            "input": "Machine Learning has been a big success story during the AI resurgence. One particular stand out success relates to unsupervised learning from a massive amount of data, albeit much of it relates to one modality/type of data at a time. In spite of early assertions of the unreasonable effectiveness of data, there is increasing recognition of utilizing knowledge whenever it is available or can be created purposefully. In this paper, we focus on discussing the indispensable role of knowledge for deeper understanding of complex text and multimodal data in situations where (i) large amounts of training data (labeled/unlabeled) are not available or labour intensive to create, (ii) the objects (particularly text) to be recognized are complex (i.e., beyond simple entity – person/location/organization names), such as implicit entities and highly subjective content, and (iii) applications need to use complementary or related data in multiple modalities/media. What brings us to the cusp of rapid progress is our ability to (a) create knowledge, varying from comprehensive or cross domain to domain or application specific, and (b) carefully exploit the knowledge to further empower or extend the applications of ML/NLP techniques. Using the early results in several diverse situations – both in data types and applications – we seek to foretell unprecedented progress in our ability for deeper understanding and exploitation of multimodal data.",
            "output": [
                "Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples"
            ]
        },
        {
            "id": "task1540-32c3c330f49046b0a3518eb416898cae",
            "input": "In a composite-domain task-completion dialogue system, a conversation agent often switches among multiple sub-domains before it successfully completes the task. Given such a scenario, a standard deep reinforcement learning based dialogue agent may suffer to find a good policy due to the issues such as: increased state and action spaces, high sample complexity demands, sparse reward and long horizon, etc. In this paper, we propose to use hierarchical deep reinforcement learning approach which can operate at different temporal scales and is intrinsically motivated to attack these problems. Our hierarchical network consists of two levels: the top-level meta-controller for subgoal selection and the low-level controller for dialogue policy learning. Subgoals selected by metacontroller and intrinsic rewards can guide the controller to effectively explore in the state-action space and mitigate the spare reward and long horizon problems. Experiments on both simulations and human evaluation show that our model significantly outperforms flat deep reinforcement learning agents in terms of success rate, rewards and user rating.",
            "output": [
                "Composite Task-Completion Dialogue System via Hierarchical Deep Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-bb32e2fc0bce46b3bbf0afdf41bac42b",
            "input": "We propose multi-way, multilingual neural machine translation. The proposed approach enables a single neural translation model to translate between multiple languages, with a number of parameters that grows only linearly with the number of languages. This is made possible by having a single attention mechanism that is shared across all language pairs. We train the proposed multiway, multilingual model on ten language pairs from WMT’15 simultaneously and observe clear performance improvements over models trained on only one language pair. In particular, we observe that the proposed model significantly improves the translation quality of low-resource language pairs.",
            "output": [
                "Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism"
            ]
        },
        {
            "id": "task1540-a1a90ccf75ad4e7491616924d288ca1d",
            "input": "We present Confidence-Based Autonomy (CBA), an interactive algorithm for policy learning from demonstration. The CBA algorithm consists of two components which take advantage of the complimentary abilities of humans and computer agents. The first component, Confident Execution, enables the agent to identify states in which demonstration is required, to request a demonstration from the human teacher and to learn a policy based on the acquired data. The algorithm selects demonstrations based on a measure of action selection confidence, and our results show that using Confident Execution the agent requires fewer demonstrations to learn the policy than when demonstrations are selected by a human teacher. The second algorithmic component, Corrective Demonstration, enables the teacher to correct any mistakes made by the agent through additional demonstrations in order to improve the policy and future task performance. CBA and its individual components are compared and evaluated in a complex simulated driving domain. The complete CBA algorithm results in the best overall learning performance, successfully reproducing the behavior of the teacher while balancing the tradeoff between number of demonstrations and number of incorrect actions during learning.",
            "output": [
                "Interactive Policy Learning through Confidence-Based Autonomy"
            ]
        },
        {
            "id": "task1540-070218d9cfca4a098a344d23ade024d8",
            "input": "In this paper we present an interface between a symbolic planner and a geometric task planner, which is different to a standard trajectory planner in that the former is able to perform geometric reasoning on abstract entities—tasks. We believe that this approach facilitates a more principled interface to symbolic planning, while also leaving more room for the geometric planner to make independent decisions. We show how the two planners could be interfaced, and how their planning and backtracking could be interleaved. We also provide insights for a methodology for using the combined system, and experimental results to use as a benchmark with future extensions to both the combined system, as well as to the geometric task planner.",
            "output": [
                "Towards Combining HTN Planning and Geometric Task Planning"
            ]
        },
        {
            "id": "task1540-eeadd87c0a584b03a33ad3e7665b06fb",
            "input": "To cope with changing environments, recent developments in online learning have introduced the concepts of adaptive regret and dynamic regret independently. In this paper, we illustrate an intrinsic connection between these two concepts by showing that the dynamic regret can be expressed in terms of the adaptive regret and the functional variation. This observation implies that strongly adaptive algorithms can be directly leveraged to minimize the dynamic regret. As a result, we present a series of strongly adaptive algorithms whose dynamic regrets are minimax optimal for convex functions, exponentially concave functions, and strongly convex functions, respectively. To the best of our knowledge, this is the first time that such kind of dynamic regret bound is established for exponentially concave functions. Moreover, all of those adaptive algorithms do not need any prior knowledge of the functional variation, which is a significant advantage over previous specialized methods for minimizing dynamic regret.",
            "output": [
                "Strongly Adaptive Regret Implies Optimally Dynamic Regret"
            ]
        },
        {
            "id": "task1540-89b844de77d141139f4960e8045529e5",
            "input": "This paper proposes CF-NADE, a neural autoregressive architecture for collaborative filtering (CF) tasks, which is inspired by the Restricted Boltzmann Machine (RBM) based CF model and the Neural Autoregressive Distribution Estimator (NADE). We first describe the basic CF-NADE model for CF tasks. Then we propose to improve the model by sharing parameters between different ratings. A factored version of CF-NADE is also proposed for better scalability. Furthermore, we take the ordinal nature of the preferences into consideration and propose an ordinal cost to optimize CF-NADE, which shows superior performance. Finally, CF-NADE can be extended to a deep model, with only moderately increased computational complexity. Experimental results show that CF-NADE with a single hidden layer beats all previous state-of-the-art methods on MovieLens 1M, MovieLens 10M, and Netflix datasets, and adding more hidden layers can further improve the performance.",
            "output": [
                "A Neural Autoregressive Approach to Collaborative Filtering"
            ]
        },
        {
            "id": "task1540-23b27502242c4743999cd67bee630c04",
            "input": "Assessing network security is a complex and difficult task. Attack graphs have been proposed as a tool to help network administrators understand the potential weaknesses of their networks. However, a problem has not yet been addressed by previous work on this subject; namely, how to actually execute and validate the attack paths resulting from the analysis of the attack graph. In this paper we present a complete PDDL representation of an attack model, and an implementation that integrates a planner into a penetration testing tool. This allows to automatically generate attack paths for penetration testing scenarios, and to validate these attacks by executing the corresponding actions -including exploitsagainst the real target network. We present an algorithm for transforming the information present in the penetration testing tool to the planning domain, and we show how the scalability issues of attack graphs can be solved using current planners. We include an analysis of the performance of our solution, showing how our model scales to medium-sized networks and the number of actions available in current penetration testing tools.",
            "output": [
                "Attack Planning in the Real World"
            ]
        },
        {
            "id": "task1540-9b1e8251ea4e412a82d4fa7eeab3a5b7",
            "input": "Heuristics used for solving hard real-time search problems have regions with depressions. Such regions are bounded areas of the search space in which the heuristic function is inaccurate compared to the actual cost to reach a solution. Early real-time search algorithms, like LRTA∗, easily become trapped in those regions since the heuristic values of their states may need to be updated multiple times, which results in costly solutions. State-of-the-art real-time search algorithms, like LSS-LRTA∗ or LRTA∗(k), improve LRTA∗’s mechanism to update the heuristic, resulting in improved performance. Those algorithms, however, do not guide search towards avoiding depressed regions. This paper presents depression avoidance, a simple real-time search principle to guide search towards avoiding states that have been marked as part of a heuristic depression. We propose two ways in which depression avoidance can be implemented: mark-and-avoid and move-to-border. We implement these strategies on top of LSS-LRTA∗ and RTAA∗, producing 4 new real-time heuristic search algorithms: aLSS-LRTA∗, daLSS-LRTA∗, aRTAA∗, and daRTAA∗. When the objective is to find a single solution by running the real-time search algorithm once, we show that daLSS-LRTA∗ and daRTAA∗ outperform their predecessors sometimes by one order of magnitude. Of the four new algorithms, daRTAA∗ produces the best solutions given a fixed deadline on the average time allowed per planning episode. We prove all our algorithms have good theoretical properties: in finite search spaces, they find a solution if one exists, and converge to an optimal after a number of trials.",
            "output": [
                "Avoiding and Escaping Depressions in Real-Time Heuristic Search"
            ]
        },
        {
            "id": "task1540-77b77fdabe864e06938bac12199a239a",
            "input": "The margin of victory is easy to compute for many election schemes but difficult for Instant Runoff Voting (IRV). This is important because arguments about the correctness of an election outcome usually rely on the size of the electoral margin. For example, risk-limiting audits require a knowledge of the margin of victory in order to determine how much auditing is necessary. This paper presents a practical branch-and-bound algorithm for exact IRV margin computation that substantially improves on the current best-known approach. Although exponential in the worst case, our algorithm runs efficiently in practice on all the real examples we could find. We can efficiently discover exact margins on election instances that cannot be solved by the current state-of-the-art.",
            "output": [
                "Efficient Computation of Exact IRV Margins"
            ]
        },
        {
            "id": "task1540-020d5a21386e4c038a1ec8bd76f8f8ca",
            "input": "Most state-of-the-art named entity recognition (NER) systems rely on the use of handcrafted features and on the output of other NLP tasks such as part-of-speech (POS) tagging and text chunking. In this work we propose a language-independent NER system that uses automatically learned features only. Our approach is based on the CharWNN deep neural network, which uses word-level and character-level representations (embeddings) to perform sequential classification. We perform an extensive number of experiments using two annotated corpora in two different languages: HAREM I corpus, which contains texts in Portuguese; and the SPA CoNLL-2002, which contains texts in Spanish. Our experimental results shade light on the contribution of neural character embeddings for NER. Moreover, we demonstrate that the same neural network which has been successfully applied for POS tagging can also achieve state-of-the-art results for language-independet NER, using the same hyper-parameters, and without any handcrafted features. For the HAREM I corpus, CharWNN outperforms the state-of-the-art system by 7.9 points in the F1-score for the total scenario (ten NE classes), and by 7.2 points in the F1 for the selective scenario (five NE classes).",
            "output": [
                "Boosting Named Entity Recognition with Neural Character Embeddings"
            ]
        },
        {
            "id": "task1540-58f020aefab744629183b718c8435df4",
            "input": "The World Wide Web no longer consists just of HTML pages. Our work sheds light on a number of trends on the Internet that go beyond simple Web pages. The hidden Web provides a wealth of data in semi-structured form, accessible through Web forms and Web services. These services, as well as numerous other applications on the Web, commonly use XML, the eXtensible Markup Language. XML has become the lingua franca of the Internet that allows customized markups to be defined for specific domains. On top of XML, the Semantic Web grows as a common structured data source. In this work, we first explain each of these developments in detail. Using real-world examples from scientific domains of great interest today, we then demonstrate how these new developments can assist the managing, harvesting, and organization of data on the Web. On the way, we also illustrate the current research avenues in these domains. We believe that this effort would help bridge multiple database tracks, thereby attracting researchers with a view to extend database technology.",
            "output": [
                "The Hidden Web, XML and the Semantic Web: Scientific Data Management Perspectives"
            ]
        },
        {
            "id": "task1540-f72a1b8304064177be20f1138a3c24d0",
            "input": "Designing an e-commerce recommender system that serves hundreds of millions of active users is a daunting challenge. Ranking strategy as the key module needs to be more carefully designed. We find two key factors that affect users’ behaviors: attractive item content and compatibility with users’ interests. To extract these factors, a ranking model needs to understand users from a human vision perspective. This paper proposes Telepath, a vision-based architecture that simulates the human vision system to extract the key visual signals that attract users to a displayed item and generate vision activations and simulates cerebral cortex to understand users’ interest based on the captured activations from browsed items. Telepath is a combination of CNN, RNN and DNN. In practice, the Telepath model has been launched to JD’s online recommender system and advertising system. For one of the major item recommendation blocks on the JD app, CTR, GMV and orders have increased 1.59%, 8.16% and 8.71% respectively. For several major advertising publishers of JD DSP, CTR, GMV and ROI have increased 6.58%, 61.72% and 65.57% respectively by the first launch, and further increased 2.95%, 41.75% and 41.37% respectively by the second launch.",
            "output": [
                "Telepath: Understanding Users from a Human Vision Perspective in Large-Scale Recommender Systems"
            ]
        },
        {
            "id": "task1540-5b7b369018e8437f8e019c2089059ae0",
            "input": "Learning commonsense knowledge from natural language text is nontrivial due to reporting bias: people rarely state the obvious, e.g., “my house is bigger than me”. However, while rarely stated explicitly, this trivial everyday knowledge does influence the way people talk about the world, which provides indirect clues to reason about the world. For example, a statement like “John entered his house” implies that his house is bigger than John. In this paper, we present an approach to infer relative physical knowledge of actions and objects along six dimensions (e.g., size, weight, and strength) from unstructured natural language text. We frame knowledge acquisition as joint inference over two closely related problems: learning (1) relative physical knowledge of object pairs and (2) physical implications of actions when applied to those object pairs. Empirical results demonstrate that it is possible to extract knowledge of actions and objects from language and that joint inference over different knowledge types improves performance.",
            "output": [
                "Verb Physics: Relative Physical Knowledge of Actions and Objects"
            ]
        },
        {
            "id": "task1540-1f196173f930416a933c94285b5c5958",
            "input": "We propose a general information-theoretic approach called SERAPH (SEmi-supervised metRic leArning Paradigm with Hyper-sparsity) for metric learning that does not rely upon the manifold assumption. Given the probability parameterized by a Mahalanobis distance, we maximize the entropy of that probability on labeled data and minimize it on unlabeled data following entropy regularization, which allows the supervised and unsupervised parts to be integrated in a natural and meaningful way. Furthermore, SERAPH is regularized by encouraging a low-rank projection induced from the metric. The optimization of SERAPH is solved efficiently and stably by an EMlike scheme with the analytical E-Step and convex M-Step. Experiments demonstrate that SERAPH compares favorably with many well-known global and local metric learning methods.",
            "output": [
                "Information-theoretic Semi-supervised Metric Learningvia Entropy Regularization"
            ]
        },
        {
            "id": "task1540-b600d32d17174833bb6d5a68b53e8d75",
            "input": "The use of M-estimators in generalized linear regression models in high dimensional settings requires risk minimization with hard L0 constraints. Of the known methods, the class of projected gradient descent (also known as iterative hard thresholding (IHT)) methods is known to offer the fastest and most scalable solutions. However, the current state-of-the-art is only able to analyze these methods in extremely restrictive settings which do not hold in high dimensional statistical models. In this work we bridge this gap by providing the first analysis for IHT-style methods in the high dimensional statistical setting. Our bounds are tight and match known minimax lower bounds. Our results rely on a general analysis framework that enables us to analyze several popular hard thresholding style algorithms (such as HTP, CoSaMP, SP) in the high dimensional regression setting. We also extend our analysis to a large family of “fully corrective methods” that includes two-stage and partial hard-thresholding algorithms. We show that our results hold for the problem of sparse regression, as well as low-rank matrix recovery.",
            "output": [
                "On Iterative Hard Thresholding Methods for High-dimensional M-Estimation"
            ]
        },
        {
            "id": "task1540-e43ca89b2bbb43bfb3cee38a412fa3d9",
            "input": "A major task in systematic reviews is abstract screening, i.e., excluding, often hundreds or thousand of, irrelevant citations returned from a database search based on titles and abstracts. Thus, a systematic review platform that can automate the abstract screening process is of huge importance. Several methods have been proposed for this task. However, it is very hard to clearly understand the applicability of these methods in a systematic review platform because of the following challenges: (1) the use of non-overlapping metrics for the evaluation of the proposed methods, (2) usage of features that are very hard to collect, (3) using a small set of reviews for the evaluation, and (4) no solid statistical testing or equivalence grouping of the methods. In this paper, we use feature representation that can be extracted per citation. We evaluate SVM based methods (commonly used) on a large set of reviews (61) and metrics (11) to provide equivalence grouping of methods based on a solid statistical test. Our analysis also includes a strong variability of the metrics using 500x2 cross validation. While some methods shine for different metrics and for different datasets, there is no single method that dominates the pack. Furthermore, we observe that in some cases relevant (included) citations can be found after screening only 15-20% of them via a certainty based sampling. A few included citations present outlying characteristics and can only be found after a very large number of screening steps. Finally, we present an ensemble algorithm for producing a 5star rating of citations based on their relevance. Such algorithm combines the best methods from our evaluation and through its 5-star rating outputs a more easy-to-consume prediction.",
            "output": [
                "A large scale study of SVM based methods for abstract screening in systematic reviews*"
            ]
        },
        {
            "id": "task1540-98155329628f4c9e8f7832b462484a9d",
            "input": "Neural networks have recently been proposed for multi-label classification because they are able to capture and model label dependencies in the output layer. In this work, we investigate limitations of BP-MLL, a neural network (NN) architecture that aims at minimizing pairwise ranking error. Instead, we propose to use a comparably simple NN approach with recently proposed learning techniques for large-scale multi-label text classification tasks. In particular, we show that BP-MLL’s ranking loss minimization can be efficiently and effectively replaced with the commonly used cross entropy error function, and demonstrate that several advances in neural network training that have been developed in the realm of deep learning can be effectively employed in this setting. Our experimental results show that simple NN models equipped with advanced techniques such as rectified linear units, dropout, and AdaGrad perform as well as or even outperform state-of-the-art approaches on six large-scale textual datasets with diverse characteristics.",
            "output": [
                "Large-scale Multi-label Text Classification — Revisiting Neural Networks"
            ]
        },
        {
            "id": "task1540-2255c235d57448d1b529012bf544cba2",
            "input": "The cutting plane method is an augmentative constrained optimization procedure that is often used with continuous-domain optimization techniques such as linear and convex programs. We investigate the viability of a similar idea within message passing – which produces integral solutions in the context of two combinatorial problems: 1) For Traveling Salesman Problem (TSP), we propose a factor-graph based on Held-Karp formulation, with an exponential number of constraint factors, each of which has an exponential but sparse tabular form. 2) For graph-partitioning (a.k.a. community mining) using modularity optimization, we introduce a binary variable model with a large number of constraints that enforce formation of cliques. In both cases we are able to derive surprisingly simple message updates that lead to competitive solutions on benchmark instances. In particular for TSP we are able to find near-optimal solutions in the time that empirically grows with N, demonstrating that augmentation is practical and efficient.",
            "output": [
                "Augmentative Message Passing for Traveling Salesman Problem and Graph Partitioning"
            ]
        },
        {
            "id": "task1540-4340121953f74b94862d7435a2ff813e",
            "input": "We propose a framework grounded in Logic Programming for representing and reasoning about business processes from both the procedural and ontological point of views. In particular, our goal is threefold: (1) define a logical language and a formal semantics for process models enriched with ontology-based annotations; (2) provide an effective inference mechanism that supports the combination of reasoning services dealing with the structural definition of a process model, its behavior, and the domain knowledge related to the participating business entities; (3) implement such a theoretical framework into a process modeling and reasoning platform. To this end we define a process ontology coping with a relevant fragment of the popular BPMN modeling notation. The behavioral semantics of a process is defined as a state transition system by following an approach similar to the Fluent Calculus, and allows us to specify state change in terms of preconditions and effects of the enactment of activities. Then we show how the procedural process knowledge can be seamlessly integrated with the domain knowledge specified by using the OWL 2 RL rule-based ontology language. Our framework provides a wide range of reasoning services, including CTL model checking, which can be performed by using standard Logic Programming inference engines through a goal-oriented, efficient, sound and complete evaluation procedure. We also present a software environment implementing the proposed framework, and we report on an experimental evaluation of the system, whose results are encouraging and show the viability of the approach.",
            "output": [
                "Ontology-based Representation and Reasoning on Process Models: A Logic Programming Approach"
            ]
        },
        {
            "id": "task1540-63e9a41631b34837a37fe6b2a6e58ffa",
            "input": "This short paper concerns discretization schemes for representing and computing approximate Nash equilibria, with emphasis on graphical games, but briefly touching on normal-form and poly-matrix games. The main technical contribution is a representation theorem that informally states that to account for every exact Nash equilibrium using a nearby approximate Nash equilibrium on a grid over mixed strategies, a uniform discretization size linear on the inverse of the approximation quality and natural game-representation parameters suffices. For graphical games, under natural conditions, the discretization is logarithmic in the game-representation size, a substantial improvement over the linear dependency previously required. The paper has five other objectives: (1) given the venue, to highlight the important, but often ignored, role that work on constraint networks in AI has in simplifying the derivation and analysis of algorithms for computing approximate Nash equilibria; (2) to summarize the state-of-the-art on computing approximate Nash equilibria, with emphasis on relevance to graphical games; (3) to help clarify the distinction between sparse-discretization and sparse-support techniques; (4) to illustrate and advocate for the deliberate mathematical simplicity of the formal proof of the representation theorem; and (5) to list and discuss important open problems, emphasizing graphical-game generalizations, which the AI community is most suitable to solve.",
            "output": [
                "On Sparse Discretization for Graphical Games"
            ]
        },
        {
            "id": "task1540-63eec7df3a7643b6bbbdf21e048f9ae9",
            "input": "Automatic description generation from natural images is a challenging problem that has recently received a large amount of interest from the computer vision and natural language processing communities. In this survey, we classify the existing approaches based on how they conceptualize this problem, viz., models that cast description as either generation problem or as a retrieval problem over a visual or multimodal representational space. We provide a detailed review of existing models, highlighting their advantages and disadvantages. Moreover, we give an overview of the benchmark image datasets and the evaluation measures that have been developed to assess the quality of machine-generated image descriptions. Finally we extrapolate future directions in the area of automatic image description generation.",
            "output": [
                "Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures"
            ]
        },
        {
            "id": "task1540-91e0cd88a2144728a461a176b70f5bd9",
            "input": "We consider the stochastic approximation problem where a convex function has to be minimized, given only the knowledge of unbiased estimates of its gradients at certain points, a framework which includes machine learning methods based on the minimization of the empirical risk. We focus on problems without strong convexity, for which all previously known algorithms achieve a convergence rate for function values of O(1/ √",
            "output": [
                "Non-strongly-convex smooth stochastic approximation with convergence rate O(1/n)"
            ]
        },
        {
            "id": "task1540-dd4457cb09504580bae91f7cce2ff26c",
            "input": "In distributed classification, each learner observes its environment and deduces a classifier. As a learner has only a local view of its environment, classifiers can be exchanged among the learners and integrated, or merged, to improve accuracy. However, the operation of merging is not defined for most classifiers. Furthermore, the classifiers that have to be merged may be of different types in settings such as ad-hoc networks in which several generations of sensors may be creating classifiers. We introduce decision spaces as a framework for merging possibly different classifiers. We formally study the merging operation as an algebra, and prove that it satisfies a desirable set of properties. The impact of time is discussed for the two main data mining settings. Firstly, decision spaces can naturally be used with non-stationary distributions, such as the data collected by sensor networks, as the impact of a model decays over time. Secondly, we introduce an approach for stationary distributions, such as homogeneous databases partitioned over different learners, which ensures that all models have the same impact. We also present a method that uses storage flexibly to achieve different types of decay for non-stationary distributions. Finally, we show that the algebraic approach developed for merging can also be used to analyze the behaviour of other operators.",
            "output": [
                "An Algebra to Merge Heterogeneous Classifiers"
            ]
        },
        {
            "id": "task1540-6febae80305648b1ba564e50cf6b00bb",
            "input": "In the present paper we use principles of fuzzy logic to develop a general model representing several processes in a system’s operation characterized by a degree of vagueness and/or uncertainty. For this, the main stages of the corresponding process are represented as fuzzy subsets of a set of linguistic labels characterizing the system’s performance at each stage. We also introduce three alternative measures of a fuzzy system’s effectiveness connected to our general model. These measures include the system’s total possibilistic uncertainty, the Shannon’s entropy properly modified for use in a fuzzy environment and the “centroid” method in which the coordinates of the center of mass of the graph of the membership function involved provide an alternative measure of the system’s performance. The advantages and disadvantages of the above measures are discussed and a combined use of them is suggested for achieving a worthy of credit mathematical analysis of the corresponding situation. An application is also developed for the Mathematical Modelling process illustrating the use of our results in practice.",
            "output": [
                "A Study on Fuzzy Systems"
            ]
        },
        {
            "id": "task1540-61759a44f1fe45068767675cf8731626",
            "input": "Rapid increase of digitized document give birth to high demand of document image retrieval. While conventional document image retrieval approaches depend on complex OCR-based text recognition and text similarity detection, this paper proposes a new content-based approach, in which more attention is paid to features extraction and fusion. In the proposed approach, multiple features of document images are extracted by different CNN models. After that, the extracted CNN features are reduced and fused into weighted average feature. Finally, the document images are ranked based on feature similarity to a provided query image. Experimental procedure is performed on a group of document images that transformed from academic papers, which contain both English and Chinese document, the results show that the proposed approach has good ability to retrieve document images with similar text content, and the fusion of CNN features can effectively improve the retrieval accuracy.",
            "output": [
                "Content-based similar document image retrieval using fusion of CNN features"
            ]
        },
        {
            "id": "task1540-72f6970c0cdb4c0d99b9966205c95bb2",
            "input": "In this paper, we describe a dataset relating to cellular and physical conditions of patients who are operated upon to remove colorectal tumours. This data provides a unique insight into immunological status at the point of tumour removal, tumour classification and post-operative survival. We build on existing research on clustering and machine learning facets of this data to demonstrate a role for an ensemble approach to highlighting patients with clearer prognosis parameters. Results for survival prediction using 3 different approaches are shown for a subset of the data which is most difficult to model. The performance of each model individually is compared with subsets of the data where some agreement is reached for multiple models. Significant improvements in model accuracy on an unseen test set can be achieved for patients where agreement between models is achieved. Keywords—ensemble learning; anti-learning; colorectal cancer.",
            "output": [
                "Ensemble Learning of Colorectal Cancer Survival Rates"
            ]
        },
        {
            "id": "task1540-802d5179248c449db43470c53e3c2475",
            "input": "A college student’s life can be primarily categorized into domains such as education, health, social and other activities which may include daily chores and travelling time. Time management is crucial for every student. A self realisation of one’s daily time expenditure in various domains is therefore essential to maximize one’s effective output. This paper presents how a mobile application using Fuzzy Logic and Global Positioning System (GPS) analyzes a student’s lifestyle and provides recommendations and suggestions based on the results. Keywords—Fuzzy Logic, GPS, Android Application",
            "output": [
                "A Fuzzy Logic System to Analyze a Student’s Lifestyle"
            ]
        },
        {
            "id": "task1540-fa2a664b9a204dfe983af43c75866877",
            "input": "Object recognition and localization are important tasks in computer vision. The focus of this work is the incorporation of contextual information in order to improve object recognition and localization. For instance, it is natural to expect not to see an elephant to appear in the middle of an ocean. We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents. By merely counting the number of times nouns (such as elephants, sharks, oceans, etc.) co-occur in web documents, we obtain a good estimate of expected co-occurrences in visual data. We then cast the problem of combining textual co-occurrence statistics with the predictions of image-based classifiers as an optimization problem. The resulting optimization problem serves as a surrogate for our inference procedure. Albeit the simplicity of the resulting optimization problem, it is effective in improving both recognition and localization accuracy. Concretely, we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets.",
            "output": [
                "Using Web Co-occurrence Statistics for Improving Image Categorization"
            ]
        },
        {
            "id": "task1540-f4c8462acb604468a5eefad3cbd9cc4b",
            "input": "We introduce Natural Neural Networks, a novel family of algorithms that speed up convergence by adapting their internal representation during training to improve conditioning of the Fisher matrix. In particular, we show a specific example that employs a simple and efficient reparametrization of the neural network weights by implicitly whitening the representation obtained at each layer, while preserving the feed-forward computation of the network. Such networks can be trained efficiently via the proposed Projected Natural Gradient Descent algorithm (PRONG), which amortizes the cost of these reparametrizations over many parameter updates and is closely related to the Mirror Descent online learning algorithm. We highlight the benefits of our method on both unsupervised and supervised learning tasks, and showcase its scalability by training on the large-scale ImageNet Challenge dataset.",
            "output": [
                "Natural Neural Networks"
            ]
        },
        {
            "id": "task1540-a727d84adcf74d119d660156ce786e77",
            "input": "We consider online learning of ensembles of portfolio selection algorithms and aim to regularize risk by encouraging diversification with respect to a predefined risk-driven grouping of stocks. Our procedure uses online convex optimization to control capital allocation to underlying investment algorithms while encouraging non-sparsity over the given grouping. We prove a logarithmic regret for this procedure with respect to the best-in-hindsight ensemble. We applied the procedure with known mean-reversion portfolio selection algorithms using the standard GICS industry sector grouping. Empirical Experimental results showed an impressive percentage increase of risk-adjusted return (Sharpe ratio).",
            "output": [
                "Online Learning of Portfolio Ensembles with Sector Exposure Regularization"
            ]
        },
        {
            "id": "task1540-4fb50d9ebfe1425b92d613ff85fd97ad",
            "input": "Chinese characters have a complex and hierarchical graphical structure carrying both semantic and phonetic information. We use this structure to enhance the text model and obtain better results in standard NLP operations. First of all, to tackle the problem of graphical variation we define allographic classes of characters. Next, the relation of inclusion of a subcharacter in a characters, provides us with a directed graph of allographic classes. We provide this graph with two weights: semanticity (semantic relation between subcharacter and character) and phoneticity (phonetic relation) and calculate “most semantic subcharacter paths” for each character. Finally, adding the information contained in these paths to unigrams we claim to increase the efficiency of text mining methods. We evaluate our method on a text classification task on two corpora (Chinese and Japanese) of a total of 18 million characters and get an improvement of 3% on an already high baseline of 89.6% precision, obtained by a linear SVM classifier. Other possible applications and perspectives of the system are discussed.",
            "output": [
                "New Perspectives in Sinographic Language Processing Through the Use of Character Structure"
            ]
        },
        {
            "id": "task1540-1611980a3ea543db9d91279cc6c32a46",
            "input": "In this paper we present architecture of a fuzzy expert system used for therapy of dyslalic children. With fuzzy approach we can create a better model for speech therapist decisions. A software interface was developed for validation of the system. The main objectives of this task are: personalized therapy (the therapy must be in according with child’s problems level, context and possibilities), speech therapist assistant (the expert system offer some suggestion regarding what exercises are better for a specific moment and from a specific child), (self) teaching (when system’s conclusion is different that speech therapist’s conclusion the last one must have the knowledge base change possibility).",
            "output": [
                "ARCHITECTURE OF A FUZZY EXPERT SYSTEM USED FOR DYSLALIC CHILDREN THERAPY"
            ]
        },
        {
            "id": "task1540-9ecfee6326024c7fa92cd670c2683d0b",
            "input": "In some domestic professional sports leagues, the home stadiums are located in cities connected by a common train line running in one direction. For these instances, we can incorporate this geographical information to determine optimal or nearly-optimal solutions to the n-team Traveling Tournament Problem (TTP), an NP-hard sports scheduling problem whose solution is a double round-robin tournament schedule that minimizes the sum total of distances traveled by all n teams. We introduce the Linear Distance Traveling Tournament Problem (LD-TTP), and solve it for n = 4 and n = 6, generating the complete set of possible solutions through elementary combinatorial techniques. For larger n, we propose a novel “expander construction” that generates an approximate solution to the LD-TTP. For n ≡ 4 (mod 6), we show that our expander construction produces a feasible double round-robin tournament schedule whose total distance is guaranteed to be no worse than 4 3 times the optimal solution, regardless of where the n teams are located. This 4 3 -approximation for the LD-TTP is stronger than the currently best-known ratio of 5 3 + for the general TTP. We conclude the paper by applying this linear distance relaxation to general (nonlinear) n-team TTP instances, where we develop fast approximate solutions by simply “assuming” the n teams lie on a straight line and solving the modified problem. We show that this technique surprisingly generates the distance-optimal tournament on all benchmark sets on 6 teams, as well as close-to-optimal schedules for larger n, even when the teams are located around a circle or positioned in three-dimensional space.",
            "output": [
                "Generating Approximate Solutions to the Traveling Tournament Problem using a Linear Distance Relaxation"
            ]
        },
        {
            "id": "task1540-7bb59760be8746948bcdfec5cad43b9c",
            "input": "I. Abstract This paper attempts multi-label classification by extending the idea of independent binary classification models for each output label, and exploring how the inherent correlation between output labels can be used to improve predictions. Logistic Regression, Naive Bayes, Random Forest, and SVM models were constructed, with SVM giving the best results: an improvement of 12.9% over binary models was achieved for hold out cross validation by augmenting with pairwise correlation probabilities of the labels.",
            "output": [
                "Exploring Correlation between Labels to improve Multi-Label Classification"
            ]
        },
        {
            "id": "task1540-44d84a6c5c8644569b9f968531bbfd16",
            "input": "This paper presents a multilingual study on, per single post of microblog text, (a) how much can be said, (b) how much is written in terms of characters and bytes, and (c) how much is said in terms of information content in posts by different organizations in different languages. Focusing on three different languages (English, Chinese, and Japanese), this research analyses Weibo and Twitter accounts of major embassies and news agencies. We first establish our criterion for quantifying “how much can be said” in a digital text based on the openly available Universal Declaration of Human Rights and the translated subtitles from TED talks. These parallel corpora allow us to determine the number of characters and bits needed to represent the same content in different languages and character encodings. We then derive the amount of information that is actually contained in microblog posts authored by selected accounts on Weibo and Twitter. Our results confirm that languages with larger character sets such as Chinese and Japanese contain more information per character than English, but the actual information content contained within a microblog text varies depending on both the type of organization and the language of the post. We conclude with a discussion on the design implications of microblog text limits for different languages.",
            "output": [
                "How much is said in a microblog? A multilingual inquiry based on Weibo and Twitter"
            ]
        },
        {
            "id": "task1540-c3331cecf5854d1c86ca7e8b550b7d4d",
            "input": "Classification and clustering have been studied separately in machine learning and computer vision. Inspired by the recent success of deep learning models in solving various vision problems (e.g., object recognition, semantic segmentation) and the fact that humans serve as the gold standard in assessing clustering algorithms, here, we advocate for a unified treatment of the two problems and suggest that hierarchical frameworks that progressively build complex patterns on top of the simpler ones (e.g., convolutional neural networks) offer a promising solution. We do not dwell much on the learning mechanisms in these frameworks as they are still a matter of debate, with respect to biological constraints. Instead, we emphasize on the compositionality of the real world structures and objects. In particular, we show that CNNs, trained end to end using back propagation with noisy labels, are able to cluster data points belonging to several overlapping shapes, and do so much better than the state of the art algorithms. The main takeaway lesson from our study is that mechanisms of human vision, particularly the hierarchal organization of the visual ventral stream should be taken into account in clustering algorithms (e.g., for learning representations in an unsupervised manner or with minimum supervision) to reach human level clustering performance. This, by no means, suggests that other methods do not hold merits. For example, methods relying on pairwise affinities (e.g., spectral clustering) have been very successful in many cases but still fail in some cases (e.g., overlapping clusters).",
            "output": [
                "A new look at clustering through the lens of deep convolutional neural networks"
            ]
        },
        {
            "id": "task1540-fc928ca4fa934e7bab53f5938940c6c5",
            "input": "We introduce Deep Neural Programs (DNP), a novel programming paradigm for writing adaptive controllers for cyber-physical systems (CPS). DNP replace if and while statements, whose discontinuity is responsible for undecidability in CPS analysis, intractability in CPS design, and frailness in CPS implementation, with their smooth, neural nif and nwhile counterparts. This not only makes CPS analysis decidable and CPS design tractable, but also allows to write robust and adaptive CPS code. In DNP the connection between the sigmoidal guards of the nif and nwhile statements has to be given as a Gaussian Bayesian network, which reflects the partial knowledge, the CPS program has about its environment. To the best of our knowledge, DNP are the first approach linking neural networks to programs, in a way that makes explicit the meaning of the network. In order to prove and validate the usefulness of DNP, we use them to write and learn an adaptive CPS controller for the parallel parking of the Pioneer rovers available in our CPS lab.",
            "output": [
                "Deep Neural Programs for Adaptive Control in Cyber-Physical Systems"
            ]
        },
        {
            "id": "task1540-dedde9ae19114f3c830a0b6c80df543e",
            "input": "Topic Models have been reported to be beneficial for aspect-based sentiment analysis. This paper reports a simple topic model for sarcasm detection, a first, to the best of our knowledge. Designed on the basis of the intuition that sarcastic tweets are likely to have a mixture of words of both sentiments as against tweets with literal sentiment (either positive or negative), our hierarchical topic model discovers sarcasm-prevalent topics and topic-level sentiment. Using a dataset of tweets labeled using hashtags, the model estimates topic-level, and sentiment-level distributions. Our evaluation shows that topics such as ‘work’, ‘gun laws’, ‘weather’ are sarcasm-prevalent topics. Our model is also able to discover the mixture of sentiment-bearing words that exist in a text of a given sentiment-related label. Finally, we apply our model to predict sarcasm in tweets. We outperform two prior work based on statistical classifiers with specific features, by around 25%.",
            "output": [
                "‘Who would have thought of that!’: A Hierarchical Topic Model for Extraction of Sarcasm-prevalent Topics and Sarcasm Detection"
            ]
        },
        {
            "id": "task1540-095a7b3aecf042c19d1dd484ece125b8",
            "input": "Deep reinforcement learning (RL) has achieved several high profile successes in difficult control problems. However, these algorithms typically require a huge amount of data before they reach reasonable performance. In fact, their performance during learning can be extremely poor. This may be acceptable for a simulator, but it severely limits the applicability of deep RL to many real-world tasks, where the agent must learn in the real environment. In this paper we study a setting where the agent may access data from previous control of the system. We present an algorithm, Deep Q-learning from Demonstrations (DQfD), that leverages this data to massively accelerate the learning process even from relatively small amounts of demonstration data. DQfD works by combining temporal difference updates with large-margin classification of the demonstrator’s actions. We show that DQfD has better initial performance than Deep Q-Networks (DQN) on 40 of 42 Atari games and it receives more average rewards than DQN on 27 of 42 Atari games. We also demonstrate that DQfD learns faster than DQN even when given poor demonstration data.",
            "output": [
                "Learning from Demonstrations for Real World Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-5772c558155c4056b307657d7aac9712",
            "input": "In budget–limited multi–armed bandit (MAB) problems, the learner’s actions are costly and constrained by a fixed budget. Consequently, an optimal exploitation policy may not be to pull the optimal arm repeatedly, as is the case in other variants of MAB, but rather to pull the sequence of different arms that maximises the agent’s total reward within the budget. This difference from existing MABs means that new approaches to maximising the total reward are required. Given this, we develop two pulling policies, namely: (i) KUBE; and (ii) fractional KUBE. Whereas the former provides better performance up to 40% in our experimental settings, the latter is computationally less expensive. We also prove logarithmic upper bounds for the regret of both policies, and show that these bounds are asymptotically optimal (i.e. they only differ from the best possible regret by a constant factor).",
            "output": [
                "Knapsack based Optimal Policies for Budget–Limited Multi–Armed Bandits"
            ]
        },
        {
            "id": "task1540-fb0cbe5daecd495fa4ff31b49c851890",
            "input": "Correct inference of genetic regulations inside a cell is one of the greatest challenges in post genomic era for the biologist and researchers. Several intelligent techniques and models were already proposed to identify the regulatory relations among genes from the biological database like time series microarray data. Recurrent Neural Network (RNN) is one of the most popular and simple approach to model the dynamics as well as to infer correct dependencies among genes. In this paper, Bat Algorithm (BA) was applied to optimize the model parameters of RNN model of Gene Regulatory Network (GRN). Initially the proposed method is tested against small artificial network without any noise and the efficiency was observed in term of number of iteration, number of population and BA optimization parameters. The model was also validated in presence of different level of random noise for the small artificial network and that proved its ability to infer the correct inferences in presence of noise like real world dataset. In the next phase of this research, BA based RNN is applied to real world benchmark time series microarray dataset of E. Coli. The results shown that it can able to identify the maximum true positive regulation but also include some false positive regulations. Therefore, BA is very suitable for identifying biological plausible GRN with the help RNN model.",
            "output": [
                "Recurrent Neural Network Based Modeling of Gene Regulatory Network Using Bat Algorithm"
            ]
        },
        {
            "id": "task1540-16aacbbf94514f389b9afff8a19afe84",
            "input": "With the acceptance of Western culture and science, Traditional Chinese Medicine (TCM) has become a controversial issue in China. So, it’s important to study the public’s sentiment and opinion on TCM. The rapid development of online social network, such as twitter, make it convenient and efficient to sample hundreds of millions of people for the aforementioned sentiment study. To the best of our knowledge, the present work is the first attempt that applies sentiment analysis to the domain of TCM on Sina Weibo (a twitter-like microblogging service in China). In our work, firstly we collect tweets topic about TCM from Sina Weibo, and label the tweets as supporting TCM and opposing TCM automatically based on user tag. Then, a support vector machine classifier has been built to predict the sentiment of TCM tweets without labels. Finally, we present a method to adjust the classifier result. The performance of F-measure attained with our method is 97%.",
            "output": [
                "Sentiment Analysis based on User Tag for Traditional Chinese Medicine in Weibo"
            ]
        },
        {
            "id": "task1540-707717acd759407da880270ae8c2f331",
            "input": "We describe and analyze a simple and effective algorithm for sequence segmentation applied to speech processing tasks. We propose a neural architecture that is composed of two modules trained jointly: a recurrent neural network (RNN) module and a structured prediction model. The RNN outputs are considered as feature functions to the structured model. The overall model is trained with a structured loss function which can be designed to the given segmentation task. We demonstrate the effectiveness of our method by applying it to two simple tasks commonly used in phonetic studies: word segmentation and voice onset time segmentation. Results suggest the proposed model is superior to previous methods, obtaining state-of-the-art results on the tested datasets.",
            "output": [
                "SEQUENCE SEGMENTATION USING JOINT RNN AND STRUCTURED PREDICTION MODELS"
            ]
        },
        {
            "id": "task1540-c3ae64d4250c4189a572699c04969473",
            "input": "In this work we aim to discover high quality speech features and linguistic units directly from unlabeled speech data in a zero resource scenario. The results are evaluated using the metrics and corpora proposed in the Zero Resource Speech Challenge organized at Interspeech 2015. A Multi-layered Acoustic Tokenizer (MAT) was proposed for automatic discovery of multiple sets of acoustic tokens from the given corpus. Each acoustic token set is specified by a set of hyperparameters that describe the model configuration. These sets of acoustic tokens carry different characteristics fof the given corpus and the language behind, thus can be mutually reinforced. The multiple sets of token labels are then used as the targets of a Multi-target Deep Neural Network (MDNN) trained on low-level acoustic features. Bottleneck features extracted from the MDNN are then used as the feedback input to the MAT and the MDNN itself in the next iteration. We call this iterative deep learning framework the Multi-layered Acoustic Tokenizing Deep Neural Network (MAT-DNN), which generates both high quality speech features for the Track 1 of the Challenge and acoustic tokens for the Track 2 of the Challenge. In addition, we performed extra experiments on the same corpora on the application of query-by-example spoken term detection. The experimental results showed the iterative deep learning framework of MAT-DNN improved the detection performance due to better underlying speech features and acoustic tokens.",
            "output": [
                "AN ITERATIVE DEEP LEARNING FRAMEWORK FOR UNSUPERVISED DISCOVERY OF SPEECH FEATURES AND LINGUISTIC UNITS WITH APPLICATIONS ON SPOKEN TERM DETECTION"
            ]
        },
        {
            "id": "task1540-4414f1b3a4a542ac9683b1bdf74221e9",
            "input": "In real-time strategy games like StarCraft, skilled players often block the entrance to their base with buildings to prevent the opponent’s units from getting inside. This technique, called “walling-in”, is a vital part of player’s skill set, allowing him to survive early aggression. However, current artificial players (bots) do not possess this skill, due to numerous inconveniences surfacing during its implementation in imperative languages like C++ or Java. In this text, written as a guide for bot programmers, we address the problem of finding an appropriate building placement that would block the entrance to player’s base, and present a ready to use declarative solution employing the paradigm of answer set programming (ASP). We also encourage the readers to experiment with different declarative approaches to this problem.",
            "output": [
                "Implementing a Wall-In Building Placement in StarCraft with Declarative Programming"
            ]
        },
        {
            "id": "task1540-8771acd885394ca8be2336458182a282",
            "input": "Realizability for knowledge representation formalisms studies the following question: Given a semantics and a set of interpretations, is there a knowledge base whose semantics coincides exactly with the given interpretation set? We introduce a general framework for analyzing realizability in abstract dialectical frameworks (ADFs) and various of its subclasses. In particular, the framework applies to Dung argumentation frameworks, SETAFs by Nielsen and Parsons, and bipolar ADFs. We present a uniform characterization method for the admissible, complete, preferred and model/stable semantics. We employ this method to devise an algorithm that decides realizability for the mentioned formalisms and semantics; moreover the algorithm allows for constructing a desired knowledge base whenever one exists. The algorithm is built in a modular way and thus easily extensible to new formalisms and semantics. We have also implemented our approach in answer set programming, and used the implementation to obtain several novel results on the relative expressiveness of the abovementioned formalisms.",
            "output": [
                "Characterizing Realizability in Abstract Argumentation"
            ]
        },
        {
            "id": "task1540-a08ce95480244762b7fbb0bc370fec6b",
            "input": "We theoretically analyze and compare the following five popular multiclass classification methods: One vs. All, All Pairs, Tree-based classifiers, Error Correcting Output Codes (ECOC) with randomly generated code matrices, and Multiclass SVM. In the first four methods, the classification is based on a reduction to binary classification. We consider the case where the binary classifier comes from a class of VC dimension d, and in particular from the class of halfspaces over R. We analyze both the estimation error and the approximation error of these methods. Our analysis reveals interesting conclusions of practical relevance, regarding the success of the different approaches under various conditions. Our proof technique employs tools from VC theory to analyze the approximation error of hypothesis classes. This is in sharp contrast to most, if not all, previous uses of VC theory, which only deal with estimation error.",
            "output": [
                "Multiclass Learning Approaches: A Theoretical Comparison with Implications"
            ]
        },
        {
            "id": "task1540-11f868a2b42b482e94649be93020478b",
            "input": "Collaborative data consist of ratings relating two distinct sets of objects: users and items. Much of the work with such data focuses on filtering: predicting unknown ratings for pairs of users and items. In this paper we focus on the problem of visualizing the information. Given all of the ratings, our task is to embed all of the users and items as points in the same Euclidean space. We would like to place users near items that they have rated (or would rate) high, and far away from those they would give low ratings. We pose this problem as a real-valued non-linear Bayesian network and employ Markov chain Monte Carlo and expectation maximization to find an embedding. We present a metric by which to judge the quality of a visualization and compare our results to Eigentaste, locally linear embedding and cooccurrence data embedding on three real-world datasets.",
            "output": [
                "Visualization of Collaborative Data"
            ]
        },
        {
            "id": "task1540-6ca6d68491904e84bc66dfd2b9bc4eba",
            "input": "Recently, resources and tasks were proposed to go beyond state tracking in dialogue systems. An example is the frame tracking task, which requires recording multiple frames, one for each user goal set during the dialogue. This allows a user, for instance, to compare items corresponding to different goals. This paper proposes a model which takes as input the list of frames created so far during the dialogue, the current user utterance as well as the dialogue acts, slot types, and slot values associated with this utterance. The model then outputs the frame being referenced by each triple of dialogue act, slot type, and slot value. We show that on the recently published Frames dataset, this model significantly outperforms a previously proposed rule-based baseline. In addition, we propose an extensive analysis of the frame tracking task by dividing it into sub-tasks and assessing their difficulty with respect to our model.",
            "output": [
                "A Frame Tracking Model for Memory-Enhanced Dialogue Systems"
            ]
        },
        {
            "id": "task1540-1253f547c5e1495a9d9b26a2792c9566",
            "input": "In this paper we propose an extension to the Fuzzy Cognitive Maps (FCMs) that aims at aggregating a number of reasoning tasks into a one parallel run. The described approach consists in replacing real-valued activation levels of concepts (and further influence weights) by random variables. Such extension, followed by the implemented software tool, allows for determining ranges reached by concept activation levels, sensitivity analysis as well as statistical analysis of multiple reasoning results. We replace multiplication and addition operators appearing in the FCM state equation by appropriate convolutions applicable for discrete random variables. To make the model computationally feasible, it is further augmented with aggregation operations for discrete random variables. We discuss four implemented aggregators, as well as we report results of preliminary tests.",
            "output": [
                "Combining Fuzzy Cognitive Maps and Discrete Random Variables"
            ]
        },
        {
            "id": "task1540-99cf258b04a642c3b4a5e61d1de6b7ef",
            "input": "Neural machine translation (NMT) models are able to partially learn syntactic information from sequential lexical information. Still, some complex syntactic phenomena such as prepositional phrase attachment are poorly modeled. This work aims to answer two questions: 1) Does explicitly modeling source or target language syntax help NMT? 2) Is tight integration of words and syntax better than multitask training? We introduce syntactic information in the form of CCG supertags either in the source as an extra feature in the embedding, or in the target, by interleaving the target supertags with the word sequence. Our results on WMT data show that explicitly modeling syntax improves machine translation quality for English↔German, a high-resource pair, and for English↔Romanian, a lowresource pair and also several syntactic phenomena including prepositional phrase attachment. Furthermore, a tight coupling of words and syntax improves translation quality more than multitask training.",
            "output": [
                "Syntax-aware Neural Machine Translation Using CCG"
            ]
        },
        {
            "id": "task1540-c06788158fd34588bb910231bf556b59",
            "input": "We investigate the problem of learning discrete, undirected graphical models in a differentially private way. We show that the approach of releasing noisy sufficient statistics using the Laplace mechanism achieves a good trade-off between privacy, utility, and practicality. A naive learning algorithm that uses the noisy sufficient statistics “as is” outperforms general-purpose differentially private learning algorithms. However, it has three limitations: it ignores knowledge about the data generating process, rests on uncertain theoretical foundations, and exhibits certain pathologies. We develop a more principled approach that applies the formalism of collective graphical models to perform inference over the true sufficient statistics within an expectationmaximization framework. We show that this learns better models than competing approaches on both synthetic data and on real human mobility data used as a case study.",
            "output": [
                "Differentially Private Learning of Undirected Graphical Models Using Collective Graphical Models"
            ]
        },
        {
            "id": "task1540-4a5933ddd5b641659fd5d6fcadb8b152",
            "input": "Recommender systems play an increasingly important role in online applications to help users find what they need or prefer. Collaborative filtering algorithms that generate predictions by analyzing the user-item rating matrix perform poorly when the matrix is sparse. To alleviate this problem, this paper proposes a simple recommendation algorithm that fully exploits the similarity information among users and items and intrinsic structural information of the user-item matrix. The proposed method constructs a new representation which preserves affinity and structure information in the user-item rating matrix and then performs recommendation task. To capture proximity information about users and items, two graphs are constructed. Manifold learning idea is used to constrain the new representation to be smooth on these graphs, so as to enforce users and item proximities. Our model is formulated as a convex optimization problem, for which we need to solve the well known Sylvester equation only. We carry out extensive empirical evaluations on six benchmark datasets to show the effectiveness of this approach.",
            "output": [
                "Top-N Recommendation on Graphs"
            ]
        },
        {
            "id": "task1540-71d38a60fe614eb4820bf206fb0fa458",
            "input": "Web Service is one of the most significant current discussions in information sharing technologies and one of the examples of service oriented processing. To ensure accurate execution of web services operations, it must be adaptable with policies of the social networks in which it signs up. This adaptation implements using controls called “Commitment”. This paper describes commitments structure and existing research about commitments and social web services, then suggests an algorithm for consistency of commitments in social web services. As regards the commitments may be executed concurrently, a key challenge in web services execution based on commitment structure is consistency ensuring in execution time. The purpose of this research is providing an algorithm for consistency ensuring between web services operations based on commitments structure.",
            "output": [
                "Consistency Ensuring in Social Web Services Based on Commitments Structure"
            ]
        },
        {
            "id": "task1540-a4a3ea81f2a24984b1e32753a08b258b",
            "input": "Understanding physical phenomena is a key competence that enables humans and animals to act and interact under uncertain perception in previously unseen environments containing novel object and their configurations. Developmental psychology has shown that such skills are acquired by infants from observations at a very early stage. In this paper, we contrast a more traditional approach of taking a modelbased route with explicit 3D representations and physical simulation by an end-to-end approach that directly predicts stability and related quantities from appearance. We ask the question if and to what extent and quality such a skill can directly be acquired in a data-driven way— bypassing the need for an explicit simulation. We present a learning-based approach based on simulated data that predicts stability of towers comprised of wooden blocks under different conditions and quantities related to the potential fall of the towers. The evaluation is carried out on synthetic data and compared to human judgments on the same stimuli.",
            "output": [
                "To Fall Or Not To Fall: A Visual Approach to Physical Stability Prediction"
            ]
        },
        {
            "id": "task1540-7757e6c7e47740899623d7ce2f1d92fd",
            "input": "This paper describes the best first search strategy used by U-Plan (Mansell 1993a), a planning system that constructs quantitatively ranked plans given an incomplete description of an uncertain environment. U-Plan uses uncertain and incomplete evidence describing the environment, characterises it using a Dempster­ Shafer interval, and generates a set of possible world states. Plan construction takes place in an abstraction hierarchy where strategic decisions are made before tactical decisions. Search through this abstraction hierarchy is guided by a quantitative measure (expected fulfilment) based on decision theory. The search strategy is best first with the provision to update expected fulfilments and review previous decisions in the light of planning developments. U-Pian generates multiple plans for multiple possible worlds, and attempts to use existing plans for new world situations. A super-plan is then constructed, based on merging the set of plans and appropriately timed knowledge acquisition operators, which are used to decide between plan alternatives during plan execution.",
            "output": [
                "Operator Selection While Planning Under Uncertainty"
            ]
        },
        {
            "id": "task1540-bbed1f3b64e64d6bbb4c0288dfa86a4f",
            "input": "The manuscript presents an experiment at implementation of a Machine Translation system in a MapReduce model. The empirical evaluation was done using fully implemented translation systems embedded into the MapReduce programming model. Two machine translation paradigms were studied: shallow transfer Rule Based Machine Translation and Statistical Machine Translation. The results show that the MapReduce model can be successfully used to increase the throughput of a machine translation system. Furthermore this method enhances the throughput of a machine translation system without decreasing the quality of the translation output. Thus, the present manuscript also represents a contribution to the seminal work in natural language processing, specifically Machine Translation. It first points toward the importance of the definition of the metric of throughput of translation system and, second, the applicability of the machine translation task to the MapReduce paradigm.",
            "output": [
                "Increasing the throughput of machine translation systems using clouds"
            ]
        },
        {
            "id": "task1540-c33871bef392411e930e7aa9479d8d0e",
            "input": "In many machine learning applications, labeled data is scarce and obtaining more labels is expensive. We introduce a new approach to supervising neural networks by specifying constraints that should hold over the output space, rather than direct examples of input-output pairs. These constraints are derived from prior domain knowledge, e.g., from known laws of physics. We demonstrate the effectiveness of this approach on real world and simulated computer vision tasks. We are able to train a convolutional neural network to detect and track objects without any labeled examples. Our approach can significantly reduce the need for labeled training data, but introduces new challenges for encoding prior knowledge into appropriate loss functions.",
            "output": [
                "Label-Free Supervision of Neural Networks with Physics and Domain Knowledge"
            ]
        },
        {
            "id": "task1540-0bf4bc51a31643fb8c9a3cb1ad74b670",
            "input": "Holding commercial negotiations and selecting the best supplier in supply chain management systems are among weaknesses of producers in production process. Therefore, applying intelligent systems may have an effective role in increased speed and improved quality in the selections .This paper introduces a system which tries to trade using multi-agents systems and holding negotiations between any agents. In this system, an intelligent agent is considered for each segment of chains which it tries to send order and receive the response with attendance in negotiation medium and communication with other agents .This paper introduces how to communicate between agents, characteristics of multi-agent and standard registration medium of each agent in the environment. JADE (Java Application Development Environment) was used for implementation and simulation of agents cooperation. Keyword(s): e-Commerce, e-Business, Supply Chain Management System(SCM), eSCM, Intelligent Agents, JADE, Multi Agents",
            "output": [
                "An Intelligent Approach for Negotiating between chains in Supply Chain Management Systems"
            ]
        },
        {
            "id": "task1540-70a466ed17e649e6a6b321f33fd7d38f",
            "input": "This paper introduces an elemental building block which combines Dictionary Learning and Dimension Reduction (DRDL). We show how this foundational element can be used to iteratively construct a Hierarchical Sparse Representation (HSR) of a sensory stream. We compare our approach to existing models showing the generality of our simple prescription. We then perform preliminary experiments using this framework, illustrating with the example of an object recognition task using standard datasets. This work introduces the very first steps towards an integrated framework for designing and analyzing various computational tasks from learning to attention to action. The ultimate goal is building a mathematically rigorous, integrated theory of intelligence.",
            "output": [
                "Learning Hierarchical Sparse Representations using Iterative Dictionary Learning and Dimension Reduction"
            ]
        },
        {
            "id": "task1540-7e12da476f984787baae6fdd3d7a4e4a",
            "input": "We start with an overview of a class of submodular functions called SCMMs (sums of concave composed with non-negative modular functions plus a final arbitrary modular). We then define a new class of submodular functions we call deep submodular functions or DSFs. We show that DSFs are a flexible parametric family of submodular functions that share many of the properties and advantages of deep neural networks (DNNs), including many-layered hierarchical topologies, representation learning, distributed representations, opportunities and strategies for training, and suitability to GPU-based matrix/vector computing. DSFs can be motivated by considering a hierarchy of descriptive concepts over ground elements and where one wishes to allow submodular interaction throughout this hierarchy. In machine learning and data science applications, where there is often either a natural or an automatically learnt hierarchy of concepts over data, DSFs therefore naturally apply. Results in this paper show that DSFs constitute a strictly larger class of submodular functions than SCMMs, thus justifying their mathematical and practical utility. Moreover, we show that, for any integer k > 0, there are k-layer DSFs that cannot be represented by a k′-layer DSF for any k′ < k. This implies that, like DNNs, there is a utility to depth, but unlike DNNs (which can be universally approximated by shallow networks), the family of DSFs strictly increase with depth. Despite this property, however, we show that DSFs, even with arbitrarily large k, do not comprise all submodular functions. We show this using a technique that “backpropagates” certain requirements if it was the case that DSFs comprised all submodular functions. In offering the above results, we also define the notion of an antitone superdifferential of a concave function and show how this relates to submodular functions (in general), DSFs (in particular), negative second-order partial derivatives, continuous submodularity, and concave extensions. To further motivate our analysis, we provide various special case results from matroid theory, comparing DSFs with forms of matroid rank, in particular the laminar matroid. Lastly, we discuss strategies to learn DSFs, and define the classes of deep supermodular functions, deep difference of submodular functions, and deep multivariate submodular functions, and discuss where these can be useful in applications.",
            "output": [
                "Deep Submodular Functions"
            ]
        },
        {
            "id": "task1540-76ac039483544e5fbc19b5c1b2ffdd16",
            "input": "Vector Symbolic Architectures (VSAs) are high-dimensional vector representations of objects (eg., words, image parts), relations (eg., sentence structures), and sequences for use with machine learning algorithms. They consist of a vector addition operator for representing a collection of unordered objects, a Binding operator for associating groups of objects, and a methodology for encoding complex structures. We first develop Constraints that machine learning imposes upon VSAs: for example, similar structures must be represented by similar vectors. The constraints suggest that current VSAs should represent phrases (“The smart Brazilian girl”) by binding sums of terms, in addition to simply binding the terms directly. We show that matrix multiplication can be used as the binding operator for a VSA, and that matrix elements can be chosen at random. A consequence for living systems is that binding is mathematically possible without the need to specify, in advance, precise neuron-to-neuron connection properties for large numbers of synapses. A VSA that incorporates these ideas, MBAT (Matrix Binding of Additive Terms), is described that satisfies all Constraints. With respect to machine learning, for some types of problems appropriate VSA representations permit us to prove learnability, rather than relying on simulations. We also propose dividing machine (and neural) learning and representation into three Stages, with differing roles for learning in each stage. For neural modeling, we give “representational reasons” for nervous systems to have many recurrent connections, as well as for the importance of phrases in language processing. Sizing simulations and analyses suggest that VSAs in general, and MBAT in particular, are ready for real-world applications.",
            "output": [
                "Representing Objects, Relations, and Sequences"
            ]
        },
        {
            "id": "task1540-520bacf9d7ff40b5957370ef7cd72bd9",
            "input": "It was recently shown that the problem of de­<lb>coding messages transmitted through a noisy<lb>channel can be formulated as a belief up­<lb>dating task over a probabilistic network (14).<lb>Moreover, it was observed that iterative ap­<lb>plication of the (linear time) belief propa­<lb>gation algorithm designed for polytrees (15)<lb>outperformed state of the art decoding algo­<lb>rithms, even though the corresponding net­<lb>works may have many cycles.<lb>This paper demonstrates empirically that<lb>an approximation algorithm approx-mpe<lb>for solving the most probable explana­<lb>tion<lb>(MPE) problem, developed within the<lb>recently proposed mini-bucket elimination<lb>framework (4), outperforms iterative belief<lb>propagation on classes of coding networks<lb>that have bounded induced width.<lb>Our ex­<lb>periments suggest that approximate MPE de­<lb>coders can be good competitors to the ap­<lb>proximate belief updating decoders.",
            "output": [
                "Empirical Evaluation of Approximation Algorithms for Probabilistic Decoding"
            ]
        },
        {
            "id": "task1540-e9188bee8bd14f55ad4819a05faebc4c",
            "input": "Local consistency techniques such as k-consistency are a key component of specialised solvers for constraint satisfaction problems. In this paper we show that the power of using k-consistency techniques on a constraint satisfaction problem is precisely captured by using a particular inference rule, which we call negative-hyper-resolution, on the standard direct encoding of the problem into Boolean clauses. We also show that current clauselearning SAT-solvers will discover in expected polynomial time any inconsistency that can be deduced from a given set of clauses using negative-hyper-resolvents of a fixed size. We combine these two results to show that, without being explicitly designed to do so, current clause-learning SAT-solvers efficiently simulate k-consistency techniques, for all fixed values of k. We then give some experimental results to show that this feature allows clause-learning SAT-solvers to efficiently solve certain families of constraint problems which are challenging for conventional constraint-programming solvers.",
            "output": [
                "Local Consistency and SAT-Solvers"
            ]
        },
        {
            "id": "task1540-3ebec859d3e040d9b6a67a22b26c1cae",
            "input": "The capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks. A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. We present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost.",
            "output": [
                "OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER"
            ]
        },
        {
            "id": "task1540-0adae063cdd345089d8a229cbd928905",
            "input": "Generative state estimators based on probabilistic filters and smoothers are one of the most popular classes of state estimators for robots and autonomous vehicles. However, generative models have limited capacity to handle rich sensory observations, such as camera images, since they must model the entire distribution over sensor readings. Discriminative models do not suffer from this limitation, but are typically more complex to train as latent variable models for state estimation. We present an alternative approach where the parameters of the latent state distribution are directly optimized as a deterministic computation graph, resulting in a simple and effective gradient descent algorithm for training discriminative state estimators. We show that this procedure can be used to train state estimators that use complex input, such as raw camera images, which must be processed using expressive nonlinear function approximators such as convolutional neural networks. Our model can be viewed as a type of recurrent neural network, and the connection to probabilistic filtering allows us to design a network architecture that is particularly well suited for state estimation. We evaluate our approach on tracking task with raw image inputs. The results show significant improvement over both standard generative approaches and regular recurrent neural networks.",
            "output": [
                "Backprop KF: Learning Discriminative Deterministic State Estimators"
            ]
        },
        {
            "id": "task1540-d9543de07c0e49a6a17cf9e5b656dc47",
            "input": "We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoderdecoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available.",
            "output": [
                "Skip-Thought Vectors"
            ]
        },
        {
            "id": "task1540-f04f99ec0002421a840d07c026eda144",
            "input": "The computational cost of many signal processing and machine learning techniques is often dominated by the cost of applying certain linear operators to high-dimensional vectors. This paper introduces an algorithm aimed at reducing the complexity of applying linear operators in high dimension by approximately factorizing the corresponding matrix into few sparse factors. The approach relies on recent advances in non-convex optimization. It is first explained and analyzed in details and then demonstrated experimentally on various problems including dictionary learning for image denoising, and the approximation of large matrices arising in inverse problems.",
            "output": [
                "Flexible Multi-layer Sparse Approximations of Matrices and Applications"
            ]
        },
        {
            "id": "task1540-06bce01a014a427595638c734b6669d5",
            "input": "Cyber-Physical Systems in general, and Intelligent Transport Systems (ITS) in particular use heterogeneous data sources combined with problem solving expertise in order to make critical decisions that may lead to some form of actions e.g., driver notifications, change of traffic light signals and braking to prevent an accident. Currently, a major part of the decision process is done by human domain experts, which is time-consuming, tedious and error-prone. Additionally, due to the intrinsic nature of knowledge possession this decision process cannot be easily replicated or reused. Therefore, there is a need for automating the reasoning processes by providing computational systems a formal representation of the domain knowledge and a set of methods to process that knowledge. In this paper, we propose a knowledge model that can be used to express both declarative knowledge about the systems’ components, their relations and their current state, as well as procedural knowledge representing possible system behavior. In addition, we introduce a framework for knowledge management and automated reasoning (KMARF). The idea behind KMARF is to automatically select an appropriate problem solver based on formalized reasoning expertise in the knowledge base, and convert a problem definition to the corresponding format. This approach automates reasoning, thus reducing operational costs, and enables reusability of knowledge and methods across different domains. We illustrate the approach on a transportation",
            "output": [
                "A Framework for Knowledge Management and Automated Reasoning Applied on Intelligent Transport Systems"
            ]
        },
        {
            "id": "task1540-f10b41bf93f4430b86fe6aea851c35e0",
            "input": "Multi-Agent Path Finding (MAPF) is an NP-hard problem well studied in artificial intelligence and robotics. It has many real-world applications for which existing MAPF solvers use various heuristics. However, these solvers are deterministic and perform poorly on “hard” instances typically characterized by many agents interfering with each other in a small region. In this paper, we enhance MAPF solvers with randomization and observe that they exhibit heavy-tailed distributions of runtimes on hard instances. This leads us to develop simple rapid randomized restart (RRR) strategies with the intuition that, given a hard instance, multiple short runs have a better chance of solving it compared to one long run. We validate this intuition through experiments and show that our RRR strategies indeed boost the performance of state-ofthe-art MAPF solvers such as iECBS and M*.",
            "output": [
                "Rapid Randomized Restarts for Multi-Agent Path Finding Solvers"
            ]
        },
        {
            "id": "task1540-4050f92da0424078b78be330c5121959",
            "input": "Recurrent Neural Networks (RNN) have obtained excellent result in many natural language processing (NLP) tasks. However, understanding and interpreting the source of this success remains a challenge. In this paper, we propose Recurrent Memory Network (RMN), a novel RNN architecture, that not only amplifies the power of RNN but also facilitates our understanding of its internal functioning and allows us to discover underlying patterns in data. We demonstrate the power of RMN on language modeling and sentence completion tasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM) network on three large German, Italian, and English dataset. Additionally we perform indepth analysis of various linguistic dimensions that RMN captures. On Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous stateof-the-art by a large margin.",
            "output": [
                "Recurrent Memory Network for Language Modeling"
            ]
        },
        {
            "id": "task1540-92b71a260cea4439ac0529474cd1ac29",
            "input": "This paper studies theoretically and empirically a method of turning machinelearning algorithms into probabilistic predictors that automatically enjoys a property of validity (perfect calibration) and is computationally efficient. The price to pay for perfect calibration is that these probabilistic predictors produce imprecise (in practice, almost precise for large data sets) probabilities. When these imprecise probabilities are merged into precise probabilities, the resulting predictors, while losing the theoretical property of perfect calibration, are consistently more accurate than the existing methods in empirical studies. The conference version of this paper is to appear in Advances in Neural Information Processing Systems 28, 2015.",
            "output": [
                "Large-scale probabilistic prediction with and without validity guarantees"
            ]
        },
        {
            "id": "task1540-8e8d80205de5477893ae045c5efd913f",
            "input": "Reinforcement learning is a powerful technique to train an agent to perform a task. However, an agent that is trained using reinforcement learning is only capable of achieving the single task that is specified via its reward function. Such an approach does not scale well to settings in which an agent needs to perform a diverse set of tasks, such as navigating to varying positions in a room or moving objects to varying locations. Instead, we propose a method that allows an agent to automatically discover the range of tasks that it is capable of performing in its environment. We use a generator network to propose tasks for the agent to try to achieve, each task being specified as reaching a certain parametrized sub-set of the state-space. The generator network is optimized using adversarial training to produce tasks that are always at the appropriate level of difficulty for the agent. Our method thus automatically produces a curriculum of tasks for the agent to learn. We show that, by using this framework, an agent can efficiently and automatically learn to perform a wide set of tasks without requiring any prior knowledge of its environment. Our method can also learn to achieve tasks with sparse rewards, which traditionally pose significant challenges.",
            "output": [
                "Automatic Goal Generation for Reinforcement Learning Agents"
            ]
        },
        {
            "id": "task1540-396741e0e9d84954b742b0c7de602133",
            "input": "Nearest neighbor (k-NN) graphs are widely used in machine learning and data mining applications, and our aim is to better understand what they reveal about the cluster structure of the unknown underlying distribution of points. Moreover, is it possible to identify spurious structures that might arise due to sampling variability? Our first contribution is a statistical analysis that reveals how certain subgraphs of a k-NN graph form a consistent estimator of the cluster tree of the underlying distribution of points. Our second and perhaps most important contribution is the following finite sample guarantee. We carefully work out the tradeoff between aggressive and conservative pruning and are able to guarantee the removal of all spurious cluster structures at all levels of the tree while at the same time guaranteeing the recovery of salient clusters. This is the first such finite sample result in the context of clustering.",
            "output": [
                "Pruning nearest neighbor cluster trees"
            ]
        },
        {
            "id": "task1540-13a21f3431b64ab6b3c72470e99295eb",
            "input": "A new algorithm named EXPected Similarity Estimation (EXPoSE) was recently proposed to solve the problem of large-scale anomaly detection. It is a non-parametric and distribution free kernel method based on the Hilbert space embedding of probability measures. Given a dataset of n samples, EXPoSE needs only O(n) (linear time) to build a model and O(1) (constant time) to make a prediction. In this work we improve the linear computational complexity and show that an -accurate model can be estimated in constant time, which has significant implications for large-scale learning problems. To achieve this goal, we cast the original EXPoSE formulation into a stochastic optimization problem. It is crucial that this approach allows us to determine the number of iteration based on a desired accuracy , independent of the dataset size n. We will show that the proposed stochastic gradient descent algorithm works in general (possible infinite-dimensional) Hilbert spaces, is easy to implement and requires no additional step-size parameters.",
            "output": [
                "CONSTANT TIME EXPECTED SIMILARITY ESTIMATION USING STOCHASTIC OPTIMIZATION"
            ]
        },
        {
            "id": "task1540-860c8860bff342b182572bd36582a7f8",
            "input": "This paper investigates how far a very deep neural network is from attaining close to saturating performance on existing 2D and 3D face alignment datasets. To this end, we make the following 5 contributions: (a) we construct, for the first time, a very strong baseline by combining a state-of-the-art architecture for landmark localization with a state-of-the-art residual block, train it on a very large yet synthetically expanded 2D facial landmark dataset and finally evaluate it on all other 2D facial landmark datasets. (b) We create a guided by 2D landmarks network which converts 2D landmark annotations to 3D and unifies all existing datasets, leading to the creation of LS3D-W, the largest and most challenging 3D facial landmark dataset to date (~230,000 images). (c) Following that, we train a neural network for 3D face alignment and evaluate it on the newly introduced LS3D-W. (d) We further look into the effect of all “traditional” factors affecting face alignment performance like large pose, initialization and resolution, and introduce a “new” one, namely the size of the network. (e) We show that both 2D and 3D face alignment networks achieve performance of remarkable accuracy which is probably close to saturating the datasets used. Training and testing code as well as the dataset can be downloaded from https: //www.adrianbulat.com/face-alignment/",
            "output": [
                "How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)"
            ]
        },
        {
            "id": "task1540-72f6ef8038144b6a85ce48d9bece8b7b",
            "input": "Exposing latent knowledge in geospatial trajectories has the potential to provide a better understanding of the movements of individuals and groups. Motivated by such a desire, this work presents the context tree, a new hierarchical data structure that summarises the context behind user actions in a single model. We propose a method for context tree construction that augments geospatial trajectories with land usage data to identify such contexts. Through evaluation of the construction method and analysis of the properties of generated context trees, we demonstrate the foundation for understanding and modelling behaviour a↵orded. Summarising user contexts into a single data structure gives easy access to information that would otherwise remain latent, providing the basis for better understanding and predicting the actions and behaviours of individuals and groups. Finally, we also present a method for pruning context trees, for use in applications where it is desirable to reduce the size of the tree while retaining useful information.",
            "output": [
                "Context Trees: Augmenting Geospatial Trajectories with Context"
            ]
        },
        {
            "id": "task1540-c5fa4f6f8f85406eb3e76f956113f712",
            "input": "Problems at the intersection of vision and language are of significant importance both as challenging research questions and for the rich set of applications they enable. However, inherent structure in our world and bias in our language tend to be a simpler signal for learning than visual modalities, resulting in models that ignore visual information, leading to an inflated sense of their capability. We propose to counter these language priors for the task of Visual Question Answering (VQA) and make vision (the V in VQA) matter! Specifically, we balance the popular VQA dataset [3] by collecting complementary images such that every question in our balanced dataset is associated with not just a single image, but rather a pair of similar images that result in two different answers to the question. Our dataset is by construction more balanced than the original VQA dataset and has approximately twice the number of image-question pairs. Our complete balanced dataset is publicly available at http://visualqa.org/ as part of the 2nd iteration of the Visual Question Answering Dataset and Challenge (VQA v2.0). We further benchmark a number of state-of-art VQA models on our balanced dataset. All models perform significantly worse on our balanced dataset, suggesting that these models have indeed learned to exploit language priors. This finding provides the first concrete empirical evidence for what seems to be a qualitative sense among practitioners. Finally, our data collection protocol for identifying complementary images enables us to develop a novel interpretable model, which in addition to providing an answer to the given (image, question) pair, also provides a counterexample based explanation. Specifically, it identifies an image that is similar to the original image, but it believes has a different answer to the same question. This can help in building trust for machines among their users. ∗The first two authors contributed equally. Who is wearing glasses? Where is the child sitting? Is the umbrella upside down? How many children are in the bed? woman man arms fridge",
            "output": [
                "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"
            ]
        },
        {
            "id": "task1540-24e4a1642a90444ba7e2bc7efdc19457",
            "input": "Feature reduction is an important concept which is used for reducing dimensions to decrease the computation complexity and time of classification. Since now many approaches have been proposed for solving this problem, but almost all of them just presented a fix output for each input dataset that some of them aren’t satisfied cases for classification. In this we proposed an approach as processing input dataset to increase accuracy rate of each feature extraction methods. First of all, a new concept called dispelling classes gradually (DCG) is proposed to increase separability of classes based on their labels. Next, this method is used to process input dataset of the feature reduction approaches to decrease the misclassification error rate of their outputs more than when output is achieved without any processing. In addition our method has a good quality to collate with noise based on adapting dataset with feature reduction approaches. In the result part, two conditions (With process and without that) are compared to support our idea by using some of UCI datasets.",
            "output": [
                "Dispelling Classes Gradually to Improve Quality of Feature Reduction Approaches"
            ]
        },
        {
            "id": "task1540-2da3afa5771f41f38d57dbd354b59d32",
            "input": "Gaussian state space models have been used for decades as generative models of sequential data. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption. We introduce a unified algorithm to efficiently learn a broad class of linear and non-linear state space models, including variants where the emission and transition distributions are modeled by deep neural networks. Our learning algorithm simultaneously learns a compiled inference network and the generative model, leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution. We apply the learning algorithm to both synthetic and real-world datasets, demonstrating its scalability and versatility. We find that using the structured approximation to the posterior results in models with significantly higher held-out likelihood.",
            "output": [
                "Structured Inference Networks for Nonlinear State Space Models"
            ]
        },
        {
            "id": "task1540-5379c91116904b21a8d10d6ed6897f56",
            "input": "We address the problem of learning a ranking by using adaptively chosen pairwise comparisons. Our goal is to recover the ranking accurately but to sample the comparisons sparingly. If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort. But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking? We give favorable guarantees for Quicksort for the popular Bradley–Terry model, under natural assumptions on the parameters. Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items. This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.",
            "output": [
                "Just Sort It! A Simple and Effective Approach to Active Preference Learning"
            ]
        },
        {
            "id": "task1540-c656d09d4304475aa0b846425f951b75",
            "input": "While recent neural machine translation approaches have delivered state-of-the-art performance for resource-rich language pairs, they suffer from the data scarcity problem for resource-scarce language pairs. Although this problem can be alleviated by exploiting a pivot language to bridge the source and target languages, the source-to-pivot and pivot-to-target translation models are usually independently trained. In this work, we introduce a joint training algorithm for pivot-based neural machine translation. We propose three methods to connect the two models and enable them to interact with each other during training. Experiments on Europarl and WMT corpora show that joint training of source-to-pivot and pivot-to-target models leads to significant improvements over independent training across various languages.",
            "output": [
                "Joint Training for Pivot-based Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-4046ccd880be4adca9173f7cad81fa46",
            "input": "We study the task of online boosting — combining online weak learners into an online strong learner. While batch boosting has a sound theoretical foundation, online boosting deserves more study from the theoretical perspective. In this paper, we carefully compare the differences between online and batch boosting, and propose a novel and reasonable assumption for the online weak learner. Based on the assumption, we design an online boosting algorithm with a strong theoretical guarantee by adapting from the offline SmoothBoost algorithm that matches the assumption closely. We further tackle the task of deciding the number of weak learners using established theoretical results for online convex programming and predicting with expert advice. Experiments on real-world data sets demonstrate that the proposed algorithm compares favorably with existing online boosting algorithms.",
            "output": [
                "An Online Boosting Algorithm with Theoretical Justifications"
            ]
        },
        {
            "id": "task1540-7a22a412c458420e9782e219936dc271",
            "input": "Gene and protein networks are very important to model complex large-scale systems in molecular biology. Inferring or reverseengineering such networks can be defined as the process of identifying gene/protein interactions from experimental data through computational analysis. However, this task is typically complicated by the enormously large scale of the unknowns in a rather small sample size. Furthermore, when the goal is to study causal relationships within the network, tools capable of overcoming the limitations of correlation networks are required. In this work, we make use of Bayesian Graphical Models to attach this problem and, specifically, we perform a comparative study of different state-of-the-art heuristics, analyzing their performance in inferring the structure of the Bayesian Network from breast cancer data.",
            "output": [
                "Combining Bayesian Approaches and Evolutionary Techniques for the Inference of Breast Cancer Networks"
            ]
        },
        {
            "id": "task1540-857ebc553d8a4d1890993ce268c0cbef",
            "input": "In this paper, we study the problem of learning a monotone DNF with at most s terms of size (number of variables in each term) at most r (s term r-MDNF) from membership queries. This problem is equivalent to the problem of learning a general hypergraph using hyperedge-detecting queries, a problem motivated by applications arising in chemical reactions and genome sequencing. We first present new lower bounds for this problem and then present deterministic and randomized adaptive algorithms with query complexities that are almost optimal. All the algorithms we present in this paper run in time linear in the query complexity and the number of variables n. In addition, all of the algorithms we present in this paper are asymptotically tight for fixed r and/or s.",
            "output": [
                "On Exact Learning Monotone DNF from Membership Queries"
            ]
        },
        {
            "id": "task1540-e4a95afd41414b3ea969feeb58e511ee",
            "input": "Influence diagrams are decision theoretic extensions of Bayesian networks. They are applied to diverse decision problems. In this paper we apply influence diagrams to the optimization of a vehicle speed profile. We present results of computational experiments in which an influence diagram was used to optimize the speed profile of a Formula 1 race car at the Silverstone F1 circuit. The computed lap time and speed profiles correspond well to those achieved by test pilots. An extended version of our model that considers a more complex optimization function and diverse traffic constraints is currently being tested onboard a testing car by a major car manufacturer. This paper opens doors for new applications of influence diagrams.",
            "output": [
                "Influence diagrams for the optimization of a vehicle speed profile"
            ]
        },
        {
            "id": "task1540-b7ebb66d040648388af46912dfee1cbe",
            "input": "Reinforcement learning has been applied to many interesting problems such as the famous TD-gammon [1] and the inverted helicopter flight [2]. However little effort has been put into developing methods to learn policies for complex persistent tasks and tasks that are time-sensitive. In this paper we take a step towards solving this problem by using signal temporal logic (STL) as task specification, and taking advantage of the temporal abstraction feature that the options framework provide. We show via simulation that a relatively easy to implement algorithm that combines STL and options can learn a satisfactory policy with a small number of training cases.",
            "output": [
                "A Hierarchical Reinforcement Learning Method for Persistent Time-Sensitive Tasks"
            ]
        },
        {
            "id": "task1540-0bf7c55a806d427dbebdbb8ab27e1ce1",
            "input": "Constrained sampling and counting are two fundamental problems in artificial intelligence with a diverse range of applications, spanning probabilistic reasoning and planning to constrained-random verification. While the theory of these problems was thoroughly investigated in the 1980s, prior work either did not scale to industrial size instances or gave up correctness guarantees to achieve scalability. Recently, we proposed a novel approach that combines universal hashing and SAT solving and scales to formulas with hundreds of thousands of variables without giving up correctness guarantees. This paper provides an overview of the key ingredients of the approach and discusses challenges that need to be overcome to handle larger real-world instances.",
            "output": [
                "Constrained Sampling and Counting: Universal Hashing Meets SAT Solving∗"
            ]
        },
        {
            "id": "task1540-178ade1d179744509292c61197eacf46",
            "input": "The field of Distributed Constraint Optimization has gained momentum in recent years thanks to its ability to address various applications related to multi-agent cooperation. While techniques to solve Distributed Constraint Optimization Problems (DCOPs) are abundant and have matured substantially since the field inception, the number of DCOP realistic applications and benchmark used to asses the performance of DCOP algorithms is lagging behind. To contrast this background we (i) introduce the Smart Home Device Scheduling (SHDS) problem, which describe the problem of coordinating smart devices schedules across multiple homes as a multi-agent system, (ii) detail the physical models adopted to simulate smart sensors, smart actuators, and homes environments, and (iii) introduce a DCOP realistic benchmark for SHDS problems.",
            "output": [
                "A Realistic Dataset for the Smart Home Device Scheduling Problem for DCOPs"
            ]
        },
        {
            "id": "task1540-acc9febdce7b44ce8b9a18b04d9915f1",
            "input": "Traditional approaches to non-monotonic reasoning fail to satisfy a number of plausible axioms for belief revision and suffer from conceptual difficulties as well. Recent work on ranked preferential models (RPMs) promises to overcome some of these difficulties. Here we show that RPMs are not adequate to handle iterated belief change. Specifically, we show that RPMs do not always allow for the reversibility of belief change. 1bis result indicates the need for numerical strengths of belief.",
            "output": [
                "Non-monotonic Reasoning and the Reversibility of Belief Change"
            ]
        },
        {
            "id": "task1540-e8e4c951ac214b84bbf280381f7ba205",
            "input": "The quality of a Neural Machine Translation system depends substantially on the availability of sizable parallel corpora. For low-resource language pairs this is not the case, resulting in poor translation quality. Inspired by work in computer vision, we propose a novel data augmentation approach that targets low-frequency words by generating new sentence pairs containing rare words in new, synthetically created contexts. Experimental results on simulated low-resource settings show that our method improves translation quality by up to 2.9 BLEU points over the baseline and up to 3.2 BLEU over back-translation.",
            "output": [
                "Data Augmentation for Low-Resource Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-41fb234bff624c4493c381cefd39683a",
            "input": "One of the most important aims of the fields of robotics, artificial intelligence and artificial life is the design and construction of systems and machines as versatile and as reliable as living organisms at performing high level human-like tasks. But how are we to evaluate artificial systems if we are not certain how to measure these capacities in living systems, let alone how to define life or intelligence? Here I survey a concrete metric towards measuring abstract properties of natural and artificial systems, such as the ability to react to the environment and to control one’s own behaviour.",
            "output": [
                "Quantifying Natural and Artificial Intelligence in Robots and Natural Systems with an Algorithmic Behavioural Test"
            ]
        },
        {
            "id": "task1540-52101dd5049d4524a0721e203a0ea361",
            "input": "Residual learning has recently surfaced as an effective means of constructing very deep neural networks for object recognition. However, current incarnations of residual networks do not allow for the modeling and integration of complex relations between closely coupled recognition tasks or across domains. Such problems are often encountered in multimedia applications involving large-scale content recognition. We propose a novel extension of residual learning for deep networks that enables intuitive learning across multiple related tasks using cross-connections called cross-residuals. These cross-residuals connections can be viewed as a form of innetwork regularization and enables greater network generalization. We show how cross-residual learning (CRL) can be integrated in multitask networks to jointly train and detect visual concepts across several tasks. We present a single multitask cross-residual network with >40% less parameters that is able to achieve competitive, or even better, detection performance on a visual sentiment concept detection problem normally requiring multiple specialized single-task networks. The resulting multitask cross-residual network also achieves better detection performance by about 10.4% over a standard multitask residual network without cross-residuals with even a small amount of cross-task weighting.",
            "output": [
                "Deep Cross Residual Learning for Multitask Visual Recognition"
            ]
        },
        {
            "id": "task1540-52d1a147dfd844419b5c11bfa8f28404",
            "input": "In the context of contemporary monophonic music, expression can be seen as the difference between a musical performance and its symbolic representation, i.e. a musical score. In this paper, we show how Maximum Entropy (MaxEnt) models can be used to generate musical expression in order to mimic a human performance. As a training corpus, we had a professional pianist play about 150 melodies of jazz, pop, and latin jazz. The results show a good predictive power, validating the choice of our model. Additionally, we set up a listening test whose results reveal that on average, people significantly prefer the melodies generated by the MaxEnt model than the ones without any expression, or with fully random expression. Furthermore, in some cases, MaxEnt melodies are almost as popular as the human performed ones.",
            "output": [
                "Maximum entropy models for generation of expressive music"
            ]
        },
        {
            "id": "task1540-8f5eb39997324b678835cd1d6f72e1db",
            "input": "Many online communities present user-contributed responses such as reviews of products and answers to questions. User-provided helpfulness votes can highlight the most useful responses, but voting is a social process that can gain momentum based on the popularity of responses and the polarity of existing votes. We propose the Chinese Voting Process (CVP) which models the evolution of helpfulness votes as a self-reinforcing process dependent on position and presentation biases. We evaluate this model on Amazon product reviews and more than 80 StackExchange forums, measuring the intrinsic quality of individual responses and behavioral coefficients of different communities.",
            "output": [
                "Beyond Exchangeability: The Chinese Voting Process"
            ]
        },
        {
            "id": "task1540-758d437c4b5a4d1ba7a5c8c2c0ffa72b",
            "input": "It is well known that conditional indepen­ dence can be used to factorize a joint prob­ ability into a multiplication of conditional probabilities. This paper proposes a con­ structive definition of intercausal indepen­ dence, which can be used to further factorize a conditional probability. An inference algo­ rithm is developed, which makes use of both conditional independence and intercausal in­ dependence to reduce inference complexity in Bayesian networks.",
            "output": [
                "Intercausal Independence and Heterogeneous Factorization"
            ]
        },
        {
            "id": "task1540-6392682802ed4ea7ad0bb432132166f3",
            "input": "A frequent object of study in linguistic typology is the order of elements {demonstrative, adjective, numeral, noun} in the noun phrase. The goal is to predict the relative frequencies of these orders across languages. Here we use Poisson regression to statistically compare some prominent accounts of this variation. We compare feature systems derived from Cinque (2005) to feature systems given in Cysouw (2010) and Dryer (in prep). In this setting, we do not find clear reasons to prefer the model of Cinque (2005) or Dryer (in prep), but we find both of these models have substantially better fit to the typological data than the model from Cysouw (2010).",
            "output": [
                "A Statistical Comparison of Some Theories of NP Word Order"
            ]
        },
        {
            "id": "task1540-4f94cdfb177347fdae09d628f972b653",
            "input": "This work focuses on the rapid development of linguistic annotation tools for resource-poor languages. We experiment several cross-lingual annotation projection methods using Recurrent Neural Networks (RNN) models. The distinctive feature of our approach is that our multilingual word representation requires only a parallel corpus between the source and target language. More precisely, our method has the following characteristics: (a) it does not use word alignment information, (b) it does not assume any knowledge about foreign languages, which makes it applicable to a wide range of resource-poor languages, (c) it provides truly multilingual taggers. We investigate both uniand bi-directional RNN models and propose a method to include external information (for instance low level information from POS) in the RNN to train higher level taggers (for instance, super sense taggers). We demonstrate the validity and genericity of our model by using parallel corpora (obtained by manual or automatic translation). Our experiments are conducted to induce cross-lingual POS and super sense taggers.",
            "output": [
                "Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-5c049555b18740e49025622fea6ddf11",
            "input": "We derive an equation for temporal difference learning from statistical principles. Specifically, we start with the variational principle and then bootstrap to produce an updating rule for discounted state value estimates. The resulting equation is similar to the standard equation for temporal difference learning with eligibility traces, so called TD(λ), however it lacks the parameter α that specifies the learning rate. In the place of this free parameter there is now an equation for the learning rate that is specific to each state transition. We experimentally test this new learning rule against TD(λ) and find that it offers superior performance in various settings. Finally, we make some preliminary investigations into how to extend our new temporal difference algorithm to reinforcement learning. To do this we combine our update equation with both Watkins’ Q(λ) and Sarsa(λ) and find that it again offers superior performance without a learning rate parameter.",
            "output": [
                "Temporal Difference Updating without a Learning Rate"
            ]
        },
        {
            "id": "task1540-cc756518aea04e21934fe92520a2ea36",
            "input": "Existing works based on latent factor models have focused on representing the rating matrix as a product of user and item latent factor matrices, both being dense. Latent (factor) vectors define the degree to which a trait is possessed by an item or the affinity of user towards that trait. A dense user matrix is a reasonable assumption as each user will like/dislike a trait to certain extent. However, any item will possess only a few of the attributes and never all. Hence, the item matrix should ideally have a sparse structure rather than a dense one as formulated in earlier works. Therefore we propose to factor the ratings matrix into a dense user matrix and a sparse item matrix which leads us to the Blind Compressed Sensing (BCS) framework. We derive an efficient algorithm for solving the BCS problem based on Majorization Minimization (MM) technique. Our proposed approach is able to achieve significantly higher accuracy and shorter run times as compared to existing approaches.",
            "output": [
                "Blind Compressive Sensing Framework for Collaborative Filtering"
            ]
        },
        {
            "id": "task1540-d7d1c71851f149928a0d60bf3a01b35f",
            "input": "Many real-world problems involving constraints can be regarded as instances of the Max-SAT problem, which is the optimization variant of the classic satisfiability problem. In this paper, we propose a novel probabilistic approach for Max-SAT called ProMS. Our algorithm relies on a stochastic local search strategy using a novel probability distribution function with two strategies for picking variables, one based on available information and another purely random one. Moreover, while most previous algorithms based on WalkSAT choose unsatisfied clauses randomly, we introduce a novel clause selection strategy to improve our algorithm. Experimental results illustrate that ProMS outperforms many state-of-the-art stochastic local search solvers on hard unweighted random Max-SAT benchmarks.",
            "output": [
                "A Probability Distribution Strategy with Efficient Clause Selection for Hard Max-SAT Formulas"
            ]
        },
        {
            "id": "task1540-49d2976e14af48128cba20515004d588",
            "input": "The purported “black box” nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Learning Important FeaTures), an efficient and effective method for computing importance scores in a neural network. DeepLIFT compares the activation of each neuron to its ‘reference activation’ and assigns contribution scores according to the difference. We apply DeepLIFT to models trained on natural images and genomic data, and show significant advantages over gradient-based methods.",
            "output": [
                "Not Just A Black Box:  Interpretable Deep Learning by Propagating Activation Differences"
            ]
        },
        {
            "id": "task1540-5f545e4d6ebb455799ae8c9dca3e634c",
            "input": "User engagement refers to the amount of interaction an instance (e.g., tweet, news, and forum post) achieves. Ranking the items in social media websites based on the amount of user participation in them, can be used in different applications, such as recommender systems. In this paper, we consider a tweet containing a rating for a movie as an instance and focus on ranking the instances of each user based on their engagement, i.e., the total number of retweets and favorites it will gain. For this task, we define several features which can be extracted from the meta-data of each tweet. The features are partitioned into three categories: user-based, movie-based, and tweet-based. We show that in order to obtain good results, features from all categories should be considered. We exploit regression and learning to rank methods to rank the tweets and propose to aggregate the results of regression and learning to rank methods to achieve better performance. We have run our experiments on an extended version of MovieTweeting dataset provided by ACM RecSys Challenge 2014. The results show that learning to rank approach outperforms most of the regression models and the combination can improve the performance significantly.",
            "output": [
                "Regression and Learning to Rank Aggregation for User Engagement Evaluation"
            ]
        },
        {
            "id": "task1540-4b64ed401dd94dbb8e72f25abae51837",
            "input": "Analogy Based Effort Estimation (ABE) is one of the prominent methods for software effort estimation. The fundamental concept of ABE is closer to the mentality of expert estimation but with an automated procedure in which the final estimate is generated by reusing similar historical projects. The main key issue when using ABE is how to adapt the effort of the retrieved nearest neighbors. The adaptation process is an essential part of ABE to generate more successful accurate estimation based on tuning the selected raw solutions, using some adaptation strategy. In this study we show that there are three interrelated decision variables that have great impact on the success of adaptation method: (1) number of nearest analogies (k), (2) optimum feature set needed for adaptation, and (3) adaptation weights. To find the right decision regarding these variables, one need to study all possible combinations and evaluate them individually to select the one that can improve all prediction evaluation measures. The existing evaluation measures usually behave differently, presenting sometimes opposite trends in evaluating prediction methods. This means that changing one decision variable could improve one evaluation measure while it is decreasing the others. Therefore, the main theme of this research is how to come up with best decision variables that improve adaptation strategy and thus, the overall evaluation measures without degrading the others. The impact of these decisions together has not been investigated before, therefore we propose to view the building of adaptation procedure as a multi-objective optimization problem. The Particle Swarm Optimization Algorithm (PSO) is utilized to find the optimum solutions for such decision variables based on optimizing multiple evaluation measures. We evaluated the proposed approaches over 15 datasets and using 4 evaluation measures. After extensive experimentation we found that: (1) predictive performance of ABE has noticeably been improved, (2) optimizing all decision variables together is more efficient than ignoring any one of them. (3) Optimizing decision variables for each project individually yield better accuracy than optimizing them for the whole dataset.",
            "output": [
                "Pareto Efficient Multi Objective Optimization for Local Tuning of Analogy Based Estimation"
            ]
        },
        {
            "id": "task1540-7c09f85f578f460fbe1c15115afae877",
            "input": "Computing the probability of evidence even with known error bounds is NP-hard. In this paper we address this hard problem by settling on an easier problem. We propose an approximation which provides high confidence lower bounds on probability of evidence but does not have any guarantees in terms of relative or absolute error. Our proposed approximation is a randomized importance sampling scheme that uses the Markov inequality. However, a straight-forward application of the Markov inequality may lead to poor lower bounds. We therefore propose several heuristic measures to improve its performance in practice. Empirical evaluation of our scheme with stateof-the-art lower bounding schemes reveals the promise of our approach.",
            "output": [
                "Studies in Lower Bounding Probability of Evidence using the Markov Inequality"
            ]
        },
        {
            "id": "task1540-fde34b1273b14536b9f82186975130c7",
            "input": "Most contemporary multi-task learning methods assume linear models. This setting is considered shallow in the era of deep learning. In this paper, we present a new deep multi-task representation learning framework that learns cross-task sharing structure at every layer in a deep network. Our approach is based on generalising the matrix factorisation techniques explicitly or implicitly used by many conventional MTL algorithms to tensor factorisation, to realise automatic learning of end-to-end knowledge sharing in deep networks. This is in contrast to existing deep learning approaches that need a user-defined multi-task sharing strategy. Our approach applies to both homogeneous and heterogeneous MTL. Experiments demonstrate the efficacy of our deep multi-task representation learning in terms of both higher accuracy and fewer design choices.",
            "output": [
                "DEEP MULTI-TASK REPRESENTATION LEARNING: A TENSOR FACTORISATION APPROACH"
            ]
        },
        {
            "id": "task1540-412fc33783714f9c9dfe0bde7abd4477",
            "input": "This work presents a fast and scalable algorithm for incremental learning of Gaussian mixture models. By performing rank-one updates on its precision matrices and determinants, its asymptotic time complexity is of O ( NKD ) for N data points, K Gaussian components and D dimensions. The resulting algorithm can be applied to high dimensional tasks, and this is confirmed by applying it to the classification datasets MNIST and CIFAR-10. Additionally, in order to show the algorithm’s applicability to function approximation and control tasks, it is applied to three reinforcement learning tasks and its data-efficiency is evaluated.",
            "output": [
                "Scalable and Incremental Learning of Gaussian Mixture Models"
            ]
        },
        {
            "id": "task1540-b3352a7ba98d4e6facc2f487b7a39c10",
            "input": "Kernel classifiers and regressors designed for structured data, such as sequences, trees and graphs, have significantly advanced in a number of interdisciplinary areas such as computational biology and drug design. Typically, kernel functions are designed beforehand for a data type which either exploit statistics of the structures or make use of probabilistic generative models, and then a discriminative classifier is learned based on the kernels via convex optimization. However, such an elegant two-stage approach also limited kernel methods from scaling up to millions of data points, and exploiting discriminative information to learn feature representations. We propose an effective and scalable approach for structured data representation which is based on the idea of embedding latent variable models into feature spaces, and learning such feature spaces using discriminative information. Furthermore, our feature learning algorithm runs a sequence of function mappings in a way similar to graphical model inference procedures, such as mean field and belief propagation. In real world applications involving sequences and graphs, we showed that the proposed approach is much more scalable than alternatives while at the same time produce comparable results to the state-of-the-art in terms of classification and regression.",
            "output": [
                "Discriminative Embeddings of Latent Variable Models for Structured Data"
            ]
        },
        {
            "id": "task1540-4ddb5981b56846f08e024d34b52edc8f",
            "input": "We show that strategies implemented in automatic theorem proving involve an interesting tradeoff between execution speed, proving speedup/computational time and usefulness of information. We advance formal definitions for these concepts by way of a notion of normality related to an expected (optimal) theoretical speedup when adding useful information (other theorems as axioms), as compared with actual strategies that can be effectively and efficiently implemented. We propose the existence of an ineluctable tradeoff between this normality and computational time complexity. The argument quantifies the usefulness of information in terms of (positive) speed-up. The results disclose a kind of no-free-lunch scenario and a tradeoff of a fundamental nature. The main theorem in this paper together with the numerical experiment—undertaken using two different automatic theorem provers (AProS and Prover9) on random theorems of propositional logic—provide strong theoretical and empirical arguments for the fact that finding new useful information for solving a specific problem (theorem) is, in general, as hard as the problem (theorem) itself.",
            "output": [
                "Rare Speed-up in Automatic Theorem Proving Reveals Tradeoff Between Computational Time and Information Value"
            ]
        },
        {
            "id": "task1540-3d8dfe5709ed4496bc5b50442501da91",
            "input": "This report presents a general model of the architecture of information systems for the children’s speech recognition. It presents a model of the speech data stream and how it works. The result of these studies and presented veins architectural model shows that research needs to be focused on acoustic-phonetic modeling in order to improve the quality of children's speech recognition and the sustainability of the systems to noise and changes in transmission environment. Another important aspect is the development of more accurate algorithms for modeling of spontaneous child speech.",
            "output": [
                "On model architecture for a children’s speech recognition interactive dialog system"
            ]
        },
        {
            "id": "task1540-23d8cfac301a44b9a3f7f9075fa6a7ed",
            "input": "Pointwise matches between two time series are of great importance in time series analysis, and dynamic time warping (DTW) is known to provide generally reasonable matches. There are situations where time series alignment should be invariant to scaling and offset in amplitude or where local regions of the considered time series should be strongly reflected in pointwise matches. Two different variants of DTW, affine DTW (ADTW) and regional DTW (RDTW), are proposed to handle scaling and offset in amplitude and provide regional emphasis respectively. Furthermore, ADTW and RDTW can be combined in two different ways to generate alignments that incorporate advantages from both methods, where the affine model can be applied either globally to the entire time series or locally to each region. The proposed alignment methods outperform DTW on specific simulated datasets, and one-nearest-neighbor classifiers using their associated difference measures are competitive with the difference measures associated with state-of-the-art alignment methods on real datasets.",
            "output": [
                "Affine and Regional Dynamic Time Warping"
            ]
        },
        {
            "id": "task1540-aa0ec363cb3f439f942f02153e2d4e09",
            "input": "We consider the problem of sequentially choosing between a set of unbiased Monte Carlo estimators to minimize the mean-squared-error (MSE) of a final combined estimate. By reducing this task to a stochastic multi-armed bandit problem, we show that well developed allocation strategies can be used to achieve an MSE that approaches that of the best estimator chosen in retrospect. We then extend these developments to a scenario where alternative estimators have different, possibly stochastic costs. The outcome is a new set of adaptive Monte Carlo strategies that provide stronger guarantees than previous approaches while offering practical advantages.",
            "output": [
                "Adaptive Monte Carlo via Bandit Allocation"
            ]
        },
        {
            "id": "task1540-5a6c483b9ee545ca96e3d3cf55acd468",
            "input": "The paper presents an application of Conformal Predictors to a chemoinformatics problem of identifying activities of chemical compounds. The paper addresses some specific challenges of this domain: a large number of compounds (training examples), high-dimensionality of feature space, sparseness and a strong class imbalance. A variant of conformal predictors called Inductive Mondrian Conformal Predictor is applied to deal with these challenges. Results are presented for several non-conformity measures (NCM) extracted from underlying algorithms and different kernels. A number of performance measures are used in order to demonstrate the flexibility of Inductive Mondrian Conformal Predictors in dealing with such a complex set of data.",
            "output": [
                "Conformal Predictors for Compound Activity Prediction"
            ]
        },
        {
            "id": "task1540-ba26ac712d6d4e6f9f3a8b77626421e1",
            "input": "Recent advances in deep learning have led various applications to unprecedented achievements, which could potentially bring higher intelligence to a broad spectrum of mobile and ubiquitous applications. Although existing studies have demonstrated the eectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices, they overlooked the reliability of mobile computing models. Reliability measurements such as predictive uncertainty estimations are key factors for improving the decision accuracy and user experience. In this work, we propose RDeepSense, the rst deep learning model that provides well-calibrated uncertainty estimations for resource-constrained mobile and embedded devices. RDeepSense enables the predictive uncertainty by adopting a tunable proper scoring rule as the training criterion and dropout as the implicit Bayesian approximation, which theoretically proves its correctness. To reduce the computational complexity, RDeepSense employs ecient dropout and predictive distribution estimation instead of model ensemble or sampling-based method for inference operations. We evaluate RDeepSense with four mobile sensing applications using Intel Edison devices. Results show that RDeepSense can reduce around 90% of the energy consumption while producing superior uncertainty estimations and preserving at least the same model accuracy compared with other state-of-the-art methods.",
            "output": [
                "RDeepSense: Reliable Deep Mobile Computing Models with Uncertainty Estimations"
            ]
        },
        {
            "id": "task1540-c5b57adf6c274c3f80037a511217a141",
            "input": "In this report, we describe a Theano-based AlexNet (Krizhevsky et al., 2012) implementation and its naive data parallelism on multiple GPUs. Our performance on 2 GPUs is comparable with the state-of-art Caffe library (Jia et al., 2014) run on 1 GPU. To the best of our knowledge, this is the first open-source Python-based AlexNet implementation to-date.",
            "output": [
                "TION WITH MULTIPLE GPUS"
            ]
        },
        {
            "id": "task1540-c22e833de4604470a2483a530b3eda89",
            "input": "We consider online learning algorithms that guarantee worst-case regret rates in adversarial environments (so they can be deployed safely and will perform robustly), yet adapt optimally to favorable stochastic environments (so they will perform well in a variety of settings of practical importance). We quantify the friendliness of stochastic environments by means of the well-known Bernstein (a.k.a. generalized Tsybakov margin) condition. For two recent algorithms (Squint for the Hedge setting and MetaGrad for online convex optimization) we show that the particular form of their data-dependent individual-sequence regret guarantees implies that they adapt automatically to the Bernstein parameters of the stochastic environment. We prove that these algorithms attain fast rates in their respective settings both in expectation and with high probability.",
            "output": [
                "Combining Adversarial Guarantees and Stochastic Fast Rates in Online Learning"
            ]
        },
        {
            "id": "task1540-4664ee9c79504d5a8cb3e7bbc8ded7b7",
            "input": "In this paper we introduce Latent Tree Language Model (LTLM), a novel approach to language modeling that encodes syntax and semantics of a given sentence as a tree of word roles. The learning phase iteratively updates the trees by moving nodes according to Gibbs sampling. We introduce two algorithms to infer a tree for a given sentence. The first one is based on Gibbs sampling. It is fast, but does not guarantee to find the most probable tree. The second one is based on dynamic programming. It is slower, but guarantees to find the most probable tree. We provide comparison of both algorithms. We combine LTLM with 4-gram Modified Kneser-Ney language model via linear interpolation. Our experiments with English and Czech corpora show significant perplexity reductions (up to 46% for English and 49% for Czech) compared with standalone 4-gram Modified Kneser-Ney language model.",
            "output": [
                "Latent Tree Language Model"
            ]
        },
        {
            "id": "task1540-1b72dc450b164216ac0140ff5d558614",
            "input": "Past research has challenged us with the task of showing relational patterns between text-based data and then clustering for predictive analysis using Golay Code technique. We focus on a novel approach to extract metaknowledge in multimedia datasets. Our collaboration has been an on-going task of studying the relational patterns between datapoints based on metafeatures extracted from metaknowledge in multimedia datasets. Those selected are significant to suit the mining technique we applied, Golay Code algorithm. In this research paper we summarize findings in optimization of metaknowledge representation for 23-bit representation of structured and unstructured multimedia data in order to be processed in 23-bit Golay Code for cluster recognition. Keywords— Big Multimedia Data Processing and Analytics; Information Retrieval Challenges; Content Identification, Metafeature Extraction and Selection; Metalearning System; 23-Bit Meta-knowledge template; Knowledge Discovery, Golay Code.",
            "output": [
                "Novel Metaknowledge-based Processing Technique for Multimedia Big Data clustering challenges"
            ]
        },
        {
            "id": "task1540-d4c19f4aaa6b4f08ac4a30a2cee18f01",
            "input": "In natural-language discourse, related events tend to appear near each other to describe a larger scenario. Such structures can be formalized by the notion of a frame (a.k.a. template), which comprises a set of related events and prototypical participants and event transitions. Identifying frames is a prerequisite for information extraction and natural language generation, and is usually done manually. Methods for inducing frames have been proposed recently, but they typically use ad hoc procedures and are difficult to diagnose or extend. In this paper, we propose the first probabilistic approach to frame induction, which incorporates frames, events, participants as latent topics and learns those frame and event transitions that best explain the text. The number of frames is inferred by a novel application of a split-merge method from syntactic parsing. In end-to-end evaluations from text to induced frames and extracted facts, our method produced state-of-the-art results while substantially reducing engineering effort.",
            "output": [
                "Probabilistic Frame Induction∗"
            ]
        },
        {
            "id": "task1540-c9bf0c2ba7144ae2953bf5aa41a51ee2",
            "input": "Syntactic parsing, the process of obtaining the internal structure of sentences in natural languages, is a crucial task for artificial intelligence applications that need to extract meaning from natural language text or speech. Sentiment analysis is one example of application for which parsing has recently proven useful. In recent years, there have been significant advances in the accuracy of parsing algorithms. In this article, we perform an empirical, task-oriented evaluation to determine how parsing accuracy influences the performance of a state-of-the-art sentiment analysis system that determines the polarity of sentences from their parse trees. In particular, we evaluate the system using four well-known dependency parsers, including both current models with state-of-the-art accuracy and more innacurate models which, however, require less computational resources. The experiments show that all of the parsers produce similarly good results in the sentiment analysis task, without their accuracy having any relevant influence on the results. Since parsing is currently a task with a relatively high computational cost that varies strongly between algorithms, this suggests that sentiment analysis researchers and users should prioritize speed over accuracy when choosing a parser; and parsing researchers should investigate models that improve speed further, even at some cost to accuracy.",
            "output": [
                "How Important is Syntactic Parsing Accuracy? An Empirical Evaluation on Sentiment Analysis"
            ]
        },
        {
            "id": "task1540-c57fc5158c28435c9daee21ec702ee3a",
            "input": "We introduce a new model of interactive learning in which an expert examines the predictions of a learner and partially fixes them if they are wrong. Although this kind of feedback is not i.i.d., we show statistical generalization bounds on the quality of the learned model.",
            "output": [
                "Learning from partial correction"
            ]
        },
        {
            "id": "task1540-41eac14527f34cac9777658314789383",
            "input": "As mobile devices have become indispensable in modern life, mobile security is becoming much more important. Traditional password or PIN-like point-of-entry security measures score low on usability and are vulnerable to brute force and other types of attacks. In order to improve mobile security, an adaptive neuro-fuzzy inference system(ANFIS)-based implicit authentication system is proposed in this paper to provide authentication in a continuous and transparent manner. To illustrate the applicability and capability of ANFIS in our implicit authentication system, experiments were conducted on behavioural data collected for up to 12 weeks from different Android users. The ability of the ANFIS-based system to detect an adversary is also tested with scenarios involving an attacker with varying levels of knowledge. The results demonstrate that ANFIS is a feasible and efficient approach for implicit authentication with an average of 95% user recognition rate. Moreover, the use of ANFIS-based system for implicit authentication significantly reduces manual tuning and configuration tasks due to its selflearning capability.",
            "output": [
                "Continuous Implicit Authentication for Mobile Devices based on Adaptive Neuro-Fuzzy Inference System"
            ]
        },
        {
            "id": "task1540-e41bebeda74a4e2ab282bcf179b10c06",
            "input": "RCC8 is a popular fragment of the region connection calculus, in which qualitative spatial relations between regions, such as adjacency, overlap and parthood, can be expressed. While RCC8 is essentially dimensionless, most current applications are confined to reasoning about two-dimensional or threedimensional physical space. In this paper, however, we are mainly interested in conceptual spaces, which typically are high-dimensional Euclidean spaces in which the meaning of natural language concepts can be represented using convex regions. The aim of this paper is to analyze how the restriction to convex regions constrains the realizability of networks of RCC8 relations. First, we identify all ways in which the set of RCC8 base relations can be restricted to guarantee that consistent networks can be convexly realized in respectively 1D, 2D, 3D, and 4D. Most surprisingly, we find that if the relation ‘partially overlaps’ is disallowed, all consistent atomic RCC8 networks can be convexly realized in 4D. If instead refinements of the relation ‘part of’ are disallowed, all consistent atomic RCC8 relations can be convexly realized in 3D. We furthermore show, among others, that any consistent RCC8 network with 2n + 1 variables can be realized using convex regions in the n-dimensional Euclidean space.",
            "output": [
                "Realizing RCC8 networks using convex regions"
            ]
        },
        {
            "id": "task1540-2da5d516f9a149a4ad2737d44ea5f2d3",
            "input": "A standard assumption in machine learning is the exchangeability of data, which is equivalent to assuming that the examples are generated from the same probability distribution independently. This paper is devoted to testing the assumption of exchangeability on-line: the examples arrive one by one, and after receiving each example we would like to have a valid measure of the degree to which the assumption of exchangeability has been falsified. Such measures are provided by exchangeability martingales. We extend known techniques for constructing exchangeability martingales and show that our new method is competitive with the martingales introduced before. Finally we investigate the performance of our testing method on two benchmark datasets, USPS and Statlog Satellite data; for the former, the known techniques give satisfactory results, but for the latter our new more flexible method becomes necessary.",
            "output": [
                "Plug-in martingales for testing exchangeability on-line"
            ]
        },
        {
            "id": "task1540-8c991e150c814d899c8eae1b28586f5d",
            "input": "This manuscript develops the theory of agglomerative clustering with Bregman divergences. Geometric smoothing techniques are developed to deal with degenerate clusters. To allow for cluster models based on exponential families with overcomplete representations, Bregman divergences are developed for nondifferentiable convex functions.",
            "output": [
                "Agglomerative Bregman Clustering"
            ]
        },
        {
            "id": "task1540-f48074c48c2540f59b232db49106b0e0",
            "input": "Sequence prediction and classification are ubiquitous and challenging problems in machine learning that can require identifying complex dependencies between temporally distant inputs. Recurrent Neural Networks (RNNs) have the ability, in theory, to cope with these temporal dependencies by virtue of the short-term memory implemented by their recurrent (feedback) connections. However, in practice they are difficult to train successfully when the long-term memory is required. This paper introduces a simple, yet powerful modification to the standard RNN architecture, the Clockwork RNN (CW-RNN), in which the hidden layer is partitioned into separate modules, each processing inputs at its own temporal granularity, making computations only at its prescribed clock rate. Rather than making the standard RNN models more complex, CW-RNN reduces the number of RNN parameters, improves the performance significantly in the tasks tested, and speeds up the network evaluation. The network is demonstrated in preliminary experiments involving two tasks: audio signal generation and TIMIT spoken word classification, where it outperforms both RNN and LSTM networks.",
            "output": [
                "A Clockwork RNN"
            ]
        },
        {
            "id": "task1540-ab1200d3ff1146c2b8cb0823b7498ab0",
            "input": "Programming languages themselves have a limited number of reserved keywords and character based tokens that define the language specification. However, programmers have a rich use of natural language within their code through comments, text literals and naming entities. The programmer defined names that can be found in source code are a rich source of information to build a high level understanding of the project. The goal of this paper is to apply topic modeling to names used in over 13.6 million repositories and perceive the inferred topics. One of the problems in such a study is the occurrence of duplicate repositories not officially marked as forks (obscure forks). We show how to address it using the same identifiers which are extracted for topic modeling. We open with a discussion on naming in source code, we then elaborate on our approach to remove exact duplicate and fuzzy duplicate repositories using Locality Sensitive Hashing on the bag-of-words model and then discuss our work on topic modeling; and finally present the results from our data analysis together with open-access to the source code, tools and datasets.",
            "output": [
                "Topic modeling of public repositories at scale using names in source code"
            ]
        },
        {
            "id": "task1540-0e3d45b7964d4f86b33e577915aab30f",
            "input": "Transfer learning is a vital technique that generalizes models trained for one setting or task to other settings or tasks. For example in speech recognition, an acoustic model trained for one language can be used to recognize speech in another language, with little or no re-training data. Transfer learning is closely related to multi-task learning (cross-lingual vs. multilingual), and is traditionally studied in the name of ‘model adaptation’. Recent advance in deep learning shows that transfer learning becomes much easier and more effective with high-level abstract features learned by deep models, and the ‘transfer’ can be conducted not only between data distributions and data types, but also between model structures (e.g., shallow nets and deep nets) or even model types (e.g., Bayesian models and neural models). This review paper summarizes some recent prominent research towards this direction, particularly for speech and language processing. We also report some results from our group and highlight the potential of this very interesting research field.",
            "output": [
                "Transfer Learning for Speech and Language Processing"
            ]
        },
        {
            "id": "task1540-6efd47cad32d46ef81d7b725a430d6d6",
            "input": "The paradigm shift from shallow classifiers with hand-crafted features to endto-end trainable deep learning models has shown significant improvements on supervised learning tasks. Despite the promising power of deep neural networks (DNN), how to alleviate overfitting during training has been a research topic of interest. In this paper, we present a Generative-Discriminative Variational Model (GDVM) for visual classification, in which we introduce a latent variable inferred from inputs for exhibiting generative abilities towards prediction. In other words, our GDVM casts the supervised learning task as a generative learning process, with data discrimination to be jointly exploited for improved classification. In our experiments, we consider the tasks of multi-class classification, multi-label classification, and zero-shot learning. We show that our GDVM performs favorably against the baselines or recent generative DNN models.",
            "output": [
                "Generative-Discriminative Variational Model for Visual Recognition"
            ]
        },
        {
            "id": "task1540-37450cbe74fc4964a8160f4e1191712e",
            "input": "Despite tremendous progress in computer vision, there has not been an attempt for machine learning on very large-scale medical image databases. We present an interleaved text/image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital’s Picture Archiving and Communication System. With natural language processing, we mine a collection of representative ∼216K two-dimensional key images selected by clinicians for diagnostic reference, and match the images with their descriptions in an automated manner. Our system interleaves between unsupervised learning and supervised learning on documentand sentence-level text collections, to generate semantic labels and to predict them given an image. Given an image of a patient scan, semantic topics in radiology levels are predicted, and associated key-words are generated. Also, a number of frequent disease types are detected as present or absent, to provide more specific interpretation of a patient scan. This shows the potential of largescale learning and prediction in electronic patient records available in most modern clinical institutions.",
            "output": [
                "Interleaved Text/Image Deep Mining on a Large-Scale Radiology Database for Automated Image Interpretation"
            ]
        },
        {
            "id": "task1540-7e8301266aa547d89f8024ae5f48d1c4",
            "input": "We improve the computational complexity of online learning algorithms that require to often recompute least squares regression estimates of parameters. We propose two stochastic gradient descent schemes with randomisation in order to efficiently track the true solutions of the regression problems achieving an O(d) improvement in complexity, where d is the dimension of the data. The first algorithm assumes strong convexity in the regression problem, and we provide bounds on the error both in expectation and high probability (the latter is often needed to provide theoretical guarantees for higher level algorithms). The second algorithm deals with cases where strong convexity of the regression problem cannot be guaranteed and uses adaptive regularisation. We again give error bounds in both expectation and high probability. We apply our approaches to the linear bandit algorithms PEGE and ConfidenceBall and demonstrate significant gains in complexity in both cases. Since strong convexity is guaranteed by the PEGE algorithm, we lose only logarithmic factors in the regret performance of the algorithm. On the other hand, in the ConfidenceBall algorithm we adaptively regularise to ensure strong convexity, and this results in an Õ(n1/5)1 deterioration of the regret.",
            "output": [
                "Online gradient descent for least squares regression: Non-asymptotic bounds and application to bandits"
            ]
        },
        {
            "id": "task1540-a5d34ce4f3aa478295cd2c5e238701b8",
            "input": "Bi-directional LSTMs have emerged as a standard method for obtaining per-token vector representations serving as input to various token labeling tasks (whether followed by Viterbi prediction or independent classification). This paper proposes an alternative to Bi-LSTMs for this purpose: iterated dilated convolutional neural networks (ID-CNNs), which have better capacity than traditional CNNs for large context and structured prediction. We describe a distinct combination of network structure, parameter sharing and training procedures that is not only more accurate than Bi-LSTM-CRFs, but also 8x faster at test time on long sequences. Moreover, ID-CNNs with independent classification enable a dramatic 14x testtime speedup, while still attaining accuracy comparable to the Bi-LSTM-CRF. We further demonstrate the ability of IDCNNs to combine evidence over long sequences by demonstrating their improved accuracy on whole-document (rather than per-sentence) inference. Unlike LSTMs whose sequential processing on sentences of length N requires O(N) time even in the face of parallelism, IDCNNs permit fixed-depth convolutions to run in parallel across entire documents. Today when many companies run basic NLP on the entire web and large-volume traffic, faster methods are paramount to saving time and energy costs.",
            "output": [
                "Fast and Accurate Sequence Labeling with Iterated Dilated Convolutions"
            ]
        },
        {
            "id": "task1540-9e54e6214fda4a3c9d7dbc8a0d2b896e",
            "input": "Natural language generation (NLG) is a critical component of spoken dialogue and it has a significant impact both on usability and perceived quality. Most NLG systems in common use employ rules and heuristics and tend to generate rigid and stylised responses without the natural variation of human language. They are also not easily scaled to systems covering multiple domains and languages. This paper presents a statistical language generator based on a semantically controlled Long Short-term Memory (LSTM) structure. The LSTM generator can learn from unaligned data by jointly optimising sentence planning and surface realisation using a simple cross entropy training criterion, and language variation can be easily achieved by sampling from output candidates. With fewer heuristics, an objective evaluation in two differing test domains showed the proposed method improved performance compared to previous methods. Human judges scored the LSTM system higher on informativeness and naturalness and overall preferred it to the other systems.",
            "output": [
                "Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems"
            ]
        },
        {
            "id": "task1540-826e298a460841babdca4f546dd1313c",
            "input": "We propose a method for using synthetic data to help learning classifiers. Synthetic data, even is generated based on real data, normally results in a shift from the distribution of real data in feature space. To bridge the gap between the real and synthetic data, and jointly learn from synthetic and real data, this paper proposes a Multichannel Autoencoder(MCAE). We show that by suing MCAE, it is possible to learn a better feature representation for classification. To evaluate the proposed approach, we conduct experiments on two types of datasets. Experimental results on two datasets validate the efficiency of our MCAE model and our methodology of generating synthetic data.",
            "output": [
                "Learning Classifiers from Synthetic Data Using a Multichannel Autoencoder"
            ]
        },
        {
            "id": "task1540-7deaed5c2ceb433ca1d6323afd77d8c5",
            "input": "Unsupervised dependency parsing, which tries to discover linguistic dependency structures from unannotated data, is a very challenging task. Almost all previous work on this task focuses on learning generative models. In this paper, we develop an unsupervised dependency parsing model based on the CRF autoencoder. The encoder part of our model is discriminative and globally normalized which allows us to use rich features as well as universal linguistic priors. We propose an exact algorithm for parsing as well as a tractable learning algorithm. We evaluated the performance of our model on eight multilingual treebanks and found that our model achieved comparable performance with state-of-the-art approaches.",
            "output": [
                "CRF Autoencoder for Unsupervised Dependency Parsing∗"
            ]
        },
        {
            "id": "task1540-3881c6f499874e57a559c53d96d58b77",
            "input": "We propose a regularized linear learning algorithm to sequence groups of features, where each group incurs test-time cost or computation. Specifically, we develop a simple extension to Orthogonal Matching Pursuit (OMP) that respects the structure of groups of features with variable costs, and we prove that it achieves nearoptimal anytime linear prediction at each budget threshold where a new group is selected. Our algorithm and analysis extends to generalized linear models with multi-dimensional responses. We demonstrate the scalability of the resulting approach on large real-world data-sets with many feature groups associated with test-time computational costs. Our method improves over Group Lasso and Group OMP in the anytime performance of linear predictions, measured in timeliness[7], an anytime prediction performance metric, while providing rigorous performance guarantees.",
            "output": [
                "Efficient Feature Group Sequencing for Anytime Linear Prediction"
            ]
        },
        {
            "id": "task1540-91e7695ed6e44b679523e589dc59ea44",
            "input": "There is a brief description of the probabilistic causal graph model for representing, reasoning with, and learn­ ing causal structure using Bayesian networks. It is then argued that this model is closely related to how humans reason with and learn causal structure. It is shown that studies in psychology on discounting (reasoning concern­ ing how the presence of one cause of an effect makes an­ other cause less probable) support the hypothesis that humans reach the same judgments as algorithms for do­ ing inference in Bayesian networks. Next, it is shown how studies by Piaget indicate that humans learn causal structure by observing the same independencies and de­ pendencies as those used by certain algorithms for learn­ ing the structure of a Bayesian network. Based on this indication, a subjective definition of causality is for­ warded. Finally, methods for further testing the accu­ racy of these claims are discussed.",
            "output": [
                "THE CoGNITIVE PROCESSING OF CAUSAL KNOWLEDGE"
            ]
        },
        {
            "id": "task1540-80ff2311b20f4552aac6b83648368c31",
            "input": "Chain graphs combine directed and undi­ rected graphs and their underlying mathe­ matics combines properties of the two. This paper gives a simplified definition of chain graphs based on a hierarchical combination of Bayesian (directed) and Markov (undirected) networks. Examples of a chain graph are multivariate feed-forward networks, cluster­ ing with conditional interaction between vari­ ables, and forms of Bayes classifiers. Chain graphs are then extended using the notation of plates so that samples and data analysis problems can be represented in a graphical model as well. Implications for learning are discussed in the conclusion.",
            "output": [
                "Chain graphs for learning"
            ]
        },
        {
            "id": "task1540-7430e9f95f914384a8947e01a1c3276b",
            "input": "We approach the challenging problem of generating highlights from sports broadcasts utilizing audio information only. A language-independent, multi-stage classification approach is employed for detection of key acoustic events which then act as a platform for summarization of highlight scenes. Objective results and human experience indicate that our system is highly efficient.",
            "output": [
                "Sports highlights generation based on acoustic events detection: A rugby case study"
            ]
        },
        {
            "id": "task1540-d06afd1952d34ad2a93e0493d311df0e",
            "input": "We propose a black-box variational inference method to approximate intractable distributions with an increasingly rich approximating class. Our method, termed variational boosting, iteratively refines an existing variational approximation by solving a sequence of optimization problems, allowing the practitioner to trade computation time for accuracy. We show how to expand the variational approximating class by incorporating additional covariance structure and by introducing new components to form a mixture. We apply variational boosting to synthetic and real statistical models, and show that resulting posterior inferences compare favorably to existing posterior approximation algorithms in both accuracy and efficiency.",
            "output": [
                "Variational Boosting: Iteratively Refining Posterior Approximations"
            ]
        },
        {
            "id": "task1540-d68195d7a2c94da9bb60e7d8c3c08a8a",
            "input": "In this paper we study the application of convolutional neural networks for jointly detecting objects depicted in still images and estimating their 3D pose. We identify different feature representations of oriented objects, and energies that lead a network to learn this representations. The choice of the representation is crucial since the pose of an object has a natural, continuous structure while its category is a discrete variable. We evaluate the different approaches on the joint object detection and pose estimation task of the Pascal3D+ benchmark using Average Viewpoint Precision. We show that a classification approach on discretized viewpoints achieves state-of-the-art performance for joint object detection and pose estimation, and significantly outperforms existing baselines on this benchmark. We also show that performing the two tasks jointly can improve significantly the detection performances.",
            "output": [
                "A COMPARATIVE STUDY"
            ]
        },
        {
            "id": "task1540-56c47bf35e4743edb7f658e94d0e889a",
            "input": "We address the statistical and optimization impacts of using classical sketch versus Hessian sketch to solve approximately the Matrix Ridge Regression (MRR) problem. Prior research has considered the effects of classical sketch on least squares regression (LSR), a strictly simpler problem. We establish that classical sketch has a similar effect upon the optimization properties of MRR as it does on those of LSR—namely, it recovers nearly optimal solutions. In contrast, Hessian sketch does not have this guarantee; instead, the approximation error is governed by a subtle interplay between the “mass” in the responses and the optimal objective value. For both types of approximations, the regularization in the sketched MRR problem gives it significantly different statistical properties from the sketched LSR problem. In particular, there is a bias-variance trade-off in sketched MRR that is not present in sketched LSR. We provide upper and lower bounds on the biases and variances of sketched MRR; these establish that the variance is significantly increased when classical sketches are used, while the bias is significantly increased when using Hessian sketches. Empirically, sketched MRR solutions can have risks that are higher by an order-of-magnitude than those of the optimal MRR solutions. We establish theoretically and empirically that model averaging greatly decreases this gap. Thus, in the distributed setting, sketching combined with model averaging is a powerful technique that quickly obtains near-optimal solutions to the MRR problem while greatly mitigating the statistical risks incurred by sketching.",
            "output": [
                "Sketched Ridge Regression: Optimization Perspective, Statistical Perspective, and Model Averaging"
            ]
        },
        {
            "id": "task1540-e7152074f76948fb8ec3050b1d30bac0",
            "input": "This paper presents a Bayesian optimization method with exponential convergence without the need of auxiliary optimization and without the δ-cover sampling. Most Bayesian optimization methods require auxiliary optimization: an additional non-convex global optimization problem, which can be time-consuming and hard to implement in practice. Also, the existing Bayesian optimization method with exponential convergence [1] requires access to the δ-cover sampling, which was considered to be impractical [1, 2]. Our approach eliminates both requirements and achieves an exponential convergence rate.",
            "output": [
                "Bayesian Optimization with Exponential Convergence"
            ]
        },
        {
            "id": "task1540-81fd13f2e29b4552bb369908c010581c",
            "input": "Movie ratings play an important role both in determining the likelihood of a potential viewer to watch the movie and in reflecting the current viewer satisfaction with the movie. They are available in several sources like the television guide, best-selling reference books, newspaper columns, and television programs. Furthermore, movie ratings are crucial for recommendation engines that track the behavior of all users and utilize the information to suggest items they might like. Movie ratings in most cases, thus, provide information that might be more important than movie feature-based data. It is intuitively appealing that information about the viewing preferences in movie genres is sufficient for predicting a genre of an unlabeled movie. In order to predict movie genres, we treat ratings as a feature vector, apply the Bernoulli event model to estimate the likelihood of a movies given genre, and evaluate the posterior probability of the genre of a given movie using the Bayes rule. The goal of the proposed technique is to efficiently use the movie ratings for the task of predicting movie genres. In our approach we attempted to answer the question: ”Given the set of users who watched a movie, is it possible to predict the genre of a movie based on its ratings?” Our simulation results with MovieLens 100k data demonstrated the efficiency and accuracy of our proposed technique, achieving 59% prediction rate for exact prediction and 69% when including correlated genres.",
            "output": [
                "A movie genre prediction based on Multivariate Bernoulli model and genre correlations"
            ]
        },
        {
            "id": "task1540-04e11e6af38f432880d35a8794a44f6c",
            "input": "We study the effectiveness of neural sequence models for premise selection in automated theorem proving, one of the main bottlenecks in the formalization of mathematics. We propose a two stage approach for this task that yields good results for the premise selection task on the Mizar corpus while avoiding the handengineered features of existing state-of-the-art models. To our knowledge, this is the first time deep learning has been applied to theorem proving.",
            "output": [
                "DeepMath - Deep Sequence Models for Premise Selection"
            ]
        },
        {
            "id": "task1540-2257065e68bf402797b7cd51d1c65a41",
            "input": "This report presents Giraffe, a chess engine that uses self-play to discover all its domain-specific knowledge, with minimal hand-crafted knowledge given by the programmer. Unlike previous attempts using machine learning only to perform parametertuning on hand-crafted evaluation functions, Giraffe’s learning system also performs automatic feature extraction and pattern recognition. The trained evaluation function performs comparably to the evaluation functions of state-of-the-art chess engines all of which containing thousands of lines of carefully hand-crafted pattern recognizers, tuned over many years by both computer chess experts and human chess masters. Giraffe is the most successful attempt thus far at using end-to-end machine learning to play chess. We also investigated the possibility of using probability thresholds instead of depth to shape search trees. Depth-based searches form the backbone of virtually all chess engines in existence today, and is an algorithm that has become well-established over the past half century. Preliminary comparisons between a basic implementation of probability-based search and a basic implementation of depth-based search showed that our new probability-based approach performs moderately better than the established approach. There are also evidences suggesting that many successful ad-hoc add-ons to depth-based searches are generalized by switching to a probability-based search. We believe the probability-based search to be a more fundamentally correct way to perform minimax. Finally, we designed another machine learning system to shape search trees within the probability-based search framework. Given any position, this system estimates the probability of each of the moves being the best move without looking ahead. The system is highly effective the actual best move is within the top 3 ranked moves 70% of the time, out of an average of approximately 35 legal moves from each position. This also resulted in a significant increase in playing strength. With the move evaluator guiding a probability-based search using the learned evaluator, Giraffe plays at approximately the level of an FIDE International Master (top 2.2% of tournament chess players with an official rating)12. Fédération Internationale des Échecs, or the World Chess Federation, is the international organisation that governs all major international chess competitions. Please see Appendix A for a description of the Elo rating system.",
            "output": [
                "Giraffe: Using Deep Reinforcement Learning to Play Chess"
            ]
        },
        {
            "id": "task1540-90e6aee6738e4950be25b37611ea9320",
            "input": "We study optimization algorithms based on variance reduction for stochastic gradient descent (SGD). Remarkable recent progress has been made in this direction through development of algorithms like SAG, SVRG, SAGA. These algorithms have been shown to outperform SGD, both theoretically and empirically. However, asynchronous versions of these algorithms—a crucial requirement for modern large-scale applications—have not been studied. We bridge this gap by presenting a unifying framework for many variance reduction techniques. Subsequently, we propose an asynchronous algorithm grounded in our framework, and prove its fast convergence. An important consequence of our general approach is that it yields asynchronous versions of variance reduction algorithms such as SVRG and SAGA as a byproduct. Our method achieves near linear speedup in sparse settings common to machine learning. We demonstrate the empirical performance of our method through a concrete realization of asynchronous SVRG.",
            "output": [
                "On Variance Reduction in Stochastic Gradient Descent and its Asynchronous Variants"
            ]
        },
        {
            "id": "task1540-ba3d2a7a077e49b1b0e27c48c5936a3d",
            "input": "Learning to solve complex sequences of tasks—while both leveraging transfer and avoiding catastrophic forgetting—remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy.",
            "output": [
                "Progressive Neural Networks"
            ]
        },
        {
            "id": "task1540-a4ac7838a679432e9ce57d804c2b9aaf",
            "input": "The essence of distantly supervised relation extraction is that it is an incomplete multi-label classification problem with sparse and noisy features. To tackle the sparsity and noise challenges, we propose solving the classification problem using matrix completion on factorized matrix of minimized rank. We formulate relation classification as completing the unknown labels of testing items (entity pairs) in a sparse matrix that concatenates training and testing textual features with training labels. Our algorithmic framework is based on the assumption that the rank of item-by-feature and item-by-label joint matrix is low. We apply two optimization models to recover the underlying low-rank matrix leveraging the sparsity of featurelabel matrix. The matrix completion problem is then solved by the fixed point continuation (FPC) algorithm, which can find the global optimum. Experiments on two widely used datasets with different dimensions of textual features demonstrate that our low-rank matrix completion approach significantly outperforms the baseline and the state-of-the-art methods.",
            "output": [
                "Errata: Distant Supervision for Relation Extraction with Matrix Completion"
            ]
        },
        {
            "id": "task1540-ddd138fd559d490091a5e2928144d82a",
            "input": "The web plays an important role in people’s social lives since the emergence of Web 2.0. It facilitates the interaction between users, gives them the possibility to freely interact, share and collaborate through social networks, online communities forums, blogs, wikis and other online collaborative media. However, an other side of the web is negatively taken such as posting inflammatory messages. Thus, when dealing with the online communities forums, the managers seek to always enhance the performance of such platforms. In fact, to keep the serenity and prohibit the disturbance of the normal atmosphere, managers always try to novice users against these malicious persons by posting such message (DO NOT FEED TROLLS). But, this kind of warning is not enough to reduce this phenomenon. In this context we propose a new approach for detecting malicious people also called ’Trolls’ in order to allow community managers to take their ability to post online. To be more realistic, our proposal is defined within an uncertain framework. Based on the assumption consisting on the trolls’ integration in the successful discussion threads, we try to detect the presence of such malicious users. Indeed, this method is based on a conflict measure of the belief function theory applied between the different messages of the thread. In order to show the feasibility and the result of our approach, we test it in different simulated data. Keywords—Q&AC, trolls, belief function theory, conflict measure.",
            "output": [
                "Trolls Identification within an Uncertain Framework"
            ]
        },
        {
            "id": "task1540-90be022139354474a69cc8f49d785f87",
            "input": "A model checker can produce a trace of counterexample, for a erroneous program, which is often long and difficult to understand. In general, the part about the loops is the largest among the instructions in this trace. This makes the location of errors in loops critical, to analyze errors in the overall program. In this paper, we explore the scalability capabilities of LocFaults, our error localization approach exploiting paths of CFG(Control Flow Graph) from a counterexample to calculate the MCDs (Minimal Correction Deviations), and MCSs (Minimal Correction Subsets) from each MCD found. We present the times of our approach on programs with While-loops unfolded b times, and a number of diverted conditions ranging from 0 to n. Our preliminary results show that the times of our approach, constraintbased and flow-driven, are better compared to BugAssist which is based on SAT and transforms the entire program to a Boolean formula, although the information provided by LocFaults is more expressive for the user.",
            "output": [
                "Exploration de la scalabilité de LocFaults"
            ]
        },
        {
            "id": "task1540-b63722af50e149769aa2f08546767e9d",
            "input": "Predicting the Credit Defaulter is a perilous task of Financial Industries like Banks. Ascertainingnonpayer before giving loan is a significant and conflict-ridden task of the Banker. Classification techniques are the better choice for predictive analysis like finding the claimant, whether he/she is an unpretentious customer or a cheat. Defining the outstanding classifier is a risky assignment for any industrialist like a banker. This allow computer science researchers to drill down efficient research works through evaluating different classifiers and finding out the best classifier for such predictive problems. This research work investigates the productivity of LADTree Classifier and REPTree Classifier for the credit risk prediction and compares their fitness through various measures. German credit dataset has been taken and used to predict the credit risk with a help of open source machine learning tool.",
            "output": [
                "PROFICIENCY COMPARISON OFLADTREE AND REPTREE CLASSIFIERS FOR CREDIT RISK FORECAST"
            ]
        },
        {
            "id": "task1540-43569bbaebd24cc6803af657694d536f",
            "input": "Automated writing evaluation (AWE) has been shown to be an effective mechanism for quickly providing feedback to students. It has already seen wide adoption in enterprise-scale applications and is starting to be adopted in large-scale contexts. Training an AWE model has historically required a single batch of several hundred writing examples and human scores for each of them. This requirement limits large-scale adoption of AWE since human-scoring essays is costly. Here we evaluate algorithms for ensuring that AWE models are consistently trained using the most informative essays. Our results show how to minimize training set sizes while maximizing predictive performance, thereby reducing cost without unduly sacrificing accuracy. We conclude with a discussion of how to integrate this approach into large-scale AWE systems.",
            "output": [
                "Effective sampling for large-scale automated writing evaluation systems"
            ]
        },
        {
            "id": "task1540-3768b81ed07946eb9fc9b8afc0e87106",
            "input": "Modified policy iteration (MPI) is a dynamic programming (DP) algorithm that contains the two celebrated policy and value iteration methods. Despite its generality, MPI has not been thoroughly studied, especially its approximation form which is used when the state and/or action spaces are large or infinite. In this paper, we propose three implementations of approximate MPI (AMPI) that are extensions of well-known approximate DP algorithms: fitted-value iteration, fitted-Q iteration, and classification-based policy iteration. We provide error propagation analyses that unify those for approximate policy and value iteration. On the last classification-based implementation, we develop a finite-sample analysis that shows that MPI’s main parameter allows to control the balance between the estimation error of the classifier and the overall value function approximation.",
            "output": [
                "Approximate Modified Policy Iteration"
            ]
        },
        {
            "id": "task1540-942af0746a104c288058776305105d29",
            "input": "Feature squeezing is a recently-introduced framework for mitigating and detecting adversarial examples. In previous work, we showed that it is effective against several earlier methods for generating adversarial examples. In this short note, we report on recent results showing that simple feature squeezing techniques also make deep learning models significantly more robust against the Carlini/Wagner attacks, which are the best known adversarial methods discovered to date.",
            "output": [
                "Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial Examples"
            ]
        },
        {
            "id": "task1540-609dee87333d4540ae0226dec2585401",
            "input": "The ability to accurately represent sentences is central to language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for the semantic modelling of sentences. The network uses Dynamic k-Max Pooling, a global pooling operation over linear sequences. The network handles input sentences of varying length and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. We test the DCNN in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline.",
            "output": [
                "A Convolutional Neural Network for Modelling Sentences"
            ]
        },
        {
            "id": "task1540-c591989ed61148d497ee97db43ff563e",
            "input": "We present a software tool that employs state-ofthe-art natural language processing (NLP) and machine learning techniques to help newspaper editors compose effective headlines for online publication. The system identifies the most salient keywords in a news article and ranks them based on both their overall popularity and their direct relevance to the article. The system also uses a supervised regression model to identify headlines that are likely to be widely shared on social media. The user interface is designed to simplify and speed the editor’s decision process on the composition of the headline. As such, the tool provides an efficient way to combine the benefits of automated predictors of engagement and search-engine optimization (SEO) with human judgments of overall headline quality.",
            "output": [
                "Helping News Editors Write Better Headlines: A Recommender to Improve the Keyword Contents & Shareability of News Headlines"
            ]
        },
        {
            "id": "task1540-37d8e7d224c943ae9c03e6ae51d8cd20",
            "input": "The continual growth of high speed networks is a challenge for real-time network analysis systems. The real time traffic classification is an issue for corporations and ISPs (Internet Service Providers). This work presents the design and implementation of a real time flow-based network traffic classification system. The classifier monitor acts as a pipeline consisting of three modules: packet capture and pre-processing, flow reassembly, and classification with Machine Learning (ML). The modules are built as concurrent processes with well defined data interfaces between them so that any module can be improved and updated independently. In this pipeline, the flow reassembly function becomes the bottleneck of the performance. In this implementation, was used a efficient method of reassembly which results in a average delivery delay of 0.49 seconds, approximately. For the classification module, the performances of the K-Nearest Neighbor (KNN), C4.5 Decision Tree, Naive Bayes (NB), Flexible Naive Bayes (FNB) and AdaBoost Ensemble Learning Algorithm are compared in order to validate our approach.",
            "output": [
                "ITCM: A REAL TIME INTERNET TRAFFIC"
            ]
        },
        {
            "id": "task1540-6601a47d6a334e96867febb675763d62",
            "input": "Smoothed analysis is a framework for analyzing the complexity of an algorithm, acting as a bridge between average and worst-case behaviour. For example, Quicksort and the Simplex algorithm are widely used in practical applications, despite their heavy worst-case complexity. Smoothed complexity aims to better characterize such algorithms. Existing theoretical bounds for the smoothed complexity of sorting algorithms are still quite weak. Furthermore, empirically computing the smoothed complexity via its original definition is computationally infeasible, even for modest input sizes. In this paper, we focus on accurately predicting the smoothed complexity of sorting algorithms, using machine learning techniques. We propose two regression models that take into account various properties of sorting algorithms and some of the known theoretical results in smoothed analysis to improve prediction quality. We show experimental results for predicting the smoothed complexity of Quicksort, Mergesort, and optimized Bubblesort for large input sizes, therefore filling the gap between known theoretical and empirical results.",
            "output": [
                "A Machine Learning Approach to Predicting the Smoothed Complexity of Sorting Algorithms"
            ]
        },
        {
            "id": "task1540-05b6605ec0154622a49c12dd66964417",
            "input": "We present initial ideas for a programming paradigm based on simulation that is targeted towards applications of artificial intelligence (AI). The approach aims at integrating techniques from different areas of AI and is based on the idea that simulated entities may freely exchange data and behavioural patterns. We define basic notions of a simulation-based programming paradigm and show how it can be used for implementing AI applications.",
            "output": [
                "Towards a Simulation-Based Programming Paradigm for AI applications"
            ]
        },
        {
            "id": "task1540-c49006adf99c40ada6dbe97dd2ccd20a",
            "input": "Attack detection problems in the smart grid are posed as statistical learning problems for different attack scenarios in which the measurements are observed in batch or online settings. In this approach, machine learning algorithms are used to classify measurements as being either secure or attacked. An attack detection framework is provided to exploit any available prior knowledge about the system and surmount constraints arising from the sparse structure of the problem in the proposed approach. Well-known batch and online learning algorithms (supervised and semi-supervised) are employed with decision and feature level fusion to model the attack detection problem. The relationships between statistical and geometric properties of attack vectors employed in the attack scenarios and learning algorithms are analyzed to detect unobservable attacks using statistical learning methods. The proposed algorithms are examined on various IEEE test systems. Experimental analyses show that machine learning algorithms can detect attacks with performances higher than the attack detection algorithms which employ state vector estimation methods in the proposed attack detection framework.",
            "output": [
                "Machine Learning Methods for Attack Detection in the Smart Grid"
            ]
        },
        {
            "id": "task1540-f9e701874a8e469c822c23c8099399bd",
            "input": "This paper studies a new and more general axiomatization than one presented in [6] for preference on likelihood gambles. Likelihood gambles describe actions in a situation where a decision maker knows multiple probabilistic models and a random sample generated from one of those models but does not know prior probability of models. This new axiom system is inspired by Jensen’s axiomatization of probabilistic gambles. Our approach provides a new perspective to the role of data in decision making under ambiguity. 1 Likelihood gambles Likelihood gambles introduced in [5, 6] describe actions in situation of model ambiguity characterized by (1) there are multiple probabilistic models; (2) there is data providing likelihoods for the models and (3) there is no prior probability about the models. Formally, we consider a general problem described by a tuple (X,Y,Θ,A,x). X,Y are variables describing a phenomenon of interest. X is experiment variable whose values can be observed through experiments or data gathering (e.g. lab test results, clinical observations). Y is utility variable whose values determine the utility of actions (e.g. stages of disease, relative size of the tumor). Θ is the set of models that encode the knowledge about the phenomenon. To be precise, Θ is a set of indices and knowledge is encoded in probability functions Prθ(X,Y ) for θ ∈ Θ. A is the set of alternative actions (e.g. surgery, radiation therapy, chemotherapy) that are functions from utility variable Y to the unit interval [0, 1] representing utility. Fi∗I thank Bharat Rao for encouragement and support and UAI-2006 referees for their constructive comments. One should note that the use of utility rather than nally, evidence/data/observation gathered on experiment variable is X = x. A fundamental question to be answered is which among the alternative actions is the best choice given the information. We introduce the concept of likelihood gambles and derive a pricing formula that will allow their comparison. Note that given a model θ ∈ Θ and observation x, distribution on utility variable Y is Prθ(y|x). According to the classical Bayesian decision theory actions a ∈ A are values by their expected utility",
            "output": [
                "A new axiomatization for likelihood gambles"
            ]
        },
        {
            "id": "task1540-4dbe9ca1991f434fb44e2efc9f2db33e",
            "input": "Problem solving in Answer Set Programming consists of two steps, a first grounding phase, systematically replacing all variables by terms, and a second solving phase computing the stable models of the obtained ground program. An intricate part of both phases is the treatment of aggregates, which are popular language constructs that allow for expressing properties over sets. In this paper, we elaborate upon the treatment of aggregates during grounding in gringo series 4. Consequently, our approach is applicable to grounding based on semi-naive database evaluation techniques. In particular, we provide a series of algorithms detailing the treatment of recursive aggregates and illustrate this by a running example.",
            "output": [
                "Grounding Recursive Aggregates: Preliminary Report"
            ]
        },
        {
            "id": "task1540-caf585b1d6e743bcbca9c4c529a38de1",
            "input": "Catastrophic forgetting is a problem which refers to losing the information of the first task after training from the second task in continual learning of neural networks. To resolve this problem, we propose the incremental moment matching (IMM), which uses the Bayesian neural network framework. IMM assumes that the posterior distribution of parameters of neural networks is approximated with Gaussian distribution and incrementally matches the moment of the posteriors, which are trained for the first and second task, respectively. To make our Gaussian assumption reasonable, the IMM procedure utilizes various transfer learning techniques including weight transfer, L2-norm of old and new parameters, and a newly proposed variant of dropout using old parameters. We analyze our methods on the MNIST and CIFAR-10 datasets, and then evaluate them on a real-world life-log dataset collected using Google Glass. Experimental results show that IMM produces state-of-the-art performance in a variety of datasets.",
            "output": [
                "Overcoming Catastrophic Forgetting by Incremental Moment Matching"
            ]
        },
        {
            "id": "task1540-6b8064dc903c41cf95a530d067f20b06",
            "input": "We propose a method to construct finite-state reactive controllers for systems whose interactions with their adversarial environment are modeled by infinite-duration twoplayer games over (possibly) infinite graphs. The proposed method targets safety games with infinitely many states or with such a large number of states that it would be impractical— if not impossible—for conventional synthesis techniques that work on the entire state space. We resort to constructing finitestate controllers for such systems through an automata learning approach, utilizing a symbolic representation of the underlying game that is based on finite automata. Throughout the learning process, the learner maintains an approximation of the winning region (represented as a finite automaton) and refines it using different types of counterexamples provided by the teacher until a satisfactory controller can be derived (if one exists). We present a symbolic representation of safety games (inspired by regular model checking), propose implementations of the learner and teacher, and evaluate their performance on examples motivated by robotic motion planning in dynamic environments.",
            "output": [
                "An Automaton Learning Approach to Solving Safety Games over Infinite Graphs"
            ]
        },
        {
            "id": "task1540-f0c1f958537d4981882528f2d29004cf",
            "input": "In this work, we study an important problem: learning programs from input-output<lb>examples. We propose a novel method to learn a neural program operating a<lb>domain-specific non-differentiable machine, and demonstrate that this method<lb>can be applied to learn programs that are significantly more complex than the<lb>ones synthesized before: programming language parsers from input-output pairs<lb>without knowing the underlying grammar. The main challenge is to train the neural<lb>program without supervision on execution traces. To tackle it, we propose: (1)<lb>LL machines and neural programs operating them to effectively regularize the<lb>space of the learned programs; and (2) a two-phase reinforcement learning-based<lb>search technique to train the model. Our evaluation demonstrates that our approach<lb>can successfully learn to parse programs in both an imperative language and a<lb>functional language, and achieve 100% test accuracy, while existing approaches’<lb>accuracies are almost 0%. This is the first successful demonstration of applying<lb>reinforcement learning to train a neural program operating a non-differentiable<lb>machine that can fully generalize to test sets on a non-trivial task.",
            "output": [
                "Learning Neural Programs To Parse Programs"
            ]
        },
        {
            "id": "task1540-31e8da96587a45ca9b79f48318235226",
            "input": "Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model (“generator”) and a task solving model (“solver”). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.",
            "output": [
                "Continual Learning with Deep Generative Replay"
            ]
        },
        {
            "id": "task1540-d2d2a41a3dda4b39be47cca8e9bfe8d8",
            "input": "Conventional methods of estimating latent behaviour generally use attitudinal questions which are subjective and these survey questions may not always be available. We hypothesize that an alternative approach can be used for latent variable estimation through an undirected graphical models. For instance, non-parametric artificial neural networks. In this study, we explore the use of generative non-parametric modelling methods to estimate latent variables from prior choice distribution without the conventional use of measurement indicators. A restricted Boltzmann machine is used to represent latent behaviour factors by analyzing the relationship information between the observed choices and explanatory variables. The algorithm is adapted for latent behaviour analysis in discrete choice scenario and we use a graphical approach to evaluate and understand the semantic meaning from estimated parameter vector values. We illustrate our methodology on a financial instrument choice dataset and perform statistical analysis on parameter sensitivity and stability. Our findings show that through non-parametric statistical tests, we can extract useful latent information on the behaviour of latent constructs through machine learning methods and present strong and significant influence on the choice process. Furthermore, our modelling framework shows robustness in input variability through sampling and validation. ∗Paper presented at International Choice Modelling Conference 2017 †Laboratory of Innovations in Transportation (LITrans), Department of Civil Engineering, Ryerson University, Toronto, Canada, Email: melvin.wong@ryerson.ca ‡Laboratory of Innovations in Transportation (LITrans), Department of Civil Engineering, Ryerson University, Toronto, Canada, Email: bilal.farooq@ryerson.ca Laboratoire d’Interprétation et de Traitement d’Images et Vidéo (LITIV), Department of Computer and Software Engineering, Polytechnique Montréal, Montréal, Canada, Email: guillaume-alexandre.bilodeau@polymtl.ca ar X iv :1 70 6. 00 50 5v 1 [ cs .L G ] 1 J un 2 01 7",
            "output": [
                "Discriminative conditional restricted Boltzmann machine for discrete choice and latent variable modelling"
            ]
        },
        {
            "id": "task1540-bfe8a72d046f4de7834b708b10182df5",
            "input": "Variational autoencoders (VAE) represent a popular, flexible form of deep generative model that can be stochastically fit to samples from a given random process using an information-theoretic variational bound on the true underlying distribution. Once so-obtained, the model can be putatively used to generate new samples from this distribution, or to provide a low-dimensional latent representation of existing samples. While quite effective in numerous application domains, certain important mechanisms which govern the behavior of the VAE are obfuscated by the intractable integrals and resulting stochastic approximations involved. Moreover, as a highly non-convex model, it remains unclear exactly how minima of the underlying energy relate to original design purposes. We attempt to better quantify these issues by analyzing a series of tractable special cases of increasing complexity. In doing so, we unveil interesting connections with more traditional dimensionality reduction models, as well as an intrinsic yet underappreciated propensity for robustly dismissing outliers when estimating latent manifolds. With respect to the latter, we demonstrate that the VAE can be viewed as the natural evolution of recent robust PCA models, capable of learning nonlinear manifolds obscured by gross corruptions. However, this previously unexplored feature comes with the cost of potential model collapse to a degenerate distribution that may be less suitable as the basis for generating new samples.",
            "output": [
                "Veiled Attributes of the Variational Autoencoder"
            ]
        },
        {
            "id": "task1540-d5876caac89e47f3b7529e46b370d267",
            "input": "Relational Markov Random Fields are a general and flexible framework for reasoning about the joint distribution over attributes of a large number of interacting entities. The main computational difficulty in learning such models is inference. Even when dealing with complete data, where one can summarize a large domain by sufficient statistics, learning requires one to compute the expectation of the sufficient statistics given different parameter choices. The typical solution to this problem is to resort to approximate inference procedures, such as loopy belief propagation. Although these procedures are quite efficient, they still require computation that is on the order of the number of interactions (or features) in the model. When learning a large relational model over a complex domain, even such approximations require unrealistic running time. In this paper we show that for a particular class of relational MRFs, which have inherent symmetry, we can perform the inference needed for learning procedures using a template-level belief propagation. This procedure’s running time is proportional to the size of the relational model rather than the size of the domain. Moreover, we show that this computational procedure is equivalent to sychronous loopy belief propagation. This enables a dramatic speedup in inference and learning time. We use this procedure to learn relational MRFs for capturing the joint distribution of large protein-protein interaction networks.",
            "output": [
                "Template Based Inference in Symmetric Relational Markov Random Fields"
            ]
        },
        {
            "id": "task1540-35444280be144c45b17c65ca542333fe",
            "input": "We show that the average stability notion introduced by [12, 4] is invariant to data preconditioning, for a wide class of generalized linear models that includes most of the known exp-concave losses. In other words, when analyzing the stability rate of a given algorithm, we may assume the optimal preconditioning of the data. This implies that, at least from a statistical perspective, explicit regularization is not required in order to compensate for ill-conditioned data, which stands in contrast to a widely common approach that includes a regularization for analyzing the sample complexity of generalized linear models. Several important implications of our findings include: a) We demonstrate that the excess risk of empirical risk minimization (ERM) is controlled by the preconditioned stability rate. This immediately yields a relatively short and elegant proof for the fast rates attained by ERM in our context. b) We strengthen the recent bounds of [9] on the stability rate of the Stochastic Gradient Descent algorithm.",
            "output": [
                "Average Stability is Invariant to Data Preconditioning. Implications to Exp-concave Empirical Risk Minimization"
            ]
        },
        {
            "id": "task1540-37abdcf3a2204c2b9fed4e6e9e0624be",
            "input": "imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of overand under-sampling, and (iv) ensemble learning methods. The proposed toolbox only depends on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. The toolbox is publicly available in GitHub https://github.com/scikit-learn-contrib/imbalanced-learn.",
            "output": [
                "Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning"
            ]
        },
        {
            "id": "task1540-6937aeae46ae4d4f9f144a1099f72bdd",
            "input": "This study implements a vector space model approach to measure the sentiment orientations of words. Two representative vectors for positive/negative polarity are constructed using high-dimensional vector space in both an unsupervised and a semisupervised manner. A sentiment orientation value per word is determined by taking the difference between the cosine distances against the two reference vectors. These two conditions (unsupervised and semi-supervised) are compared against an existing unsupervised method (Turney, 2002). As a result of our experiment, we demonstrate that this novel approach significantly outperforms the previous unsupervised approach and is more practical and data efficient as well.",
            "output": [
                "A New Approach for Measuring Sentiment Orientation based on Multi-Dimensional Vector Space"
            ]
        },
        {
            "id": "task1540-7f5134cd68e64a0b8cb4d8999dc14f01",
            "input": "We study a surprising phenomenon related to the representation of a cloud of data points using polynomials. We start with the previously unnoticed empirical observation that, given a collection (a cloud) of data points, the sublevel sets of a certain distinguished polynomial capture the shape of the cloud very accurately. This distinguished polynomial is a sum-of-squares (SOS) derived in a simple manner from the inverse of the empirical moment matrix. In fact, this SOS polynomial is directly related to orthogonal polynomials and the Christoffel function. This allows to generalize and interpret extremality properties of orthogonal polynomials and to provide a mathematical rationale for the observed phenomenon. Among diverse potential applications, we illustrate the relevance of our results on a network intrusion detection task for which we obtain performances similar to existing dedicated methods reported in the literature.",
            "output": [
                "Sorting out typicality with the inverse moment matrix SOS polynomial"
            ]
        },
        {
            "id": "task1540-0bfae2012094417fab086a5602e8a8a4",
            "input": "We propose a localized approach to multiple kernel learning that can be formulated as a convex optimization problem over a given cluster structure. For which we obtain generalization error guarantees and derive an optimization algorithm based on the Fenchel dual representation. Experiments on real-world datasets from the application domains of computational biology and computer vision show that convex localized multiple kernel learning can achieve higher prediction accuracies than its global and non-convex local counterparts.",
            "output": [
                "Localized Multiple Kernel Learning—A Convex Approach"
            ]
        },
        {
            "id": "task1540-181666bb4e6143c3bee51c3c2942b92e",
            "input": "We present a new perspective on graph-based methods for collaborative ranking for recommender systems. Unlike user-based or item-based methods that compute a weighted average of ratings given by the nearest neighbors, or low-rank approximation methods using convex optimization and the nuclear norm, we formulate matrix completion as a series of semi-supervised learning problems, and propagate the known ratings to the missing ones on the user-user or item-item graph globally. The semi-supervised learning problems are expressed as LaplaceBeltrami equations on a manifold, or namely, harmonic extension, and can be discretized by a point integral method. We show that our approach does not impose a low-rank Euclidean subspace on the data points, but instead minimizes the dimension of the underlying manifold. Our method, named LDM (low dimensional manifold), turns out to be particularly effective in generating rankings of items, showing decent computational efficiency and robust ranking quality compared to state-of-the-art methods.",
            "output": [
                "A Harmonic Extension Approach for Collaborative Ranking"
            ]
        },
        {
            "id": "task1540-dbb4e941afab44e4bae8e9e6a3cd6527",
            "input": "Previous work has modeled the compositionality of words by creating characterlevel models of meaning, reducing problems of sparsity for rare words. However, in many writing systems compositionality has an effect even on the character-level: the meaning of a character is derived by the sum of its parts. In this paper, we model this effect by creating embeddings for characters based on their visual characteristics, creating an image for the character and running it through a convolutional neural network to produce a visual character embedding. Experiments on a text classification task demonstrate that such model allows for better processing of instances with rare characters in languages such as Chinese, Japanese, and Korean. Additionally, qualitative analyses demonstrate that our proposed model learns to focus on the parts of characters that carry categorical content which resulting in embeddings that are coherent in visual space.",
            "output": [
                "Learning Character-level Compositionality with Visual Features"
            ]
        },
        {
            "id": "task1540-a4dc92ef1fc2459aa778ab9b788d8dd1",
            "input": "Temporal abstraction is key to scaling up learning and planning in reinforcement learning. While planning with temporally extended actions is well understood, creating such abstractions autonomously from data has remained challenging. We tackle this problem in the framework of options [Sutton, Precup & Singh, 1999; Precup, 2000]. We derive policy gradient theorems for options and propose a new option-critic architecture capable of learning both the internal policies and the termination conditions of options, in tandem with the policy over options, and without the need to provide any additional rewards or subgoals. Experimental results in both discrete and continuous environments showcase the flexibility and efficiency of the framework. Introduction Temporal abstraction allows representing knowledge about course of actions that take place at different time scales. In reinforcement learning, options (Sutton, Precup, and Singh 1999; Precup 2000) provide a framework for defining such courses of action and for seamlessly learning and planning with them. Discovering temporal abstractions autonomously has been the subject of extensive research efforts in the last 15 years (McGovern and Barto 2001; Stolle and Precup 2002; Menache, Mannor, and Shimkin 2002; Şimşek and Barto 2009; Silver and Ciosek 2012), but approaches that can be used naturally with continuous state and/or action spaces have only recently started to become feasible (Konidaris et al. 2011; Niekum and Barto 2011; Mann, Mannor, and Precup ; Mankowitz, Mann, and Mannor 2016; Kulkarni et al. 2016; Vezhnevets et al. 2016; Daniel et al. 2016). The majority of the existing work has focused on finding subgoals (useful states that an agent should reach) and subsequently learning policies to achieve them. This idea has lead to interesting methods but ones which are also difficult to scale up given their “combinatorial” flavor. Additionally, learning policies associated with subgoals can be expensive in terms of data and computation time; in the worst case, it can be as expensive as solving the entire task. We present an alternative view, which blurs the line between the problem of discovering options from that of learning options. Based on the policy gradient theorem (Sutton et al. 2000), we derive new results which enable a gradual learning process of the intra-option policies and termination functions, simultaneously with the policy over them. This approach works naturally with both linear and non-linear function approximators, under discrete or continuous state and action spaces. Existing methods for learning options are considerably slower when learning from a single task: much of the benefit will come from re-using the learned options in similar tasks. In contrast, we show that our approach is capable of successfully learning options within a single task without incurring any slowdown and while still providing re-use speedups. We start by reviewing background related to the two main ingredients of our work: policy gradient methods and options. We then describe the core ideas of our approach: the intra-option policy and termination gradient theorems. Additional technical details are included in the appendix. We present experimental results showing that our approach learns meaningful temporally extended behaviors in an effective manner. As opposed to other methods, we only need to specify the number of desired options; it is not necessary to have subgoals, extra rewards, demonstrations, multiple problems or any other special accommodations (however, the approach can work with pseudo-reward functions if desired). To our knowledge, this is the first end-to-end approach for learning options that scales to very large domains at comparable efficiency. Preliminaries and Notation A Markov Decision Process consists of a set of states S, a set of actionsA, a transition function P : S×A → (S → [0, 1]) and a reward function r : S × A → R. For convenience, we develop our ideas assuming discrete state and action sets. However, our results extend to continuous spaces using usual measure-theoretic assumptions (some of our empirical results are in continuous tasks). A (Markovian stationary) policy is a probability distribution over actions conditioned on states, π : S × A → [0, 1]. In discounted problems, the value function of a policy π is defined as the expected return: Vπ(s) = Eπ [ ∑∞ t=0 γ rt+1 | s0 = s] and its action-value function as Qπ(s, a) = Eπ [ ∑∞ t=0 γ rt+1 | s0 = s, a0 = a], where γ ∈ [0, 1) is the discount factor. A policy π is greedy with respect to a given action-value function Q if π(s, a) > 0 iff a = argmaxa′ Q(s, a ′). In a discrete MDP, there is at least one optimal policy which is greedy with rear X iv :1 60 9. 05 14 0v 1 [ cs .A I] 1 6 Se p 20 16 spect to its own action-value function. Policy gradient methods (Sutton et al. 2000; Konda and Tsitsiklis 2000) address the problem of finding a good policy by performing stochastic gradient descent to optimize a performance objective over a given family of parametrized stochastic policies, πθ. The policy gradient theorem (Sutton et al. 2000) provides expressions for the gradient of the average reward and discounted reward objectives with respect to θ. In the discounted setting, the objective is defined with respect to a designated start state (or distribution) s0: ρ(θ, s0) = Eπθ [ ∑ t=0 γ rt+1 | s0]. The policy gradient theorem shows that: ∂ρ(θ,s0) ∂θ = ∑ s μπθ (s | s0) ∑ a ∂πθ(a|s) ∂θ Qπθ (s, a), where μπθ (s | s0) = ∑∞ t=0 γ t P (st = s | s0) is a discounted weighting of the states along the trajectories starting from s0. In practice, the policy gradient is estimated from samples along the on-policy stationary distribution. (Thomas 2014) showed that neglecting the discount factor in this stationary distribution makes the usual policy gradient estimator biased. However, correcting for this discrepancy also reduces data efficiency. For simplicity, we build on the framework of (Sutton et al. 2000) and discuss how to extend our results according to (Thomas 2014). The options framework (Sutton, Precup, and Singh 1999; Precup 2000) formalizes the idea of temporally extended actions. A Markovian option ω ∈ Ω is a triple (Iω, πω, βω) in which Iω ⊆ S is an initiation set, πω is an intra-option policy, and βω : S → [0, 1] is a termination function. We also assume that ∀s ∈ S,∀ω ∈ Ω : s ∈ Iω (i.e., all options are available everywhere), an assumption made in the majority of options discovery algorithms. We will discuss how to dispense with this assumption in the final section. (Sutton, Precup, and Singh 1999; Precup 2000) show that an MDP endowed with a set of options becomes a Semi-Markov Decision Process (Puterman 1994, chapter 11), which has a corresponding optimal value function over options VΩ(s) and option-value function QΩ(s, ω). Learning and planning algorithms for MDPs have their counterparts in this setting. However, the existence of the underlying MDP offers the possibility of learning about many different options in parallel : the idea of intra-option learning, which we leverage in our work. Learning Options We adopt a continual perspective on the problem of learning options. At any time, we would like to distill all of the available experience into every component of our system: value function and policy over options, intra-option policies and termination functions. To achieve this goal, we focus on learning option policies and termination functions, assuming they are represented using differentiable parameterized function approximators. We consider the call-and-return option execution model, in which an agent picks option ω according to its policy over options πΩ , then follows the intra-option policy πω until termination (as dictated by βω), at which point this procedure is repeated. Let πω,θ denote the intra-option policy of option ω parametrized by θ and βω,θ, the termination function of ω parameterized by θ. We present two new results for learning options, obtained using as blueprint the policy gradient theorem (Sutton et al. 2000). Both results are derived under the assumption that the goal is to learn options that maximize the expected return in the current task. However, if one wanted to add extra information to the objective function, this could readily be done so long as it comes in the form of an additive differentiable function. Suppose we aim to optimize directly the discounted return, expected over all the trajectories starting at a designated state s0 and option ω0, then: ρ(Ω, θ, θ, s0, ω0) = EΩ,θ,ω [ ∑∞ t=0 γ rt+1 | s0, ω0]. Note that this return depends on the policy over options, as well as the parameters of the option policies and termination functions. We will take gradients of this objective with respect to θ and θ. In order to do this, we will manipulate equations similar to those used in intra-option learning (Sutton, Precup, and Singh 1999, section 8). Specifically, the definition of the option-value function can be written as: QΩ(s, ω) = E Ω,θ,θ [ ∞ ∑ t=0 γrt+1 ∣∣∣∣ s0 = s, ω0 = ω ]",
            "output": [
                "The Option-Critic Architecture"
            ]
        },
        {
            "id": "task1540-3589da6b7f1844faa36aa7b5c0924d40",
            "input": "The current information analysis capabilities of legal professionals are still lagging behind the explosive growth in legal document availability through digital means, driving the need for higher efficiency Legal Information Retrieval (IR) and Question Answering (QA) methods. The IR task in particular has a set of unique challenges that invite the use of semantic motivated NLP techniques. In this work, a two-stage method for Legal Information Retrieval is proposed, combining lexical statistics and distributional sentence representations in the context of Competition on Legal Information Extraction/Entailment (COLIEE). The combination is done by means of disambiguation rules, applied over the lexical rankings when those deemed unreliable for a given query. Competition and experimental results indicate small gains in overall retrieval performance using the proposed approach. Additionally, a analysis of error and improvement cases is presented for a better understanding of the contributions.",
            "output": [
                "Improving Legal Information Retrieval by Distributional Composition with Term Order Probabilities"
            ]
        },
        {
            "id": "task1540-931fe73cdf3e428dae953d550f473555",
            "input": "Multivariate time series naturally exist in many fields, like energy, bioinformatics, signal processing, and finance. Most of these applications need to be able to compare these structured data. In this context, dynamic time warping (DTW) is probably the most common comparison measure. However, not much research effort has been put into improving it by learning. In this paper, we propose a novel method for learning similarities based on DTW, in order to improve time series classification. Making use of the uniform stability framework, we provide the first theoretical guarantees in the form of a generalization bound for linear classification. The experimental study shows that the proposed approach is efficient, while yielding sparse classifiers.",
            "output": [
                "Similarity Learning for Time Series Classification"
            ]
        },
        {
            "id": "task1540-899f300880744a96b7669b9f6dfac9f9",
            "input": "In this paper, we describe a system for generating threedimensional visual simulations of natural language motion expressions. We use a rich formal model of events and their participants to generate simulations that satisfy the minimal constraints entailed by the associated utterance, relying on semantic knowledge of physical objects and motion events. This paper outlines technical considerations and discusses implementing the aforementioned semantic models into such a system.",
            "output": [
                "Multimodal Semantic Simulations of Linguistically Underspecified Motion Events"
            ]
        },
        {
            "id": "task1540-a5f16201612e46d7a0d4f34b229b77d6",
            "input": "Within the framework of ADABOOST.MH, we propose to train vector-valued decision trees to optimize the multi-class edge without reducing the multi-class problem toK binary one-againstall classifications. The key element of the method is a vector-valued decision stump, factorized into an input-independent vector of length K and label-independent scalar classifier. At inner tree nodes, the label-dependent vector is discarded and the binary classifier can be used for partitioning the input space into two regions. The algorithm retains the conceptual elegance, power, and computational efficiency of binary ADABOOST. In experiments it is on par with support vector machines and with the best existing multi-class boosting algorithm AOSOLOGITBOOST, and it is significantly better than other known implementations of ADABOOST.MH.",
            "output": [
                "The return of ADABOOST.MH: multi-class Hamming trees"
            ]
        },
        {
            "id": "task1540-a8ecfbfc89b34853b72f04c34decef43",
            "input": "Neural network based models are a very powerful tool for creating word embeddings, the objective of these models is to group similar words together. These embeddings have been used as features to improve results in various applications such as document classification, named entity recognition, etc. Neural language models are able to learn word representations which have been used to capture semantic shifts across time and geography. The objective of this paper is to first identify and then visualize how words change meaning in different text corpus. We will train a neural language model on texts from a diverse set of disciplines – philosophy, religion, fiction etc. Each text will alter the embeddings of the words to represent the meaning of the word inside that text. We will present a computational technique to detect words that exhibit significant linguistic shift in meaning and usage. We then use enhanced scatterplots and storyline visualization to visualize the linguistic shift",
            "output": [
                "Visualizing Linguistic Shift"
            ]
        },
        {
            "id": "task1540-daf66aa975e544c9b5714b4c559b86bd",
            "input": "The analysis of the current integration attempts of some modes and use cases of user-machine interaction is presented. The new concept of the user-driven intelligent interface is proposed on the basis of multimodal augmented reality and brain-computer interaction for various applications: in disabilities studies, education, home care, health care, etc. The several use cases of multimodal augmentation are presented. The perspectives of the better human comprehension by the immediate feedback through neurophysical channels by means of brain-computer interaction are outlined. It is shown that brain– computer interface (BCI) technology provides new strategies to overcome limits of the currently available user interfaces, especially for people with functional disabilities. The results of the previous studies of the low end consumer and open-source BCI-devices allow us to conclude that combination of machine learning (ML), multimodal interactions (visual, sound, tactile) with BCI will profit from the immediate feedback from the actual neurophysical reactions classified by ML methods. In general, BCI in combination with other modes of AR interaction can deliver much more information than these types of interaction themselves. Even in the current state the combined AR-BCI interfaces could provide the highly adaptable and personal services, especially for people with functional disabilities. Keywords— augmented reality, interfaces for accessibility, multimodal user interface, brain-computer interface, eHealth, machine learning, machine-to-machine interactions, human-tohuman interactions, human-to-machine interactions",
            "output": [
                "User-driven Intelligent Interface on the Basis of Multimodal Augmented Reality and Brain-Computer Interaction for People with Functional Disabilities"
            ]
        },
        {
            "id": "task1540-4ec136cbc64c46cbba097f4aaadc0c18",
            "input": "Our experience of the world is multimodal we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.",
            "output": [
                "Multimodal Machine Learning: A Survey and Taxonomy"
            ]
        },
        {
            "id": "task1540-0a3b185a4e8749aeb25cf81219388848",
            "input": "The lack of diversity in a genetic algorithm’s population may lead to a bad performance of the genetic operators since there is not an equilibrium between exploration and exploitation. In those cases, genetic algorithms present a fast and unsuitable convergence. In this paper we develop a novel hybrid genetic algorithm which attempts to obtain a balance between exploration and exploitation. It confronts the diversity problem using the named greedy diversification operator. Furthermore, the proposed algorithm applies a competition between parent and children so as to exploit the high quality visited solutions. These operators are complemented by a simple selection mechanism designed to preserve and take advantage of the population diversity. Additionally, we extend our proposal to the field of memetic algorithms, obtaining an improved model with outstanding results in practice. The experimental study shows the validity of the approach as well as how important is taking into account the exploration and exploitation concepts when designing an evolution-",
            "output": [
                "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION"
            ]
        },
        {
            "id": "task1540-b38e1bce64ad41eab61ffff3060b959e",
            "input": "Deep generative models provide a powerful and flexible means to learn complex distributions over data by incorporating neural networks into latent-variable models. Variational approaches to training such models introduce a probabilistic encoder that casts data, typically unsupervised, into an entangled representation space. While unsupervised learning is often desirable, sometimes even necessary, when we lack prior knowledge about what to represent, being able to incorporate domain knowledge in characterising certain aspects of variation in the data can often help learn better disentangled representations. Here, we introduce a new formulation of semi-supervised learning in variational autoencoders that allows precisely this. It permits flexible specification of probabilistic encoders as directed graphical models via a stochastic computation graph, containing both continuous and discrete latent variables, with conditional distributions parametrised by neural networks. We demonstrate how the provision of dependency structures, along with a few labelled examples indicating plausible values for some components of the latent space, can help quickly learn disentangled representations. We then evaluate its ability to do so, both qualitatively by exploring its generative capacity, and quantitatively by using the disentangled representation to perform classification, on a variety of models and datasets.",
            "output": [
                "IN DEEP GENERATIVE MODELS"
            ]
        },
        {
            "id": "task1540-5262709cf899441d87aee7f56be0bc31",
            "input": "Optimization by stochastic gradient descent is an important component of many large-scale machine learning algorithms. A wide variety of such optimization algorithms have been devised; however, it is unclear whether these algorithms are robust and widely applicable across many different optimization landscapes. In this paper we develop a collection of unit tests for stochastic optimization. Each unit test rapidly evaluates an optimization algorithm on a small-scale, isolated, and well-understood difficulty, rather than in real-world scenarios where many such issues are entangled. Passing these unit tests is not sufficient, but absolutely necessary for any algorithms with claims to generality or robustness. We give initial quantitative and qualitative results on a dozen established algorithms. The testing framework is open-source, extensible, and easy to apply to new algorithms.",
            "output": [
                "Unit Tests for Stochastic Optimization"
            ]
        },
        {
            "id": "task1540-06b26215e7a54b378f09cc42fa58780d",
            "input": "As Wireless Sensor Networks are penetrating into the industrial domain, many research opportunities are emerging. One such essential and challenging application is that of node localization. A feed-forward neural network based methodology is adopted in this paper. The Received Signal Strength Indicator (RSSI) values of the anchor node beacons are used. The number of anchor nodes and their configurations has an impact on the accuracy of the localization system, which is also addressed in this paper. Five different training algorithms are evaluated to find the training algorithm that gives the best result. The multi-layer Perceptron (MLP) neural network model was trained using Matlab. In order to evaluate the performance of the proposed method in real time, the model obtained was then implemented on the Arduino microcontroller. With four anchor nodes, an average 2D localization error of 0.2953 m has been achieved with a 12-12-2 neural network structure. The proposed method can also be implemented on any other embedded microcontroller system.",
            "output": [
                "LOCALIZATION FOR WIRELESS SENSOR NETWORKS: A NEURAL NETWORK APPROACH"
            ]
        },
        {
            "id": "task1540-03def38e85ba45bb8435182ea2061418",
            "input": "In many embedded systems, such as imaging systems, the system has a single designated purpose, and same threads are executed repeatedly. Profiling thread behavior, allows the system to allocate each thread its resources in a way that improves overall system performance. We study an online resource allocation problem, where a resource manager simultaneously allocates resources (exploration), learns the impact on the different consumers (learning) and improves allocation towards optimal performance (exploitation). We build on the rich framework of multiarmed bandits and present online and offline algorithms. Through extensive experiments with both synthetic data and real-world cache allocation to threads we show the merits and properties of our algorithms.",
            "output": [
                "Bandits meet Computer Architecture: Designing a Smartly-allocated Cache"
            ]
        },
        {
            "id": "task1540-454bddb7124e4e2a85e060f9bb2e2113",
            "input": "Motivated by value function estimation in reinforcement learning, we study statistical linear inverse problems, i.e., problems where the coefficients of a linear system to be solved are observed in noise. We consider penalized estimators, where performance is evaluated using a matrix-weighted two-norm of the defect of the estimator measured with respect to the true, unknown coefficients. Two objective functions are considered depending whether the error of the defect measured with respect to the noisy coefficients is squared or unsquared. We propose simple, yet novel and theoretically well-founded data-dependent choices for the regularization parameters for both cases that avoid datasplitting. A distinguishing feature of our analysis is that we derive deterministic error bounds in terms of the error of the coefficients, thus allowing the complete separation of the analysis of the stochastic properties of these errors. We show that our results lead to new insights and bounds for linear value function estimation in reinforcement learning.",
            "output": [
                "Statistical linear estimation with penalized estimators: an application to reinforcement learning"
            ]
        },
        {
            "id": "task1540-1234d0c669174457a87c9bb81cf6f717",
            "input": "We discuss representing and reasoning with knowledge about the time-dependent util­ ity of an agent's actions. Time-dependent utility plays a crucial role in the interac­ tion between computation and action under bounded resources. We present a semantics for time-dependent utility and describe the use of time-dependent information in deci­ sion contexts. We illustrate our discussion with examples of time-pressured reasoning in Protos, a system constructed to explore the ideal control of inference by reasoners with limited abilities.",
            "output": [
                "Time-Dependent Utility and Action Under Uncertainty"
            ]
        },
        {
            "id": "task1540-31b2c6f4693a4890ae3850222edbe753",
            "input": "In this paper, we propose a universal model for high-dimensional data, called the Hybrid Orthogonal Projection and Estimation (HOPE) model, which combines a linear orthogonal projection and a finite mixture model under a unified generative modelling framework. The HOPE model itself can be learned unsupervisedly from un-labelled data based on the maximum likelihood estimation as well as trained discriminatively from labelled data. More interestingly, we have shown the proposed HOPE models are closely related to neural networks (NNs) in a sense that each hidden layer can be reformulated as a HOPE model. As a result, the HOPE framework can be used as a novel tool to probe why and how NNs work, more importantly, it also provides several new learning algorithms to learn NNs either supervisedly or unsupervisedly. In this work, we have investigated the HOPE framework in learning NNs for several standard tasks, including image recognition on MNIST and speech recognition on TIMIT. Experimental results show that the HOPE framework yields significant performance gains over the current stateof-the-art methods in various types of NN learning problems, including unsupervised feature learning, supervised or semi-supervised learning.",
            "output": [
                "Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to Probe and Learn Neural Networks"
            ]
        },
        {
            "id": "task1540-749b4063a2dd49d2a7541f38bb6f16a2",
            "input": "In previous work [BGHK92, BGHK93], we have studied the random-worlds approach�a particular (and quite powerful) method for generating degrees of belief (i.e., subjective probabilities) from a knowl­ edge base consisting of objective (first-order, slalisti­ cal, and defaull) infonnation. But allowing a know l ­ edge base to contain only objective information is sometimes limiting. We occa<;ionally wish to include infonnation about degrees of belief in the knowledge base as well, because there are contexts in which old be1iefs represent important information that should influence new beliefs. In this paper, we describe three quite general techniques for extending a method that generates degrees of belief from objective informa­ tion to one that can make use of degrees of belief as well. All of our techniques are ha<;ed on well-known approaches, such a5 cross-emropy. We discuss gen­ eral connections between the techniques and in partic­ ular show that, although conceptually and technically quite different, all of the techniques give the same answer when applied to the random-worlds method.",
            "output": [
                "Generating New Beliefs From Old*"
            ]
        },
        {
            "id": "task1540-bf74d80bf37147848e164ba5b50fa927",
            "input": "Exploration has been a crucial part of reinforcement learning, yet several important questions concerning exploration efficiency are still not answered satisfactorily by existing analytical frameworks. These questions include exploration parameter setting, situation analysis, and hardness of MDPs, all of which are unavoidable for practitioners. To bridge the gap between the theory and practice, we propose a new analytical framework called the success probability of exploration. We show that those important questions of exploration above can all be answered under our framework, and the answers provided by our framework meet the needs of practitioners better than the existing ones. More importantly, we introduce a concrete and practical approach to evaluating the success probabilities in certain MDPs without the need of actually running the learning algorithm. We then provide empirical results to verify our approach, and demonstrate how the success probability of exploration can be used to analyse and predict the behaviours and possible outcomes of exploration, which are the keys to the answer of the important questions of exploration.",
            "output": [
                "Success Probability of Exploration: a Concrete Analysis of Learning Efficiency"
            ]
        },
        {
            "id": "task1540-f00fa921ec7d4aaaa5a1dd73cc0b5972",
            "input": "It has always been a burden to the users of statistical topic models to predetermine the right number of topics, which is a key parameter of most topic models. Conventionally, automatic selection of this parameter is done through either statistical model selection (e.g., cross-validation, AIC, or BIC) or Bayesian nonparametric models (e.g., hierarchical Dirichlet process). These methods either rely on repeated runs of the inference algorithm to search through a large range of parameter values which does not suit the mining of big data, or replace this parameter with alternative parameters that are less intuitive and still hard to be determined. In this paper, we explore to “eliminate” this parameter from a new perspective. We first present a nonparametric treatment of the PLSA model named nonparametric probabilistic latent semantic analysis (nPLSA). The inference procedure of nPLSA allows for the exploration and comparison of different numbers of topics within a single execution, yet remains as simple as that of PLSA. This is achieved by substituting the parameter of the number of topics with an alternative parameter that is the minimal goodness of fit of a document. We show that the new parameter can be further eliminated by two parameter-free treatments: either by monitoring the diversity among the discovered topics or by a weak supervision from users in the form of an exemplar topic. The parameter-free topic model finds the appropriate number of topics when the diversity among the discovered topics is maximized, or when the granularity of the discovered topics matches the exemplar topic. Experiments on both synthetic and real data prove that the parameterfree topic model extracts topics with a comparable quality comparing to classical topic models with “manual transmission.” The quality of the topics outperforms those extracted through classical Bayesian nonparametric models. ∗This study is done when the first author is visiting the University of Michigan. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$10.00.",
            "output": [
                "\"Look Ma, No Hands!\" A Parameter-Free Topic Model"
            ]
        },
        {
            "id": "task1540-49f19a109f5e46df963770dccb8b97da",
            "input": "Knowledge compilation is an approach to tackle the computational intractability of general reasoning problems. According to this approach, knowledge bases are converted off-line into a target compilation language which is tractable for on-line querying. Reduced ordered binary decision diagram (ROBDD) is one of the most influential target languages. We generalize ROBDD by associating some implied literals in each node and the new language is called reduced ordered binary decision diagram with implied literals (ROBDD-L). Then we discuss a kind of subsets of ROBDD-L called ROBDD-i with precisely i implied literals (0 ≤ i ≤ ∞). In particular, ROBDD-0 is isomorphic to ROBDD; ROBDD-∞ requires that each node should be associated by the implied literals as many as possible. We show that ROBDD-i has uniqueness over some specific variables order, and ROBDD-∞ is the most succinct subset in ROBDD-L and can meet most of the querying requirements involved in the knowledge compilation map. Finally, we propose an ROBDD-i compilation algorithm for any i and a ROBDD-∞ compilation algorithm. Based on them, we implement a ROBDD-L package called BDDjLu and then get some conclusions from preliminary experimental results: ROBDD-∞ is obviously smaller than ROBDD for all benchmarks; ROBDD-∞ is smaller than the d-DNNF the benchmarks whose compilation results are relatively small; it seems that it is better to transform ROBDDs-∞ into FBDDs and ROBDDs rather than straight compile the benchmarks.",
            "output": [
                "Reduced Ordered Binary Decision Diagram with Implied Literals: A New knowledge Compilation Approach"
            ]
        },
        {
            "id": "task1540-3c7d8333d0cd40b38b10ce693f3930ea",
            "input": "Diagnosis of liver infection at preliminary stage is important for better treatment. In today’s scenario devices like sensors are used for detection of infections. Accurate classification techniques are required for automatic identification of disease samples. In this context, this study utilizes data mining approaches for classification of liver patients from healthy individuals. Four algorithms (Naïve Bayes, Bagging, Random forest and SVM) were implemented for classification using R platform. Further to improve the accuracy of classification a hybrid NeuroSVM model was developed using SVM and feed-forward artificial neural network (ANN). The hybrid model was tested for its performance using statistical parameters like root mean square error (RMSE) and mean absolute percentage error (MAPE). The model resulted in a prediction accuracy of 98.83%. The results suggested that development of hybrid model improved the accuracy of prediction. To serve the medicinal community for prediction of liver disease among patients, a graphical user interface (GUI) has been developed using R. The GUI is deployed as a package in local repository of R platform for users to perform prediction.",
            "output": [
                "NeuroSVM: A Graphical User Interface for Identification of Liver Patients"
            ]
        },
        {
            "id": "task1540-da2488501a174357a159e4a2453d085f",
            "input": "Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. This has resulted is substantial duplication of effort and incompatible infrastructure across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon. This TensorFlow-based infrastructure provides a complete modular deep learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications with data loading, data augmentation, network architectures, loss functions and evaluation metrics that are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted interventions.",
            "output": [
                "NiftyNet: a deep-learning platform for medical imaging"
            ]
        },
        {
            "id": "task1540-52a0da7e094d4e2d84cb6d1e38c3ac17",
            "input": "Cooperative games model the allocation of profit from joint actions, following considerations such as stability and fairness. We propose the reliability extension of such games, where agents may fail to participate in the game. In the reliability extension, each agent only “survives” with a certain probability, and a coalition’s value is the probability that its surviving members would be a winning coalition in the base game. We study prominent solution concepts in such games, showing how to approximate the Shapley value and how to compute the core in games with few agent types. We also show that applying the reliability extension may stabilize the game, making the core non-empty even when the base game has an empty core.",
            "output": [
                "Solving Cooperative Reliability Games"
            ]
        },
        {
            "id": "task1540-b01bade413f244f78cb541cac6416e12",
            "input": "Previous studies have proposed image-based clutter measures that correlate with human search times and/or eye movements. However, most models do not take into account the fact that the effects of clutter interact with the foveated nature of the human visual system: visual clutter further from the fovea has an increasing detrimental influence on perception. Here, we introduce a new foveated clutter model to predict the detrimental effects in target search utilizing a forced fixation search task. We use Feature Congestion (Rosenholtz et al.) as our non foveated clutter model, and we stack a peripheral architecture on top of Feature Congestion for our foveated model. We introduce the Peripheral Integration Feature Congestion (PIFC) coefficient, as a fundamental ingredient of our model that modulates clutter as a non-linear gain contingent on eccentricity. We finally show that Foveated Feature Congestion (FFC) clutter scores (r(44) = −0.82 ± 0.04, p < 0.0001) correlate better with target detection (hit rate) than regular Feature Congestion (r(44) = −0.19 ± 0.13, p = 0.0774) in forced fixation search. Thus, our model allows us to enrich clutter perception research by computing fixation specific clutter maps. A toolbox for creating peripheral architectures: Piranhas: Peripheral Architectures for Natural, Hybrid and Artificial Systems will be made available1.",
            "output": [
                "Can Peripheral Representations Improve Clutter Metrics on Complex Scenes?"
            ]
        },
        {
            "id": "task1540-901e562200cb4b16aa81387767281102",
            "input": "The advent of Web 2.0 has led to an increase in the amount of sentimental content available in the Web. Such content is often found in social media web sites in the form of movie or product reviews, user comments, testimonials, messages in discussion forums etc. Timely discovery of the sentimental or opinionated web content has a number of advantages, the most important of all being monetization. Understanding of the sentiments of human masses towards different entities and products enables better services for contextual advertisements, recommendation systems and analysis of market trends. The focus of our project is sentiment focussed web crawling framework to facilitate the quick discovery of sentimental contents of movie reviews and hotel reviews and analysis of the same. We use statistical methods to capture elements of subjective style and the sentence polarity. The paper elaborately discusses two supervised machine learning algorithms: K-Nearest Neighbour(K-NN) and Naïve Bayes’ and compares their overall accuracy, precisions as well as recall values. It was seen that in case of movie reviews Naïve Bayes’ gave far better results than K-NN but for hotel reviews these algorithms gave lesser, almost same",
            "output": [
                "Sentiment Analysis of Review Datasets using Naïve Bayes’ and K-NN Classifier"
            ]
        },
        {
            "id": "task1540-8fe34a78f2b1421ab61253d8c529d4b3",
            "input": "Nowadays this is very popular to use deep architectures in machine learning. Deep Belief Networks (DBNs) are deep architectures that use stack of Restricted Boltzmann Machines (RBM) to create a powerful generative model using training data. In this paper we present an improvement in a common method that is usually used in training of RBMs. The new method uses free energy as a criterion to obtain elite samples from generative model. We argue that these samples can more accurately compute gradient of log probability of training data. According to the results, an error rate of 0.99% was achieved on MNIST test set. This result shows that the proposed method outperforms the method presented in the first paper introducing DBN (1.25% error rate) and general classification methods such as SVM (1.4% error rate) and KNN (with 1.6% error rate). In another test using ISOLET dataset, letter classification error dropped to 3.59% compared to 5.59% error rate achieved in those papers using this dataset. The implemented method is available online at “http://ceit.aut.ac.ir/~keyvanrad/DeeBNet Toolbox.html”.",
            "output": [
                "Deep Belief Network Training Improvement Using Elite Samples Minimizing Free Energy"
            ]
        },
        {
            "id": "task1540-4a00259c4cf0451ca805e056bc8f097e",
            "input": "In many applications, ideas that are described by a set of words often flow between different groups. To facilitate users in analyzing the flow, we present a method to model the flow behaviors that aims at identifying the lead-lag relationships between word clusters of different user groups. In particular, an improved Bayesian conditional cointegration based on dynamic time warping is employed to learn links between words in different groups. A tensor-based technique is developed to cluster these linked words into different clusters (ideas) and track the flow of ideas. The main feature of the tensor representation is that we introduce two additional dimensions to represent both time and lead-lag relationships. Experiments on both synthetic and real datasets show that our method is more effective than methods based on traditional clustering techniques and achieves better accuracy. A case study was conducted to demonstrate the usefulness of our method in helping users understand the flow of ideas between different user groups on social media.",
            "output": [
                "Tracking Idea Flows between Social Groups"
            ]
        },
        {
            "id": "task1540-87752b8c0c274c91adb2aac9a2a2c2d3",
            "input": "We combine Riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic, deep neural networks with random weights. Our results reveal an order-to-chaos expressivity phase transition, with networks in the chaotic phase computing nonlinear functions whose global curvature grows exponentially with depth but not width. We prove this generic class of deep random functions cannot be efficiently computed by any shallow network, going beyond prior work restricted to the analysis of single functions. Moreover, we formalize and quantitatively demonstrate the long conjectured idea that deep networks can disentangle highly curved manifolds in input space into flat manifolds in hidden space. Our theoretical analysis of the expressive power of deep networks broadly applies to arbitrary nonlinearities, and provides a quantitative underpinning for previously abstract notions about the geometry of deep functions.",
            "output": [
                "Exponential expressivity in deep neural networks through transient chaos"
            ]
        },
        {
            "id": "task1540-e02b9df5ce9e40b8aac541afed889ecb",
            "input": "A model of associative memory is studied, which stores and reliably retrieves many more patterns than the number of neurons in the network. We propose a simple duality between this dense associative memory and neural networks commonly used in deep learning. On the associative memory side of this duality, a family of models that smoothly interpolates between two limiting cases can be constructed. One limit is referred to as the feature-matching mode of pattern recognition, and the other one as the prototype regime. On the deep learning side of the duality, this family corresponds to feedforward neural networks with one hidden layer and various activation functions, which transmit the activities of the visible neurons to the hidden layer. This family of activation functions includes logistics, rectified linear units, and rectified polynomials of higher degrees. The proposed duality makes it possible to apply energy-based intuition from associative memory to analyze computational properties of neural networks with unusual activation functions – the higher rectified polynomials which until now have not been used for training neural networks. The utility of the dense memories is illustrated for two test cases: the logical gate XOR and the recognition of handwritten digits from the MNIST data set.",
            "output": [
                "Dense Associative Memory for Pattern Recognition"
            ]
        },
        {
            "id": "task1540-d595290d870e4d49a8e777aafaeee7a9",
            "input": "Observational studies are based on accurate assessment of human state. A behavior recognition system that models interlocutors’ state in real-time can significantly aid the mental health domain. However, behavior recognition from speech remains a challenging task since it is difficult to find generalizable and representative features because of noisy and high-dimensional data, especially when data is limited and annotated coarsely and subjectively. Deep Neural Networks (DNN) have shown promise in a wide range of machine learning tasks, but for Behavioral Signal Processing (BSP) tasks their application has been constrained due to limited quantity of data. We propose a Sparsely-Connected and Disjointly-Trained DNN (SD-DNN) framework to deal with limited data. First, we break the acoustic feature set into subsets and train multiple distinct classifiers. Then, the hidden layers of these classifiers become parts of a deeper network that integrates all feature streams. The overall system allows for full connectivity while limiting the number of parameters trained at any time and allows convergence possible with even limited data. We present results on multiple behavior codes in the couples’ therapy domain and demonstrate the benefits in behavior classification accuracy. We also show the viability of this system towards live behavior annotations.",
            "output": [
                "Sparsely Connected and Disjointly Trained Deep Neural Networks for Low Resource Behavioral Annotation: Acoustic Classification in Couples’ Therapy"
            ]
        },
        {
            "id": "task1540-dc84f629fee143a385308bc3868d306d",
            "input": "Compared with word-level and sentence-level convolutional neural networks (ConvNets), the character-level ConvNets has a better applicability for misspellings and typos input. Due to this, recent researches for text classification mainly focus on character-level ConvNets. However, while the majority of these researches employ English corpus for the character-level text classification, few researches have been done using Chinese corpus. This research hopes to bridge this gap, exploring character-level ConvNets for Chinese corpus test classification. We have constructed a large-scale Chinese dataset, and the result shows that character-level ConvNets works better on Chinese character dataset than its corresponding pinyin format dataset, which is the general solution in previous researches. This is the first time that character-level ConvNets has been applied to Chinese character dataset for text classification problem.",
            "output": [
                "Character-level Convolutional Network for Text Classification Applied to Chinese Corpus"
            ]
        },
        {
            "id": "task1540-8ebb9f28ed2d4de7838557d3ae0e0357",
            "input": "We propose a StochAstic Fault diagnosis AlgoRIthm, called Safari, which trades off guarantees of computing minimal diagnoses for computational efficiency. We empirically demonstrate, using the 74XXX and ISCAS85 suites of benchmark combinatorial circuits, that Safari achieves several orders-of-magnitude speedup over two well-known deterministic algorithms, CDA∗ and HA∗, for multiple-fault diagnoses; further, Safari can compute a range of multiple-fault diagnoses that CDA∗ and HA∗ cannot. We also prove that Safari is optimal for a range of propositional fault models, such as the widely-used weak-fault models (models with ignorance of abnormal behavior). We discuss the optimality of Safari in a class of strong-fault circuit models with stuck-at failure modes. By modeling the algorithm itself as a Markov chain, we provide exact bounds on the minimality of the diagnosis computed. Safari also displays strong anytime behavior, and will return a diagnosis after any non-trivial inference time.",
            "output": [
                "Approximate Model-Based Diagnosis Using Greedy Stochastic Search"
            ]
        },
        {
            "id": "task1540-2cf53a29e942455389799d92663712c7",
            "input": "In this paper we deal with a new approach to probabilistic reasoning in a logical frame­ work. Nearly almost all logics of probabil­ ity that have been proposed in the litera­ ture are based on classical two-valued logic. After making clear the differences between fuzzy logic and probability theory, here we propose a fuzzy logic of probability for which completeness results (in a probabilistic sense) are provided. The main idea behind this approach is that probability values of crisp propositions can be understood as truth­ values of some suitable fuzzy propositions as­ sociated to the crisp ones. Moreover, sug­ gestiotlS and examples of how to extend the formalism to cope with conditional probabil­ ities and with other uncertainty formalisms are also provided.",
            "output": [
                "Fuzzy logic and probability"
            ]
        },
        {
            "id": "task1540-199a361140e440b9aad1a39538c49b20",
            "input": "In Chile, does not exist an independent entity that publishes quantitative or qualitative surveys to   understand   the   traditional   media   environment   and   its   adaptation   on   the   Social  Web. Nowadays, Chilean newsreaders are increasingly using social web platforms as their primary source of   information,  among which Twitter  plays  a central   role.  Historical  media and pure players  are developing  different  strategies   to   increase  their  audience  and  influence on  this platform. In this article, we propose a methodology based on data mining techniques to provide a first level of analysis of the new Chilean media environment. We use a crawling technique to mine news streams of  37 different  Chilean media actively  presents on Twitter  and propose several  indicators  to compare  them. We analyze their  volumes of production,   their  potential audience, and using NLP techniques, we explore the content of their production: their editorial line and their geographic coverage.",
            "output": [
                "Diagnosing editorial strategies of Chilean media on Twitter using an automatic news classifier"
            ]
        },
        {
            "id": "task1540-d848d98055014dfb8ebca165e6e022c4",
            "input": "Practically all programming languages allow the programmer to split a program into several modules which brings along several advantages in software development. In this paper, we are interested in the area of answer-set programming where fully declarative and nonmonotonic languages are applied. In this context, obtaining a modular structure for programs is by no means straightforward since the output of an entire program cannot in general be composed from the output of its components. To better understand the effects of disjunctive information on modularity we restrict the scope of analysis to the case of disjunctive logic programs (DLPs) subject to stable-model semantics. We define the notion of a DLP-function, where a well-defined input/output interface is provided, and establish a novel module theorem which indicates the compositionality of stable-model semantics for DLP-functions. The module theorem extends the well-known splitting-set theorem and enables the decomposition of DLP-functions given their strongly connected components based on positive dependencies induced by rules. In this setting, it is also possible to split shared disjunctive rules among components using a generalized shifting technique. The concept of modular equivalence is introduced for the mutual comparison of DLP-functions using a generalization of a translation-based verification method.",
            "output": [
                "Modularity Aspects of Disjunctive Stable Models"
            ]
        },
        {
            "id": "task1540-de34d08edba7416c85f0b7e8678cffc2",
            "input": "In this work, we study the guaranteed delivery model which is widely used in online display advertising. In the guaranteed delivery scenario, ad exposures (which are also called impressions in some works) to users are guaranteed by contracts signed in advance between advertisers and publishers. A crucial problem for the advertising platform is how to fully utilize the valuable user traffic to generate as much as possible revenue. Different from previous works which usually minimize the penalty of unsatisfied contracts and some other cost (e.g. representativeness), we propose the novel consumption minimization model, in which the primary objective is to minimize the user traffic consumed to satisfy all contracts. Under this model, we develop a near optimal method to deliver ads for users. The main advantage of our method lies in that it consumes nearly as least as possible user traffic to satisfy all contracts, therefore more contracts can be accepted to produce more revenue. It also enables the publishers to estimate how much user traffic is redundant or short so that they can sell or buy this part of traffic in bulk in the exchange market. Furthermore, it is robust with regard to priori knowledge of user type distribution. Finally, the simulation shows that our method outperforms the traditional state-of-the-art methods.",
            "output": [
                "Efficient Delivery Policy to Minimize User Traffic Consumption in Guaranteed Advertising∗"
            ]
        },
        {
            "id": "task1540-e6f93704aed44197bd13ef04b6f4db64",
            "input": "The CSA-ES is an Evolution Strategy with Cumulative Step size Adaptation, where the step size is adapted measuring the length of a so-called cumulative path. The cumulative path is a combination of the previous steps realized by the algorithm, where the importance of each step decreases with time. This article studies the CSA-ES on composites of strictly increasing with affine linear functions through the investigation of its underlying Markov chains. Rigorous results on the change and the variation of the step size are derived with and without cumulation. The step-size diverges geometrically fast in most cases. Furthermore, the influence of the cumulation parameter is studied.",
            "output": [
                "Cumulative Step-size Adaptation on Linear Functions"
            ]
        },
        {
            "id": "task1540-f7dc3a7ad86d42d4abcc77cbf9380df7",
            "input": "miRNA and gene expression profiles have been proved useful for classifying cancer samples. Efficient classifiers have been recently sought and developed. A number of attempts to classify cancer samples using miRNA/gene expression profiles are known in literature. However, the use of semi-supervised learning models have been used recently in bioinformatics, to exploit the huge corpuses of publicly available sets. Using both labeled and unlabeled sets to train sample classifiers, have not been previously considered when gene and miRNA expression sets are used. Moreover, there is a motivation to integrate both miRNA and gene expression for a semi-supervised cancer classification as that provides more information on the characteristics of cancer samples. In this paper, two semi-supervised machine learning approaches, namely self-learning and co-training, are adapted to enhance the quality of cancer sample classification. These approaches exploit the huge public corpuses to enrich the training data. In self-learning, miRNA and gene based classifiers are enhanced independently. While in co-training, both miRNA and gene expression profiles are used simultaneously to provide different views of cancer samples. To our knowledge, it is the first attempt to apply these learning approaches to cancer classification. The approaches were evaluated using breast cancer, hepatocellular carcinoma (HCC) and lung cancer expression sets. Results show up to 20% improvement in F1-measure over Random Forests and SVM classifiers. Co-Training also outperforms Low Density Separation (LDS) approach by around 25% improvement in F1-measure in breast cancer. Keywords— miRNA and gene expression analysis; Semisupervised Approaches; Self-Learning; Co-Training; Cancer sample classifiers",
            "output": [
                "miRNA and Gene Expression based Cancer Classification using Self- Learning and Co-Training Approaches"
            ]
        },
        {
            "id": "task1540-c7cd37919cb04e20a404a9d3e72e61c6",
            "input": "Building neural networks to query a knowledge base (a table) with natural language is an emerging research topic in NLP. The neural enquirer typically necessitates multiple steps of execution because of the compositionality of queries. In previous studies, researchers have developed either distributed enquirers or symbolic ones for table querying. The distributed enquirer is end-to-end learnable, but is weak in terms of execution efficiency and explicit interpretability. The symbolic enqurier, on the contrary, is efficient during execution; but it is very difficult to train especially at initial stages. In this paper, we propose to couple distributed and symbolic execution for natural language queries. The observation is that a fully distributed executor also exhibits meaningful, albeit imperfect, interpretation. We can thus pretrain the symbolic executor with the distributed one’s intermediate execution results in a step-by-step fashion. Experiments show that our approach significantly outperforms either the distributed or symbolic executor; moreover, we have recovered more than 80% execution sequences with only groundtruth denotations during training. In summary, the coupled neural enquirer takes advantages of both distributed and symbolic executors, and has high performance, high learning efficiency, high execution efficiency, and high interpretability.",
            "output": [
                "Coupling Distributed and Symbolic Execution for Natural Language Queries"
            ]
        },
        {
            "id": "task1540-d37df6c1df1541de8972c282dd3819b7",
            "input": "In this work we present a new approach to learn compressible representations in deep architectures with an end-to-end training strategy. Our method is based on a soft (continuous) relaxation of quantization and entropy, which we anneal to their discrete counterparts throughout training. We showcase this method for two challenging applications: Image compression and neural network compression. While these tasks have typically been approached with different methods, our soft-to-hard quantization approach gives state-of-the-art results for both.",
            "output": [
                "Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks"
            ]
        },
        {
            "id": "task1540-aaea8d983a164fd29496d3f22a0ed929",
            "input": "Automated answering of natural language questions is an interesting and useful problem to solve. Question answering (QA) systems often perform information retrieval at an initial stage. Information retrieval (IR) performance, provided by engines such as Lucene, places a bound on overall system performance. For example, no answer bearing documents are retrieved at low ranks for almost 40% of questions. In this paper, answer texts from previous QA evaluations held as part of the Text REtrieval Conferences (TREC) are paired with queries and analysed in an attempt to identify performance-enhancing words. These words are then used to evaluate the performance of a query expansion method. Data driven extension words were found to help in over 70% of difficult questions. These words can be used to improve and evaluate query expansion methods. Simple blind relevance feedback (RF) was correctly predicted as unlikely to help overall performance, and an possible explanation is provided for its low value in IR for QA.",
            "output": [
                "A Data Driven Approach to Query Expansion in Question Answering"
            ]
        },
        {
            "id": "task1540-9620d4b3fbb54ed6969781b2f4b8ac07",
            "input": "In this paper, we introduce a lightweight dynamic epistemic logical framework for automated planning under initial uncertainty. We reduce plan verification and conformant planning to model checking problems of our logic. We show that the model checking problem of the iteration-free fragment is PSPACE-complete. By using two non-standard (but equivalent) semantics, we give novel model checking algorithms to the full language and the iteration-free language.",
            "output": [
                "A Dynamic Epistemic Framework for Conformant Planning"
            ]
        },
        {
            "id": "task1540-9ccd6eea5f25421b9c9341d2d1cdde16",
            "input": "Recurrent Neural Network (RNN) is one of the most popular architectures used in Natural Language Processsing (NLP) tasks because its recurrent structure is very suitable to process variablelength text. RNN can utilize distributed representations of words by first converting the tokens comprising each text into vectors, which form a matrix. And this matrix includes two dimensions: the time-step dimension and the feature vector dimension. Then most existing models usually utilize one-dimensional (1D) max pooling operation or attention-based operation only on the time-step dimension to obtain a fixed-length vector. However, the features on the feature vector dimension are not mutually independent, and simply applying 1D pooling operation over the time-step dimension independently may destroy the structure of the feature representation. On the other hand, applying two-dimensional (2D) pooling operation over the two dimensions may sample more meaningful features for sequence modeling tasks. To integrate the features on both dimensions of the matrix, this paper explores applying 2D max pooling operation to obtain a fixed-length representation of the text. This paper also utilizes 2D convolution to sample more meaningful information of the matrix. Experiments are conducted on six text classification tasks, including sentiment analysis, question classification, subjectivity classification and newsgroup classification. Compared with the state-of-the-art models, the proposed models achieve excellent performance on 4 out of 6 tasks. Specifically, one of the proposed models achieves highest accuracy on Stanford Sentiment Treebank binary classification and fine-grained classification tasks.",
            "output": [
                "Text Classification Improved by Integrating Bidirectional LSTM with Two-dimensional Max Pooling"
            ]
        },
        {
            "id": "task1540-436184804fc747439f097010ae1f524b",
            "input": "Given an existing trained neural network, it is often desirable to be able to add new capabilities without hindering performance of already learned tasks. Existing approaches either learn sub-optimal solutions, require joint training, or incur a substantial increment in the number of parameters for each added task, typically as many as the original network. We propose a method which fully preserves performance on the original task, with only a small increase (around 20%) in the number of required parameters while performing on par with more costly finetuning procedures, which typically double the number of parameters. The learned architecture can be controlled to switch between various learned representations, enabling a single network to solve a task from multiple different domains. We conduct extensive experiments showing the effectiveness of our method and explore different aspects of its behavior.",
            "output": [
                "Incremental Learning Through Deep Adaptation"
            ]
        },
        {
            "id": "task1540-5527d0b69498451c937a0049c9cf6b25",
            "input": "We study the parsing complexity of Combinatory Categorial Grammar (CCG) in the formalism of Vijay-Shanker and Weir (1994). As our main result, we prove that any parsing algorithm for this formalism will necessarily take exponential time when the size of the grammar, and not only the length of the input sentence, is included in the analysis. This result sets the formalism of Vijay-Shanker and Weir (1994) apart from weakly equivalent formalisms such as Tree-Adjoining Grammar (TAG), for which parsing can be performed in time polynomial in the combined size of grammar and input sentence. Our proof highlights important differences between the formalism of Vijay-Shanker and Weir (1994) and contemporary incarnations of CCG.",
            "output": [
                "On the Complexity of CCG Parsing"
            ]
        },
        {
            "id": "task1540-7e026b45ac57400daf9ded7951eb5100",
            "input": "In any knowledge discovery process the value of extracted knowledge is directly related to the quality of the data used. Big Data problems, generated by massive growth in the scale of data observed in recent years, also follow the same dictate. A common problem affecting data quality is the presence of noise, particularly in classification problems, where label noise refers to the incorrect labeling of training instances, and is known to be a very disruptive feature of data. However, in this Big Data era, the massive growth in the scale of the data poses a challenge to traditional proposals created to tackle noise, as they have difficulties coping with such a large amount of data. New algorithms need to be proposed to treat the noise in Big Data problems, providing high quality and clean data, also known as Smart Data. In this paper, two Big Data preprocessing approaches to remove noisy examples are proposed: an homogeneous ensemble and an heterogeneous ensemble filter, with special emphasis in their scalability and performance traits. The obtained results show that these proposals enable the practitioner to efficiently obtain a Smart Dataset from any Big Data classification problem.",
            "output": [
                "Enabling Smart Data: Noise filtering in Big Data classification"
            ]
        },
        {
            "id": "task1540-2b0663c21d6c4b6cbc637c2709254695",
            "input": "The human visual system can spot an abnormal image, and reason about what makes it strange. This task has not received enough attention in computer vision. In this paper we study various types of atypicalities in images in a more comprehensive way than has been done before. We propose a new dataset of abnormal images showing a wide range of atypicalities. We design human subject experiments to discover a coarse taxonomy of the reasons for abnormality. Our experiments reveal three major categories of abnormality: object-centric, scene-centric, and contextual. Based on this taxonomy, we propose a comprehensive computational model that can predict all different types of abnormality in images and outperform prior arts in abnormality recognition.",
            "output": [
                "Toward a Taxonomy and Computational Models of Abnormalities in Images"
            ]
        },
        {
            "id": "task1540-e7774178381148b7ad0a131a79a85ea9",
            "input": "This paper presents an approach to identify efficient techniques used in Web Search Engine Optimization (SEO). Understanding SEO factors which can influence page’s ranking in search engine is significant for webmasters who wish to attract large number of users to their website. Different from previous relevant research, in this study we developed an intelligent Meta search engine which aggregates results from various search engines and ranks them based on several important SEO parameters. The research tries to establish that using more SEO parameters in ranking algorithms helps in retrieving better search results thus increasing user satisfaction. Initial results generated from Meta search engine outperformed existing search engines in terms of better retrieved search results with high precision.",
            "output": [
                "An Innovative Approach for online Meta Search Engine Optimization"
            ]
        },
        {
            "id": "task1540-e5130cad877843f9b3802b1e2aca2c36",
            "input": "Multitask learning can be effective when features useful in one task are also useful for other tasks, and the group lasso is a standard method for selecting a common subset of features. In this paper, we are interested in a less restrictive form of multitask learning, wherein (1) the available features can be organized into subsets according to a notion of similarity and (2) features useful in one task are similar, but not necessarily identical, to the features best suited for other tasks. The main contribution of this paper is a new procedure called Sparse Overlapping Sets (SOS) lasso, a convex optimization that automatically selects similar features for related learning tasks. Error bounds are derived for SOSlasso and its consistency is established for squared error loss. In particular, SOSlasso is motivated by multisubject fMRI studies in which functional activity is classified using brain voxels as features. Experiments with real and synthetic data demonstrate the advantages of SOSlasso compared to the lasso and group lasso.",
            "output": [
                "Sparse Overlapping Sets Lasso for Multitask Learning and its Application to fMRI Analysis"
            ]
        },
        {
            "id": "task1540-45a7f74185eb4fbea545457a4c726d3f",
            "input": "Finding repeated patterns or motifs in a time series is an important unsupervised task that has still a number of open issues, starting by the definition of motif. In this paper, we revise the notion of motif support, characterizing it as the number of patterns or repetitions that define a motif. We then propose GENMOTIF, a genetic algorithm to discover motifs with support which, at the same time, is flexible enough to accommodate other motif specifications and task characteristics. GENMOTIF is an anytime algorithm that easily adapts to many situations: searching in a range of segment lengths, applying uniform scaling, dealing with multiple dimensions, using different similarity and grouping criteria, etc. GENMOTIF is also parameter-friendly: it has only two intuitive parameters which, if set within reasonable bounds, do not substantially affect its performance. We demonstrate the value of our approach in a number of synthetic and real-world settings, considering traffic volume measurements, accelerometer signals, and telephone call records.",
            "output": [
                "A Genetic Algorithm to Discover Flexible Motifs with Support"
            ]
        },
        {
            "id": "task1540-5d4b479a63a34b79b1baba4673fbef1d",
            "input": "We propose a new fast word embedding technique using hash functions. The method is a derandomization of a new type of random projections: By disregarding the classic constraint used in designing random projections (i.e., preserving pairwise distances in a particular normed space), our solution exploits extremely sparse non-negative random projections. Our experiments show that the proposed method can achieve competitive results, comparable to neural embedding learning techniques, however, with only a fraction of the computational complexity of these methods. While the proposed derandomization enhances the computational and space complexity of our method, the possibility of applying weighting methods such as positive pointwise mutual information (PPMI) to our models after their construction (and at a reduced dimensionality) imparts a high discriminatory power to the resulting embeddings. Obviously, this method comes with other known benefits of random projection-based techniques such as ease of update.",
            "output": [
                "Sketching Word Vectors Through Hashing"
            ]
        },
        {
            "id": "task1540-16cdd1eceee14979aa6228abb07ae33c",
            "input": "A long-standing dream of Artificial Intelligence (AI) has pursued to enrich computer programs with commonsense knowledge enabling machines to reason about our world. This paper offers a new practical insight towards the automation of commonsense reasoning with first-order logic (FOL) ontologies. We propose a new black-box testing methodology of FOL SUMO-based ontologies by exploiting WordNet and its mapping into SUMO. Our proposal includes a method for the (semi-)automatic creation of a very large set of tests and a procedure for its automated evaluation by using automated theorem provers (ATPs). Applying our testing proposal, we are able to successfully evaluate a) the competency of several translations of SUMO into FOL and b) the performance of various automated ATPs. In addition, we are also able to evaluate the resulting set of tests according to different quality criteria.",
            "output": [
                "Black-box Testing of First-Order Logic Ontologies Using WordNet"
            ]
        },
        {
            "id": "task1540-ebe584e564764fb193cd3e2c391eabb6",
            "input": "Fuzzy controllers are known to serve as efficient and interpretable system controllers for continuous state and action spaces. To date these controllers have been constructed by hand, or automatically trained either on expert generated problem specific cost functions or by incorporating detailed knowledge about the optimal control strategy. Both requirements for automatic training processes are not given in the majority of real world reinforcement learning (RL) problems. We introduce a new particle swarm reinforcement learning (PSRL) approach which is capable of constructing fuzzy RL policies solely by training parameters on world models produced from randomly generated samples of the real system. This approach relates self-organizing fuzzy controllers to model-based RL for the first time. PSRL can be used straightforward on any RL problem, which is demonstrated on three standard RL benchmarks, mountain car, cart pole balancing and cart pole swing up. Our experiments yielded high performing and well interpretable fuzzy policies.",
            "output": [
                "Particle Swarm Optimization for Generating Fuzzy Reinforcement Learning Policies"
            ]
        },
        {
            "id": "task1540-1d85de2d3e754986b7cdbb53755fd065",
            "input": "Graph models are relevant in many fields, such as distributed computing, intelligent tutoring systems or social network analysis. In many cases, such models need to take changes in the graph structure into account, i.e. a varying number of nodes or edges. Predicting such changes within graphs can be expected to yield important insight with respect to the underlying dynamics, e.g. with respect to user behaviour. However, predictive techniques in the past have almost exclusively focused on single edges or nodes. In this contribution, we attempt to predict the future state of a graph as a whole. We propose to phrase time series prediction as a regression problem and apply dissimilarityor kernel-based regression techniques, such as 1-nearest neighbor, kernel regression and Gaussian process regression, which can be applied to graphs via graph kernels. The output of the regression is a point embedded in a pseudo-Euclidean space, which can be analyzed using subsequent dissimilarityor kernel-based processing methods. We discuss strategies to speed up Gaussian Processes regression from cubic to linear time and evaluate our approach on two well-established theoretical models of graph evolution as well as two real data sets from the domain of intelligent tutoring systems. We find that simple regression methods, such as kernel regression, are sufficient to capture the dynamics in the theoretical models, but that Gaussian process regression significantly improves the prediction error for real-world data.",
            "output": [
                "Time Series Prediction for Graphs in Kernel and Dissimilarity Spaces∗†"
            ]
        },
        {
            "id": "task1540-c795ff55476e44329d45befef535c5f3",
            "input": "We describe a neural network model that jointly learns distributed representations of texts and knowledge base (KB) entities. Given a text in the KB, we train our proposed model to predict entities that are relevant to the text. Our model is designed to be generic with the ability to address various NLP tasks with ease. We train the model using a large corpus of texts and their entity annotations extracted from Wikipedia. We evaluated the model on three important NLP tasks (i.e., sentence textual similarity, entity linking, and factoid question answering) involving both unsupervised and supervised settings. As a result, we achieved state-of-the-art results on all three of these tasks.",
            "output": [
                "Learning Distributed Representations of Texts and Entities from Knowledge Base"
            ]
        },
        {
            "id": "task1540-6b134c916bdf4e318074c78c144691c2",
            "input": "Modeling the purposeful behavior of imperfect agents from a small number of observations is a challenging task. When restricted to the single-agent decision-theoretic setting, inverse optimal control techniques assume that observed behavior is an approximately optimal solution to an unknown decision problem. These techniques learn a utility function that explains the example behavior and can then be used to accurately predict or imitate future behavior in similar observed or unobserved situations. In this work, we consider similar tasks in competitive and cooperative multi-agent domains. Here, unlike single-agent settings, a player cannot myopically maximize its reward; it must speculate on how the other agents may act to influence the game’s outcome. Employing the 1 ar X iv :1 30 8. 35 06 v1 [ cs .G T ] 1 5 A ug 2 01 3 game-theoretic notion of regret and the principle of maximum entropy, we introduce a technique for predicting and generalizing behavior.",
            "output": [
                "Computational Rationalization: The Inverse Equilibrium Problem"
            ]
        },
        {
            "id": "task1540-dc07ef32d16d487a89946918c7cbd474",
            "input": "Learning to predict multi-label outputs is challenging, but in many problems there is a natural metric on the outputs that can be used to improve predictions. In this paper we develop a loss function for multi-label learning, based on the Wasserstein distance. The Wasserstein distance provides a natural notion of dissimilarity for probability measures. Although optimizing with respect to the exact Wasserstein distance is costly, recent work has described a regularized approximation that is efficiently computed. We describe efficient learning algorithms based on this regularization, extending the Wasserstein loss from probability measures to unnormalized measures. We also describe a statistical learning bound for the loss and show connections with the total variation norm and the Jaccard index. The Wasserstein loss can encourage smoothness of the predictions with respect to a chosen metric on the output space. We demonstrate this property on a real-data tag prediction problem, using the Yahoo Flickr Creative Commons dataset, achieving superior performance over a baseline that doesn’t use the metric.",
            "output": [
                "Learning with a Wasserstein Loss"
            ]
        },
        {
            "id": "task1540-f305dc700cc94ce69b72d287221eac91",
            "input": "Community-based question answering platforms have attracted substantial users to share knowledge and learn from each other. As the rapid enlargement of CQA platforms, quantities of overlapped questions emerge, which makes users confounded to select a proper reference. It is urgent for us to take effective automated algorithms to reuse historical questions with corresponding answers. In this paper we focus on the problem with question retrieval, which aims to match historical questions that are relevant or semantically equivalent to resolve one’s query directly. The challenges in this task are the lexical gaps between questions for the word ambiguity and word mismatch problem. Furthermore, limited words in queried sentences cause sparsity of word features. To alleviate these challenges, we propose a novel framework named HNIL which encodes not only the question contents but also the asker’s social interactions to enhance the question embedding performance. More specifically, we apply random walk based learning method with recurrent neural network to match the similarities between asker’s question and historical questions proposed by other users. Extensive experiments on a large-scale dataset from a real world CQA site Quora show that employing the heterogeneous social network information outperforms the other state-of-the-art solutions in this task.",
            "output": [
                "Question Retrieval for Community-based Question Answering via Heterogeneous Network Integration Learning"
            ]
        },
        {
            "id": "task1540-1f1b6c6ee01a4da0b36d980ff689834a",
            "input": "In this paper, we study the impact of selection methods in the context of on-line on-board distributed evolutionary algorithms. We propose a variant of the mEDEA algorithm in which we add a selection operator, and we apply it in a task-driven scenario. We evaluate four selection methods that induce different intensity of selection pressure in a multi-robot navigation with obstacle avoidance task and a collective foraging task. Experiments show that a small intensity of selection pressure is sufficient to rapidly obtain good performances on the tasks at hand. We introduce different measures to compare the selection methods, and show that the higher the selection pressure, the better the performances obtained, especially for the more challenging food foraging task.",
            "output": [
                "Comparison of Selection Methods in On-line Distributed Evolutionary Robotics"
            ]
        },
        {
            "id": "task1540-a638eb7baaea4513af21d6f86303c3e5",
            "input": "The term “affordance” denotes the behavioral meaning of objects. We propose a cognitive architecture for the detection of affordances in the visual modality. This model is based on the internal simulation of movement sequences. For each movement step, the resulting sensory state is predicted by a forward model, which in turn triggers the generation of a new (simulated) motor command by an inverse model. Thus, a series of mental images in the sensory and in the motor domain is evoked. Starting from a real sensory state, a large number of such sequences is simulated in parallel. Final affordance detection is based on the generated motor commands. We apply this model to a real–world mobile robot which is faced with obstacle arrangements some of which are passable (corridor) and some of which are not (dead ends). The robot’s task is to detect the right affordance (“pass–through–able” or “non–pass–through–able”). The required internal models are acquired in a hierarchical training process. Afterwards, the robotic agent is able to distinguish reliably between corridors and dead ends. This real–world result enhances the validity of the proposed mental simulation approach. In addition, we compare several key factors in the simulation process regarding performance and efficiency. Funding statement: This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors. 1 ar X iv :1 61 1. 00 27 4v 1 [ cs .A I] 1 N ov 2 01 6",
            "output": [
                "Detecting Affordances by Visuomotor Simulation"
            ]
        },
        {
            "id": "task1540-5245f0e1ac9d4176af7d67b1d3cfae02",
            "input": "Multi-step temporal-difference (TD) learning, where the update targets contain information from multiple time steps ahead, is one of the most popular forms of TD learning for linear function approximation. The reason is that multi-step methods often yield substantially better performance than their single-step counter-parts, due to a lower bias of the update targets. For non-linear function approximation, however, single-step methods appear to be the norm. Part of the reason could be that on many domains the popular multi-step methods TD(λ) and Sarsa(λ) do not perform well when combined with non-linear function approximation. In particular, they are very susceptible to divergence of value estimates. In this paper, we identify the reason behind this. Furthermore, based on our analysis, we propose a new multi-step TD method for non-linear function approximation that addresses this issue. We confirm the effectiveness of our method using two benchmark tasks with neural networks as function approximation.",
            "output": [
                "Effective Multi-step Temporal-Difference Learning for Non-Linear Function Approximation"
            ]
        },
        {
            "id": "task1540-9e6a278e2f024853bbd9c857fb510462",
            "input": "As probabilistic systems gain popularity and are coming into wider use, the need for a mechanism that explains the system's findings and recom­ mendations becomes more critical. The system will also need a mechanism for ordering compet­ ing explanations. We examine two representa­ tive approaches to explanation in the literature­ one due to Gardenfors and one due to Pearl-and show that both suffer from significant problems. We propose an approach to defining a notion of \"better explanation\" that combines some of the features of both together with more recent work by Pearl and others on causality.",
            "output": [
                "Defining Explanation in Probabilistic Systems"
            ]
        },
        {
            "id": "task1540-8192c2649fcd45ecaba3b14f835a36ba",
            "input": "We address the novel problem of automatically generating quiz-style knowledge questions from a knowledge graph such as DBpedia. Questions of this kind have ample applications, for instance, to educate users about or to evaluate their knowledge in a specific domain. To solve the problem, we propose an end-to-end approach. The approach first selects a named entity from the knowledge graph as an answer. It then generates a structured triple-pattern query, which yields the answer as its sole result. If a multiplechoice question is desired, the approach selects alternative answer options. Finally, our approach uses a template-based method to verbalize the structured query and yield a natural language question. A key challenge is estimating how difficult the generated question is to human users. To do this, we make use of historical data from the Jeopardy! quiz show and a semantically annotated Web-scale document collection, engineer suitable features, and train a logistic regression classifier to predict question difficulty. Experiments demonstrate the viability of our overall approach.",
            "output": [
                "Knowledge Questions from Knowledge Graphs"
            ]
        },
        {
            "id": "task1540-1ab40d038b454b2c895d3245320e6280",
            "input": "A crucial aspect of a knowledge base population system that extracts new facts from text corpora, is the generation of training data for its relation extractors. In this paper, we present a method that maximizes the effectiveness of newly trained relation extractors at a minimal annotation cost. Manual labeling can be significantly reduced by Distant Supervision, which is a method to construct training data automatically by aligning a large text corpus with an existing knowledge base of known facts. For example, all sentences mentioning both ‘Barack Obama’ and ‘US’ may serve as positive training instances for the relation born in(subject,object). However, distant supervision typically results in a highly noisy training set: many training sentences do not really express the intended relation. We propose to combine distant supervision with minimal manual supervision in a technique called feature labeling, to eliminate noise from the large and noisy initial training set, resulting in a significant increase of precision. We further improve on this approach by introducing the Semantic Label Propagation method, which uses the similarity between low-dimensional representations of candidate training instances, to extend the training set in order to increase recall while maintaining high precision. Our proposed strategy for generating training data is studied and evaluated on an established test collection designed for knowledge base population tasks. The experimental results show that the Semantic Label Propagation strategy leads to substantial performance gains when compared to existing approaches, while requiring an almost negligible manual annotation effort.",
            "output": [
                "Knowledge Base Population using Semantic Label Propagation"
            ]
        },
        {
            "id": "task1540-c27d98351c3e4c499729bae9a76d6ff7",
            "input": "Convolutional neural networks (CNNs) with convolutional and pooling operations along the frequency axis have been proposed to attain invariance to frequency shifts of features. However, this is inappropriate with regard to the fact that acoustic features vary in frequency. In this paper, we contend that convolution along the time axis is more effective. We also propose the addition of an intermap pooling (IMP) layer to deep CNNs. In this layer, filters in each group extract common but spectrally variant features, then the layer pools the feature maps of each group. As a result, the proposed IMP CNN can achieve insensitivity to spectral variations characteristic of different speakers and utterances. The effectiveness of the IMP CNN architecture is demonstrated on several LVCSR tasks. Even without speaker adaptation techniques, the architecture achieved a WER of 12.7% on the SWB part of the Hub5’2000 evaluation test set, which is competitive with other state-of-the-art methods.",
            "output": [
                "Deep CNNs along the Time Axis with Intermap Pooling for Robustness to Spectral Variations"
            ]
        },
        {
            "id": "task1540-5121e28562ab4989a420c41f6a45f12d",
            "input": "In this paper, the performance of two dependency parsers, namely Stanford and Minipar, on biomedical texts has been reported. The performance of the parsers to assign dependencies between two biomedical concepts that are already proved to be connected is not satisfying. Both Stanford and Minipar, being statistical parsers, fail to assign dependency relation between two connected concepts if they are distant by at least one clause. Minipar’s performance, in terms of precision, recall and the F-Score of the attachment score (e.g., correctly identified head in a dependency), to parse biomedical text is also measured taking the Stanford’s as a gold standard. The results suggest that Minipar is not suitable yet to parse biomedical texts. In addition, a qualitative investigation reveals that the difference between working principles of the parsers also play a vital role for Minipar’s degraded performance.",
            "output": [
                "Performance of Stanford and Minipar Parser on Biomedical Texts"
            ]
        },
        {
            "id": "task1540-2b95055baf1b49809b83d962f3e6203a",
            "input": "Class imbalance is one of the challenging problems for machine learning in many real-world applications, such as coal and gas burst accident monitoring: the burst premonition data is extreme smaller than the normal data, however, which is the highlight we truly focus on. Cost-sensitive adjustment approach is a typical algorithm-level method resisting the data set imbalance. For SVMs classifier, which is modified to incorporate varying penalty parameter(C) for each of considered groups of examples. However, the C value is determined empirically, or is calculated according to the evaluation metric, which need to be computed iteratively and time consuming. This paper presents a novel cost-sensitive SVM method whose penalty parameter C optimized on the basis of cluster probability density function(PDF) and the cluster PDF is estimated only according to similarity matrix and some predefined hyper-parameters. Experimental results on various standard benchmark data sets and real-world data with different ratios of imbalance show that the proposed method is effective in comparison with commonly used cost-sensitive techniques.",
            "output": [
                "Optimizing Cost-Sensitive SVM for Imbalanced Data :Connecting Cluster to Classification"
            ]
        },
        {
            "id": "task1540-32d088c0d40442a19339dfc29599dcfc",
            "input": "Variational autoencoders (VAE) often use Gaussian or category distribution to model the inference process. This puts a limit on variational learning because this simplified assumption does not match the true posterior distribution, which is usually much more sophisticated. To break this limitation and apply arbitrary parametric distribution during inference, this paper derives a semi-continuous latent representation, which approximates a continuous density up to a prescribed precision, and is much easier to analyze than its continuous counterpart because it is fundamentally discrete. We showcase the proposition by applying polynomial exponential family distributions as the posterior, which are universal probability density function generators. Our experimental results show consistent improvements over commonly used VAE models.",
            "output": [
                "Coarse Grained Exponential Variational Autoencoders"
            ]
        },
        {
            "id": "task1540-c9f2c8254be94311ba2501637094ff7e",
            "input": "Leaf vein forms the basis of leaf characterization and classification. Different species have different leaf vein patterns. It is seen that leaf vein segmentation will help in maintaining a record of all the leaves according to their specific pattern of veins thus provide an effective way to retrieve and store information regarding various plant species in database as well as provide an effective means to characterize plants on the basis of leaf vein structure which is unique for every species. The algorithm proposes a new way of segmentation of leaf veins with the use of Odd Gabor filters and the use of morphological operations for producing a better output. The Odd Gabor filter gives an efficient output and is robust and scalable as compared with the existing techniques as it detects the fine fiber like veins present in leaves much more efficiently.",
            "output": [
                "Leaf vein segmentation using Odd Gabor filters and morphological operations"
            ]
        },
        {
            "id": "task1540-1c7e702e917640c6bf28c04eefb38ab6",
            "input": "Or’s of And’s (OA) models are comprised of a small number of disjunctions of conjunctions, also called disjunctive normal form. An example of an OA model is as follows: If (x1 = ‘blue’ AND x2 = ‘middle’) OR (x1 = ‘yellow’), then predict Y = 1, else predict Y = 0. Or’s of And’s models have the advantage of being interpretable to human experts, since they are a set of conditions that concisely capture the characteristics of a specific subset of data. We present two optimization-based machine learning frameworks for constructing OA models, Optimized OA (OOA) and its faster version, Optimized OA with Approximations (OOAx). We prove theoretical bounds on the properties of patterns in an OA model. We build OA models as a diagnostic screening tool for obstructive sleep apnea, that achieves high accuracy with a substantial gain in interpretability over other methods.",
            "output": [
                "Learning Optimized Or’s of And’s"
            ]
        },
        {
            "id": "task1540-01817aedc6ee49248f51ddff64733e27",
            "input": "This paper presents a new deterministic approx­ imation technique in Bayesian networks. This method, \"Expectation Propagation,\" unifies two previous techniques: assumed-density filtering, an extension of the Kalman filter, and loopy be­ lief propagation, an extension of belief propaga­ tion in Bayesian networks. Loopy belief propa­ gation, because it propagates exact belief states, is useful for a limited class of belief networks, such as those which are purely discrete. Expec­ tation Propagation approximates the belief states by only retaining expectations, such as mean and variance, and iterates until these expectations are consistent throughout the network. This makes it applicable to hybrid networks with discrete and continuous nodes. Experiments with Gaussian mixture models show Expectation Propagation to be convincingly better than methods with simi­ lar computational cost: Laplace's method, vari­ ational Bayes, and Monte Carlo. Expectation Propagation also provides an efficient algorithm for training Bayes point machine classifiers.",
            "output": [
                "Expectation Propagation for Approximate Bayesian Inference"
            ]
        },
        {
            "id": "task1540-0d9dd84414b347b0a5aa7a450b7963d7",
            "input": "Obtaining models that capture imaging markers relevant for<lb>disease progression and treatment monitoring is challenging. Models are<lb>typically based on large amounts of data with annotated examples of<lb>known markers aiming at automating detection. High annotation ef-<lb>fort and the limitation to a vocabulary of known markers limit the<lb>power of such approaches. Here, we perform unsupervised learning to<lb>identify anomalies in imaging data as candidates for markers. We pro-<lb>pose AnoGAN, a deep convolutional generative adversarial network to<lb>learn a manifold of normal anatomical variability, accompanying a novel<lb>anomaly scoring scheme based on the mapping from image space to a la-<lb>tent space. Applied to new data, the model labels anomalies, and scores<lb>image patches indicating their fit into the learned distribution. Results<lb>on optical coherence tomography images of the retina demonstrate that<lb>the approach correctly identifies anomalous images, such as images con-<lb>taining retinal fluid or hyperreflective foci.",
            "output": [
                "Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery"
            ]
        },
        {
            "id": "task1540-34302f3dd4244fcb88fa8189f1718ee0",
            "input": "A major investment made by a telecom operator goes into the infrastructure and its maintenance, while business revenues are proportional to how big and good the customer base is. We present a data-driven analytic strategy based on combinatorial optimization and analysis of historical data. The data cover historical mobility of the users in one region of Sweden during a week. Applying the proposed method to the case study, we have identified the optimal proportion of geo-demographic segments in the customer base, developed a functionality to assess the potential of a planned marketing campaign, and explored the problem of an optimal number and types of the geo-demographic segments to target through marketing campaigns. With the help of fuzzy logic, the conclusions of data analysis are automatically translated into comprehensible recommendations in a natural language.",
            "output": [
                "Recommendations for Marketing Campaigns in Telecommunication Business based on the footprint analysis"
            ]
        },
        {
            "id": "task1540-27fd20d529db45b98b4e9828ddca9c30",
            "input": "This work presents and analyzes three convolutional neural network (CNN) models for efficient pixelwise classification of images. When using convolutional neural networks to classify single pixels in patches of a whole image, a lot of redundant computations are carried out when using sliding window networks. This set of new architectures solve this issue by either removing redundant computations or using fully convolutional architectures that inherently predict many pixels at once. The implementations of the three models are accessible through a new utility on top of the Caffe library. The utility provides support for a wide range of image input and output formats, pre-processing parameters and methods to equalize the label histogram during training. The Caffe library has been extended by new layers and a new backend for availability on a wider range of hardware such as CPUs and GPUs through OpenCL. On AMD GPUs, speedups of 54× (SK-Net), 437× (U-Net) and 320× (USKNet) have been observed, taking the SK equivalent SW (sliding window) network as the baseline. The label throughput is up to one megapixel per second. The analyzed neural networks have distinctive characteristics that apply during training or processing, and not every data set is suitable to every architecture. The quality of the predictions is assessed on two neural tissue data sets, of which one is the ISBI 2012 challenge data set. Two different loss functions, Malis loss and Softmax loss, were used during training. The whole pipeline, consisting of models, interface and modified Caffe library, is available as Open Source software under the working title Project Greentea.",
            "output": [
                "Efficient Convolutional Neural Networks for Pixelwise Classification on Heterogeneous Hardware Systems"
            ]
        },
        {
            "id": "task1540-b22cfce82d404459a340a43df53f8987",
            "input": "Different notions of equivalence, such as the prominent notions of strong and uniform equivalence, have been studied in Answer-Set Programming, mainly for the purpose of identifying programs that can serve as substitutes without altering the semantics, for instance in program optimization. Such semantic comparisons are usually characterized by various selections of models in the logic of Hereand-There (HT). For uniform equivalence however, correct characterizations in terms of HT-models can only be obtained for finite theories, respectively programs. In this article, we show that a selection of countermodels in HT captures uniform equivalence also for infinite theories. This result is turned into coherent characterizations of the different notions of equivalence by countermodels, as well as by a mixture of HT-models and countermodels (so-called equivalence interpretations). Moreover, we generalize the so-called notion of relativized hyperequivalence for programs to propositional theories, and apply the same methodology in order to obtain a semantic characterization which is amenable to infinite settings. This allows for a lifting of the results to first-order theories under a very general semantics given in terms of a quantified version of HT. We thus obtain a general framework for the study of various notions of equivalence for theories under answer-set semantics. Moreover, we prove an expedient property that allows for a simplified treatment of extended signatures, and provide further results for non-ground logic programs. In particular, uniform equivalence coincides under open and ordinary answer-set semantics, and for finite non-ground programs under these semantics, also the usual characterization of uniform equivalence in terms of maximal and total HT-models of the grounding is correct, even for infinite domains, when corresponding ground programs are infinite. To appear in Theory and Practice of Logic Programming (TPLP).",
            "output": [
                "A General Framework for Equivalences in Answer-Set Programming by Countermodels in the Logic of Here-and-There ∗"
            ]
        },
        {
            "id": "task1540-1d7e8f10a54d4ca6a907bf71824a1d2c",
            "input": "Language is a social phenomenon and inherent to its social nature is that it is constantly changing. Recently, a surge of interest can be observed within the computational linguistics (CL) community in the social dimension of language. In this article we present a survey of the emerging field of ‘Computational Sociolinguistics’ that reflects this increased interest. We aim to provide a comprehensive overview of CL research on sociolinguistic themes, featuring topics such as the relation between language and social identity, language use in social interaction and multilingual communication. Moreover, we demonstrate the potential for synergy between the research communities involved, by showing how the large-scale data-driven methods that are widely used in CL can complement existing sociolinguistic studies, and how sociolinguistics can inform and challenge the methods and assumptions employed in CL studies. We hope to convey the possible benefits of a closer collaboration between the two communities and conclude with a discussion of open challenges.",
            "output": [
                "Computational Sociolinguistics: A Survey"
            ]
        },
        {
            "id": "task1540-6e76462cf49a4c429a3a40ddb443c3a0",
            "input": "Summarization of large texts is still an open problem in language processing. In this work we develop a full fledged pipeline to generate summaries of news articles using the Abstract Meaning Representation(AMR). We first generate the AMR graphs of stories then extract summary graphs from the story graphs and finally generate sentences from the summary graph. For extracting summary AMRs from the story AMRs we use a two step process. First, we find important sentences from the text and then extract the summary AMRs from those selected sentences. We outperform the previous methods using AMR for summarization by more that 3 ROGUE-1 points. On the CNN-Dailymail corpus we achieve results competitive with the strong lead-3 baseline till summary graph extraction step.",
            "output": [
                "Text Summarization using Abstract Meaning Representation"
            ]
        },
        {
            "id": "task1540-47270aee5bd94008ba9a52b6f56c1e5c",
            "input": "We address the problem of determining correspondences between two images in agreement with a geometric model such as an affine or thin-plate-spline transformation, and estimating its parameters. The contributions of this work are three-fold. First, we propose a convolutional neural network architecture for geometric matching. The architecture is based on three main components that mimic the standard steps of feature extraction, matching and simultaneous inlier detection and model parameter estimation, while being trainable end-to-end. Second, we demonstrate that the network parameters can be trained from synthetically generated imagery without the need for manual annotation and that our matching layer significantly increases generalization capabilities to never seen before images. Finally, we show that the same model can perform both instance-level and category-level matching giving state-of-the-art results on the challenging Proposal Flow dataset.",
            "output": [
                "Convolutional neural network architecture for geometric matching"
            ]
        },
        {
            "id": "task1540-bbdd07964d924be8af8c7522920b531e",
            "input": "Deep learning tools have recently gained much attention in applied machine learning. However such tools for regression and classification do not allow us to capture model uncertainty. Bayesian models offer us the ability to reason about model uncertainty, but usually come with a prohibitive computational cost. We show that dropout in multilayer perceptron models (MLPs) can be interpreted as a Bayesian approximation. Results are obtained for modelling uncertainty for dropout MLP models – extracting information that has been thrown away so far, from existing models. This mitigates the problem of representing uncertainty in deep learning without sacrificing computational performance or test accuracy. We perform an exploratory study of the dropout uncertainty properties. Various network architectures and non-linearities are assessed on tasks of extrapolation, interpolation, and classification. We show that model uncertainty is important for classification tasks using MNIST as an example, and use the model’s uncertainty in a Bayesian pipeline, with deep reinforcement learning as a concrete example.",
            "output": [
                "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"
            ]
        },
        {
            "id": "task1540-43b02fb21dab4d65918c9b81894ebbae",
            "input": "This paper has two parts. In the first part we discuss word embeddings. We discuss the need for them, some of the methods to create them, and some of their interesting properties. We also compare them to image embeddings and see how word embedding and image embedding can be combined to perform different tasks. In the second part we implement a convolutional neural network trained on top of pre-trained word vectors. The network is used for several sentence-level classification tasks, and achieves state-of-art (or comparable) results, demonstrating the great power of pre-trainted word embeddings over random ones.",
            "output": [
                "Word Embeddings and Their Use In Sentence Classification Tasks"
            ]
        },
        {
            "id": "task1540-e548cb4952164568b081a99c6af89872",
            "input": "Asynchronous parallel implementations for stochastic optimization have received huge successes in theory and practice recently. Asynchronous implementations with lock-free are more efficient than the one with writing or reading lock. In this paper, we focus on a composite objective function consisting of a smooth convex function f and a block separable convex function, which widely exists in machine learning and computer vision. We propose an asynchronous stochastic block coordinate descent algorithm with the accelerated technology of variance reduction (AsySBCDVR), which are with lock-free in the implementation and analysis. AsySBCDVR is particularly important because it can scale well with the sample size and dimension simultaneously. We prove that AsySBCDVR achieves a linear convergence rate when the function f is with the optimal strong convexity property, and a sublinear rate when f is with the general convexity. More importantly, a near-linear speedup on a parallel system with shared memory can be obtained.",
            "output": [
                "Asynchronous Stochastic Block Coordinate Descent with Variance Reduction"
            ]
        },
        {
            "id": "task1540-12c1573e1f1048db92073077f7aa4f12",
            "input": "We consider a general framework of online learning with expert advice where the regret is defined with respect to a competitor class defined by a weighted automaton over sequences of experts. Our framework covers several problems previously studied, in particular that of competing against k-shifting experts. We give a series of algorithms for this problem, including an automata-based algorithm extending weightedmajority and more efficient algorithms based on the notion of failure transitions. We further present efficient algorithms based on a compact approximation of the competitor automaton, in particular efficient n-gram models obtained by minimizing the Rényi divergence, and present an extensive study of the approximation properties of such models. We also extend our algorithms and results to the framework of sleeping experts. Finally, we describe the extension of our approximation methods to online convex optimization and a general mirror descent setting.",
            "output": [
                "Online Learning against Expert Automata"
            ]
        },
        {
            "id": "task1540-aab1c93ec6ec473fb80ea5f345f356b9",
            "input": "In this paper, the framework of kernel machines with two layers is introduced, generalizing classical kernel methods. The new learning methodology provide a formal connection between computational architectures with multiple layers and the theme of kernel learning in standard regularization methods. First, a representer theorem for two-layer networks is presented, showing that finite linear combinations of kernels on each layer are optimal architectures whenever the corresponding functions solve suitable variational problems in reproducing kernel Hilbert spaces (RKHS). The input-output map expressed by these architectures turns out to be equivalent to a suitable single-layer kernel machines in which the kernel function is also learned from the data. Recently, the so-called multiple kernel learning methods have attracted considerable attention in the machine learning literature. In this paper, multiple kernel learning methods are shown to be specific cases of kernel machines with two layers in which the second layer is linear. Finally, a simple and effective multiple kernel learning method called RLS2 (regularized least squares with two layers) is introduced, and his performances on several learning problems are extensively analyzed. An open source MATLAB toolbox to train and validate RLS2 models with a Graphic User Interface is available.",
            "output": [
                "Kernel machines with two layers and multiple kernel learning"
            ]
        },
        {
            "id": "task1540-88c2a6a10e3b47868898c63d2022ba8b",
            "input": "We study two mixed robust/average-case submodular partitioning problems that we collectively call Submodular Partitioning. These problems generalize both purely robust instances of the problem (namely max-min submodular fair allocation (SFA) Golovin (2005) and min-max submodular load balancing (SLB) Svitkina and Fleischer (2008)) and also generalize average-case instances (that is the submodular welfare problem (SWP) Vondrák (2008) and submodular multiway partition (SMP) Chekuri and Ene (2011a)). While the robust versions have been studied in the theory community Goemans et al. (2009); Golovin (2005); Khot and Ponnuswami (2007); Svitkina and Fleischer (2008); Vondrák (2008), existing work has focused on tight approximation guarantees, and the resultant algorithms are not, in general, scalable to very large real-world applications. This is in contrast to the average case, where most of the algorithms are scalable. In the present paper, we bridge this gap, by proposing several new algorithms (including those based on greedy, majorization-minimization, minorization-maximization, and relaxation algorithms) that not only scale to large sizes but that also achieve theoretical approximation guarantees close to the state-of-the-art, and in some cases achieve new tight bounds. We also provide new scalable algorithms that apply to additive combinations of the robust and average-case extreme objectives. We show that these problems have many applications in machine learning (ML). This includes: 1) data 1 ar X iv :1 51 0. 08 86 5v 2 [ cs .D S] 1 6 A ug 2 01 6 Wei, Iyer, Wang, Bai, Bilmes partitioning and load balancing for distributed machine algorithms on parallel machines; 2) data clustering; and 3) multi-label image segmentation with (only) Boolean submodular functions via pixel partitioning. We empirically demonstrate the efficacy of our algorithms on real-world problems involving data partitioning for distributed optimization of standard machine learning objectives (including both convex and deep neural network objectives), and also on purely unsupervised (i.e., no supervised or semi-supervised learning, and no interactive segmentation) image segmentation.",
            "output": [
                "Mixed Robust/Average Submodular Partitioning: Fast Algorithms, Guarantees, and Applications to Parallel Machine Learning and Multi-Label Image Segmentation"
            ]
        },
        {
            "id": "task1540-8d14e0d06a904da689ef62f1dbef3bd0",
            "input": "<lb>We show that any model trained by a stochastic gradient method with few iterations has<lb>vanishing generalization error. We prove this by showing the method is algorithmically stable<lb>in the sense of Bousquet and Elisseeff. Our analysis only employs elementary tools from convex<lb>and continuous optimization. Our results apply to both convex and non-convex optimization<lb>under standard Lipschitz and smoothness assumptions.<lb>Applying our results to the convex case, we provide new explanations for why multiple<lb>epochs of stochastic gradient descent generalize well in practice. In the nonconvex case, we<lb>provide a new interpretation of common practices in neural networks, and provide a formal<lb>rationale for stability-promoting mechanisms in training large, deep models. Conceptually, our<lb>findings underscore the importance of reducing training time beyond its obvious benefit.",
            "output": [
                "Stability of stochastic gradient descent"
            ]
        },
        {
            "id": "task1540-fb0078bad92d4bfbbf76ba1c70e6d946",
            "input": "Tasks such as record linkage and multi-target tracking, which involve reconstructing the set of objects that underlie some observed data, are particularly challenging for probabilistic inference. Recent work has achieved efficient and accurate inference on such problems using Markov chain Monte Carlo (MCMC) techniques with customized proposal distributions. Currently, implementing such a system requires coding MCMC state representations and acceptance probability calculations that are specific to a particular application. An alternative approach, which we pursue in this paper, is to use a general-purpose probabilistic modeling language (such as BLOG) and a generic Metropolis-Hastings MCMC algorithm that supports user-supplied proposal distributions. Our algorithm gains flexibility by using MCMC states that are only partial descriptions of possible worlds; we provide conditions under which MCMC over partial worlds yields correct answers to queries. We also show how to use a context-specific Bayes net to identify the factors in the acceptance probability that need to be computed for a given proposed move. Experimental results on a citation matching task show that our general-purpose MCMC engine compares favorably with an application-specific system.",
            "output": [
                "General-Purpose MCMC Inference over Relational Structures"
            ]
        },
        {
            "id": "task1540-2aff2ff7839143f99b70c95935f942bf",
            "input": "Recommender systems often use latent features to explain the behaviors of users and capture the properties of items. As users interact with different items over time, user and item features can influence each other, evolve and co-evolve over time. To accurately capture the fine grained nonlinear coevolution of these features, we propose a recurrent coevolutionary feature embedding process model, which combines recurrent neural network (RNN) with a multidimensional point process model. The RNN learns a nonlinear representation of user and item features which take into account mutual influence between user and item features, and the feature evolution over time. We also develop an efficient stochastic gradient algorithm for learning the model parameters, which can readily scale up to millions of events. Experiments on diverse real-world datasets demonstrate significant improvements in user behavior prediction compared to state-of-the-arts.",
            "output": [
                "Recurrent Coevolutionary Feature Embedding Processes for Recommendation"
            ]
        },
        {
            "id": "task1540-0ac78de116394329b250583efd7a9572",
            "input": "Multiple automakers have in development or in production automated driving systems (ADS) that offer freeway-pilot functions. This type of ADS is typically limited to restricted-access freeways only, that is, the transition from manual to automated modes takes place only after the ramp merging process is completed manually. One major challenge to extend the automation to ramp merging is that the automated vehicle needs to incorporate and optimize long-term objectives (e.g. successful and smooth merge) when near-term actions must be safely executed. Moreover, the merging process involves interactions with other vehicles whose behaviors are sometimes hard to predict but may influence the merging vehicle’s optimal actions. To tackle such a complicated control problem, we propose to apply Deep Reinforcement Learning (DRL) techniques for finding an optimal driving policy by maximizing the long-term reward in an interactive environment. Specifically, we apply a Long Short-Term Memory (LSTM) architecture to model the interactive environment, from which an internal state containing historical driving information is conveyed to a Deep Q-Network (DQN). The DQN is used to approximate the Q-function, which takes the internal state as input and generates Q-values as output for action selection. With this DRL architecture, the historical impact of interactive environment on the long-term reward can be captured and taken into account for deciding the optimal control policy. The proposed architecture has the potential to be extended and applied to other autonomous driving scenarios such as driving through a complex intersection or changing lanes under varying traffic flow conditions. Keywords— Autonomous Driving; Highway On-Ramp Merge; Deep Reinforcement Learning; Long Short-Term Memory; Deep Q-Network; Control Policy",
            "output": [
                "Formulation of Deep Reinforcement Learning Architecture Toward Autonomous Driving for On-Ramp Merge"
            ]
        },
        {
            "id": "task1540-f55fddc273664cf78e18bdc6c39d8dfe",
            "input": "Stochastic variational inference (SVI) lets us scale up Bayesian computation to massive data. It uses stochastic optimization to fit a variational distribution, following easy-to-compute noisy natural gradients. As with most traditional stochastic optimization methods, SVI takes precautions to use unbiased stochastic gradients whose expectations are equal to the true gradients. In this paper, we explore the idea of following biased stochastic gradients in SVI. Our method replaces the natural gradient with a similarly constructed vector that uses a fixed-window moving average of some of its previous terms. We will demonstrate the many advantages of this technique. First, its computational cost is the same as for SVI and storage requirements only multiply by a constant factor. Second, it enjoys significant variance reduction over the unbiased estimates, smaller bias than averaged gradients, and leads to smaller mean-squared error against the full gradient. We test our method on latent Dirichlet allocation with three large corpora.",
            "output": [
                "Smoothed Gradients for Stochastic Variational Inference"
            ]
        },
        {
            "id": "task1540-29e5d980cebf45d5bb19b91127d833fc",
            "input": "The alternating direction method of multipliers (ADMM) has been recognized as a versatile approach for solving modern large-scale machine learning and signal processing problems efficiently. When the data size and/or the problem dimension is large, a distributed version of ADMM can be used, which is capable of distributing the computation load and the data set to a network of computing nodes. Unfortunately, a direct synchronous implementation of such algorithm does not scale well with the problem size, as the algorithm speed is limited by the slowest computing nodes. To address this issue, in a companion paper, we have proposed an asynchronous distributed ADMM (AD-ADMM) and studied its worst-case convergence conditions. In this paper, we further the study by characterizing the conditions under which the AD-ADMM achieves linear convergence. Our conditions as well as the resulting linear rates reveal the impact that various algorithm parameters, network delay and network size have on the algorithm performance. To demonstrate the superior time efficiency of the proposed AD-ADMM, we test the ADADMM on a high-performance computer cluster by solving a large-scale logistic regression problem. Keywords− Distributed optimization, ADMM, Asynchronous, Consensus optimization ⋆Tsung-Hui Chang is the corresponding author. Address: School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China 518172, E-mail: tsunghui.chang@ieee.org. Wei-Cheng Liao is with Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455, USA, E-mail: mhong@umn.edu Mingyi Hong is with Department of Industrial and Manufacturing Systems Engineering, Iowa State University, Ames, 50011, USA, E-mail: mingyi@iastate.edu Xiangfeng Wang is with Shanghai Key Lab for Trustworthy Computing, Software Engineering Institute, East China Normal University, Shanghai, 200062, China, E-mail: xfwang@sei.ecnu.edu.cn September 10, 2015 DRAFT",
            "output": [
                "Asynchronous Distributed ADMM for Large-Scale Optimization- Part II: Linear Convergence Analysis and Numerical Performance"
            ]
        },
        {
            "id": "task1540-a4492fb4eb824c2498cafec18d704248",
            "input": "In many sequential decision-making problems we may want to manage risk by minimizing some measure of variability in costs in addition to minimizing a standard criterion. Conditional value-at-risk (CVaR) is a relatively new risk measure that addresses some of the shortcomings of the well-known variance-related risk measures, and because of its computational efficiencies has gained popularity in finance and operations research. In this paper, we consider the mean-CVaR optimization problem in MDPs. We first derive a formula for computing the gradient of this risk-sensitive objective function. We then devise policy gradient and actor-critic algorithms that each uses a specific method to estimate this gradient and updates the policy parameters in the descent direction. We establish the convergence of our algorithms to locally risk-sensitive optimal policies. Finally, we demonstrate the usefulness of our algorithms in an optimal stopping problem.",
            "output": [
                "Algorithms for CVaR Optimization in MDPs"
            ]
        },
        {
            "id": "task1540-ffacb99b228e4e36af6bb36a7bff45a3",
            "input": "Despite significant developments in Proof Theory, surprisingly little attention has been devoted to the concept of proof verifier. In particular, mathematical community may be interested in studying different types of proof verifiers (people, programs, oracles, communities, superintelligences, etc.) as mathematical objects, their properties, their powers and limitations (particularly in human mathematicians), minimum and maximum complexity, as well as selfverification and self-reference issues in verifiers. We propose an initial classification system for verifiers and provide some rudimentary analysis of solved and open problems in this important domain. Our main contribution is a formal introduction of the notion of unverifiability, for which the paper could serve as a general citation in domains of theorem proving, software and AI verification.",
            "output": [
                "Verifier Theory from Axioms to Unverifiability of Mathematical Proofs, Software and AI"
            ]
        },
        {
            "id": "task1540-2b524933ceea4dc18416de6403a7a8e2",
            "input": "The paper studies machine learning problems where each example is described using a set of Boolean features and where hypotheses are represented by linear threshold elements. One method of increasing the expressiveness of learned hypotheses in this context is to expand the feature set to include conjunctions of basic features. This can be done explicitly or where possible by using a kernel function. Focusing on the well known Perceptron and Winnow algorithms, the paper demonstrates a tradeoff between the computational efficiency with which the algorithm can be run over the expanded feature space and the generalization ability of the corresponding learning algorithm. We first describe several kernel functions which capture either limited forms of conjunctions or all conjunctions. We show that these kernels can be used to efficiently run the Perceptron algorithm over a feature space of exponentially many conjunctions; however we also show that using such kernels, the Perceptron algorithm can provably make an exponential number of mistakes even when learning simple functions. We then consider the question of whether kernel functions can analogously be used to run the multiplicative-update Winnow algorithm over an expanded feature space of exponentially many conjunctions. Known upper bounds imply that the Winnow algorithm can learn Disjunctive Normal Form (DNF) formulae with a polynomial mistake bound in this setting. However, we prove that it is computationally hard to simulate Winnow’s behavior for learning DNF over such a feature set. This implies that the kernel functions which correspond to running Winnow for this problem are not efficiently computable, and that there is no general construction that can run Winnow with kernels.",
            "output": [
                "Efficiency versus Convergence of Boolean Kernels for On-Line Learning Algorithms"
            ]
        },
        {
            "id": "task1540-d26eebc31a6c41f3b5340943043b4b7e",
            "input": "In this paper we consider the problem of multi-task learning, in which a learner is given a collection of prediction tasks that need to be solved. In contrast to previous work, we give up on the assumption that labeled training data is available for all tasks. Instead, we propose an active task selection framework, where based only on the unlabeled data, the learner can choose a, typically small, subset of tasks for which he gets some labeled examples. For the remaining tasks, which have no available annotation, solutions are found by transferring information from the selected tasks. We analyze two transfer strategies and develop generalization bounds for each of them. Based on this theoretical analysis we propose two algorithms for making the choice of labeled tasks in a principled way and show their effectiveness on synthetic and real data.",
            "output": [
                "Active Task Selection for Multi-Task Learning"
            ]
        },
        {
            "id": "task1540-9022f0ce8f1b407a86b34ad2593be916",
            "input": "The study of social networks is a burgeoning research area. However, most existing work deals with networks that simply encode whether relationships exist or not. In contrast, relationships in signed networks can be positive (“like”, “trust”) or negative (“dislike”, “distrust”). The theory of social balance shows that signed networks tend to conform to some local patterns that, in turn, induce certain global characteristics. In this paper, we exploit both local as well as global aspects of social balance theory for two fundamental problems in the analysis of signed networks: sign prediction and clustering. Motivated by local patterns of social balance, we first propose two families of sign prediction methods: measures of social imbalance (MOIs), and supervised learning using high order cycles (HOCs). These methods predict signs of edges based on triangles and l-cycles for relatively small values of l. Interestingly, by examining measures of social imbalance, we show that the classic Katz measure, which is used widely in unsigned link prediction, actually has a balance theoretic interpretation when applied to signed networks. Furthermore, motivated by the global structure of balanced networks, we propose an effective low rank modeling approach for both sign prediction and clustering. For the low rank modeling approach, we provide theoretical performance guarantees via convex relaxations, scale it up to large problem sizes using a matrix factorization based algorithm, and provide extensive experimental validation including comparisons with local approaches. Our experimental results indicate that, by adopting a more global viewpoint of balance structure, we get significant performance and computational gains in prediction and clustering tasks on signed networks. Our work therefore highlights the usefulness of the global aspect of balance theory for the analysis of signed networks.",
            "output": [
                "Prediction and Clustering in Signed Networks: A Local to Global Perspective"
            ]
        },
        {
            "id": "task1540-46cc087bd1df483e8fc3b71ebacb6cf4",
            "input": "Generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks. We propose a generative adversarial model that works on continuous sequential data, and apply it by training it on a collection of classical music. We conclude that it generates music that sounds better and better as the model is trained, report statistics on generated music, and let the reader judge the quality by downloading the generated songs.",
            "output": [
                "C-RNN-GAN: Continuous recurrent neural networks with adversarial training"
            ]
        },
        {
            "id": "task1540-4e9bf7929fe548ee8aa46bb30a3ad742",
            "input": "We train a generator by maximum likelihood and we also train the same generator architecture by Wasserstein GAN. We then compare the generated samples, exact log-probability densities and approximate Wasserstein distances. We show that an independent critic trained to approximate Wasserstein distance between the validation set and the generator distribution helps detect overfitting. Finally, we use ideas from the one-shot learning literature to develop a novel fast learning critic.",
            "output": [
                "Comparison of Maximum Likelihood and GAN-based training of Real NVPs"
            ]
        },
        {
            "id": "task1540-6d226de836b54a25b22b4fc2f71c1ed8",
            "input": "Neural Turing Machines (NTM) [2] contain memory component that simulates “working memroy” in the brain to store and retrieve information to ease simple algorithms learning. So far, only linearly organized memory is proposed, and during experiments, we observed that the model does not always converge, and overfits easily when handling certain tasks. We think memory component is key to some faulty behaviors of NTM, and better organization of memory component could help fight those problems. In this paper, we propose several different structures of memory for NTM, and we proved in experiments that two of our proposed structured-memory NTMs could lead to better convergence, in term of speed and prediction accuracy on copy task and associative recall task as in [2].",
            "output": [
                "Structured Memory for Neural Turing Machines"
            ]
        },
        {
            "id": "task1540-8a9e27b683e54213872ff0708f6047f9",
            "input": "Label distribution learning (LDL) is a general learning framework, which assigns a distribution over a set of labels to an instance rather than a single label or multiple labels. Current LDL methods have either restricted assumptions on the expression form of the label distribution or limitations in representation learning. This paper presents label distribution learning forests (LDLFs) a novel label distribution learning algorithm based on differentiable decision trees, which have several advantages: 1) Decision trees have the potential to model any general form of label distributions by the mixture of leaf node predictions. 2) The learning of differentiable decision trees can be combined with representation learning, e.g., to learn deep features in an end-to-end manner. We define a distributionbased loss function for forests, enabling all the trees to be learned jointly, and show that an update function for leaf node predictions, which guarantees a strict decrease of the loss function, can be derived by variational bounding. The effectiveness of the proposed LDLFs is verified on two LDL problems, including age estimation and crowd opinion prediction on movies, showing significant improvements to the state-of-the-art LDL methods.",
            "output": [
                "Label Distribution Learning Forests"
            ]
        },
        {
            "id": "task1540-817e8e0c6bcd455cb566244d77b13d2f",
            "input": "The paper investigates parameterized approximate message-passing schemes that are based on bounded inference and are inspired by Pearl’s belief propagation algorithm (BP). We start with the bounded inference mini-clustering algorithm and then move to the iterative scheme called Iterative Join-Graph Propagation (IJGP), that combines both iteration and bounded inference. Algorithm IJGP belongs to the class of Generalized Belief Propagation algorithms, a framework that allowed connections with approximate algorithms from statistical physics and is shown empirically to surpass the performance of mini-clustering and belief propagation, as well as a number of other stateof-the-art algorithms on several classes of networks. We also provide insight into the accuracy of iterative BP and IJGP by relating these algorithms to well known classes of constraint propagation schemes.",
            "output": [
                "Join-Graph Propagation Algorithms"
            ]
        },
        {
            "id": "task1540-ca92977a88164afeaf5655946ba8c47f",
            "input": "We present in this paper a study on the ability and the benefits of using a keystroke dynamics authentication method for collaborative systems. Authentication is a challenging issue in order to guarantee the security of use of collaborative systems during the access control step. Many solutions exist in the state of the art such as the use of one time passwords or smart-cards. We focus in this paper on biometric based solutions that do not necessitate any additional sensor. Keystroke dynamics is an interesting solution as it uses only the keyboard and is invisible for users. Many methods have been published in this field. We make a comparative study of many of them considering the operational constraints of use for collaborative systems.",
            "output": [
                "Keystroke Dynamics Authentication For Collaborative Systems"
            ]
        },
        {
            "id": "task1540-47ceb37194d3487283a48e2ee8889043",
            "input": "We introduce a globally-convergent algorithm for optimizing the tree-reweighted (TRW) variational objective over the marginal polytope. The algorithm is based on the conditional gradient method (Frank-Wolfe) and moves pseudomarginals within the marginal polytope through repeated maximum a posteriori (MAP) calls. This modular structure enables us to leverage black-box MAP solvers (both exact and approximate) for variational inference, and obtains more accurate results than tree-reweighted algorithms that optimize over the local consistency relaxation. Theoretically, we bound the sub-optimality for the proposed algorithm despite the TRW objective having unbounded gradients at the boundary of the marginal polytope. Empirically, we demonstrate the increased quality of results found by tightening the relaxation over the marginal polytope as well as the spanning tree polytope on synthetic and real-world instances.",
            "output": [
                "Barrier Frank-Wolfe for Marginal Inference"
            ]
        },
        {
            "id": "task1540-0e698b417518461d831267c5a900286d",
            "input": "As the type and the number of such venues increase, automated analysis of sentiment on textual resources has become an essential data mining task. In this paper, we investigate the problem of mining opinions on the collection of informal short texts. Both positive and negative sentiment strength of texts are detected. We focus on a non-English language that has few resources for text mining. This approach would help enhance the sentiment analysis in languages where a list of opinionated words does not exist. We propose a new method projects the text into dense and low dimensional feature vectors according to the sentiment strength of the words. We detect the mixture of positive and negative sentiments on a multi-variant scale. Empirical evaluation of the proposed framework on Turkish tweets shows that our approach gets good results for opinion mining.",
            "output": [
                "Opinion Mining on Non-English Short Text"
            ]
        },
        {
            "id": "task1540-71032cf9c2a74eea94853b52febe1a72",
            "input": "In daily communications, Arabs use local dialects which are hard to identify automatically using conventional classification methods. The dialect identification challenging task becomes more complicated when dealing with an under-resourced dialects belonging to a same county/region. In this paper, we start by analyzing statistically Algerian dialects in order to capture their specificities related to prosody information which are extracted at utterance level after a coarse-grained consonant/vowel segmentation. According to these analysis findings, we propose a Hierarchical classification approach for spoken Arabic algerian Dialect IDentification (HADID). It takes advantage from the fact that dialects have an inherent property of naturally structured into hierarchy. Within HADID, a top-down hierarchical classification is applied, in which we use Deep Neural Networks (DNNs) method to build a local classifier for every parent node into the hierarchy dialect structure. Our framework is implemented and evaluated on Algerian Arabic dialects corpus. Whereas, the hierarchy dialect structure is deduced from historic and linguistic knowledges. The results reveal that within HADID, the best classifier is DNNs compared to Support Vector Machine. In addition, compared with a baseline Flat classification system, our HADID gives an improvement of 63.5% in term of precision. Furthermore, overall results evidence the suitability of our prosody-based HADID for speaker independent dialect identification while requiring less than 6s test utterances. Email addresses: sm.bougrine@lagh-univ.dz (Soumia Bougrine), hadda_cherroun@mail.lagh-univ.dz (Hadda Cherroun), djelloul.ziadi@univ-rouen.fr (Djelloul Ziadi ) Preprint submitted to Elsevier March 30, 2017 ar X iv :1 70 3. 10 06 5v 1 [ cs .C L ] 2 9 M ar 2 01 7",
            "output": [
                "Hierarchical Classification for Spoken Arabic Dialect Identification using Prosody: Case of Algerian Dialects"
            ]
        },
        {
            "id": "task1540-0077571cd27348fea97ed5ea26743058",
            "input": "Recurrent Neural Networks (RNNs), and specifically a variant with Long ShortTerm Memory (LSTM), are enjoying renewed interest as a result of successful applications in a wide range of machine learning problems that involve sequential data. However, while LSTMs provide exceptional results in practice, the source of their performance and their limitations remain rather poorly understood. Using character-level language models as an interpretable testbed, we aim to bridge this gap by providing a comprehensive analysis of their representations, predictions and error types. In particular, our experiments reveal the existence of interpretable cells that keep track of long-range dependencies such as line lengths, quotes and brackets. Moreover, an extensive analysis with finite horizon n-gram models suggest that these dependencies are actively discovered and utilized by the networks. Finally, we provide detailed error analysis that suggests areas for further study.",
            "output": [
                "Visualizing and Understanding Recurrent Networks"
            ]
        },
        {
            "id": "task1540-e28b82ab8a82461eb532cf659452ad88",
            "input": "We consider the Bayesian active learning and experimental design problem, where the goal is to learn the value of some unknown target variable through a sequence of informative, noisy tests. In contrast to prior work, we focus on the challenging, yet practically relevant setting where test outcomes can be conditionally dependent given the hidden target variable. Under such assumptions, common heuristics, such as greedily performing tests that maximize the reduction in uncertainty of the target, often perform poorly. In this paper, we propose ECED, a novel, computationally efficient active learning algorithm, and prove strong theoretical guarantees that hold with correlated, noisy tests. Rather than directly optimizing the prediction error, at each step, ECED picks the test that maximizes the gain in a surrogate objective, which takes into account the dependencies between tests. Our analysis relies on an information-theoretic auxiliary function to track the progress of ECED, and utilizes adaptive submodularity to attain the near-optimal bound. We demonstrate strong empirical performance of ECED on two problem instances, including a Bayesian experimental design task intended to distinguish among economic theories of how people make risky decisions, and an active preference learning task via pairwise comparisons.",
            "output": [
                "Near-optimal Bayesian Active Learning with Correlated and Noisy Tests"
            ]
        },
        {
            "id": "task1540-ff956737d80642918b70c4702e1bdaa8",
            "input": "Recurrent neural networks (RNN) are capable of learning to encode and exploit activation history over an arbitrary timescale. However, in practice, state of the art gradient descent based training methods are known to suffer from difficulties in learning long term dependencies. Here, we describe a novel training method that involves concurrent parallel cloned networks, each sharing the same weights, each trained at different stimulus phase and each maintaining independent activation histories. Training proceeds by recursively performing batch-updates over the parallel clones as activation history is progressively increased. This allows conflicts to propagate hierarchically from short-term contexts towards longer-term contexts until they are resolved. We illustrate the parallel clones method and hierarchical conflict propagation with a character-level deep RNN tasked with memorizing a paragraph of Moby Dick (by Herman Melville).",
            "output": [
                "Hierarchical Conflict Propagation: Sequence Learning in a Recurrent Deep Neural Network"
            ]
        },
        {
            "id": "task1540-86f531c4de1247e0a6b8f2aa5481d28a",
            "input": "Reservoir computing is a new, powerful and flexible machine learning technique that is easily implemented in hardware. Recently, by using a time-multiplexed architecture, hardware reservoir computers have reached performance comparable to digital implementations. Operating speeds allowing for real time information operation have been reached using optoelectronic systems. At present the main performance bottleneck is the readout layer which uses slow, digital postprocessing. We have designed an analog readout suitable for time-multiplexed optoelectronic reservoir computers, capable of working in real time. The readout has been built and tested experimentally on a standard benchmark task. Its performance is better than non-reservoir methods, with ample room for further improvement. The present work thereby overcomes one of the major limitations for the future development of hardware reservoir computers.",
            "output": [
                "Analog readout for optical reservoir computers"
            ]
        },
        {
            "id": "task1540-954e3d96f0d34169bf3b71ed779fc867",
            "input": "Here we describe work on learning the subcategories of verbs in a morphologically rich language using only minimal linguistic resources. Our goal is to learn verb subcategorizations for Quechua, an under-resourced morphologically rich language, from an unannotated corpus. We compare results from applying this approach to an unannotated Arabic corpus with those achieved by processing the same text in treebank form. The original plan was to use only a morphological analyzer and an unannotated corpus, but experiments suggest that this approach by itself will not be effective for learning the combinatorial potential of Arabic verbs in general. The lower bound on resources for acquiring this information is somewhat higher, apparently requiring a a part-of-speech tagger and chunker for most languages, and a morphological disambiguater for Arabic.",
            "output": [
                "Considering a resource-light approach to learning verb valencies"
            ]
        },
        {
            "id": "task1540-590402a5451e4006905e5523df69fa3f",
            "input": "Electronic health records (EHRs) contain important clinical information about patients. Efficient and effective use of this information could supplement or even replace manual chart review as a means of studying and improving the quality and safety of healthcare delivery. However, some of these clinical data are in the form of free text and require pre-processing before use in automated systems. A common free text data source is radiology reports, typically dictated by radiologists to explain their interpretations. We sought to demonstrate machine learning classification of computed tomography (CT) imaging reports into binary outcomes, i.e. positive and negative for fracture, using regular text classification and classifiers based on topic modeling. Topic modeling provides interpretable themes (topic distributions) in reports, a representation that is more compact than the commonly used bag-of-words representation and can be processed faster than raw text in subsequent automated processes. We demonstrate new classifiers based on this topic modeling representation of the reports. Aggregate topic classifier (ATC) and confidence-based topic classifier (CTC) use a single topic that is determined from the training dataset based on different measures to classify the reports on the test dataset. Alternatively, similarity-based topic classifier (STC) measures the similarity between the reports’ topic distributions to determine the predicted class. Our proposed topic modeling-based classifier systems are shown to be competitive with existing text classification techniques and provides an efficient and interpretable representation.",
            "output": [
                "Topic Modeling for Classification of Clinical Reports"
            ]
        },
        {
            "id": "task1540-40859a933c954811a97c885cc0966ae8",
            "input": "Network data mining has become an important area of study due to the large number of problems it can be applied to. This paper presents NOESIS, an open source framework for network data mining that provides a large collection of network analysis techniques, including the analysis of network structural properties, community detection methods, link scoring, and link prediction, as well as network visualization algorithms. It also features a complete stand–alone graphical user interface that facilitates the use of all these techniques. The NOESIS framework has been designed using solid object–oriented design principles and structured parallel programming. As a lightweight library with minimal external dependencies and a permissive software license, NOESIS can be incorporated into other software projects. Released under a BSD license, it is available from http://noesis.ikor.org.",
            "output": [
                "The NOESIS Network-Oriented Exploration, Simulation, and Induction System"
            ]
        },
        {
            "id": "task1540-07f4642ac9994035a2e17fb66407011c",
            "input": "Word embedding, specially with its recent developments, promises a quantification of the similarity between terms. However, it is not clear to which extent this similarity value can be genuinely meaningful and useful for subsequent tasks. We explore how the similarity score obtained from the models is really indicative of term relatedness. We first observe and quantify the uncertainty factor of the word embedding models regarding to the similarity value. Based on this factor, we introduce a general threshold on various dimensions which effectively filters the highly related terms. Our evaluation on four information retrieval collections supports the effectiveness of our approach as the results of the introduced threshold are significantly better than the baseline while being equal to or statistically indistinguishable from the optimal results.",
            "output": [
                "Uncertainty in Neural Network Word Embedding Exploration of Threshold for Similarity"
            ]
        },
        {
            "id": "task1540-ff559614e1544daaa9f4922971ca8393",
            "input": "Here we study the problem of predicting labels for large text corpora where each text can be assigned multiple labels. The problem might seem trivial when the number of labels is small, and can be easily solved using a series of one-vsall classifiers. However, as the number of labels increases to several thousand, the parameter space becomes extremely large, and it is no longer possible to use the one-vs-all technique. Here we propose a model based on the factorization of higher order word vector moments, as well as the cross moments between the labels and the words for multi-label prediction. Our model provides guaranteed converge bounds on the extracted parameters. Further, our model takes only three passes through the training dataset to extract the parameters, resulting in a highly scalable algorithm that can train on GB’s of data consisting of millions of documents with hundreds of thousands of labels using a nominal resource of a single processor with 16GB RAM. Our model achieves 10x-15x order of speed-up on large-scale datasets while producing competitive performance in comparison with existing benchmark algorithms.",
            "output": [
                "Large-Scale Label Prediction for Sparse Data with Probable Guarantees"
            ]
        },
        {
            "id": "task1540-a2649f61c6a84315a858028a45f50d8c",
            "input": "We present a practical and statistically consistent scheme for actively learning binary classifiers under general loss functions. Our algorithm uses importance weighting to correct sampling bias, and by controlling the variance, we are able to give rigorous label complexity bounds for the learning process. Experiments on passively labeled data show that this approach reduces the label complexity required to achieve good predictive performance on many learning problems.",
            "output": [
                "Importance Weighted Active Learning"
            ]
        },
        {
            "id": "task1540-bb33a5a9bdab437faebb8b154991e54b",
            "input": "This paper addresses the issue of model selection for hidden Markov models (HMMs). We generalize factorized asymptotic Bayesian inference (FAB), which has been recently developed for model selection on independent hidden variables (i.e., mixture models), for time-dependent hidden variables. As with FAB in mixture models, FAB for HMMs is derived as an iterative lower bound maximization algorithm of a factorized information criterion (FIC). It inherits, from FAB for mixture models, several desirable properties for learning HMMs, such as asymptotic consistency of FIC with marginal log-likelihood, a shrinkage effect for hidden state selection, monotonic increase of the lower FIC bound through the iterative optimization. Further, it does not have a tunable hyper-parameter, and thus its model selection process can be fully automated. Experimental results shows that FAB outperforms states-of-the-art variational Bayesian HMM and non-parametric Bayesian HMM in terms of model selection accuracy and computational efficiency.",
            "output": [
                "Factorized Asymptotic Bayesian Hidden Markov Models"
            ]
        },
        {
            "id": "task1540-4423cbc8801944b7b4f67a457da19f76",
            "input": "The strength with which a statement is made can have a significant impact on the audience. For example, international relations can be strained by how the media in one country describes an event in another; and papers can be rejected because they overstate or understate their findings. It is thus important to understand the effects of statement strength. A first step is to be able to distinguish between strong and weak statements. However, even this problem is understudied, partly due to a lack of data. Since strength is inherently relative, revisions of texts that make claims are a natural source of data on strength differences. In this paper, we introduce a corpus of sentence-level revisions from academic writing. We also describe insights gained from our annotation efforts for this task.",
            "output": [
                "A Corpus of Sentence-level Revisions in Academic Writing: A Step towards Understanding Statement Strength in Communication"
            ]
        },
        {
            "id": "task1540-0217b9cf17244b5e82814343e4871aee",
            "input": "Regularization is a well studied problem in the context of neural networks. It is usually used to improve the generalization performance when the number of input samples is relatively small or heavily contaminated with noise. The regularization of a parametric model can be achieved in different manners some of which are early stopping (Morgan and Bourlard, 1990), weight decay, output smoothing that are used to avoid overfitting during the training of the considered model. From a Bayesian point of view, many regularization techniques correspond to imposing certain prior distributions on model parameters (Krogh and Hertz, 1991). Using Bishop’s approximation (Bishop, 1995) of the objective function when a restricted type of noise is added to the input of a parametric function, we derive the higher order terms of the Taylor expansion and analyze the coefficients of the regularization terms induced by the noisy input. In particular we study the effect of penalizing the Hessian of the mapping function with respect to the input in terms of generalization performance. We also show how we can control independently this coefficient by explicitly penalizing the Jacobian of the mapping function on corrupted inputs.",
            "output": [
                "Adding noise to the input of a model trained with a regularized objective"
            ]
        },
        {
            "id": "task1540-d0e7da6a49404cf2913eee43b43a2991",
            "input": "Despite interest in using cross-lingual knowledge to learn word embeddings for various tasks, a systematic comparison of the possible approaches is lacking in the literature. We perform an extensive evaluation of four popular approaches of inducing cross-lingual embeddings, each requiring a different form of supervision, on four typographically different language pairs. Our evaluation setup spans four different tasks, including intrinsic evaluation on mono-lingual and cross-lingual similarity, and extrinsic evaluation on downstream semantic and syntactic applications. We show that models which require expensive cross-lingual knowledge almost always perform better, but cheaply supervised models often prove competitive on certain tasks.",
            "output": [
                "Cross-lingual Models of Word Embeddings: An Empirical Comparison"
            ]
        },
        {
            "id": "task1540-83ca1e4afe2545d6bc713472a406a9d1",
            "input": "Deep learning (DL) became the method of choice in recent years for solving problems ranging from object recognition and speech recognition to robotic perception and human disease prediction. In this paper, we present a hybrid architecture of convolutional neural networks (CNN) and stacked autoencoders (SAE) to learn a sequence of actions that nonlinearly transforms an input shape or distribution into a target shape or distribution with the same support. While such a framework can be useful in a variety of problems such as robotic path planning, sequential decision-making in games and identifying material processing pathways to achieve desired microstructures, this paper focuses on controlling fluid deformations in a microfluidic channel by deliberately placing a sequence of pillars, which has a significant impact on manufacturing for biomedical and textile applications where highly targeted shapes are desired. We propose an architecture which simultaneously predicts the intermediate shape lying in the nonlinear transformation pathway between the undeformed and desired flow shape, then learns the causal action–the single pillar which results in the deformation of the flow–one at a time. The learning of stage-wise transformations provides deep insights into the physical flow deformation. Results show that under the current framework, our model is able to predict a sequence of pillars that reconstructs the flow shape which highly resembles the desired shape.",
            "output": [
                "Deep Action Sequence Learning for Causal Shape Transformation"
            ]
        },
        {
            "id": "task1540-048bea121ec146a08b67d243827f6553",
            "input": "The production of color language is essential for grounded language generation. Color descriptions have many challenging properties: they can be vague, compositionally complex, and denotationally rich. We present an effective approach to generating color descriptions using recurrent neural networks and a Fouriertransformed color representation. Our model outperforms previous work on a conditional language modeling task over a large corpus of naturalistic color descriptions. In addition, probing the model’s output reveals that it can accurately produce not only basic color terms but also descriptors with non-convex denotations (“greenish”), bare modifiers (“bright”, “dull”), and compositional phrases (“faded teal”) not seen in training.",
            "output": [
                "Learning to Generate Compositional Color Descriptions"
            ]
        },
        {
            "id": "task1540-2ba5c87d4df7409aa954e1753b276a91",
            "input": "Domain-independent planning is one of the foundational areas in the field of Artificial Intelligence. A description of a planning task consists of an initial world state, a goal, and a set of actions for modifying the world state. The objective is to find a sequence of actions, that is, a plan, that transforms the initial world state into a goal state. In optimal planning, we are interested in finding not just a plan, but one of the cheapest plans. A prominent approach to optimal planning these days is heuristic state-space search, guided by admissible heuristic functions. Numerous admissible heuristics have been developed, each with its own strengths and weaknesses, and it is well known that there is no single “best” heuristic for optimal planning in general. Thus, which heuristic to choose for a given planning task is a difficult question. This difficulty can be avoided by combining several heuristics, but that requires computing numerous heuristic estimates at each state, and the tradeoff between the time spent doing so and the time saved by the combined advantages of the different heuristics might be high. We present a novel method that reduces the cost of combining admissible heuristics for optimal planning, while maintaining its benefits. Using an idealized search space model, we formulate a decision rule for choosing the best heuristic to compute at each state. We then present an active online learning approach for learning a classifier with that decision rule as the target concept, and employ the learned classifier to decide which heuristic to compute at each state. We evaluate this technique empirically, and show that it substantially outperforms the standard method for combining several heuristics via their pointwise maximum.",
            "output": [
                "Online Speedup Learning for Optimal Planning"
            ]
        },
        {
            "id": "task1540-a70af20310434c3a952549eed856845c",
            "input": "There is a small but growing body of research on statistical scripts, models of event sequences that allow probabilistic inference of implicit events from documents. These systems operate on structured verb-argument events produced by an NLP pipeline. We compare these systems with recent Recurrent Neural Net models that directly operate on raw tokens to predict sentences, finding the latter to be roughly comparable to the former in terms of predicting missing events in documents.",
            "output": [
                "Using Sentence-Level LSTM Language Models for Script Inference"
            ]
        },
        {
            "id": "task1540-22ec4146db414757a40524b5d0906f73",
            "input": "We introduce a novel training principle for generative probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework generalizes Denoising Auto-Encoders (DAE) and is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution is a conditional distribution that generally involves a small move, so it has fewer dominant modes and is unimodal in the limit of small moves. This simplifies the learning problem, making it less like density estimation and more akin to supervised function approximation, with gradients that can be obtained by backprop. The theorems provided here provide a probabilistic interpretation for denoising autoencoders and generalize them; seen in the context of this framework, auto-encoders that learn with injected noise are a special case of GSNs and can be interpreted as generative models. The theorems also provide an interesting justification for dependency networks and generalized pseudolikelihood and define an appropriate joint distribution and sampling mechanism, even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. Experiments validating these theoretical results are conducted on both synthetic datasets and image datasets. The experiments employ a particular architecture that mimics the Deep Boltzmann Machine Gibbs sampler but that allows training to proceed with backprop through a recurrent neural network with noise injected inside and without the need for layerwise pretraining.",
            "output": [
                "GSNs: Generative Stochastic Networks"
            ]
        },
        {
            "id": "task1540-3bcc8177aee843688034dcfaeb66c082",
            "input": "In this thesis we present a new algorithm for the Vehicle Routing Problem called the Enhanced Bees Algorithm. It is adapted from a fairly recent algorithm, the Bees Algorithm, which was developed for continuous optimisation problems. We show that the results obtained by the Enhanced Bees Algorithm are competitive with the best meta-heuristics available for the Vehicle Routing Problem—it is able to achieve results that are within 0.5% of the optimal solution on a commonly used set of test instances. We show that the algorithm has good runtime performance, producing results within 2% of the optimal solution within 60 seconds, making it suitable for use within real world dispatch scenarios. Additionally, we provide a short history of well known results from the literature along with a detailed description of the foundational methods developed to solve the Vehicle Routing Problem.",
            "output": [
                "The Bees Algorithm for the Vehicle Routing Problem"
            ]
        },
        {
            "id": "task1540-42a3a536d0f047c3bc608afc14574f82",
            "input": "We analyze in this paper a random feature map based on a theory of invariance (I-theory) introduced in [1]. More specifically, a group invariant signal signature is obtained through cumulative distributions of group transformed random projections. Our analysis bridges invariant feature learning with kernel methods, as we show that this feature map defines an expected Haar integration kernel that is invariant to the specified group action. We show how this non-linear random feature map approximates this group invariant kernel uniformly on a set of N points. Moreover, we show that it defines a function space that is dense in the equivalent Invariant Reproducing Kernel Hilbert Space. Finally, we quantify error rates of the convergence of the empirical risk minimization, as well as the reduction in the sample complexity of a learning algorithm using such an invariant representation for signal classification, in a classical supervised learning setting.",
            "output": [
                "Learning with Group Invariant Features: A Kernel Perspective"
            ]
        },
        {
            "id": "task1540-61c58adfd20f46188bf102d410acc148",
            "input": "The parameters of temporal models, such as dynamic Bayesian networks, may be modelled in a Bayesian context as static or atemporal variables that influence transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the observation sequence. Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik’s filter and a Kalman filter in parameter space and establish more general conditions under which Storvik’s filter works. Drawing on an analogy to the extended Kalman filter, we develop and analyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik’s method to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods.",
            "output": [
                "The Extended Parameter Filter"
            ]
        },
        {
            "id": "task1540-573fdcbdc0eb46de90714b3083c43c27",
            "input": "Many real systems have been modelled in terms of network concepts, and written texts are a particular example of information networks. In recent years, the use of network methods to analyze language has allowed the discovery of several interesting findings, including the proposition of novel models to explain the emergence of fundamental universal patterns. While syntactical networks, one of the most prevalent networked models of written texts, display both scale-free and small-world properties, such representation fails in capturing other textual features, such as the organization in topics or subjects. In this context, we propose a novel network representation whose main purpose is to capture the semantical relationships of words in a simple way. To do so, we link all words co-occurring in the same semantic context, which is defined in a threefold way. We show that the proposed representations favours the emergence of communities of semantically related words, and this feature may be used to identify relevant topics. The proposed methodology to detect topics was applied to segment selected Wikipedia articles. We have found that, in general, our methods outperform traditional bag-of-words representations, which suggests that a high-level textual representation may be useful to study semantical features of texts.",
            "output": [
                "Topic segmentation via community detection in complex networks"
            ]
        },
        {
            "id": "task1540-a18c37fa24424be5acf4c5e9a8f1bced",
            "input": "In machine learning contests such as the ImageNet Large Scale Visual Recognition Challenge [RDS15] and the KDD Cup, contestants can submit candidate solutions and receive from an oracle (typically the organizers of the competition) the accuracy of their guesses compared to the ground-truth labels. One of the most commonly used accuracy metrics for binary classification tasks is the Area Under the Receiver Operating Characteristics Curve (AUC). In this paper we provide proofs-of-concept of how knowledge of the AUC of a set of guesses can be used, in two different kinds of attacks, to improve the accuracy of those guesses. On the other hand, we also demonstrate the intractability of one kind of AUC exploit by proving that the number of possible binary labelings of n examples for which a candidate solution obtains a AUC score of c grows exponentially in n, for every c ∈ (0, 1).",
            "output": [
                "Exploiting an Oracle that Reports AUC Scores in Machine Learning Contests"
            ]
        },
        {
            "id": "task1540-234979f81bda430faa7d5d05f315cdb2",
            "input": "We explore techniques to maximize the effectiveness of discourse information in the task of authorship attribution. We present a novel method to embed discourse features in a Convolutional Neural Network text classifier, which achieves a state-ofthe-art result by a substantial margin. We empirically investigate several featurization methods to understand the conditions under which discourse features contribute non-trivial performance gains, and analyze discourse embeddings.",
            "output": [
                "Leveraging Discourse Information Effectively for Authorship Attribution∗"
            ]
        },
        {
            "id": "task1540-0142949520cd4d778a5c322acbf78da6",
            "input": "Preferences play an important role in our everyday lives. CP-networks, or CP-nets in short, are graphical models for representing conditional qualitative preferences under ceteris paribus (“all else being equal”) assumptions. Despite their intuitive nature and rich representation, dominance testing with CP-nets is computationally complex, even when the CP-nets are restricted to binary-valued preferences. Tractable algorithms exist for binary CP-nets, but these algorithms are incomplete for multi-valued CPnets. In this paper, we identify a class of multivalued CP-nets, which we call more-or-less CPnets, that have the same computational complexity as binary CP-nets. More-or-less CP-nets exploit the monotonicity of the attribute values and use intervals to aggregate values that induce similar preferences. We then present a search control rule for dominance testing that effectively prunes the search space while preserving completeness.",
            "output": [
                "More-or-Less CP-Networks"
            ]
        },
        {
            "id": "task1540-ce1cd846ebea4e8b836fcc18af1b683f",
            "input": "We evaluate Machine Learning techniques for Green energy (wind, solar and biomass) prediction based on weather forecasts. Weather is constituted by multiple attributes: temperature, cloud cover, wind speed / direction which are discrete random variables. One of our objectives is to predict the weather based on the previous weather data. Additionally we are interested in finding correlation (dependencies in order to reduce the dimensionality of the data set) between these variables, predicting missing data predict deviations in weather forecasts (for job scheduling within the green control center), finding clusters within the data (constituted by closely related variables e.g. PCA that can be used to remove redundant variables), classification, finding (non-linear using SVMs) regression models, training artificial neural networks based on the historical data so that they can be used for prediction in the future.",
            "output": [
                "Evaluation of Machine Learning Techniques for Green Energy Prediction"
            ]
        },
        {
            "id": "task1540-f703ef80d25e4d8fbbcc76c6d2724a0e",
            "input": "We introduce a novel framework for evaluating multimodal deep learning models with respect to their language understanding and generalization abilities. In this approach, artificial data is automatically generated according to the experimenter’s specifications. The content of the data, both during training and evaluation, can be controlled in detail, which enables tasks to be created that require true generalization abilities, in particular the combination of previously introduced concepts in novel ways. We demonstrate the potential of our methodology by evaluating various visual question answering models on four different tasks, and show how our framework gives us detailed insights into their capabilities and limitations. By opensourcing our framework, we hope to stimulate progress in the field of multimodal language understanding.",
            "output": [
                "SHAPEWORLD: A new test methodology for multimodal language understanding"
            ]
        },
        {
            "id": "task1540-db0ee3c237334f0ca561e73507aba62a",
            "input": "Particle Filter (PF) is the most widely used Bayesian sequential estimation method for obtaining hidden states of nonlinear dynamic systems. However, it still suffers from certain problems such as the loss of particle diversity, the need for large number of particles, and the costly selection of the importance density functions. In this paper, a novel PF called Exponential Natural Particle Filter (xNPF) is introduced to solve the above problems. In this approach, a state transitional probability with the use of natural gradient learning is proposed which balances exploration and exploitation more robustly. PF with the proposed density function does not need a large number of particles and it retains particles’ diversity in a course of run. The proposed system is evaluated in a time-varying parameter estimation problem on a dynamic model of HIV virus immune response. This model is used to show the performance of the xNPF in comparison with several state of the art particle filter variants such as Annealed PF, Bootstrap PF, iterative PF, equivalent weight PF, and intelligent PF. The results show that xNPF converges much closer to the true target states than the other methods.",
            "output": [
                "Exponential Natural Particle Filter"
            ]
        },
        {
            "id": "task1540-1a04dc91a4fd4c0d8db35e356ab50c4c",
            "input": "We introduce the nonparametric metadata dependent relational (NMDR) model, a Bayesian nonparametric stochastic block model for network data. The NMDR allows the entities associated with each node to have mixed membership in an unbounded collection of latent communities. Learned regression models allow these memberships to depend on, and be predicted from, arbitrary node metadata. We develop efficient MCMC algorithms for learning NMDR models from partially observed node relationships. Retrospective MCMC methods allow our sampler to work directly with the infinite stickbreaking representation of the NMDR, avoiding the need for finite truncations. Our results demonstrate recovery of useful latent communities from real-world social and ecological networks, and the usefulness of metadata in link prediction tasks.",
            "output": [
                "The Nonparametric Metadata Dependent Relational Model"
            ]
        },
        {
            "id": "task1540-050d0e73a6074828b00059204a73e795",
            "input": "We consider the problem of online learning in misspecified linear stochastic multi-armed bandit problems. Regret guarantees for state-of-the-art linear bandit algorithms such as Optimism in the Face of Uncertainty Linear bandit (OFUL) hold under the assumption that the arms expected rewards are perfectly linear in their features. It is, however, of interest to investigate the impact of potential misspecification in linear bandit models, where the expected rewards are perturbed away from the linear subspace determined by the arms features. Although OFUL has recently been shown to be robust to relatively small deviations from linearity, we show that any linear bandit algorithm that enjoys optimal regret performance in the perfectly linear setting (e.g., OFUL) must suffer linear regret under a sparse additive perturbation of the linear model. In an attempt to overcome this negative result, we define a natural class of bandit models characterized by a non-sparse deviation from linearity. We argue that the OFUL algorithm can fail to achieve sublinear regret even under models that have non-sparse deviation. We finally develop a novel bandit algorithm, comprising a hypothesis test for linearity followed by a decision to use either the OFUL or Upper Confidence Bound (UCB) algorithm. For perfectly linear bandit models, the algorithm provably exhibits OFULs favorable regret performance, while for misspecified models satisfying the non-sparse deviation property, the algorithm avoids the linear regret phenomenon and falls back on UCBs sublinear regret scaling. Numerical experiments on synthetic data, and on recommendation data from the public Yahoo! Learning to Rank Challenge dataset, empirically support our findings.",
            "output": [
                "Misspecified Linear Bandits"
            ]
        },
        {
            "id": "task1540-454ab2120f3a49f7bca6b28301768046",
            "input": "We consider the problem of accurately recovering a matrix B of size M ×M , which represents a probability distribution overM outcomes, given access to an observed matrix of “counts” generated by taking independent samples from the distribution B. How can structural properties of the underlying matrix B be leveraged to yield computationally efficient and information theoretically optimal reconstruction algorithms? When can accurate reconstruction be accomplished in the sparse data regime? This basic problem lies at the core of a number of questions that are currently being considered by different communities, including community detection in sparse random graphs, learning structured models such as topic models or hidden Markov models, and the efforts from the natural language processing community to compute “word embeddings”. Many aspects of this problem—both in terms of learning and property testing/estimation and on both the algorithmic and information theoretic sides—remain open. Our results apply to the setting where B has a particular rank 2 structure. For this setting, we propose an efficient (and practically viable) algorithm that accurately recovers the underlying M × M matrix using Θ(M) samples. This result easily translates to Θ(M) sample algorithms for learning topic models with two topics over dictionaries of size M , and learning hidden Markov Models with two hidden states and observation distributions supported on M elements. These linear sample complexities are optimal, up to constant factors, in an extremely strong sense: even testing basic properties of the underlying matrix (such as whether it has rank 1 or 2) requires Ω(M) samples. Furthermore, we provide an even stronger lower bound where distinguishing whether a sequence of observations were drawn from the uniform distribution over M observations versus being generated by an HMM with two hidden states requires Ω(M) observations. This precludes sublinear-sample hypothesis tests for basic properties, such as identity or uniformity, as well as sublinear sample estimators for quantities such as the entropy rate of HMMs. This impossibility of sublinear-sample property testing in these settings is intriguing and underscores the significant differences between these structured settings and the standard setting of drawing i.i.d samples from an unstructured distribution of support size M . ∗MIT. Email: qqh@mit.edu. †University of Washington. Email: sham@cs.washington.edu ‡Stanford University. Email: kweihao@gmail.com §Stanford University. Email: valiant@stanford.edu. Gregory and Weihao’s contributions were supported by NSF CAREER Award CCF-1351108, and a research grant from the Okawa Foundation. ar X iv :1 60 2. 06 58 6v 1 [ cs .L G ] 2 1 Fe b 20 16",
            "output": [
                "Recovering Structured Probability Matrices"
            ]
        },
        {
            "id": "task1540-abd53d25b82d482489aee8d5379e7f15",
            "input": "We aim to shed light on the strengths and weaknesses of the newly introduced neural machine translation paradigm. To that end, we conduct a multifaceted evaluation in which we compare outputs produced by state-of-the-art neural machine translation and phrase-based machine translation systems for 9 language directions across a number of dimensions. Specifically, we measure the similarity of the outputs, their fluency and amount of reordering, the effect of sentence length and performance across different error categories. We find out that translations produced by neural machine translation systems are considerably different, more fluent and more accurate in terms of word order compared to those produced by phrase-based systems. Neural machine translation systems are also more accurate at producing inflected forms, but they perform poorly when translating very long sentences.",
            "output": [
                "A Multifaceted Evaluation of Neural versus Phrase-Based Machine Translation for 9 Language Directions"
            ]
        },
        {
            "id": "task1540-d9c18c785be04435b4f7bb99357c1803",
            "input": "We present a character-level recurrent neural network that generates relevant and coherent text given auxiliary information such as a sentiment or topic. Using a simple input replication strategy, we preserve the signal of auxiliary input across wider sequence intervals than can feasibly be trained by back-propagation through time. Our main results center on a large corpus of 1.5 million beer reviews from BeerAdvocate. In generative mode, our network produces reviews on command, tailored to a star rating or item category. The generative model can also run in reverse, performing classification with surprising accuracy. Performance of the reverse model provides a straightforward way to determine what the generative model knows without relying too heavily on subjective analysis. Given a review, the model can accurately determine the corresponding rating and infer the beer’s category (IPA, Stout, etc.). We exploit this capability, tracking perceived sentiment and class membership as each character in a review is processed. Quantitative and qualitative empirical evaluations demonstrate that the model captures meaning and learns nonlinear dynamics in text, such as the effect of negation on sentiment, despite possessing no a priori notion of words. Because the model operates at the character level, it handles misspellings, slang, and large vocabularies without any machinery explicitly dedicated to the purpose.",
            "output": [
                "CHARACTER-LEVEL GENERATIVE TEXT MODELS"
            ]
        },
        {
            "id": "task1540-7856a6f5bbd047fb8f313f51f959dd04",
            "input": "This paper summarizes the recent progress we have made for the computer vision technologies in physical therapy with the accessible and affordable devices. We first introduce the remote health coaching system we build with Microsoft Kinect. Since the motion data captured by Kinect is noisy, we investigate the data accuracy of Kinect with respect to the high accuracy motion capture system. We also propose an outlier data removal algorithm based on the data distribution. In order to generate the kinematic parameter from the noisy data captured by Kinect, we propose a kinematic filtering algorithm based on Unscented Kalman Filter and the kinematic model of human skeleton. The proposed algorithm can obtain smooth kinematic parameter with reduced noise compared to the kinematic parameter generated from the raw motion data from Kinect.",
            "output": [
                "Remote Health Coaching System and Human Motion Data Analysis for Physical Therapy with Microsoft Kinect"
            ]
        },
        {
            "id": "task1540-ce32f8118e2348948e92c736e072426a",
            "input": "Many combinatorial problems arising in machine learning can be reduced to the problem of minimizing a submodular function. Submodular functions are a natural discrete analog of convex functions, and can be minimized in strongly polynomial time. Unfortunately, state-of-the-art algorithms for general submodular minimization are intractable for larger problems. In this paper, we introduce a novel subclass of submodular minimization problems that we call decomposable. Decomposable submodular functions are those that can be represented as sums of concave functions applied to modular functions. We develop an algorithm, SLG, that can efficiently minimize decomposable submodular functions with tens of thousands of variables. Our algorithm exploits recent results in smoothed convex minimization. We apply SLG to synthetic benchmarks and a joint classification-and-segmentation task, and show that it outperforms the state-of-the-art general purpose submodular minimization algorithms by several orders of magnitude.",
            "output": [
                "Efficient Minimization of Decomposable Submodular Functions"
            ]
        },
        {
            "id": "task1540-b04a1c8f83554fcf94253d85f57a3c2a",
            "input": "This work introduces a method to tune a sequence-based generative model for molecular de novo design that through augmented episodic likelihood can learn to generate structures with certain specified desirable properties. We demonstrate how this model can execute a range of tasks such as generating analogues to a query structure and generating compounds predicted to be active against a biological target. As a proof of principle, the model is first trained to generate molecules that do not contain sulphur. As a second example, the model is trained to generate analogues to the drug Celecoxib, a technique that could be used for scaffold hopping or library expansion starting from a single molecule. Finally, when tuning the model towards generating compounds predicted to be active against the dopamine receptor D2, the model generates structures of which more than 95% are predicted to be active, including experimentally confirmed actives that have not been included in either the generative model nor the activity prediction model.",
            "output": [
                "Molecular De-Novo Design through Deep Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-c5077e7ff76840b1a784fc40a1eaa541",
            "input": "Existing studies on semantic parsing mainly focus on the in-domain setting. We formulate cross-domain semantic parsing as a domain adaptation problem: train a semantic parser on some source domains and then adapt it to the target domain. Due to the diversity of logical forms in different domains, this problem presents unique and intriguing challenges. By converting logical forms into canonical utterances in natural language, we reduce semantic parsing to paraphrasing, and develop an attentive sequence-to-sequence paraphrase model that is general and flexible to adapt to different domains. We discover two problems, small micro variance and large macro variance, of pretrained word embeddings that hinder their direct use in neural networks, and propose standardization techniques as a remedy. On the popular OVERNIGHT dataset, which contains eight domains, we show that both cross-domain training and standardized pre-trained word embedding can bring significant improvement.",
            "output": [
                "Cross-domain Semantic Parsing via Paraphrasing"
            ]
        },
        {
            "id": "task1540-7a2ed44e65f24e0cb791bfabe7dcac32",
            "input": "In this paper, we present nmtpy, a flexible Python toolkit based on Theano for training Neural Machine Translation and other neural sequence-to-sequence architectures. nmtpy decouples the specification of a network from the training and inference utilities to simplify the addition of a new architecture and reduce the amount of boilerplate code to be written. nmtpy has been used for LIUM’s topranked submissions to WMT Multimodal Machine Translation and News Translation tasks in 2016 and 2017. 1 OVERVIEW nmtpy is a refactored, extended and Python 3 only version of dl4mt-tutorial 1, a Theano (Theano Development Team, 2016) implementation of attentive Neural Machine Translation (NMT) (Bahdanau et al., 2014). The development of nmtpy project which has been open-sourced2 under MIT license in March 2017, started in March 2016 as an effort to adapt dl4mt-tutorial to multimodal translation models. nmtpy has now become a powerful toolkit where adding a new model is as simple as deriving from an abstract base class to fill in a set of fundamental methods and (optionally) implementing a custom data iterator. The training and inference utilities are as model-agnostic as possible allowing one to use them for different sequence generation networks such as multimodal NMT and image captioning to name a few. This flexibility and the rich set of provided architectures (Section 3) is what differentiates nmtpy from Nematus (Sennrich et al., 2017) another NMT software derived from dl4mt-tutorial.",
            "output": [
                "NMTPY: A FLEXIBLE TOOLKIT FOR ADVANCED NEURAL MACHINE TRANSLATION SYSTEMS"
            ]
        },
        {
            "id": "task1540-154e1c81d49e4e988c79d4f598488107",
            "input": "In this paper we address the problem of estimating the ratio q p where p is a density function and q is another density, or, more generally an arbitrary function. Knowing or approximating this ratio is needed in various problems of inference and integration, in particular, when one needs to average a function with respect to one probability distribution, given a sample from another. It is often referred as importance sampling in statistical inference and is also closely related to the problem of covariate shift in transfer learning as well as to various MCMC methods. It may also be useful for separating the underlying geometry of a space, say a manifold, from the density function defined on it. Our approach is based on reformulating the problem of estimating q p as an inverse problem in terms of an integral operator corresponding to a kernel, and thus reducing it to an integral equation, known as the Fredholm problem of the first kind. This formulation, combined with the techniques of regularization and kernel methods, leads to a principled kernel-based framework for constructing algorithms and for analyzing them theoretically. The resulting family of algorithms (FIRE, for Fredholm Inverse Regularized Estimator) is flexible, simple and easy to implement. We provide detailed theoretical analysis including concentration bounds and convergence rates for the Gaussian kernel in the case of densities defined on R, compact domains in R and smooth d-dimensional sub-manifolds of the Euclidean space. We also show experimental results including applications to classification and semi-supervised learning within the covariate shift framework and demonstrate some encouraging experimental comparisons. We also show how the parameters of our algorithms can be chosen in a completely unsupervised manner.",
            "output": [
                "Inverse Density as an Inverse Problem: the Fredholm Equation Approach"
            ]
        },
        {
            "id": "task1540-79feee4f1c4e458489a1cfc508f571f9",
            "input": "Consider designing an effective crowdsourcing system for an M -ary classification task. Crowd workers complete simple binary microtasks whose results are aggregated to give the final result. We consider the novel scenario where workers have a reject option so they may skip microtasks when they are unable or choose not to respond. For example, in mismatched speech transcription, workers who do not know the language may not be able to respond to microtasks focused on phonological dimensions outside their categorical perception. We present an aggregation approach using a weighted majority voting rule, where each worker’s response is assigned an optimized weight to maximize the crowd’s classification performance. We evaluate system performance in both exact and asymptotic forms. Further, we consider the setting where there may be a set of greedy workers that complete microtasks even when they are unable to perform it reliably. We consider an oblivious and an expurgation strategy to deal with greedy workers, developing an algorithm to adaptively switch between the two based on the estimated fraction of greedy workers in the anonymous crowd. Simulation results show improved performance compared with conventional majority voting.",
            "output": [
                "Multi-object Classification via Crowdsourcing with a Reject Option"
            ]
        },
        {
            "id": "task1540-2e58157a76d543c3a91068309cc3d9ef",
            "input": "A variety of real-world processes (over networks) produce sequences of data whose complex temporal dynamics need to be studied. More especially, the event timestamps can carry important information about the underlying network dynamics, which otherwise are not available from the time-series evenly sampled from continuous signals. Moreover, in most complex processes, event sequences and evenly-sampled times series data can interact with each other, which renders joint modeling of those two sources of data necessary. To tackle the above problems, in this paper, we utilize the rich framework of (temporal) point processes to model event data and timely update its intensity function by the synergic twin Recurrent Neural Networks (RNNs). In the proposed architecture, the intensity function is synergistically modulated by one RNN with asynchronous events as input and another RNN with time series as input. Furthermore, to enhance the interpretability of the model, the attention mechanism for the neural point process is introduced. The whole model with event type and timestamp prediction output layers can be trained end-to-end and allows a black-box treatment for modeling the intensity. We substantiate the superiority of our model in synthetic data and three real-world benchmark datasets.",
            "output": [
                "Joint Modeling of Event Sequence and Time Series with Attentional Twin Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-988a6dbb54a740d9aa6f581fee1f98ad",
            "input": "The capability to store data about business processes execution in so-called Event Logs has brought to the diffusion of tools for the analysis of process executions and for the assessment of the goodness of a process model. Nonetheless, these tools are often very rigid in dealing with with Event Logs that include incomplete information about the process execution. Thus, while the ability of handling incomplete event data is one of the challenges mentioned in the process mining manifesto, the evaluation of compliance of an execution trace still requires an endto-end complete trace to be performed. This paper exploits the power of abduction to provide a flexible, yet computationally effective, framework to deal with different forms of incompleteness in an Event Log. Moreover it proposes a refinement of the classical notion of compliance into strong and conditional compliance to take into account incomplete logs. Finally, performances evaluation in an experimental setting shows the feasibility of the presented approach.",
            "output": [
                "Abducing Compliance of Incomplete Event Logs"
            ]
        },
        {
            "id": "task1540-770d175d99624a789d6dd646b33746c5",
            "input": "Universal induction is a crucial issue in AGI. Its practical applicability can be achieved by the choice of the reference machine or representation of algorithms agreed with the environment. This machine should be updatable for solving subsequent tasks more efficiently. We study this problem on an example of combinatory logic as the very simple Turing-complete reference machine, which enables modifying program representations by introducing different sets of primitive combinators. Genetic programming system is used to search for combinator expressions, which are easily decomposed into sub-expressions being recombined in crossover. Our experiments show that low-complexity induction or prediction tasks can be solved by the developed system (much more efficiently than using brute force); useful combinators can be revealed and included into the representation simplifying more difficult tasks. However, optimal sets of combinators depend on the specific task, so the reference machine should be adaptively chosen in coordination with the search engine.",
            "output": [
                "Universal Induction with Varying Sets of Combinators"
            ]
        },
        {
            "id": "task1540-509b3f6c0b324decaf4146786c742b7e",
            "input": "We consider the problem of repeatedly solving a variant of the same dynamic programming problem in successive trials. An instance of the type of problems we consider is to find the optimal binary search tree. At the beginning of each trial, the learner probabilistically chooses a tree with the n keys at the internal nodes and the n+ 1 gaps between keys at the leaves. It is then told the frequencies of the keys and gaps and is charged by the average search cost for the chosen tree. The problem is online because the frequencies can change between trials. The goal is to develop algorithms with the property that their total average search cost (loss) in all trials is close to the total loss of the best tree chosen in hind sight for all trials. The challenge, of course, is that the algorithm has to deal with exponential number of trees. We develop a methodology for tackling such problems for a wide class of dynamic programming algorithms. Our framework allows us to extend online learning algorithms like Hedge [9] and Component Hedge [15] to a significantly wider class of combinatorial objects than was possible before.",
            "output": [
                "Online Dynamic Programming"
            ]
        },
        {
            "id": "task1540-09ead4392ab7458090b92ae91f4ef120",
            "input": "We introduce the first global recursive neural parsing model with optimality guarantees during decoding. To support global features, we give up dynamic programs and instead search directly in the space of all possible subtrees. Although this space is exponentially large in the sentence length, we show it is possible to learn an efficient A* parser. We augment existing parsing models, which have informative bounds on the outside score, with a global model that has loose bounds but only needs to model non-local phenomena. The global model is trained with a novel objective that encourages the parser to search both efficiently and accurately. The approach is applied to CCG parsing, improving state-of-the-art accuracy by 0.4 F1. The parser finds the optimal parse for 99.9% of held-out sentences, exploring on average only 190 subtrees.",
            "output": [
                "Global Neural CCG Parsing with Optimality Guarantees"
            ]
        },
        {
            "id": "task1540-6c564840a1bb4f788546a92bb2575788",
            "input": "We propose a model to learn visually grounded word embeddings (vis-w2v) to capture visual notions of semantic relatedness. While word embeddings trained using text have been extremely successful, they cannot uncover notions of semantic relatedness implicit in our visual world. For instance, visual grounding can help us realize that concepts like eating and staring at are related, since when people are eating something, they also tend to stare at the food. Grounding a rich variety of relations like eating and stare at in vision is a challenging task, despite recent progress in vision. We realize the visual grounding for words depends on the semantics of our visual world, and not the literal pixels. We thus use abstract scenes created from clipart to provide the visual grounding. We find that the embeddings we learn capture fine-grained visually grounded notions of semantic relatedness. We show improvements over text only word embeddings (word2vec) on three tasks: common-sense assertion classification, visual paraphrasing and text-based image retrieval. Our code and datasets will be available online.",
            "output": [
                "Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes"
            ]
        },
        {
            "id": "task1540-3993094978cf4ee3835bd98088a1707c",
            "input": "Dialog act identification plays an important role in understanding conversations. It has been widely applied in many fields such as dialogue systems, automatic machine translation, automatic speech recognition, and especially useful in systems with human-computer natural language dialogue interfaces such as virtual assistants and chatbots. The first step of identifying dialog act is identifying the boundary of the dialog act in utterances. In this paper, we focus on segmenting the utterance according to the dialog act boundaries, i.e. functional segments identification, for Vietnamese utterances. We investigate carefully functional segment identification in two approaches: (1) machine learning approach using maximum entropy (ME) and conditional random fields (CRFs); (2) deep learning approach using bidirectional Long Short-Term Memory (LSTM) with a CRF layer (Bi-LSTM-CRF) on two different conversational datasets: (1) Facebook messages (Message data); (2) transcription from phone conversations (Phone data). To the best of our knowledge, this is the first work that applies deep learning based approach to dialog act segmentation. As the results show, deep learning approach performs appreciably better as to compare with traditional machine learning approaches. Moreover, it is also the first study that tackles dialog act and functional segment identification for Vietnamese. Keywords—Dialog act segmentation, functional segment, Vietnamese conversation.",
            "output": [
                "Dialogue Act Segmentation for Vietnamese Human-Human Conversational Texts"
            ]
        },
        {
            "id": "task1540-0ff2756a31544d4d9c42bd138bac6bf7",
            "input": "People exhibit a tendency to generalize a novel noun to the basic-level in a hierarchical taxonomy – a cognitively salient category such as “dog” – with the degree of generalization depending on the number and type of exemplars. Recently, a change in the presentation timing of exemplars has also been shown to have an effect, surprisingly reversing the prior observed pattern of basic-level generalization. We explore the precise mechanisms that could lead to such behavior by extending a computational model of word learning and word generalization to integrate cognitive processes of memory and attention. Our results show that the interaction of forgetting and attention to novelty, as well as sensitivity to both type and token frequencies of exemplars, enables the model to replicate the empirical results from different presentation timings. Our results reinforce the need to incorporate general cognitive processes within word learning models to better understand the range of observed behaviors in vocabulary acquisition.",
            "output": [
                "The Interaction of Memory and Attention in Novel Word Generalization: A Computational Investigation"
            ]
        },
        {
            "id": "task1540-023462ae3cde42ec8c222dbac0afd921",
            "input": "Current Deep Learning approaches have been very successful using convolutional neural networks (CNN) trained on large graphical processing units (GPU)-based computers. Three limitations of this approach are: 1) they are based on a simple layered network topology, i.e., highly connected layers, without intra-layer connections; 2) the networks are manually configured to achieve optimal results, and 3) the implementation of neuron model is expensive in both cost and power. In this paper, we evaluate deep learning models using three different computing architectures to address these problems: quantum computing to train complex topologies, high performance computing (HPC) to automatically determine network topology, and neuromorphic computing for a low-power hardware implementation. We use the MNIST dataset for our experiment, due to input size limitations of current quantum computers. Our results show the feasibility of using the three architectures in tandem to address the above deep learning limitations. We show a quantum computer can find high quality values of intra-layer connections weights, in a tractable time as the complexity of the network increases; a high performance computer can find optimal layer-based topologies; and a neuromorphic computer can represent the complex topology and weights derived from the other architectures in low power memristive hardware. Notice: This manuscript has been authored by UT-Battelle, LLC under Contract No. DE-AC05-00OR22725 with the U.S. Department of Energy. The United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United States Government retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this manuscript, or allow others to do so, for United States Government purposes. The Department of Energy will provide public access to these results of federally sponsored research in accordance with the DOE Public Access Plan (http://energy.gov/downloads/doe-public-access-plan). 1 ar X iv :1 70 3. 05 36 4v 1 [ cs .N E ] 1 5 M ar 2 01 7",
            "output": [
                "A Study of Complex Deep Learning Networks on High Performance, Neuromorphic, and Quantum Computers"
            ]
        },
        {
            "id": "task1540-e815c5200f794815868bd3c4b87cd21d",
            "input": "Machine transliteration is the process of automatically transforming the script of a word from a source language to a target language, while preserving pronunciation. Sequence to sequence learning has recently emerged as a new paradigm in supervised learning. In this paper a character-based encoder-decoder model has been proposed that consists of two Recurrent Neural Networks. The encoder is a Bidirectional recurrent neural network that encodes a sequence of symbols into a fixed-length vector representation, and the decoder generates the target sequence using an attention-based recurrent neural network. The encoder, the decoder and the attention mechanism are jointly trained to maximize the conditional probability of a target sequence given a source sequence. Our experiments on different datasets show that the proposed encoderdecoder model is able to achieve significantly higher transliteration quality over traditional statistical models.",
            "output": [
                "Neural Machine Transliteration: Preliminary Results"
            ]
        },
        {
            "id": "task1540-d406a837568541b4a84f77b8e4d74e26",
            "input": "Kernel approximation using randomized feature maps has recently gained a lot of interest. In this work, we identify that previous approaches for polynomial kernel approximation create maps that are rank deficient, and therefore do not utilize the capacity of the projected feature space effectively. To address this challenge, we propose compact random feature maps (CRAFTMaps) to approximate polynomial kernels more concisely and accurately. We prove the error bounds of CRAFTMaps demonstrating their superior kernel reconstruction performance compared to the previous approximation schemes. We show how structured random matrices can be used to efficiently generate CRAFTMaps, and present a single-pass algorithm using CRAFTMaps to learn non-linear multi-class classifiers. We present experiments on multiple standard data-sets with performance competitive with state-of-the-art results.",
            "output": [
                "Compact Random Feature Maps"
            ]
        },
        {
            "id": "task1540-4a5926c463054e7fbb32e069b763675a",
            "input": "The multi-agent path-finding (MAPF) problem has recently received a lot of attention. However, it does not capture important characteristics of many real-world domains, such as automated warehouses, where agents are constantly engaged with new tasks. In this paper, we therefore study a lifelong version of the MAPF problem, called the multiagent pickup and delivery (MAPD) problem. In the MAPD problem, agents have to attend to a stream of delivery tasks in an online setting. One agent has to be assigned to each delivery task. This agent has to first move to a given pickup location and then to a given delivery location while avoiding collisions with other agents. We present two decoupled MAPD algorithms, Token Passing (TP) and Token Passing with Task Swaps (TPTS). Theoretically, we show that they solve all well-formed MAPD instances, a realistic subclass of MAPD instances. Experimentally, we compare them against a centralized strawman MAPD algorithm without this guarantee in a simulated warehouse system. TP can easily be extended to a fully distributed MAPD algorithm and is the best choice when real-time computation is of primary concern since it remains efficient for MAPD instances with hundreds of agents and tasks. TPTS requires limited communication among agents and balances well between TP and the centralized MAPD algorithm.",
            "output": [
                "Lifelong Multi-Agent Path Finding for Online Pickup and Delivery Tasks∗"
            ]
        },
        {
            "id": "task1540-5bac14cac5694e828b500690e188e6d8",
            "input": "Recommendation systems are emerging as an important business application with significant economic impact. Currently popular systems include Amazon’s book recommendations, Netflix’s movie recommendations, and Pandora’s music recommendations. In this paper we address the problem of estimating probabilities associated with recommendation system data using non-parametric kernel smoothing. In our estimation we interpret missing items as randomly censored observations and obtain efficient computation schemes using combinatorial properties of generating functions. We demonstrate our approach with several case studies involving real world movie recommendation data. The results are comparable with state-of-the-art techniques while also providing probabilistic preference estimates outside the scope of traditional recommender systems.",
            "output": [
                "Estimating Probabilities in Recommendation Systems"
            ]
        },
        {
            "id": "task1540-afb4f84c16eb47498d929be76d65c634",
            "input": "Studies of the overall structure of vocabulary and its dynamics became possible due to creation of diachronic text corpora, especially Google Books Ngram. This article discusses the question of core change rate and the degree to which the core words cover the texts. Different periods of the last three centuries and six main European languages presented in Google Books Ngram are compared. The main result is high stability of core change rate, which is analogous to stability of the Swadesh list.",
            "output": [
                "Dynamics of core of language vocabulary"
            ]
        },
        {
            "id": "task1540-4d3af9f93461461bb9cbcabd9077f270",
            "input": "Stochastic gradient-boosted decision trees are widely employed for multivariate classification and regression tasks. This paper presents a speed-optimized and cache-friendly implementation for multivariate classification called FastBDT. FastBDT is one order of magnitude faster during the fitting-phase and application-phase, in comparison with popular implementations in software frameworks like TMVA, scikit-learn and XGBoost. The concepts used to optimize the execution time and performance studies are discussed in detail in this paper. The key ideas include: An equal-frequency binning on the input data, which allows replacing expensive floating-point with integer operations, while at the same time increasing the quality of the classification; a cache-friendly linear access pattern to the input data, in contrast to usual implementations, which exhibit a random access pattern. FastBDT provides interfaces to C/C++, Python and TMVA. It is extensively used in the field of high energy physics by the Belle II experiment.",
            "output": [
                "A speed-optimized and cache-friendly implementation of stochastic gradient-boosted decision trees for multivariate classification"
            ]
        },
        {
            "id": "task1540-d1156ec2f3a344fba8fdf79b3329c7a3",
            "input": "We present LTLS, a technique for multiclass and multilabel prediction that can perform training and inference in logarithmic time and space. LTLS embeds large classification problems into simple structured prediction problems and relies on efficient dynamic programming algorithms for inference. We train LTLS with stochastic gradient descent on a number of multiclass and multilabel datasets and show that despite its small memory footprint it is often competitive with existing approaches.",
            "output": [
                "Log-time and Log-space Extreme Classification"
            ]
        },
        {
            "id": "task1540-30acd15fa5dd4033888d6d25a2aa157a",
            "input": "In this paper we investigate the problem of localizing a mobile device based on readings from its embedded sensors utilizing machine learning methodologies. We consider a realworld environment, collect a large dataset of 3110 datapoints, and examine the performance of a substantial number of machine learning algorithms in localizing a mobile device. We have found algorithms that give a mean error as accurate as 0.76 meters, outperforming other indoor localization systems reported in the literature. We also propose a hybrid instance-based approach that results in a speed increase by a factor of ten with no loss of accuracy in a live deployment over standard instance-based methods, allowing for fast and accurate localization. Further, we determine how smaller datasets collected with less density affect accuracy of localization, important for use in real-world environments. Finally, we demonstrate that these approaches are appropriate for real-world deployment by evaluating their performance in an online, in-motion experiment.",
            "output": [
                "Machine Learning for Indoor Localization Using Mobile Phone-Based Sensors"
            ]
        },
        {
            "id": "task1540-a0a2e369b5c54cc2a1ed3d99086be2e2",
            "input": "The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.",
            "output": [
                "Variational Inference with Normalizing Flows"
            ]
        },
        {
            "id": "task1540-9231cd6c6b6746cfa07e22bdf05e97b6",
            "input": "Sentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences – the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average.",
            "output": [
                "Representing Sentences as Low-Rank Subspaces"
            ]
        },
        {
            "id": "task1540-3366975bd6d14e24aa2d4110d7dc65b4",
            "input": "Private Set Intersection (PSI) is usually implemented as a sequence of encryption rounds between pairs of users, whereas the present work implements PSI in a simpler fashion: each set only needs to be encrypted once, after which each pair of users need only one ordinary set comparison. This is typically orders of magnitude faster than ordinary PSI at the cost of some “fuzziness” in the matching, which may nonetheless be tolerable or even desirable. This is demonstrated in the case where the sets consist of English words processed with WordNet. Email: 1054h34@gmail.com",
            "output": [
                "Fast and Fuzzy Private Set Intersection"
            ]
        },
        {
            "id": "task1540-9dae648edef84406b523457e347b3003",
            "input": "Submodular functions describe a variety of discrete problems in machine learn-<lb>ing, signal processing, and computer vision. However, minimizing submodular<lb>functions poses a number of algorithmic challenges. Recent work introduced an<lb>easy-to-use, parallelizable algorithm for minimizing submodular functions that<lb>decompose as the sum of “simple” submodular functions. Empirically, this al-<lb>gorithm performs extremely well, but no theoretical analysis was given. In this<lb>paper, we show that the algorithm converges linearly, and we provide upper and<lb>lower bounds on the rate of convergence. Our proof relies on the geometry of<lb>submodular polyhedra and draws on results from spectral graph theory.",
            "output": [
                "On the Convergence Rate of Decomposable Submodular Function Minimization"
            ]
        },
        {
            "id": "task1540-14e651433693406c9e71bdf2c475ebdc",
            "input": "The holy Quran is the holy book of the Muslims. It contains information about many domains. Often people search for particular concepts of holy Quran based on the relations among concepts. An ontological modeling of holy Quran can be useful in such a scenario. In this paper, we have modeled nature related concepts of holy Quran using OWL (Web Ontology Language) / RDF (Resource Description Framework). Our methodology involves identifying nature related concepts mentioned in holy Quran and identifying relations among those concepts. These concepts and relations are represented as classes/instances and properties of an OWL ontology. Later, in the result section it is shown that, using the Ontological model, SPARQL queries can retrieve verses and concepts of interest. Thus, this modeling helps semantic search and query on the holy Quran. In this work, we have used English translation of the holy Quran by Sahih International, Protege OWL Editor and for querying we have used SPARQL. Keywords— Quranic Ontology; Semantic Quran; Quranic Knowledge Representation.",
            "output": [
                "Applying Ontological Modeling on Quranic “Nature” Domain"
            ]
        },
        {
            "id": "task1540-2910af8479ee407d9fd798ef1e38e893",
            "input": "The game of Go is more challenging than other board games, due to the difficulty of constructing a position or move evaluation function. In this paper we investigate whether deep convolutional networks can be used to directly represent and learn this knowledge. We train a large 12-layer convolutional neural network by supervised learning from a database of human professional games. The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional-search program GnuGo in 97% of games, and matched the performance of a state-of-the-art Monte-Carlo tree search that simulates two million positions per move.",
            "output": [
                "MOVE EVALUATION IN GO USING DEEP CONVOLUTIONAL NEURAL NETWORKS"
            ]
        },
        {
            "id": "task1540-9c0fe4e5b4f941bea54c033ace32cff4",
            "input": "Cluster analysis plays an important role in decision making process for many knowledge-based systems. There exist a wide variety of different approaches for clustering applications including the heuristic techniques, probabilistic models, and traditional hierarchical algorithms. In this paper, a novel heuristic approach based on big bang-big crunch algorithm is proposed for clustering problems. The proposed method not only takes advantage of heuristic nature to alleviate typical clustering algorithms such as k-means, but it also benefits from the memory based scheme as compared to its similar heuristic techniques. Furthermore, the performance of the proposed algorithm is investigated based on several benchmark test functions as well as on the well-known datasets. The experimental results shows the significant superiority of the proposed method over the similar algorithms.",
            "output": [
                "Memory Enriched Big Bang Big Crunch Optimization Algorithm for Data Clustering"
            ]
        },
        {
            "id": "task1540-d395df9f4088459a916725054d5ec683",
            "input": "Performing sensitivity analysis for influence diagrams using the decision circuit framework is particularly convenient, since the partial derivatives with respect to every parameter are readily available [Bhattacharjya and Shachter, 2007; 2008]. In this paper we present three non-linear sensitivity analysis methods that utilize this partial derivative information and therefore do not require re-evaluating the decision situation multiple times. Specifically, we show how to efficiently compare strategies in decision situations, perform sensitivity to risk aversion and compute the value of perfect hedging [Seyller, 2008].",
            "output": [
                "Three new sensitivity analysis methods for influence diagrams"
            ]
        },
        {
            "id": "task1540-7af12ec9a971438bb9571ca0c696658b",
            "input": "We present two related methods for creating MasterPrints, synthetic fingerprints that a fingerprint verification system identifies as many different people. Both methods start with training a Generative Adversarial Network (GAN) on a set of real fingerprint images. The generator network is then used to search for images that can be recognized as multiple individuals. The first method uses evolutionary optimization in the space of latent variables, and the second uses gradient-based search. Our method is able to design a MasterPrint that a commercial fingerprint system matches to 22% of all users in a strict security setting, and 75% of all users at a looser security setting.",
            "output": [
                "DeepMasterPrint: Generating Fingerprints for Presentation Attacks"
            ]
        },
        {
            "id": "task1540-e583e1adceb448e1a3eb796404eab86c",
            "input": "This paper develops the idea of membership function assignment for OWL (Web Ontology Language) ontology elements in order to subsequently generate fuzzy rules from this ontology. The task of membership function assignment for OWL ontology elements had already been partially described, but this concerned the case , when several OWL ontologies of the same domain were available, and they were merged into a single ontology. The purpose of this paper is to present the way of membership function assignment for OWL ontology elements in the case, when there is the only one available ontology. Fuzzy rules, generated from the OWL ontology, are necessary for supplement of the SWES (Semantic Web Expert System) knowledge base. SWES is an expert system, which will be able to extract knowledge from OWL ontologies , found in the Web, and will serve as a universal expert for the user.",
            "output": [
                "Membership Function Assignment for Elements of Single OWL Ontology"
            ]
        },
        {
            "id": "task1540-f0e374c0198040188889952c2873b007",
            "input": "Authors are encouraged to submit new papers to INFORMS journals by means of a style file template, which includes the journal title. However, use of a template does not certify that the paper has been accepted for publication in the named journal. INFORMS journal templates are for the exclusive purpose of submitting to an INFORMS journal and should not be used to distribute the papers in print or online or to submit the papers to another publication.",
            "output": [
                "A Dynamic Near-Optimal Algorithm for Online Linear Programming"
            ]
        },
        {
            "id": "task1540-7cdbb4ace1af47a5b3da8b10d83e9007",
            "input": "For agents and robots to become more useful, they must be able to quickly learn from non-technical users. This paper investigates the problem of interactively learning behaviors communicated by a human teacher using positive and negative feedback. Much previous work on this problem has made the assumption that people provide feedback for decisions that is dependent on the behavior they are teaching and is independent from the learner’s current policy. We present empirical results that show this assumption to be false—whether human trainers give a positive or negative feedback for a decision is influenced by the learner’s current policy. We argue that policy-dependent feedback, in addition to being commonplace, enables useful training strategies from which agents should benefit. Based on this insight, we introduce Convergent Actor-Critic by Humans (COACH), an algorithm for learning from policy-dependent feedback that converges to a local optimum. Finally, we demonstrate that COACH can successfully learn multiple behaviors on a physical robot, even with noisy image features.",
            "output": [
                "Interactive Learning from Policy-Dependent Human Feedback"
            ]
        },
        {
            "id": "task1540-8673b5d2dd164d928fd766856574cd80",
            "input": "This paper considers a general data-fitting problem over a networked system, in which many computing nodes are connected by an undirected graph. This kind of problem can find many real-world applications and has been studied extensively in the literature. However, existing solutions either need a central controller for information sharing or requires slot synchronization among different nodes, which increases the difficulty of practical implementations, especially for a very large and heterogeneous system. As a contrast, in this paper, we treat the data-fitting problem over the network as a stochastic programming problem with many constraints. By adapting the results in a recent paper [18], we design a fully distributed and asynchronized stochastic gradient descent (SGD) algorithm. We show that our algorithm can achieve global optimality and consensus asymptotically by only local computations and communications. Additionally, we provide a sharp lower bound for the convergence speed in the regular graph case. This result fits the intuition and provides guidance to design a ‘good’ network topology to speed up the convergence. Also, the merit of our design is validated by experiments on both synthetic and real-world datasets.",
            "output": [
                "Fully Distributed and Asynchronized Stochastic Gradient Descent for Networked Systems"
            ]
        },
        {
            "id": "task1540-edfa218aaed644538cb9910e13057cd0",
            "input": "Data-to-text systems are powerful in generating reports from data automatically and thus they simplify the presentation of complex data. Rather than presenting data using visualisation techniques, datato-text systems use natural (human) language, which is the most common way for human-human communication. In addition, data-to-text systems can adapt their output content to users’ preferences, background or interests and therefore they can be pleasant for users to interact with. Content selection is an important part of every data-to-text system, because it is the module that determines which from the available information should be conveyed to the user. This survey initially introduces the field of data-to-text generation, describes the general data-to-text system architecture and then it reviews the state-ofthe-art content selection methods. Finally, it provides recommendations for choosing an approach and discusses opportunities for future research.",
            "output": [
                "Content Selection in Data-to-Text Systems: A Survey"
            ]
        },
        {
            "id": "task1540-93b2969648ab4c98b015c6dda482f7a0",
            "input": "Semi-supervised learning based on the low-density separation principle such as<lb>the cluster and manifold assumptions has been extensively studied in the last<lb>decades. However, such semi-supervised learning methods do not always per-<lb>form well due to violation of the cluster and manifold assumptions. In this paper,<lb>we propose a novel approach to semi-supervised learning that does not require<lb>such restrictive assumptions. Our key idea is to combine learning from positive<lb>and negative data (standard supervised learning) and learning from positive and<lb>unlabeled data (PU learning), the latter is guaranteed to be able to utilize unla-<lb>beled data without the cluster and manifold assumptions. We theoretically and<lb>experimentally show the usefulness of our approach.",
            "output": [
                "Beyond the Low-density Separation Principle: A Novel Approach to Semi-supervised Learning"
            ]
        },
        {
            "id": "task1540-7d388dd8a7584cf797be6cfa0e1c8555",
            "input": "In this paper we propose a neural network model with a novel Sequential Attention layer that extends soft attention by assigning weights to words in an input sequence in a way that takes into account not just how well that word matches a query, but how well surrounding words match. We evaluate this approach on the task of reading comprehension (Who did What and CNN) and show that it dramatically improves a strong baseline like the Stanford Reader. The resulting model is competitive with the state of the art.",
            "output": [
                "Sequential Attention"
            ]
        },
        {
            "id": "task1540-d1b4a47780664ee085254d9446181739",
            "input": "We propose two novel techniques — stacking bottleneck features and minimum generation error training criterion — to improve the performance of deep neural network (DNN)based speech synthesis. The techniques address the related issues of frame-by-frame independence and ignorance of the relationship between static and dynamic features, within current typical DNNbased synthesis frameworks. Stacking bottleneck features, which are an acoustically–informed linguistic representation, provides an efficient way to include more detailed linguistic context at the input. The minimum generation error training criterion minimises overall output trajectory error across an utterance, rather than minimising the error per frame independently, and thus takes into account the interaction between static and dynamic features. The two techniques can be easily combined to further improve performance. We present both objective and subjective results that demonstrate the effectiveness of the proposed techniques. The subjective results show that combining the two techniques leads to significantly more natural synthetic speech than from conventional DNN or long short-term memory (LSTM) recurrent neural network (RNN) systems.",
            "output": [
                "Improving Trajectory Modelling for DNN-based Speech Synthesis by using Stacked Bottleneck Features and Minimum Generation Error Training"
            ]
        },
        {
            "id": "task1540-f421cc922e2a41d697ea063e9f52e678",
            "input": "When training deep neural networks, it is typically assumed that the training examples are uniformly difficult to learn. Or, to restate, it is assumed that the training error will be uniformly distributed across the training examples. Based on these assumptions, each training example is used an equal number of times. However, this assumption may not be valid in many cases. “Oddball SGD” (novelty-driven stochastic gradient descent) was recently introduced to drive training probabilistically according to the error distribution – training frequency is proportional to training error magnitude. In this article, using a deep neural network to encode a video, we show that oddball SGD can be used to enforce uniform error across the training set.",
            "output": [
                "Uniform Learning in a Deep Neural Network via \"Oddball\" Stochastic Gradient Descent"
            ]
        },
        {
            "id": "task1540-5a3e1a7bce6247dfb2549839e806ddc0",
            "input": "In this project, a rather complete proof-theoretical formalization of Lambek Calculus (non-associative with arbitrary extensions) has been ported from Coq proof assistent to HOL4 theorem prover, with some improvements and new theorems. Three deduction systems (Syntactic Calculus, Natural Deduction and Sequent Calculus) of Lambek Calculus are defined with many related theorems proved. The equivalance between these systems are formally proved. Finally, a formalization of Sequent Calculus proofs (where Coq has built-in supports) has been designed and implemented in HOL4. Some basic results including the subformula properties of the so-called “cut-free” proofs are formally proved. This work can be considered as the preliminary work towards a language parser based on category grammars which is not multimodal but still has ability to support context-sensitive languages through customized extensions.",
            "output": [
                "Formalized Lambek Calculus in Higher Order Logic (HOL4)"
            ]
        },
        {
            "id": "task1540-8d04456071de4b35b18c23eb9abd035b",
            "input": "This paper addresses the problem of predicting the k events that are most likely to occur next, over historical real-time event streams. Existing approaches to causal prediction queries have a number of limitations. First, they exhaustively search over an acyclic causal network to find the most likely k effect events; however, data from real event streams frequently reflect cyclic causality. Second, they contain conservative assumptions intended to exclude all possible non-causal links in the causal network; it leads to the omission of many less-frequent but important causal links. We overcome these limitations by proposing a novel event precedence model and a runtime causal inference mechanism. The event precedence model constructs a first order absorbing Markov chain incrementally over event streams, where an edge between two events signifies a temporal precedence relationship between them, which is a necessary condition for causality. Then, the run-time causal inference mechanism learns causal relationships dynamically during query processing. This is done by removing some of the temporal precedence relationships that do not exhibit causality in the presence of other events in the event precedence model. This paper presents two query processing algorithms – one performs exhaustive search on the model and the other performs a more efficient reduced search with early termination. Experiments using two real datasets (cascading blackouts in power systems and web page views) verify the effectiveness of the probabilistic top-k prediction queries and the efficiency of the algorithms. Specifically, the reduced search algorithm reduced runtime, relative to exhaustive search, by 25− 80% (depending on the application) with only a small reduction in accuracy.",
            "output": [
                "Real-time Top-K Predictive Query Processing over Event Streams"
            ]
        },
        {
            "id": "task1540-e3e4a3fa540f416bb31fdaec187fbc69",
            "input": "We develop a probabilistic latent-variable model to discover semantic frames—types of events and their participants—from corpora. We present a Dirichlet-multinomial model in which frames are latent categories that explain the linking of verb-subject-object triples, given document-level sparsity. We analyze what the model learns, and compare it to FrameNet, noting it learns some novel and interesting frames. This document also contains a discussion of inference issues, including concentration parameter learning; and a small-scale error analysis of syntactic parsing accuracy. Note: this work was originally posted online October 2012 as part of CMU MLD’s Data Analysis Project requirement. This version has no new experiments or results, but has added some discussion of new related work.",
            "output": [
                "Learning Frames from Text with an Unsupervised Latent Variable Model"
            ]
        },
        {
            "id": "task1540-1326bd7530624e1896ff3247cafb98e0",
            "input": "Drugs are frequently prescribed to patients with the aim of improving each patient’s medical state, but an unfortunate consequence of most prescription drugs is the occurrence of undesirable side effects. Side effects that occur in more than one in a thousand patients are likely to be signalled efficiently by current drug surveillance methods, however, these same methods may take decades before generating signals for rarer side effects, risking medical morbidity or mortality in patients prescribed the drug while the rare side effect is undiscovered. In this paper we propose a novel computational meta-analysis framework for signalling rare side effects that integrates existing methods, knowledge from the web, metric learning and semi-supervised clustering. The novel framework was able to signal many known rare and serious side effects for the selection of drugs investigated, such as tendon rupture when prescribed Ciprofloxacin or Levofloxacin, renal failure with Naproxen and depression associated with Rimonabant. Furthermore, for the majority of the drug investigated it generated signals for rare side effects at a more stringent signalling threshold than existing methods and shows the potential to become a fundamental part of post marketing surveillance to detect rare side effects.",
            "output": [
                "A Novel Semi-Supervised Algorithm for Rare Prescription Side Effect Discovery"
            ]
        },
        {
            "id": "task1540-d081da5ec9bc465cbda3d7dfa6678f20",
            "input": "We exhibit a strong link between frequentist PAC-Bayesian bounds and the Bayesian marginal likelihood. That is, for the negative log-likelihood loss function, we show that the minimization of PAC-Bayesian generalization bounds maximizes the Bayesian marginal likelihood. This provides an alternative explanation to the Bayesian Occam’s razor criteria, under the assumption that the data is generated by a i.i.d. distribution. Moreover, as the negative log-likelihood is an unbounded loss function, we motivate and propose a PAC-Bayesian theorem tailored for the sub-Gamma loss family, and we show that our approach is sound on classical Bayesian linear regression tasks.",
            "output": [
                "PAC-Bayesian Theory Meets Bayesian Inference"
            ]
        },
        {
            "id": "task1540-9aa928d915d6497e803a9c23204eb647",
            "input": "In educational technology and learning sciences, there are multiple uses for a predictive model of whether a student will perform a task correctly or not. For example, an intelligent tutoring system may use such a model to estimate whether or not a student has mastered a skill. We analyze the significance of data recency in making such predictions, i.e., asking whether relatively more recent observations of a student’s performance matter more than relatively older observations. We develop a new Recent-Performance Factors Analysis model that takes data recency into account. The new model significantly improves predictive accuracy over both existing logistic-regression performance models and over novel baseline models in evaluations on real-world and synthetic datasets. As a secondary contribution, we demonstrate how the widely used cross-validation with 0-1 loss is inferior to AIC and to cross-validation with L1 prediction error loss as a measure of model performance.",
            "output": [
                "Predicting Performance During Tutoring with Models of Recent Performance"
            ]
        },
        {
            "id": "task1540-b9161eee080a4c909e58179186e485de",
            "input": "We propose a supervised machine learning approach for boosting existing signal and image recovery methods and demonstrate its efficacy on example of image reconstruction in computed tomography. Our technique is based on a local nonlinear fusion of several image estimates, all obtained by applying a chosen reconstruction algorithm with different values of its control parameters. Usually such output images have different bias/variance trade-off. The fusion of the images is performed by feed-forward neural network trained on a set of known examples. Numerical experiments show an improvement in reconstruction quality relatively to existing direct and iterative reconstruction methods.",
            "output": [
                "Spatially-Adaptive Reconstruction in Computed Tomography using Neural Networks"
            ]
        },
        {
            "id": "task1540-1418a5f1ac3e4b6faaa5d76d49f69908",
            "input": "We introduce a new interpretation of two re­ lated notions conditional utility and utility independence. Unlike the traditional inter­ pretation, the new interpretation render the notions the direct analogues of their prob­ abilistic counterparts. To capture these no­ tions formally, we appeal to the notion of util­ ity distribution, introduced in previous paper. We show that utility distributions, which have a structure that is identical to that of probability distributions, can be viewed as a special case of an additive multiattribute utility functions, and show how this special case permits us to capture the novel senses of conditional utility and utility independence. Finally, we present the notion of utility net­ works, which do for utilities what Bayesian networks do for probabilities. Specifically, utility networks exploit the new interpreta­ tion of conditional utility and utility indepen­ dence to compactly represent a utility distri­ bution.",
            "output": [
                "Conditional Utility, Utility Independence, and Utility Networks"
            ]
        },
        {
            "id": "task1540-45a0e7a9142c44ef9f5b3e88a9198654",
            "input": "We present the first differentially private algorithms for reinforcement learning, which apply to the task of evaluating a fixed policy. We establish two approaches for achieving differential privacy, provide a theoretical analysis of the privacy and utility of the two algorithms, and show promising results on simple empirical examples.",
            "output": [
                "Differentially Private Policy Evaluation∗"
            ]
        },
        {
            "id": "task1540-edde7526ab724e66b38f2b3fe36a5f90",
            "input": "The high probability of hardware failures prevents many advanced robots (e.g. legged robots) to be confidently deployed in real-world situations (e.g post-disaster rescue). Instead of attempting to diagnose the failure(s), robots could adapt by trial-and-error in order to be able to complete their tasks. However, the best trial-and-error algorithms for robotics are all episodic: between each trial, the robot needs to be put back in the same state, that is, the robot is not learning autonomously. In this paper, we introduce a novel learning algorithm called “Reset-free Trial-and-Error” (RTE) that allows robots to recover from damage while completing their tasks. We evaluate it on a hexapod robot that is damaged in several ways (e.g. a missing leg, a shortened leg, etc.) and whose objective is to reach a sequence of targets in an arena. Our experiments show that the robot can recover most of its locomotion abilities in a few minutes, in an environment with obstacles, and without any human intervention. Overall, this new algorithm makes it possible to contemplate sending robots to places that are truly too dangerous for humans and in which robots cannot be rescued.",
            "output": [
                "Reset-free Trial-and-Error Learning for Data-Efficient Robot Damage Recovery"
            ]
        },
        {
            "id": "task1540-101a9bca2e6d4634bbf81d7540e59822",
            "input": "Coalition formation is a key topic in multi-agent systems. Coalitions enable agents to achieve goals that they may not have been able to achieve on their own. Previous work has shown problems in coalition games to be computationally hard. Wooldridge and Dunne (Artificial Intelligence 2006) studied the classical computational complexity of several natural decision problems in Coalitional Resource Games (CRG) games in which each agent is endowed with a set of resources and coalitions can bring about a set of goals if they are collectively endowed with the necessary amount of resources. The input of coalitional resource games bundles together several elements, e.g., the agent set Ag, the goal set G, the resource set R, etc. Shrot, Aumann and Kraus (AAMAS 2009) examine coalition formation problems in the CRG model using the theory of Parameterized Complexity. Their refined analysis shows that not all parts of input act equal some instances of the problem are indeed tractable while others still remain intractable. We answer an important question left open by Shrot, Aumann and Kraus by showing that the SC Problem (checking whether a Coalition is Successful) is W[1]-hard when parameterized by the size of the coalition. Then via a single theme of reduction from SC, we are able to show that various problems related to resources, resource bounds and resource conflicts introduced by Wooldridge et al are 1. W[1]-hard or co-W[1]-hard when parameterized by the size of the coalition. 2. para-NP-hard or co-para-NP-hard when parameterized by |R|. 3. FPT when parameterized by either |G| or |Ag|+ |R|. ∗Supported in part by Google Faculty Research Award, ONR Young Investigator Award and NSF CAREER award. †Department of Computer Science , University of Maryland at College Park, USA, email: rchitnis@cs.umd.edu ‡Department of Computer Science , University of Maryland at College Park, USA. email: hajiagha@cs.umd.edu §Department of Computer Science , University of Maryland at College Park, USA. email: vliaghat@cs.umd.edu",
            "output": [
                "Parameterized Complexity of Problems in Coalitional Resource Games"
            ]
        },
        {
            "id": "task1540-72e8147d9d6e403280db82b644b38e6c",
            "input": "A Verbal Autopsy is the record of an interview about the circumstances of an uncertified death. In developing countries, if a death occurs away from health facilities, a field-worker interviews a relative of the deceased about the circumstances of the death; this Verbal Autopsy can be reviewed offsite. We report on a comparative study of the processes involved in Text Classification applied to classifying Cause of Death: feature value representation; machine learning classification algorithms; and feature reduction strategies in order to identify the suitable approaches applicable to the classification of Verbal Autopsy text. We demonstrate that normalised term frequency and the standard TFiDF achieve comparable performance across a number of classifiers. The results also show Support Vector Machine is superior to other classification algorithms employed in this research. Finally, we demonstrate the effectiveness of employing a ’locally-semisupervised’ feature reduction strategy in order to increase performance accuracy.",
            "output": [
                "A Comparative Study of Machine Learning Methods for Verbal Autopsy Text Classification"
            ]
        },
        {
            "id": "task1540-d3fcffe8d11841d796a833980d9f28ca",
            "input": "We consider principal component analysis for contaminated data-set in the high dimensional regime, where the dimensionality of each observation is comparable or even more than the number of observations. We propose a deterministic high-dimensional robust PCA algorithm which inherits all theoretical properties of its randomized counterpart, i.e., it is tractable, robust to contaminated points, easily kernelizable, asymptotic consistent and achieves maximal robustness – a breakdown point of 50%. More importantly, the proposed method exhibits significantly better computational efficiency, which makes it suitable for large-scale real applications.",
            "output": [
                "Robust PCA in High-dimension: A Deterministic Approach"
            ]
        },
        {
            "id": "task1540-a9d786fb570543c39c4842eb24e68f2e",
            "input": "Background: Lung cancer was known as primary cancers and the survival rate of cancer is about 15%. Early detection of lung cancer is the leading factor in survival rate. All symptoms (features) of lung cancer do not appear until the cancer spreads to other areas. It needs an accurate early detection of lung cancer, for increasing the survival rate. For accurate detection, it need characterizes efficient features and delete redundancy features among all features.Feature selection is the problem of selecting informative features among all features. Materialsand Methods: Lung cancer database consist of 32 patient records with 57 features. This database collected by Hong and Youngand indexed in the University of California Irvine repository. Experimental contents include the extracted from the clinical data and X-ray data, etc. The data described 3 types of pathological lung cancers and all features are taking an integer value 0-3. In our study, new method is proposed for identify efficient features of lung cancer. It is based on Hyper-Heuristic. Results:We obtained an accuracy of 80.63% using reduced 11 feature set.The proposed method compare to the accuracy of 5 machine learning feature selections.The accuracy of these 5 methods are 60.94, 57.81, 68.75, 60.94 and 68.75. Conclusions: The proposed method has better performance with the highest level of accuracy. Therefore, the proposed model is recommended for identifying an efficient symptom of Disease. These finding are very important in health research, particularly in allocation of medical resources for patients who predicted as high-risks",
            "output": [
                "Hyper-Heuristic Algorithm for Finding Efficient Features in Diagnose of Lung Cancer Disease"
            ]
        },
        {
            "id": "task1540-d95058c3b71e4e5cb317c0184419c0af",
            "input": "We consider the question of the stability of evolutionary algorithms to gradual changes,<lb>or drift, in the target concept. We define an algorithm to be resistant to drift if, for<lb>some inverse polynomial drift rate in the target function, it converges to accuracy 1 − ǫ<lb>with polynomial resources, and then stays within that accuracy indefinitely, except with<lb>probability ǫ at any one time. We show that every evolution algorithm, in the sense of<lb>Valiant [19], can be converted using the Correlational Query technique of Feldman [9], into<lb>such a drift resistant algorithm. For certain evolutionary algorithms, such as for Boolean<lb>conjunctions, we give bounds on the rates of drift that they can resist. We develop some<lb>new evolution algorithms that are resistant to significant drift. In particular, we give an<lb>algorithm for evolving linear separators over the spherically symmetric distribution that is<lb>resistant to a drift rate of O(ǫ/n), and another algorithm over the more general product<lb>normal distributions that resists a smaller drift rate. The above translation result can be also interpreted as one on the robustness of the notion of<lb>evolvability itself under changes of definition. As a second result in that direction we show<lb>that every evolution algorithm can be converted to a quasi-monotonic one that can evolve<lb>from any starting point without the performance ever dipping significantly below that of<lb>the starting point. This permits the somewhat unnatural feature of arbitrary performance<lb>degradations to be removed from several known robustness translations.",
            "output": [
                "Evolution with Drifting Targets"
            ]
        },
        {
            "id": "task1540-cba2b82444e047a19d3b0b1d36f7be94",
            "input": "The goal of two-sample tests is to assess whether two samples, SP ∼ P and SQ ∼ Q, are drawn from the same distribution. Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the n examples in SP with a positive label, and by pairing the m examples in SQ with a negative label. If the null hypothesis “P = Q” is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level. As we will show, such Classifier Two-Sample Tests (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where P and Q differ. The goal of this paper is to establish the properties, performance, and uses of C2ST. First, we analyze their main theoretical properties. Second, we compare their performance against a variety of state-of-the-art alternatives. Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs). Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.",
            "output": [
                "REVISITING CLASSIFIER TWO-SAMPLE TESTS"
            ]
        },
        {
            "id": "task1540-80a1b85f028c4f63bf89dadadb6e52a8",
            "input": "Data can be acquired, shared, and processed by an increasingly larger number of entities, in particular people. The distributed nature of this phenomenon has contributed to the development of many crowdsourcing projects. This scenario is prevalent in most forms of expert/non-expert group opinion and rating tasks (including many forms of internet or on-line user behavior), where a key element is the aggregation of observations-opinions from multiple sources.",
            "output": [
                "Evaluating Crowdsourcing Participants in the Absence of Ground-Truth"
            ]
        },
        {
            "id": "task1540-758abae4f57d47b7b0be88de579209a9",
            "input": "In this paper, a new technique for the optimization of (partially) bound queries over disjunctive Datalog programs with stratified negation is presented. The technique exploits the propagation of query bindings and extends the Magic Set optimization technique (originally defined for non-disjunctive programs). An important feature of disjunctive Datalog programs is nonmonotonicity, which calls for nondeterministic implementations, such as backtracking search. A distinguishing characteristic of the new method is that the optimization can be exploited also during the nondeterministic phase. In particular, after some assumptions have been made during the computation, parts of the program may become irrelevant to a query under these assumptions. This allows for dynamic pruning of the search space. In contrast, the effect of the previously defined Magic Set methods for disjunctive Datalog is limited to the deterministic portion of the process. In this way, the potential performance gain by using the proposed method can be exponential, as could be observed empirically. The correctness of the method is established and proved in a formal way thanks to a strong relationship between Magic Sets and unfounded sets that has not been studied in the literature before. This knowledge allows for extending the method and the correctness proof also to programs with stratified negation in a natural way. The proposed method has been implemented in the DLV system and various experiments on synthetic as well as on real-world data have been conducted. The experimental results on synthetic data confirm the utility of Magic Sets for disjunctive Datalog, and they highlight the computational gain that may be obtained by the new method with respect to the previously proposed Magic Set method for disjunctive Datalog programs. Further experiments on data taken from a real-life application show the benefits of the Magic Set method within an application scenario that has received considerable attention in recent years, the problem of answering user queries over possibly inconsistent databases originating from integration of autonomous sources of information.",
            "output": [
                "Magic Sets for Disjunctive Datalog Programs"
            ]
        },
        {
            "id": "task1540-9b5569d70cb94134924e90d24dbc5723",
            "input": "Zero-sum stochastic games are easy to solve as they can be cast as simple Markov decision processes. This is however not the case with general-sum stochastic games. A fairly general optimization problem formulation is available for general-sum stochastic games by Filar and Vrieze [2004]. However, the optimization problem there has a non-linear objective and non-linear constraints with special structure. Since gradients of both the objective as well as constraints of this optimization problem are well defined, gradient based schemes seem to be a natural choice. We discuss a gradient scheme tuned for two-player stochastic games. We show in simulations that this scheme indeed converges to a Nash equilibrium, for a simple terrain exploration problem modelled as a general-sum stochastic game. However, it turns out that only global minima of the optimization problem correspond to Nash equilibria of the underlying general-sum stochastic game, while gradient schemes only guarantee convergence to local minima. We then provide important necessary conditions for gradient schemes to converge to Nash equilibria in general-sum stochastic games.",
            "output": [
                "A Study of Gradient Descent Schemes for General-Sum Stochastic Games"
            ]
        },
        {
            "id": "task1540-9617f9fd248f46ad8096a858985c0744",
            "input": "Training generative adversarial networks is unstable in high-dimensions when the true data distribution lies on a lower-dimensional manifold. The discriminator is then easily able to separate nearly all generated samples leaving the generator without meaningful gradients. We propose training a single generator simultaneously against an array of discriminators, each of which looks at a different random low-dimensional projection of the data. We show that individual discriminators then provide stable gradients to the generator, and that the generator learns to produce samples consistent with the full data distribution to satisfy all discriminators. We demonstrate the practical utility of this approach experimentally, and show that it is able to produce image samples with higher quality than traditional training with a single discriminator.",
            "output": [
                "Stabilizing GAN Training with Multiple Random Projections"
            ]
        },
        {
            "id": "task1540-c194f4f836a54546b6c9e3acbc78ed98",
            "input": "Transcription of broadcast news is an interesting and challenging application for large-vocabulary continuous speech recognition (LVCSR). We present in detail the structure of a manually segmented and annotated corpus including over 160 hours of German broadcast news, and propose it as an evaluation framework of LVCSR systems. We show our own experimental results on the corpus, achieved with a state-of-the-art LVCSR decoder, measuring the effect of different feature sets and decoding parameters, and thereby demonstrate that real-time decoding of our test set is feasible on a desktop PC at 9.2 % word error rate.",
            "output": [
                "A Broadcast News Corpus for Evaluation and Tuning of German LVCSR Systems"
            ]
        },
        {
            "id": "task1540-67a46a437946421b824a79b236d3d043",
            "input": "Spectral methods have greatly advanced the estimation of latent variable models, generating a sequence of novel and efficient algorithms with strong theoretical guarantees. However, current spectral algorithms are largely restricted to mixtures of discrete or Gaussian distributions. In this paper, we propose a kernel method for learning multi-view latent variable models, allowing each mixture component to be nonparametric. The key idea of the method is to embed the joint distribution of a multi-view latent variable into a reproducing kernel Hilbert space, and then the latent parameters are recovered using a robust tensor power method. We establish that the sample complexity for the proposed method is quadratic in the number of latent components and is a low order polynomial in the other relevant parameters. Thus, our non-parametric tensor approach to learning latent variable models enjoys good sample and computational efficiencies. Moreover, the non-parametric tensor power method compares favorably to EM algorithm and other existing spectral algorithms in our experiments.",
            "output": [
                "Nonparametric Estimation of Multi-View Latent Variable Models"
            ]
        },
        {
            "id": "task1540-717b0ef4dd7444eea5c5ddee9354539b",
            "input": "Proposed methods for prediction interval estimation so far focus on cases where input variables are numerical. In datasets with solely nominal input variables, we observe records with the exact same input x, but different real valued outputs due to the inherent noise in the system. Existing prediction interval estimation methods do not use representations that can accurately model such inherent noise in the case of nominal inputs. We propose a new prediction interval estimation method tailored for this type of data, which is prevalent in biology and medicine. We call this method Distribution Adaptive Prediction Interval Estimation given Nominal inputs (DAPIEN) and has four main phases. First, we select a distribution function that can best represent the inherent noise of the system for all unique inputs. Then we infer the parameters θi (e.g. θi = [meani, variancei]) of the selected distribution function for all unique input vectors xi and generate a new corresponding training set using pairs of xi , θi. III). Then, we train a model to predict θ given a new xu. Finally, we calculate the prediction interval for a new sample using the inverse of the cumulative distribution function once the parameters θ is predicted by the trained model. We compared DAPIEN to the commonly used Bootstrap method on three synthetic datasets. Our results show that DAPIEN provides tighter prediction intervals while preserving the requested coverage when compared to Bootstrap. This work can facilitate broader usage of regression methods in medicine and biology where it is necessary to provide tight prediction intervals while preserving coverage when input variables are nominal.",
            "output": [
                "DICTION INTERVAL ESTIMATION USING NOMINAL VARIABLES"
            ]
        },
        {
            "id": "task1540-483ac270a5c2438498ecac4e0203a0c9",
            "input": "This paper explores two separate questions: Can we perform natural language processing tasks without a lexicon?; and, Should we? Existing natural language processing techniques are either based on words as units or use units such as grams only for basic classification tasks. How close can a machine come to reasoning about the meanings of words and phrases in a corpus without using any lexicon, based only on grams? Our own motivation for posing this question is based on our efforts to find popular trends in words and phrases from online Chinese social media. This form of written Chinese uses so many neologisms, creative character placements, and combinations of writing systems that it has been dubbed the “Martian Language.” Readers must often use visual queues, audible queues from reading out loud, and their knowledge and understanding of current events to understand a post. For analysis of popular trends, the specific problem is that it is difficult to build a lexicon when the invention of new ways to refer to a word or concept is easy and common. For natural language processing in general, we argue in this paper that new uses of language in social media will challenge machines’ abilities to operate with words as the basic unit of understanding, not only in Chinese but potentially in other languages.",
            "output": [
                "Language Without Words: A Pointillist Model for Natural Language Processing"
            ]
        },
        {
            "id": "task1540-5ec1caf974ae4998b1e9ac35a8c6f7d9",
            "input": "Imputation of missing attribute values in medical datasets for extracting hidden knowledge from medical datasets is an interesting research topic of interest which is very challenging. One cannot eliminate missing values in medical records. The reason may be because some tests may not been conducted as they are cost effective, values missed when conducting clinical trials, values may not have been recorded to name some of the reasons. Data mining researchers have been proposing various approaches to find and impute missing values to increase classification accuracies so that disease may be predicted accurately. In this paper, we propose a novel imputation approach for imputation of missing values and performing classification after fixing missing values. The approach is based on clustering concept and aims at dimensionality reduction of the records. The case study discussed shows that missing values can be fixed and imputed efficiently by achieving dimensionality reduction. The importance of proposed approach for classification is visible in the case study which assigns single class label in contrary to multi-label assignment if dimensionality reduction is not performed. Keywords— imputation; missing values; prediction; nearest neighbor, cluster, medical records, dimensionality reduction",
            "output": [
                "An Innovative Imputation and Classification Approach for Accurate Disease Prediction"
            ]
        },
        {
            "id": "task1540-73444ce2013a40108d7709e3e222e474",
            "input": "Bilattice-based triangle provides an elegant algebraic structure for reasoning with vague and uncertain information. But the truth and knowledge ordering of intervals in bilattice-based triangle can not handle repetitive belief revisions which is an essential characteristic of nonmonotonic reasoning. Moreover the ordering induced over the intervals by the bilattice-based triangle is not sometimes intuitive. In this work, we construct an alternative algebraic structure, namely preorder-based triangle and we formulate proper logical connectives for this. It is an enhancement of the bilattice-based triangle to handle belief revision in nonmonotonic reasoning.",
            "output": [
                "Preorder-Based Triangle: A Modified Version of Bilattice-Based Triangle for Belief Revision in Nonmonotonic Reasoning"
            ]
        },
        {
            "id": "task1540-18109dbe577c411483837155e19d807a",
            "input": "Distributional semantic models learn vector representations of words through the contexts they occur in. Although the choice of context (which often takes the form of a sliding window) has a direct influence on the resulting embeddings, the exact role of this model component is still not fully understood. This paper presents a systematic analysis of context windows based on a set of four distinct hyperparameters. We train continuous SkipGram models on two English-language corpora for various combinations of these hyper-parameters, and evaluate them on both lexical similarity and analogy tasks. Notable experimental results are the positive impact of cross-sentential contexts and the surprisingly good performance of right-context windows.",
            "output": [
                "Redefining Context Windows for Word Embedding Models: An Experimental Study"
            ]
        },
        {
            "id": "task1540-98a4fdab8f0a4a11b7dbe6bb7709241a",
            "input": "We introduce a method to train Quantized Neural Networks (QNNs) — neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At traintime the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves 51% top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online. 1 ar X iv :1 60 9. 07 06 1v 1 [ cs .N E ] 2 2 Se p 20 16 Hubara, Courbariaux, Soudry, El-Yaniv and Bengio",
            "output": [
                "Quantized Neural Networks Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations"
            ]
        },
        {
            "id": "task1540-4595029c820f4d7c9571985c03d0e5d5",
            "input": "Nowadays, geographic information related to Twitter is crucially important for fine-grained applications. However, the amount of geographic information available on Twitter is low, which makes the pursuit of many applications challenging. Under such circumstances, estimating the location of a tweet is an important goal of the study. Unlike most previous studies that estimate the pre-defined district as the classification task, this study employs a probability distribution to represent richer information of the tweet, not only the location but also its ambiguity. To realize this modeling, we propose the convolutional mixture density network (CMDN), which uses text data to estimate the mixture model parameters. Experimentally obtained results reveal that CMDN achieved the highest prediction performance among the method for predicting the exact coordinates. It also provides a quantitative representation of the location ambiguity for each tweet that properly works for extracting the reliable location estimations.",
            "output": [
                "Density Estimation for Geolocation via Convolutional Mixture Density Network"
            ]
        },
        {
            "id": "task1540-146de8426df644888175bb65a874a918",
            "input": "Kernel-based clustering algorithms have the ability to capture the non-linear structure in real world data. Among various kernel-based clustering algorithms, kernel k -means has gained popularity due to its simple iterative nature and ease of implementation. However, its run-time complexity and memory footprint increase quadratically in terms of the size of the data set, and hence, large data sets cannot be clustered efficiently. In this paper, we propose an approximation scheme based on randomization, called the Approximate Kernel k-means. We approximate the cluster centers using the kernel similarity between a few sampled points and all the points in the data set. We show that the proposed method achieves better clustering performance than the traditional low rank kernel approximation based clustering schemes. We also demonstrate that it’s running time and memory requirements are significantly lower than those of kernel k -means, with only a small reduction in the clustering quality on several public domain large data sets. We then employ ensemble clustering techniques to further enhance the performance of our algorithm.",
            "output": [
                "Scalable Kernel Clustering: Approximate Kernel k -means"
            ]
        },
        {
            "id": "task1540-70c7650fbdb845d88416902195f732fa",
            "input": "With the popularity of massive open online courses (MOOCs), grading through crowdsourcing has become a prevalent approach towards large scale classes. However, for getting grades for complex tasks, which require specific skills and efforts for grading, crowdsourcing encounters a restriction of insufficient knowledge of the workers from the crowd. Due to knowledge limitation of the crowd graders, grading based on partial perspectives becomes a big challenge for evaluating complex tasks through crowdsourcing. Especially for those tasks which not only need specific knowledge for grading, but also should be graded as a whole instead of being decomposed into smaller and simpler sub-tasks. We propose a framework for grading complex tasks via multiple views, which are different grading perspectives defined by experts for the task, to provide uniformity. Aggregation algorithm based on graders’ variances are used to combine the grades for each view. We also detect bias patterns of the graders, and de-bias them regarding each view of the task. Bias pattern determines how the behavior is biased among graders, which is detected by a statistical technique. The proposed approach is analyzed on a synthetic data set. We show that our model gives more accurate results compared to the grading approaches without different views and de-biasing algorithm. Keywords—complex task; crowdsourcing; view; bias pattern; debias; Vancouver algorithm",
            "output": [
                "Evaluating Complex Task through Crowdsourcing: Multiple Views Approach"
            ]
        },
        {
            "id": "task1540-c8491bcfacfb405da344842dff991cc3",
            "input": "The project of the Ontology Web Search Engine is presented in this paper. The main purpose of this paper is to develop such a project that can be easily implemented. Ontology Web Search Engine is software to look for and index ontologies in the Web. OWL (Web Ontology Languages) ontologies are meant, and they are necessary for the functioning of the SWES (Semantic Web Expert System). SWES is an expert system that will use found ontologies from the Web, generating rules from them, and will supplement its knowledge base with these generated rules. It is expected that the SWES will serve as a universal expert system for the average user.",
            "output": [
                "TOWARDS THE ONTOLOGY WEB SEARCH ENGINE"
            ]
        },
        {
            "id": "task1540-ddb571fcfed74277b06676d2284565a1",
            "input": "With the rise of big data sets, the popularity of kernel methods declined and neural networks took over again. The main problem with kernel methods is that the kernel matrix grows quadratically with the number of data points. Most attempts to scale up kernel methods solve this problem by discarding data points or basis functions of some approximation of the kernel map. Here we present a simple yet effective alternative for scaling up kernel methods that takes into account the entire data set via doubly stochastic optimization of the emprical kernel map. The algorithm is straightforward to implement, in particular in parallel execution settings; it leverages the full power and versatility of classical kernel functions without the need to explicitly formulate a kernel map approximation. We provide empirical evidence that the algorithm works on large data sets.",
            "output": [
                "Doubly stochastic large scale kernel learning with the empirical kernel map"
            ]
        },
        {
            "id": "task1540-ee9db39feb5346f5a38dd5cc47935e3b",
            "input": "Since its inception, the modus operandi of multi-task learning (MTL) has been to minimize the task-wise mean of the empirical risks. We introduce a generalized loss-compositional paradigm for MTL that includes a spectrum of formulations as a subfamily. One endpoint of this spectrum is minimax MTL: a new MTL formulation that minimizes the maximum of the tasks’ empirical risks. Via a certain relaxation of minimax MTL, we obtain a continuum of MTL formulations spanning minimax MTL and classical MTL. The full paradigm itself is loss-compositional, operating on the vector of empirical risks. It incorporates minimax MTL, its relaxations, and many new MTL formulations as special cases. We show theoretically that minimax MTL tends to avoid worst case outcomes on newly drawn test tasks in the learning to learn (LTL) test setting. The results of several MTL formulations on synthetic and real problems in the MTL and LTL test settings are encouraging.",
            "output": [
                "Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL"
            ]
        },
        {
            "id": "task1540-728e142eb33b4a31b29a64403205d64c",
            "input": "Interactive topic models are powerful tools for those seeking to understand large collections of text. However, existing sampling-based interactive topic modeling approaches scale poorly to large data sets. Anchor methods, which use a single word to uniquely identify a topic, offer the speed needed for interactive work but lack both a mechanism to inject prior knowledge and lack the intuitive semantics needed for user-facing applications. We propose combinations of words as anchors, going beyond existing single word anchor algorithms—an approach we call “Tandem Anchors”. We begin with a synthetic investigation of this approach then apply the approach to interactive topic modeling in a user study and compare it to interactive and non-interactive approaches. Tandem anchors are faster and more intuitive than existing interactive approaches. Topic models distill large collections of text into topics, giving a high-level summary of the thematic structure of the data without manual annotation. In addition to facilitating discovery of topical trends (Gardner et al., 2010), topic modeling is used for a wide variety of problems including document classification (Rubin et al., 2012), information retrieval (Wei and Croft, 2006), author identification (Rosen-Zvi et al., 2004), and sentiment analysis (Titov and McDonald, 2008). However, the most compelling use of topic models is to help users understand large datasets (Chuang et al., 2012). Interactive topic modeling (Hu et al., 2014) allows non-experts to refine automatically generated topics, making topic models less of a “take it or leave it” proposition. Including humans input during training improves the quality of the model and allows users to guide topics in a specific way, custom tailoring the model for a specific downstream task or analysis. The downside is that interactive topic modeling is slow—algorithms typically scale with the size of the corpus—and requires non-intuitive information from the user in the form of must-link and cannot-link constraints (Andrzejewski et al., 2009). We address these shortcomings of interactive topic modeling by using an interactive version of the anchor words algorithm for topic models. The anchor algorithm (Arora et al., 2013) is an alternative topic modeling algorithm which scales with the number of unique word types in the data rather than the number of documents or tokens (Section 1). This makes the anchor algorithm fast enough for interactive use, even in web-scale document collections. A drawback of the anchor method is that anchor words—words that have high probability of being in a single topic—are not intuitive. We extend the anchor algorithm to use multiple anchor words in tandem (Section 2). Tandem anchors not only improve interactive refinement, but also make the underlying anchor-based method more intuitive. For interactive topic modeling, tandem anchors produce higher quality topics than single word anchors (Section 3). Tandem anchors provide a framework for fast interactive topic modeling: users improve and refine an existing model through multiword anchors (Section 4). Compared to existing methods such as Interactive Topic Models (Hu et al., 2014), our method is much faster.",
            "output": [
                "Tandem Anchoring: a Multiword Anchor Approach for Interactive Topic Modeling"
            ]
        },
        {
            "id": "task1540-c4eb7660bea9426a90d88e4cecb959b8",
            "input": "We investigate the direct-sum problem in the context of differentially private PAC learning: What<lb>is the sample complexity of solving k learning tasks simultaneously under differential privacy, and how<lb>does this cost compare to that of solving k learning tasks without privacy? In our setting, an individual<lb>example consists of a domain element x labeled by k unknown concepts (c1, . . . ,<lb>ck). The goal of a<lb>multi-learner is to output k hypotheses (h1, . . . , hk) that generalize the input examples.<lb>Without concern for privacy, the sample complexity needed to simultaneously learn k concepts is<lb>essentially the same as needed for learning a single concept. Under differential privacy, the basic strategy<lb>of learning each hypothesis independently yields sample complexity that grows polynomially with k.<lb>For some concept classes, we give multi-learners that require fewer samples than the basic strategy.<lb>Unfortunately, however, we also give lower bounds showing that even for very simple concept classes,<lb>the sample cost of private multi-learning must grow polynomially in k.",
            "output": [
                "Simultaneous Private Learning of Multiple Concepts"
            ]
        },
        {
            "id": "task1540-e05eaf6f889e45298edb11da7b5e89cf",
            "input": "Causal inference from observational data is a subject of active research and development in statistics and computer science. Many toolkits have been developed for this purpose that depends on statistical software. However, these toolkits do not scale to large datasets. In this paper we describe a suite of techniques for expressing causal inference tasks from observational data in SQL. This suite supports the state-ofthe-art methods for causal inference and run at scale within a database engine. In addition, we introduce several optimization techniques that significantly speedup causal inference, both in the online and offline setting. We evaluate the quality and performance of our techniques by experiments of real datasets.",
            "output": [
                "ZaliQL: A SQL-Based Framework for Drawing Causal Inference from Big Data"
            ]
        },
        {
            "id": "task1540-7f985d3ae38f4c5f9c046308d26d4437",
            "input": "The inclusion problem deals with how to characterize (in graphical terms) whether all independence statements in the model in­ duced by a DAG K are in the model induced by a second DAG L. Meek (1997) conjec­ tured that this inclusion holds iff there exists a sequence of DAGs from L to K such that only certain 'legal' arrow reversal and 'legal' arrow adding operations are performed to get the next DAG in the sequence. In this paper we give several characterizations of inclusion of DAG models and verify Meek's conjecture in the case that the DAGs K and L differ in at most one adjacency. As a warming up a rigorous proof of graphical characterizations of equivalence of DAGs is given.",
            "output": [
                "On characterizing Inclusion of Bayesian Networks"
            ]
        },
        {
            "id": "task1540-201f888ab28f42a5a831ae1a3462ea5d",
            "input": "1 Ranks, processes and flat grammar ....................................................................................... 2 2 The Rank-Interpretation Architecture for Multilinear Grammars ......................................... 6 2.1 Outline of the Rank-Interpretation Architecture framework .............................................. 6 2.2 A preliminary note on linearity and hierarchy at the phrasal rank ..................................... 7 2.3 Characterisation of the Rank-Interpretation Architecture .................................................. 9 2.3.1 Background ..................................................................................................................... 9 2.3.2 Formal summary ........................................................................................................... 10 2.3.3 Contrast with traditional views of language architecture .............................................. 11 2.3.4 Search for sui generis properties of ranks ..................................................................... 11 2.4 Procedural perspectives on the rank hierarchy ................................................................. 12 3 The discourse rank .............................................................................................................. 15 3.1 The primacy of discourse patterning ................................................................................ 15 3.2 Intonation of an adjacency pair ........................................................................................ 16 3.3 Chanted ‘call’ intonation .................................................................................................. 18 4 The utterance or text rank ................................................................................................... 20 5 The phrase rank ................................................................................................................... 22 5.1 Characteristics of phrasal structure .................................................................................. 22 5.2 Linear sequences, iteration: regular and subregular grammars ........................................ 23 5.3 A note on long-distance and cross-serial dependencies ................................................... 26 5.4 Prosodic-phonetic interpretation at the phrasal rank ........................................................ 27 6 The word rank ..................................................................................................................... 30 6.1 Flat words ......................................................................................................................... 30 6.2 Flat derivations ................................................................................................................. 30 6.3 Flat compounds ................................................................................................................ 31 6.4 Prosodic-phonetic interpretation at the word rank ........................................................... 31 7 Summary and conclusion .................................................................................................... 33 7.1 From Duality to Multilinear Grammar and Rank Interpretation Architecture ................. 33 7.2 Generalisation to stochastic flat linear models ................................................................. 34 7.3 Future work ...................................................................................................................... 35 8 References ........................................................................................................................... 36",
            "output": [
                "Multilinear Grammar: Ranks and Interpretations"
            ]
        },
        {
            "id": "task1540-2b61157550624df485f6f68e47a16599",
            "input": "Biological neural networks are systems of extraordinary computational capabilities shaped by evolution, development, and lifetime learning. The interplay of these elements leads to the emergence of adaptive behavior and intelligence, but the complexity of the whole system of interactions is an obstacle to the understanding of the key factors at play. Inspired by such intricate natural phenomena, Evolved Plastic Artificial Neural Networks (EPANNs) use simulated evolution in-silico to breed plastic neural networks, artificial systems composed of sensors, outputs, and plastic components that change in response to sensory-output experiences in an environment. These systems may reveal key algorithmic ingredients of adaptation, autonomously discover novel adaptive algorithms, and lead to hypotheses on the emergence of biological adaptation. EPANNs have seen considerable progress over the last two decades. Current scientific and technological advances in artificial neural networks are now setting the conditions for radically new approaches and results. In particular, the limitations of hand-designed structures and algorithms currently used in most deep neural networks could be overcome by more flexible and innovative solutions. This paper brings together a variety of inspiring ideas that define the field of EPANNs. The main computational methods and results are reviewed. Finally, new opportunities and developments are presented.",
            "output": [
                "Born to Learn: the Inspiration, Progress, and Future of Evolved Plastic Artificial Neural Networks"
            ]
        },
        {
            "id": "task1540-913b614c8f934afabbab880eeefc8d4d",
            "input": "We describe a simple scheme that allows an agent to explore its environment in an unsupervised manner. Our scheme pits two versions of the same agent, Alice and Bob, against one another. Alice proposes a task for Bob to complete; and then Bob attempts to complete the task. In this work we will focus on (nearly) reversible environments, or environments that can be reset, and Alice will “propose” the task by running a set of actions and then Bob must partially undo, or repeat them, respectively. Via an appropriate reward structure, Alice and Bob automatically generate a curriculum of exploration, enabling unsupervised training of the agent. When deployed on an RL task within the environment, this unsupervised training reduces the number of episodes needed to learn.",
            "output": [
                "Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play"
            ]
        },
        {
            "id": "task1540-46b220a6abb343039287e5001e0643e0",
            "input": "We present an approach for the detection of coordinateterm relationships between entities from the software domain, that refer to Java classes. Usually, relations are found by examining corpus statistics associated with text entities. In some technical domains, however, we have access to additional information about the real-world objects named by the entities, suggesting that coupling information about the “grounded” entities with corpus statistics might lead to improved methods for relation discovery. To this end, we develop a similarity measure for Java classes using distributional information about how they are used in software, which we combine with corpus statistics on the distribution of contexts in which the classes appear in text. Using our approach, cross-validation accuracy on this dataset can be improved dramatically, from around 60% to 88%. Human labeling results show that our classifier has an F1 score of 86% over the top 1000 predicted pairs.",
            "output": [
                "Grounded Discovery of Coordinate Term Relationships between Software Entities"
            ]
        },
        {
            "id": "task1540-2b51c1c96a044df58beba28fc537cd0b",
            "input": "The multi-armed bandit problem (MBP) is the problem of finding, as accurately and quickly as possible, the most profitable option from a set of options that gives stochastic rewards by referring to past experiences. Inspired by fluctuated movements of a rigid body in a tug-of-war game, we formulated a unique search algorithm that we call the ‘tug-of-war (TOW) dynamics’ for solving the MBP efficiently [1-5]. The cognitive medium access, which refers to multiuser channel allocations in cognitive radio, can be interpreted as the competitive multi-armed bandit problem (CMBP); the problem is to determine the optimal strategy for allocating channels to users which yields maximum total rewards gained by all users [6]. Here we show that it is possible to construct a physical device for solving the CMBP, which we call the ‘TOW Bombe’, by exploiting the TOW dynamics existed in coupled incompressible-fluid cylinders. This analog computing device achieves the ‘socially-maximum’ resource allocation that maximizes the total rewards in cognitive medium access without paying a huge computational cost that grows exponentially as a function of the problem size.",
            "output": [
                "Decision Maker using Coupled Incompressible-Fluid Cylinders"
            ]
        },
        {
            "id": "task1540-4cfcbaf9643e4c97b7e617c990a35580",
            "input": "In the data mining field many clustering methods have been proposed, yet standard versions do not take into account uncertain databases. This paper deals with a new approach to cluster uncertain data by using a hierarchical clustering defined within the belief function framework. The main objective of the belief hierarchical clustering is to allow an object to belong to one or several clusters. To each belonging, a degree of belief is associated, and clusters are combined based on the pignistic properties. Experiments with real uncertain data show that our proposed method can be considered as a propitious tool.",
            "output": [
                "Belief Hierarchical Clustering"
            ]
        },
        {
            "id": "task1540-7486bed4c54742a2b0121a9b73e3502e",
            "input": "We address a problem of area protection in graphbased scenarios with multiple mobile agents where connectivity is maintained among agents to ensure they can communicate. The problem consists of two adversarial teams of agents that move in an undirected graph shared by both teams. Agents are placed in vertices of the graph; at most one agent can occupy a vertex; and they can move into adjacent vertices in a conflict free way. Teams have asymmetric goals: the aim of one team attackers is to invade into given area while the aim of the opponent team defenders is to protect the area from being entered by attackers by occupying selected vertices. The team of defenders need to maintain connectivity of vertices occupied by its own agents in a visibility graph. The visibility graph models possibility of communication between pairs of vertices. We study strategies for allocating vertices to be occupied by the team of defenders to block attacking agents where connectivity is maintained at the same time. To do this we reserve a subset of defending agents that do not try to block the attackers but instead are placed to support connectivity of the team. The performance of strategies is tested in multiple benchmarks. The success of a strategy is heavily dependent on the type of the instance, and so one of the contributions of this work is that we identify suitable strategies for diverse instance types.",
            "output": [
                "Maintaining Ad-Hoc Communication Network in Area Protection Scenarios with Adversarial Agents"
            ]
        },
        {
            "id": "task1540-dd5a177ec9be45809845a4189cd03ccd",
            "input": "We study the properties of common loss surfaces through their Hessian matrix. In particular, in the context of deep learning, we empirically show that the spectrum of the Hessian is composed of two parts: (1) the bulk centered near zero, (2) and outliers away from the bulk. We present numerical evidence and mathematical justifications to the following conjectures laid out by Sagun et al. [2016]: Fixing data, increasing the number of parameters merely scales the bulk of the spectrum; fixing the dimension and changing the data (for instance adding more clusters or making the data less separable) only affects the outliers. We believe that our observations have striking implications for non-convex optimization in high dimensions. First, the flatness of such landscapes (which can be measured by the singularity of the Hessian) implies that classical notions of basins of attraction may be quite misleading. And that the discussion of wide/narrow basins may be in need of a new perspective around over-parametrization and redundancy that are able to create large connected components at the bottom of the landscape. Second, the dependence of small number of large eigenvalues to the data distribution can be linked to the spectrum of the covariance matrix of gradients of model outputs. With this in mind, we may reevaluate the connections within the data-architecturealgorithm framework of a model, hoping that it would shed light into the geometry of high-dimensional and non-convex spaces in modern applications. In particular, we present a case that links the two observations: a gradient based method appears to be first climbing uphill and then falling downhill between two points; whereas, in fact, they lie in the same basin.",
            "output": [
                "Empirical Analysis of the Hessian of Over-Parametrized Neural Networks"
            ]
        },
        {
            "id": "task1540-286810855d614f0ab7eac202a91035ba",
            "input": "The development of methods to deal with the informative contents of the text units in the matching process is a major challenge in automatic summary evaluation systems that use fixed n-gram matching. The limitation causes inaccurate matching between units in a peer and reference summaries. The present study introduces a new Keyphrase based Summary Evaluator (KpEval) for evaluating automatic summaries. The KpEval relies on the keyphrases since they convey the most important concepts of a text. In the evaluation process, the keyphrases are used in their lemma form as the matching text unit. The system was applied to evaluate different summaries of Arabic multi-document data set presented at TAC2011. The results showed that the new evaluation technique correlates well with the known evaluation systems: Rouge-1, Rouge-2, Rouge-SU4, and AutoSummENG–MeMoG. KpEval has the strongest correlation with AutoSummENG–MeMoG, Pearson and spearman correlation coefficient measures are 0.8840, 0.9667 respectively. General Terms Automatic summary evaluation, Automatic summarization, Keyphrase extraction, Natural language processing, computational linguistics, Information retrieval.",
            "output": [
                "Keyphrase based Evaluation of Automatic Text Summarization"
            ]
        },
        {
            "id": "task1540-85dd973c254c4ea7bdd3387bdd81e8f1",
            "input": "We extend the theory of boosting for regression problems to the online learning setting. Generalizing from the batch setting for boosting, the notion of a weak learning algorithm is modeled as an online learning algorithm with linear loss functions that competes with a base class of regression functions, while a strong learning algorithm is an online learning algorithm with smooth convex loss functions that competes with a larger class of regression functions. Our main result is an online gradient boosting algorithm that converts a weak online learning algorithm into a strong one where the larger class of functions is the linear span of the base class. We also give a simpler boosting algorithm that converts a weak online learning algorithm into a strong one where the larger class of functions is the convex hull of the base class, and prove its optimality.",
            "output": [
                "Online Gradient Boosting"
            ]
        },
        {
            "id": "task1540-ac30685f74ed45b580567da05f1266ba",
            "input": "Gaussian processes are rich distributions over functions, which provide a Bayesian nonparametric approach to smoothing and interpolation. We introduce simple closed form kernels that can be used with Gaussian processes to discover patterns and enable extrapolation. These kernels are derived by modelling a spectral density – the Fourier transform of a kernel – with a Gaussian mixture. The proposed kernels support a broad class of stationary covariances, but Gaussian process inference remains simple and analytic. We demonstrate the proposed kernels by discovering patterns and performing long range extrapolation on synthetic examples, as well as atmospheric CO2 trends and airline passenger data. We also show that we can reconstruct standard covariances within our framework.",
            "output": [
                "Gaussian Process Covariance Kernels for Pattern Discovery and Extrapolation"
            ]
        },
        {
            "id": "task1540-b6a09d61b5654ba3aa6559bcbe1d5c05",
            "input": "Accurate software development effort estimation is critical to the success of software projects. Although many techniques and algorithmic models have been developed and implemented by practitioners, accurate software development effort prediction is still a challenging endeavor in the field of software engineering, especially in handling uncertain and imprecise inputs and collinear characteristics. In this paper, a hybrid intelligent model combining a neural network model integrated with fuzzy model (neuro-fuzzy model) has been used to improve the accuracy of estimating software cost. The performance of the proposed model is assessed by designing and conducting evaluation with published project and industrial data. Results have shown that the proposed model demonstrates the ability of improving the estimation accuracy by 18% based on the Mean Magnitude of Relative Error (MMRE) criterion.",
            "output": [
                "A HYBRID INTELLIGENT MODEL FOR SOFTWARE COST ESTIMATION"
            ]
        },
        {
            "id": "task1540-3006bbb7bcfc41d4a8c032d998d3f487",
            "input": "We first observe a potential weakness of continuous vector representations of symbols in neural machine translation. That is, the continuous vector representation, or a word embedding vector, of a symbol encodes multiple dimensions of similarity, equivalent to encoding more than one meaning of the word. This has the consequence that the encoder and decoder recurrent networks in neural machine translation need to spend substantial amount of their capacity in disambiguating source and target words based on the context which is defined by a source sentence. Based on this observation, in this paper we propose to contextualize the word embedding vectors using a nonlinear bag-of-words representation of the source sentence. Additionally, we propose to represent special tokens (such as numbers, proper nouns and acronyms) with typed symbols to facilitate translating those words that are not well-suited to be translated via continuous vectors. The experiments on En-Fr and En-De reveal that the proposed approaches of contextualization and symbolization improves the translation quality of neural machine translation systems significantly.",
            "output": [
                "Context-Dependent Word Representation for Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-d31d097cf6984810969d599b0720b500",
            "input": "We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.",
            "output": [
                "Improved Techniques for Training GANs"
            ]
        },
        {
            "id": "task1540-cb40e0150ead4f7fa1641f9fd491e35b",
            "input": "Sarcasm occurring due to the presence of numerical portions in text has been quoted as an error made by automatic sarcasm detection approaches in the past. We present a first study in detecting sarcasm in numbers, as in the case of the sentence ‘Love waking up at 4 am’. We analyze the challenges of the problem, and present Rulebased, Machine Learning and Deep Learning approaches to detect sarcasm in numerical portions of text. Our Deep Learning approach outperforms four past works for sarcasm detection and Rule-based and Machine learning approaches on a dataset of tweets, obtaining an F1-score of 0.93. This shows that special attention to text containing numbers may be useful to improve state-of-the-art in sarcasm detection.",
            "output": [
                "“Having 2 hours to write a paper is fun!”: Detecting Sarcasm in Numerical Portions of Text"
            ]
        },
        {
            "id": "task1540-7a289acba635489b9e4819ad9744fe48",
            "input": "Toby Walsh in “The Singularity May Never Be Near” gives six arguments to support his point of view that technological singularity may happen but that it is unlikely. In this paper, we provide analysis of each one of his arguments and arrive at similar conclusions, but with more weight given to the “likely to happen” probability.",
            "output": [
                "The Singularity May Be Near"
            ]
        },
        {
            "id": "task1540-58f00837e55242db992d6b1ce0334b1d",
            "input": "Rapid crisis response requires real-time analysis of messages. After a disaster happens, volunteers attempt to classify tweets to determine needs, e.g., supplies, infrastructure damage, etc. Given labeled data, supervised machine learning can help classify these messages. Scarcity of labeled data causes poor performance in machine training. Can we reuse old tweets to train classifiers? How can we choose labeled tweets for training? Specifically, we study the usefulness of labeled data of past events. Do labeled tweets in different language help? We observe the performance of our classifiers trained using different combinations of training sets obtained from past disasters. We perform extensive experimentation on real crisis datasets and show that the past labels are useful when both source and target events are of the same type (e.g. both earthquakes). For similar languages (e.g., Italian and Spanish), cross-language domain adaptation was useful, however, when for different languages (e.g., Italian and English), the performance decreased.",
            "output": [
                "Cross-Language Domain Adaptation for Classifying Crisis-Related Short Messages"
            ]
        },
        {
            "id": "task1540-8e013171c89340bea6a56df2920baa68",
            "input": "Recurrent Neural Networks (RNN) have recently achieved the best performance in off-line Handwriting Text Recognition. At the same time, learning RNN by gradient descent leads to slow convergence, and training times are particularly long when the training database consists of full lines of text. In this paper, we propose an easy way to accelerate stochastic gradient descent in this set-up, and in the general context of learning to recognize sequences. The principle is called Curriculum Learning, or shaping. The idea is to first learn to recognize short sequences before training on all available training sequences. Experiments on three different handwritten text databases (Rimes, IAM, OpenHaRT) show that a simple implementation of this strategy can significantly speed up the training of RNN for Text Recognition, and even significantly improve performance in some cases.",
            "output": [
                "Curriculum Learning for Handwritten Text Line Recognition"
            ]
        },
        {
            "id": "task1540-d34382504c0b49b38b1760955408ce25",
            "input": "Methods of deep machine learning enable to to reuse low-level representations efficiently for generating more abstract high-level representations. Originally, deep learning has been applied passively (e.g., for classification purposes). Recently, it has been extended to estimate the value of actions for autonomous agents within the framework of reinforcement learning (RL). Explicit models of the environment can be learned to augment such a value function. Although “flat” connectionist methods have already been used for model-based RL, up to now, only modelfree variants of RL have been equipped with methods from deep learning. We propose a variant of deep model-based RL that enables an agent to learn arbitrarily abstract hierarchical representations of its environment. In this paper, we present research on how such hierarchical representations can be grounded in sensorimotor interaction between an agent and its environment.",
            "output": [
                "Grounding Hierarchical Reinforcement Learning Models for Knowledge Transfer"
            ]
        },
        {
            "id": "task1540-da91c63dc32a4ca3a9b85b4b52139ab9",
            "input": "We propose Edward, a Turing-complete probabilistic programming language. Edward defines two compositional representations—random variables and inference. By treating inference as a first class citizen, on a par with modeling, we show that probabilistic programming can be as flexible and computationally efficient as traditional deep learning. For flexibility, Edward makes it easy to fit the same model using a variety of composable inference methods, ranging from point estimation to variational inference to MCMC. In addition, Edward can reuse the modeling representation as part of inference, facilitating the design of rich variational models and generative adversarial networks. For efficiency, Edward is integrated into TensorFlow, providing significant speedups over existing probabilistic systems. For example, we show on a benchmark logistic regression task that Edward is at least 35x faster than Stan and 6x faster than PyMC3. Further, Edward incurs no runtime overhead: it is as fast as handwritten TensorFlow.",
            "output": [
                "DEEP PROBABILISTIC PROGRAMMING"
            ]
        },
        {
            "id": "task1540-4acdc3c10c0e4a88aba158f31b314cdf",
            "input": "Deriving prior polarity lexica for sentiment analysis – where positive or negative scores are associated with words out of context – is a challenging task. Usually, a trade-off between precision and coverage is hard to find, and it depends on the methodology used to build the lexicon. Manually annotated lexica provide a high precision but lack in coverage, whereas automatic derivation from pre-existing knowledge guarantees high coverage at the cost of a lower precision. Since the automatic derivation of prior polarities is less time consuming than manual annotation, there has been a great bloom of these approaches, in particular based on the SentiWordNet resource. In this paper, we compare the most frequently used techniques based on SentiWordNet with newer ones and blend them in a learning framework (a so called ‘ensemble method’). By taking advantage of manually built prior polarity lexica, our ensemble method is better able to predict the prior value of unseen words and to outperform all the other SentiWordNet approaches. Using this technique we have built SentiWords, a prior polarity lexicon of approximately 155,000 words, that has both a high precision and a high coverage. We finally show that in sentiment analysis tasks, using our lexicon allows us to outperform both the single metrics derived from SentiWordNet and popular manually annotated sentiment lexica.",
            "output": [
                "SentiWords: Deriving a High Precision and High Coverage Lexicon for Sentiment Analysis"
            ]
        },
        {
            "id": "task1540-b076cccaad484d1b902fb7c1a7bc6978",
            "input": "The logistic loss function is often advocated in machine learning and statistics as a smooth and strictly convex surrogate for the 0-1 loss. In this paper we investigate the question of whether these smoothness and convexity properties make the logistic loss preferable to other widely considered options such as the hinge loss. We show that in contrast to known asymptotic bounds, as long as the number of prediction/optimization iterations is sub exponential, the logistic loss provides no improvement over a generic non-smooth loss function such as the hinge loss. In particular we show that the convergence rate of stochastic logistic optimization is bounded from below by a polynomial in the diameter of the decision set and the number of prediction iterations, and provide a matching tight upper bound. This resolves the COLT open problem of McMahan and Streeter (2012).",
            "output": [
                "Logistic Regression: Tight Bounds for Stochastic and Online Optimization∗"
            ]
        },
        {
            "id": "task1540-1a5ca36713c94a07af0dc549374a51db",
            "input": "The first ever human vs. computer no-limit Texas hold ’em competition took place from April 24– May 8, 2015 at River’s Casino in Pittsburgh, PA. In this article I present my thoughts on the competition design, agent architecture, and lessons learned.",
            "output": [
                "My Reflections on the First Man vs. Machine No-Limit Texas Hold ’em Competition∗"
            ]
        },
        {
            "id": "task1540-c6d4986b2e7144b8a933211de53c84a0",
            "input": "We study several questions in the reliable agnostic learning framework of Kalai et al. (2009), which captures learning tasks in which one type of error is costlier than other types. A positive reliable classifier is one that makes no false positive errors. The goal in the positive reliable agnostic framework is to output a hypothesis with the following properties: (i) its false positive error rate is at most ǫ, (ii) its false negative error rate is at most ǫ more than that of the best positive reliable classifier from the class. A closely related notion is fully reliable agnostic learning, which considers partial classifiers that are allowed to predict “unknown” on some inputs. The best fully reliable partial classifier is one that makes no errors and minimizes the probability of predicting “unknown”, and the goal in fully reliable learning is to output a hypothesis that is almost as good as the best fully reliable partial classifier from a class. For distribution-independent learning, the best known algorithms for PAC learning typically utilize polynomial threshold representations, while the state of the art agnostic learning algorithms use pointwise polynomial approximations. We show that one-sided polynomial approximations, an intermediate notion between polynomial threshold representations and point-wise polynomial approximations, suffice for learning in the reliable agnostic settings. We then show that majorities can be fully reliably learned and disjunctions of majorities can be positive reliably learned, through constructions of appropriate onesided polynomial approximations. Our fully reliable algorithm for majorities provides the first evidence that fully reliable learning may be strictly easier than agnostic learning. Our algorithms also satisfy strong attribute-efficiency properties, and in many cases they provide smooth tradeoffs between sample complexity and running time. University of California, Berkeley. Email: vkanade@eecs.berkeley.edu The Simons Institute for the Theory of Computing at UC Berkeley. Email: jthaler@seas.harvard.edu",
            "output": [
                "Distribution-Independent Reliable Learning"
            ]
        },
        {
            "id": "task1540-3bb53b6c282849d88748787e8f3a1a29",
            "input": "Can one parallelize complex exploration– exploitation tradeoffs? As an example, consider the problem of optimal highthroughput experimental design, where we wish to sequentially design batches of experiments in order to simultaneously learn a surrogate function mapping stimulus to response and identify the maximum of the function. We formalize the task as a multiarmed bandit problem, where the unknown payoff function is sampled from a Gaussian process (GP), and instead of a single arm, in each round we pull a batch of several arms in parallel. We develop GP-BUCB, a principled algorithm for choosing batches, based on the GP-UCB algorithm for sequential GP optimization. We prove a surprising result; as compared to the sequential approach, the cumulative regret of the parallel algorithm only increases by a constant factor independent of the batch size B. Our results provide rigorous theoretical support for exploiting parallelism in Bayesian global optimization. We demonstrate the effectiveness of our approach on two real-world applications.",
            "output": [
                "Parallelizing Exploration–Exploitation Tradeoffs with Gaussian Process Bandit Optimization"
            ]
        },
        {
            "id": "task1540-3064d771bbc2482b8b5912c8ccec0824",
            "input": "Learning useful information across long time lags is a critical and difficult problem for temporal neural models in tasks like language modeling. Existing architectures that address the issue are often complex and costly to train. The Delta Recurrent Neural Network (Delta-RNN) framework is a simple and highperforming design that unifies previously proposed gated neural models. The DeltaRNN models maintain longer-term memory by learning to interpolate between a fast-changing data-driven representation and a slowly changing, implicitly stable state. This requires hardly any more parameters than a classical simple recurrent network. The models outperform popular complex architectures, such as the Long Short Term Memory (LSTM) and the Gated Recurrent Unit (GRU) and achieve state-of-the art performance in language modeling at character and word levels and yield comparable performance at the subword level.",
            "output": [
                "Learning Simpler Language Models with the Delta Recurrent Neural Network Framework"
            ]
        },
        {
            "id": "task1540-35aa6f842f714be3a8651b3096bcd60d",
            "input": "Answer Set Programming (ASP) is a well-established formalism for nonmonotonic reasoning. An ASP program can have no answer set due to cyclic default negation. In this case, it is not possible to draw any conclusion, even if this is not intended. Recently, several paracoherent semantics have been proposed that address this issue, and several potential applications for these semantics have been identified. However, paracoherent semantics have essentially been inapplicable in practice, due to the lack of efficient algorithms and implementations. In this paper, this lack is addressed, and several different algorithms to compute semi-stable and semi-equilibrium models are proposed and implemented into an answer set solving framework. An empirical performance comparison among the new algorithms on benchmarks from ASP competitions is given as well.",
            "output": [
                "On the Computation of Paracoherent Answer Sets"
            ]
        },
        {
            "id": "task1540-af0e8e5c5e0e4a87baf424a337bc6a67",
            "input": "Deep neural nets have caused a revolution in many classification tasks. A related ongoing revolution—also theoretically not understood—concerns their ability to serve as generative models for complicated types of data such as images and texts. These models are trained using ideas like variational autoencoders and Generative Adversarial Networks. We take a first cut at explaining the expressivity of multilayer nets by giving a sufficient criterion for a function to be approximable by a neural network with n hidden layers. A key ingredient is Barron’s Theorem [Bar93], which gives a Fourier criterion for approximability of a function by a neural network with 1 hidden layer. We show that a composition of n functions which satisfy certain Fourier conditions (“Barron functions”) can be approximated by a n+ 1layer neural network. For probability distributions, this translates into a criterion for a probability distribution to be approximable in Wasserstein distance—a natural metric on probability distributions—by a neural network applied to a fixed base distribution (e.g., multivariate gaussian). Building up recent lower bound work, we also give an example function that shows that composition of Barron functions is more expressive than Barron functions alone.",
            "output": [
                "On the ability of neural nets to express distributions"
            ]
        },
        {
            "id": "task1540-4f59a1c60f2543478f2d8b0dd2eac0bc",
            "input": "This paper presents the computational logic foundations of a model of agency called the KGP (Knowledge, Goals and Plan) model. This model allows the specification of heterogeneous agents that can interact with each other, and can exhibit both proactive and reactive behaviour allowing them to function in dynamic environments by adjusting their goals and plans when changes happen in such environments. KGP provides a highly modular agent architecture that integrates a collection of reasoning and physical capabilities, synthesised within transitions that update the agent’s state in response to reasoning, sensing and acting. Transitions are orchestrated by cycle theories that specify the order in which transitions are executed while taking into account the dynamic context and agent preferences, as well as selection operators for providing inputs to transitions.",
            "output": [
                "Computational Logic Foundations of KGP Agents"
            ]
        },
        {
            "id": "task1540-c1df32c07d1c458db9907a3faf643c63",
            "input": "The proximal problem for structured penalties obtained via convex relaxations of submodular functions is known to be equivalent to minimizing separable convex functions over the corresponding submodular polyhedra. In this paper, we reveal a comprehensive class of structured penalties for which penalties this problem can be solved via an efficiently solvable class of parametric maxflow optimization. We then show that the parametric maxflow algorithm proposed by Gallo et al. [17] and its variants, which runs, in the worst-case, at the cost of only a constant factor of a single computation of the corresponding maxflow optimization, can be adapted to solve the proximal problems for those penalties. Several existing structured penalties satisfy these conditions; thus, regularized learning with these penalties is solvable quickly using the parametric maxflow algorithm. We also investigate the empirical runtime performance of the proposed framework.",
            "output": [
                "Parametric Maxflows for Structured Sparse Learning with Convex Relaxations of Submodular Functions"
            ]
        },
        {
            "id": "task1540-edbf9e7e6d8d49dfaaccf3a3ae0ab1c8",
            "input": "Cloze-style reading comprehension is a representative problem in mining relationship between document and query. In this paper, we present a simple but novel model called attention-over-attention reader for better solving cloze-style reading comprehension task. Our model aims to place another attention mechanism over the document-level attention and induces “attended attention” for final answer predictions. One advantage of our model is that it is simpler than related works while giving excellent performance. We also propose an N-best re-ranking strategy to double check the validity of the candidates and further improve the performance. Experimental results show that the proposed methods significantly outperform various state-of-the-art systems by a large margin in public datasets, such as CNN and Children’s Book Test.",
            "output": [
                "Attention-over-Attention Neural Networks for Reading Comprehension"
            ]
        },
        {
            "id": "task1540-dbfc13519543422098b60aeb6c2b89de",
            "input": "The paper steps outside the comfort-zone of the traditional NLP tasks like automatic speech recognition (ASR) and machine translation (MT) to addresses two novel problems arising in the automated multilingual news monitoring: segmentation of the TV and radio program ASR transcripts into individual stories, and clustering of the individual stories coming from various sources and languages into storylines. Storyline clustering of stories covering the same events is an essential task for inquisitorial media monitoring. We address these two problems jointly by engaging the low-dimensional semantic representation capabilities of the sequence to sequence neural translation models. To enable joint multi-task learning for multilingual neural translation of morphologically rich languages we replace the attention mechanism with the sliding-window mechanism and operate the sequence to sequence neural translation model on the character-level rather than on the word-level. The story segmentation and storyline clustering problem is tackled by examining the low-dimensional vectors produced as a side-product of the neural translation process. The results of this paper describe a novel approach to the automatic story segmentation and storyline clustering problem.",
            "output": [
                "Character-Level Neural Translation for Multilingual Media Monitoring in the SUMMA Project"
            ]
        },
        {
            "id": "task1540-e9b44654cb624e04b66fe01c1059a784",
            "input": "This paper describes the USTC NELSLIP systems submitted to the Trilingual Entity Detection and Linking (EDL) track in 2016 TAC Knowledge Base Population (KBP) contests. We have built two systems for entity discovery and mention detection (MD): one uses the conditional RNNLM and the other one uses the attention-based encoder-decoder framework. The entity linking (EL) system consists of two modules: a rule based candidate generation and a neural networks probability ranking model. Moreover, some simple string matching rules are used for NIL clustering. At the end, our best system has achieved an F1 score of 0.624 in the end-to-end typed mention ceaf plus metric.",
            "output": [
                "The USTC NELSLIP Systems for Trilingual Entity Detection and Linking Tasks at TAC KBP 2016"
            ]
        },
        {
            "id": "task1540-b07359fed3a540358fb10196a67bcf81",
            "input": "Words can be represented by composing the representations of subword units such as word segments, characters, and/or character n-grams. While such representations are effective and may capture the morphological regularities of words, they have not been systematically compared, and it is not understood how they interact with different morphological typologies. On a language modeling task, we present experiments that systematically vary (1) the basic unit of representation, (2) the composition of these representations, and (3) the morphological typology of the language modeled. Our results largely confirm previous findings that character representations are effective across many languages, though we find that a previously unstudied combination of character trigram representations composed with bi-LSTMs outperforms most other settings. However, we also find room for improvement: character models do not match the predictive accuracy of a model with access to explicit morphological analyses.",
            "output": [
                "From Characters to Words to in Between: Do We Capture Morphology?"
            ]
        },
        {
            "id": "task1540-c1a848e9b9424fca9031c18fa6b7e4cb",
            "input": "A modification of the neo-fuzzy neuron is proposed (an extended neo-fuzzy neuron (ENFN)) that is characterized by improved approximating properties. An adaptive learning algorithm is proposed that has both tracking and smoothing properties and solves prediction, filtering and smoothing tasks of non-stationary “noisy” stochastic and chaotic signals. An ENFN distinctive feature is its computational simplicity compared to other artificial neural networks and neuro-fuzzy systems.",
            "output": [
                "An Extended Neo-Fuzzy Neuron and its Adaptive Learning Algorithm"
            ]
        },
        {
            "id": "task1540-f1bf38e0711d41899e2e0db0132c1727",
            "input": "Classification is widely used technique in the data mining domain, where scalability and efficiency are the immediate problems in classification algorithms for large databases. We suggest improvements to the existing C4.5 decision tree algorithm. In this paper attribute oriented induction (AOI) and relevance analysis are incorporated with concept hierarchy‟s knowledge and HeightBalancePriority algorithm for construction of decision tree along with Multi level mining. The assignment of priorities to attributes is done by evaluating information entropy, at different levels of abstraction for building decision tree using HeightBalancePriority algorithm. Modified DMQL queries are used to understand and explore the shortcomings of the decision trees generated by C4.5 classifier for education dataset and the results are compared with the proposed approach.",
            "output": [
                "EXTRACTING USEFUL RULES THROUGH IMPROVED DECISION TREE INDUCTION USING INFORMATION ENTROPY"
            ]
        },
        {
            "id": "task1540-93564d79710f4025bf2d27254a5731bb",
            "input": "With the large volume of new information created every day, determining the validity of information in a knowledge graph and filling in its missing parts are crucial tasks for many researchers and practitioners. To address this challenge, a number of knowledge graph completion methods have been developed using low-dimensional graph embeddings. Although researchers continue to improve these models using an increasingly complex feature space, we show that simple changes in the architecture of the underlying model can outperform state-of-the-art models without the need for complex feature engineering. In this work, we present a shared variable neural network model called ProjE that fills-in missing information in a knowledge graph by learning joint embeddings of the knowledge graph’s entities and edges, and through subtle, but important, changes to the standard loss function. In doing so, ProjE has a parameter size that is smaller than 11 out of 15 existing methods while performing 37% better than the current-best method on standard datasets. We also show, via a new fact checking task, that ProjE is capable of accurately determining the veracity of many declarative statements. Knowledge Graphs (KGs) have become a crucial resource for many tasks in machine learning, data mining, and artificial intelligence applications including question answering [34], entity disambiguation [7], named entity linking [14], fact checking [32], and link prediction [28] to name a few. In our view, KGs are an example of a heterogeneous information network containing entity-nodes and relationship-edges corresponding to RDF-style triples 〈h, r, t〉 where h represents a head entity, and r is a relationship that connects h to a tail entity t. KGs are widely used for many practical tasks, however, their correctness and completeness are not guaranteed. Therefore, it is necessary to develop knowledge graph completion (KGC) methods to find missing or errant relationships with the goal of improving the general quality of KGs, which, in turn, can be used to improve or create interesting downstream applications. The KGC task can be divided into two non-mutually exclusive sub-tasks: (i) entity prediction and (ii) relationship prediction. The entity prediction task takes a partial triple 〈h, r, ?〉 as input and produces a ranked list of candidate entities as output: Definition 1. (Entity Ranking Problem) Given a Knowledge Graph G = {E,R} and an input triple 〈h, r, ?〉, the entity ranking problem attempts to find the optimal ordered list such that ∀ej∀ei ((ej ∈ E− ∧ ei ∈ E+)→ ei ≺ ej), where E+ = {e ∈ {e1, e2, . . . , el}|〈h, r, e〉 ∈ G} and E− = {e ∈ {el+1, el+2, . . . , e|E|}|〈h, r, e〉 / ∈ G}. Distinguishing between head and tail-entities is usually arbitrary, so we can easily substitute 〈h, r, ?〉 for 〈?, r, t〉. The relationship prediction task aims to find a ranked list of relationships that connect a head-entity with a tail-entity, i.e., 〈h, ?, t〉. When discussing the details of the present work, we focus specifically on the entity prediction task; however, it is straightforward to adapt the methodology to the relationship prediction task by changing the input. A number of KGC algorithms have been developed in recent years, and the most successful models all have one thing in common: they use low-dimensional embedding vectors to represent entities and relationships. Many embedding models, e.g., Unstructured [3], TransE [4], TransH [35], and TransR [25], use a margin-based pairwise ranking loss function, which measures the score of each possible result as the Ln-distance between h+ r and t. In these models the loss functions are all the same, so models differ in how they transform the 1 ar X iv :1 61 1. 05 42 5v 1 [ cs .A I] 1 6 N ov 2 01 6 entity embeddings h and t with respect to the relationship embeddings r. Instead of simply adding h + r, more expressive combination operators are learned by Knowledge Vault [8] and HolE [29] in order to predict the existence of 〈h, r, t〉 in the KG. Other models, such as the Neural Tensor Network (NTN) [33] and the Compositional Vector Space Model (CVSM) [27], incorporate a multilayer neural network solution into the existing models. Unfortunately, due to their extremely large parameter size, these models either (i) do not scale well or (2) consider only a single relationship at a time [10] thereby limiting their usefulness on large, real-world KGs. Despite their large model size, the aforementioned methods only use singleton triples, i.e., length-1 paths in the KG. PTransE [24] and RTransE [10] employ extended path information from 2 and 3-hop trails over the knowledge graph. These extended models achieve excellent performance due to the richness of the input data; unfortunately, their model-size grows exponentially as the path-length increases, which further exacerbates the scalability issues associated with the already high number of parameters of the underlying-models. Another curious finding is that some of the existing models are not self-contained models, i.e., they require pre-trained KG embeddings (RTransE, CVSM), pre-selected paths (PTransE, RTransE), or pre-computed content embeddings of each node (DKRL [36]) before their model training can even begin. TransR and TransH are self-contained models, but their experiments only report results using pre-trained TransE embeddings as input. With these considerations in mind, in the present work we rethink some of the basic decisions made by previous models to create a projection embedding model (ProjE) for KGC. ProjE has four parts that distinguish it from the related work: 1. Instead of measuring the distance between input triple 〈h, r, ?〉 and entity candidates on a unified or a relationship-specific plane, we choose to project the entity candidates onto a target vector representing the input data. 2. Unlike existing models that use transformation matrices, we combine the embedding vectors representing the input data into a target vector using a learnable combination operator. This avoids the addition of a large number of transformation matrices by reusing the entity-embeddings. 3. Rather than optimizing the margin-based pairwise ranking loss, we optimize a ranking loss of the list of candidate-entities (or relationships) collectively. We further use candidate sampling to handle very large data sets. 4. Unlike many of the related models that require pre-trained data from prerequisite models or explore expensive multi-hop paths through the knowledge graph, ProjE is a self-contained model over length-1 edges.",
            "output": [
                "ProjE: Embedding Projection for Knowledge Graph Completion"
            ]
        },
        {
            "id": "task1540-76e8fbd2bc42455597c4dc9a6b7fc68b",
            "input": "Generative models defining joint distributions over parse trees and sentences are useful for parsing and language modeling, but impose restrictions on the scope of features and are often outperformed by discriminative models. We propose a framework for parsing and language modeling which marries a generative model with a discriminative recognition model in an encoder-decoder setting. We provide interpretations of the framework based on expectation maximization and variational inference, and show that it enables parsing and language modeling within a single implementation. On the English Penn Treenbank, our framework obtains competitive performance on constituency parsing while matching the state-of-the-art singlemodel language modeling score.",
            "output": [
                "A Generative Parser with a Discriminative Recognition Algorithm"
            ]
        },
        {
            "id": "task1540-76584fd236e146f5b5e3493f9fb4b9cf",
            "input": "Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as -greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent’s belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards.",
            "output": [
                "Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian Neural Networks"
            ]
        },
        {
            "id": "task1540-3288c9c305c64f06816b6d8df76fdac9",
            "input": "Latent force models (LFMs) are flexible models that combine mechanistic modelling principles (i.e., physical models) with nonparametric data-driven components. Several key applications of LFMs need nonlinearities, which results in analytically intractable inference. In this work we show how non-linear LFMs can be represented as nonlinear white noise driven state-space models and present an efficient non-linear Kalman filtering and smoothing based method for approximate state and parameter inference. We illustrate the performance of the proposed methodology via two simulated examples, and apply it to a real-world problem of long-term prediction of GPS satellite orbits.",
            "output": [
                "State-Space Inference for Non-Linear Latent Force Models with Application to Satellite Orbit Prediction"
            ]
        },
        {
            "id": "task1540-59562c39c1504b5aa8b4885cd6f4c908",
            "input": "The research of attribute characters in information system which contains core, necessary, unnecessary is a basic and important issue in attribute reduct. Many methods for the judgement of attribute characters are based on the relationship between the objects and attributes. In this paper, a new type of judgement theorems which are absolutely based on the relationship among attributes is proposed for the judgement of attribute characters. The method is through comparing the two new attribute sets E(a) and N(a) with respect to the designated attribute a which is proposed in this paper. We conclude that which type of the attribute a belongs to is determined by the relationship between E(a) and N(a) in essence. Secondly, more concise and clear results are given about the judgment of the attribute characters through analyzing the properties of refinement and precise-refinement between E(a) andN(a) in topology. In addition, the relationship among attributes are discussed which is useful for constructing a reduct in the last section of this paper. In the last, we propose a reduct algorithm based on E(a), and this algorithm is an extended application of the analysis of attribute characters above.",
            "output": [
                "A new type of judgement theorems for attribute characters in information system"
            ]
        },
        {
            "id": "task1540-9193e6d264704b098b3d2e84cbe88f26",
            "input": "The goal of open information extraction (OIE) is to extract surface relations and their arguments from naturallanguage text in an unsupervised, domainindependent manner. In this paper, we explore how overly-specific extractions can be reduced in OIE systems without producing uninformative or inaccurate results. We propose MinIE, an OIE system that produces minimized, annotated extractions. At its heart, MinIE rewrites OIE extractions by (1) identifying and removing parts that are considered overly specific; (2) representing information about polarity, modality, attribution, and quantities with suitable annotations instead of in the actual extraction. We conducted an experimental study with several real-world datasets and found that MinIE achieves competitive or higher precision and recall than most prior systems, while at the same time producing much shorter extractions.",
            "output": [
                "MinIE: Minimizing Facts in Open Information Extraction"
            ]
        },
        {
            "id": "task1540-72946525683c4de5b45e6f38e6121060",
            "input": "Words in some natural languages can have a composite structure. Elements of this structure include the root (that could also be composite), prefixes and suffixes with which various nuances and relations to other words can be expressed. Thus, in order to build a proper word representation one must take into account its internal structure. From a corpus of texts we extract a set of frequent subwords and from the latter set we select patterns, i.e. subwords which encapsulate information on character n-gram regularities. The selection is made using the patternbased Conditional Random Field model [23,19] with l1 regularization. Further, for every word we construct a new sequence over an alphabet of patterns. The new alphabet’s symbols confine a local statistical context stronger than the characters, therefore they allow better representations in R and are better building blocks for word representation. In the task of subword-aware language modeling, pattern-based models outperform character-based analogues by 2-20 perplexity points. Also, a recurrent neural network in which a word is represented as a sum of embeddings of its patterns is on par with a competitive and significantly more sophisticated character-based convolutional architecture.",
            "output": [
                "Patterns versus Characters in Subword-aware Neural Language Modeling"
            ]
        },
        {
            "id": "task1540-149e13c4a81e495995e6f09c40f485c0",
            "input": "Recommendation and collaborative filtering systems are important in modern information and e-commerce applications. As these systems are becoming increasingly popular in the industry, their outputs could affect business decision making, introducing incentives for an adversarial party to compromise the availability or integrity of such systems. We introduce a data poisoning attack on collaborative filtering systems. We demonstrate how a powerful attacker with full knowledge of the learner can generate malicious data so as to maximize his/her malicious objectives, while at the same time mimicking normal user behavior to avoid being detected. While the complete knowledge assumption seems extreme, it enables a robust assessment of the vulnerability of collaborative filtering schemes to highly motivated attacks. We present efficient solutions for two popular factorizationbased collaborative filtering algorithms: the alternative minimization formulation and the nuclear norm minimization method. Finally, we test the effectiveness of our proposed algorithms on real-world data and discuss potential defensive strategies.",
            "output": [
                "Data Poisoning Attacks on Factorization-Based Collaborative Filtering"
            ]
        },
        {
            "id": "task1540-137d93d36c3641b0bb6c79de41ec7cf7",
            "input": "We present an efficient method for training slackrescaled structural SVM. Although finding the most violating label in a margin-rescaled formulation is often easy since the target function decomposes with respect to the structure, this is not the case for a slack-rescaled formulation, and finding the most violated label might be very difficult. Our core contribution is an efficient method for finding the most-violatinglabel in a slack-rescaled formulation, given an oracle that returns the most-violating-label in a (slightly modified) margin-rescaled formulation. We show that our method enables accurate and scalable training for slack-rescaled SVMs, reducing runtime by an order of magnitude compared to previous approaches to slack-rescaled SVMs.",
            "output": [
                "Fast and Scalable Structural SVM with Slack Rescaling"
            ]
        },
        {
            "id": "task1540-6b1ac633f8b14e73855efcdd2b7966f3",
            "input": "Text analysis includes lexical analysis of the text and has been widely studied and used in diverse applications. In the last decade, researchers have proposed many efficient solutions to analyze / classify large text dataset, however, analysis / classification of short text is still a challenge because 1) the data is very sparse 2) It contains noise words and 3) It is difficult to understand the syntactical structure of the text. Short Messaging Service (SMS) is a text messaging service for mobile/smart phone and this service is frequently used by all mobile users. Because of the popularity of SMS service, marketing companies nowadays are also using this service for direct marketing also known as SMS marketing.In this paper, we have proposed Ontology based SMS Controller which analyze the text message and classify it using ontology aslegitimate or spam. The proposed system has been tested on different scenarios and experimental results shows that the proposed solution is effective both in terms of efficiency and time. Keywords—Short Text Classification; SMS Spam; Text Analysis; Ontology based SMS Spam; Text Analysis and Ontology",
            "output": [
                "Ontology Based SMS Controller for Smart Phones"
            ]
        },
        {
            "id": "task1540-edc988a8d26f47af827570d19dee02ab",
            "input": "In this paper, we study a variant of the framework of online learning using expert advice with limited/bandit feedback. We consider each expert as a learning entity, seeking to more accurately reflecting certain real-world applications. In our setting, the feedback at any time t is limited in a sense that it is only available to the expert i that has been selected by the central algorithm (forecaster), i.e., only the expert i receives feedback from the environment and gets to learn at time t. We consider a generic black-box approach whereby the forecaster does not control or know the learning dynamics of the experts apart from knowing the following no-regret learning property: the average regret of any expert j vanishes at a rate of at leastO(t j ) with tj learning steps where β ∈ [0, 1] is a parameter. In the spirit of competing against the best action in hindsight in multi-armed bandits problem, our goal here is to be competitive w.r.t. the cumulative losses the algorithm could receive by following the policy of always selecting one expert. We prove the following hardness result: without any coordination between the forecaster and the experts, it is impossible to design a forecaster achieving no-regret guarantees. In order to circumvent this hardness result, we consider a practical assumption allowing the forecaster to “guide” the learning process of the experts by filtering/blocking some of the feedbacks observed by them from the environment, i.e., not allowing the selected expert i to learn at time t for some time steps. Then, we design a novel no-regret learning algorithm LEARNEXP for this problem setting by carefully guiding the feedbacks observed by experts. We prove that LEARNEXP achieves the worst-case expected cumulative regret ofO(T 1 2−β ) after T time steps and matches the regret bound of Θ(T 1 2 ) for the special case of multi-armed bandits.",
            "output": [
                "Learning to Use Learners’ Advice"
            ]
        },
        {
            "id": "task1540-038eb25aa1174da288d76d782031f5e3",
            "input": "A commonly used learning rule is to approximately minimize the average loss over the training set. Other learning algorithms, such as AdaBoost and hard-SVM, aim at minimizing the maximal loss over the training set. The average loss is more popular, particularly in deep learning, due to three main reasons. First, it can be conveniently minimized using online algorithms, that process few examples at each iteration. Second, it is often argued that there is no sense to minimize the loss on the training set too much, as it will not be reflected in the generalization loss. Last, the maximal loss is not robust to outliers. In this paper we describe and analyze an algorithm that can convert any online algorithm to a minimizer of the maximal loss. We prove that in some situations better accuracy on the training set is crucial to obtain good performance on unseen examples. Last, we propose robust versions of the approach that can handle outliers.",
            "output": [
                "Minimizing the Maximal Loss: How and Why"
            ]
        },
        {
            "id": "task1540-4f0290fc291e41469982ba0edaf133dc",
            "input": "In this article using Cuckoo Optimization Algorithm and simple additive weighting method the hybrid COAW algorithm is presented to solve multi-objective problems. Cuckoo algorithm is an efficient and structured method for solving nonlinear continuous problems. The created Pareto frontiers of the COAW proposed algorithm are exact and have good dispersion. This method has a high speed in finding the Pareto frontiers and identifies the beginning and end points of Pareto frontiers properly. In order to validation the proposed algorithm, several experimental problems were analyzed. The results of which indicate the proper effectiveness of COAW algorithm for solving multi-objective problems.",
            "output": [
                "THE NEW HYBRID COAW METHOD FOR SOLVING MULTI-OBJECTIVE PROBLEMS"
            ]
        },
        {
            "id": "task1540-777a258d102241c19ab151d07b8ad472",
            "input": "This article constructs a Turing Machine which can solve for β ′ which is REcomplete. Such a machine is only possible if there is something wrong with the foundations of computer science and mathematics. We therefore check our work by looking very closely at Cantor’s diagonalization and construct a novel formal language as an Abelian group which allows us, through equivalence relations, to provide a non-trivial counterexample to Cantor’s argument. As if that wasn’t enough, we then discover that the impredicative nature of Gödel’s diagonalization lemma leads to logical tautology, invalidating any meaning behind the method, leaving no doubt that diagonalization is flawed. Our discovery in regards to these foundational arguments opens the door to solving the P vs NP problem. 1 Turing’s Proof on the Entscheidungsproblem has",
            "output": [
                "A Stronger Foundation for Computer Science and P=NP"
            ]
        },
        {
            "id": "task1540-73a6ba4bad00459a9389e4026b55d0c5",
            "input": "Here, I review current state-of-the-arts in many areas of AI to estimate when it’s reasonable to expect human level AI development. Predictions of prominent AI researchers vary broadly from very pessimistic predictions of Andrew Ng to much more moderate predictions of Geoffrey Hinton and optimistic predictions of Shane Legg, DeepMind cofounder. Given huge rate of progress in recent years and this broad range of predictions of AI experts, AI safety questions are also discussed.",
            "output": [
                "Review of state-of-the-arts in artificial intelligence with application to AI safety problem"
            ]
        },
        {
            "id": "task1540-449af93377e543a0a28785e83c11c7a3",
            "input": "Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents’ messages by translating them. Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener. We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.1",
            "output": [
                "Translating Neuralese"
            ]
        },
        {
            "id": "task1540-ded63d723aa2463baf14e5c453b3a120",
            "input": "Circumscription is a representative example of a nonmonotonic reasoning inference technique. Circumscription has often been studied for first order theories, but its propositional version has also been the subject of extensive research, having been shown equivalent to extended closed world assumption (ECWA). Moreover, entailment in propositional circumscription is a well-known example of a decision problem in the second level of the polynomial hierarchy. This paper proposes a new Boolean Satisfiability (SAT)-based algorithm for entailment in propositional circumscription that explores the relationship of propositional circumscription to minimal models. The new algorithm is inspired by ideas commonly used in SAT-based model checking, namely counterexample guided abstraction refinement. In addition, the new algorithm is refined to compute the theory closure for generalized close world assumption (GCWA). Experimental results show that the new algorithm can solve problem instances that other solutions are unable to solve.",
            "output": [
                "Counterexample Guided Abstraction Refinement Algorithm for Propositional Circumscription"
            ]
        },
        {
            "id": "task1540-9f55e4460665415a8565588fb4dd4dac",
            "input": "Abstract Stochastic gradient descent (SGD) on a low-rank factorization [9] is commonly employed to speed up matrix problems including matrix completion, subspace tracking, and SDP relaxation. In this paper, we exhibit a step size scheme for SGD on a low-rank least-squares problem, and we prove that, under broad sampling conditions, our method converges globally from a random starting point within O(ǫn logn) steps with constant probability for constant-rank problems. Our modification of SGD relates it to stochastic power iteration. We also show experiments to illustrate the runtime and convergence of the algorithm.",
            "output": [
                "Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems"
            ]
        },
        {
            "id": "task1540-3de654e58fc14405a4ff75386b901ce2",
            "input": "This paper describes our deep learning-based approach to sentiment analysis in Twitter as part of SemEval-2016 Task 4. We use a convolutional neural network to determine sentiment and participate in all subtasks, i.e. two-point, three-point, and five-point scale sentiment classification and two-point and five-point scale sentiment quantification. We achieve competitive results for two-point scale sentiment classification and quantification, ranking fifth and a close fourth (third and second by alternative metrics) respectively despite using only pre-trained embeddings that contain no sentiment information. We achieve good performance on three-point scale sentiment classification, ranking eighth out of 35, while performing poorly on fivepoint scale sentiment classification and quantification. An error analysis reveals that this is due to low expressiveness of the model to capture negative sentiment as well as an inability to take into account ordinal information. We propose improvements in order to address these and other issues.",
            "output": [
                "INSIGHT-1 at SemEval-2016 Task 4: Convolutional Neural Networks for Sentiment Classification and Quantification"
            ]
        },
        {
            "id": "task1540-c48f27d2e429424db414f151c7aa546e",
            "input": "The standard approach to supervised classification involves the minimization of a log-loss as an upper bound to the classification error. While this is a tight bound early on in the optimization, it overemphasizes the influence of incorrectly classified examples far from the decision boundary. Updating the upper bound during the optimization leads to improved classification rates while transforming the learning into a sequence of minimization problems. In addition, in the context where the classifier is part of a larger system, this modification makes it possible to link the performance of the classifier to that of the whole system, allowing the seamless introduction of external constraints.",
            "output": [
                "TIGHTER BOUNDS LEAD TO IMPROVED CLASSIFIERS"
            ]
        },
        {
            "id": "task1540-1e2b527d63e14aa5b7c4e7b9659de44f",
            "input": "Embeddings are generic representations that are useful for many NLP tasks. In this paper, we introduce DENSIFIER, a method that learns an orthogonal transformation of the embedding space that focuses the information relevant for a task in an ultradense subspace of a dimensionality that is smaller by a factor of 100 than the original space. We show that ultradense embeddings generated by DENSIFIER reach state of the art on a lexicon creation task in which words are annotated with three types of lexical information – sentiment, concreteness and frequency. On the SemEval2015 10B sentiment analysis task we show that no information is lost when the ultradense subspace is used, but training is an order of magnitude more efficient due to the compactness of the ultradense space.",
            "output": [
                "Ultradense Word Embeddings by Orthogonal Transformation"
            ]
        },
        {
            "id": "task1540-d8d689cd0a4b44f9a3ee0f295e014bbf",
            "input": "This paper presents the development of several models of a deep convolutional auto-encoder in the Caffe deep learning framework and their experimental evaluation on the example of MNIST dataset. We have created five models of a convolutional auto-encoder which differ architecturally by the presence or absence of pooling and unpooling layers in the auto-encoder’s encoder and decoder parts. Our results show that the developed models provide very good results in dimensionality reduction and unsupervised clustering tasks, and small classification errors when we used the learned internal code as an input of a supervised linear classifier and multi-layer perceptron. The best results were provided by a model where the encoder part contains convolutional and pooling layers, followed by an analogous decoder part with deconvolution and unpooling layers without the use of switch variables in the decoder part. The paper also discusses practical details of the creation of a deep convolutional auto-encoder in the very popular Caffe deep learning framework. We believe that our approach and results presented in this paper could help other researchers to build efficient deep neural network architectures in the future.",
            "output": [
                "A Deep Convolutional Auto-Encoder with Pooling - Unpooling Layers in Caffe"
            ]
        },
        {
            "id": "task1540-093d26b8f6ac4b06b646fb97b9959d64",
            "input": "We propose an online convex optimization algorithm (RESCALEDEXP) that achieves<lb>optimal regret in the unconstrained setting without prior knowledge of any bounds<lb>on the loss functions. We prove a lower bound showing an exponential sep-<lb>aration between the regret of existing algorithms that require a known bound<lb>on the loss functions and any algorithm that does not require such knowledge.<lb>RESCALEDEXP matches this lower bound asymptotically in the number of itera-<lb>tions. RESCALEDEXP is naturally hyperparameter-free and we demonstrate empir-<lb>ically that it matches prior optimization algorithms that require hyperparameter<lb>optimization. 1 Online Convex Optimization Online Convex Optimization (OCO) [1, 2] provides an elegant framework for modeling noisy,<lb>antagonistic or changing environments. The problem can be stated formally with the help of the<lb>following definitions:<lb>Convex Set: A setW is convex ifW is contained in some real vector space and tw+(1− t)w′ ∈W<lb>for all w,w′ ∈W and t ∈ [0, 1].<lb>Convex Function: f :W → R is a convex function if f(tw + (1− t)w′) ≤ tf(w) + (1− t)f(w′)<lb>for all w,w′ ∈W and t ∈ [0, 1]. An OCO problem is a game of repeated rounds in which on round t a learner first chooses an element<lb>wt in some convex space W , then receives a convex loss function `t, and suffers loss `t(wt). The<lb>regret of the learner with respect to some other u ∈W is defined by",
            "output": [
                "Online Convex Optimization with Unconstrained Domains and Losses"
            ]
        },
        {
            "id": "task1540-58965754189f467ea00aebe1963f64cc",
            "input": "We formalize Simplified Boardgames language, which describes a subclass of arbitrary board games. The language structure is based on the regular expressions, which makes the rules easily machine-processable while keeping the rules concise and fairly human-readable.",
            "output": [
                "SIMPLIFIED BOARDGAMES"
            ]
        },
        {
            "id": "task1540-b06cec63b22e48b28e8f9191f20bbc9c",
            "input": "We propose a new tensor factorization method, called the Sparse Hierarchical Tucker (Sparse H-Tucker), for sparse and high-order data tensors. Sparse H-Tucker is inspired by its namesake, the classical Hierarchical Tucker method, which aims to compute a tree-structured factorization of an input data set that may be readily interpreted by a domain expert. However, Sparse H-Tucker uses a nested sampling technique to overcome a key scalability problem in Hierarchical Tucker, which is the creation of an unwieldy intermediate dense core tensor; the result of our approach is a faster, more space-efficient, and more accurate method. We extensively test our method on a real healthcare dataset, which is collected from 30K patients and results in an 18th order sparse data tensor. Unlike competing methods, Sparse H-Tucker can analyze the full data set on a single multi-threaded machine. It can also do so more accurately and in less time than the state-of-the-art: on a 12th order subset of the input data, Sparse H-Tucker is 18× more accurate and 7.5× faster than a previously state-of-the-art method. Even for analyzing low order tensors (e.g., 4-order), our method requires close to an order of magnitude less time and over two orders of magnitude less memory, as compared to traditional tensor factorization methods such as CP and Tucker. Moreover, we observe that Sparse H-Tucker scales nearly linearly in the number of non-zero tensor elements. The resulting model also provides an interpretable disease hierarchy, which is confirmed by a clinical expert.",
            "output": [
                "Sparse Hierarchical Tucker Factorization and its Application to Healthcare"
            ]
        },
        {
            "id": "task1540-7b833986c93a4e248bfb29c73fa40c10",
            "input": "Text alignment and text quality are critical to the accuracy of Machine Translation (MT) systems, some NLP tools, and any other text processing tasks requiring bilingual data. This research proposes a language independent bi-sentence filtering approach based on Polish (not a positionsensitive language) to English experiments. This cleaning approach was developed on the TED Talks corpus and also initially tested on the Wikipedia comparable corpus, but it can be used for any text domain or language pair. The proposed approach implements various heuristics for sentence comparison. Some of them leverage synonyms and semantic and structural analysis of text as additional information. Minimization of data loss was ensured. An improvement in MT system score with text processed using the tool is discussed.",
            "output": [
                "Noisy-parallel and comparable corpora filtering methodology for the extraction of bi-lingual equivalent data at sentence level"
            ]
        },
        {
            "id": "task1540-922ee293824146d7b1afe038520dce3c",
            "input": "The explosive growth of the location-enabled devices coupled with the increasing use of Internet services has led to an increasing awareness of the importance and usage of geospatial information in many applications. The navigation apps (often called “Maps”), use a variety of available data sources to calculate and predict the travel time as well as several options for routing in public transportation, car or pedestrian modes. This paper evaluates the pedestrian mode of Maps apps in three major smartphone operating systems (Android, iOS and Windows Phone). In the paper, we will show that the Maps apps on iOS, Android and Windows Phone in pedestrian mode, predict travel time without learning from the individual’s movement profile. In addition, we will exemplify that those apps suffer from a specific data quality issue which relates to the absence of information about location and type of pedestrian crossings. Finally, we will illustrate learning from movement profile of individuals using various predictive analytics models to improve the accuracy of travel time estimation.",
            "output": [
                "Predictive Analytics for Enhancing Travel Time Estimation in Navigation Apps of Apple, Google, and Microsoft"
            ]
        },
        {
            "id": "task1540-e2c700b875514b64b2823c41745a1ca6",
            "input": "A series of monte carlo studies were performed to compare the behavior of some alternative procedures for reasoning under uncertainty. The behavior of several Bayesian, linear model and default reasoning procedures were examined in the context of increasing levels of calibration error. The most interesting result is that Bayesian procedures tended to output more extreme posterior belief values (posterior beliefs near 0.0 or 1.0) than other techniques, but the linear models were relatively less likely to output strong support for an erroneous conclusion. Also, accounting for the probabilistic dependencies between evidence items was important for both Bayesian and linear updating procedures.",
            "output": [
                "Reasoning under Uncertainty:"
            ]
        },
        {
            "id": "task1540-855c5337ca37404ba8410884c38252da",
            "input": "This paper describes pre-processing phase of ontology graph generation system from Punjabi text documents of different domains. This research paper focuses on pre-processing of Punjabi text documents. Pre-processing is structured representation of the input text. Pre-processing of ontology graph generation includes allowing input restrictions to the text, removal of special symbols and punctuation marks, removal of duplicate terms, removal of stop words, extract terms by matching input terms with dictionary and gazetteer lists terms. KeywordsOntology, Pre-processing phase, Ontology Graph, Knowledge Representation, Natural Language Processing.",
            "output": [
                "Pre-processing of Domain Ontology Graph Generation System in Punjabi"
            ]
        },
        {
            "id": "task1540-6a9c9c9eeea740e1837b1138da16902d",
            "input": "We investigate the usage of convolutional neural networks (CNNs) for the slot filling task in spoken language understanding. We propose a novel CNN architecture for sequence labeling which takes into account the previous context words with preserved order information and pays special attention to the current word with its surrounding context. Moreover, it combines the information from the past and the future words for classification. Our proposed CNN architecture outperforms even the previously best ensembling recurrent neural network model and achieves state-of-the-art results with an F1-score of 95.61% on the ATIS benchmark dataset without using any additional linguistic knowledge and resources.",
            "output": [
                "Sequential Convolutional Neural Networks for Slot Filling in Spoken Language Understanding"
            ]
        },
        {
            "id": "task1540-aa9f42530cec46ffabb86ba92fec5b61",
            "input": "This work proposes a low complexity nonlinearity model and develops adaptive algorithms over it. The model is based on the decomposable—or rank-one, in tensor language— Volterra kernels. It may also be described as a product of FIR filters, which explains its low-complexity. The rank-one model is also interesting because it comes from a well-posed problem in approximation theory. The paper uses such model in an estimation theory context to develop an exact gradienttype algorithm, from which adaptive algorithms such as the least mean squares (LMS) filter and its data-reuse version—the TRUE-LMS—are derived. Stability and convergence issues are addressed. The algorithms are then tested in simulations, which show its good performance when compared to other nonlinear processing algorithms in the literature.",
            "output": [
                "Nonlinear Adaptive Algorithms on Rank-One Tensor Models"
            ]
        },
        {
            "id": "task1540-5ddac4af416d447d8e39178cb274f27a",
            "input": "This paper takes an approach to clustering domestic electricity load profiles that has been successfully used with data from Portugal and applies it to UK data. Clustering techniques are applied and it is found that the preferred technique in the Portuguese work (a two stage process combining Self Organised Maps and Kmeans) is not appropriate for the UK data. The work shows that up to nine clusters of households can be identified with the differences in usage profiles being visually striking. This demonstrates the appropriateness of breaking the electricity usage patterns down to more detail than the two load profiles currently published by the electricity industry. The paper details initial results using data collected in Milton Keynes around 1990. Further work is described and will concentrate on building accurate and meaningful clusters of similar electricity users in order to better direct demand side management initiatives to the most relevant target customers.",
            "output": [
                "Application of a clustering framework to UK domestic electricity data"
            ]
        },
        {
            "id": "task1540-fe04cf65869e4c08b9c8f598c6eec265",
            "input": "In Bayesian networks, a Most Probable Explanation (MPE) is a complete variable instantiation with the highest probability given the current evidence. In this paper, we discuss the problem of finding robustness conditions of the MPE under single parameter changes. Specifically, we ask the question: How much change in a single network parameter can we afford to apply while keeping the MPE unchanged? We will describe a procedure, which is the first of its kind, that computes this answer for all parameters in the Bayesian network in time O(n exp(w)), where n is the number of network variables and w is its treewidth.",
            "output": [
                "On the Robustness of Most Probable Explanations"
            ]
        },
        {
            "id": "task1540-71775f378a5a44f1b6ede1e0e3f15d23",
            "input": "We learn rich natural sound representations by capitalizing on large amounts of unlabeled sound data collected in the wild. We leverage the natural synchronization between vision and sound to learn an acoustic representation using two-million unlabeled videos. Unlabeled video has the advantage that it can be economically acquired at massive scales, yet contains useful signals about natural sound. We propose a student-teacher training procedure which transfers discriminative visual knowledge from well established visual recognition models into the sound modality using unlabeled video as a bridge. Our sound representation yields significant performance improvements over the state-of-the-art results on standard benchmarks for acoustic scene/object classification. Visualizations suggest some high-level semantics automatically emerge in the sound network, even though it is trained without ground truth labels.",
            "output": [
                "SoundNet: Learning Sound Representations from Unlabeled Video"
            ]
        },
        {
            "id": "task1540-033fb9f94e1a47429a28635f504c58a8",
            "input": "We describe MITRE’s submission to the SemEval-2016 Task 6, Detecting Stance in Tweets. This effort achieved the top score in Task A on supervised stance detection, producing an average F1 score of 67.8 when assessing whether a tweet author was in favor or against a topic. We employed a recurrent neural network initialized with features learned via distant supervision on two large unlabeled datasets. We trained embeddings of words and phrases with the word2vec skip-gram method, then used those features to learn sentence representations via a hashtag prediction auxiliary task. These sentence vectors were then finetuned for stance detection on several hundred labeled examples. The result was a high performing system that used transfer learning to maximize the value of the available training data.",
            "output": [
                "MITRE at SemEval-2016 Task 6: Transfer Learning for Stance Detection"
            ]
        },
        {
            "id": "task1540-504f877684da4527acac2832177e550a",
            "input": "Using current reinforcement learning methods, it has recently become possible to learn to play unknown 3D games from raw pixels. In this work, we study the challenges that arise in such complex environments, and summarize current methods to approach these. We choose a task within the Doom game, that has not been approached yet. The goal for the agent is to fight enemies in a 3D world consisting of five rooms. We train the DQN and LSTMA3C algorithms on this task. Results show that both algorithms learn sensible policies, but fail to achieve high scores given the amount of training. We provide insights into the learned behavior, which can serve as a valuable starting point for further research in the Doom domain.",
            "output": [
                "Deep Reinforcement Learning From Raw Pixels in Doom"
            ]
        },
        {
            "id": "task1540-40de837961a14cc9b655749b7a51cf0f",
            "input": "This work focuses on answering singlerelation factoid questions over Freebase. Each question can acquire the answer from a single fact of form (subject, predicate, object) in Freebase. This task, simple question answering (SimpleQA), can be addressed via a twostep pipeline: entity linking and fact selection. In fact selection, we match the subject entity in fact with the entity mention in question by a character-level convolutional neural network (char-CNN), and match the predicate in fact with the question by a word-level CNN (wordCNN). This work makes two main contributions. (i) A simple and effective entity linker over Freebase is proposed. Our entity linker outperforms the state-of-the-art entity linker of SimpleQA task. (ii) A novel attentive maxpooling is stacked over word-CNN, so that the predicate representation can be matched with the predicate-focused question representation more effectively. Experiments show that our system sets new state-of-the-art in this task.",
            "output": [
                "Simple Question Answering by Attentive Convolutional Neural Network"
            ]
        },
        {
            "id": "task1540-8f6c655c043f493aa990fe4c29032d9b",
            "input": "Artificial intelligence methods have often been applied to perform specific functions or tasks in the cyber– defense realm. However, as adversary methods become more complex and difficult to divine, piecemeal efforts to understand cyber–attacks, and malware–based attacks in particular, are not providing sufficient means for malware analysts to understand the past, present and future characteristics of malware. In this paper, we present the Malware Analysis and Attributed using Genetic Information (MAAGI) system. The underlying idea behind the MAAGI system is that there are strong similarities between malware behavior and biological organism behavior, and applying biologically inspired methods to corpora of malware can help analysts better understand the ecosystem of malware attacks. Due to the sophistication of the malware and the analysis, the MAAGI system relies heavily on artificial intelligence techniques to provide this capability. It has already yielded promising results over its development life, and will hopefully inspire more integration between the artificial intelligence and cyber–defense communities.",
            "output": [
                "Artificial Intelligence Based Malware Analysis"
            ]
        },
        {
            "id": "task1540-f33189c1b47246cdb59b559232867856",
            "input": "We show how eye-tracking corpora can be used to improve sentence compression models, presenting a novel multi-task learning algorithm based on multi-layer LSTMs. We obtain performance competitive with or better than state-of-the-art approaches.",
            "output": [
                "Improving sentence compression by learning to predict gaze"
            ]
        },
        {
            "id": "task1540-8116619091ea44b09c316964a1080ec4",
            "input": "We present the discriminative recurrent sparse auto-encoder model, comprising a recurrent encoder of rectified linear units, unrolled for a fixed number of iterations, and connected to two linear decoders that reconstruct the input and predict its supervised classification. Training via backpropagation-through-time initially minimizes an unsupervised sparse reconstruction error; the loss function is then augmented with a discriminative term on the supervised classification. The depth implicit in the temporally-unrolled form allows the system to exhibit far more representational power, while keeping the number of trainable parameters fixed. From an initially unstructured network the hidden units differentiate into categorical-units, each of which represents an input prototype with a well-defined class; and part-units representing deformations of these prototypes. The learned organization of the recurrent encoder is hierarchical: part-units are driven directly by the input, whereas the activity of categorical-units builds up over time through interactions with the part-units. Even using a small number of hidden units per layer, discriminative recurrent sparse auto-encoders achieve excellent performance on MNIST.",
            "output": [
                "Discriminative Recurrent Sparse Auto-Encoders"
            ]
        },
        {
            "id": "task1540-26bef879b29447ae878401e759b78a2e",
            "input": "In many natural language processing (NLP) tasks, a document is commonly modeled as a bag of words using the term frequencyinverse document frequency (TF-IDF) vector. One major shortcoming of the frequencybased TF-IDF feature vector is that it ignores word orders that carry syntactic and semantic relationships among the words in a document, and they can be important in some NLP tasks such as genre classification. This paper proposes a novel distributed vector representation of a document: a simple recurrentneural-network language model (RNN-LM) or a long short-term memory RNN language model (LSTM-LM) is first created from all documents in a task; some of the LM parameters are then adapted by each document, and the adapted parameters are vectorized to represent the document. The new document vectors are labeled as DV-RNN and DV-LSTM respectively. We believe that our new document vectors can capture some high-level sequential information in the documents, which other current document representations fail to capture. The new document vectors were evaluated in the genre classification of documents in three corpora: the Brown Corpus, the BNC Baby Corpus and an artificially created Penn Treebank dataset. Their classification performances are compared with the performance of TF-IDF vector and the state-of-the-art distributed memory model of paragraph vector (PV-DM). The results show that DV-LSTM significantly outperforms TF-IDF and PV-DM in most cases, and combinations of the proposed document vectors with TF-IDF or PVDM may further improve performance.",
            "output": [
                "Recurrent Neural Network Language Model Adaptation Derived Document Vector"
            ]
        },
        {
            "id": "task1540-17c41827abb8490dbc0263f73921db88",
            "input": "We extend Stochastic Gradient Variational Bayes to perform posterior inference for the weights of Stick-Breaking processes. This development allows us to define a Stick-Breaking Variational Autoencoder (SB-VAE), a Bayesian nonparametric version of the variational autoencoder that has a latent representation with stochastic dimensionality. We experimentally demonstrate that the SB-VAE, and a semisupervised variant, learn highly discriminative latent representations that often outperform the Gaussian VAE’s.",
            "output": [
                "STICK-BREAKING VARIATIONAL AUTOENCODERS"
            ]
        },
        {
            "id": "task1540-24f1bf92e88e4f6281d6d5f0587c416d",
            "input": "We formalize synthesis of shared control protocols with correctness guarantees for temporal logic specifications. More specifically, we introduce a modeling formalism in which both a human and an autonomy protocol can issue commands to a robot towards performing a certain task. These commands are blended into a joint input to the robot. The autonomy protocol is synthesized using an abstraction of possible human commands accounting for randomness in decisions caused by factors such as fatigue or incomprehensibility of the problem at hand. The synthesis is designed to ensure that the resulting robot behavior satisfies given safety and performance specifications, e.g., in temporal logic. Our solution is based on nonlinear programming and we address the inherent scalability issue by presenting alternative methods. We assess the feasibility and the scalability of the approach by an experimental evaluation.",
            "output": [
                "Synthesis of Shared Control Protocols with Provable Safety and Performance Guarantees"
            ]
        },
        {
            "id": "task1540-6886492287ac4d56b75ed6954d841325",
            "input": "The work presented here involves the design of a Multi Layer Perceptron (MLP) based pattern classifier for recognition of handwritten Bangla digits using a 76 element feature vector. Bangla is the second most popular script and language in the Indian subcontinent and the fifth most popular language in the world. The feature set developed for representing handwritten Bangla numerals here includes 24 shadow features, 16 centroid features and 36 longest-run features. On experimentation with a database of 6000 samples, the technique yields an average recognition rate of 96.67% evaluated after three-fold cross validation of results. It is useful for applications related to OCR of handwritten Bangla Digit and can also be extended to include OCR of handwritten characters of Bangla alphabet.",
            "output": [
                "An MLP based Approach for Recognition of Handwritten ‘Bangla’ Numerals"
            ]
        },
        {
            "id": "task1540-d4e6dedd6c894a9e8a90c5a708c603f3",
            "input": "LSTMs have become a basic building block for many deep NLP models. In recent years, many improvements and variations have been proposed for deep sequence models in general, and LSTMs in particular. We propose and analyze a series of augmentations and modifications to LSTM networks resulting in improved performance for text classification datasets. We observe compounding improvements on traditional LSTMs using Monte Carlo test-time model averaging, average pooling, and residual connections, along with four other suggested modifications. Our analysis provides a simple, reliable, and high quality baseline model.",
            "output": [
                "BINING RECENT INSIGHTS FOR LSTMS"
            ]
        },
        {
            "id": "task1540-f635cfc0757040aba94da6e0b68913df",
            "input": "Social media and data mining are increasingly being used to analyse political and societal issues. Here we undertake the classification of social media users as supporting or opposing ongoing independence movements in their territories. Independence movements occur in territories whose citizens have conflicting national identities; users with opposing national identities will then support or oppose the sense of being part of an independent nation that differs from the officially recognised country. We describe a methodology that relies on users’ self-reported location to build datasets for three territories – Catalonia, the Basque Country and Scotland – and we test language-independent classifiers using four types of features. We show the effectiveness of the approach to build large annotated datasets, and the ability to achieve accurate, language-independent classification performances ranging from 85% to 97% for the three territories under study. A data analysis shows the existence of echo chambers that isolate opposing national identities from each other.",
            "output": [
                "Stance Classification of Social Media Users in Independence Movements"
            ]
        },
        {
            "id": "task1540-a17bd58869bb49a3988c24e4d519adbb",
            "input": "Text Classification is a challenging and a red hot field in the current scenario and has great importance in text categorization applications. A lot of research work has been done in this field but there is a need to categorize a collection of text documents into mutually exclusive categories by extracting the concepts or features using supervised learning paradigm and different classification algorithms. In this paper, a new Fuzzy Similarity Based Concept Mining Model (FSCMM) is proposed to classify a set of text documents into pre defined Category Groups (CG) by providing them training and preparing on the sentence, document and integrated corpora levels along with feature reduction, ambiguity removal on each level to achieve high system performance. Fuzzy Feature Category Similarity Analyzer (FFCSA) is used to analyze each extracted feature of Integrated Corpora Feature Vector (ICFV) with the corresponding categories or classes. This model uses Support Vector Machine Classifier (SVMC) to classify correctly the training data patterns into two groups; i. e., + 1 and – 1, thereby producing accurate and correct results. The proposed model works efficiently and effectively with great performance and high accuracy results. Keywords-Text Classification; Natural Language Processing; Feature Extraction; Concept Mining; Fuzzy Similarity Analyzer; Dimensionality Reduction; Sentence Level; Document Level; Integrated Corpora Level Processing.",
            "output": [
                "A Fuzzy Similarity Based Concept Mining Model for Text Classification"
            ]
        },
        {
            "id": "task1540-23f0a4953b1348769a062307a4cd1a64",
            "input": "Distortion of the underlying speech is a common problem for single-channel speech enhancement algorithms, and hinders such methods from being used more extensively. A dictionary based speech enhancement method that emphasizes preserving the underlying speech is proposed. Spectral patches of clean speech are sampled and clustered to train a dictionary. Given a noisy speech spectral patch, the best matching dictionary entry is selected and used to estimate the noise power at each time-frequency bin. The noise estimation step is formulated as an outlier detection problem, where the noise at each bin is assumed present only if it is an outlier to the corresponding bin of the best matching dictionary entry. This framework assigns higher priority in removing spectral elements that strongly deviate from a typical spoken unit stored in the trained dictionary. Even without the aid of a separate noise model, this method can achieve significant noise reduction for various non-stationary noises, while effectively preserving the underlying speech in more challenging noisy environments.",
            "output": [
                "SINGLE CHANNEL SPEECH ENHANCEMENT USING OUTLIER DETECTION"
            ]
        },
        {
            "id": "task1540-866aa386f0c9404aa67e10bf1af67def",
            "input": "Decision theoretical troubleshooting is about minimizing the expected cost of solving a certain problem like repairing a complicated man-made device. In this paper we consider situations where you have to take apart some of the device to get access to certain clusters and actions. Specifically, we investigate troubleshooting with independent actions in a tree of clusters where actions inside a cluster cannot be performed before the cluster is opened. The problem is non-trivial because there is a cost associated with opening and closing a cluster. Troubleshooting with independent actions and no clusters can be solved in O(n · lg n) time (n being the number of actions) by the well-known ”P-over-C” algorithm due to Kadane and Simon, but an efficient and optimal algorithm for a tree cluster model has not yet been found. In this paper we describe a ”bottom-up P-over-C” O(n · lg n) time algorithm and show that it is optimal when the clusters do not need to be closed to test whether the actions solved the problem.",
            "output": [
                "The Cost of Troubleshooting Cost Clusters with Inside Information"
            ]
        },
        {
            "id": "task1540-ac7b09460a1b44fb9c301f1881863ff8",
            "input": "The stable model (SM) semantics lacks the properties of existence, relevance and cumulativity. If we prospectively consider the class of conservative extensions of the SM semantics (i.e., semantics that for each normal logic program P retrieve a superset of the set of stable models of P), one may wander how do the semantics of this class behave in what concerns the aforementioned properties. That is the type of issue dealt with in this paper. We define a large class of conservative extensions of the SM semantics, dubbed affix stable model semantics (ASM), and study the above referred properties into two non-disjoint subfamilies of the class ASM, here dubbed ASMh and ASMm. From this study a number of results stem which facilitate the assessment of semantics in the class ASMh ∪ASMm with respect to the properties of existence, relevance and cumulativity, whilst unveiling relations among these properties. As a result of the approach taken in our work, light is shed on the characterization of the SM semantics, as we show that the properties of (lack of) existence and (lack of) cautious monotony are equivalent, which opposes statements on this issue that may be found in the literature. We also characterize the relevance failure of SM semantics in a more clear way than usually stated in the literature.",
            "output": [
                "Properties of Stable Model Semantics Extensions"
            ]
        },
        {
            "id": "task1540-e6bfc459578a4fa192051e279b6acfc4",
            "input": "This paper discusses a method for im­ plementing a probabilistic inference system based on an extended relational data model. This model provides a unified approach for a variety of applications such as dynamic pro­ gramming, solving sparse linear equations, and constraint propagation. In this frame­ work, the probability model is represented as a generalized relational database. Subse­ quent probabilistic requests can be processed as standard relational queries. Conventional database management systems can be easily adopted for implementing such an approxi­ mate reasoning system.",
            "output": [
                "A Method for Implementing a Probabilistic Model as a Relational Database"
            ]
        },
        {
            "id": "task1540-2d38c991646c4fd9a98f19c3d5b10d94",
            "input": "In multilingual question answering, either the question needs to be translated into the document language, or vice versa. In addition to direction, there are multiple methods to perform the translation, four of which we explore in this paper: word-based, 10-best, contextbased, and grammar-based. We build a feature for each combination of translation direction and method, and train a model that learns optimal feature weights. On a large forum dataset consisting of posts in English, Arabic, and Chinese, our novel learn-to-translate approach was more effective than a strong baseline (p < 0.05): translating all text into English, then training a classifier based only on English (original or translated) text.",
            "output": [
                "Learning to Translate for Multilingual Question Answering"
            ]
        },
        {
            "id": "task1540-04c8f1f43c7746ba9a08386db48b2054",
            "input": "Statistical Relational Learning (SRL) methods have shown that classification accuracy can be improved by integrating relations between samples. Techniques such as iterative classification or relaxation labeling achieve this by propagating information between related samples during the inference process. When only a few samples are labeled and connections between samples are sparse, collective inference methods have shown large improvements over standard feature-based ML methods. However, in contrast to feature based ML, collective inference methods require complex inference procedures and often depend on the strong assumption of label consistency among related samples. In this paper, we introduce new relational features for standard ML methods by extracting information from direct and indirect relations. We show empirically on three standard benchmark datasets that our relational features yield results comparable to collective inference methods. Finally we show that our proposal outperforms these methods when additional information is available.",
            "output": [
                "Graph Based Relational Features for Collective Classification"
            ]
        },
        {
            "id": "task1540-1a6b5860c48a4c5795b23c28bca80a88",
            "input": "This paper describes a new approach allowing the generation of a simplified Biped gait. This approach combines a classical dynamic modeling with an inverse kinematics’ solver based on particle swarm optimization, PSO. First, an inverted pendulum, IP, is used to obtain a simplified dynamic model of the robot and to compute the target position of a key point in biped locomotion, the Centre Of Mass, COM. The proposed algorithm, called IK-PSO, Inverse Kinematics PSO, returns and inverse kinematics solution corresponding to that COM respecting the joints constraints. In This paper the inertia weight PSO variant is used to generate a possible solution according to the stability based fitness function and a set of joints motions constraints. The method is applied with success to a leg motion generation. Since based on a precalculated COM, that satisfied the biped stability, the proposal allowed also to plan a walk with application on a small size biped robot. General Terms Robotics, Robotic Modeling, Computational Intelligence",
            "output": [
                "IK-PSO, PSO Inverse Kinematics Solver with Application to Biped Gait Generation"
            ]
        },
        {
            "id": "task1540-f336fe02dd3d4d27abcae8059f161dd5",
            "input": "We consider manipulation problems when the manipulator only has partial information about the votes of the nonmanipulators. Such partial information is described by an information set, which is the set of profiles of the nonmanipulators that are indistinguishable to the manipulator. Given such an information set, a dominating manipulation is a non-truthful vote that the manipulator can cast which makes the winner at least as preferable (and sometimes more preferable) as the winner when the manipulator votes truthfully. When the manipulator has full information, computing whether or not there exists a dominating manipulation is in P for many common voting rules (by known results). We show that when the manipulator has no information, there is no dominating manipulation for many common voting rules. When the manipulator’s information is represented by partial orders and only a small portion of the preferences are unknown, computing a dominating manipulation is NP-hard for many common voting rules. Our results thus throw light on whether we can prevent strategic behavior by limiting information about the votes of other voters.",
            "output": [
                "Dominating Manipulations in Voting with Partial Information"
            ]
        },
        {
            "id": "task1540-e2f2f6688cd34051b8e0e84c6a25f0a1",
            "input": "Distributed optimization algorithms for largescale machine learning suffer from a communication bottleneck. Reducing communication makes the efficient aggregation of partial work from different machines more challenging. In this paper we present a novel generalization of the recent communication efficient primal-dual coordinate ascent framework (COCOA). Our framework, COCOA+, allows for additive combination of local updates to the global parameters at each iteration, whereas previous schemes only allowed conservative averaging. We give stronger (primal-dual) convergence rate guarantees for both COCOA as well as our new variants, and generalize the theory for both methods to also cover non-smooth convex loss functions. We provide an extensive experimental comparison on several real-world distributed datasets, showing markedly improved performance, especially when scaling up the number of machines.",
            "output": [
                "Adding vs. Averaging in Distributed Primal-Dual Optimization "
            ]
        },
        {
            "id": "task1540-fd8593f18aff41d386c829a9eca6e9bf",
            "input": "Understanding language goes hand in hand with the ability to integrate complex contextual information obtained via perception. In this work, we present a novel task for grounded language understanding: disambiguating a sentence given a visual scene which depicts one of the possible interpretations of that sentence. To this end, we introduce a new multimodal corpus containing ambiguous sentences, representing a wide range of syntactic, semantic and discourse ambiguities, coupled with videos that visualize the different interpretations for each sentence. We address this task by extending a vision model which determines if a sentence is depicted by a video. We demonstrate how such a model can be adjusted to recognize different interpretations of the same underlying sentence, allowing to disambiguate sentences in a unified fashion across the different ambiguity types.",
            "output": [
                "Do You See What I Mean? Visual Resolution of Linguistic Ambiguities"
            ]
        },
        {
            "id": "task1540-027474bea82e4b48bcfec9f5e74c186f",
            "input": "Multimodal sentiment analysis is an increasingly popular research area, which extends the conventional language-based definition of sentiment analysis to a multimodal setup where other relevant modalities accompany language. In this paper, we pose the problem of multimodal sentiment analysis as modeling intra-modality and inter-modality dynamics. We introduce a novel model, termed Tensor Fusion Network, which learns both such dynamics end-to-end. The proposed approach is tailored for the volatile nature of spoken language in online videos as well as accompanying gestures and voice. In the experiments, our model outperforms state-ofthe-art approaches for both multimodal and unimodal sentiment analysis.",
            "output": [
                "Tensor Fusion Network for Multimodal Sentiment Analysis"
            ]
        },
        {
            "id": "task1540-602ec94ae18c41a980e8ea587053a582",
            "input": "We propose a multiagent system that have feedforward networks as its subset while free from layer structure with matrix-vector scheme. Deep networks are often compared to the brain neocortex or visual perception system. One of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture. It would help understanding the way human brain works if we manage to develop good deep network model without the layer architecture while preserving their performance. The brain neocortex works as an aggregation of the local level interactions between neurons, which is rather similar to multiagent system consists of autonomous partially observing agents than units aligned in column vectors and manipulated by global level algorithm. Therefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents. Our method also has advantage in scalability and memory efficiency. We reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives. Additionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\", and showed its computational advantage with the MNIST dataset.",
            "output": [
                "MULTIAGENT SYSTEM FOR LAYER FREE NETWORK"
            ]
        },
        {
            "id": "task1540-bfbe5e52973c42cebf7832675021615d",
            "input": "Recursive neural models, which use syntactic parse trees to recursively generate representations bottom-up from parse children, are a popular new architecture, promising to capture structural properties like the scope of negation or long-distance semantic dependencies. But understanding exactly which tasks this parse-based method is appropriate for remains an open question. In this paper we benchmark recursive neural models against sequential recurrent neural models, which are structured solely on word sequences. We investigate 5 tasks: sentiment classification on (1) sentences and (2) syntactic phrases; (3) question answering; (4) discourse parsing; (5) semantic relations (e.g., component-whole between nouns); We find that recurrent models have equal or superior performance to recursive models on all tasks except one: semantic relations between nominals. Our analysis suggests that tasks relying on the scope of negation (like sentiment) are well-handled by sequential models. Recursive models help only with tasks that require representing long-distance relations between words. Our results offer insights on the design of neural architectures for representation learning.",
            "output": [
                "When Are Tree Structures Necessary for Deep Learning of Representations?"
            ]
        },
        {
            "id": "task1540-282d6fa4fac4408a9d8612a8487177f9",
            "input": "In this paper, we propose and investigate a novel memory architecture for neural networks called Hierarchical Attentive Memory (HAM). It is based on a binary tree with leaves corresponding to memory cells. This allows HAM to perform memory access in Θ(logn) complexity, which is a significant improvement over the standard attention mechanism that requires Θ(n) operations, where n is the size of the memory. We show that an LSTM network augmented with HAM can learn algorithms for problems like merging, sorting or binary searching from pure input-output examples. In particular, it learns to sort n numbers in time Θ(n logn) and generalizes well to input sequences much longer than the ones seen during the training. We also show that HAM can be trained to act like classic data structures: a stack, a FIFO queue and a priority queue.",
            "output": [
                "Learning Efficient Algorithms with Hierarchical Attentive Memory"
            ]
        },
        {
            "id": "task1540-f3777e50a8994b09afd95891aae6795e",
            "input": "We propose a new algorithm for minimizing regularized empirical loss: Stochastic Dual Newton Ascent (SDNA). Our method is dual in nature: in each iteration we update a random subset of the dual variables. However, unlike existing methods such as stochastic dual coordinate ascent, SDNA is capable of utilizing all curvature information contained in the examples, which leads to striking improvements in both theory and practice – sometimes by orders of magnitude. In the special case when an L2-regularizer is used in the primal, the dual problem is a concave quadratic maximization problem plus a separable term. In this regime, SDNA in each step solves a proximal subproblem involving a random principal submatrix of the Hessian of the quadratic function; whence the name of the method. If, in addition, the loss functions are quadratic, our method can be interpreted as a novel variant of the recently introduced Iterative Hessian Sketch.",
            "output": [
                "SDNA: Stochastic Dual Newton Ascent for Empirical Risk Minimization"
            ]
        },
        {
            "id": "task1540-1ed67470024f4cb3923c85a75e354da8",
            "input": "Clustering is an effective technique in data mining to generate groups that are the matter of interest. Among various clustering approaches, the family of k-means algorithms and min-cut algorithms gain most popularity due to their simplicity and efficacy. The classical k-means algorithm partitions a number of data points into several subsets by iteratively updating the clustering centers and the associated data points. By contrast, a weighted undirected graph is constructed in min-cut algorithms which partition the vertices of the graph into two sets. However, existing clustering algorithms tend to cluster minority of data points into a subset, which shall be avoided when the target dataset is balanced. To achieve more accurate clustering for balanced dataset, we propose to leverage exclusive lasso on k-means and min-cut to regulate the balance degree of the clustering results. By optimizing our objective functions that build atop the exclusive lasso, we can make the clustering result as much balanced as possible. Extensive experiments on several large-scale datasets validate the advantage of the proposed algorithms compared to the state-of-the-art clustering algorithms.",
            "output": [
                "Balanced k-Means and Min-Cut Clustering"
            ]
        },
        {
            "id": "task1540-d15dcce487024eee8a84f9dd8378f577",
            "input": "In this report, we will be interested at Dynamic Bayesian Network (DBNs) as a model that tries to incorporate temporal dimension with uncertainty. We start with basics of DBN where we especially focus in Inference and Learning concepts and algorithms. Then we will present different levels and methods of creating DBNs as well as approaches of incorporating temporal dimension in static Bayesian network. KeywordsDBN, DAG, Inference, Learning, HMM, EM Algorithm, SEM, MLE, coupled HMMs",
            "output": [
                "Characterization of Dynamic Bayesian Network The Dynamic Bayesian Network as temporal network"
            ]
        },
        {
            "id": "task1540-9611534e5a38438e9d95b0710e08d7b7",
            "input": "Logic programs with aggregates (LP) are one of the major linguistic extensions to Logic Programming (LP). In this work, we propose a generalization of the notions of unfounded set and well-founded semantics for programs with monotone and antimonotone aggregates (LPm,a programs). In particular, we present a new notion of unfounded set for LPm,a programs, which is a sound generalization of the original definition for standard (aggregate-free) LP. On this basis, we define a well-founded operator for LPm,a programs, the fixpoint of which is called well-founded model (or well-founded semantics) for LPm,a programs. The most important properties of unfounded sets and the well-founded semantics for standard LP are retained by this generalization, notably existence and uniqueness of the well-founded model, together with a strong relationship to the answer set semantics for LPm,a programs. We show that one of the D̃-well-founded semantics, defined by Pelov, Denecker, and Bruynooghe for a broader class of aggregates using approximating operators, coincides with the well-founded model as defined in this work on LPm,a programs. We also discuss some complexity issues, most importantly we give a formal proof of tractable computation of the well-founded model for LPm,a programs. Moreover, we prove that for general LP programs, which may contain aggregates that are neither monotone nor antimonotone, deciding satisfaction of aggregate expressions with respect to partial interpretations is coNP-complete. As a consequence, a well-founded semantics for general LP programs that allows for tractable computation is unlikely to exist, which justifies the restriction on LPm,a programs. Finally, we present a prototype system extending DLV, which supports the well-founded semantics for LPm,a programs, at the time of writing the only implemented system that does so. Experiments with this prototype show significant computational advantages of aggregate constructs over equivalent aggregate-free encodings.",
            "output": [
                "Unfounded Sets and Well-Founded Semantics of Answer Set Programs with Aggregates"
            ]
        },
        {
            "id": "task1540-dc77b3ecb7d6418dabf0762e69ab7516",
            "input": "Stochastic gradient MCMC (SG-MCMC) has played an important role in largescale Bayesian learning, with well-developed theoretical convergence properties. In such applications of SG-MCMC, it is becoming increasingly popular to employ distributed systems, where stochastic gradients are computed based on some outdated parameters, yielding what are termed stale gradients. While stale gradients could be directly used in SG-MCMC, their impact on convergence properties has not been well studied. In this paper we develop theory to show that while the bias and MSE of an SG-MCMC algorithm depend on the staleness of stochastic gradients, its estimation variance (relative to the expected estimate, based on a prescribed number of samples) is independent of it. In a simple Bayesian distributed system with SG-MCMC, where stale gradients are computed asynchronously by a set of workers, our theory indicates a linear speedup on the decrease of estimation variance w.r.t. the number of workers. Experiments on synthetic data and deep neural networks validate our theory, demonstrating the effectiveness and scalability of SG-MCMC with stale gradients.",
            "output": [
                "Stochastic Gradient MCMC with Stale Gradients"
            ]
        },
        {
            "id": "task1540-8d038b51b93f4fadb57ecb8f0a01452c",
            "input": "We extend the standard rough set-based approach to deal with huge amounts of numeric attributes versus small amount of available objects. Here, a novel approach of clustering along with dimensionality reduction; Hybrid Fuzzy C Means-Quick Reduct (FCMQR) algorithm is proposed for single gene selection. Gene selection is a process to select genes which are more informative. It is one of the important steps in knowledge discovery. The problem is that all genes are not important in gene expression data. Some of the genes may be redundant, and others may be irrelevant and noisy. In this study, the entire dataset is divided in proper grouping of similar genes by applying Fuzzy C Means (FCM) algorithm. A high class discriminated genes has been selected based on their degree of dependenc e by applying Quick Reduct algorithm based on Rough Set Theory to all the resultant clusters. Average Correlation Value (ACV) is calculated f or the high class discriminated genes. The clusters which have the ACV value a s 1 is determined as significant clusters, whose classification accuracy will be equal or high when comparing to the accuracy of the entire dataset. The proposed algorithm is evaluated using WEKA classifiers and compared. Finally, experimental results related to the leukemia cancer data confirm that our approach is quite promising, though it surely requires further research.",
            "output": [
                "A Novel Approach for Single Gene Selection Using Clustering and Dimensionality Reduction"
            ]
        },
        {
            "id": "task1540-f8be7b1130ee46b59a4d7811b264cdb8",
            "input": "A word’s sentiment depends on the domain in which it is used. Computational social science research thus requires sentiment lexicons that are specific to the domains being studied. We combine domain-specific word embeddings with a label propagation framework to induce accurate domain-specific sentiment lexicons using small sets of seed words. We show that our approach achieves state-of-the-art performance on inducing sentiment lexicons from domain-specific corpora and that our purely corpus-based approach outperforms methods that rely on hand-curated resources (e.g., WordNet). Using our framework, we induce and release historical sentiment lexicons for 150 years of English and community-specific sentiment lexicons for 250 online communities from the social media forum Reddit. The historical lexicons we induce show that more than 5% of sentiment-bearing (nonneutral) English words completely switched polarity during the last 150 years, and the community-specific lexicons highlight how sentiment varies drastically between different communities.",
            "output": [
                "Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora"
            ]
        },
        {
            "id": "task1540-30431adb59cb422e8ff6ba05b67c4e3f",
            "input": "There have been multiple attempts to resolve various inflection matching problems in information retrieval. Stemming is a common approach to this end. Among many techniques for stemming, statistical stemming has been shown to be effective in a number of languages, particularly highly inflected languages. In this paper we propose a method for finding affixes in different positions of a word. Common statistical techniques heavily rely on string similarity in terms of prefix and suffix matching. Since infixes are common in irregular/informal inflections in morphologically complex texts, it is required to find infixes for stemming. In this paper we propose a method whose aim is to find statistical inflectional rules based on minimum edit distance table of word pairs and the likelihoods of the rules in a language. These rules are used to statistically stem words and can be used in different text mining tasks. Experimental results on CLEF 2008 and CLEF 2009 English-Persian CLIR tasks indicate that the proposed method significantly outperforms all the baselines in terms of MAP.",
            "output": [
                "SS4MCT: A Statistical Stemmer for Morphologically Complex Texts"
            ]
        },
        {
            "id": "task1540-0cda0cc6b1cb4a14a5d64332de427bdc",
            "input": "The recent surge in interest in ethics in artificial intelligence may leave many educators wondering how to address moral, ethical, and philosophical issues in their AI courses. As instructors we want to develop curriculum that not only prepares students to be artificial intelligence practitioners, but also to understand the moral, ethical, and philosophical impacts that artificial intelligence will have on society. In this article we provide practical case studies and links to resources for use by AI educators. We also provide concrete suggestions on how to integrate AI ethics into a general artificial intelligence course and how to teach a stand-alone artificial intelligence ethics course.",
            "output": [
                "Ethical Considerations in Artificial Intelligence Courses"
            ]
        },
        {
            "id": "task1540-815a766001d94f48be64310c5c33ae31",
            "input": "The impact of culture in visual emotion perception has recently captured the attention of multimedia research. In this study, we provide powerful computational linguistics tools to explore, retrieve and browse a dataset of 16K multilingual affective visual concepts and 7.3M Flickr images. First, we design an effective crowdsourcing experiment to collect human judgements of sentiment connected to the visual concepts. We then use word embeddings to represent these concepts in a low dimensional vector space, allowing us to expand the meaning around concepts, and thus enabling insight about commonalities and differences among different languages. We compare a variety of concept representations through a novel evaluation task based on the notion of visual semantic relatedness. Based on these representations, we design clustering schemes to group multilingual visual concepts, and evaluate them with novel metrics based on the crowdsourced sentiment annotations as well as visual semantic relatedness. The proposed clustering framework enables us to analyze the full multilingual dataset in-depth and also show an application on a facial data subset, exploring cultural insights of portrait-related affective visual concepts.",
            "output": [
                "Multilingual Visual Sentiment Concept Matching"
            ]
        },
        {
            "id": "task1540-ae2de2adefeb4c5f929f5c74a37c9216",
            "input": "This paper presents machine learning solutions to a practical problem of Natural Language Generation (NLG), particularly the word formation in agglutinative languages like Tamil, in a supervised manner. The morphological generator is an important component of Natural Language Processing in Artificial Intelligence. It generates word forms given a root and affixes. The morphophonemic changes like addition, deletion, alternation etc., occur when two or more morphemes or words joined together. The Sandhi rules should be explicitly specified in the rule based morphological analyzers and generators. In machine learning framework, these rules can be learned automatically by the system from the training samples and subsequently be applied for new inputs. In this paper we proposed the machine learning models which learn the morphophonemic rules for noun declensions from the given training data. These models are trained to learn sandhi rules using various learning algorithms and the performance of those algorithms are presented. From this we conclude that machine learning of morphological processing such as word form generation can be successfully learned in a supervised manner, without explicit description of rules. The performance of Decision trees and Bayesian machine learning algorithms on noun declensions are discussed.",
            "output": [
                "MACHINE LEARNING OF PHONOLOGICALLY CONDITIONED NOUN DECLENSIONS FOR TAMIL MORPHOLOGICAL GENERATORS"
            ]
        },
        {
            "id": "task1540-19a55029061740d29e3109ec602c433a",
            "input": "A famous biologically inspired hierarchical model firstly proposed by Riesenhuber and Poggio has been successfully applied to multiple visual recognition tasks. The model is able to achieve a set of positionand scale-tolerant recognition, which is a central problem in pattern recognition. In this paper, based on some other biological experimental results, we introduce the Memory and Association Mechanisms into the above biologically inspired model. The main motivations of the work are (a) to mimic the active memory and association mechanism and add the ’top down’ adjustment to the above biologically inspired hierarchical model and (b) to build up an algorithm which can save the space and keep a good recognition performance. More details of the work could be explained as follows: (1) In objects memorizing process: Our proposed model mimics some characteristics of human’s memory mechanism as follows: (a) In our model, one object is memorized by semantic attributes and special image patches (corresponding to episodic memory). The semantic attributes describe each part of the object with clear physical meaning, for example, if eyes and mouths of faces are ’big’ or ’small’ and so on. One special patch is selected if the value of the corresponding semantic feature is far from average one. The patch should be the most prominent part of the object. (b) In our model, different features (semantic attributes and special patches) of one object are stored in distributed places and the common feature of different objects is saved aggregately, which can learn to classify the difference of similar features of different objects. The similarity thresholds to each object can be learnt when new objects are learnt. (2) In object recognition process: In biological process, the associated recognition including familiarity discrimination and recollective matching. In our proposed model, firstly mimicking familiarity discrimination (’knowing’ though the episode), we compare the special patches of candidates with that of saved objects using above mentioned biologically inspired hierarchical model, where the candidates and saved objects have the same prominent semantic features. Then mimicking recollective matching, the comparison results of special patches are combined with semantic feature comparison. The new model is also applied to object recognition processes. The primary experimental results show that our method is efficient with much less memory requirement.",
            "output": [
                "Introducing Memory and Association Mechanism Into a Biologically Inspired Visual Model"
            ]
        },
        {
            "id": "task1540-b94db145c86c4943a691aea7cf3c8a1c",
            "input": "We propose an efficient technique for multilabel classification based on calibration, a term we use to mean learning a link function that maps independent predictions to joint predictions. Though a naive implementation of our proposal would require training individual classifiers for each label, we show that for natural datasets and linear classifiers we can sidestep this by leveraging techniques from randomized linear algebra. Moreover, our algorithm applies equally well to multiclass classification. The end result is an algorithm that scales to very large multilabel and multiclass problems, and offers state of the art accuracy on many datasets.",
            "output": [
                "Multilabel Prediction via Calibration"
            ]
        },
        {
            "id": "task1540-d2c1928dc2694d2eb93ecd7eedcbda4d",
            "input": "This paper discusses SYNTAGMA, a rule based NLP system addressing the tricky issues of syntactic ambiguity reduction and word sense disambiguation as well as providing innovative and original solutions for constituent generation and constraints management. To provide an insight into how it operates, the system's general architecture and components, as well as its lexical, syntactic and semantic resources are described. After that, the paper addresses the mechanism that performs selective parsing through an interaction between syntactic and semantic information, leading the parser to a coherent and accurate interpretation of the input text.",
            "output": [
                "Syntax-Semantics Interaction Parsing Strategies. Inside SYNTAGMA"
            ]
        },
        {
            "id": "task1540-777e9345097d410e9ea4d85eb7114b07",
            "input": "The historic background of algorithmic processing with regard to etymology and methodology is translated into terms of mathematical logic and Computer Science. A formal logic structure is introduced by exemplary questions posed to Fiqh-chapters to define a logic query language. As a foundation, a generic algorithm for deciding Fiqhrulings is designed to enable and further leverage rule of law (vs. rule by law) with full transparency and complete algorithmic coverage of Islamic law eventually providing legal security, legal equality, and full legal accountability. This is implemented by disentangling and reinstating classic Fiqh-methodology (usul al-Fiqh) with the expressive power of subsets of First Order Logic (FOL) sustainably substituting ad hoc reasoning with falsifiable rational argumentation. The results are discussed in formal terms of completeness, decidability and complexity of formal Fiqh-systems. An Entscheidungsproblem for formal Fiqh-Systems is formulated and validated.",
            "output": [
                "The Algorithm of Islamic Jurisprudence (Fiqh) with Validation of an Entscheidungsproblem"
            ]
        },
        {
            "id": "task1540-23eb7c983589412e971bb994c498a976",
            "input": "Applying deep reinforcement learning (RL) on real systems suffers from slow data sampling. We propose an enhanced generative adversarial network (EGAN) to initialize an RL agent in order to achieve faster learning. The EGAN utilizes the relation between states and actions to enhance the quality of data samples generated by a GAN. Pre-training the agent with the EGAN shows a steeper learning curve with a 20% improvement of training time in the beginning of learning, compared to no pre-training, and an improvement compared to training with GAN by about 5% with smaller variations. For real time systems with sparse and slow data sampling the EGAN could be used to speed up the early phases of the training process.",
            "output": [
                "Enhanced Experience Replay Generation for Efficient Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-7d126bcc6b684c369c368a035ca85f43",
            "input": "Many logistic activities are concerned with linking material flows among companies and processes. In such applications, we find a combination of quantity decisions, e. g. the amount of goods shipped (Inventory Management), and routing decisions as tackled in the area of Vehicle Routing. Clearly, both areas intersect to a considerable degree, complicating the solution of such problems. Recently, intensive research has been conducted in this context which is commonly refereed to as Inventory Routing Problems [2, 3] (IRP). Several variants of the IRP can be found, ranging from deterministic demand cases to stochastic models. From the practical point of view of the companies, reality is much more complex than a know demand and much more uncertain than a stochastic law. In fact, companies often have a partial knowledge of the demand over the planning horizon. Our observation of this phenomenon can be transformed in a new type of data, which we propose for further experimental investigations. We here assume that demand of the current period is known at the beginning of the period. Besides, we have an approximate overview of the demand over the 5 next periods, the 20 next periods and the 60 next periods. This overview is rather good (e.g. it does not differ from reality by more that ±10%) but of course, we cannot predict with certainty what will happen the next periods. The global objective of this work is to provide practical optimization methods to companies involved in inventory routing problems, taking into account this new type of data. Also, companies are sometimes not able to deal with changing plans every period and would like to adopt regular structures for serving customers. As our work is a long term project, we are gradually going to develop our solution approach. In a first phase, we will focus on the Inventory Routing problem with a single product, deterministic known demand over a finite horizon. Contrary to [1], we assume that the routing costs and the inventory costs are not comparable and therefore should be handled as two different objectives. To our knowledge, this is the first time that a bi-objective approach is considered for this problem.",
            "output": [
                "Practical inventory routing: A problem definition and an optimization method"
            ]
        },
        {
            "id": "task1540-2f7d036b5795448f902e93007d4202a7",
            "input": "An efficient, and intuitive algorithm is presented for the identification of speakers from a long dataset (like YouTube long discussion, Cocktail party recorded audio or video).The goal of automatic speaker identification is to identify the number of different speakers and prepare a model for that speaker by extraction, characterization and speaker-specific information contained in the speech signal. It has many diverse application specially in the field of Surveillance , Immigrations at Airport , cyber security , transcription in multi-source of similar sound source, where it is difficult to assign transcription arbitrary. The most commonly speech parameterization used in speaker verification, K-mean, cepstral analysis, is detailed. Gaussian mixture modeling, which is the speaker modeling technique is then explained. Gaussian mixture models (GMM), perhaps the most robust machine learning algorithm has been introduced to examine and judge carefully speaker identification in text independent. The application or employment of Gaussian mixture models for monitoring & Analysing speaker identity is encouraged by the familiarity, awareness, or understanding gained through experience that Gaussian spectrum depict the characteristics of speaker's spectral conformational pattern and remarkable ability of GMM to construct capricious densities after that we illustrate 'Expectation maximization' an iterative algorithm which takes some arbitrary value in initial estimation and carry on the iterative process until the convergence of value is observed We have tried to obtained 85 ~ 95% of accuracy using speaker modeling of vector quantization and Gaussian Mixture model ,so by doing various number of experiments we are able to obtain 79 ~ 82% of identification rate using Vector quantization and 85 ~ 92.6% of identification rate using GMM modeling by Expectation maximization parameter estimation depending on variation of parameter.",
            "output": [
                "SPEAKER IDENTIFICATION FROM YOUTUBE OBTAINED DATA"
            ]
        },
        {
            "id": "task1540-27b49b4469a8480f8cc8d877a5dbcde9",
            "input": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC [6] while being simpler. We show competitive results in word error rate on the Librispeech corpus [18] with MFCC features, and promising results from raw waveform.",
            "output": [
                "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System"
            ]
        },
        {
            "id": "task1540-c3f55003968e4d79bab65c23647e2d10",
            "input": "The success of semi-supervised learning crucially relies on the scalability to a huge amount of unlabelled data that are needed to capture the underlying manifold structure for better classification. Since computing the pairwise similarity between the training data is prohibitively expensive in most kinds of input data, currently, there is no general readyto-use semi-supervised learning method/tool available for learning with tens of millions or more data points. In this paper, we adopted the idea of two low-rank label propagation algorithms, GLNP (Global Linear Neighborhood Propagation) and Kernel Nyström Approximation, and implemented the parallelized version of the two algorithms accelerated with Nesterov’s accelerated projected gradient descent for Big-data Label Propagation (BigLP). The parallel algorithms are tested on five real datasets ranging from 7000 to 10,000,000 in size and a simulation dataset of 100,000,000 samples. In the experiments, the implementation can scale up to datasets with 100,000,000 samples and hundreds of features and the algorithms also significantly improved the prediction accuracy when only a very small percentage of the data is labeled. The results demonstrate that the BigLP implementation is highly scalable to big data and effective in utilizing the unlabeled data for semi-supervised learning.",
            "output": [
                "Low-rank Label Propagation for Semi-supervised Learning with 100 Millions Samples"
            ]
        },
        {
            "id": "task1540-edc20043ee7a44febfd29f20631bf9ea",
            "input": "In this paper, we propose a multi-kernel classifier learning algorithm to optimize a given nonlinear and nonsmoonth multivariate classifier performance measure. Moreover, to solve the problem of kernel function selection and kernel parameter tuning, we proposed to construct an optimal kernel by weighted linear combination of some candidate kernels. The learning of the classifier parameter and the kernel weight are unified in a single objective function considering to minimize the upper boundary of the given multivariate performance measure. The objective function is optimized with regard to classifier parameter and kernel weight alternately in an iterative algorithm by using cutting plane algorithm. The developed algorithm is evaluated on two different pattern classification methods with regard to various multivariate performance measure optimization problems. The experiment results show the proposed algorithm outperforms the competing methods.",
            "output": [
                "Multiple kernel multivariate performance learning using cutting plane algorithm"
            ]
        },
        {
            "id": "task1540-19c8871f37a347faa1d936b2a9e6f55e",
            "input": "Several authors have recently developed risk-sensitive policy gradient methods<lb>that augment the standard expected cost minimization problem with a measure of<lb>variability in cost. These studies have focused on specific risk-measures, such as<lb>the variance or conditional value at risk (CVaR). In this work, we extend the pol-<lb>icy gradient method to the whole class of coherent risk measures, which is widely<lb>accepted in finance and operations research, among other fields. We consider<lb>both static and time-consistent dynamic risk measures. For static risk measures,<lb>our approach is in the spirit of policy gradient algorithms and combines a standard<lb>sampling approach with convex programming. For dynamic risk measures, our ap-<lb>proach is actor-critic style and involves explicit approximation of value function.<lb>Most importantly, our contribution presents a unified approach to risk-sensitive<lb>reinforcement learning that generalizes and extends previous results.",
            "output": [
                "Policy Gradient for Coherent Risk Measures"
            ]
        },
        {
            "id": "task1540-be617c91255e43fa9ff90e7b5b01caef",
            "input": "Plan recognition aims to discover target plans (i.e., sequences of actions) behind observed actions, with history plan libraries or domain models in hand. Previous approaches either discover plans by maximally “matching” observed actions to plan libraries, assuming target plans are from plan libraries, or infer plans by executing domain models to best explain the observed actions, assuming complete domain models are available. In real world applications, however, target plans are often not from plan libraries and complete domain models are often not available, since building complete sets of plans and complete domain models are often difficult or expensive. In this paper we view plan libraries as corpora and learn vector representations of actions using the corpora; we then discover target plans based on the vector representations. Our approach is capable of discovering underlying plans that are not from plan libraries, without requiring domain models provided. We empirically demonstrate the effectiveness of our approach by comparing its performance to traditional plan recognition approaches in three planning domains.",
            "output": [
                "Discovering Underlying Plans Based on Distributed Representations of Actions"
            ]
        },
        {
            "id": "task1540-5420a01df2fa403eac95635bc7f0b205",
            "input": "We study expressive power of shallow and deep neural networks with piece-wise linear activation functions. We establish new rigorous upper and lower bounds for the network complexity in the setting of approximations in Sobolev spaces. In particular, we prove that deep ReLU networks more efficiently approximate smooth functions than shallow networks. In the case of approximations of 1D Lipschitz functions we describe adaptive depth-6 network architectures more efficient than the standard shallow architecture.",
            "output": [
                "Error bounds for approximations with deep ReLU networks"
            ]
        },
        {
            "id": "task1540-35016aaaa4124ebfb776efc3c821f657",
            "input": "In probabilistic logic entailments, even moderate size problems can yield linear constraint systems with so many variables that exact methods are impractical. This difficulty can be remedied in many cases of interest by introducing a three­ valued logic (true, false, and \"don't care\"). The three-valued approach allows the construction of \"compressed\" constraint systems which have the same solution sets as their two-valued counterparts, but which may involve dramatically fewer variables. Techniques to calculate point estimates for the posterior probabilities of entailed sentences are discussed. 1. PROLIFERATION OF WORLDS An entailment problem in Nilsson's (1986) probabilistic logic derives an estimate for the prior probability of one sentence (hereafter, the \"target\") from the priors for a set of other (\"source\") sentences. The prior beliefs about the source sentences establish constraints of the form P=VW L wi = l Wi <': 0 sum over all \"worlds\"",
            "output": [
                "Compressed Constraints in Probabilistic Logic and Their Revision"
            ]
        },
        {
            "id": "task1540-fbf56aff8ce546c292b903e413a7a1c7",
            "input": "Concept maps can be used to concisely represent important information and bring structure into large document collections. Therefore, we study a variant of multidocument summarization that produces summaries in the form of concept maps. However, suitable evaluation datasets for this task are currently missing. To close this gap, we present a newly created corpus of concept maps that summarize heterogeneous collections of web documents on educational topics. It was created using a novel crowdsourcing approach that allows us to efficiently determine important elements in large document collections. We release the corpus along with a baseline system and proposed evaluation protocol to enable further research on this variant of summarization.",
            "output": [
                "Connecting the dots: Summarizing and Structuring Large Document Collections Using Concept Maps"
            ]
        },
        {
            "id": "task1540-f04bf1bc60044036adec0b5e89ef9ef1",
            "input": "We extend the model of Multi-armed Bandit with unit switching cost to incorporate a metric between the actions. We consider the case where the metric over the actions can be modeled by a complete binary tree, and the distance between two leaves is the size of the subtree of their least common ancestor, which abstracts the case that the actions are points on the continuous interval r0, 1s and the switching cost is their distance. In this setting, we give a new algorithm that establishes a regret of r Op ? kT ` T {kq, where k is the number of actions and T is the time horizon. When the set of actions corresponds to whole r0, 1s interval we can exploit our method for the task of bandit learning with Lipschitz loss functions, where our algorithm achieves an optimal regret rate of r ΘpT 2{3q, which is the same rate one obtains when there is no penalty for movements. As our main application, we use our new algorithm to solve an adaptive pricing problem. Specifically, we consider the case of a single seller faced with a stream of patient buyers. Each buyer has a private value and a window of time in which they are interested in buying, and they buy at the lowest price in the window, if it is below their value. We show that with an appropriate discretization of the prices, the seller can achieve a regret of r OpT 2{3q compared to the best fixed price in hindsight, which outperform the previous regret bound of r OpT 3{4q for the problem.",
            "output": [
                "Bandits with Movement Costs and Adaptive Pricing"
            ]
        },
        {
            "id": "task1540-ddb0c182f92741cdba68a1d08d0230cb",
            "input": "In this paper, we provide two axiomatizations of algebraic expected utility, which is a particular generalized expected utility, in a von NeumannMorgenstern setting, i.e. uncertainty representation is supposed to be given and here to be described by a plausibility measure valued on a semiring, which could be partially ordered. We show that axioms identical to those for expected utility entail that preferences are represented by an algebraic expected utility. This algebraic approach allows many previous propositions (expected utility, binary possibilistic utility,...) to be unified in a same general framework and proves that the obtained utility enjoys the same nice features as expected utility: linearity, dynamic consistency, autoduality of the underlying uncertainty representation, autoduality of the decision criterion and possibility of modeling decision maker’s attitude toward uncertainty.",
            "output": [
                "Axiomatic Foundations for a Class of Generalized Expected Utility: Algebraic Expected Utility"
            ]
        },
        {
            "id": "task1540-a33945746e114281a4614c4f16163912",
            "input": "s prominently include information that is relevant to the population group of interest, and intervention, comparison and disease of interest. The vector space model further measures the similarity between the query and citation based on concepts (as opposed to just terms or words themselves).",
            "output": [
                "A Hybrid Citation Retrieval Algorithm for Evidence-based Clinical Knowledge Summarization: Combining Concept Extraction, Vector Similarity and Query Expansion for High Precision"
            ]
        },
        {
            "id": "task1540-10783dbda2de48a29f08686ec38412eb",
            "input": "We propose a label propagation approach to geolocation prediction based on Modified Adsorption, with two enhancements: (1) the removal of “celebrity” nodes to increase location homophily and boost tractability; and (2) the incorporation of text-based geolocation priors for test users. Experiments over three Twitter benchmark datasets achieve state-of-the-art results, and demonstrate the effectiveness of the enhancements.",
            "output": [
                "Twitter User Geolocation Using a Unified Text and Network Prediction Model"
            ]
        },
        {
            "id": "task1540-87a35380ce494e19a218ac0628e693c7",
            "input": "In this paper the behavior of various be­ lief network learning algorithms is stud­ ied. Selecting belief networks with cer­ tain minimallity properties turns out to be NP-hard, which justifies the use of search heuristics. Search heuristics based on the Bayesian measure of Cooper and Her­ skovits and a minimum description length (MDL) measure are compared with re­ spect to their properties for both limit­ ing and finite database sizes. It is shown that the MDL measure has more desir­ able properties than the Bayesian mea­ sure. Experimental results suggest that for learning probabilities of belief net­ works smoothing is helpful.",
            "output": [
                "Properties of Bayesian Belief Network Learning Algorithms"
            ]
        },
        {
            "id": "task1540-c45fb0c9d9e2400bba125c95b497d254",
            "input": "Gaussian Process bandit optimization has emerged as a powerful tool for optimizing noisy black box functions. One example in machine learning is hyper-parameter optimization where each evaluation of the target function requires training a model which may involve days or even weeks of computation. Most methods for this so-called “Bayesian optimization” only allow sequential exploration of the parameter space. However, it is often desirable to propose batches or sets of parameter values to explore simultaneously, especially when there are large parallel processing facilities at our disposal. Batch methods require modeling the interaction between the different evaluations in the batch, which can be expensive in complex scenarios. In this paper, we propose a new approach for parallelizing Bayesian optimization by modeling the diversity of a batch via Determinantal point processes (DPPs) whose kernels are learned automatically. This allows us to generalize a previous result as well as prove better regret bounds based on DPP sampling. Our experiments on a variety of synthetic and real-world robotics and hyper-parameter optimization tasks indicate that our DPP-based methods, especially those based on DPP sampling, outperform state-of-the-art methods.",
            "output": [
                "Batched Gaussian Process Bandit Optimization via Determinantal Point Processes"
            ]
        },
        {
            "id": "task1540-955100045f0c4d38a88bd3f5f7555225",
            "input": "Training Recurrent Neural Networks is more troublesome than feedforward ones because of the vanishing and exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to understand the fundamental issues underlying the exploding gradient problem by exploring it from an analytical, a geometric and a dynamical system perspective. Our analysis is used to justify the simple yet effective solution of norm clipping the exploded gradient. In the experimental section, the comparison between this heuristic solution and standard SGD provides empirical evidence towards our hypothesis as well as it shows that such a heuristic is required to reach state of the art results on a character prediction task and a polyphonic music prediction one.",
            "output": [
                "Understanding the exploding gradient problem"
            ]
        },
        {
            "id": "task1540-5da10dc0c4784dae8b109eaa465d2448",
            "input": "Graph partitioning, a well studied problem of parallel computing has many applications in diversified fields such as distributed computing, social network analysis, data mining and many other domains. In this paper, we introduce FGPGA, an efficient genetic approach for producing feasible graph partitions. Our method takes into account the heterogeneity and capacity constraints of the partitions to ensure balanced partitioning. Such approach has various applications in mobile cloud computing that include feasible deployment of software applications on the more resourceful infrastructure in the cloud instead of mobile hand set. Our proposed approach is light weight and hence suitable for use in cloud architecture. We ensure feasibility of the partitions generated by not allowing over-sized partitions to be generated during the initialization and search. Our proposed method tested on standard benchmark datasets significantly outperforms the state-of-the-art methods in terms of quality of partitions and feasibility of the solutions.",
            "output": [
                "FGPGA: An Efficient Genetic Approach for Producing Feasible Graph Partitions"
            ]
        },
        {
            "id": "task1540-7aa658ed0fcf4b5480094bd395a9f941",
            "input": "The present complexity in designing web applications makes software security a difficult goal to achieve. An attacker can explore a deployed service on the web and attack at his/her own leisure. Moving Target Defense (MTD) in web applications is an effective mechanism to nullify this advantage of their reconnaissance but the framework demands a good switching strategy when switching between multiple configurations for its web-stack. To address this issue, we propose modeling of a real-world MTD web application as a repeated Bayesian game. We then formulate an optimization problem that generates an effective switching strategy while considering the cost of switching between different web-stack configurations. To incorporate this model into a developed MTD system, we develop an automated system for generating attack sets of Common Vulnerabilities and Exposures (CVEs) for input attacker types with predefined capabilities. Our framework obtains realistic reward values for the players (defenders and attackers) in this game by using security domain expertise on CVEs obtained from the National Vulnerability Database (NVD). We also address the issue of prioritizing vulnerabilities that when fixed, improves the security of the MTD system. Lastly, we demonstrate the robustness of our proposed model by evaluating its performance when there is uncertainty about input attacker information.",
            "output": [
                "Moving Target Defense for Web Applications using Bayesian Stackelberg Games"
            ]
        },
        {
            "id": "task1540-f0885e4200514a109e7b28beb7dfdcb2",
            "input": "As the complexity of deep neural networks (DNNs) trend to grow to absorb the increasing sizes of data, memory and energy consumption has been receiving more and more attentions for industrial applications, especially on mobile devices. This paper presents a novel structure based on functional hashing to compress DNNs, namely FunHashNN. For each entry in a deep net, FunHashNN uses multiple low-cost hash functions to fetch values in the compression space, and then employs a small reconstruction network to recover that entry. The reconstruction network is plugged into the whole network and trained jointly. FunHashNN includes the recently proposed HashedNets [7] as a degenerated case, and benefits from larger value capacity and less reconstruction loss. We further discuss extensions with dual space hashing and multi-hops. On several benchmark datasets, FunHashNN demonstrates high compression ratios with little loss on prediction accuracy.",
            "output": [
                "Functional Hashing for Compressing Neural Networks"
            ]
        },
        {
            "id": "task1540-136371659e5642a98dc3981b32560714",
            "input": "It has been proved that large-scale realistic Knowledge Based Machine Translation (KBMT) applications require acquisition of huge knowledge about language and about the world. This knowledge is encoded in computational grammars, lexicons and domain models. Another approach – which avoids the need for collecting and analyzing massive knowledgeis the Example Based approach, which is the topic of this paper. We show through the paper that using Example Based in its native form is not suitable for translating into Arabic. Therefore a modification to the basic approach is presented to improve the accuracy of the translation process. The basic idea of the new approach is to improve the technique by which template-based approaches select the appropriate templates. It relies on extracting, from a parallel Bilingual Corpus, all possible templates that could match parts of the source sentence. These templates are selected as suitable candidate chunks for the source sentence. The corresponding Arabic templates are also extracted and represented by a diredted graph. Each branch represents one possible string of templates candidate to represent the target sentence. The shortest continuous path or the most probable tree branch is selected to represent the target sentence. Finally the Arabic translation of the selected tree branch is generated.",
            "output": [
                "The Best Templates Match Technique For Example Based Machine Translation"
            ]
        },
        {
            "id": "task1540-ffc8a5e4d03d424d8ac513818847d465",
            "input": "We present a new decision rule, maximin safety, that seeks to maintain a large margin from the worst outcome, in much the same way minimax regret seeks to minimize distance from the best. We argue that maximin safety is valuable both descriptively and normatively. Descriptively, maximin safety explains the well-known decoy effect, in which the introduction of a dominated option changes preferences among the other options. Normatively, we provide an axiomatization that characterizes preferences induced by maximin safety, and show that maximin safety shares much of the same behavioral basis with minimax regret.",
            "output": [
                "Maximin Safety: When Failing to Lose is Preferable to Trying to Win"
            ]
        },
        {
            "id": "task1540-35ad305fda3e49bfabf724820cee4c36",
            "input": "In recent years we have seen rapid and significant progress in automatic image description but what are the open problems in this area? Most work has been evaluated using text-based similarity metrics, which only indicate that there have been improvements, without explaining what has improved. In this paper, we present a detailed error analysis of the descriptions generated by a state-of-the-art attentionbased model. Our analysis operates on two levels: first we check the descriptions for accuracy, and then we categorize the types of errors we observe in the inaccurate descriptions. We find only 20% of the descriptions are free from errors, and surprisingly that 26% are unrelated to the image. Finally, we manually correct the most frequently occurring error types (e.g. gender identification) to estimate the performance reward for addressing these errors, observing gains of 0.2–1 BLEU point per type.",
            "output": [
                "Room for improvement in automatic image description: an error analysis"
            ]
        },
        {
            "id": "task1540-1eebaa1f6771459a8509158c5ccf83ae",
            "input": "Retrieving spoken content with spoken queries, or query-byexample spoken term detection (STD), is attractive because it makes possible the matching of signals directly on the acoustic level without transcribing them into text. Here, we propose an end-to-end query-by-example STD model based on an attention-based multi-hop network, whose input is a spoken query and an audio segment containing several utterances; the output states whether the audio segment includes the query. The model can be trained in either a supervised scenario using labeled data, or in an unsupervised fashion. In the supervised scenario, we find that the attention mechanism and multiple hops improve performance, and that the attention weights indicate the time span of the detected terms. In the unsupervised setting, the model mimics the behavior of the existing query-by-example STD system, yielding performance comparable to the existing system but with a lower search time complexity.",
            "output": [
                "QUERY-BY-EXAMPLE SPOKEN TERM DETECTION USING ATTENTION-BASED MULTI-HOP NETWORKS"
            ]
        },
        {
            "id": "task1540-cd2b01720d5c4f6da035a155c62501a4",
            "input": "For many low-resource or endangered languages, spoken language resources are more likely to be annotated with translations than with transcriptions. Recent work exploits such annotations to produce speech-to-translation alignments, without access to any text transcriptions. We investigate whether providing such information can aid in producing better (mismatched) crowdsourced transcriptions, which in turn could be valuable for training speech recognition systems, and show that they can indeed be beneficial through a smallscale case study as a proof-of-concept. We also present a simple phonetically aware string averaging technique that produces transcriptions of higher quality.",
            "output": [
                "A case study on using speech-to-translation alignments for language documentation"
            ]
        },
        {
            "id": "task1540-2bd7c18b97184b4fb922eb641f7cb55b",
            "input": "Ensembling is a well-known technique in neural machine translation (NMT) to improve system performance. Instead of a single neural net, multiple neural nets with the same topology are trained separately, and the decoder generates predictions by averaging over the individual models. Ensembling often improves the quality of the generated translations drastically. However, it is not suitable for production systems because it is cumbersome and slow. This work aims to reduce the runtime to be on par with a single system without compromising the translation quality. First, we show that the ensemble can be unfolded into a single large neural network which imitates the output of the ensemble system. We show that unfolding can already improve the runtime in practice since more work can be done on the GPU. We proceed by describing a set of techniques to shrink the unfolded network by reducing the dimensionality of layers. On JapaneseEnglish we report that the resulting network has the size and decoding speed of a single NMT network but performs on the level of a 3-ensemble system.",
            "output": [
                "Unfolding and Shrinking Neural Machine Translation Ensembles"
            ]
        },
        {
            "id": "task1540-0b90f62d080c4f868b13b296bd61d949",
            "input": "Recent research shows that most Brazilian students have serious problems regarding their reading skills. The full development of this skill is key for the academic and professional future of every citizen. Tools for classifying the complexity of reading materials for children aim to improve the quality of the model of teaching reading and text comprehension. For English, Feng’s work [11] is considered the state-of-art in grade level prediction and achieved 74% of accuracy in automatically classifying 4 levels of textual complexity for close school grades. There are no classifiers for nonfiction texts for close grades in Portuguese. In this article, we propose a scheme for manual annotation of texts in 5 grade levels, which will be used for customized reading to avoid the lack of interest by students who are more advanced in reading and the blocking of those that still need to make further progress. We obtained 52% of accuracy in classifying texts into 5 levels and 74% in 3 levels. The results prove to be promising when compared to the state-of-art work.",
            "output": [
                "Automatic Classification of the Complexity of Nonfiction Texts in Portuguese for Early School Years"
            ]
        },
        {
            "id": "task1540-c7f5b4ef462e42de849f0b9abf6d804f",
            "input": "It is hypothesized that creativity arises from the self-mending capacity of an internal model of the world, or worldview. The uniquely honed worldview of a creative individual results in a distinctive style that is recognizable within and across domains. It is further hypothesized that creativity is domaingeneral in the sense that there exist multiple avenues by which the distinctiveness of one’s worldview can be expressed. These hypotheses were tested using art students and creative writing students. Art students guessed significantly above chance both which painting was done by which of five famous artists, and which artwork was done by which of their peers. Similarly, creative writing students guessed significantly above chance both which passage was written by which of five famous writers, and which passage was written by which of their peers. These findings support the hypothesis that creative style is recognizable. Moreover, creative writing students guessed significantly above chance which of their peers produced particular works of art, supporting the hypothesis that creative style is recognizable not just within but across domains.",
            "output": [
                "Recognizability of Individual Creative Style Within and Across Domains: Preliminary Studies"
            ]
        },
        {
            "id": "task1540-01f0886bf96f4c4daf003a743f4b9b32",
            "input": "The GLEU metric was proposed for evaluating grammatical error corrections using n-gram overlap with a set of reference sentences, as opposed to precision/recall of specific annotated errors (Napoles et al., 2015). This paper describes improvements made to the GLEU metric that address problems that arise when using an increasing number of reference sets. Unlike the originally presented metric, the modified metric does not require tuning. We recommend that this version be used instead of the original version.1",
            "output": [
                "GLEU Without Tuning"
            ]
        },
        {
            "id": "task1540-17b9b356bdfd4a13a767ca119ef7c45d",
            "input": "We present a first step towards a framework for defining and manipulating normative documents or contracts described as ContractOriented (C-O) Diagrams. These diagrams provide a visual representation for such texts, giving the possibility to express a signatory’s obligations, permissions and prohibitions, with or without timing constraints, as well as the penalties resulting from the non-fulfilment of a contract. This work presents a CNL for verbalising C-O Diagrams, a web-based tool allowing editing in this CNL, and another for visualising and manipulating the diagrams interactively. We then show how these proof-ofconcept tools can be used by applying them to a small example.",
            "output": [
                "A CNL for Contract-Oriented Diagrams"
            ]
        },
        {
            "id": "task1540-31610604c33c4a259d823f5ae6f8cdbd",
            "input": "The speed of convergence of the Expectation Maximization (EM) algorithm for Gaussian mixture model fitting is known to be dependent on the amount of overlap among the mixture components. In this paper, we study the impact of mixing coefficients on the convergence of EM. We show that when the mixture components exhibit some overlap, the convergence of EM becomes slower as the dynamic range among the mixing coefficients increases. We propose a deterministic anti-annealing algorithm, that significantly improves the speed of convergence of EM for such mixtures with unbalanced mixing coefficients. The proposed algorithm is compared against other standard optimization techniques like BFGS, Conjugate Gradient, and the traditional EM algorithm. Finally, we propose a similar deterministic antiannealing based algorithm for the Dirichlet process mixture model and demonstrate its advantages over the conventional variational Bayesian approach.",
            "output": [
                "Convergence of the EM Algorithm for Gaussian Mixtures with Unbalanced Mixing Coefficients"
            ]
        },
        {
            "id": "task1540-7448e6ba050344b28c4c2f46180e4e2c",
            "input": "We introduce the “exponential linear unit” (ELU) which speeds up learning in<lb>deep neural networks and leads to higher classification accuracies. Like rectified<lb>linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PRe-<lb>LUs), ELUs also avoid a vanishing gradient via the identity for positive values.<lb>However ELUs have improved learning characteristics compared to the units with<lb>other activation functions. In contrast to ReLUs, ELUs have negative values which<lb>allows them to push mean unit activations closer to zero. Zero means speed up<lb>learning because they bring the gradient closer to the unit natural gradient. We<lb>show that the unit natural gradient differs from the normal gradient by a bias shift<lb>term, which is proportional to the mean activation of incoming units. Like batch<lb>normalization, ELUs push the mean towards zero, but with a significantly smaller<lb>computational footprint. While other activation functions like LReLUs and PRe-<lb>LUs also have negative values, they do not ensure a noise-robust deactivation state.<lb>ELUs saturate to a negative value with smaller inputs and thereby decrease the<lb>propagated variation and information. Therefore ELUs code the degree of pres-<lb>ence of particular phenomena in the input, while they do not quantitatively model<lb>the degree of their absence. Consequently, dependencies between ELUs are much<lb>easier to model and distinct concepts are less likely to interfere.<lb>We found that ELUs lead not only to faster learning, but also to better general-<lb>ization performance once networks have many layers (≥ 5). ELU networks were<lb>among top 10 reported CIFAR-10 results and yielded the best published result on<lb>CIFAR-100, without resorting to multi-view evaluation or model averaging. On<lb>ImageNet, ELU networks considerably speed up learning compared to a ReLU<lb>network with the same architecture, obtaining less than 10% classification error<lb>for a single crop, single model network.",
            "output": [
                "EXPONENTIAL LINEAR UNITS (ELUS)"
            ]
        },
        {
            "id": "task1540-b752ee3f279e41c8948b0d7f22228317",
            "input": "A method is presented for the rhythmic pars­<lb>ing problem: Given a sequence of observed<lb>musical note onset times, we simultaneously<lb>estimate the corresponding notated rhythm<lb>and tempo process. A graphical model is<lb>developed that<lb>represents the evolution of<lb>tempo and rhythm and relates these hid­<lb>den quantities to an observable performance.<lb>The rhythm variables are discrete and the<lb>tempo and observation variables are contin­<lb>uous. We show how to compute the<lb>glob­<lb>ally most likely configuration of the tempo<lb>and rhythm variables given an observation of<lb>note onset times. Preliminary experiments<lb>are presented on a small data set. A gen­<lb>eralization to computing MAP estimates for<lb>arbitrary conditional Gaussian distributions<lb>is outlined.",
            "output": [
                "A Mixed Graphical Model for Rhythmic Parsing"
            ]
        },
        {
            "id": "task1540-77f2b4b542c945d9a444fbeafe0ad0c0",
            "input": "The properties of local optimal solutions in multi-objective combinatorial optimization problems are crucial for the effectiveness of local search algorithms, particularly when these algorithms are based on Pareto dominance. Such local search algorithms typically return a set of mutually nondominated Pareto local optimal (PLO) solutions, that is, a PLO-set. This paper investigates two aspects of PLO-sets by means of experiments with Pareto local search (PLS). First, we examine the impact of several problem characteristics on the properties of PLO-sets for multi-objective NK-landscapes with correlated objectives. In particular, we report that either increasing the number of objectives or decreasing the correlation between objectives leads to an exponential increment on the size of PLO-sets, whereas the variable correlation has only a minor effect. Second, we study the running time and the quality reached when using bounding archiving methods to limit the size of the archive handled by PLS, and thus, the maximum size of the PLO-set found. We argue that there is a clear relationship between the running time of PLS and the difficulty of a problem instance.",
            "output": [
                "Local Optimal Sets and Bounded Archiving on Multi-objective NK-Landscapes with Correlated Objectives"
            ]
        },
        {
            "id": "task1540-27c046e1a9134557bf5b80faf5609fce",
            "input": "Topic models provide a useful method for dimensionality reduction and exploratory data<lb>analysis in large text corpora. Most approaches to topic model inference have been based on<lb>a maximum likelihood objective. Efficient algorithms exist that approximate this objective,<lb>but they have no provable guarantees. Recently, algorithms have been introduced that provide<lb>provable bounds, but these algorithms are not practical because they are inefficient and not ro-<lb>bust to violations of model assumptions. In this paper we present an algorithm for topic model<lb>inference that is both provable and practical. The algorithm produces results comparable to the<lb>best MCMC implementations while running orders of magnitude faster.",
            "output": [
                "A Practical Algorithm for Topic Modeling with Provable Guarantees"
            ]
        },
        {
            "id": "task1540-45e9fa2ebb1f430c8de37f5549275bdb",
            "input": "Despite the increasing use of social media platforms for information and news gathering, its unmoderated nature often leads to the emergence and spread of rumours, i.e. pieces of information that are unverified at the time of posting. At the same time, the openness of social media platforms provides opportunities to study how users share and discuss rumours, and to explore how natural language processing and data mining techniques may be used to find ways of determining their veracity. In this survey we introduce and discuss two types of rumours that circulate on social media; long-standing rumours that circulate for long periods of time, and newly-emerging rumours spawned during fast-paced events such as breaking news, where reports are released piecemeal and often with an unverified status in their early stages. We provide an overview of research into social media rumours with the ultimate goal of developing a rumour classification system that consists of four components: rumour detection, rumour tracking, rumour stance classification and rumour veracity classification. We delve into the approaches presented in the scientific literature for the development of each of these four components. We summarise the efforts and achievements so far towards the development of rumour classification systems and conclude with suggestions for avenues for future research in social media mining for detection and resolution of rumours.",
            "output": [
                "Detection and Resolution of Rumours in Social Media: A Survey"
            ]
        },
        {
            "id": "task1540-b3905604550040b692afc43376a98903",
            "input": "Today data mining techniques are exploited in medical science for diagnosing, overcoming and treating diseases. Neural network is one of the techniques which are widely used for diagnosis in medical field. In this article efficiency of nine algorithms, which are basis of neural network learning in diagnosing cardiovascular diseases, will be assessed. Algorithms are assessed in terms of accuracy, sensitivity, transparency, AROC and convergence rate by means of 10 fold cross validation. The results suggest that in training phase, Lonberg-M algorithm has the best efficiency in terms of all metrics, algorithm OSS has maximum accuracy in testing phase, algorithm SCG has the maximum transparency and algorithm CGB has the maximum sensitivity. Keywords— cardiovascular disease; neural network; learning algorithms.",
            "output": [
                "Comparing learning algorithms in neural network for diagnosing cardiovascular disease"
            ]
        },
        {
            "id": "task1540-2e00968cc7a74920b6d99eaa40e7b3a0",
            "input": "Multimedia reasoning, which is suitable for, among others, multimedia content analysis and high-level video scene interpretation, relies on the formal and comprehensive conceptualization of the represented knowledge domain. However, most multimedia ontologies are not exhaustive in terms of role definitions, and do not incorporate complex role inclusions and role interdependencies. In fact, most multimedia ontologies do not have a role box at all, and implement only a basic subset of the available logical constructors. Consequently, their application in multimedia reasoning is limited. To address the above issues, VidOnt, the very first multimedia ontology with SROIQ(D) expressivity and a DL-safe ruleset has been introduced for next-generation multimedia reasoning. In contrast to the common practice, the formal grounding has been set in one of the most expressive description logics, and the ontology validated with industry-leading reasoners, namely HermiT and FaCT++. This paper also presents best practices for developing multimedia ontologies, based on my ontology engineering approach.",
            "output": [
                "A Novel Approach to Multimedia Ontology Engineering for Automated Reasoning over Audiovisual LOD Datasets"
            ]
        },
        {
            "id": "task1540-f9667a20eda04875a9ad3aaa30123ae2",
            "input": "We present a novel diffusion scheme for online kernel-based learning over networks. So far, a major drawback of any online learning algorithm, operating in a reproducing kernel Hilbert space (RKHS), is the need for updating a growing number of parameters as time iterations evolve. Besides complexity, this leads to an increased need of communication resources, in a distributed setting. In contrast, the proposed method approximates the solution as a fixed-size vector (of larger dimension than the input space) using Random Fourier Features. This paves the way to use standard linear combine-then-adapt techniques. To the best of our knowledge, this is the first time that a complete protocol for distributed online learning in RKHS is presented. Conditions for asymptotic convergence and boundness of the networkwise regret are also provided. The simulated tests illustrate the performance of the proposed scheme.",
            "output": [
                "Online Distributed Learning Over Networks in RKH Spaces Using Random Fourier Features"
            ]
        },
        {
            "id": "task1540-805718f88b1d4676a8acf712cf11048d",
            "input": "We propose a new active learning (AL) method for text classification based on convolutional neural networks (CNNs). In AL, one selects the instances to be manually labeled with the aim of maximizing model performance with minimal effort. Neural models capitalize on word embeddings as features, tuning these to the task at hand. We argue that AL strategies for neural text classification should focus on selecting instances that most affect the embedding space (i.e., induce discriminative word representations). This is in contrast to traditional AL approaches (e.g., uncertainty sampling), which specify higher level objectives. We propose a simple approach that selects instances containing words whose embeddings are likely to be updated with the greatest magnitude, thereby rapidly learning discriminative, task-specific embeddings. Empirical results show that our method outperforms baseline AL approaches.",
            "output": [
                "Active Discriminative Word Embedding Learning"
            ]
        },
        {
            "id": "task1540-8357ec923c8f4b6aa9bb2c3e237d6bed",
            "input": "We present Grid Beam Search (GBS), an algorithm which extends beam search to allow the inclusion of pre-specified lexical constraints. The algorithm can be used with any model that generates a sequence ŷ = {y0 . . . yT }, by maximizing p(y|x) = ∏ t p(yt|x; {y0 . . . yt−1}). Lexical constraints take the form of phrases or words that must be present in the output sequence. This is a very general way to incorporate additional knowledge into a model’s output without requiring any modification of the model parameters or training data. We demonstrate the feasibility and flexibility of Lexically Constrained Decoding by conducting experiments on Neural Interactive-Predictive Translation, as well as Domain Adaptation for Neural Machine Translation. Experiments show that GBS can provide large improvements in translation quality in interactive scenarios, and that, even without any user input, GBS can be used to achieve significant gains in performance in domain adaptation scenarios.",
            "output": [
                "Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search"
            ]
        },
        {
            "id": "task1540-72b397ec33804b3894c088ea22a7935b",
            "input": "Feature selection plays an important role in the data mining process. It is needed to deal with the excessive number of features, which can become a computational burden on the learning algorithms. It is also necessary, even when computational resources are not scarce, since it improves the accuracy of the machine learning tasks, as we will see in the upcoming sections. In this review, we discuss the different feature selection approaches, and the relation between them and the various machine learning algorithms.",
            "output": [
                "Survey on Feature Selection"
            ]
        },
        {
            "id": "task1540-f5429aea89224b0e84bb45a3181b7bf1",
            "input": "Robust belief revision methods are crucial in streaming data situations for updating existing knowledge (or beliefs) with new incoming evidence. Bayes conditioning is the primary mechanism in use for belief revision in data fusion systems that use probabilistic inference. However, traditional conditioning methods face several challenges due to inherent data/source imperfections in big-data environments that harness soft (i.e., human or human-based) sources in addition to hard (i.e., physicsbased) sensors. The objective of this paper is to investigate the most natural extension of Bayes conditioning that is suitable for evidence updating in the presence of such uncertainties. By viewing the evidence updating process as a thought experiment, an elegant strategy is derived for robust evidence updating in the presence of extreme uncertainties that are characteristic of big-data environments. In particular, utilizing the Fagin-Halpern conditional notions, a natural extension to Bayes conditioning is derived for evidence that takes the form of a general belief function. The presented work differs fundamentally from the Conditional Update Equation (CUE) and authors own extensions of it. An overview of this development is provided via illustrative examples. Furthermore, insights into parameter selection under various fusion contexts are also provided.",
            "output": [
                "Evidence Updating for Stream-Processing in Big-Data: Robust Conditioning in Soft and Hard Data Fusion Environments"
            ]
        },
        {
            "id": "task1540-6e31ba4baed34e4d830779a411d8b873",
            "input": "Image Registration implies mapping images having varying orientation, multi-modal or multi-temporal images to map to one coordinate system. Digital Elevation models (DEM) are images having terrain information embedded into them. DEM-to-DEM registration incorporate registration of DEMs having different orientation, may have been mapped at different times, or may have been processed using different resolutions. Though very important only a handful of methods for DEM registration exist, most of which are for DEM-to-topographical map or DEMto-Remote Sensed Image registration. Using cognitive mapping concepts for DEM registration, has evolved from this basic idea of using the mapping between the space to objects and defining their relationships to form the basic landmarks that need to be marked, stored and manipulated in and about the environment or other candidate environments, namely, in our case, the DEMs. The progressive two-level encapsulation of methods of geo-spatial cognition includes landmark knowledge and layout knowledge and can be useful for DEM registration. Space-based approach, that emphasizes on explicit extent of the environment under consideration, and object-based approach, that emphasizes on the relationships between objects in the local environment being the two paradigms of cognitive mapping can be methodically integrated in this three-architecture for DEM registration. Initially, P-model based segmentation is performed followed by landmark formation for contextual mapping that uses contextual pyramid formation. Apart from landmarks being used for registration key-point finding, Euclidean distance based deformation calculation has been used for transformation and change detection. Initially, P-model based segmentation is performed followed by landmark formation for contextual mapping that uses contextual pyramid formation. Landmarks have been categorized to belong to either being flat-plain areas without much variation in the land heights; peaks that can be found when there is gradual increase in height as compared to the flat areas; valleys, marked with gradual decrease in the height seen in DEM; and finally, ripple areas with very shallow crests and nadirs. For the final storage of co-registered DEMs, fractal based compression has been found to give good results in terms of space and computation requirements. In this paper, an attempt has been made to implement DEM-DEM registration based on human spatial cognition method of recollection. This method may further be extended for DEM-totopographic map and DEM-to-remote sensed image registration. Experimental results further cement the fact that DEM registration may be effectively done using the proposed method.",
            "output": [
                "Cognitive-mapping and contextual pyramid based Digital Elevation Model Registration and its effective storage using fractal based compression"
            ]
        },
        {
            "id": "task1540-c6242a833e4c4db18e7ad72b2891317e",
            "input": "This work uses the L-system to construct a tree structure for the text sequence and derives its complexity [1]. It serves as a measure of structural complexity of the text. It is applied to anomaly detection in data transmission. Keyword: text complexity, anomaly detection, structural complexity, rewriting rule, context-free grammar, L-system",
            "output": [
                "Syntactic sensitive complexity for symbol-free sequence"
            ]
        },
        {
            "id": "task1540-7a80a19342a24d218de48d73fa74c888",
            "input": "Low dimensional representations of words allow<lb>accurate NLP models to be trained on limited<lb>annotated data. While most representations ig-<lb>nore words’ local context, a natural way to in-<lb>duce context-dependent representations is to per-<lb>form inference in a probabilistic latent-variable<lb>sequence model. Given the recent success of<lb>continuous vector space word representations,<lb>we provide such an inference procedure for con-<lb>tinuous states, where words’ representations are<lb>given by the posterior mean of a linear dynam-<lb>ical system. Here, efficient inference can be<lb>performed using Kalman filtering. Our learn-<lb>ing algorithm is extremely scalable, operating<lb>on simple cooccurrence counts for both param-<lb>eter initialization using the method of moments<lb>and subsequent iterations of EM. In our exper-<lb>iments, we employ our inferred word embed-<lb>dings as features in standard tagging tasks, ob-<lb>taining significant accuracy improvements. Fi-<lb>nally, the Kalman filter updates can be seen as a<lb>linear recurrent neural network. We demonstrate<lb>that using the parameters of our model to ini-<lb>tialize a non-linear recurrent neural network lan-<lb>guage model reduces its training time by a day<lb>and yields lower perplexity.",
            "output": [
                "A Linear Dynamical System Model for Text"
            ]
        },
        {
            "id": "task1540-fb0c40e3239d4896926db301f581d6d0",
            "input": "The abstract should summarize the contents of the paper using at least 70 and at most 150 words. It will be set in 9-point font size and be inset 1.0 cm from the right and left margins. There will be two blank lines before and after the Abstract. . . .",
            "output": [
                "Discriminative Parameter Estimation for Random Walks Segmentation: Technical Report"
            ]
        },
        {
            "id": "task1540-13769441716a43f381d24755875a4e02",
            "input": "The Stable Marriage Problem (SMP) is a well-known matching problem first introduced and solved by Gale and Shapley [7]. Several variants and extensions to this problem have since been investigated to cover a wider set of applications. Each time a new variant is considered, however, a new algorithm needs to be developed and implemented. As an alternative, in this paper we propose an encoding of the SMP using Answer Set Programming (ASP). Our encoding can easily be extended and adapted to the needs of specific applications. As an illustration we show how stable matchings can be found when individuals may designate unacceptable partners and ties between preferences are allowed. Subsequently, we show how our ASP based encoding naturally allows us to select specific stable matchings which are optimal according to a given criterion. Each time, we can rely on generic and efficient off-the-shelf answer set solvers to find (optimal) stable matchings.",
            "output": [
                "Modeling Stable Matching Problems with Answer Set Programming"
            ]
        },
        {
            "id": "task1540-c706f3125b894292a996f8d1f8fd0f90",
            "input": "Idea Density (ID) measures the rate at which ideas or elementary predications are expressed in an utterance or in a text. Lower ID is found to be associated with an increased risk of developing Alzheimer’s disease (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID has been used in two different versions: propositional idea density (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as picture description tasks. In this paper, we develop DEPID, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas—a feature characteristic to AD speech. We conduct the first comparison of automatically extracted PID and SID in the diagnostic classification task on two different AD datasets covering both closed-topic and free-recall domains. While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 Fscore). On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an Fscore of 84.8.",
            "output": [
                "Idea density for predicting Alzheimer’s disease from transcribed speech"
            ]
        },
        {
            "id": "task1540-b990f430f102463495224a18558bb02f",
            "input": "Philosophers writing about the ravens paradox often note that Nicod’s Condition (NC) holds given some set of background information, and fails to hold against others, but rarely go any further. That is, it is usually not explored which background information makes NC true or false. The present paper aims to fill this gap. For us, “(objective) background knowledge” is restricted to information that can be expressed as probability events. Any other configuration is regarded as being subjective and a property of the a priori probability distribution. We study NC in two specific settings. In the first case, a complete description of some individuals is known, e.g. one knows of each of a group of individuals whether they are black and whether they are ravens. In the second case, the number of individuals having a particular property is given, e.g. one knows how many ravens or how many black things there are (in the relevant population). While some of the most famous answers to the paradox are measure-dependent, our discussion is not restricted to any particular probability measure. Our most interesting result is that in the second setting, NC violates a simple kind of inductive inference (namely projectability). Since relative to NC, this latter rule is more closely related to, and more directly justified by our intuitive notion of inductive reasoning, this tension makes a case against the plausibility of NC. In the end, we suggest that the informal representation of NC may seem to be intuitively plausible because it can easily be mistaken for reasoning by analogy.",
            "output": [
                "On Nicod’s Condition, Rules of Induction and the Raven Paradox"
            ]
        },
        {
            "id": "task1540-6e6b6627f2674ea384bbf49e71bd4105",
            "input": "Robot warehouse automation has attracted significant interest in recent years, perhaps most visibly in the Amazon Picking Challenge (APC) [1]. A fully autonomous warehouse pick-and-place system requires robust vision that reliably recognizes and locates objects amid cluttered environments, self-occlusions, sensor noise, and a large variety of objects. In this paper we present an approach that leverages multiview RGB-D data and self-supervised, data-driven learning to overcome those difficulties. The approach was part of the MITPrinceton Team system that took 3rdand 4thplace in the stowing and picking tasks, respectively at APC 2016. In the proposed approach, we segment and label multiple views of a scene with a fully convolutional neural network, and then fit pre-scanned 3D object models to the resulting segmentation to get the 6D object pose. Training a deep neural network for segmentation typically requires a large amount of training data. We propose a self-supervised method to generate a large labeled dataset without tedious manual segmentation. We demonstrate that our system can reliably estimate the 6D pose of objects under a variety of scenarios. All code, data, and benchmarks are available at http://www.cs.princeton.edu/∼andyz/apc2016.",
            "output": [
                "Multi-view Self-supervised Deep Learning for 6D Pose Estimation in the Amazon Picking Challenge"
            ]
        },
        {
            "id": "task1540-e45b5f3133fb4923b6f36a1056792eb6",
            "input": "Possibilistic logic bases and possibilistic graphs are two different frameworks of interest for representing knowledge. The former stratifies the pieces of knowledge (expressed by logical formulas) accor?i�g to their level of certainty, while the latter exhibits relationships between variables. The two types of representations are semantically equivalent when they lead to the same possibility distribution (which rank­ orders the possible interpretations). A possibility distribution can be decomposed using a chain rule which may be based on two different kinds of conditioning which exist in possibility theory (one based on product in a numerical setting, one based on minimum operation in a qualitative setting). These two types of conditioning induce two kin_ds of possibilistic graphs. In both cases, a translatiOn of these graphs into possibilistic bases is provided. The converse translation from a possibilistic knowledge base into a min-based graph is also described.",
            "output": [
                "Possibilistic logic bases and possibilistic graphs"
            ]
        },
        {
            "id": "task1540-765232697f5e40d394e546b65eda3523",
            "input": "This is a companion note to our recent study of the weak convergence properties of constrained emphatic temporal-difference learning (ETD) algorithms from a theoretic perspective. It supplements the latter analysis with simulation results and illustrates the behavior of some of the ETD algorithms using three example problems.",
            "output": [
                "Some Simulation Results for Emphatic Temporal-Difference Learning Algorithms∗"
            ]
        },
        {
            "id": "task1540-a7c9c482e64e45c4a31b348bdb509dda",
            "input": "Protein subcellular localization prediction is an important and challenging problem. The traditional biology experiments are expensive and time-consuming, so more and more research interests tend to a series of machine learning approaches for predicting protein subcellular location. There are two main difficult problems among the existing state-of-the-art methods. First, most of the existing techniques are designed to deal with the multi-class but not the multi-label classification, which ignores the connection between the multiple labels. In reality, multiple location proteins implicate that there are vital and unique biological significances worthy of special focus, which cannot be ignored. Second, the techniques for handling imbalanced data in multi-label classification problem is significant but less. For solving the two issues, we have developed an ensemble multi-label classifier called HPSLPred which can be applied for the multi-label classification with imbalanced protein source. For the conveniences of users, a user-friendly webserver for HPSLPred was established at http://server.malab.cn/HPSLPred.",
            "output": [
                "HPSLPred: An Ensemble Multi-label Classifier for Human Protein Subcellular Location Prediction with Imbalanced Source"
            ]
        },
        {
            "id": "task1540-7dd430b06bc242e4b86265cc89cd799e",
            "input": "Composition of low-dimensional distribu­ tions, whose foundations were laid in the pa­ per published in the Proceedings of UAI'97 (Jirousek 1997), appeared to be an alterna­ tive apparatus to describe multidimensional probabilistic models. In contrast to Graphi­ cal Markov Models, which define multidimen­ sional distributions in a declarative way, this approach is rather procedural. Ordering of low-dimensional distributions into a proper sequence fully defines the respective compu­ tational procedure; therefore, a study of dif­ ferent types of generating sequences is one of the central problems in this field. Thus, it ap­ pears that an important role is played by spe­ cial sequences that are called perfect. Their main characterization theorems are presented in this paper. However, the main result of this paper is a solution to the problem of marginalization for general sequences. The main theorem describes a way to obtain a generating sequence that defines the model corresponding to the marginal of the distri­ bution defined by an arbitrary generating se­ quence. From this theorem the reader can see to what extent these computations are lo­ cal; i.e., the sequence consists of marginal dis­ tributions whose computation must be made by summing up over the values of the vari­ able eliminated (the paper deals with a finite model) .",
            "output": [
                "Marginalization in Composed Probabilistic Models"
            ]
        },
        {
            "id": "task1540-23c3eb6109fe42589a2ebc548d3abcb3",
            "input": "Many academic disciplines including information systems, computer science, and operations management face scheduling problems as important decision making tasks. Since many scheduling problems are NP-hard in the strong sense, there is a need for developing solution heuristics. For scheduling problems with setup times on unrelated parallel machines, there is limited research on solution methods and to the best of our knowledge, parallel computer architectures have not yet been taken advantage of. We address this gap by proposing and implementing a new solution heuristic and by testing different parallelization strategies. In our computational experiments, we show that our heuristic calculates near-optimal solutions even for large instances and that computing time can be reduced substantially by our parallelization approach.",
            "output": [
                "High-Performance Computing for Scheduling Decision Support: A Parallel Depth-First Search Heuristic"
            ]
        },
        {
            "id": "task1540-ea65dfa46a6d4bd3ac3a48cf70bacaa3",
            "input": "In this paper, we propose convolutional neural networks for learning an optimal representation of question and answer sentences. Their main aspect is the use of relational information given by the matches between words from the two members of the pair. The matches are encoded as embeddings with additional parameters (dimensions), which are tuned by the network. These allows for better capturing interactions between questions and answers, resulting in a significant boost in accuracy. We test our models on two widely used answer sentence selection benchmarks. The results clearly show the effectiveness of our relational information, which allows our relatively simple network to approach the state of the art.",
            "output": [
                "Modeling Relational Information in Question-Answer Pairs with Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-fe54fef6f3984532b1b39e57d7f2c471",
            "input": "For a finite state automaton, a synchronizing sequence is an input sequence that takes all the states to the same state. Checking the existence of a synchronizing sequence and finding a synchronizing sequence, if one exists, can be performed in polynomial time. However, the problem of finding a shortest synchronizing sequence is known to be NP-hard. In this work, the usefulness of Answer Set Programming to solve this optimization problem is investigated, in comparison with brute-force algorithms and SAT-based approaches.",
            "output": [
                "Generating Shortest Synchronizing Sequences using Answer Set Programming"
            ]
        },
        {
            "id": "task1540-b5011c1339814fa8b16688528d63c956",
            "input": "This paper proposes a hierarchical attentional neural translation model which focuses on enhancing source-side hierarchical representations by covering both local and global semantic information using a bidirectional tree-based encoder. To maximize the predictive likelihood of target words, a weighted variant of an attention mechanism is used to balance the attentive information between lexical and phrase vectors. Using a tree-based rare word encoding, the proposed model is extended to sub-word level to alleviate the out-of-vocabulary (OOV) problem. Empirical results reveal that the proposed model significantly outperforms sequence-to-sequence attention-based and tree-based neural translation models in English-Chinese translation tasks.",
            "output": [
                "Towards Bidirectional Hierarchical Representations for Attention-Based Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-fda476d165cb458c86fc3556bcff4568",
            "input": "In this paper we present a hybrid approach for automatic composition of Web services that generates semantic inputoutput based compositions with optimal end-to-end QoS, minimizing the number of services of the resulting composition. The proposed approach has four main steps: 1) generation of the composition graph for a request; 2) computation of the optimal composition that minimizes a single objective QoS function; 3) multi-step optimizations to reduce the search space by identifying equivalent and dominated services; and 4) hybrid local-global search to extract the optimal QoS with the minimum number of services. An extensive validation with the datasets of the Web Service Challenge 2009-2010 and randomly generated datasets shows that: 1) the combination of local and global optimization is a general and powerful technique to extract optimal compositions in diverse scenarios; and 2) the hybrid strategy performs better than the state-of-the-art, obtaining solutions with less services and optimal QoS. Keywords—Service Composition; Service Optimization; Hybrid Algorithm; QoS-aware; Semantic Web Services.",
            "output": [
                "Hybrid Optimization Algorithm for Large-Scale QoS-Aware Service Composition"
            ]
        },
        {
            "id": "task1540-6bcbdaec923643d69e02eb5c9583f3f0",
            "input": "A graphical multiagent model (GMM) represents a joint distribution over the behavior of a set of agents. One source of knowledge about agents' behavior may come from gametheoretic analysis, as captured by several graphical game representations developed in recent years. GMMs generalize this approach to express arbitrary distributions, based on game descriptions or other sources of knowledge bearing on beliefs about agent behavior. To illustrate the exibility of GMMs, we exhibit game-derived models that allow probabilistic deviation from equilibrium, as well as models based on heuristic action choice. We investigate three di erent methods of integrating these models into a single model representing the combined knowledge sources. To evaluate the predictive performance of the combined model, we treat as actual outcome the behavior produced by a reinforcement learning process. We nd that combining the two knowledge sources, using any of the methods, provides better predictions than either source alone. Among the combination methods, mixing data outperforms the opinion pool and direct update methods investigated in this empirical trial.",
            "output": [
                "Knowledge Combination in Graphical Multiagent Models"
            ]
        },
        {
            "id": "task1540-9d9649dfb57149e59417c5222380ec1c",
            "input": "Ristretto: Hardware-Oriented Approximation of Convolutional Neural Networks Convolutional neural networks (CNN) have achieved major breakthroughs in recent years. Their performance in computer vision have matched and in some areas even surpassed human capabilities. Deep neural networks can capture complex non-linear features; however this ability comes at the cost of high computational and memory requirements. State-ofart networks require billions of arithmetic operations and millions of parameters. To enable embedded devices such as smart phones, Google glasses and monitoring cameras with the astonishing power of deep learning, dedicated hardware accelerators can be used to decrease both execution time and power consumption. In applications where fast connection to the cloud is not guaranteed or where privacy is important, computation needs to be done locally. Many hardware accelerators for deep neural networks have been proposed recently. A first important step of accelerator design is hardware-oriented approximation of deep networks, which enables energy-efficient inference. We present Ristretto, a fast and automated framework for CNN approximation. Ristretto simulates the hardware arithmetic of a custom hardware accelerator. The framework reduces the bit-width of network parameters and outputs of resource-intense layers, which reduces the chip area for multiplication units significantly. Alternatively, Ristretto can remove the need for multipliers altogether, resulting in an adder-only arithmetic. The tool fine-tunes trimmed networks to achieve high classification accuracy. Since training of deep neural networks can be time-consuming, Ristretto uses highly optimized routines which run on the GPU. This enables fast compression of any given network. Given a maximum tolerance of 1%, Ristretto can successfully condense CaffeNet and SqueezeNet to 8-bit. The code for Ristretto is available.",
            "output": [
                "Ristretto: Hardware-Oriented Approximation of Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-80e25b5b49584c0fba10e05404166963",
            "input": "The rise of robotic applications has led to the generation of a huge volume of unstructured data, whereas the current cloud infrastructure was designed to process limited amounts of structured data. To address this problem, we propose a learn-memorize-recall-reduce paradigm for robotic cloud computing. The learning stage converts incoming unstructured data into structured data; the memorization stage provides effective storage for the massive amount of data; the recall stage provides efficient means to retrieve the raw data; while the reduction stage provides means to make sense of this massive amount of unstructured data with limited computing resources.",
            "output": [
                "Learn-Memorize-Recall-Reduce: A Robotic Cloud Computing Paradigm"
            ]
        },
        {
            "id": "task1540-2f049a0091594e0086b7d5485ee49a7b",
            "input": "A Dialogue System is a system which interacts with human in natural language. At present many universities are developing the dialogue system in their regional language. This paper will discuss about dialogue system, its components, challenges and its evaluation. This paper helps the researchers for getting info regarding dialogues system.",
            "output": [
                "Dialogue System: A Brief Review"
            ]
        },
        {
            "id": "task1540-1ea759e119224c3d9d2cd69a9a511476",
            "input": "We present a Bayesian scheme for the approximate diagonalisation of several square matrices which are not necessarily symmetric. A Gibbs sampler is derived to simulate samples of the common eigenvectors and the eigenvalues for these matrices. Several synthetic examples are used to illustrate the performance of the proposed Gibbs sampler and we then provide comparisons to several other joint diagonalization algorithms, which shows that the Gibbs sampler achieves the state-of-theart performance on the examples considered. As a byproduct, the output of the Gibbs sampler could be used to estimate the log marginal likelihood, however we employ the approximation based on the Bayesian information criterion (BIC) which in the synthetic examples considered correctly located the number of common eigenvectors. We then succesfully applied the sampler to the source separation problem as well as the common principal component analysis and the common spatial pattern analysis problems.",
            "output": [
                "A Bayesian Approach to Approximate Joint Diagonalization of Square Matrices"
            ]
        },
        {
            "id": "task1540-decd6a8c01144d5694e988c55d55b18b",
            "input": "The chain-structured long short-term memory (LSTM) has showed to be effective in a wide range of problems such as speech recognition and machine translation. In this paper, we propose to extend it to tree structures, in which a memory cell can reflect the history memories of multiple child cells or multiple descendant cells in a recursive process. We call the model S-LSTM, which provides a principled way of considering long-distance interaction over hierarchies, e.g., language or image parse structures. We leverage the models for semantic composition to understand the meaning of text, a fundamental problem in natural language understanding, and show that it outperforms a state-of-theart recursive model by replacing its composition layers with the S-LSTM memory blocks. We also show that utilizing the given structures is helpful in achieving a performance better than that without considering the structures.",
            "output": [
                "Long Short-Term Memory Over Tree Structures"
            ]
        },
        {
            "id": "task1540-17e703fb7ed445629a62f1779243d48e",
            "input": "This paper provides a global vision of the scientific publications related with the Systemic Lupus Erythematosus (SLE), taking as starting point abstracts of articles. Through the time, abstracts have been evolving towards higher complexity on used terminology, which makes necessary the use of sophisticated statistical methods and answering questions including: how vocabulary is evolving through the time? Which ones are most influential articles? And which one are the articles that introduced new terms and vocabulary? To answer these, we analyze a dataset composed by 506 abstracts and downloaded from 115 different journals and cover a 18 year-period.",
            "output": [
                "How scientific literature has been evolving over the time? A novel statistical approach using tracking verbal-based methods"
            ]
        },
        {
            "id": "task1540-71765e186dc4483288ae02246eb7c5ee",
            "input": "Service level agreement (SLA) is an essential part of cloud systems to ensure maximum availability of services for customers. With a violation of SLA, the provider has to pay penalties. Thus, being able to predict SLA violations favors both the customers and the providers. In this paper, we explore two machine learning models: Naive Bayes and Random Forest Classifiers to predict SLA violations. Since SLA violations are a rare event in the real world (∼ 0.2%), the classification task becomes more challenging. In order to overcome these challenges, we use several re-sampling methods such as Random Over and Under Sampling, SMOTH, NearMiss (1,2,3), One-sided Selection, Neighborhood Cleaning Rule, etc. to re-balance the dataset. We use the Google Cloud Cluster trace as the dataset to examine these different methods. We find that random forests with SMOTE-ENN re-sampling have the best performance among other methods with the accuracy of 0.9988% and F1 score of 0.9980.",
            "output": [
                "SLA Violation Prediction In Cloud Computing: A Machine Learning Perspective"
            ]
        },
        {
            "id": "task1540-4302672f2a714c9781859c93bdbfb412",
            "input": "Many combinatorial problems deal with preferences and violations, the goal of which is to find solutions with the minimum cost. Weighted constraint satisfaction is a framework for modeling such problems, which consists of a set of cost functions to measure the degree of violation or preferences of different combinations of variable assignments. Typical solution methods for weighted constraint satisfaction problems (WCSPs) are based on branch-and-bound search, which are made practical through the use of powerful consistency techniques such as AC*, FDAC*, EDAC* to deduce hidden cost information and value pruning during search. These techniques, however, are designed to be efficient only on binary and ternary cost functions which are represented in table form. In tackling many real-life problems, high arity (or global) cost functions are required. We investigate efficient representation scheme and algorithms to bring the benefits of the consistency techniques to also high arity cost functions, which are often derived from hard global constraints from classical constraint satisfaction. The literature suggests some global cost functions can be represented as flow networks, and the minimum cost flow algorithm can be used to compute the minimum costs of such networks in polynomial time. We show that naive adoption of this flow-based algorithmic method for global cost functions can result in a stronger form of ∅-inverse consistency. We further show how the method can be modified to handle cost projections and extensions to maintain generalized versions of AC* and FDAC* for cost functions with more than two variables. Similar generalization for the stronger EDAC* is less straightforward. We reveal the oscillation problem when enforcing EDAC* on cost functions sharing more than one variable. To avoid oscillation, we propose a weak version of EDAC* and generalize it to weak EDGAC* for non-binary cost functions. Using various benchmarks involving the soft variants of hard global constraints ALLDIFFERENT, GCC, SAME, and REGULAR, empirical results demonstrate that our proposal gives improvements of up to an order of magnitude when compared with the traditional constraint optimization approach, both in terms of time and pruning.",
            "output": [
                "Consistency Techniques for Flow-Based Projection-Safe Global Cost Functions in Weighted Constraint Satisfaction"
            ]
        },
        {
            "id": "task1540-e8c867cbad364bc8969d2817be31dd37",
            "input": "To bridge the gap between humans and machines in image understanding and describing, we need further insight into how people describe a perceived scene. In this paper, we study the agreement between bottom-up saliency-based visual attention and object referrals in scene description constructs. We investigate the properties of human-written descriptions and machine-generated ones. We then propose a saliency-boosted image captioning model in order to investigate benefits from low-level cues in language models. We learn that (1) humans mention more salient objects earlier than less salient ones in their descriptions, (2) the better a captioning model performs, the better attention agreement it has with human descriptions, (3) the proposed saliencyboosted model, compared to its baseline form, does not improve significantly on the MS COCO database, indicating explicit bottom-up boosting does not help when the task is well learnt and tuned on a data, (4) a better generalization ability is, however, observed for the saliency-boosted model on unseen data.",
            "output": [
                "Can Saliency Information Benefit Image Captioning Models?"
            ]
        },
        {
            "id": "task1540-71d744f7dbbc4ef1a9bfb2e845027036",
            "input": "Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values, which implicitly encourages the target rank constraint. Our experimental analyses show that, when the number of samples is deficient, our approach leads to a higher success rate than conventional rank minimization, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, motion edge detection, photometric stereo, image alignment and recovery, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.",
            "output": [
                "Partial Sum Minimization of Singular Values in Robust PCA: Algorithm and Applications"
            ]
        },
        {
            "id": "task1540-ac66bf4623be4784be6cf4c3e4ce6b68",
            "input": "Conditional probabilities are a core concept in machine learning. For ex-<lb>ample, optimal prediction of a label Y given an inputX corresponds to maximizing<lb>the conditional probability of Y given X . A common approach to inference tasks<lb>is learning a model of conditional probabilities. However, these models are often<lb>based on strong assumptions (e.g., log-linear models), and hence their estimate of<lb>conditional probabilities is not robust and is highly dependent on the validity of<lb>their assumptions.<lb>Here we propose a framework for reasoning about conditional probabilities without<lb>assuming anything about the underlying distributions, except knowledge of their<lb>second order marginals, which can be estimated from data. We show how this<lb>setting leads to guaranteed bounds on conditional probabilities, which can be calcu-<lb>lated efficiently in a variety of settings, including structured-prediction. Finally, we<lb>apply them to semi-supervised deep learning, obtaining results competitive with<lb>variational autoencoders.",
            "output": [
                "Robust Conditional Probabilities"
            ]
        },
        {
            "id": "task1540-8f6d95c9f8854b09b91f1613fd2d58c0",
            "input": "Arabic Documents Clustering is an important task for obtaining good results with the traditional Information Retrieval (IR) systems especially with the rapid growth of the number of online documents present in Arabic language. Documents clustering aim to automatically group similar documents in one cluster using different similarity/distance measures. This task is often affected by the documents length, useful information on the documents is often accompanied by a large amount of noise, and therefore it is necessary to eliminate this noise while keeping useful information to boost the performance of Documents clustering. In this paper, we propose to evaluate the impact of text summarization using the Latent Semantic Analysis Model on Arabic Documents Clustering in order to solve problems cited above, using five similarity/distance measures: Euclidean Distance, Cosine Similarity, Jaccard Coefficient, Pearson Correlation Coefficient and Averaged Kullback-Leibler Divergence, for two times: without and with stemming. Our experimental results indicate that our proposed approach effectively solves the problems of noisy information and documents length, and thus significantly improve the clustering performance.",
            "output": [
                "SEMANTIC ANALYSIS TO ENHANCE ARABIC DOCUMENTS CLUSTERING"
            ]
        },
        {
            "id": "task1540-b2e766ffac0a49929eebb0de7e18766d",
            "input": "Significant efforts have been made to understand and document knowledge related to scientific measurements. Many of those efforts resulted in one or more high-quality ontologies that describe some aspects of scientific measurements, but not in a comprehensive and coherently integrated manner. For instance, we note that many of these high-quality ontologies are not properly aligned, and more challenging, that they have different and often conflicting concepts and approaches for encoding knowledge about empirical measurements. As a result of this lack of an integrated view, it is often challenging for scientists to determine whether any two scientific measurements were taken in semantically compatible manners, thus making it difficult to decide whether measurements should be analyzed in combination or not. In this paper, we present the Human-Aware Sensor Network Ontology that is a comprehensive alignment and integration of a sensing infrastructure ontology and a provenance ontology. HASNetO has been under development for more than one year, and has been reviewed, shared and used by multiple scientific communities. The ontology has been in use to support the data management of a number of large-scale ecological monitoring activities (observations) and empirical experiments.",
            "output": [
                "Human-Aware Sensor Network Ontology: Semantic Support for Empirical Data Collection"
            ]
        },
        {
            "id": "task1540-4ded0abc1a0b40bb93144875b8161788",
            "input": "This paper investigates stochastic and adversarial combinatorial multi-armed bandit problems. In the stochastic setting, we first derive problem-specific regret lower bounds, and analyze how these bounds scale with the dimension of the decision space. We then propose COMBUCB, algorithms that efficiently exploit the combinatorial structure of the problem, and derive finite-time upper bound on their regrets. These bounds improve over regret upper bounds of existing algorithms, and we show numerically thatCOMBUCB significantly outperforms any other algorithm. In the adversarial setting, we propose two simple algorithms, namely COMBEXP-1 and COMBEXP-2 for semi-bandit and bandit feedback, respectively. Their regrets have similar scaling as state-of-the-art algorithms, in spite of the simplicity of their implementation.",
            "output": [
                "Stochastic and Adversarial Combinatorial Bandits"
            ]
        },
        {
            "id": "task1540-c217c2adf1d143c7ac8c41dd2925ad78",
            "input": "Sarcasm is considered one of the most difficult problem in sentiment analysis. In our ob-servation on Indonesian social media, for cer-tain topics, people tend to criticize something using sarcasm. Here, we proposed two additional features to detect sarcasm after a common sentiment analysis is conducted. The features are the negativity information and the number of interjection words. We also employed translated SentiWordNet in the sentiment classification. All the classifications were conducted with machine learning algorithms. The experimental results showed that the additional features are quite effective in the sarcasm detection. Keywords— Sentimen analysis, sarcasm, classification,",
            "output": [
                "Indonesian Social Media Sentiment Analysis with Sarcasm Detection"
            ]
        },
        {
            "id": "task1540-25a9a073f7004ceeaf26c9dc2ebfc3b9",
            "input": "Extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory. Recent neural program induction approaches have attempted to address this problem, but are typically limited to differentiable memory, and consequently cannot scale beyond small synthetic tasks. In this work, we propose the Manager-ProgrammerComputer framework, which integrates neural networks with non-differentiable memory to support abstract, scalable and precise operations through a friendly neural computer interface. Specifically, we introduce a Neural Symbolic Machine, which contains a sequence-to-sequence neural \"programmer\", and a nondifferentiable \"computer\" that is a Lisp interpreter with code assist. To successfully apply REINFORCE for training, we augment it with approximate gold programs found by an iterative maximum likelihood training process. NSM is able to learn a semantic parser from weak supervision over a large knowledge base. It achieves new state-of-the-art performance on WEBQUESTIONSSP, a challenging semantic parsing dataset. Compared to previous approaches, NSM is end-to-end, therefore does not rely on feature engineering or domain specific knowledge.",
            "output": [
                "Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision (Short Version)"
            ]
        },
        {
            "id": "task1540-2dd65e9d6dca4d65901ae14b8c35a17c",
            "input": "A fundamental problem in control is to learn a model of a system from observations that is useful for controller synthesis. To provide good performance guarantees, existing methods must assume that the real system is in the class of models considered during learning. We present an iterative method with strong guarantees even in the agnostic case where the system is not in the class. In particular, we show that any no-regret online learning algorithm can be used to obtain a nearoptimal policy, provided some model achieves low training error and access to a good exploration distribution. Our approach applies to both discrete and continuous domains. We demonstrate its efficacy and scalability on a challenging helicopter domain from the literature.",
            "output": [
                "Agnostic System Identification for Model-Based Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-3d7c2944fc2046db8316ed5b7b48e53a",
            "input": "In the last two decades, a number of methods have been proposed for forecasting based on fuzzy time series. Most of the fuzzy time series methods are presented for forecasting of car road accidents. However , the forecasting accuracy rates of the existing methods are not good enough. In this paper, we compared our proposed new method of fuzzy time series forecasting with existing methods. Our method is based on means based partitioning of the historical data of car road accidents. The proposed method belongs to the kth order and time-variant methods. The proposed method can get the best forecasting accuracy rate for forecasting the car road accidents than the existing methods. KeywordsFuzzy sets, Fuzzy logical groups, fuzzified data, fuzzy time series.",
            "output": [
                "Inaccuracy Minimization by Partitioning Fuzzy Data Sets – Validation of an Analytical Methodology"
            ]
        },
        {
            "id": "task1540-cec01a2896fd4216a03b6222376416e7",
            "input": "Living organisms intertwine soft (e.g., muscle) and hard (e.g., bones) materials, giving them an intrinsic flexibility and resiliency often lacking in conventional rigid robots. The emerging field of soft robotics seeks to harness these same properties in order to create resilient machines. The nature of soft materials, however, presents considerable challenges to aspects of design, construction, and control – and up until now, the vast majority of gaits for soft robots have been hand-designed through empirical trial-and-error. This manuscript describes an easy-to-assemble tensegritybased soft robot capable of highly dynamic locomotive gaits and demonstrating structural and behavioral resilience in the face of physical damage. Enabling this is the use of a machine learning algorithm able to discover novel gaits with a minimal number of physical trials. These results lend further credence to soft-robotic approaches that seek to harness the interaction of complex material dynamics in order to generate a wealth of dynamical behaviors.",
            "output": [
                "Soft tensegrity robots"
            ]
        },
        {
            "id": "task1540-c0e4ab00e068459087a401787e7c3c3c",
            "input": "Translating information between text and image is a fundamental problem in artificial intelligence that connects natural language processing and computer vision. In the past few years, performance in image caption generation has seen significant improvement through the adoption of recurrent neural networks (RNN). Meanwhile, text-to-image generation begun to generate plausible images using datasets of specific categories like birds and flowers. We’ve even seen image generation from multi-category datasets such as the Microsoft Common Objects in Context (MSCOCO) through the use of generative adversarial networks (GANs). Synthesizing objects with a complex shape, however, is still challenging. For example, animals and humans have many degrees of freedom, which means that they can take on many complex shapes. We propose a new training method called Image-Text-Image (I2T2I) which integrates text-to-image and image-to-text (image captioning) synthesis to improve the performance of textto-image synthesis. We demonstrate that I2T2I can generate better multi-categories images using MSCOCO than the stateof-the-art. We also demonstrate that I2T2I can achieve transfer learning by using a pre-trained image captioning module to generate human images on the MPII Human Pose dataset (MHP) without using sentence annotation.",
            "output": [
                "I2T2I: LEARNING TEXT TO IMAGE SYNTHESIS WITH TEXTUAL DATA AUGMENTATION"
            ]
        },
        {
            "id": "task1540-2a606b01f05b468e9ccbec8ce0aed68e",
            "input": "In Machine Learning, the parent set identification problem is to find a set of random variables that best explain selected variable given the data and some predefined scoring function. This problem is a critical component to structure learning of Bayesian networks and Markov blankets discovery, and thus has many practical applications ranging from fraud detection to clinical decision support. In this paper, we introduce a new distributed memory approach to the exact parent sets assignment problem. To achieve scalability, we derive theoretical bounds to constraint the search space when MDL scoring function is used, and we reorganize the underlying dynamic programming such that the computational density is increased and fine-grain synchronization is eliminated. We then design efficient realization of our approach in the Apache Spark platform. Through experimental results, we demonstrate that the method maintains strong scalability on a 500-core standalone Spark cluster, and it can be used to efficiently process data sets with 70 variables, far beyond the reach of the currently available solutions.",
            "output": [
                "Scalable Exact Parent Sets Identification in Bayesian Networks Learning with Apache Spark"
            ]
        },
        {
            "id": "task1540-5f412f1324ab47e6a64370f6434a959c",
            "input": "Efficient and robust algorithms for decentralized estimation in networks are essential to many distributed systems. Whereas distributed estimation of sample mean statistics has been the subject of a good deal of attention, computation of U statistics, relying on more expensive averaging over pairs of observations, is a less investigated area. Yet, such data functionals are essential to describe global properties of a statistical population, with important examples including Area Under the Curve, empirical variance, Gini mean difference and within-cluster point scatter. This paper proposes new synchronous and asynchronous randomized gossip algorithms which simultaneously propagate data across the network and maintain local estimates of the U -statistic of interest. We establish convergence rate bounds of O(1/t) and O(log t/t) for the synchronous and asynchronous cases respectively, where t is the number of iterations, with explicit data and network dependent terms. Beyond favorable comparisons in terms of rate analysis, numerical experiments provide empirical evidence the proposed algorithms surpasses the previously introduced approach.",
            "output": [
                "Extending Gossip Algorithms to Distributed Estimation of U -Statistics"
            ]
        },
        {
            "id": "task1540-65999922c46a4dafa76569ec97c5273f",
            "input": "This paper presents a dataset collected from natural dialogs which enables to test the ability of dialog systems to learn new facts from user utterances throughout the dialog. This interactive learning will help with one of the most prevailing problems of open domain dialog system, which is the sparsity of facts a dialog system can reason about. The proposed dataset, consisting of 1900 collected dialogs, allows simulation of an interactive gaining of denotations and questions explanations from users which can be used for the interactive learning.",
            "output": [
                "Data Collection for Interactive Learning through the Dialog"
            ]
        },
        {
            "id": "task1540-f3a06218c6cd40bea3ce32a7f833c6b9",
            "input": "Policy evaluation is concerned with estimating the value function that predicts long-term values of states under a given policy. It is a crucial step in many reinforcement-learning algorithms. In this paper, we focus on policy evaluation with linear function approximation over a fixed dataset. We first transform the empirical policy evaluation problem into a (quadratic) convex-concave saddle-point problem, and then present a primal-dual batch gradient method, as well as two stochastic variance reduction methods for solving the problem. These algorithms scale linearly in both sample size and feature dimension. Moreover, they achieve linear convergence even when the saddle-point problem has only strong concavity in the dual variables but no strong convexity in the primal variables. Numerical experiments on benchmark problems demonstrate the effectiveness of our methods.",
            "output": [
                "Stochastic Variance Reduction Methods for Policy Evaluation"
            ]
        },
        {
            "id": "task1540-8384b28238ac4fb1a81d8745240c7438",
            "input": "Structured sparse optimization is an important and challenging problem for analyzing high-dimensional data in a variety of applications such as bioinformatics, medical imaging, social networks, and astronomy. Although a number of structured sparsity models have been explored, such as trees, groups, clusters, and paths, connected subgraphs have been rarely explored in the current literature. One of the main technical challenges is that there is no structured sparsity-inducing norm that can directly model the space of connected subgraphs, and there is no exact implementation of a projection oracle for connected subgraphs due to its NP-hardness. In this paper, we explore efficient approximate projection oracles for connected subgraphs, and propose two new efficient algorithms, namely, GRAPH-IHT and GRAPH-GHTP, to optimize a generic nonlinear objective function subject to connectivity constraint on the support of the variables. Our proposed algorithms enjoy strong guarantees analogous to several current methods for sparsity-constrained optimization, such as Projected Gradient Descent (PGD), Approximate Model Iterative Hard Thresholding (AM-IHT), and Gradient Hard Thresholding Pursuit (GHTP) with respect to convergence rate and approximation accuracy. We apply our proposed algorithms to optimize several well-known graph scan statistics in several applications of connected subgraph detection as a case study, and the experimental results demonstrate that our proposed algorithms outperform state-of-the-art methods.",
            "output": [
                "Technical Report: Graph-Structured Sparse Optimization for Connected Subgraph Detection"
            ]
        },
        {
            "id": "task1540-9809ba5a32794a9e844afc4b6b204c23",
            "input": "Due to imprecision and uncertainties in predicting real world problems, artificial neural network (ANN) techniques have become increasingly useful for modeling and optimization. This paper presents an artificial neural network approach for forecasting electric energy consumption. For effective planning and operation of power systems, optimal forecasting tools are needed for energy operators to maximize profit and also to provide maximum satisfaction to energy consumers. Monthly data for electric energy consumed in the Gaza strip was collected from year 1994 to 2013. Data was trained and the proposed model was validated using 2-Fold and K-Fold cross validation techniques. The model has been tested with actual energy consumption data and yields satisfactory performance.",
            "output": [
                "Using Artificial Neural Network Techniques for Prediction of Electric Energy Consumption"
            ]
        },
        {
            "id": "task1540-eb47bc43994944e5abf51d3b93308542",
            "input": "We propose a transfer deep learning (TDL) framework that can transfer the knowledge obtained from a single-modal neural network to a network with a different modality. Specifically, we show that we can leverage speech data to fine-tune the network trained for video recognition, given an initial set of audio-video parallel dataset within the same semantics. Our approach first learns the analogypreserving embeddings between the abstract representations learned from intermediate layers of each network, allowing for semantics-level transfer between the source and target modalities. We then apply our neural network operation that fine-tunes the target network with the additional knowledge transferred from the source network, while keeping the topology of the target network unchanged. While we present an audio-visual recognition task as an application of our approach, our framework is flexible and thus can work with any multimodal dataset, or with any already-existing deep networks that share the common underlying semantics. In this work in progress report, we aim to provide comprehensive results of different configurations of the proposed approach on two widely used audiovisual datasets, and we discuss potential applications of the proposed approach.",
            "output": [
                "Multimodal Transfer Deep Learning with Applications in Audio-Visual Recognition"
            ]
        },
        {
            "id": "task1540-0610589040524db68fa60562554b04ca",
            "input": "In this paper we present an Action Language-Answer Set Programming based approach to solving planning and scheduling problems in hybrid domains domains that exhibit both discrete and continuous behavior. We use action language H to represent the domain and then translate the resulting theory into an A-Prolog program. In this way, we reduce the problem of finding solutions to planning and scheduling problems to computing answer sets of A-Prolog programs. We cite a planning and scheduling example from the literature and show how to model it in H. We show how to translate the resulting H theory into an equivalent A-Prolog program. We compute the answer sets of the resulting program using a hybrid solver called EZCSP which loosely integrates a constraint solver with an answer set solver. The solver allows us reason about constraints over reals and compute solutions to complex planning and scheduling problems. Results have shown that our approach can be applied to any planning and scheduling problem in hybrid domains.",
            "output": [
                "Planning and Scheduling in Hybrid Domains Using Answer Set Programming"
            ]
        },
        {
            "id": "task1540-5fcbb821b26748f1b1193e586df244d3",
            "input": "We first consider the problem of learning k-parities in the on-line mistake-bound model: given a hidden vector x ∈ {0, 1} with |x| = k and a sequence of “questions” a1, a2, · · · ∈ {0, 1} , where the algorithm must reply to each question with 〈ai, x〉 (mod 2), what is the best tradeoff between the number of mistakes made by the algorithm and its time complexity? We improve the previous best result of Buhrman et. al. [BGM10] by an exp(k) factor in the time complexity. Second, we consider the problem of learning k-parities in the presence of classification noise of rate η ∈ (0, 1/2). A polynomial time algorithm for this problem (when η > 0 and k = ω(1)) is a longstanding challenge in learning theory. Grigorescu et al. [GRV11] showed an algorithm running in time ( n k/2 )1+4η+o(1) . Note that this algorithm inherently requires time ( n k/2 ) even when the noise rate η is polynomially small. We observe that for sufficiently small noise rate, it is possible to break the ( n k/2 ) barrier. In particular, if for some function f(n) = ω(1) and α ∈ [1/2, 1), k = n/f(n) and η = o(f(n)/ log n), then there is an algorithm for the problem with running time poly(n) · ( n k )1−α · e.",
            "output": [
                "On learning k-parities with and without noise"
            ]
        },
        {
            "id": "task1540-ee904a0d2e024391bb7d2208fb1d8ade",
            "input": "English to Indian language machine translation poses the challenge of structural and morphological divergence. This paper describes English to Indian language statistical machine translation using pre-ordering and suffix separation. The pre-ordering uses rules to transfer the structure of the source sentences prior to training and translation. This syntactic restructuring helps statistical machine translation to tackle the structural divergence and hence better translation quality. The suffix separation is used to tackle the morphological divergence between English and highly agglutinative Indian languages. We demonstrate that the use of pre-ordering and suffix separation helps in improving the quality of English to Indian Language machine translation.",
            "output": [
                "MTIL17: English to Indian Langauge Statistical Machine Translation"
            ]
        },
        {
            "id": "task1540-0aeb2cf4ed674f648bbfb475fa3013cc",
            "input": "We explore the problem of binary classification in machine learning, with a twist the classifier is allowed to abstain on any datum, professing ignorance about the true class label without committing to any prediction. This is directly motivated by applications like medical diagnosis and fraud risk assessment, in which incorrect predictions have potentially calamitous consequences. We focus on a recent spate of theoretically driven work in this area that characterizes how allowing abstentions can lead to fewer errors in very general settings. Two areas are highlighted: the surprising possibility of zero-error learning, and the fundamental tradeoff between predicting sufficiently often and avoiding incorrect predictions. We review efficient algorithms with provable guarantees for each of these areas. We also discuss connections to other scenarios, notably active learning, as they suggest promising directions of further inquiry in this emerging field.",
            "output": [
                "The Utility of Abstaining in Binary Classification"
            ]
        },
        {
            "id": "task1540-c2a81819aa22475d9c7ea8cce8668595",
            "input": "Evolution has resulted in highly developed abilities in many natural intelligences to quickly and accurately predict mechanical phenomena. Humans have successfully developed laws of physics to abstract and model such mechanical phenomena. In the context of artificial intelligence, a recent line of work has focused on estimating physical parameters based on sensory data and use them in physical simulators to make long-term predictions. In contrast, we investigate the effectiveness of a single neural network for end-to-end long-term prediction of mechanical phenomena. Based on extensive evaluation, we demonstrate that such networks can outperform alternate approaches having even access to ground-truth physical simulators, especially when some physical parameters are unobserved or not known a-priori. Further, our network outputs a distribution of outcomes to capture the inherent uncertainty in the data. Our approach demonstrates for the first time the possibility of making actionable long-term predictions from sensor data without requiring to explicitly model the underlying physical laws.",
            "output": [
                "Learning A Physical Long-term Predictor"
            ]
        },
        {
            "id": "task1540-1157a41132744c2699d40f27e1426501",
            "input": "Semantic segmentation requires a detailed labeling of image pixels by object category. Information derived from local image patches is necessary to describe the detailed shape of individual objects. However, this information is ambiguous and can result in noisy labels. Global inference of image content can instead capture the general semantic concepts present. We advocate that holistic inference of image concepts provides valuable information for detailed pixel labeling. We propose a generic framework to leverage holistic information in the form of a LabelBank for pixellevel segmentation. We show the ability of our framework to improve semantic segmentation performance in a variety of settings. We learn models for extracting a holistic LabelBank from visual cues, attributes, and/or textual descriptions. We demonstrate improvements in semantic segmentation accuracy on standard datasets across a range of state-of-the-art segmentation architectures and holistic inference approaches.",
            "output": [
                "LabelBank: Revisiting Global Perspectives for Semantic Segmentation"
            ]
        },
        {
            "id": "task1540-88c2634002d149dbbb319486f1b8ea3c",
            "input": "Phase retrieval problems involve solving linear equations, but with missing sign (or phase, for<lb>complex numbers) information. Over the last two decades, a popular generic empirical approach<lb>to the many variants of this problem has been one of alternating minimization; i.e. alternating<lb>between estimating the missing phase information, and the candidate solution. In this paper, we<lb>show that a simple alternating minimization algorithm geometrically converges to the solution<lb>of one such problem – finding a vector x from y,A, where y = |Ax| and |z| denotes a vector<lb>of element-wise magnitudes of z – under the assumption that A is Gaussian.<lb>Empirically, our algorithm performs similar to recently proposed convex techniques for this<lb>variant (which are based on “lifting” to a convex matrix problem) in sample complexity and<lb>robustness to noise. However, our algorithm is much more efficient and can scale to large<lb>problems. Analytically, we show geometric convergence to the solution, and sample complexity<lb>that is off by log factors from obvious lower bounds. We also establish close to optimal scaling<lb>for the case when the unknown vector is sparse. Our work represents the only known theoretical<lb>guarantee for alternating minimization for any variant of phase retrieval problems in the non-<lb>convex setting.",
            "output": [
                "Phase Retrieval using Alternating Minimization"
            ]
        },
        {
            "id": "task1540-452f2cc354e44835ac253f3978e8429b",
            "input": "Estimation of causal effects of interventions in dynamical systems of interacting agents is under-developed. In this paper, we explore the intricacies of this problem through standard approaches, and demonstrate the need for more appropriate methods. Working under the Neyman-Rubin causal model, we proceed to develop a causal inference method and we explicate the stability assumptions that are necessary for valid causal inference. Our method consists of a temporal component that models the evolution of behaviors that agents adopt over time, and a behavioral component that models the distribution of agent actions conditional on adopted behaviors. This allows the imputation of long-term estimates of quantities of interest, and thus the estimation of long-term causal effects of interventions. We demonstrate our method on a dataset from behavioral game theory, and discuss open problems to stimulate future research.",
            "output": [
                "Statistical inference of long-term causal effects in multiagent systems under the Neyman-Rubin model"
            ]
        },
        {
            "id": "task1540-fc92d8e150bc4815a7c027f28e1a7cda",
            "input": "In this paper, we present a conversational model that incorporates both context and participant role for two-party conversations. Different architectures are explored for integrating participant role and context information into a Long Short-term Memory (LSTM) language model. The conversational model can function as a language model or a language generation model. Experiments on the Ubuntu Dialog Corpus show that our model can capture multiple turn interaction between participants. The proposed method outperforms a traditional LSTM model as measured by language model perplexity and response ranking. Generated responses show characteristic differences between the two participant roles.",
            "output": [
                "LSTM based Conversation Models"
            ]
        },
        {
            "id": "task1540-5b427da1f9814e02b9f08dcd81a8c962",
            "input": "Spelling errors are introduced in text either during typing, or when the user does not know the correct phoneme or grapheme. If a language contains complex words like sandhi where two or more morphemes join based on some rules, spell checking becomes very tedious. In such situations, having a spell checker with sandhi splitter which alerts the user by flagging the errors and providing suggestions is very useful. A novel algorithm of sandhi splitting is proposed in this paper. The sandhi splitter can split about 7000 most common sandhi words in Kannada language used as test samples. The sandhi splitter was integrated with a Kannada spell checker and a mechanism for generating suggestions was added. A comprehensive, platform independent, standalone spell checker with sandhi splitter application software was thus developed and tested extensively for its efficiency and correctness. A comparative analysis of this spell checker with sandhi splitter was made and results concluded that the Kannada spell checker with sandhi splitter has an improved performance. It is twice as fast, 200 times more space efficient, and it is 90% accurate in case of complex nouns and 50% accurate for complex verbs. Such a spell checker with sandhi splitter will be of foremost significance in machine translation systems, voice processing, etc. This is the first sandhi splitter in Kannada and the advantage of the novel algorithm is that, it can be extended to all Indian languages. Keywords— Natural language processing; Morphology; Computational linguistics; Sandhi splitter; Spell checke.",
            "output": [
                "Kannada Spell Checker with Sandhi Splitter"
            ]
        },
        {
            "id": "task1540-76ceb5fe2c8d4749a9b5c876ae437d99",
            "input": "The aim of the paper is to provide an exact approach for generating a Poisson process sampled from a hierarchical CRM, without having to instantiate the infinitely many atoms of the random measures. We use completely random measures (CRM) and hierarchical CRM to define a prior for Poisson processes. We derive the marginal distribution of the resultant point process, when the underlying CRM is marginalized out. Using well known properties unique to Poisson processes, we were able to derive an exact approach for instantiating a Poisson process with a hierarchical CRM prior. Furthermore, we derive Gibbs sampling strategies for hierarchical CRM models based on Chinese restaurant franchise sampling scheme. As an example, we present the sum of generalized gamma process (SGGP), and show its application in topicmodelling. We show that one can determine the power-law behaviour of the topics and words in a Bayesian fashion, by defining a prior on the parameters of SGGP.",
            "output": [
                "On collapsed representation of hierarchical Completely Random Measures"
            ]
        },
        {
            "id": "task1540-ad75f3e4f08f4e1a89774d3739c752ac",
            "input": "claims trigrams trigrams dependencies AMT-trained fixed dependencies 3.699% 4.697% 5.974% 18.18% 3.99% 2.797% 3.696% 2.597% 3.297% FEATURES (TFIDFs of) SVM Classifier's Error Rate DATASET",
            "output": [
                "Improving Automated Patent Claim Parsing: Dataset, System, and Experiments"
            ]
        },
        {
            "id": "task1540-421f04b2531446188dbe142a345c79b2",
            "input": "In this paper we explore a symmetry-based search space reduction technique which can speed up optimal pathfinding on undirected uniform-cost grid maps by up to 38 times. Our technique decomposes grid maps into a set of empty rectangles, removing from each rectangle all interior nodes and possibly some from along the perimeter. We then add a series of macro-edges between selected pairs of remaining perimeter nodes to facilitate provably optimal traversal through each rectangle. We also develop a novel online pruning technique to further speed up search. Our algorithm is fast, memory efficient and retains the same optimality and completeness guarantees as searching on an unmodified grid map.",
            "output": [
                "Symmetry-Based Search Space Reduction For Grid Maps"
            ]
        },
        {
            "id": "task1540-49481e3b72004a898cb547e8070521f9",
            "input": "Recommender systems leverage user demographic informa-<lb>tion, such as age, gender, etc., to personalize recommenda-<lb>tions and better place their targeted ads. Oftentimes, users<lb>do not volunteer this information due to privacy concerns, or<lb>due to a lack of initiative in filling out their online profiles.<lb>We illustrate a new threat in which a recommender learns<lb>private attributes of users who do not voluntarily disclose<lb>them. We design both passive and active attacks that so-<lb>licit ratings for strategically selected items, and could thus<lb>be used by a recommender system to pursue this hidden<lb>agenda. Our methods are based on a novel usage of Bayesian<lb>matrix factorization in an active learning setting. Evalua-<lb>tions on multiple datasets illustrate that such attacks are<lb>indeed feasible and use significantly fewer rated items than<lb>static inference methods. Importantly, they succeed without<lb>sacrificing the quality of recommendations to users.",
            "output": [
                "Recommending with an Agenda: Active Learning of Private Attributes using Matrix Factorization"
            ]
        },
        {
            "id": "task1540-85e87f63ae774411b5f3a3dea7ea0797",
            "input": "The majority of online display ads are served through realtime bidding (RTB) — each ad display impression is auctioned off in real-time when it is just being generated from a user visit. To place an ad automatically and optimally, it is critical for advertisers to devise a learning algorithm to cleverly bid an ad impression in real-time. Most previous works consider the bid decision as a static optimization problem of either treating the value of each impression independently or setting a bid price to each segment of ad volume. However, the bidding for a given ad campaign would repeatedly happen during its life span before the budget runs out. As such, each bid is strategically correlated by the constrained budget and the overall effectiveness of the campaign (e.g., the rewards from generated clicks), which is only observed after the campaign has completed. Thus, it is of great interest to devise an optimal bidding strategy sequentially so that the campaign budget can be dynamically allocated across all the available impressions on the basis of both the immediate and future rewards. In this paper, we formulate the bid decision process as a reinforcement learning problem, where the state space is represented by the auction information and the campaign’s real-time parameters, while an action is the bid price to set. By modeling the state transition via auction competition, we build a Markov Decision Process framework for learning the optimal bidding policy to optimize the advertising performance in the dynamic real-time bidding environment. Furthermore, the scalability problem from the large real-world auction volume and campaign budget is well handled by state value approximation using neural networks. The empirical study on two large-scale real-world datasets and the live A/B testing on a commercial platform have demonstrated the superior performance and high efficiency compared to state-of-the-art methods.",
            "output": [
                "Real-Time Bidding by Reinforcement Learning in Display Advertising"
            ]
        },
        {
            "id": "task1540-298120deaaef46ae814ba65f64a3815d",
            "input": "An important way to make large training sets is to gather noisy labels from crowds of non experts. We propose a method to aggregate noisy labels collected from a crowd of workers or annotators. Eliciting labels is important in tasks such as judging web search quality and rating products. Our method assumes that labels are generated by a probability distribution over items and labels. We formulate the method by drawing parallels between Gaussian Mixture Models (GMMs) and Restricted Boltzmann Machines (RBMs) and show that the problem of vote aggregation can be viewed as one of clustering. We use K-RBMs to perform clustering. We finally show some empirical evaluations over real datasets.",
            "output": [
                "Vote Aggregation as a Clustering Problem"
            ]
        },
        {
            "id": "task1540-7db6441f6f47476bae213ac7f110f4a8",
            "input": "This paper presents a powerful genetic algorithm (GA) to solve the traveling salesman problem (TSP). To construct a powerful GA, I use edge swapping(ES) with a local search procedure to determine good combinations of building blocks of parent solutions for generating even better offspring solutions. Experimental results on well studied TSP benchmarks demonstrate that the proposed GA is competitive in finding very high quality solutions on instances with up to 16,862 cities.",
            "output": [
                "A Powerful Genetic Algorithm for Traveling Salesman Problem"
            ]
        },
        {
            "id": "task1540-89ec796a24d045ff91f15bc45e4e2a1c",
            "input": "Machine-learning techniques are widely used in security-related applications, like spam and malware detection. However, in such settings, they have been shown to be vulnerable to adversarial attacks, including the deliberate manipulation of data at test time to evade detection. In this work, we focus on the vulnerability of linear classifiers to evasion attacks. This can be considered a relevant problem, as linear classifiers have been increasingly used in embedded systems and mobile devices for their low processing time and memory requirements. We exploit recent findings in robust optimization to investigate the link between regularization and security of linear classifiers, depending on the type of attack. We also analyze the relationship between the sparsity of feature weights, which is desirable for reducing processing cost, and the security of linear classifiers. We further propose a novel octagonal regularizer that allows us to achieve a proper trade-off between them. Finally, we empirically show how this regularizer can improve classifier security and sparsity in real-world application examples including spam and malware detection.",
            "output": [
                "On Security and Sparsity of Linear Classifiers for Adversarial Settings"
            ]
        },
        {
            "id": "task1540-083bbe36b573457d9efdf76b55051bfe",
            "input": "One of the core components of modern spoken dialogue systems is the belief tracker, which estimates the user’s goal at every step of the dialogue. However, most current approaches have difficulty scaling to larger, more complex dialogue domains. This is due to their dependency on either: a) Spoken Language Understanding models that require large amounts of annotated training data; or b) hand-crafted lexicons for capturing some of the linguistic variation in users’ language. We propose a novel Neural Belief Tracking (NBT) framework which overcomes these problems by building on recent advances in representation learning. NBT models reason over pre-trained word vectors, learning to compose them into distributed representations of user utterances and dialogue context. Our evaluation on two datasets shows that this approach surpasses past limitations, matching the performance of state-of-the-art models which rely on hand-crafted semantic lexicons and outperforming them when such lexicons are not provided.",
            "output": [
                "Neural Belief Tracker: Data-Driven Dialogue State Tracking"
            ]
        },
        {
            "id": "task1540-40a55737fd8c4d35bdb3c4c5cc051ed1",
            "input": "Bayesian Belief Networks (BBNs) are a pow­ erful formalism for reasoning under uncer­ tainty but bear some severe limitations: they require a large amount of information be­ fore any reasoning process can start, they have limited contradiction handling capabil­ ities, and their ability to provide explana­ tions for their conclusion is still controversial. There exists a class of reasoning systems, called 11-uth Maintenance Systems (TMSs), which are able to deal with partially speci­ fied knowledge, to provide well-founded ex­ planation for their conclusions, and to detect and handle contradictions. TMSs incorporat­ ing measure of uncertainty are called Belief Maintenance Systems (BMss). This paper de­ scribes how a BMS based on probabilitistic logic can be applied to BBNs, thus introduc­ ing a new class of BBNs, called Ignorant Be­ lief Networks, able to incrementally deal with partially specified conditional dependencies, to provide explanations, and to detect and handle contradictions.",
            "output": [
                "Belief Maintenance in Bayesian Networks"
            ]
        },
        {
            "id": "task1540-d00b7edcd17042e88f7ece4ed752e07b",
            "input": "We analyze a class of estimators based on convex relaxation for solving high-dimensional matrix decomposition problems. The observations are noisy realizations of a linear transformation X of the sum of an (approximately) low rank matrix Θ⋆ with a second matrix Γ⋆ endowed with a complementary form of low-dimensional structure; this set-up includes many statistical models of interest, including forms of factor analysis, multi-task regression with shared structure, and robust covariance estimation. We derive a general theorem that gives upper bounds on the Frobenius norm error for an estimate of the pair (Θ⋆,Γ⋆) obtained by solving a convex optimization problem that combines the nuclear norm with a general decomposable regularizer. Our results are based on imposing a “spikiness” condition that is related to but milder than singular vector incoherence. We specialize our general result to two cases that have been studied in past work: low rank plus an entrywise sparse matrix, and low rank plus a columnwise sparse matrix. For both models, our theory yields non-asymptotic Frobenius error bounds for both deterministic and stochastic noise matrices, and applies to matrices Θ⋆ that can be exactly or approximately low rank, and matrices Γ⋆ that can be exactly or approximately sparse. Moreover, for the case of stochastic noise matrices and the identity observation operator, we establish matching lower bounds on the minimax error, showing that our results cannot be improved beyond constant factors. The sharpness of our theoretical predictions is confirmed by numerical simulations.",
            "output": [
                "Noisy matrix decomposition via convex relaxation: Optimal rates in high dimensions"
            ]
        },
        {
            "id": "task1540-c2798123e94f4c04bcea41594582930e",
            "input": "We undertook a study of the use of a memristor network for music generation, making use of the memristor’s memory to go beyond the Markov hypothesis. Seed transition matrices are created and populated using memristor equations, and which are shown to generate musical melodies and change in style over time as a result of feedback into the transition matrix. The spiking properties of simple memristor networks are demonstrated and discussed with reference to applications of music making. The limitations of simulating composing memristor networks in von Neumann hardware is discussed and a hardware solution based on physical memristor properties is presented.",
            "output": [
                "Beyond Markov Chains, Towards Adaptive Memristor Network-based Music Generation"
            ]
        },
        {
            "id": "task1540-8f3b66965f444729b911584b94f87e2b",
            "input": "We propose a new learning method for heterogeneous domain adaptation (HDA), in which the data from the source domain and the target domain are represented by heterogeneous features with different dimensions. Using two different projection matrices, we first transform the data from two domains into a common subspace in order to measure the similarity between the data from two domains. We then propose two new feature mapping functions to augment the transformed data with their original features and zeros. The existing learning methods (e.g., SVM and SVR) can be readily incorporated with our newly proposed augmented feature representations to effectively utilize the data from both domains for HDA. Using the hinge loss function in SVM as an example, we introduce the detailed objective function in our method called Heterogeneous Feature Augmentation (HFA) for a linear case and also describe its kernelization in order to efficiently cope with the data with very high dimensions. Moreover, we also develop an alternating optimization algorithm to effectively solve the nontrivial optimization problem in our HFA method. Comprehensive experiments on two benchmark datasets clearly demonstrate that HFA outperforms the existing HDA methods.",
            "output": [
                "Learning with Augmented Features for Heterogeneous Domain Adaptation"
            ]
        },
        {
            "id": "task1540-808a36f1baa549c0aff8b013a0540646",
            "input": "The paper presents a novel technique called “Structural Crossing-Over” to synthesize qualified data for training machine learning-based handwriting recognition. The proposed technique can provide a greater variety of patterns of training data than the existing approaches such as elastic distortion and tangentbased affine transformation. A couple of training characters are chosen, then they are analyzed by their similar and different structures, and finally are crossed over to generate the new characters. The experiments are set to compare the performances of tangent-based affine transformation and the proposed approach in terms of the variety of generated characters and percent of recognition errors. The standard MNIST corpus including 60,000 training characters and 10,000 test characters is employed in the experiments. The proposed technique uses 1,000 characters to synthesize 60,000 characters, and then uses these data to train and test the benchmark handwriting recognition system that exploits Histogram of Gradient: HOG as features and Support Vector Machine: SVM as recognizer. The experimental result yields 8.06% of errors. It significantly outperforms the tangent-based affine transformation and the original MNIST training data, which are 11.74% and 16.55%, respectively.",
            "output": [
                "AUTOMATIC TRAINING DATA SYNTHESIS FOR HANDWRITING RECOGNITION USING THE STRUCTURAL CROSSING-OVER TECHNIQUE"
            ]
        },
        {
            "id": "task1540-0be266d0e7c74c33b17537a370f00a2c",
            "input": "Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time.",
            "output": [
                "A large annotated corpus for learning natural language inference"
            ]
        },
        {
            "id": "task1540-4c2d273743d64a67a483c5af12b53f05",
            "input": "Building on recent advances in image caption generation and optical character recognition (OCR), we present a generalpurpose, deep learning-based system to decompile an image into presentational markup. While this task is a wellstudied problem in OCR, our method takes an inherently different, data-driven approach. Our model does not require any knowledge of the underlying markup language, and is simply trained end-to-end on real-world example data. The model employs a convolutional network for text and layout recognition in tandem with an attention-based neural machine translation system. To train and evaluate the model, we introduce a new dataset of real-world rendered mathematical expressions paired with LaTeX markup, as well as a synthetic dataset of web pages paired with HTML snippets. Experimental results show that the system is surprisingly effective at generating accurate markup for both datasets. While a standard domainspecific LaTeX OCR system achieves around 25% accuracy, our model reproduces the exact rendered image on 75% of examples.",
            "output": [
                "What You Get Is What You See: A Visual Markup Decompiler"
            ]
        },
        {
            "id": "task1540-10f848302e0a4ddc95e88f877be2c7fc",
            "input": "In this paper we extend neural Turing machine (NTM) into a dynamic neural Turing machine (D-NTM) by introducing a trainable memory addressing scheme. This scheme maintains for each memory cell two separate vectors, content and address vectors. This allows the D-NTM to learn a wide variety of location-based addressing strategies including both linear and nonlinear ones. We implement the D-NTM with both soft, differentiable and hard, non-differentiable read/write mechanisms. We investigate the mechanisms and effects for learning to read and write to a memory through experiments on Facebook bAbI tasks using both a feedforward and GRU-controller. The D-NTM is evaluated on a set of the Facebook bAbI tasks and shown to outperform NTM and LSTM baselines.",
            "output": [
                "Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes"
            ]
        },
        {
            "id": "task1540-1a112749a48144f590a87bb1a9019034",
            "input": "Distilling from a knowledge base only the part that is relevant to a subset of alphabet, which is recognized as forgetting, has attracted extensive interests in AI community. In standard propositional logic, a general algorithm of forgetting and its computation-oriented investigation in various fragments whose satisfiability are tractable are still lacking. The paper aims at filling the gap. After exploring some basic properties of forgetting in propositional logic, we present a resolution-based algorithm of forgetting for CNF fragment, and some complexity results about forgetting in Horn, renamable Horn, q-Horn, Krom, DNF and CNF fragments of propositional logic.",
            "output": [
                "On Forgetting in Tractable Propositional Fragments"
            ]
        },
        {
            "id": "task1540-5f6c898f7d0f4ab3a15970979539b881",
            "input": "Traditional algorithms for stochastic optimization require projecting the solution at each iteration into a given domain to ensure its feasibility. When facing complex domains, such as positive semi-definite cones, the projection operation can be expensive, leading to a high computational cost per iteration. In this paper, we present a novel algorithm that aims to reduce the number of projections for stochastic optimization. The proposed algorithm combines the strength of several recent developments in stochastic optimization, including mini-batch, extra-gradient, and epoch gradient descent, in order to effectively explore the smoothness and strong convexity. We show, both in expectation and with a high probability, that when the objective function is both smooth and strongly convex, the proposed algorithm achieves the optimal O(1/T ) rate of convergence with only O(log T ) projections. Our empirical study verifies the theoretical result.",
            "output": [
                "O(logT ) Projections for Stochastic Optimization of Smooth and Strongly Convex Functions"
            ]
        },
        {
            "id": "task1540-68040f07b48d426e9c20daf74f4a416c",
            "input": "Minimizing the rank of a matrix subject to affine constraints is a fundamental problem with many important applications in machine learning and statistics. In this paper we propose a simple and fast algorithm SVP (Singular Value Projection) for rank minimization with affine constraints (ARMP) and show that SVP recovers the minimum rank solution for affine constraints that satisfy the restricted isometry property. We show robustness of our method to noise with a strong geometric convergence rate even for noisy measurements. Our results improve upon a recent breakthrough by Recht, Fazel and Parillo [RFP07] in three significant ways: 1) our method (SVP) is significantly simpler to analyse and easier to implement, 2) we give geometric convergence guarantees for SVP and, as demonstrated empiricially, SVP is significantly faster on real-world and synthetic problems, 3) we give optimality and geometric convergence guarantees even for the noisy version of ARMP. In addition, we address the practically important problem of low-rank matrix completion, which can be seen as a special case of ARMP. However, the affine constraints defining the matrix-completion problem do not obey the restricted isometry property in general. We empirically demonstrate that our algorithm recovers low-rank incoherent matrices from an almost optimal number of uniformly sampled entries. We make partial progress towards proving exact recovery and provide some intuition for the performance of SVP applied to matrix completion by showing a more restricted isometry property. Our algorithm outperforms existing methods, such as those of [RFP07, CR08, CT09, CCS08, KOM09], for ARMP and the matrix-completion problem by an order of magnitude and is also significantly more robust to noise.",
            "output": [
                "Guaranteed Rank Minimization via Singular Value Projection"
            ]
        },
        {
            "id": "task1540-fcdfbc66516948d4ba1648464e609387",
            "input": "Automatically generated political event data is an important part of the social science data ecosystem. The approaches for generating this data, though, have remained largely the same for two decades. During this time, the field of computational linguistics has progressed tremendously. This paper presents an overview of political event data, including methods and ontologies, and a set of experiments to determine the applicability of deep neural networks to the extraction of political events from news text.",
            "output": [
                "Generating Politically-Relevant Event Data"
            ]
        },
        {
            "id": "task1540-5759bfe072f64cd8aa9211f24aae0a11",
            "input": "In recent years, Deep Learning has become the go-to solution for a broad range of applications, often outperforming state-of-the-art. However, it is important, for both theoreticians and practitioners, to gain a deeper understanding of the difficulties and limitations associated with common approaches and algorithms. We describe four families of problems for which some of the commonly used existing algorithms fail or suffer significant difficulty. We illustrate the failures through practical experiments, and provide theoretical insights explaining their source, and how they might be remedied.",
            "output": [
                "Failures of Deep Learning"
            ]
        },
        {
            "id": "task1540-9a4224e758ac41c0bcb8258dd34361ec",
            "input": "In order to tell stories in different voices for different audiences, interactive story systems require: (1) a semantic representation of story structure, and (2) the ability to automatically generate story and dialogue from this semantic representation using some form of Natural Language Generation (nlg). However, there has been limited research on methods for linking story structures to narrative descriptions of scenes and story events. In this paper we present an automatic method for converting from Scheherazade’s story intention graph, a semantic representation, to the input required by the personage nlg engine. Using 36 Aesop Fables distributed in DramaBank, a collection of story encodings, we train translation rules on one story and then test these rules by generating text for the remaining 35. The results are measured in terms of the string similarity metrics Levenshtein Distance and BLEU score. The results show that we can generate the 35 stories with correct content: the test set stories on average are close to the output of the Scheherazade realizer, which was customized to this semantic representation. We provide some examples of story variations generated by personage. In future work, we will experiment with measuring the quality of the same stories generated in different voices, and with techniques for making storytelling interactive.",
            "output": [
                "Generating Different Story Tellings from Semantic Representations of Narrative"
            ]
        },
        {
            "id": "task1540-bfc7ecd07c7d465e9c95ef6d5d989f48",
            "input": "This paper provides a theoretical explanation on the clustering aspect of nonnegative matrix factorization (NMF). We prove that even without imposing orthogonality nor sparsity constraint on the basis and/or coefficient matrix, NMF still can give clustering results, thus providing a theoretical support for many works, e.g., Xu et al. [1] and Kim et al. [2], that show the superiority of the standard NMF as a clustering method. Keywords—bound-constrained optimization, clustering method, non-convex optimization, nonnegative matrix factorization",
            "output": [
                "On the clustering aspect of nonnegative matrix factorization"
            ]
        },
        {
            "id": "task1540-5379b4557bcf4513aaf3fc7dc7e7ab3e",
            "input": "The assignment of unique IDs to n variables is an instance of the well-known renaming problem, for which multiple algorithms have been proposed in the literature on distributed algorithms. However, to our knowledge, all these algorithms focus on robustness to failures, and ignore the issue of privacy. On the contrary, in this paper we do not consider agent failures, and we rather need an algorithm that protects agent and topology privacy. To this purpose, we propose Algorithm 1, which is a modification of the pseudo-tree generation algorithm in Online Appendix 2, and is an improved version of the algorithm proposed by Léauté and Faltings (2009). Each variable x is assigned a unique number idx that corresponds to the order in which it is first visited during the distributed traversal of the constraint graph (or, more precisely, an upper bound thereon). This is done by appending to each CHILD message the number id of variables visited so far (lines 8, 29 and 31). Each variable adds a random number to id so as not to leak any useful upper bound on its number of neighbors (lines 5 and 15). At the end of this algorithm, the root variable discovers an upper bound n+ on the total number of variables, and reveals it to everyone (lines 35 and 22 to 24).",
            "output": [
                "Protecting Privacy through Distributed Computation in Multi-agent Decision Making Online Appendix 3: Unique ID Generation Algorithm"
            ]
        },
        {
            "id": "task1540-8c4d655e3c154582881f0d137b853398",
            "input": "Artificial object perception usually relies on a priori defined models and feature extraction algorithms. We study how the concept of object can be grounded in the sensorimotor experience of a naive agent. Without any knowledge about itself or the world it is immersed in, the agent explores its sensorimotor space and identifies objects as consistent networks of sensorimotor transitions, independent from their context. A fundamental drive for prediction is assumed to explain the emergence of such networks from a developmental standpoint. An algorithm is proposed and tested to illustrate the approach.",
            "output": [
                "Grounding object perception in a naive agent’s sensorimotor experience"
            ]
        },
        {
            "id": "task1540-dccc6c6551cd4e05bff3377489a4f914",
            "input": "This paper studies the problem of learning weighted automata from a finite labeled training sample. We consider several general families of weighted automata defined in terms of three different measures: the norm of an automaton’s weights, the norm of the function computed by an automaton, or the norm of the corresponding Hankel matrix. We present new data-dependent generalization guarantees for learning weighted automata expressed in terms of the Rademacher complexity of these families. We further present upper bounds on these Rademacher complexities, which reveal key new data-dependent terms related to the complexity of learning weighted automata.",
            "output": [
                "Generalization Bounds for Weighted Automata"
            ]
        },
        {
            "id": "task1540-05c78e4b397843e989829b1091d4784c",
            "input": "We propose a new method to enforce priors on the solution of the nonnegative matrix factorization (NMF). The proposed algorithm can be used for denoising or single-channel source separation (SCSS) applications. The NMF solution is guided to follow the Minimum Mean Square Error (MMSE) estimates under Gaussian mixture prior models (GMM) for the source signal. In SCSS applications, the spectra of the observed mixed signal are decomposed as a weighted linear combination of trained basis vectors for each source using NMF. In this work, the NMF decomposition weight matrices are treated as a distorted image by a distortion operator, which is learned directly from the observed signals. The MMSE estimate of the weights matrix under GMM prior and log-normal distribution for the distortion is then found to improve the NMF decomposition results. The MMSE estimate is embedded within the optimization objective to form a novel regularized NMF cost function. The corresponding update rules for the new objectives are derived in this paper. Experimental results show that, the proposed regularized NMF alPreprint submitted to Elsevier March 1, 2013 ar X iv :1 30 2. 72 83 v1 [ cs .L G ] 2 8 Fe b 20 13 gorithm improves the source separation performance compared with using NMF without prior or with other prior models.",
            "output": [
                "Source Separation using Regularized NMF with MMSE Estimates under GMM Priors with Online Learning for The Uncertainties"
            ]
        },
        {
            "id": "task1540-e603dd46e8364470ae7a95aae29a3cae",
            "input": "We describe a strategy for the acquisition of training data necessary to build a social-media-driven early detection system for individuals at risk for (preventable) type 2 diabetes mellitus (T2DM). The strategy uses a game-like quiz with data and questions acquired semi-automatically from Twitter. The questions are designed to inspire participant engagement and collect relevant data to train a public-health model applied to individuals. Prior systems designed to use social media such as Twitter to predict obesity (a risk factor for T2DM) operate on entire communities such as states, counties, or cities, based on statistics gathered by government agencies. Because there is considerable variation among individuals within these groups, training data on the individual level would be more effective, but this data is difficult to acquire. The approach proposed here aims to address this issue. Our strategy has two steps. First, we trained a random forest classifier on data gathered from (public) Twitter statuses and state-level statistics with state-of-the-art accuracy. We then converted this classifier into a 20-questions-style quiz and made it available online. In doing so, we achieved high engagement with individuals that took the quiz, while also building a training set of voluntarily supplied individual-level data for future classification.",
            "output": [
                "Towards Using Social Media to Identify Individuals at Risk for Preventable Chronic Illness"
            ]
        },
        {
            "id": "task1540-ffb99b3cb8514a01b5127f3e9ce47a5f",
            "input": "The RoboCup 2D Simulation League incorporates several challenging features, setting a benchmark for Artificial Intelligence (AI). In this paper we describe some of the ideas and tools around the development of our team, Gliders2012. In our description, we focus on the evaluation function as one of our central mechanisms for action selection. We also point to a new framework for watching log files in a web browser that we release for use and further development by the RoboCup community. Finally, we also summarize results of the group and final matches we played during RoboCup 2012, with Gliders2012 finishing 4th out of 19 teams.",
            "output": [
                "Gliders2012: Development and Competition Results"
            ]
        },
        {
            "id": "task1540-351b5217f745437dbafb540364998681",
            "input": "We introduce the first, general purpose, slice sampling inference engine for probabilistic programs. This engine is released as part of StocPy, a new Turing-Complete probabilistic programming language, available as a Python library. We present a transdimensional generalisation of slice sampling which is necessary for the inference engine to work on traces with different numbers of random variables. We show that StocPy compares favourably to other PPLs in terms of flexibility and usability, and that slice sampling can outperform previously introduced inference methods. Our experiments include a logistic regression, HMM, and Bayesian Neural Net.",
            "output": [
                "Slice Sampling for Probabilistic Programming"
            ]
        },
        {
            "id": "task1540-d65188c9af0c49be8666b1d65d4c8ba3",
            "input": "This paper tackles temporal resolution of documents, such as determining when a document is about or when it was written, based only on its text. We apply techniques from information retrieval that predict dates via language models over a discretized timeline. Unlike most previous works, we rely solely on temporal cues implicit in the text. We consider both document-likelihood and divergence based techniques and several smoothing methods for both of them. Our best model predicts the mid-point of individuals’ lives with a median of 22 and mean error of 36 years for Wikipedia biographies from 3800 B.C. to the present day. We also show that this approach works well when training on such biographies and predicting dates both for nonbiographical Wikipedia pages about specific years (500 B.C. to 2010 A.D.) and for publication dates of short stories (1798 to 2008). Together, our work shows that, even in absence of temporal extraction resources, it is possible to achieve remarkable temporal locality across a diverse set of texts.",
            "output": [
                "Dating Texts without Explicit Temporal Cues"
            ]
        },
        {
            "id": "task1540-8cf8d216b2ef4eb6b71dcb2fe3ab2d49",
            "input": "In reinforcement learning, we often define goals by specifying rewards within desirable states. One problem with this approach is that we typically need to redefine the rewards each time the goal changes, which often requires some understanding of the solution in the agent’s environment. When humans are learning to complete tasks, we regularly utilize alternative sources that guide our understanding of the problem. Such task representations allow one to specify goals on their own terms, thus providing specifications that can be appropriately interpreted across various environments. This motivates our own work, in which we represent goals in environments that are different from the agent’s. We introduce Cross-Domain Perceptual Reward (CDPR) functions, learned rewards that represent the visual similarity between an agent’s state and a cross-domain goal image. We report results for learning the CDPRs with a deep neural network and using them to solve two tasks with deep reinforcement learning.",
            "output": [
                "Cross-Domain Perceptual Reward Functions"
            ]
        },
        {
            "id": "task1540-f75f549290da4086a2c69580f058346c",
            "input": "We introduce a new spatial data structure for high dimensional data called the approximate principal direction tree (APD tree) that adapts to the intrinsic dimension of the data. Our algorithm ensures vector-quantization accuracy similar to that of computationally-expensive PCA trees with similar time-complexity to that of loweraccuracy RP trees. APD trees use a small number of powermethod iterations to find splitting planes for recursively partitioning the data. As such they provide a natural trade-off between the running-time and accuracy achieved by RP and PCA trees. Our theoretical results establish a) strong performance guarantees regardless of the convergence rate of the powermethod and b) that O(log d) iterations suffice to establish the guarantee of PCA trees when the intrinsic dimension is d. We demonstrate this trade-off and the efficacy of our data structure on both the CPU and GPU.",
            "output": [
                "Approximate Principal Direction Trees"
            ]
        },
        {
            "id": "task1540-8ab4083d11c449ccbf63b922fd06ad41",
            "input": "Progress in language and image understanding by machines has sparkled the interest of the research community in more open-ended, holistic tasks, and refueled an old AI dream of building intelligent machines. We discuss a few prominent challenges that characterize such holistic tasks and argue for “question answering about images” as a particular appealing instance of such a holistic task. In particular, we point out that it is a version of a Turing Test that is likely to be more robust to over-interpretations and contrast it with tasks like grounding and generation of descriptions. Finally, we discuss tools to measure progress in this field.",
            "output": [
                "Hard to Cheat: A Turing Test based on Answering Questions about Images"
            ]
        },
        {
            "id": "task1540-d66b8f1028d646ffbb764d269a164a40",
            "input": "The collection and analysis of user data drives improvements in the app and web ecosystems, but comes with risks to privacy. This paper examines discrete distribution estimation under local privacy, a setting wherein service providers can learn the distribution of a categorical statistic of interest without collecting the underlying data. We present new mechanisms, including hashed k-ary Randomized Response (k-RR), that empirically meet or exceed the utility of existing mechanisms at all privacy levels. New theoretical results demonstrate the order-optimality of k-RR and the existing RAPPOR mechanism at different privacy regimes.",
            "output": [
                "Discrete Distribution Estimation under Local Privacy"
            ]
        },
        {
            "id": "task1540-ca8fabf15f5748c89f5a84d59fddb04e",
            "input": "One important challenge for a set of agents to achieve more efficient collaboration is for these agents to maintain proper models of each other. An important aspect of these models of other agents is that they are often partial and incomplete. Thus far, there are two common representations of agent models: MDP based and action based, which are both based on action modeling. In many applications, agent models may not have been given, and hence must be learnt. While it may seem convenient to use either MDP based or action based models for learning, in this paper, we introduce a new representation based on capability models, which has several unique advantages. First, we show that learning capability models can be performed efficiently online via Bayesian learning, and the learning process is robust to high degrees of incompleteness in plan execution traces (e.g., with only start and end states). While high degrees of incompleteness in plan execution traces presents learning challenges for MDP based and action based models, capability models can still learn to abstract useful information out of these traces. As a result, capability models are useful in applications in which such incompleteness is common, e.g., robot learning human model from observations and interactions. Furthermore, when used in multi-agent planning (with each agent modeled separately), capability models provide flexible abstraction of actions. The limitation, however, is that the synthesized plan is incomplete and abstract.",
            "output": [
                "Learning of Agent Capability Models with Applications in Multi-agent Planning"
            ]
        },
        {
            "id": "task1540-b6bf07bf4f0a40539221c052c06eea87",
            "input": "We present an alternative methodology for the analysis of algorithms, based on the concept of expected discounted reward. This methodology naturally handles algorithms that do not always terminate, so it can (theoretically) be used with partial algorithms for undecidable problems, such as those found in artificial general intelligence (AGI) and automated theorem proving. We mention an approach to self-improving AGI enabled by this methodology.",
            "output": [
                "Analysis of Algorithms and Partial Algorithms"
            ]
        },
        {
            "id": "task1540-d4da71c18d5e40df83bcb8c122a5254e",
            "input": "In this paper, we propose a method which uses semi-supervised convolutional neural networks (CNNs) to select in-domain training data for statistical machine translation. This approach is particularly effective when only tiny amounts of in-domain data are available. The in-domain data and randomly sampled general-domain data are used to train a data selection model with semi-supervised CNN, then this model computes domain relevance scores for all the sentences in the generaldomain data set. The sentence pairs with top scores are selected to train the system. We carry out experiments on 4 language directions with three test domains. Compared with strong baseline systems trained with large amount of data, this method can improve the performance up to 3.1 BLEU. Its performances are significant better than three state-of-the-art language model based data selection methods. We also show that the in-domain data used to train the selection model could be as few as 100 sentences, which makes finegrained topic-dependent translation adaptation possible.",
            "output": [
                "Semi-supervised Convolutional Networks for Translation Adaptation with Tiny Amount of In-domain Data"
            ]
        },
        {
            "id": "task1540-e2d034bd59af4ff39456fede2530c9aa",
            "input": "The pre-image problem has to be solved during inference by most structured output predictors. For string kernels, this problem corresponds to finding the string associated to a given input. An algorithm capable of solving or finding good approximations to this problem would have many applications in computational biology and other fields. This work uses a recent result on combinatorial optimization of linear predictors based on string kernels to develop, for the pre-image, a low complexity upper bound valid for many string kernels. This upper bound is used with success in a branch and bound searching algorithm. Applications and results in the discovery of druggable peptides are presented and discussed.",
            "output": [
                "On the String Kernel Pre-Image Problem with Applications in Drug Discovery"
            ]
        },
        {
            "id": "task1540-77e0f04773ac43dd806cf3ba8e515ea9",
            "input": "We consider the problem of online active learning to collect data for regression modeling. Specifically, we consider a decision maker with a limited experimentation budget who must efficiently learn an underlying linear population model. Our main contribution is a novel threshold-based algorithm for selection of most informative observations; we characterize its performance and fundamental lower bounds. We extend the algorithm and its guarantees to sparse linear regression in high-dimensional settings. Simulations suggest the algorithm is remarkably robust: it provides significant benefits over passive random sampling in real-world datasets that exhibit high nonlinearity and high dimensionality — significantly reducing both the mean and variance of the squared error.",
            "output": [
                "Online Active Linear Regression via Thresholding"
            ]
        },
        {
            "id": "task1540-47869e7845e444679288d7cf6e2df77c",
            "input": "Americans spend about a third of their time online, with many participating in online conversations on social and political issues. We hypothesize that social media arguments on such issues may be more engaging and persuasive than traditional media summaries, and that particular types of people may be more or less convinced by particular styles of argument, e.g. emotional arguments may resonate with some personalities while factual arguments resonate with others. We report a set of experiments testing at large scale how audience variables interact with argument style to affect the persuasiveness of an argument, an under-researched topic within natural language processing. We show that belief change is affected by personality factors, with conscientious, open and agreeable people being more convinced by emotional arguments.",
            "output": [
                "Argument Strength is in the Eye of the Beholder: Audience Effects in Persuasion"
            ]
        },
        {
            "id": "task1540-9a90e599089e4d23b6786d01a6d5435d",
            "input": "This paper introduces a self-organizing traffic signal system for an urban road network. The key elements of this system are agents that control traffic signals at intersections. Each agent uses an interval microscopic traffic model to predict effects of its possible control actions in a short time horizon. The executed control action is selected on the basis of predicted delay intervals. Since the prediction results are represented by intervals, the agents can recognize and suspend those control actions, whose positive effect on the performance of traffic control is uncertain. Evaluation of the proposed traffic control system was performed in a simulation environment. The simulation experiments have shown that the proposed approach results in an improved performance, particularly for non-uniform traffic streams.",
            "output": [
                "A self-organizing system for urban traffic control based on predictive interval microscopic model"
            ]
        },
        {
            "id": "task1540-275ae3f186594ae18ea81b012822ab77",
            "input": "Imitation learning has traditionally been applied to learn a single task from demonstrations thereof. The requirement of structured and isolated demonstrations limits the scalability of imitation learning approaches as they are difficult to apply to real-world scenarios, where robots have to be able to execute a multitude of tasks. In this paper, we propose a multi-modal imitation learning framework that is able to segment and imitate skills from unlabelled and unstructured demonstrations by learning skill segmentation and imitation learning jointly. The extensive simulation results indicate that our method can efficiently separate the demonstrations into individual skills and learn to imitate them using a single multi-modal policy. The video of our experiments is available at http://sites.google.com/view/nips17intentiongan.",
            "output": [
                "Multi-Modal Imitation Learning from Unstructured Demonstrations using Generative Adversarial Nets"
            ]
        },
        {
            "id": "task1540-7e98c5e6bc2245b09783f5c38ee5adeb",
            "input": "Conditional Simple Temporal Network (CSTN) is a constraint-based graph-formalism for conditional temporal planning. It offers a more flexible formalism than the equivalent CSTP model of Tsamardinos, Vidal and Pollack, from which it was derived mainly as a sound formalization. Three notions of consistency arise for CSTNs and CSTPs: weak, strong, and dynamic. Dynamic consistency is the most interesting notion, but it is also the most challenging and it was conjectured to be hard to assess. Tsamardinos, Vidal and Pollack gave a doubly-exponential time algorithm for deciding whether a CSTN is dynamicallyconsistent and to produce, in the positive case, a dynamic execution strategy of exponential size. In the present work we offer a proof that deciding whether a CSTN is dynamicallyconsistent is coNP-hard and provide the first singly-exponential time algorithm for this problem, also producing a dynamic execution strategy whenever the input CSTN is dynamically-consistent. The algorithm is based on a novel connection with Mean Payoff Games, a family of two-player infinite games played on finite graphs, well known for having applications in model-checking and formal verification. The presentation of such connection is mediated by the Hyper Temporal Network model, a tractable generalization of Simple Temporal Networks whose consistency checking is equivalent to determining Mean Payoff Games. In order to analyze the algorithm we introduce a refined notion of dynamic-consistency, named -dynamic-consistency, and present a sharp lower bounding analysis on the critical value of the reaction time ε̂ where the CSTN transits from being, to not being, dynamically-consistent. The proof technique introduced in this analysis of ε̂ is applicable more generally when dealing with linear difference constraints which include strict inequalities.",
            "output": [
                "Dynamic Consistency of Conditional Simple Temporal Networks via Mean Payoff Games: a Singly-Exponential Time DC-Checking"
            ]
        },
        {
            "id": "task1540-25956d8644224911ac3cfcc0aae34761",
            "input": "Machine-learning techniques have been recently used with spectacular results to generate artefacts such as music or text. However, these techniques are still unable to capture and generate artefacts that are convincingly structured. In this paper we present an approach to generate structured musical sequences. We introduce a mechanism for sampling efficiently variations of musical sequences. Given a input sequence and a statistical model, this mechanism samples a set of sequences whose distance to the input sequence is approximately within specified bounds. This mechanism is implemented as an extension of belief propagation, and uses local fields to bias the generation. We show experimentally that sampled sequences are indeed closely correlated to the standard musical similarity measure defined by Mongeau and Sankoff. We then show how this mechanism can used to implement composition strategies that enforce arbitrary structure on a musical lead sheet generation problem.",
            "output": [
                "Sampling Variations of Lead Sheets"
            ]
        },
        {
            "id": "task1540-6912cb201d3b4a9c9139102a08631e82",
            "input": "Learning representations of data, and in particular learning features for a subsequent prediction task, has been a fruitful area of research delivering impressive empirical results in recent years. However, relatively little is understood about what makes a representation ‘good’. We propose the idea of a risk gap induced by representation learning for a given prediction context, which measures the difference in the risk of some learner using the learned features as compared to the original inputs. We describe a set of sufficient conditions for unsupervised representation learning to provide a benefit, as measured by this risk gap. These conditions decompose the problem of when representation learning works into its constituent parts, which can be separately evaluated using an unlabeled sample, suitable domain-specific assumptions about the joint distribution, and analysis of the feature learner and subsequent supervised learner. We provide two examples of such conditions in the context of specific properties of the unlabeled distribution, namely when the data lies close to a low-dimensional manifold and when it forms clusters. We compare our approach to a recently proposed analysis of semi-supervised learning.",
            "output": [
                "A Modular Theory of Feature Learning"
            ]
        },
        {
            "id": "task1540-d8128bbce0aa4c08a08f6b0e8defd00b",
            "input": "In many real applications that use and analyze networked data, the links in the network graph may be erroneous, or derived from probabilistic techniques. In such cases, the node classification problem can be challenging, since the unreliability of the links may affect the final results of the classification process. If the information about link reliability is not used explicitly, the classification accuracy in the underlying network may be affected adversely. In this paper, we focus on situations that require the analysis of the uncertainty that is present in the graph structure. We study the novel problem of node classification in uncertain graphs, by treating uncertainty as a first-class citizen. We propose two techniques based on a Bayes model and automatic parameter selection, and show that the incorporation of uncertainty in the classification process as a first-class citizen is beneficial. We experimentally evaluate the proposed approach using different real data sets, and study the behavior of the algorithms under different conditions. The results demonstrate the effectiveness and efficiency of our approach.",
            "output": [
                "Node Classification in Uncertain Graphs"
            ]
        },
        {
            "id": "task1540-2657b04aa0534bd7be115782f58a6514",
            "input": "The paper continues the investigation of Poincare and Russel’s Vicious Circle Principle (VCP) in the context of the design of logic programming languages with sets. We expand previously introduced language Alog with aggregates by allowing infinite sets and several additional set related constructs useful for knowledge representation and teaching. In addition, we propose an alternative formalization of the original VCP and incorporate it into the semantics of new language, Slog, which allows more liberal construction of sets and their use in programming rules. We show that, for programs without disjunction and infinite sets, the formal semantics of aggregates in Slog coincides with that of several other known languages. Their intuitive and formal semantics, however, are based on quite different ideas and seem to be more involved than that of Slog.",
            "output": [
                "Vicious Circle Principle and Formation of Sets in ASP Based Languages"
            ]
        },
        {
            "id": "task1540-089834d542624c858b6f7f85220cba33",
            "input": "Information hierarchies are organizational structures that often used to organize and present large and complex information as well as provide a mechanism for effective human navigation. Fortunately, many statistical and computational models exist that automatically generate hierarchies; however, the existing approaches do not consider linkages in information networks that are increasingly common in real-world scenarios. Current approaches also tend to present topics as an abstract probably distribution over words, etc rather than as tangible nodes from the original network. Furthermore, the statistical techniques present in many previous works are not yet capable of processing data at Web-scale. In this paper we present the Hierarchical Document Topic Model (HDTM), which uses a distributed vertex-programming process to calculate a nonparametric Bayesian generative model. Experiments on three medium size data sets and the entire Wikipedia dataset show that HDTM can infer accurate hierarchies even over large information networks.",
            "output": [
                "Scalable Models for Computing Hierarchies in Information Networks"
            ]
        },
        {
            "id": "task1540-ef99eeb7948048c0b49ec30e036e2ab7",
            "input": "A landmark based heuristic is investigated for reducing query phase run-time of the probabilistic roadmap (PRM) motion planning method. The heuristic is generated by storing minimum spanning trees from a small number of vertices within the PRM graph and using these trees to approximate the cost of a shortest path between any two vertices of the graph. The intermediate step of preprocessing the graph increases the time and memory requirements of the classical motion planning technique in exchange for speeding up individual queries making the method advantageous in multi-query applications. This paper investigates these trade-offs on PRM graphs constructed in randomized environments as well as a practical manipulator simulation. We conclude that the method is preferable to Dijkstra’s algorithm or the A∗ algorithm with conventional heuristics in multi-query applications.",
            "output": [
                "Landmark Guided Probabilistic Roadmap Queries"
            ]
        },
        {
            "id": "task1540-bc8a2797a9c24ef3a255201cd64d044b",
            "input": "We propose Diverse Embedding Neural Network (DENN), a novel architecture for language models (LMs). A DENNLM projects the input word history vector onto multiple diverse low-dimensional sub-spaces instead of a single higherdimensional sub-space as in conventional feed-forward neural network LMs. We encourage these sub-spaces to be diverse during network training through an augmented loss function. Our language modeling experiments on the Penn Treebank data set show the performance benefit of using a DENNLM.",
            "output": [
                "DIVERSE EMBEDDING NEURAL NETWORK LANGUAGE MODELS"
            ]
        },
        {
            "id": "task1540-02c8131e4f5645598305e77d3a0af9fd",
            "input": "Non-negative matrix factorization (NMF) is a natural model of admixture and is widely used in science and engineering. A plethora of algorithms have been developed to tackle NMF, but due to the non-convex nature of the problem, there is little guarantee on how well these methods work. Recently a surge of research have focused on a very restricted class of NMFs, called separable NMF, where provably correct algorithms have been developed. In this paper, we propose the notion of subset-separable NMF, which substantially generalizes the property of separability. We show that subset-separability is a natural necessary condition for the factorization to be unique or to have minimum volume. We developed the Face-Intersect algorithm which provably and efficiently solves subset-separable NMF under natural conditions, and we prove that our algorithm is robust to small noise. We explored the performance of Face-Intersect on simulations and discuss settings where it empirically outperformed the state-of-art methods. Our work is a step towards finding provably correct algorithms that solve large classes of NMF problems.",
            "output": [
                "Intersecting Faces: Non-negative Matrix Factorization With New Guarantees"
            ]
        },
        {
            "id": "task1540-154f1c834e0e409cb68832b40f98ec25",
            "input": "We present a novel approach to constraintbased causal discovery, that takes the form of straightforward logical inference, applied to a list of simple, logical statements about causal relations that are derived directly from observed (in)dependencies. It is both sound and complete, in the sense that all invariant features of the corresponding partial ancestral graph (PAG) are identified, even in the presence of latent variables and selection bias. The approach shows that every identifiable causal relation corresponds to one of just two fundamental forms. More importantly, as the basic building blocks of the method do not rely on the detailed (graphical) structure of the corresponding PAG, it opens up a range of new opportunities, including more robust inference, detailed accountability, and application to large models.",
            "output": [
                "A Logical Characterization of Constraint-Based Causal Discovery"
            ]
        },
        {
            "id": "task1540-a241fbc04f1c48c2b4e6048ec27b432a",
            "input": "*Rajdeep Borgohain Department of Computer Science and Engineering, Dibrugarh University Institute of Engineering and Technology, Dibrugarh, Assam Email: rajdeepgohain@gmail.com Sugata Sanyal School of Technology and Computer Science, Tata Ins titute of Fundamental Research, Mumbai, India Email: sanyals@gmail.com *Corresponding Author -------------------------------------------------------------------ABSTRACT-----------------------------------------------------------------The use of Artificial Intelligence is finding prominence not only in core computer areas, but also in cross disciplinary areas including medical diagnosis. In this paper, we present a rule based Expert System used in diagnosis of Cerebral Palsy. The expert system takes user input and depending on the symptoms of the patient, diagnoses if the patient is suffering from Cerebral Palsy. The Expert System also classifies the Cerebral Palsy as mil d, moderate or severe based on the presented symptoms.",
            "output": [
                "Rule Based Expert System for Cerebral Palsy Diagnosis"
            ]
        },
        {
            "id": "task1540-325c395351a74790a9f74ea2b9b0cc4b",
            "input": "While end-to-end neural machine translation (NMT) has made remarkable progress recently, NMT systems only rely on parallel corpora for parameter estimation. Since parallel corpora are usually limited in quantity, quality, and coverage, especially for low-resource languages, it is appealing to exploit monolingual corpora to improve NMT. We propose a semisupervised approach for training NMT models on the concatenation of labeled (parallel corpora) and unlabeled (monolingual corpora) data. The central idea is to reconstruct the monolingual corpora using an autoencoder, in which the sourceto-target and target-to-source translation models serve as the encoder and decoder, respectively. Our approach can not only exploit the monolingual corpora of the target language, but also of the source language. Experiments on the ChineseEnglish dataset show that our approach achieves significant improvements over state-of-the-art SMT and NMT systems.",
            "output": [
                "Semi-Supervised Learning for Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-f7147019362b4a96bdff7fbba0d116cb",
            "input": "A Bayesian net (BN) is more than a succinct way to encode a probabilistic distribution; it also corresponds to a function used to answer queries. A BN can therefore be evaluated by the accuracy of the answers it returns. Many algorithms for learning BNs, however, attempt to optimize another criterion (usu­ ally likelihood, possibly augmented with a regularizing term) , which is independent of the distribution of queries that are posed. This paper takes the \"performance criteria\" seriously, and considers the challenge of com­ puting the BN whose performance read \"accuracy over the distribution of queries\" is optimal. We show that many aspects of this learning task are more difficult than the corresponding subtasks in the standard model.",
            "output": [
                "Learning Bayesian Nets that Perform Well"
            ]
        },
        {
            "id": "task1540-64bb0daf2876413f836c883571394c75",
            "input": "Recently there has been significant activity in developing algorithms with provable guarantees for topic modeling. In standard topic models, a topic (such as sports, business, or politics) is viewed as a probability distribution ai over words, and a document is generated by first selecting a mixture w over topics, and then generating words i.i.d. from the associated mixture Aw. Given a large collection of such documents, the goal is to recover the topic vectors and then to correctly classify new documents according to their topic mixture. In this work we consider a broad generalization of this framework in which words are no longer assumed to be drawn i.i.d. and instead a topic is a complex distribution over sequences of paragraphs. Since one could not hope to even represent such a distribution in general (even if paragraphs are given using some natural feature representation), we aim instead to directly learn a document classifier. That is, we aim to learn a predictor that given a new document, accurately predicts its topic mixture, without learning the distributions explicitly. We present several natural conditions under which one can do this efficiently and discuss issues such as noise tolerance and sample complexity in this model. More generally, our model can be viewed as a generalization of the multi-view or co-training setting in machine learning. ∗Supported in part by National Science Foundation grants CCF-1525971 and CCF-1535967. †Supported in part by National Science Foundation grant CCF-1525971 and by a Microsoft Research Graduate Fellowship and an IBM Ph.D Fellowship. ar X iv :1 61 1. 01 25 9v 1 [ cs .L G ] 4 N ov 2 01 6",
            "output": [
                "Generalized Topic Modeling"
            ]
        },
        {
            "id": "task1540-bbf335b061684ed5870c7207ecb474f6",
            "input": "We address the problem of extracting structured representations of economic events from a large corpus of news articles, using a combination of natural language processing and machine learning techniques. The developed techniques allow for semi-automatic population of a financial knowledge base, which, in turn, may be used to support a range of data mining and exploration tasks. The key challenge we face in this domain is that the same event is often reported multiple times, with varying correctness of details. We address this challenge by first collecting all information pertinent to a given event from the entire corpus, then considering all possible representations of the event, and finally, using a supervised learning method, to rank these representations by the associated confidence scores. A main innovative element of our approach is that it jointly extracts and stores all attributes of the event as a single representation (quintuple). Using a purpose-built test set we demonstrate that our supervised learning approach can achieve 25% improvement in F1-score over baseline methods that consider the earliest, the latest or the most frequent reporting of the event.",
            "output": [
                "Towards Building a Knowledge Base of Monetary Transactions from a News Collection"
            ]
        },
        {
            "id": "task1540-c5d252f16b004578beddc91829478a55",
            "input": "Many natural language understanding (NLU) tasks, such as shallow parsing (i.e., text chunking) and semantic slot filling, require the assignment of representative labels to the meaningful chunks in a sentence. Most of the current deep neural network (DNN) based methods consider these tasks as a sequence labeling problem, in which a word, rather than a chunk, is treated as the basic unit for labeling. These chunks are then inferred by the standard IOB (Inside-OutsideBeginning) labels. In this paper, we propose an alternative approach by investigating the use of DNN for sequence chunking, and propose three neural models so that each chunk can be treated as a complete unit for labeling. Experimental results show that the proposed neural sequence chunking models can achieve start-of-the-art performance on both the text chunking and slot filling tasks.",
            "output": [
                "Neural Models for Sequence Chunking"
            ]
        },
        {
            "id": "task1540-7ce09eeb240540d49dcec8613976bd13",
            "input": "Most work in the area of statistical relational learning (SRL) is focussed on discrete data, even though a few approaches for hybrid SRL models have been proposed that combine numerical and discrete variables. In this paper we distinguish numerical random variables for which a probability distribution is defined by the model from numerical input variables that are only used for conditioning the distribution of discrete response variables. We show how numerical input relations can very easily be used in the Relational Bayesian Network framework, and that existing inference and learning methods need only minor adjustments to be applied in this generalized setting. The resulting framework provides natural relational extensions of classical probabilistic models for categorical data. We demonstrate the usefulness of RBN models with numeric input relations by several examples. In particular, we use the augmented RBN framework to define probabilistic models for multi-relational (social) networks in which the probability of a link between two nodes depends on numeric latent feature vectors associated with the nodes. A generic learning procedure can be used to obtain a maximum-likelihood fit of model parameters and latent feature values for a variety of models that can be expressed in the high-level RBN representation. Specifically, we propose a model that allows us to interpret learned latent feature values as community centrality degrees by which we can identify nodes that are central for one community, that are hubs between communities, or that are isolated nodes. In a multi-relational setting, the model also provides a characterization of how different relations are associated with each community.",
            "output": [
                "Numeric Input Relations for Relational Learning with Applications to Community Structure Analysis"
            ]
        },
        {
            "id": "task1540-9dc28fb05da84e088df9d1c550c9eb2e",
            "input": "In recent years significant progress has been made in successfully training recurrent neural networks (RNNs) on sequence learning problems involving long range temporal dependencies. The progress has been made on three fronts: (a) Algorithmic improvements involving sophisticated optimization techniques, (b) network design involving complex hidden layer nodes and specialized recurrent layer connections and (c) weight initialization methods. In this paper, we focus on recently proposed weight initialization with identity matrix for the recurrent weights in a RNN. This initialization is specifically proposed for hidden nodes with Rectified Linear Unit (ReLU) non linearity. We offer a simple dynamical systems perspective on weight initialization process, which allows us to propose a modified weight initialization strategy. We show that this initialization technique leads to successfully training RNNs composed of ReLUs. We demonstrate that our proposal produces comparable or better solution for three toy problems involving long range temporal structure: the addition problem, the multiplication problem and the MNIST classification problem using sequence of pixels. In addition, we present results for a benchmark action recognition problem.",
            "output": [
                "IMPROVING PERFORMANCE OF RECURRENT NEURAL NETWORK WITH RELU NONLINEARITY"
            ]
        },
        {
            "id": "task1540-39eb385d24bf43289c81b8ff9c65973e",
            "input": "This paper investigates neural characterbased morphological tagging for languages with complex morphology and large tag sets. We systematically explore a variety of neural architectures (DNN, CNN, CNNHighway, LSTM, BLSTM) to obtain character-based word vectors combined with bidirectional LSTMs to model across-word context in an end-to-end setting. We explore supplementary use of word-based vectors trained on large amounts of unlabeled data. Our experiments for morphological tagging suggest that for ”simple” model configurations, the choice of the network architecture (CNN vs. CNNHighway vs. LSTM vs. BLSTM) or the augmentation with pre-trained word embeddings can be important and clearly impact the accuracy. Increasing the model capacity by adding depth, for example, and carefully optimizing the neural networks can lead to substantial improvements, and the differences in accuracy (but not training time) become much smaller or even negligible. Overall, our best morphological taggers for German and Czech outperform the best results reported in the literature by a large margin.",
            "output": [
                "Neural Morphological Tagging from Characters for Morphologically Rich Languages"
            ]
        },
        {
            "id": "task1540-10bc44438a52415aa488dbe575806097",
            "input": "Reordering poses a major challenge in machine translation (MT) between two languages with significant differences in word order. In this paper, we present a novel reordering approach utilizing sparse features based on dependency word pairs. Each instance of these features captures whether two words, which are related by a dependency link in the source sentence dependency parse tree, follow the same order or are swapped in the translation output. Experiments on Chinese-to-English translation show a statistically significant improvement of 1.21 BLEU point using our approach, compared to a state-of-the-art statistical MT system that incorporates prior reordering approaches.",
            "output": [
                "To Swap or Not to Swap? Exploiting Dependency Word Pairs for Reordering in Statistical Machine Translation"
            ]
        },
        {
            "id": "task1540-234c10329fb74effb7418370218eaeb2",
            "input": "We study the distributed computing setting in which there are multiple servers, each holding a set of points, who wish to compute functions on the union of their point sets. A key task in this setting is Principal Component Analysis (PCA), in which the servers would like to compute a low dimensional subspace capturing as much of the variance of the union of their point sets as possible. Given a procedure for approximate PCA, one can use it to approximately solve problems such as k-means clustering and low rank approximation. The essential properties of an approximate distributed PCA algorithm are its communication cost and computational efficiency for a given desired accuracy in downstream applications. We give new algorithms and analyses for distributed PCA which lead to improved communication and computational costs for k-means clustering and related problems. Our empirical study on real world data shows a speedup of orders of magnitude, preserving communication with only a negligible degradation in solution quality. Some of these techniques we develop, such as a general transformation from a constant success probability subspace embedding to a high success probability subspace embedding with a dimension and sparsity independent of the success probability, may be of independent interest.",
            "output": [
                "Improved Distributed Principal Component Analysis"
            ]
        },
        {
            "id": "task1540-84bd89b854b1491fb6c5b0b82e6fd729",
            "input": "Deep neural networks (DNN) are the state of the art on many engineering problems such as computer vision and audition. A key factor in the success of the DNN is scalability – bigger networks work better. However, the reason for this scalability is not yet well understood. Here, we interpret the DNN as a discrete system, of linear filters followed by nonlinear activations, that is subject to the laws of sampling theory. In this context, we demonstrate that over-sampled networks are more selective, learn faster and learn more robustly. Our findings may ultimately generalize to the human brain.",
            "output": [
                "Over-Sampling in a Deep Neural Network_arxiv"
            ]
        },
        {
            "id": "task1540-d2092c1e985f42a6840c8d4cf5536274",
            "input": "We consider the problem of learning for planning, where knowledge acquired while planning is reused to plan faster in new problem instances. For robotic tasks, among others, plan execution can be captured as a sequence of visual images. For such domains, we propose to use deep neural networks in learning for planning, based on learning a reactive policy that imitates execution traces produced by a planner. We investigate architectural properties of deep networks that are suitable for learning long-horizon planning behavior, and explore how to learn, in addition to the policy, a heuristic function that can be used with classical planners or search algorithms such as A∗. Our results on the challenging Sokoban domain show that, with a suitable network design, complex decision making policies and powerful heuristic functions can be learned through imitation. Videos available at https://sites.google.com/site/learn2plannips/.",
            "output": [
                "Learning Generalized Reactive Policies using Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-02d29b69f1134ff1b18a84a4eb83ae3e",
            "input": "We show that collaborative filtering can be viewed as a sequence prediction problem, and that given this interpretation, recurrent neural networks offer very competitive approach. In particular we study how the long short-term memory (LSTM) can be applied to collaborative filtering, and how it compares to standard nearest neighbors and matrix factorization methods on movie recommendation. We show that the LSTM is competitive in all aspects, and largely outperforms other methods in terms of item coverage and short term predictions.",
            "output": [
                "Collaborative Filtering with Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-64bf51140b3a4942b400ad479df10f63",
            "input": "Recently, many variance reduced stochastic alternating direction method of multipliers (ADMM) methods (e.g. SAGADMM, SDCA-ADMM and SVRG-ADMM) have made exciting progress such as linear convergence rates for strongly convex problems. However, the best known convergence rate for general convex problems is O(1/T ) as opposed to O(1/T ) of accelerated batch algorithms, where T is the number of iterations. Thus, there still remains a gap in convergence rates between existing stochastic ADMM and batch algorithms. To bridge this gap, we introduce the momentum acceleration trick for batch optimization into the stochastic variance reduced gradient based ADMM (SVRG-ADMM), which leads to an accelerated (ASVRG-ADMM) method. Then we design two different momentum term update rules for strongly convex and general convex cases. We prove that ASVRG-ADMM converges linearly for strongly convex problems. Besides having a low per-iteration complexity as existing stochastic ADMM methods, ASVRG-ADMM improves the convergence rate on general convex problems from O(1/T ) to O(1/T ). Our experimental results show the effectiveness of ASVRG-ADMM. Introduction In this paper, we consider a class of composite convex optimization problems min x∈Rd1 f(x) + h(Ax), (1) where A∈Rd2×d1 is a given matrix, f(x) := 1 n ∑n i=1fi(x), each fi(x) is a convex function, and h(Ax) is convex but possibly non-smooth. With regard to h(·), we are interested in a sparsity-inducing regularizer, e.g. `1-norm, group Lasso and nuclear norm. When A is an identity matrix, i.e. A = Id1 , the above formulation (1) arises in many places in machine learning, statistics, and operations research (Bubeck 2015), such as logistic regression, Lasso and support vector machine (SVM). We mainly focus on the large sample regime. In this regime, even first-order batch methods, e.g. FISTA (Beck and Teboulle 2009), become computationally burdensome due to their per-iteration complexity of O(nd1). As a result, stochastic gradient descent (SGD) with per-iteration complexity of O(d1) has Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. witnessed tremendous progress in the recent years. Especially, a number of stochastic variance reduced gradient methods such as SAG (Roux, Schmidt, and Bach 2012), SDCA (Shalev-Shwartz and Zhang 2013) and SVRG (Johnson and Zhang 2013) have been proposed to successfully address the problem of high variance of the gradient estimate in ordinary SGD, resulting in a linear convergence rate (for strongly convex problems) as opposed to sub-linear rates of SGD. More recently, the Nesterov’s acceleration technique (Nesterov 2004) was introduced in (Allen-Zhu 2016; Hien et al. 2016) to further speed up the stochastic variancereduced algorithms, which results in the best known convergence rates for both strongly convex and general convex problems. This motivates us to integrate the momentum acceleration trick into the stochastic alternating direction method of multipliers (ADMM) below. When A is a more general matrix, i.e. A 6=Id1 , the formulation (1) becomes many more complicated problems arising from machine learning, e.g. graph-guided fuzed Lasso (Kim, Sohn, and Xing 2009) and generalized Lasso (Tibshirani and Taylor 2011). To solve this class of composite optimization problems with an auxiliary variable y = Ax, which are the special case of the general ADMM form, min x∈Rd1,y∈Rd2 f(x) + h(y), s.t. Ax+By = c, (2) the ADMM is an effective optimization tool (Boyd et al. 2011), and has shown attractive performance in a wide range of real-world problems, such as big data classification (Nie et al. 2014). To tackle the issue of high periteration complexity of batch (deterministic) ADMM (as a popular first-order optimization method), Wang and Banerjee (2012), Suzuki (2013) and Ouyang et al. (2013) proposed some online or stochastic ADMM algorithms. However, all these variants only achieve the convergence rate of O(1/ √ T ) for general convex problems and O(log T/T ) for strongly convex problems, respectively, as compared with the O(1/T ) and linear convergence rates of accelerated batch algorithms (Nesterov 1983), e.g. FISTA, where T is the number of iterations. By now several accelerated and faster converging versions of stochastic ADMM, which are all based on variance reduction techniques, have been proposed, e.g. SAG-ADMM (Zhong and Kwok 2014b), SDCA-ADMM (Suzuki 2014) and SVRG-ADMM (Zheng and Kwok 2016). With regard to strongly convex problems, ar X iv :1 70 7. 03 19 0v 1 [ cs .L G ] 1 1 Ju l 2 01 7 Table 1: Comparison of convergence rates and memory requirements of some stochastic ADMM algorithms. General convex Strongly-convex Space requirement SAG-ADMM O(1/T ) unknown O(d1d2+nd1) SDCA-ADMM unknown linear rate O(d1d2+n) SCAS-ADMM O(1/T ) O(1/T ) O(d1d2) SVRG-ADMM O(1/T ) linear rate O(d1d2) ASVRG-ADMM O(1/T ) linear rate O(d1d2) Suzuki (2014) and Zheng and Kwok (2016) proved that linear convergence can be obtained for the special ADMM form (i.e. B = −Id2 and c = 0) and the general ADMM form, respectively. In SAG-ADMM and SVRG-ADMM, an O(1/T ) convergence rate can be guaranteed for general convex problems, which implies that there still remains a gap in convergence rates between the stochastic ADMM and accelerated batch algorithms. To bridge this gap, we integrate the momentum acceleration trick in (Tseng 2010) for deterministic optimization into the stochastic variance reduction gradient (SVRG) based stochastic ADMM (SVRG-ADMM). Naturally, the proposed method has low per-iteration time complexity as existing stochastic ADMM algorithms, and does not require the storage of all gradients (or dual variables) as in SCAS-ADMM (Zhao, Li, and Zhou 2015) and SVRGADMM (Zheng and Kwok 2016), as shown in Table 1. We summarize our main contributions below. • We propose an accelerated variance reduced stochastic ADMM (ASVRG-ADMM) method, which integrates both the momentum acceleration trick in (Tseng 2010) for batch optimization and the variance reduction technique of SVRG (Johnson and Zhang 2013). • We prove that ASVRG-ADMM achieves a linear convergence rate for strongly convex problems, which is consistent with the best known result in SDCA-ADMM (Suzuki 2014) and SVRG-ADMM (Zheng and Kwok 2016). • We also prove that ASVRG-ADMM has a convergence rate of O(1/T ) for non-strongly convex problems, which is a factor of T faster than SAG-ADMM and SVRG-ADMM, whose convergence rates are O(1/T ). • Our experimental results further verified that our ASVRG-ADMM method has much better performance than the state-of-the-art stochastic ADMM methods. Related Work Introducing y = Ax ∈R2 , problem (1) becomes min x∈Rd1,y∈Rd2 f(x) + h(y), s.t. Ax− y = 0. (3) Although (3) is only a special case of the general ADMM form (2), when B = −Id2 and c = 0, the stochastic (or online) ADMM algorithms and theoretical results in (Wang and Banerjee 2012; Ouyang et al. 2013; Zhong and Kwok 2014b; Zheng and Kwok 2016) and this paper are all for the more general problem (2). To minimize (2), together with the dual variable λ, the update steps of batch ADMM are yk = argminy h(y) + β 2 ‖Axk−1+By−c+λk−1‖ , (4) xk = argminx f(x) + β 2 ‖Ax+Byk−c+λk−1‖ , (5) λk = λk−1 +Axk +Byk − c, (6) where β>0 is a penalty parameter. To extend the batch ADMM to the online and stochastic settings, the update steps for yk and λk remain unchanged. In (Wang and Banerjee 2012; Ouyang et al. 2013), the update step of xk is approximated as follows: xk = argmin x x∇fik(xk−1) + 1 2ηk ‖x− xk−1‖G + β 2 ‖Ax+Byk−c+λk−1‖, (7) where we draw ik uniformly at random from [n] := {1, . . . , n}, ηk ∝ 1/ √ k is the step-size, and ‖z‖G = zGz with given positive semi-definite matrix G, e.g. G = Id1 in (Ouyang et al. 2013). Analogous to SGD, the stochastic ADMM variants use an unbiased estimate of the gradient at each iteration. However, all those algorithms have much slower convergence rates than their batch counterpart, as mentioned above. This barrier is mainly due to the variance introduced by the stochasticity of the gradients. Besides, to guarantee convergence, they employ a decaying sequence of step sizes ηk, which in turn impacts the rates. More recently, a number of variance reduced stochastic ADMM methods (e.g. SAG-ADMM, SDCA-ADMM and SVRG-ADMM) have been proposed and made exciting progress such as linear convergence rates. SVRG-ADMM in (Zheng and Kwok 2016) is particularly attractive here because of its low storage requirement compared with the algorithms in (Zhong and Kwok 2014b; Suzuki 2014). Within each epoch of SVRG-ADMM, the full gradient p̃ =∇f(x̃) is first computed, where x̃ is the average point of the previous epoch. Then ∇fik(xk−1) and ηk in (7) are replaced by ∇̃fIk(xk−1) = 1 |Ik| ∑ ik∈Ik (∇fik(xk−1)−∇fik(x̃)) + p̃ (8) and a constant step-size η, respectively, where Ik ⊂ [n] is a mini-batch of size b (which is a useful technique to reduce the variance). In fact, ∇̃fIk(xk−1) is an unbiased estimator of the gradient ∇f(xk−1), i.e. E[∇̃fIk(xk−1)]=∇f(xk−1). Accelerated Variance Reduced Stochastic ADMM In this section, we design an accelerated variance reduced stochastic ADMM method for both strongly convex and general convex problems. We first make the following assumptions: Each convex fi(·) is Li-smooth, i.e. there exists a constant Li>0 such that ‖∇fi(x)−∇fi(y)‖≤Li‖x−y‖, ∀x, y ∈ R, and L , maxi Li; f(·) is μ-strongly convex, i.e. there is μ > 0 such that f(x) ≥ f(y) +∇f(y)(x− y)+ μ2 ‖x−y‖ 2 for all x, y ∈R; The matrix A has full row rank. The first two assumptions are common in the analysis of first-order optimization methods, while the last one has Algorithm 1 ASVRG-ADMM for strongly-convex case Input: m, η, β > 0, 1 ≤ b ≤ n. Initialize: x̃= z̃, ỹ, θ, λ̃=− 1 β (A T )∇f(x̃0). 1: for s = 1, 2, . . . , T do 2: x0 = z s 0 = x̃ s−1, y 0 = ỹ s−1, λ0 = λ̃ s−1; 3: p̃ = ∇f(x̃s−1); 4: for k = 1, 2, . . . ,m do 5: Choose Ik⊆ [n]of size b, uniformly at random; 6: y k=argminy h(y)+ β 2 ‖Az s k−1+By− c+λk−1‖; 7: z k=z s k−1− η(∇̃fIk(x s k−1)+βA (Az k−1+By s k−c+λ s k−1)) γθ ; 8: xk=(1− θ)x̃s−1 + θz k; 9: λk=λ s k−1 +Az s k +By s k − c; 10: end for 11: x̃= 1 m ∑m k=1x s k, ỹ s=(1−θ)ỹs−1+ θ m ∑m k=1y s k, 12: λ̃=− 1 β (A T )†∇f(x̃s); 13: end for Output: x̃ , ỹ . been used in the convergence analysis of batch ADMM (?; Nishihara et al. 2015; Deng and Yin 2016) and stochastic ADMM (Zheng and Kwok 2016). The Strongly Convex Case In this part, we consider the case of (2) when each fi(·) is convex,L-smooth, and f(·) is μ-strongly convex. Recall that this class of problems include graph-guided Logistic Regression and SVM as notable examples. To efficiently solve this class of problems, we incorporate both the momentum acceleration and variance reduction techniques into stochastic ADMM. Our algorithm is divided into T epochs, and each epoch consists of m stochastic updates, where m is usually chosen to be O(n) as in (Johnson and Zhang 2013). Let z be an important auxiliary variable, its update rule is given as follows. Similar to (Zhong and Kwok 2014b; Zheng and Kwok 2016), we also use the inexact Uzawa method (Zhang, Burger, and Osher 2011) to approximate the sub-problem (7), which can avoid computing the inverse of the matrix ( 1 η Id1+βA A). Moreover, the momentum weight 0≤ θs ≤ 1 (the update rule for θs is provided below) is introduced into the proximal term 1 2η‖x−xk−1‖ 2 G similar to that of (7), and then the sub-problem with respect to z is formulated as follows: min z (z −z k−1) ∇̃fIk(xk−1)+ θs−1 2η ‖z −z k−1‖G + β 2 ‖Az +By k − c+ λk−1‖, (9) where ∇̃fIk(xk−1) is defined in (8), η < 1 2L , and G = γId1− ηβ θs−1 AA with γ ≥ γmin ≡ ηβ‖A A‖2 θs−1 +1 to ensure that G I similar to (Zheng and Kwok 2016), where ‖·‖2 is the spectral norm, i.e. the largest singular value of the matrix. Furthermore, the update rule for x is given by xk= x̃ +θs−1(z s k− x̃)=(1−θs−1)x̃+θs−1z k, (10) where θs−1(z k − x̃s−1) is the key momentum term (similar to those in accelerated batch methods (Nesterov 2004)), which helps accelerate our algorithm by using the iterate of the previous epoch, i.e. x̃s−1. Similar to xk, ỹ s = (1− θs−1)ỹ s−1+ θs−1 m ∑m k=1y s k. Moreover, θs can be set to a constant θ in all epochs of our algorithm, which must satisfy 0 ≤ θ ≤ 1− δ(b)/(α−1), where α = 1 Lη > 1+ δ(b), and δ(b) is defined below. The optimal value of θ is provided in Proposition 1 below. The detailed procedure is shown in Algorithm 1, where we adopt the same initialization technique for λ̃ as in (Zheng and Kwok 2016), and (·)† is the pseudo-inverse. Note that, when θ=1, ASVRG-ADMM degenerates to SVRG-ADMM in (Zheng and Kwok 2016). The Non-Strongly Convex Case In this part, we consider general convex problems of the form (2) when each fi(·) is convex, L-smooth, and h(·) is not necessarily strongly convex (but possibly non-smooth). Different from the strongly convex case, the momentum weight θs is required to satisfy the following inequalities: 1− θs θ2 s ≤ 1 θ2 s−1 and 0 ≤ θs ≤ 1− δ(b) α− 1 , (11) where δ(b) := n−b b(n−1) is a decreasing function with respect to the mini-batch size b. The condition (20) allows the momentum weight to decease, but not too fast, similar to the requirement on the step-size ηk in classical SGD and stochastic ADMM (?). Unlike batch acceleration methods, the weight must satisfy both inequalities in (20). Motivated by the momentum acceleration techniques in (Tseng 2010; Nesterov 2004) for batch optimization, we give the update rule of the weight θs for the mini-batch case: θs = √ θ4 s−1+ 4θ 2 s−1 − θ s−1 2 and θ0 = 1− δ(b) α− 1 . (12) For the special case of b = 1, we have δ(1) = 1 and θ0 = 1− 1 α−1 , while b=n (i.e. batch version), δ(n)=0 and θ0= 1. Since {θs} is decreasing, then θs ≤ 1− δ(b) α−1 is satisfied. The detailed procedure is shown in Algorithm 2, which has many slight differences in the initialization and output of each epoch from Algorithm 1. In addition, the key difference between them is the update rule for the momentum weight θs. That is, θs in Algorithm 1 can be set to a constant, while that in Algorithm 2 is adaptively adjusted as in (12). Convergence Analysis This section provides the convergence analysis of our ASVRG-ADMM algorithms (i.e. Algorithms 1 and 2) for strongly convex and general convex problems, respectively. Following (Zheng and Kwok 2016), we first introduce the following function P (x, y) := f(x)−f(x∗)−∇f(x∗)T(x− x∗)+h(y)−h(y∗)−h′(y∗)T(y− y∗) as a convergence criterion, where h′(y) denotes the (sub)gradient of h(·) at y. Indeed, P (x, y)≥ 0 for all x, y ∈ R. In the following, we give the intermediate key results for our analysis. Algorithm 2 ASVRG-ADMM for general convex case Input: m, η, β > 0, 1 ≤ b ≤ n. Initialize: x̃ = z̃, ỹ, λ̃, θ0 = 1− Lηδ(b) 1−Lη . 1: for s = 1, 2, . . . , T do 2: x0=(1−θs−1)x̃+θs−1z̃, y 0= ỹs−1, λ0= λ̃s−1; 3: p̃ = ∇f(x̃s−1), z 0= z̃s−1; 4: for k = 1, 2, . . . ,m do 5: Choose Ik⊆ [n]of size b, uniformly at random; 6: y k=argminy h(y)+ β 2 ‖Az s k−1+By− c+λk−1‖; 7: z k=z s k−1− η(∇̃fIk(x s k−1)+βA (Az k−1+By s k−c+λ s k−1)) γθs−1 ; 8: xk=(1− θs−1)x̃ + θs−1z k; 9: λk=λ s k−1 +Az s k +By s k − c; 10: end for 11: x̃= 1 m ∑m k=1x s k, ỹ =(1−θs−1)ỹ+ θs−1 m ∑m k=1y s k, 12: λ̃=λm, z̃ =z m, θs= √ θ4 s−1+4θ 2 s−1−θ 2 s−1 2 ; 13: end for Output: x̃ , ỹ . Lemma 1. E[‖∇̃fIk(xk−1)−∇f(xk−1)‖] ≤2Lδ(b) [ f(x̃)−f(xk−1)+(xk−1− x̃)∇f(xk−1) ] , where δ(b)= n−b b(n−1)≤1 and 1 ≤ b ≤ n. Lemma 2. Using the same notation as in Lemma 1, let (x∗, y∗, λ∗) denote an optimal solution of problem (2), and {(z k, xk, y k, λk, x̃, ỹ)} be the sequence generated by Algorithm 1 or 2 with θs ≤ 1− δ(b) α−1, where α= 1 Lη . Then the following holds for all k, E [ P (x̃, ỹ)− θs−1 m m ∑ k=1 ( (x∗−zs k)Aφk+(y−y k)Bφk )] ≤E [ P (x̃s−1, ỹs−1) 1/(1−θs−1) + θ s−1 ( ‖x∗− z 0‖G−‖x− z m‖G )",
            "output": [
                "Accelerated Variance Reduced Stochastic ADMM"
            ]
        },
        {
            "id": "task1540-dde06b69e89243c2bc37293de2b4d706",
            "input": "For high level path planning, environments are usually modeled as distance graphs, and path planning problems are reduced to com­ puting the shortest path in distance graphs. One major drawback of this modeling is the inability to model uncertainties, which are of­ ten encountered in practice. In this paper, a new tool, called U-graph, is proposed for environment modeling. A U-graph is an ex­ tension of distance graphs with the ability to handle a kind of uncertainty. By model­ ing an uncertain environment as a U-graph, and a navigation problem as a Markovian decision process, we can precisely define a new optimality criterion for navigation plans, and more importantly, we can come up with a general algorithm for computing optimal plans for navigation tasks.",
            "output": [
                "High Level Path Planning with Uncertainty"
            ]
        },
        {
            "id": "task1540-e1c5ef6d1c7645d89f2ffb0c46dd4841",
            "input": "In many applications data is naturally presented in terms of orderings of some basic elements or symbols. Reasoning about such data requires a notion of similarity capable of handling sequences of different lengths. In this paper we describe a family of Mercer kernel functions for such sequentially structured data. The family is characterized by a decomposable structure in terms of symbol-level and structure-level similarities, representing a specific combination of kernels which allows for efficient computation. We provide an experimental evaluation on sequential classification tasks comparing kernels from our family of kernels to a state of the art sequence kernel called the Global Alignment kernel which has been shown to outperform Dynamic Time Warping.",
            "output": [
                "On a Family of Decomposable Kernels on Sequences On a Family of Decomposable Kernels on Sequences"
            ]
        },
        {
            "id": "task1540-a852bb43fc8242e2bc85dc8aaeabed9a",
            "input": "In this paper, we introduce reactive multi-context systems (rMCSs), a framework for reactive reasoning in the presence of heterogeneous knowledge sources. In particular, we show how to integrate data streams into multi-context systems (MCSs) and how to model the dynamics of the systems, based on two types of bridge rules. We illustrate how several typical problems arising in the context of stream reasoning can be handled using our framework. Reasoning based on multiple knowledge sources that need to be integrated faces the problem of potential inconsistencies. We discuss various methods for handling inconsistencies, with a special focus on non-existence of equilibria. In particular, we show how methods developed for managed MCSs can be generalized to rMCSs. We also study the issue of nondeterminism in rMCSs. One way of avoiding nondeterminism is by applying an alternative, skeptical semantics. We show how such a semantics, called well-founded semantics, can be defined for rMCSs, and what the effect of using this semantics instead of the original one is. We investigate the complexity of various reasoning problems related to rMCSs. Finally, we discuss related work, with a special focus on two of the most relevant approaches w.r.t. stream reasoning, namely LARS and STARQL.",
            "output": [
                "Reactive Multi-Context Systems: Heterogeneous Reasoning in Dynamic Environments"
            ]
        },
        {
            "id": "task1540-e3b7f72fb1cf4bdfac43f3ae5b2970d1",
            "input": "Two-timescale Stochastic Approximation (SA) algorithms are widely used in Reinforcement Learning (RL). Their iterates have two parts that are updated with distinct stepsizes. In this work we provide a recipe for analyzing two-timescale SA. Using it, we develop the first convergence rate result for them. From this result we extract key insights on stepsize selection. As an application, we obtain convergence rates for two-timescale RL algorithms such as GTD(0), GTD2, and TDC.",
            "output": [
                "Two-Timescale Stochastic Approximation Convergence Rates with Applications to Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-7b3b063381684a2791cba9b4d216d6c4",
            "input": "One of the most promising approaches for complex technical systems analysis employs ensemble methods of classification. Ensemble methods enable to build a reliable decision rules for feature space classification in the presence of many possible states of the system. In this paper, novel techniques based on decision trees are used for evaluation of the reliability of the regime of electric power systems. We proposed hybrid approach based on random forests models and boosting models. Such techniques can be applied to predict the interaction of increasing renewable power, strage devices and swiching of smart loads from intelligent domestic appliances, storage heaters and air-conditioning units and electric vehicles with grid for enhanced decision making. The ensemble classification methods were tested on the modified 118-bus IEEE power system showing that proposed technique can be employed to examine whether the power system is secured under steady-state operating conditions.",
            "output": [
                "Ensemble Methods of Classification for Power Systems Security Assessment"
            ]
        },
        {
            "id": "task1540-0afa4e6d5e1f47238e5cee97bd9c13a9",
            "input": "To achieve state-of-the-art results on challenges in vision, Convolutional Neural Networks learn stationary filters that take advantage of the underlying image structure. Our purpose is to propose an efficient layer formulation that extends this property to any domain described by a graph. Namely, we use the support of its adjacency matrix to design learnable weight sharing filters able to exploit the underlying structure of signals. The proposed formulation makes it possible to learn the weights of the filter as well as a scheme that controls how they are shared across the graph. We perform validation experiments with image datasets and show that these filters offer performances comparable with convolutional ones.",
            "output": [
                "Learning Local Receptive Fields and their Weight Sharing Scheme on Graphs"
            ]
        },
        {
            "id": "task1540-60bf9601191748198ac9755f5b138466",
            "input": "Abstract The nearest neighbor rule is one of the most widely used models for classification, and selecting a compact set of prototype instances is a primary challenges for its applications. Many existing approaches for prototype selection exploit instance-based analyses and locally-defined criteria on the class distribution, which are intractable for numerical optimization techniques. In this paper, we explore a parametric framework with an adjusted nearest neighbor rule, in which the selection of the neighboring prototypes is modified by their respective parameters. The framework allows us to formulate a minimization problem of the violation of the adjusted nearest neighbor rule over the training set with regards to numerical parameters. We show that the problem reduces to a large-margin principled learning and demonstrate its advantage by empirical comparisons with recent state-ofthe-art methods using public benchmark data.",
            "output": [
                "Discriminative Learning of the Prototype Set for Nearest Neighbor Classification"
            ]
        },
        {
            "id": "task1540-a46db45073f64427b8384d67bfb280bc",
            "input": "Semantic parsing methods are used for capturing and representing semantic meaning of text. Meaning representation capturing all the concepts in the text may not always be available or may not be sufficiently complete. Ontologies provide a structured and reasoning-capable way to model the content of a collection of texts. In this work, we present a novel approach to joint learning of ontology and semantic parser from text. The method is based on semi-automatic induction of a context-free grammar from semantically annotated text. The grammar parses the text into semantic trees. Both, the grammar and the semantic trees are used to learn the ontology on several levels – classes, instances, taxonomic and non-taxonomic relations. The approach was evaluated on the first sentences of Wikipedia pages describing people.",
            "output": [
                "Joint learning of ontology and semantic parser from text"
            ]
        },
        {
            "id": "task1540-88e66f326db344aaa24007c66faf4aca",
            "input": "following biological inspired system stated that human action recognition in the brain of mammalian leads two distinct pathways in the model, which are specialized for analysis of motion (optic flow) and form information. Principally, we have defined a novel and robust form features applying active basis model as form extractor in form pathway in the biological inspired model. An unbalanced synergetic neural net-work classifies shapes and structures of human objects along with tuning its attention parameter by quantum particle swarm optimization (QPSO) via initiation of Centroidal Voronoi Tessellations. These tools utilized and justified as strong tools for following biological system model in form pathway. But the final decision has done by combination of ultimate outcomes of both pathways via fuzzy inference which increases novality of proposed model. Combination of these two brain pathways is done by considering each feature sets in Gaussian membership functions with fuzzy product inference method. Two configurations have been proposed for form pathway: applying multi-prototype human action templates using two time synergetic neural network for obtaining uniform template regarding each actions, and second scenario that it uses abstracting human action in four key-frames. Experimental results showed promising accuracy performance on different datasets (KTH and Weizmann).",
            "output": [
                "Bio-Inspired Human Action Recognition using Hybrid Max-Product Neuro-Fuzzy Classifier and Quantum-Behaved PSO"
            ]
        },
        {
            "id": "task1540-b574b1697fbb4af7aa033260b4a9ae94",
            "input": "We introduce a model that learns active learning algorithms via metalearning. For a distribution of related tasks, our model jointly learns: a data representation, an item selection heuristic, and a method for constructing prediction functions from labeled training sets. Our model uses the item selection heuristic to gather labeled training sets from which to construct prediction functions. Using the Omniglot and MovieLens datasets, we test our model in synthetic and practical settings.",
            "output": [
                "Learning Algorithms for Active Learning"
            ]
        },
        {
            "id": "task1540-3f8dd5bcbf1a412f9e12a6ded7a05c86",
            "input": "Randomized matrix compression techniques, such as the Johnson-Lindenstrauss transform, have emerged as an effective and practical way for solving large-scale problems efficiently. With a focus on computational efficiency, however, forsaking solutions quality and accuracy becomes the trade-off. In this paper, we investigate compressed least-squares problems and propose new models and algorithms that address the issue of error and noise introduced by compression. While maintaining computational efficiency, our models provide robust solutions that are more accurate—relative to solutions of uncompressed least-squares—than those of classical compressed variants. We introduce tools from robust optimization together with a form of partial compression to improve the error-time trade-offs of compressed least-squares solvers. We develop an efficient solution algorithm for our Robust Partially-Compressed (RPC) model based on a reduction to a one-dimensional search. We also derive the first approximation error bounds for Partially-Compressed least-squares solutions. Empirical results comparing numerous alternatives suggest that robust and partially compressed solutions are effectively insulated against aggressive randomized transforms.",
            "output": [
                "Robust Partially-Compressed Least-Squares"
            ]
        },
        {
            "id": "task1540-2d31a182f52e471b8b7d00f61f14b473",
            "input": "We propose to prune a random forest (RF) for resource-constrained prediction. We first construct a RF and then prune it to optimize expected feature cost & accuracy. We pose pruning RFs as a novel 0-1 integer program with linear constraints that encourages feature re-use. We establish total unimodularity of the constraint set to prove that the corresponding LP relaxation solves the original integer program. We then exploit connections to combinatorial optimization and develop an efficient primal-dual algorithm, scalable to large datasets. In contrast to our bottom-up approach, which benefits from good RF initialization, conventional methods are top-down acquiring features based on their utility value and is generally intractable, requiring heuristics. Empirically, our pruning algorithm outperforms existing state-of-the-art resource-constrained algorithms.",
            "output": [
                "Pruning Random Forests for Prediction on a Budget"
            ]
        },
        {
            "id": "task1540-16e779655b254850ab921e9fb9550aa0",
            "input": "The classification of opinion texts in positive and negative is becoming a subject of great interest in sentiment analysis. The existence of many labeled opinions motivates the use of statistical and machine-learning methods. First-order statistics have proven to be very limited in this field. The Opinum approach is based on the order of the words without using any syntactic and semantic information. It consists of building one probabilistic model for the positive and another one for the negative opinions. Then the test opinions are compared to both models and a decision and confidence measure are calculated. In order to reduce the complexity of the training corpus we first lemmatize the texts and we replace most namedentities with wildcards. Opinum presents an accuracy above 81% for Spanish opinions in the financial products domain. In this work we discuss which are the most important factors that have an impact on the classification performance.",
            "output": [
                "Statistical sentiment analysis performance in Opinum"
            ]
        },
        {
            "id": "task1540-c690ab333133453fa074fbb1fdc1c076",
            "input": "A prediction market is a useful means of aggregating information about a future event. To function, the market needs a trusted entity who will verify the true outcome in the end. Motivated by the recent introduction of decentralized prediction markets, we introduce a mechanism that allows for the outcome to be determined by the votes of a group of arbiters who may themselves hold stakes in the market. Despite the potential conflict of interest, we derive conditions under which we can incentivize arbiters to vote truthfully by using funds raised from market fees to implement a peer prediction mechanism. Finally, we investigate what parameter values could be used in a real-world implementation of our mechanism.",
            "output": [
                "Crowdsourced Outcome Determination in Prediction Markets"
            ]
        },
        {
            "id": "task1540-ee33400473714cefb9bf706b381dab9d",
            "input": "This article is about how the SP theory of intelligence and its realisation in the SP machine may, with advantage, be applied to the management and analysis of big data. The SP system—introduced in the article and fully described elsewhere— may help to overcome the problem of variety in big data: it has potential as a universal framework for the representation and processing of diverse kinds of knowledge (UFK), helping to reduce the diversity of formalisms and formats for knowledge and the different ways in which they are processed. It has strengths in the unsupervised learning or discovery of structure in data, in pattern recognition, in the parsing and production of natural language, in several kinds of reasoning, and more. It lends itself to the analysis of streaming data, helping to overcome the problem of velocity in big data. Central in the workings of the system is lossless compression of information: making big data smaller and reducing problems of storage and management. There is potential for substantial economies in the transmission of data, for big cuts in the use of energy in computing, for faster processing, and for smaller and lighter computers. The system provides a handle on the problem of veracity in big data, with potential to assist in the management of errors and uncertainties in data. It lends itself to the visualisation of knowledge structures and inferential processes. A high-parallel, open-source version of the SP machine would provide a means for researchers everywhere to explore what can be done with the system and to create new versions of it.",
            "output": [
                "Big Data and the SP Theory of Intelligence"
            ]
        },
        {
            "id": "task1540-359c0bb99f294a42b2a4c01c7739d43d",
            "input": "A rhetorical structure tree (RS tree) is a representation of discourse relations among elementary discourse units (EDUs). A RS tree is very useful to many text processing tasks employing relationships among EDUs such as text understanding, summarization, and question-answering. Thai language with its unique linguistic characteristics requires a unique RS tree construction technique. This paper proposes an approach for Thai RS tree construction which consists of three major steps: EDU segmentation, Thai RS tree construction, and discourse relation (DR) identification. Two hidden markov models derived from grammatical rules are used to segment EDUs, a clustering technique with its similarity measure derived from Thai semantic rules is used to construct a Thai RS tree, and a decision tree whose features extracted from the rules is used to determine the DR between EDUs. The proposed technique is evaluated using three Thai corpora. The results show the Thai RS tree construction and the DR identification effectiveness of 94.90% and 82.81%, respectively. KeywordsThai Language, Element Discourse Unit, Rhetorical Structure Tree, Discourse Relation.",
            "output": [
                "THAI RHETORICAL STRUCTURE ANALYSIS"
            ]
        },
        {
            "id": "task1540-49bbea4673a74c889842b1bd5578c269",
            "input": "L’articolo presenta un’introduzione all’Intelligenza Artificiale (IA) in forma divulgativa e informale ma precisa. L’articolo affronta prevalentemente gli aspetti informatici della disciplina, presentando varie tecniche usate nei sistemi di IA e dividendole in simboliche e subsimboliche. L’articolo si conclude presentando il dibattito in corso sull’IA e in particolare sui vantaggi e i pericoli che sono stati individuati, terminando con l’opinione dell’autore al riguardo.",
            "output": [
                "Introduzione all’Intelligenza Artificiale∗"
            ]
        },
        {
            "id": "task1540-a7456a5143544a6a8cf0ca5341c936ce",
            "input": "Techniques for plan recogmtwn under uncer­ tainty require a stochastic model of the plan­ generation process. We introduce probabilistic state-dependent grammars (PSDGs) to represent an agent's plan-generation process. The PSDG language model extends probabilistic context­ free grammars (PCFGs) by allowing production probabilities to depend on an explicit model of the planning agent's internal and external state. Given a PSDG description of the plan-generation process, we can then use inference algorithms that exploit the particular independence proper­ ties of the PSDG language to efficiently answer plan-recognition queries. The combination of the PSDG language model and inference algorithms extends the range of plan-recognition domains for which practical probabilistic inference is pos­ sible, as illustrated by applications in traffic mon­ itoring and air combat.",
            "output": [
                "Probabilistic State-Dependent Grammars for Plan Recognition"
            ]
        },
        {
            "id": "task1540-25b1f16f5d094745a8f88edcdee36ecf",
            "input": "We present a novel neural network model that learns POS tagging and graph-based dependency parsing jointly. Our model uses bidirectional LSTMs to learn feature representations shared for both POS tagging and dependency parsing tasks, thus handling the feature-engineering problem. Our extensive experiments, on 19 languages from the Universal Dependencies project, show that our model outperforms the state-of-the-art neural networkbased Stack-propagation model for joint POS tagging and transition-based dependency parsing, resulting in a new state of the art. Our code is open-source and available at: https://github.com/ datquocnguyen/jPTDP.",
            "output": [
                "A Novel Neural Network Model for Joint POS Tagging and Graph-based Dependency Parsing"
            ]
        },
        {
            "id": "task1540-6e1a596513514995ac635edac126192f",
            "input": "Classes in natural images tend to follow long tail distributions. This is problematic when there are insufficient training examples for rare classes. This effect is emphasized in compound classes, involving the conjunction of several concepts, such as those appearing in action-recognition datasets. In this paper, we propose to address this issue by learning how to utilize common visual concepts which are readily available. We detect the presence of prominent concepts in images and use them to infer the target labels instead of using visual features directly, combining tools from vision and natural-language processing. We validate our method on the recently introduced HICO dataset reaching a mAP of 31.54% and on the Stanford40 Actions dataset, where the proposed method outperforms current state-of-the art and, combined with direct visual features, obtains an accuracy 83.12%. Moreover, the method provides for each class a semantically meaningful list of keywords and relevant image regions relating it to its constituent concepts.",
            "output": [
                "Action Classification via Concepts and Attributes"
            ]
        },
        {
            "id": "task1540-504a0b67d33f45bcb867c5908d406a3b",
            "input": "Many classification problems involve data instances that are interlinked with each other, such as webpages connected by hyperlinks. Techniques for collective classification (CC) often increase accuracy for such data graphs, but usually require a fully-labeled training graph. In contrast, we examine how to improve the semi-supervised learning of CC models when given only a sparsely-labeled graph, a common situation. We first describe how to use novel combinations of classifiers to exploit the different characteristics of the relational features vs. the non-relational features. We also extend the ideas of label regularization to such hybrid classifiers, enabling them to leverage the unlabeled data to bias the learning process. We find that these techniques, which are efficient and easy to implement, significantly increase accuracy on three real datasets. In addition, our results explain conflicting findings from prior related studies.",
            "output": [
                "Semi-Supervised Collective Classification via Hybrid Label Regularization"
            ]
        },
        {
            "id": "task1540-7f0f693656904aedacb7602ad53ae4fd",
            "input": "We present a converged algorithm for Tikhonov regularized nonnegative matrix factorization (NMF). We specially choose this regularization because it is known that Tikhonov regularized least square (LS) is the more preferable form in solving linear inverse problems than the conventional LS. Because an NMF problem can be decomposed into LS subproblems, it can be expected that Tikhonov regularized NMF will be the more appropriate approach in solving NMF problems. The algorithm is derived using additive update rules which have been shown to have convergence guarantee. We equip the algorithm with a mechanism to automatically determine the regularization parameters based on the L-curve, a well-known concept in the inverse problems community, but is rather unknown in the NMF research. The introduction of this algorithm thus solves two inherent problems in Tikhonov regularized NMF algorithm research, i.e., convergence guarantee and regularization parameters determination.",
            "output": [
                "A Converged Algorithm for Tikhonov Regularized Nonnegative Matrix Factorization with Automatic Regularization Parameters Determination"
            ]
        },
        {
            "id": "task1540-8ba78b37fe164e74b35715c2a8bee5ab",
            "input": "We introduce T-LESS, a new public dataset for estimating the 6D pose, i.e. translation and rotation, of texture-less rigid objects. The dataset features thirty industry-relevant objects with no significant texture and no discriminative color or reflectance properties. The objects exhibit symmetries and mutual similarities in shape and/or size. Compared to other datasets, a unique property is that some of the objects are parts of others. The dataset includes training and test images that were captured with three synchronized sensors, specifically a structured-light and a time-of-flight RGB-D sensor and a high-resolution RGB camera. There are approximately 39K training and 10K test images from each sensor. Additionally, two types of 3D models are provided for each object, i.e. a manually created CAD model and a semi-automatically reconstructed one. Training images depict individual objects against a black background. Test images originate from twenty test scenes having varying complexity, which increases from simple scenes with several isolated objects to very challenging ones with multiple instances of several objects and with a high amount of clutter and occlusion. The images were captured from a systematically sampled view sphere around the object/scene, and are annotated with accurate ground truth 6D poses of all modeled objects. Initial evaluation results indicate that the state of the art in 6D object pose estimation has ample room for improvement, especially in difficult cases with significant occlusion. The T-LESS dataset is available online at cmp.felk.cvut.cz/t-less.",
            "output": [
                "T-LESS: An RGB-D Dataset for 6D Pose Estimation of Texture-less Objects"
            ]
        },
        {
            "id": "task1540-95959e057e1146038dadcb312731d928",
            "input": "Being able to automatically and quickly under-<lb>stand the user context during a session is a main issue for<lb>recommender systems. As a first step toward achieving that<lb>goal, we propose a model that observes in real time the<lb>diversity brought by each item relatively to a short sequence<lb>of consultations, corresponding to the recent user history. Our<lb>model has a complexity in constant time, and is generic since<lb>it can apply to any type of items within an online service (e.g.<lb>profiles, products, music tracks) and any application domain (e-<lb>commerce, social network, music streaming), as long as we have<lb>partial item descriptions. The observation of the diversity level<lb>over time allows us to detect implicit changes. In the long term,<lb>we plan to characterize the context, i.e. to find common features<lb>among a contiguous sub-sequence of items between two changes<lb>of context determined by our model. This will allow us to<lb>make context-aware and privacy-preserving recommendations,<lb>to explain them to users. As this is an on-going research, the<lb>first step consists here in studying the robustness of our model<lb>while detecting changes of context. In order to do so, we use a<lb>music corpus of 100 users and more than 210,000 consultations<lb>(number of songs played in the global history). We validate<lb>the relevancy of our detections by finding connections between<lb>changes of context and events, such as ends of session. Of<lb>course, these events are a subset of the possible changes of<lb>context, since there might be several contexts within a session.<lb>We altered the quality of our corpus in several manners, so as<lb>to test the performances of our model when confronted with<lb>sparsity and different types of items. The results show that our<lb>model is robust and constitutes a promising approach. Keywords-User Modeling; Diversity; Context; Real-Time<lb>Analysis of Navigation Path; Recommender Systems",
            "output": [
                "Toward a Robust Diversity-Based Model to Detect Changes of Context"
            ]
        },
        {
            "id": "task1540-bb561696d28f4db59098b170301773cb",
            "input": "This paper presents a novel communication-efficient parallel belief propagation (CE-PBP) algorithm for training latent Dirichlet allocation (LDA). Based on the synchronous belief propagation (BP) algorithm, we first develop a parallel belief propagation (PBP) algorithm on the parallel architecture. Because the extensive communication delay often causes a low efficiency of parallel topic modeling, we further use Zipf’s law to reduce the total communication cost in PBP. Extensive experiments on different data sets demonstrate that CE-PBP achieves a higher topic modeling accuracy and reduces more than 80% communication cost than the state-of-the-art parallel Gibbs sampling (PGS) algorithm.",
            "output": [
                "Communication-Efficient Parallel Belief Propagation for Latent Dirichlet Allocation"
            ]
        },
        {
            "id": "task1540-d9d4e20829734dde80d650caf8237987",
            "input": "Multivariate time series forecasting is an important machine learning problem across many domains, including predictions of solar plant energy output, electricity consumption, and traffic jam situation. Temporal data arise in these realworld applications often involves a mixture of long-term and short-term patterns, for which traditional approaches such as Autoregressive models and Gaussian Process may fail. In this paper, we proposed a novel deep learning framework, namely Longand Short-term Time-series network (LSTNet), to address this open challenge. LSTNet uses the Convolution Neural Network (CNN) to extract short-term local dependency patterns among variables, and the Recurrent Neural Network (RNN) to discover long-term patterns and trends. In our evaluation on real-world data with complex mixtures of repetitive patterns, LSTNet achieved significant performance improvements over that of several state-of-the-art baseline methods. The dataset and experiment code both are uploaded to Github.",
            "output": [
                "Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-a9538d9604a148018d327deb2c23bb17",
            "input": "In this work we introduce a conditional accelerated lazy stochastic gradient descent algorithm with optimal number of calls to a stochastic first-order oracle and convergence rate O( 1 ε2 ) improving over the projection-free, Online Frank-Wolfe based stochastic gradient descent of Hazan and Kale [2012] with convergence rate O( 1 ε4 ).",
            "output": [
                "Conditional Accelerated Lazy Stochastic Gradient Descent"
            ]
        },
        {
            "id": "task1540-62cb6500eed246a49e05f3f2dd8a99a6",
            "input": "In the problem of edge sign prediction, we are given a directed graph (representing a social network), and our task is to predict the binary labels of the edges (i.e., the positive or negative nature of the social relationships). Many successful heuristics for this problem are based on the troll-trust features, estimating at each node the fraction of outgoing and incoming positive/negative edges. We show that these heuristics can be understood, and rigorously analyzed, as approximators to the Bayes optimal classifier for a simple probabilistic model of the edge labels. We then show that the maximum likelihood estimator for this model approximately corresponds to the predictions of a Label Propagation algorithm run on a transformed version of the original social graph. Extensive experiments on a number of real-world datasets show that this algorithm is competitive against state-ofthe-art classifiers in terms of both accuracy and scalability. Finally, we show that trolltrust features can also be used to derive online learning algorithms which have theoretical guarantees even when edges are adversarially labeled.",
            "output": [
                "On the Troll-Trust Model for Edge Sign Prediction in Social Networks"
            ]
        },
        {
            "id": "task1540-edd2af67a0bd46c0bca09ffb1422b8a8",
            "input": "We study response selection for multi-turn conversation in retrieval based chatbots. Existing works either ignores relationships among utterances, or misses important information in context when matching a response with a highly abstract context vector finally. We propose a new session based matching model to address both problems. The model first matches a response with each utterance on multiple granularities, and distills important matching information from each pair as a vector with convolution and pooling operations. The vectors are then accumulated in a chronological order through a recurrent neural network (RNN) which models the relationships among the utterances. The final matching score is calculated with the hidden states of the RNN. Empirical study on two public data sets shows that our model can significantly outperform the state-of-the-art methods for response selection in multi-turn conversation.",
            "output": [
                "Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots"
            ]
        },
        {
            "id": "task1540-9361f6b4a092423eb16b0d8be5f43345",
            "input": "Patient time series classification faces challenges in high degrees of dimensionality and missingness. In light of patient similarity theory, this study explores effective temporal feature engineering and reduction, missing value imputation, and change point detection methods that can afford similarity-based classification models with desirable accuracy enhancement. We select a piecewise aggregation approximation method to extract fine-grain temporal features and propose a minimalist method to impute missing values in temporal features. For dimensionality reduction, we adopt a gradient descent search method for feature weight assignment. We propose new patient status and directional change definitions based on medical knowledge or clinical guidelines about the value ranges for different patient status levels, and develop a method to detect change points indicating positive or negative patient status changes. We evaluate the effectiveness of the proposed methods in the context of early Intensive Care Unit mortality prediction. The evaluation results show that the k-Nearest Neighbor algorithm that incorporates methods we select and propose significantly outperform the relevant benchmarks for early ICU mortality prediction. This study makes contributions to time series classification and early ICU mortality prediction via identifying and enhancing temporal feature engineering and reduction methods for similarity-based time series classification.",
            "output": [
                "Leveraging Time Series Data in Similarity Based Healthcare Predictive Models"
            ]
        },
        {
            "id": "task1540-fff6584e160e4c848a6a5894b07abac7",
            "input": "Mean-field variational inference is a method for approximate Bayesian posterior inference. It approximates a full posterior distribution with a factorized set of distributions by maximizing a lower bound on the marginal likelihood. This requires the ability to integrate a sum of terms in the log joint likelihood using this factorized distribution. Often not all integrals are in closed form, which is typically handled by using a lower bound. We present an alternative algorithm based on stochastic optimization that allows for direct optimization of the variational lower bound. This method uses control variates to reduce the variance of the stochastic search gradient, in which existing lower bounds can play an important role. We demonstrate the approach on two non-conjugate models: logistic regression and an approximation to the HDP.",
            "output": [
                "Variational Bayesian Inference with Stochastic Search"
            ]
        },
        {
            "id": "task1540-af8d33c36b09432a89a728ec20412026",
            "input": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM’s BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a strong phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which beats the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM’s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.",
            "output": [
                "Sequence to Sequence Learning with Neural Networks"
            ]
        },
        {
            "id": "task1540-5cf927a8fcf649eba162baf82b1e1f9e",
            "input": "In Recommender Systems research, algorithms are often characterized as either Collaborative Filtering (CF) or Content Based (CB). CF algorithms are trained using a dataset of user explicit or implicit preferences while CB algorithms are typically based on item profiles. These approaches harness very different data sources hence the resulting recommended items are generally also very different. This paper presents a novel model that serves as a bridge from items content into their CF representations. We introduce a multiple input deep regression model to predict the CF latent embedding vectors of items based on their textual description and metadata. We showcase the effectiveness of the proposed model by predicting the CF vectors of movies and apps based on their textual descriptions. Finally, we show that the model can be further improved by incorporating metadata such as the movie release year and tags which contribute to a higher accuracy.",
            "output": [
                "Microsoft Word - cb2cf_arxiv.docx"
            ]
        },
        {
            "id": "task1540-9100e902fbfd41e8819b8dfd6ab52618",
            "input": "Extraction of Electrocardiography (ECG or EKG) signals of mother and baby is a challenging task, because one single device is used and it receives a mixture of multiple heart beats. In this paper, we would like to design a filter to separate the signals from each other.",
            "output": [
                "Electrocardiography Separation of Mother and Baby"
            ]
        },
        {
            "id": "task1540-3b65fa931c2a4db388541d7f11999e4d",
            "input": "This paper describes a new kind of knowledge representation and mining system which we are calling the Semantic Knowledge Graph. At its heart, the Semantic Knowledge Graph leverages an inverted index, along with a complementary uninverted index, to represent nodes (terms) and edges (the documents within intersecting postings lists for multiple terms/nodes). This provides a layer of indirection between each pair of nodes and their corresponding edge, enabling edges to materialize dynamically from underlying corpus statistics. As a result, any combination of nodes can have edges to any other nodes materialize and be scored to reveal latent relationships between the nodes. This provides numerous benefits: the knowledge graph can be built automatically from a real-world corpus of data, new nodes along with their combined edges can be instantly materialized from any arbitrary combination of preexisting nodes (using set operations), and a full model of the semantic relationships between all entities within a domain can be represented and dynamically traversed using a highly compact representation of the graph. Such a system has widespread applications in areas as diverse as knowledge modeling and reasoning, natural language processing, anomaly detection, data cleansing, semantic search, analytics, data classification, root cause analysis, and recommendations systems. The main contribution of this paper is the introduction of a novel system the Semantic Knowledge Graph which is able to dynamically discover and score interesting relationships between any arbitrary combination of entities (words, phrases, or extracted concepts) through dynamically materializing nodes and edges from a compact graphical representation built automatically from a corpus of data representative of a knowledge domain. The source code for our Semantic Knowledge Graph implementation is being published along with this paper to facilitate further research and extensions of this work.",
            "output": [
                "The Semantic Knowledge Graph: A compact, auto-generated model for real-time traversal and ranking of any relationship within a domain"
            ]
        },
        {
            "id": "task1540-02260778e634461fab5ee207358e9e05",
            "input": "This paper investigates a new method for improving the learning algorithm of Mixture of Experts (ME) model using a hybrid of Modified Cuckoo Search (MCS) and Conjugate Gradient (CG) as a second order optimization technique. The CG technique is combined with Back-Propagation (BP) algorithm to yield a much more efficient learning algorithm for ME structure. In addition, the experts and gating networks in enhanced model are replaced by CG based Multi-Layer Perceptrons (MLPs) to provide faster and more accurate learning. The CG is considerably depends on initial weights of connections of Artificial Neural Network (ANN), so, a metaheuristic algorithm, the so-called Modified Cuckoo Search is applied in order to select the optimal weights. The performance of proposed method is compared with Gradient Decent Based ME (GDME) and Conjugate Gradient Based ME (CGME) in classification and regression problems. The experimental results show that hybrid MSC and CG based ME (MCS-CGME) has faster convergence and better performance in utilized benchmark data sets.",
            "output": [
                "Extended Mixture of MLP Experts by Hybrid of Conjugate Gradient Method and Modified Cuckoo Search"
            ]
        },
        {
            "id": "task1540-fc218dcd27a54ffc943c766669f58115",
            "input": "In many robotic applications, some aspects of the system dynamics can be modeled accurately while others are difficult to obtain or model. We present a novel reinforcement learning (RL) method for continuous state and action spaces that learns with partial knowledge of the system and without active exploration. It solves linearly-solvable Markov decision processes (L-MDPs), which are well suited for continuous state and action spaces, based on an actor-critic architecture. Compared to previous RL methods for L-MDPs and path integral methods which are model based, the actor-critic learning does not need a model of the uncontrolled dynamics and, importantly, transition noise levels; however, it requires knowing the control dynamics for the problem. We evaluate our method on two synthetic test problems, and one real-world problem in simulation and using real traffic data. Our experiments demonstrate improved learning and policy performance.",
            "output": [
                "Actor-Critic for Linearly-Solvable Continuous MDP with Partially Known Dynamics"
            ]
        },
        {
            "id": "task1540-6843132fe1bc4d8ba815d0b7a07e380d",
            "input": "This paper proposes to use probabilistic model checking to synthesize optimal robot policies in multi-tasking autonomous systems that are subject to human-robot interaction. Given the convincing empirical evidence that human behavior can be related to reinforcement models, we take as input a well-studied Q-table model of the human behavior for flexible scenarios. We first describe an automated procedure to distill a Markov decision process (MDP) for the human in an arbitrary but fixed scenario. The distinctive issue is that – in contrast to existing models – under-specification of the human behavior is included. Probabilistic model checking is used to predict the human’s behavior. Finally, the MDP model is extended with a robot model. Optimal robot policies are synthesized by analyzing the resulting two-player stochastic game. Experimental results with a prototypical implementation using PRISM show promising results.",
            "output": [
                "Probabilistic Model Checking for Complex Cognitive Tasks"
            ]
        },
        {
            "id": "task1540-7d100c3627184b499663dd218b77f389",
            "input": "Multilabel classification is a relatively recent subfield of machine learning. Unlike to the classical approach, where instances are labeled with only one category, in multilabel classification, an arbitrary number of categories is chosen to label an instance. Due to the problem complexity (the solution is one among an exponential number of alternatives), a very common solution (the binary method) is frequently used, learning a binary classifier for every category, and combining them all afterwards. The assumption taken in this solution is not realistic, and in this work we give examples where the decisions for all the labels are not taken independently, and thus, a supervised approach should learn those existing relationships among categories to make a better classification. Therefore, we show here a generic methodology that can improve the results obtained by a set of independent probabilistic binary classifiers, by using a combination procedure with a classifier trained on the co-occurrences of the labels. We show an exhaustive experimentation in three different standard corpora of labeled documents (Reuters-21578, Ohsumed-23 and RCV1), which present noticeable improvements in all of them, when using our methodology, in three probabilistic base classifiers.",
            "output": [
                "A probabilistic methodology for multilabel classification"
            ]
        },
        {
            "id": "task1540-b50d8b468ef8482681fe921192f64df6",
            "input": "Nearest neighbor methods are a popular class of nonparametric estimators with several<lb>desirable properties, such as adaptivity to different distance scales in different regions of<lb>space. Prior work on convergence rates for nearest neighbor classification has not fully<lb>reflected these subtle properties. We analyze the behavior of these estimators in metric<lb>spaces and provide finite-sample, distribution-dependent rates of convergence under min-<lb>imal assumptions. As a by-product, we are able to establish the universal consistency of<lb>nearest neighbor in a broader range of data spaces than was previously known. We illus-<lb>trate our upper and lower bounds by introducing smoothness classes that are customized<lb>for nearest neighbor classification.",
            "output": [
                "Rates of Convergence for Nearest Neighbor Classification"
            ]
        },
        {
            "id": "task1540-d694c8f0a7ef4aa28ed3c72b52b3e076",
            "input": "We analyze the structure of the state space of chess by means of transition path sampling Monte Carlo simulation. Based on the typical number of moves required to transpose a given configuration of chess pieces into another, we conclude that the state space consists of several pockets between which transitions are rare. Skilled players explore an even smaller subset of positions that populate some of these pockets only very sparsely. These results suggest that the usual measures to estimate both, the size of the state space and the size of the tree of legal moves, are not unique indicators of the complexity of the game, but that topological considerations are equally important. Chess is a two-player board game with a small set of rules according to which pieces can be moved. It belongs to the class of games with perfect information that have not been solved yet, due to the sheer size of its state space. The computerized analysis of chess started with a seminal paper by Claude Shannon in 1950 [1], and since about the year 2000 computer programs can regularly beat top-level human players [2]. They do so by employing well-tailored heuristic evaluation functions for the game’s states, which allow one to short-cut the exploration of the vast game tree of possible moves. In this context, chess is often compared to Go, where computers only very recently started to match the performance of human champions [3]. The difference is usually attributed to the different sizes of the games’ state spaces: the game-tree complexity of Go exceeds that of chess by some 200 orders of magnitude. However, while size is an important factor in determining the complexity of a game, the topology of the state space may be equally important. Intuitively, the different kinds of moves performed by different chess pieces impose a highly nontrivial (and directed) topology. It is not at all straightforward to establish whether a given point in the state space is reachable from another one by a sequence of legal moves. We thus face an interesting sampling problem: given two chess configurations, can one establish whether they are connected, i.e., whether there exists a sequence of legal moves that transforms the first configuration into the second? Furthermore, what is the typical distance (in plies, or half moves) between such configurations? Clearly, direct enumeration or standard Monte Carlo sampling are out of reach: after each ply, the game tree is estimated to branch into 30 to 35 subtrees [1]. Here we demonstrate that it is possible to analyze the topological structure of the state space of chess by stochastic-process rare-event sampling (SPRES) [4]. SPRES is a transition-path Monte Carlo sampling scheme that works in full non-equilibrium conditions, where the dynamics is neither stationary nor reversible. 1 Combining SPRES with an optimized chess-move generator [5], we estimate the distribution of path lengths between both randomly generated configurations and those encountered in games played by humans. Analyzing these distributions in terms of random-graph theory, we conjecture that the state space of chess consists of multiple distinct pockets, interconnected by relatively few paths. These pockets are only very sparsely populated by the states that are relevant for skilled play. Previous statistical-physics analyses of chess have focused mostly on the distribution of moves in human gameplay, or on games played by computer chess engines. For example, the popularity of opening sequences follows a power-law distribution according to Zipf’s law [6] (in this 1Our analysis of chess also serves to demonstrate the versatility and power of SPRES as a technique that applies to abstract nonphysical dynamics. p-1 ar X iv :1 60 9. 04 64 8v 1 [ cs .A I] 1 4 Se p 20 16 A. Atashpendar, T. Schilling, and Th. Voigtmann context, Go is rather similar [7]), highly biased by the skill of the players involved [8, 9]. Optimal play (in the sense that moves are evaluated favorably by modern computer chess engines) has also been analyzed in the language of free-energy landscapes [10]. Our approach is entirely different: we consider the set of all legal moves, irrespective of their engine evaluation, in order to establish the connectivity of the state space of chess. Within this space, we then also study the relative size and structure of the subset of positions encountered in games played by chess masters. The state of a chess game at any point in time is entirely described by the board configuration (the positions of all chess pieces), a small set of additional variables that track the possibility of special moves (castling or en-passant capture) and the information regarding which player’s turn it is. The set of possible states is given by all states that involve up to 16 chess pieces per color (there may be fewer due to captures, and the number of pieces and pawns may change due to pawn promotions). Only a subset of all possible states is legal, as for example, the two kings cannot be in check at the same time. Of interest in the following are states that are legal and also accessible from the given initial configuration. As an example of an inaccessible but legal state, consider the case where the position of a bishop differs from its initial position, while the positions of the pawns do not. This state is inaccessible, because pawns are initially placed in front of the other pieces of their colour, their moves are always irreversible and the other pieces (apart from the knights) cannot jump over the pawns. Thus, although the state is legal, it cannot be reached by legal moves. To sample the structure of the state space, we generate sequences of accessible states by randomly drawing moves evenly from all legal moves (Monte Carlo, MC). Most of these states entail dramatic disadvantages for at least one side. Therefore, the set of states encountered in optimalstrategy play is vastly smaller than the set we sample. As a proxy to these unknown optimal states, we use database (DB) states extracted from a database of about two million human-played games [11]. In both cases (MC and DB), we then pick pairs of states randomly and establish their connectivity with respect to the game tree by all legal (MC) moves, i.e., irrespective of whether the connecting pathway contains unfavorable positions in terms of gameplay. In the vicinity of the starting configuration, many randomly drawn pairs of positions are necessarily disconnected, since pawns only move forward and many of the pieces still have to gain freedom to move. At the other end of the game, mating positions act as absorbing states. And in addition, the MC dynamics has a set of absorbing states where only the kings are left on the board. In order to sample states that reflect the intrinsic topology of the state space, we thus restrict the discussion to pairs of states drawn from a depth between 5 and 50 plies into the game. This corresponds loosely to chess players’ notion of the middle game. Inside this window, we did not find an obvious correlation between the ply-depth from which a pair of states was drawn and the separation between them. We sample the pathways between states by means of SPRES [4]. In this method, interfaces in state space are defined by constant values of a scalar reaction coordinate, which quantifies the progress made from one state to the other. Then adaptive sampling of dynamic pathways is carried out such that a constant number of forward transitions between these interfaces is obtained. Once the sampling is completed, observables can be averaged over the ensemble of sampled pathways. In the case of chess, we are in particular interested in the length (number of plies) of the shortest path between two configurations. While the choice of an optimal reaction coordinate is a topic in its own right [10], we make use of the fact that SPRES will sample paths faithfully even for non-optimal choices [4]. As the reaction coordinate, we chose a Euclidean geometric measure of distance from the target configuration. For each piece, the geometric distance is calculated using a metric that is adapted to the type of moves performed by that piece: Chebyshev metric for queens, kings, and bishops, the ceil of half the Chebyshev distance for knights, the Manhattan distance for rooks, and the rank separation for pawns. (For details, see Ref. [5]). Pairs are discarded as disconnected if they are farther apart than 120 plies; this approximation is adapted to the typical length of real chess games. Trivially disconnected pairs are discarded by an initial test based on the reaction coordinate, the pawn structure and the piece count. For the estimation of path lengths, 4000 (3000) pairs generated from MC (DB) that have passed this test have been sampled. Figure 1 shows the histogram of path lengths between those randomly chosen pairs that are connected according to SPRES (corresponding to 79% of all randomly drawn MC pairs and 85% of all pairs drawn from the DB). For pairs generated via MC, the path-length distribution has two distinct contributions, one with a peak at `1 ≈ 20 plies, and a smaller one at `2 ≈ 45 plies. The path-length distribution between pairs sampled from the database is biased to smaller path lengths and has only one prominent peak at a path length slightly below `1, `1 ≈ 18 plies. A tail towards large distances is still seen as a remnant of the second peak found in the MC distribution. Note that the paths found by SPRES for the DB pairs almost certainly pass through non-DB states (i.e. states that are usually not found in games played by humans). A typical engine evaluation function (Stockfish [13]) displays huge fluctuations along the SPRES paths, indicating that these paths will probably never be chosen by skilled human players. The results shown in Fig. 1 reveal that real chess games take place in a subspace that is much more tightly connected than the space of accessible states. The doublepeaked histogram suggests a “blob” structure (see sketch",
            "output": [
                "epl draft Sequencing Chess"
            ]
        },
        {
            "id": "task1540-41bbeb6cd54b48d98dcf73d795c3befc",
            "input": "We propose a structured prediction architecture for images centered around deep recurrent neural networks. The proposed network, called ReSeg, is based on the recently introduced ReNet model for object classification. We modify and extend it to perform object segmentation, noting that the avoidance of pooling can greatly simplify pixel-wise tasks for images. The ReSeg layer is composed of four recurrent neural networks that sweep the image horizontally and vertically in both directions, along with a final layer that expands the prediction back to the original image size. ReSeg combines multiple ReSeg layers with several possible input layers as well as a final layer which expands the prediction back to the original image size, making it suitable for a variety of structured prediction tasks. We evaluate ReSeg on the specific task of object segmentation with three widely-used image segmentation datasets, namely Weizmann Horse, Fashionista and Oxford Flower. The results suggest that ReSeg can challenge the state of the art in object segmentation, and may have further applications in structured prediction at large.",
            "output": [
                "RESEG: A RECURRENT NEURAL NETWORK FOR OBJECT SEGMENTATION"
            ]
        },
        {
            "id": "task1540-6543fa794fe84368bdc1a309765b153b",
            "input": "Artificial neural networks are powerful pattern classifiers; however, they have been surpassed in accuracy by methods such as support vector machines and random forests that are also easier to use and faster to train. Backpropagation, which is used to train artificial neural networks, suffers from the herd effect problem which leads to long training times and limit classification accuracy. We use the disjunctive normal form and approximate the boolean conjunction operations with products to construct a novel network architecture. The proposed model can be trained by minimizing an error function and it allows an effective and intuitive initialization which solves the herdeffect problem associated with backpropagation. This leads to state-of-the art classification accuracy and fast training times. In addition, our model can be jointly optimized with convolutional features in an unified structure leading to state-of-the-art results on computer vision problems with fast convergence rates. A GPU implementation of LDNN with optional convolutional features is also available",
            "output": [
                "Disjunctive Normal Networks"
            ]
        },
        {
            "id": "task1540-0e937c59770c492689628ef6d4db4117",
            "input": "We propose a new training method for a feedforward neural network having the activation functions with the geometric contraction property. The method consists of constructing a new functional that is less nonlinear in comparison with the classical functional by removing the nonlinearity of the activation functions from the output layer. We validate this new method by a series of experiments that show an improved learning speed and also a better classification error. MSC: 92B20, 68T05",
            "output": [
                "A New Training Method for Feedforward Neural Networks Based on Geometric Contraction Property of Activation Functions"
            ]
        },
        {
            "id": "task1540-39209dad3a0b426992c84e1f0969555c",
            "input": "First-order factoid question answering assumes that the question can be answered by a single fact in a knowledge base (KB). While this does not seem like a challenging task, many recent attempts that apply either complex linguistic reasoning or deep neural networks achieve 35%–65% accuracy on benchmark sets. Our approach formulates the task as two machine learning problems: detecting the entities in the question, and classifying the question as one of the relation types in the KB. Based on this assumption of the structure, our simple yet effective approach trains two recurrent neural networks to outperform state of the art by significant margins — relative improvement reaches 16% for WebQuestions, and surpasses 38% for SimpleQuestions.",
            "output": [
                "Simple and Effective Question Answering with Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-199a2932f7854ecd9e66fae49a782817",
            "input": "Natural language generation plays a critical role in any spoken dialogue system. We present a new approach to natural language generation using recurrent neural networks in an encoderdecoder framework. In contrast with previous work, our model uses both lexicalized and delexicalized versions of slot-value pairs for each dialogue act. This allows our model to learn from all available data, rather than being restricted to learning only from delexicalized slot-value pairs. We show that this helps our model generate more natural sentences with better grammar. We further improve our model’s performance by initializing its weights from a pretrained language model. Human evaluation of our best-performing model indicates that it generates sentences which users find more natural and appealing.",
            "output": [
                "Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data"
            ]
        },
        {
            "id": "task1540-609bec9b85a3467c8659c095d91f3ce6",
            "input": "We propose a multi-agent algorithm able to automatically discover relevant regularities in a given dataset, determining at the same time the set of configurations of the adopted parametric dissimilarity measure yielding compact and separated clusters. Each agent operates independently by performing a Markovian random walk on a suitable weighted graph representation of the input dataset. Such a weighted graph representation is induced by the specific parameter configuration of the dissimilarity measure adopted by the agent, which searches and takes decisions autonomously for one cluster at a time. Results show that the algorithm is able to discover parameter configurations Corresponding Author Email addresses: filippo.binachi@ryerson.ca (Filippo Maria Bianchi), enrico.maiorino@uniroma1.it (Enrico Maiorino), llivi@scs.ryerson.ca (Lorenzo Livi), antonello.rizzi@uniroma1.it (Antonello Rizzi), asadeghi@ryerson.ca (Alireza Sadeghian) URL: https://sites.google.com/site/lorenzlivi/ (Lorenzo Livi), http://infocom.uniroma1.it/~rizzi/ (Antonello Rizzi), http://www.scs.ryerson.ca/~asadeghi/ (Alireza Sadeghian) Preprint submitted to Information Sciences September 18, 2014 that yield a consistent and interpretable collection of clusters. Moreover, we demonstrate that our algorithm shows comparable performances with other similar state-of-the-art algorithms when facing specific clustering problems.",
            "output": [
                "An Agent-Based Algorithm exploiting Multiple Local Dissimilarities for Clusters Mining and Knowledge Discovery"
            ]
        },
        {
            "id": "task1540-8825b3e340a642828e6c49ec147392c0",
            "input": "Microsoft Kinect camera and its skeletal tracking capabilities have been embraced by many researchers and commercial developers in various applications of real-time human movement analysis. In this paper, we evaluate the accuracy of the human kinematic motion data in the first and second generation of the Kinect system, and compare the results with an optical motion capture system. We collected motion data in 12 exercises for 10 different subjects and from three different viewpoints. We report on the accuracy of the joint localization and bone length estimation of Kinect skeletons in comparison to the motion capture. We also analyze the distribution of the joint localization offsets by fitting a mixture of Gaussian and uniform distribution models to determine the outliers in the Kinect motion data. Our analysis shows that overall Kinect 2 has more robust and more accurate tracking of human pose as compared to Kinect 1.",
            "output": [
                "Evaluation of Pose Tracking Accuracy in the First and Second Generations of Microsoft Kinect"
            ]
        },
        {
            "id": "task1540-5f70a4964b8d4d0288e0a501ce92f9e6",
            "input": "Multimedia or spoken content presents more attractive information than plain text content, but the former is more difficult to display on a screen and be selected by a user. As a result, accessing large collections of the former is much more difficult and time-consuming than the latter for humans. It’s therefore highly attractive to develop machines which can automatically understand spoken content and summarize the key information for humans to browse over. In this endeavor, a new task of machine comprehension of spoken content was proposed recently. The initial goal was defined as the listening comprehension test of TOEFL, a challenging academic English examination for English learners whose native languages are not English. An Attention-based Multi-hop Recurrent Neural Network (AMRNN) architecture was also proposed for this task, which considered only the sequential relationship within the speech utterances. In this paper, we propose a new Hierarchical Attention Model (HAM), which constructs multi-hopped attention mechanism over tree-structured rather than sequential representations for the utterances. Improved comprehension performance robust with respect to ASR errors were obtained.",
            "output": [
                "HIERARCHICAL ATTENTION MODEL FOR IMPROVED MACHINE COMPREHENSION OF SPOKEN CONTENT"
            ]
        },
        {
            "id": "task1540-7d0eab86934c42e8be08bd5722e031e6",
            "input": "One popular method for dealing with large-scale data sets is sampling. For example, by using the empirical statistical leverage scores as an importance sampling distribution, the method of algorithmic leveraging samples and rescales rows/columns of data matrices to reduce the data size before performing computations on the subproblem. This method has been successful in improving computational efficiency of algorithms for matrix problems such as least-squares approximation, least absolute deviations approximation, and low-rank matrix approximation. Existing work has focused on algorithmic issues such as worst-case running times and numerical issues associated with providing high-quality implementations, but none of it addresses statistical aspects of this method. In this paper, we provide a simple yet effective framework to evaluate the statistical properties of algorithmic leveraging in the context of estimating parameters in a linear regression model with a fixed number of predictors. In particular, for several versions of leverage-based sampling, we derive results for the bias and variance, both conditional and unconditional on the observed data. We show that from the statistical perspective of bias and variance, neither leverage-based sampling nor uniform sampling dominates the other. This result is particularly striking, given the well-known result that, from the algorithmic perspective of worst-case analysis, leverage-based sampling provides uniformly superior worst-case algorithmic results, when compared with uniform sampling. Based on these theoretical results, we propose and analyze two new leveraging algorithms: one constructs a smaller least-squares problem with “shrinked” leverage scores (SLEV), and the other solves a smaller and unweighted (or biased) least-squares problem (LEVUNW). A detailed empirical evaluation of existing leverage-based methods as well as these two new methods is carried out on both synthetic and real data sets. The empirical results indicate that our theory is a good predictor of practical performance of existing and new leverage-based algorithms and that the new algorithms achieve improved performance. For example, with the same computation reduction as in the original algorithmic leveraging approach, our proposed SLEV typically leads to improved biases and variances both unconditionally and conditionally (on the observed data), and our proposed LEVUNW typically yields improved unconditional biases and variances. ∗Department of Statistics, University of Illinois at Urbana-Champaign, Champaign, IL 61820. Email: pingma@illinois.edu. †Department of Mathematics, Stanford University, Stanford, CA 94305. Email: mmahoney@cs.stanford.edu. ‡Department of Statistics, University of California at Berkeley, Berkeley, CA 94720. Email: binyu@stat.berkeley.edu. 1 ar X iv :1 30 6. 53 62 v1 [ st at .M E ] 2 3 Ju n 20 13",
            "output": [
                "A Statistical Perspective on Algorithmic Leveraging"
            ]
        },
        {
            "id": "task1540-10c63994fab04fa8818776c084743a9c",
            "input": "Recent developments show that Multiply Sectioned Bayesian Networks (MSBNs) can be used for diagnosis of natural systems as well as for model-based diagnosis of artificial systems. They can be applied to single-agent oriented reasoning systems as well as multi­ agent distributed reasoning systems. Belief propagation between a pair of subnets plays a central role in maintenance of global consistency in a MSBN. This paper studies the operation UpdateBelief, presented orig­ inally with MSBNs, for inter-subnet propaga­ tion. We analyze how the operation achieves its intended functionality, which provides hints for improving its efficiency. New versions of UpdateBelief are then de­ fined that reduce the computation time for inter-subnet propagation. One of them is optimal in the sense that the minimum amount of computation for coordinating multi-linkage belief propagation is required. The optimization problem is solved through the solution of a graph-theoretic problem: the minimum weight open tour in a tree.",
            "output": [
                "Optimization of Inter-Subnet Belief Updating in Multiply Sectioned Bayesian Networks"
            ]
        },
        {
            "id": "task1540-0dcbe3e429cf48f4a2e613ee33ddb604",
            "input": "Data quality is fundamentally important to ensure the reliability of data for stakeholders to make decisions. In real world applications, such as scientific exploration of extreme environments, it is unrealistic to require raw data collected to be perfect. As data miners, when it is infeasible to physically know the why and the how in order to clean up the data, we propose to seek the intrinsic structure of the signal to identify the common factors of multivariate data. Using our new data-driven learning method—the common-factor data cleaning approach, we address an interdisciplinary challenge on multivariate data cleaning when complex external impacts appear to interfere with multiple data measurements. Existing data analyses typically process one signal measurement at a time without considering the associations among all signals. We analyze all signal measurements simultaneously to find the hidden common factors that drive all measurements to vary together, but not as a result of the true data measurements. We use common factors to reduce the variations in the data without changing the base mean level of the data to avoid altering the physical meaning. We have reanalyzed the NASA Mars Phoenix mission data used in the leading effort by Kounaves’s team (lead scientist for the wet chemistry experiment on the Phoenix) [1, 2] with our proposed method to show the resulting differences. We demonstrate that this new common-factor method successfully helps reducing systematic noises without definitive understanding of the source and without degrading the physical meaning of the signal.",
            "output": [
                "A Common-Factor Approach for Multivariate Data Cleaning with an Application to Mars Phoenix Mission Data"
            ]
        },
        {
            "id": "task1540-d161509d5dcb41a6a73f55e2c995593f",
            "input": "We present a method for learning treewidthbounded Bayesian networks from data sets containing thousands of variables. Bounding the treewidth of a Bayesian greatly reduces the complexity of inferences. Yet, being a global property of the graph, it considerably increases the difficulty of the learning process. We propose a novel algorithm for this task, able to scale to large domains and large treewidths. Our novel approach consistently outperforms the state of the art on data sets with up to ten thousand variables.",
            "output": [
                "Learning Bounded Treewidth Bayesian Networks with Thousands of Variables"
            ]
        },
        {
            "id": "task1540-0be4b9fe39bd424d9f1401aa371df0a6",
            "input": "This paper describes a novel approach to learning term-weighting schemes (TWSs) in the context of text classification. In text mining a TWS determines the way in which documents will be represented in a vector space model, before applying a classifier. Whereas acceptable performance has been obtained with standard TWSs (e.g., Boolean and term-frequency schemes), the definition of TWSs has been traditionally an art. Further, it is still a difficult task to determine what is the best TWS for a particular problem and it is not clear yet, whether better schemes, than those currently available, can be generated by combining known TWS. We propose in this article a genetic program that aims at learning effective TWSs that can improve the performance of current schemes in text classification. The genetic program learns how to combine a set of basic units to give rise to discriminative TWSs. We report an extensive experimental study comprising data sets from thematic and non-thematic text classification as well as from image classification. Our study shows the validity of the proposed method; in fact, we show that TWSs learned with the genetic program outperform traditional schemes and other Corresponding author. Email addresses: hugojair@inaoep.mx (Hugo Jair Escalante), mauricio.garcia.cs@gmail.com (Mauricio A. Garćıa-Limón), a.morales@inaoep.mx (Alicia Morales-Reyes), mgraffg@gmail.com (Mario Graff), mmontesg@inaoep.mx (Manuel Montes-y-Gómez), emorales@inaoep.mx (Eduardo F. Morales) Preprint submitted to Elsevier October 8, 2014 TWSs proposed in recent works. Further, we show that TWSs learned from a specific domain can be effectively used for other tasks.",
            "output": [
                "Term-Weighting Learning via Genetic Programming for Text Classification"
            ]
        },
        {
            "id": "task1540-c995f0f775c44f7a969880335fbdd19b",
            "input": "The paper describes the refinement algorithm for the Calculus of (Co)Inductive Constructions (CIC) implemented in the interactive theorem prover Matita. The refinement algorithm is in charge of giving a meaning to the terms, types and proof terms directly written by the user or generated by using tactics, decision procedures or general automation. The terms are written in an “external syntax” meant to be user friendly that allows omission of information, untyped binders and a certain liberal use of user defined sub-typing. The refiner modifies the terms to obtain related well typed terms in the internal syntax understood by the kernel of the ITP. In particular, it acts as a type inference algorithm when all the binders are untyped. The proposed algorithm is bi-directional: given a term in external syntax and a type expected for the term, it propagates as much typing information as possible towards the leaves of the term. Traditional mono-directional algorithms, instead, proceed in a bottomup way by inferring the type of a sub-term and comparing (unifying) it with the type expected by its context only at the end. We propose some novel bi-directional rules for CIC that are particularly effective. Among the benefits of bi-directionality we have better error message reporting and better inference of dependent types. Moreover, thanks to bi-directionality, the coercion system for sub-typing is more effective and type inference generates simpler unification problems that are more likely to be solved by the inherently incomplete higher order unification algorithms implemented. Finally we introduce in the external syntax the notion of vector of placeholders that enables to omit at once an arbitrary number of arguments. Vectors of placeholders allow a trivial implementation of implicit arguments and greatly simplify the implementation of primitive and simple tactics. 1998 ACM Subject Classification: D.3.1, F.3.0.",
            "output": [
                "A BI-DIRECTIONAL REFINEMENT ALGORITHM FOR THE CALCULUS OF (CO)INDUCTIVE CONSTRUCTIONS"
            ]
        },
        {
            "id": "task1540-74be15d16a1f407cb3581d9c882e24cf",
            "input": "Global optimization of the energy consumption of dual power source vehicles such as hybrid electric vehicles, plugin hybrid electric vehicles, and plug in fuel cell electric vehicles requires knowledge of the complete route characteristics at the beginning of the trip. One of the main characteristics is the vehicle speed profile across the route. The profile will translate directly into energy requirements for a given vehicle. However, the vehicle speed that a given driver chooses will vary from driver to driver and from time to time, and may be slower, equal to, or faster than the average traffic flow. If the specific driver speed profile can be predicted, the energy usage can be optimized across the route chosen. The purpose of this paper is to research the application of Deep Learning techniques to this problem to identify at the beginning of a drive cycle the driver specific vehicle speed profile for an individual driver repeated drive cycle, which can be used in an optimization algorithm to minimize the amount of fossil fuel energy used during the trip. Keywords—Deep Learning, Stacked Auto Encoders, Neural Networks, Traffic Prediction",
            "output": [
                "Vehicle Speed Prediction using Deep Learning"
            ]
        },
        {
            "id": "task1540-37dafd8efcc74dcca7330b6a316e25ff",
            "input": "In earlier work, we introduced flexible infer­ ence and decision-theoretic metareasoning to address the intractability of normative infer­ ence. Here, rather than pursuing the task of computing beliefs and actions with decision models composed of distinctions about uncer­ tain events, we examine methods for inferring beliefs about mathematical truth before an automated theorem prover completes a proof. We employ a Bayesian analysis to update be­ lief in truth, given theorem-proving progress, and show how decision-theoretic methods can be used to determine the value of continuing to deliberate versus taking immediate action in time-critical situations.",
            "output": [
                "Studies of Theorem Proving under Limited Resources"
            ]
        },
        {
            "id": "task1540-988ac8f85a374986a79266741e52daff",
            "input": "Characterizing relationships between people is fundamental for the understanding of narratives. In this work, we address the problem of inferring the polarity of relationships between people in narrative summaries. We formulate the problem as a joint structured prediction for each narrative, and present a model that combines evidence from linguistic and semantic features, as well as features based on the structure of the social community in the text. We also provide a clustering-based approach that can exploit regularities in narrative types. e.g., learn an affinity for love-triangles in romantic stories. On a dataset of movie summaries from Wikipedia, our structured models provide more than a 30% errorreduction over a competitive baseline that considers pairs of characters in isolation.",
            "output": [
                "Inferring Interpersonal Relations in Narrative Summarie"
            ]
        },
        {
            "id": "task1540-e8e446ef2ee444b8a5b58cb9aa912b07",
            "input": "Real estate appraisal, which is the process of estimating the price for real estate properties, is crucial for both buys and sellers as the basis for negotiation and transaction. Traditionally, the repeat sales model has been widely adopted to estimate real estate price. However, it depends the design and calculation of a complex economic related index, which is challenging to estimate accurately. Today, real estate brokers provide easy access to detailed online information on real estate properties to their clients. We are interested in estimating the real estate price from these large amounts of easily accessed data. In particular, we analyze the prediction power of online house pictures, which is one of the key factors for online users to make a potential visiting decision. The development of robust computer vision algorithms makes the analysis of visual content possible. In this work, we employ a Recurrent Neural Network (RNN) to predict real estate price using the state-of-the-art visual features. The experimental results indicate that our model outperforms several of other state-of-the-art baseline algorithms in terms of both mean absolute error (MAE) and mean absolute percentage error (MAPE).",
            "output": [
                "Image Based Appraisal of Real Estate Properties"
            ]
        },
        {
            "id": "task1540-dc3ab99fe8e946dd990a208f35a59519",
            "input": "We measured entropy and symbolic diversity for English and Spanish texts including literature Nobel laureates and other famous authors. Entropy, symbol diversity and symbol frequency profiles were compared for these four groups. We also built a scale sensitive to the quality of writing and evaluated its relationship with the Flesch ́s readability index for English and the Szigriszt ́s perspicuity index for Spanish. Results suggest a correlation between entropy and word diversity with quality of writing. Text genre also influences the resulting entropy and diversity of the text. Results suggest the plausibility of automated quality assessment of texts.",
            "output": [
                "Quantifying literature quality using complexity criteria"
            ]
        },
        {
            "id": "task1540-2e5991a9f4f9434388635d5590599ce7",
            "input": "Training recurrent neural networks to model long term dependencies is difficult. Hence, we propose to use external linguistic knowledge as an explicit signal to inform the model which memories it should utilize. Specifically, external knowledge is used to augment a sequence with typed edges between arbitrarily distant elements, and the resulting graph is decomposed into directed acyclic subgraphs. We introduce a model that encodes such graphs as explicit memory in recurrent neural networks, and use it to model coreference relations in text. We apply our model to several text comprehension tasks and achieve new state-of-the-art results on all considered benchmarks, including CNN, bAbi, and LAMBADA. On the bAbi QA tasks, our model solves 15 out of the 20 tasks with only 1000 training examples per task. Analysis of the learned representations further demonstrates the ability of our model to encode fine-grained entity information across a document.",
            "output": [
                "Linguistic Knowledge as Memory for Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-d38c7ec9f215480083d287e57ebd88d5",
            "input": "Variational autoencoders (VAE) are directed generative models that learn factorial latent variables. As noted by Burda et al. (2015), these models exhibit the problem of factor overpruning where a significant number of stochastic factors fail to learn anything and become inactive. This can limit their modeling power and their ability to learn diverse and meaningful latent representations. In this paper, we evaluate several methods to address this problem and propose a more effective model-based approach called the epitomic variational autoencoder (eVAE). The so-called epitomes of this model are groups of mutually exclusive latent factors that compete to explain the data. This approach helps prevent inactive units since each group is pressured to explain the data. We compare the approaches with qualitative and quantitative results on MNIST and TFD datasets. Our results show that eVAE makes efficient use of model capacity and generalizes better than VAE.",
            "output": [
                "Tackling Over-pruning in Variational Autoencoders"
            ]
        },
        {
            "id": "task1540-f3243e0a5d6d4f1c9b1272e8d003e78d",
            "input": "Expert systems prove to be suitable replacement for human experts when human experts are unavailable for different reasons. Various expert system has been developed for wide range of application. Although some expert systems in the field of fishery and aquaculture has been developed but a system that aids user in process of selecting a new addition to their aquarium tank never been designed. This paper proposed an expert system that suggests new addition to an aquarium tank based on current environmental condition of aquarium and currently existing fishes in aquarium. The system suggest the best fit for aquarium condition and most compatible to other",
            "output": [
                "An expert system for recommending suitable ornamental fish addition to an aquarium based on aquarium condition"
            ]
        },
        {
            "id": "task1540-33edde1ddfdf44698d7893261e15777f",
            "input": "Real life data often includes information from different channels. For example, in computer vision, we can describe an image using different image features, such as pixel intensity, color, HOG, GIST feature, SIFT features, etc.. These different aspects of the same objects are often called multi-view (or multi-modal) data. Lowrank regression model has been proved to be an effective learning mechanism by exploring the low-rank structure of real life data. But previous low-rank regression model only works on single view data. In this paper, we propose a multi-view low-rank regression model by imposing low-rank constraints on multi-view regression model. Most importantly, we provide a closed-form solution to the multi-view low-rank regression model. Extensive experiments on 4 multi-view datasets show that the multi-view low-rank regression model outperforms single-view regression model and reveals that multiview low-rank structure is very helpful. Introduction In many tasks, a single object can be described using information from different channels (or views). For example, a 3-D object can be described using pictures from different angles; a website can be described using the words it contains, and the hyperlinks it contains; an image can be described using different features, such as SIFT feature, and HOG feature; in daily life, a person can be characterized using age, height, weight and so on. These data all comes from different aspects and channels. Multi-view problems aim to improve existing single view model by learning a model utilizing data collected from multiple channels (Rüping and Scheffer 2005) (de Sa 2005) (Zhou and Burges 2007). Low-rank regression model has been proved to be an effective learning mechanism by exploring the low-rank structure of real life data (Xiang et al. 2012) (Evgeniou and Pontil 2007) (Cai et al. 2013). Existing regression models only work on single view data. To be specific, linear regression finds a linear model with respect to the single view feature data to fit target class data (Seber and Lee 2012). Let matrix B ∈ <p×c be the parameter of the linear model. Linear regression solves a problem of minB ||Y − XB||F , where Copyright c © 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. X = [x1,x2, ...,xn] ∈ <p×n is the single view feature data matrix and Y ∈ <n×c is the target class indicator matrix. Ridge regression can achieve better results by adding a Frobenius norm based regularization on linear regression loss objective (Hoerl and Kennard 1970) (Marquaridt 1970). Ridge regression solves the problem minB ||Y −XB||F + λ||B||F , where λ is the regularization weight parameter. Cai (Cai et al. 2013) showed that whenB is low-rank, regression is equivalent to linear discriminant analysis based regressions. However, all these work only works for single-view problems. In this paper, we propose a multi-view low-rank regression model by imposing low-rank constraints on regression model. This model can be solved using closed-form solution directly. In linear regression, low rank parameter matrix B is dependent on view ν. Through theoretical analysis, we show that multi-view low-rank regression model is equivalent to do regression in the subspace of each view. In other words, let B = AνB, and it is equivalent to find the shared regression parameter matrix B under the subspace transformation Aν with respect to view ν. Extensive experiments performed on 4 multi-view datasets show that the proposed model outperforms single-view regression model and reveals that low-rank structure can improve the classification result of a full-rank model. Notations. In this paper, matrices are written in uppercase letters, such as X, Y . Vectors are written in bold lower case letters, such as x, y. Tr(X) means the trace operation for matrix X . Multi-view Low Rank Regression Assume that there are v views and c classes, pν is the dimension of view ν, nj is the sample size of the j-th class, and n is the total sample size. Let Xν = [x1 , ...,x ν n] ∈ <pν×n be the data matrix of view ν, ν = 1, 2, ..., v, and Y = [y1, ...,yc] ∈ <n×c is the normalized class indicator matrix, i.e. Yij = 1/ √ nj if the i-th data point belongs to the j-th class and Yij = 0 otherwise. We try to minimize the residual of low rank regression model in each class and in each view. Loss function of multiProceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence 1973 ar X iv :1 61 0. 04 66 8v 1 [ cs .L G ] 1 4 O ct 2 01 6 view low rank ridge regression can be proposed as in Eq.(1):",
            "output": [
                "A Closed Form Solution to Multi-View Low-Rank Regression"
            ]
        },
        {
            "id": "task1540-b57c496fb00c49cfa6bccee6a8f9574b",
            "input": "In this paper we propose a multi-convex framework for multi-task learning that improves predictions by learning relationships both between tasks and between features. Our framework is a generalization of related methods in multi-task learning, that either learn task relationships, or feature relationships, but not both. We start with a hierarchical Bayesian model, and use the empirical Bayes method to transform the underlying inference problem into a multi-convex optimization problem. We propose a coordinate-wise minimization algorithm that has a closed form solution for each block subproblem. Naively these solutions would be expensive to compute, but by using the theory of doubly stochastic matrices, we are able to reduce the underlying matrix optimization subproblem into a minimum weight perfect matching problem on a complete bipartite graph, and solve it analytically and efficiently. To solve the weight learning subproblem, we propose three different strategies, including a gradient descent method with linear convergence guarantee when the instances are not shared by multiple tasks, and a numerical solution based on Sylvester equation when instances are shared. We demonstrate the efficiency of our method on both synthetic datasets and real-world datasets. Experiments show that the proposed optimization method is orders of magnitude faster than an off-the-shelf projected gradient method, and our model is able to exploit the correlation structures among multiple tasks and features.",
            "output": [
                "Efficient Multi-task Feature and Relationship Learning"
            ]
        },
        {
            "id": "task1540-eadbd28ca3eb4c5ca5679693f6335c79",
            "input": "In this paper we present methods for attacking and defending k-gram statistical analysis techniques that are used, for example, in network traffic analysis and covert channel detection. The main new result is our demonstration of how to use a behavior’s or process’ k-order statistics to build a stochastic process that has those same k-order stationary statistics but possesses different, deliberately designed, (k + 1)order statistics if desired. Such a model realizes a “complexification” of the process or behavior which a defender can use to monitor whether an attacker is shaping the behavior. By deliberately introducing designed (k + 1)-order behaviors, the defender can check to see if those behaviors are present in the data. We also develop constructs for source codes that respect the k-order statistics of a process while encoding covert information. One fundamental consequence of these results is that certain types of behavior analyses techniques come down to an arms race in the sense that the advantage goes to the party that has more computing resources applied to the problem. Points of view in this document are those of the authors and do not necessarily represent the official position of the sponsoring agencies or the U.S. Government. V. Crespi is with the Department of Computer Science, California State University at Los Angeles, Los Angeles CA, 90032 USA. email: vcrespi@calstatela.edu. Crespi’s work was partially supported by AFOSR Grant FA9550-07-1-0421 and by NSF Grant HRD-0932421. G. Cybenko is with the Thayer School of Engineering, Dartmouth College, Hanover NH 03755. email: gvc@dartmouth.edu. Cybenko’s work was partially supported by Air Force Research Laboratory contracts FA8750-10-1-0045, FA8750-09-1-0174, AFOSR contract FA9550-07-1-0421, U.S. Department of Homeland Security Grant 2006-CS-001-000001 and DARPA Contract HR001-06-1-0033 A. Giani is with the Department of EECS, University of California at Berkeley, Berkeley CA 94720. email: agiani@eecs.berkeley.edu. Giani’s’s work was partially supported by U.S. Department of Homeland Security Grant 2006-CS001-000001 and DARPA Contract HR001-06-1-0033 when she was a Ph.D. student at Dartmouth April 28, 2011 DRAFT ar X iv :1 10 4. 50 71 v1 [ cs .L G ] 2 7 A pr 2 01 1 CRESPI, CYBENKO, GIANI 2",
            "output": [
                "Attacking and Defending Covert Channels and Behavioral Models"
            ]
        },
        {
            "id": "task1540-50f464a92fbe4340905c22d9e370442d",
            "input": "Ontologies usually suffer from the semantic heterogeneity when simultaneously used in information sharing, merging, integrating and querying processes. Therefore, the similarity identification between ontologies being used becomes a mandatory task for all these processes to handle the problem of semantic heterogeneity. In this paper, we propose an efficient technique for similarity measurement between two ontologies. The proposed technique identifies all candidate pairs of similar concepts without omitting any similar pair. The proposed technique can be used in different types of operations on ontologies such as merging, mapping and aligning. By analyzing its results a reasonable improvement in terms of completeness, correctness and overall quality of the results has been",
            "output": [
                "An Efficient Technique for Similarity Identification between Ontologies"
            ]
        },
        {
            "id": "task1540-85ceee0ee2774ac38d797d75724788ac",
            "input": "Given a point cloud, we consider inferring kinematic models of 3D articulated objects such as boxes for the purpose of manipulating them. While previous work has shown how to extract a planar kinematic model (often represented as a linear chain), such planar models do not apply to 3D objects that are composed of segments often linked to the other segments in cyclic configurations. We present an approach for building a model that captures the relation between the input point cloud features and the object segment as well as the relation between the neighboring object segments. We use a conditional random field that allows us to model the dependencies between different segments of the object. We test our approach on inferring the kinematic structure from partial and noisy point cloud data for a wide variety of boxes including cake boxes, pizza boxes, and cardboard cartons of several sizes. The inferred structure enables our robot to successfully close these boxes by manipulating the flaps.",
            "output": [
                "Inferring 3D Articulated Models for Box Packaging Robot"
            ]
        },
        {
            "id": "task1540-74ae6bad31514d779ef71a3109706ea4",
            "input": "In an online decision problem, one makes decisions often with a pool of decisions’ sequence called experts but without knowledge of the future. After each step, one pays a cost based on the decision and observed rate. One reasonal goal would be to perform as well as the best expert in the pool. The modern and well-known way to attain this goal is the algorithm of exponential weighting. However, recently, another algorithm called follow the perturbed leader is developed and achieved about the same performance. In our work, we first show the properties shared in common by the two algorithms which explain the similarities on the performance. Next we will show that for a specific perturbation, the two algorithms are identical. Finally, we show with some examples that follow-the-leader style algorithms extend naturally to a large class of structured online problems for which the exponential algorithms are inefficient. 1 Online problem setting In an online decision problem, one makes decisions often with a pool of decisions’ sequence called experts but without knowledge of the future. After each step, one pays a cost based on the decision and observed state. As there is no prior knowledge on the accuracy of experts in the pool, one reasonable goal for this general problem would be to perform as well as the best expert in the pool after a number of steps. More precisely, we consider the following mathematical problem: • A set S of experts is given. • The algorithm interacts with an adversary in a series of T steps. • In each step j, the algorithm picks an expert xj ∈ S , and the adversary selects a cost function cj: S → R. The adversary could be adaptive, in that cj may depend on {xi : i < j}. • The algorithm incurs cost , and receives as feedback the value of cj(xj). • Minimize the algorithm’s regret which is defined as difference in expected cost between the algorithm’s sequence of choices and that of best fixed expert in S:",
            "output": [
                "Move from Perturbed scheme to exponential weighting average"
            ]
        },
        {
            "id": "task1540-4bb09ec8796c44b987cf521f60910372",
            "input": "We describe an open-source toolkit for neural machine translation (NMT). The toolkit prioritizes efficiency, modularity, and extensibility with the goal of supporting NMT research into model architectures, feature representations, and source modalities, while maintaining competitive performance and reasonable training requirements. The toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques.",
            "output": [
                "OpenNMT: Open-Source Toolkit for Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-d10f3d02d7c34228887fd386d4fa07ce",
            "input": "Over the past decade humans have experienced exponential growth in the use of online resources, in particular social media and microblogging websites such as Facebook, Twitter, YouTube and also mobile applications such as WhatsApp, Line, etc. Many companies have identified these resources as a rich mine of marketing knowledge. This knowledge provides valuable feedback which allows them to further develop the next generation of their product. In this paper, sentiment analysis of a product is performed by extracting tweets about that product and classifying the tweets showing it as positive and negative sentiment. The authors propose a hybrid approach which combines unsupervised learning in the form of K-means clustering to cluster the tweets and then performing supervised learning methods such as Decision Trees and Support Vector Machines for classification.",
            "output": [
                "Improved Twitter Sentiment Prediction through ‘Cluster-then-Predict Model’"
            ]
        },
        {
            "id": "task1540-55bff21135d840ffa0db7b35de0a5204",
            "input": "Multiplayer Online Battle Arena (MOBA) is one of the most played game genres nowadays. With the increasing growth of this genre, it becomes necessary to develop effective intelligent agents to play alongside or against human players. In this paper we address the problem of agent development for MOBA games. We implement a two-layered architecture agent that handles both navigation and game mechanics. This architecture relies on the use of Influence Maps, a widely used approach for tactical analysis. Several experiments were performed using League of Legends as a testbed, and show promising results in this highly dynamic real-time context.",
            "output": [
                "On the Development of Intelligent Agents for MOBA Games"
            ]
        },
        {
            "id": "task1540-b2d44bcd5ec144f4990869912017343e",
            "input": "We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.",
            "output": [
                "ADADELTA: AN ADAPTIVE LEARNING RATE METHOD"
            ]
        },
        {
            "id": "task1540-9c95662d9e9f460296f7b3e4508c2c67",
            "input": "Multilingual spoken dialogue systems have gained prominence in the recent past necessitating the requirement for a front-end Language Identification (LID) system. Most of the existing LID systems rely on modeling the language discriminative information from low-level acoustic features. Due to the variabilities of speech (speaker and emotional variabilities, etc.), large-scale LID systems developed using low-level acoustic features suffer from a degradation in the performance. In this approach, we have attempted to model the higher level language discriminative phonotactic information for developing an LID system. In this paper, the input speech signal is tokenized to phone sequences by using a language independent phone recognizer. The language discriminative phonotactic information in the obtained phone sequences are modeled using statistical and recurrent neural network based language modeling approaches. As this approach, relies on higher level phonotactical information it is more robust to variabilities of speech. Proposed approach is computationally light weight, highly scalable and it can be used in complement with the existing LID systems.",
            "output": [
                "A LANGUAGE MODEL BASED APPROACH TOWARDS LARGE SCALE AND LIGHTWEIGHT LANGUAGE IDENTIFICATION SYSTEMS"
            ]
        },
        {
            "id": "task1540-4eb5652ba7c34420b0d45754453f27cf",
            "input": "An important editing policy in Wikipedia is to provide citations for added statements in Wikipedia pages, where statements can be arbitrary pieces of text, ranging from a sentence to a paragraph. In many cases citations are either outdated or missing altogether. In this work we address the problem of finding and updating news citations for statements in entity pages. We propose a two-stage supervised approach for this problem. In the first step, we construct a classifier to find out whether statements need a news citation or other kinds of citations (web, book, journal, etc.). In the second step, we develop a news citation algorithm for Wikipedia statements, which recommends appropriate citations from a given news collection. Apart from IR techniques that use the statement to query the news collection, we also formalize three properties of an appropriate citation, namely: (i) the citation should entail the Wikipedia statement, (ii) the statement should be central to the citation, and (iii) the citation should be from an authoritative source. We perform an extensive evaluation of both steps, using 20 million articles from a real-world news collection. Our results are quite promising, and show that we can perform this task with high precision and at scale.",
            "output": [
                "Finding News Citations for Wikipedia"
            ]
        },
        {
            "id": "task1540-00009716d646442ba381a411bcbc163e",
            "input": "The recent adaptation of deep neural networkbased methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks. Nonetheless, progress on task-to-task transfer remains limited. In pursuit of efficient and robust generalization, we introduce the Schema Network, an objectoriented generative physics simulator capable of disentangling multiple causes of events and reasoning backward through causes to achieve goals. The richly structured architecture of the Schema Network can learn the dynamics of an environment directly from data. We compare Schema Networks with Asynchronous Advantage Actor-Critic and Progressive Networks on a suite of Breakout variations, reporting results on training efficiency and zero-shot generalization, consistently demonstrating faster, more robust learning and better transfer. We argue that generalizing from limited data and learning causal relationships are essential abilities on the path toward generally intelligent systems.",
            "output": [
                "Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics"
            ]
        },
        {
            "id": "task1540-596d25db98c347babd20457cbc846a04",
            "input": "Exploiting a priori known structural information lies at the core of many image reconstruction methods that can be stated as inverse problems. The synthesis model, which assumes that images can be decomposed into a linear combination of very few atoms of some dictionary, is now a well established tool for the design of image reconstruction algorithms. An interesting alternative is the analysis model, where the signal is multiplied by an analysis operator and the outcome is assumed to be the sparse. This approach has only recently gained increasing interest. The quality of reconstruction methods based on an analysis model severely depends on the right choice of the suitable operator. In this work, we present an algorithm for learning an analysis operator from training images. Our method is based on an `p-norm minimization on the set of full rank matrices with normalized columns. We carefully introduce the employed conjugate gradient method on manifolds, and explain the underlying geometry of the constraints. Moreover, we compare our approach to state-of-the-art methods for image denoising, inpainting, and single image super-resolution. Our numerical results show competitive performance of our general approach in all presented applications compared to the specialized state-of-the-art techniques.",
            "output": [
                "Analysis Operator Learning and Its Application to Image Reconstruction"
            ]
        },
        {
            "id": "task1540-b835180669914a539e1138c2c6cdf02f",
            "input": "We present two algorithms for exact and ap­ proximate inference in causal networks. The first algorithm, dynamic conditioning, is a re­ finement of cutset conditioning that has lin­ ear complexity on some networks for which cutset conditioning is exponential. The sec­ ond algorithm, B-conditioning, is an algo­ rithm for approximate inference that allows one to trade-off the quality of approxima­ tions with the computation time. We also present some experimental results illustrating the properties of the proposed algorithms.",
            "output": [
                "Conditioning Algorithms for Exact and Approximate Inference in Causal Networks"
            ]
        },
        {
            "id": "task1540-46ff322a0e45486aba4df648da006575",
            "input": "We introduce a model for bidirectional retrieval of images and sentences through a multi-modal embedding of visual and natural language data. Unlike previous models that directly map images or sentences into a common embedding space, our model works on a finer level and embeds fragments of images (objects) and fragments of sentences (typed dependency tree relations) into a common space. In addition to a ranking objective seen in previous work, this allows us to add a new fragment alignment objective that learns to directly associate these fragments across modalities. Extensive experimental evaluation shows that reasoning on both the global level of images and sentences and the finer level of their respective fragments significantly improves performance on image-sentence retrieval tasks. Additionally, our model provides interpretable predictions since the inferred intermodal fragment alignment is explicit.",
            "output": [
                "Deep Fragment Embeddings for Bidirectional Image Sentence Mapping"
            ]
        },
        {
            "id": "task1540-301f43aedc294ee79eeb1f400d102da4",
            "input": "We present an approach to generate novel computer game levels that blend different game concepts in an unsupervised fashion. Our primary contribution is an analogical reasoning process to construct blends between level design models learned from gameplay videos. The models represent probabilistic relationships between elements in the game. An analogical reasoning process maps features between two models to produce blended models that can then generate new level chunks. As a proof-of-concept we train our system on the classic platformer game Super Mario Bros. due to its highlyregarded and well understood level design. We evaluate the extent to which the models represent stylistic level design knowledge and demonstrate the ability of our system to explain levels that were blended by human expert designers.",
            "output": [
                "Learning to Blend Computer Game Levels"
            ]
        },
        {
            "id": "task1540-34e572715e8247f487f7b96db2cb671b",
            "input": "Standard algorithms for finding the short­ est path in a graph require that the cost of a path be additive in edge costs, and typically assume that costs are determinis­ tic. We consider the problem of uncertain edge costs, with potential probabilistic de­ pendencies among the costs. Although these dependencies violate the standard dynamic­ programming decomposition, we identify a weaker stochastic consistency condition that justifies a generalized dynamic-programming approach based on stochastic dominance. We present a revised path-planning algorithm and prove that it produces optimal paths under time-dependent uncertain costs. We test the algorithm by applying it to a model of stochastic bus networks, and present em­ pirical performance results comparing it to some alternatives. Finally, we consider ex­ tensions of these concepts to a more general class of problems of heuristic search under uncertainty.",
            "output": [
                "Path Planning under Time-Dependent Uncertainty"
            ]
        },
        {
            "id": "task1540-f66ac35e629b4e1d87c342ee26d156cb",
            "input": "Given a set of documents from a specific domain (e.g., medical research journals), how do we automatically build a Knowledge Graph (KG) for that domain? Automatic identification of relations and their schemas, i.e., type signature of arguments of relations (e.g., undergo(Patient, Surgery)), is an important first step towards this goal. We refer to this problem as Relation Schema Induction (RSI). In this paper, we propose Schema Induction using Coupled Tensor Factorization (SICTF), a novel tensor factorization method for relation schema induction. SICTF factorizes Open Information Extraction (OpenIE) triples extracted from a domain corpus along with additional side information in a principled way to induce relation schemas. To the best of our knowledge, this is the first application of tensor factorization for the RSI problem. Through extensive experiments on multiple real-world datasets, we find that SICTF is not only more accurate than state-of-the-art baselines, but also significantly faster (about 14x faster).",
            "output": [
                "Relation Schema Induction using Tensor Factorization with Side Information"
            ]
        },
        {
            "id": "task1540-baed412e5e3145ec9df9b64671d8422c",
            "input": "Stance detection, the task of identifying the speaker’s opinion towards a particular target, has attracted the attention of researchers. This paper describes a novel approach for detecting stance in Twitter. We define a set of features in order to consider the context surrounding a target of interest with the final aim of training a model for predicting the stance towards the mentioned targets. In particular, we are interested in investigating political debates in social media. For this reason we evaluated our approach focusing on two targets of the SemEval-2016 Task 6 on Detecting stance in tweets, which are related to the political campaign for the 2016 U.S. presidential elections: Hillary Clinton vs. Donald Trump. For the sake of comparison with the state of the art, we evaluated our model against the dataset released in the SemEval-2016 Task 6 shared task competition. Our results outperform the best ones obtained by participating teams, and show that information about enemies and friends of politicians help in detecting stance towards them.",
            "output": [
                "Friends and Enemies of Clinton and Trump: Using Context for Detecting Stance in Political Tweets"
            ]
        },
        {
            "id": "task1540-2bd54fa4c97744af8978a1d60f94019d",
            "input": "Vast amounts of text on the Web are unstructured and ungrammatical, such as classified ads, auction listings, forum postings, etc. We call such text “posts.” Despite their inconsistent structure and lack of grammar, posts are full of useful information. This paper presents work on semi-automatically building tables of relational information, called “reference sets,” by analyzing such posts directly. Reference sets can be applied to a number of tasks such as ontology maintenance and information extraction. Our reference-set construction method starts with just a small amount of background knowledge, and constructs tuples representing the entities in the posts to form a reference set. We also describe an extension to this approach for the special case where even this small amount of background knowledge is impossible to discover and use. To evaluate the utility of the machineconstructed reference sets, we compare them to manually constructed reference sets in the context of reference-set-based information extraction. Our results show the reference sets constructed by our method outperform manually constructed reference sets. We also compare the reference-set-based extraction approach using the machine-constructed reference set to supervised extraction approaches using generic features. These results demonstrate that using machine-constructed reference sets outperforms the supervised methods, even though the supervised methods require training data.",
            "output": [
                "Constructing Reference Sets from Unstructured, Ungrammatical Text"
            ]
        },
        {
            "id": "task1540-7fcd4b468e674094bf1eb97600589e6e",
            "input": "The recently introduced series of description logics under the common moniker ‘DLLite’ has attracted attention of the description logic and semantic web communities due to the low computational complexity of inference, on the one hand, and the ability to represent conceptual modeling formalisms, on the other. The main aim of this article is to carry out a thorough and systematic investigation of inference in extensions of the original DL-Lite logics along five axes: by (i) adding the Boolean connectives and (ii) number restrictions to concept constructs, (iii) allowing role hierarchies, (iv) allowing role disjointness, symmetry, asymmetry, reflexivity, irreflexivity and transitivity constraints, and (v) adopting or dropping the unique name assumption. We analyze the combined complexity of satisfiability for the resulting logics, as well as the data complexity of instance checking and answering positive existential queries. Our approach is based on embedding DL-Lite logics in suitable fragments of the one-variable first-order logic, which provides useful insights into their properties and, in particular, computational behavior.",
            "output": [
                "The DL-Lite Family and Relations"
            ]
        },
        {
            "id": "task1540-d6131cf9d11a4ab1a4bb941827096a93",
            "input": "In machine translation it is common phenomenon that machine-readable dictionaries and standard parsing rules are not enough to ensure accuracy in parsing and translating English phrases into Korean language, which is revealed in misleading translation results due to consequent structural and semantic ambiguities. This paper aims to suggest a solution to structural and semantic ambiguities due to the idiomaticity and non-grammaticalness of phrases commonly used in English language by applying bilingual phrase database in English-Korean Machine Translation (EKMT). This paper firstly clarifies what the phrase unit in EKMT is based on the definition of the English phrase, secondly clarifies what kind of language unit can be the target of the phrase database for EKMT, thirdly suggests a way to build the phrase database by presenting the format of the phrase database with examples, and finally discusses briefly the method to apply this bilingual phrase database to the EKMT for structural and semantic disambiguation.",
            "output": [
                "Phrase database Approach to structural and semantic disambiguation in English-Korean Machine Translation"
            ]
        },
        {
            "id": "task1540-283f3867f8cb4fad99ca207bedfc60b8",
            "input": "Knowing the largest rate at which data can be sent on an end-to-end path such that the egress rate is equal to the ingress rate with high probability can be very practical when choosing transmission rates in video streaming or selecting peers in peer-to-peer applications. We introduce probabilistic available bandwidth, which is defined in terms of ingress rates and egress rates of traffic on a path, rather than in terms of capacity and utilization of the constituent links of the path like the standard available bandwidth metric. In this paper, we describe a distributed algorithm, based on a probabilistic graphical model and Bayesian active learning, for simultaneously estimating the probabilistic available bandwidth of multiple paths through a network. Our procedure exploits the fact that each packet train provides information not only about the path it traverses, but also about any path that shares a link with the monitored path. Simulations and PlanetLab experiments indicate that this process can dramatically reduce the number of probes required to generate accurate estimates.",
            "output": [
                "Multi-path Probabilistic Available Bandwidth Estimation through Bayesian Active Learning"
            ]
        },
        {
            "id": "task1540-5e43c79ade984fedbda119ff0f3694a6",
            "input": "<lb>We study the best arm identification (Best-1-Arm) problem, which is defined as follows.<lb>We are given n stochastic bandit arms. The ith arm has a reward distribution<lb>Di with an<lb>unknown mean μi. Upon each play of the ith arm, we can get a reward, sampled i.i.d. from<lb>Di. We would like to identify the arm with the largest mean with probability at least 1 − δ,<lb>using as few samples as possible. We provide a nontrivial algorithm for Best-1-Arm, which<lb>improves upon several prior upper bounds on the same problem. We also study an important<lb>special case where there are only two arms, which we call the Sign-ξ problem. We provide a<lb>new lower bound of Sign-ξ, simplifying and significantly extending a classical result by Farrell<lb>in 1964, with a completely new proof. Using the new lower bound for Sign-ξ, we obtain the<lb>first lower bound for Best-1-Arm that goes beyond the classic Mannor-Tsitsiklis lower bound,<lb>by an interesting reduction from Sign-ξ to Best-1-Arm. We propose an interesting conjecture<lb>concerning the optimal sample complexity of Best-1-Arm from the perspective of instance-wise<lb>optimality.",
            "output": [
                "On the Optimal Sample Complexity for Best Arm Identification"
            ]
        },
        {
            "id": "task1540-e7104f7ec7bf40c0b06877264e34f5cf",
            "input": "Automatic text summarization is widely regarded as the highly difficult problem, partially because of the lack of large text summarization data set. Due to the great challenge of constructing the large scale summaries for full text, in this paper, we introduce a large corpus of Chinese short text summarization dataset constructed from the Chinese microblogging website Sina Weibo, which is released to the public1. This corpus consists of over 2 million real Chinese short texts with short summaries given by the author of each text. We also manually tagged the relevance of 10,666 short summaries with their corresponding short texts. Based on the corpus, we introduce recurrent neural network for the summary generation and achieve promising results, which not only shows the usefulness of the proposed corpus for short text summarization research, but also provides a baseline for further research on this topic.",
            "output": [
                "LCSTS: A Large Scale Chinese Short Text Summarization Dataset"
            ]
        },
        {
            "id": "task1540-3101da6051f74ce9870dca95c537f78a",
            "input": "The recently introduced Deep Q-Networks (DQN) algorithm has gained attention as one of the first successful combinations of deep neural networks and reinforcement learning. Its promise was demonstrated in the Arcade Learning Environment (ALE), a challenging framework composed of dozens of Atari 2600 games used to evaluate general competency in AI. It achieved dramatically better results than earlier approaches, showing that its ability to learn good representations is quite robust and general. This paper attempts to understand the principles that underly DQN’s impressive performance and to better contextualize its success. We systematically evaluate the importance of key representational biases encoded by DQN’s network by proposing simple linear representations that make use of these concepts. Incorporating these characteristics, we obtain a computationally practical feature set that achieves competitive performance to DQN in the ALE. Besides offering insight into the strengths and weaknesses of DQN, we provide a generic representation for the ALE, significantly reducing the burden of learning a representation for each game. Moreover, we also provide a simple, reproducible benchmark for the sake of comparison to future work in the ALE.",
            "output": [
                "State of the Art Control of Atari Games Using Shallow Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-5e95e4c53d09454b8f8e5f085aa94c99",
            "input": "Online learning aims to perform nearly as well as the best hypothesis in hindsight. For some hypothesis classes, though, even finding the best hypothesis offline is challenging. In such offline cases, local search techniques are often employed and only local optimality guaranteed. For online decision-making with such hypothesis classes, we introduce local regret, a generalization of regret that aims to perform nearly as well as only nearby hypotheses. We then present a general algorithm to minimize local regret with arbitrary locality graphs. We also show how the graph structure can be exploited to drastically speed learning. These algorithms are then demonstrated on a diverse set of online problems: online disjunct learning, online Max-SAT, and online decision tree learning.",
            "output": [
                "On Local Regret"
            ]
        },
        {
            "id": "task1540-7d4b01a0b13b40a78d2c29496a45b14f",
            "input": "The Schatten-p quasi-norm (0<p<1) is usually used to replace the standard nuclear norm in order to approximate the rank function more accurately. However, existing Schattenp quasi-norm minimization algorithms involve singular value decomposition (SVD) or eigenvalue decomposition (EVD) in each iteration, and thus may become very slow and impractical for large-scale problems. In this paper, we first define two tractable Schatten quasi-norms, i.e., the Frobenius/nuclear hybrid and bi-nuclear quasi-norms, and then prove that they are in essence the Schatten-2/3 and 1/2 quasi-norms, respectively, which lead to the design of very efficient algorithms that only need to update two much smaller factor matrices. We also design two efficient proximal alternating linearized minimization algorithms for solving representative matrix completion problems. Finally, we provide the global convergence and performance guarantees for our algorithms, which have better convergence properties than existing algorithms. Experimental results on synthetic and real-world data show that our algorithms are more accurate than the state-ofthe-art methods, and are orders of magnitude faster. Introduction In recent years, the matrix rank minimization problem arises in a wide range of applications such as matrix completion, robust principal component analysis, low-rank representation, multivariate regression and multi-task learning. To solve such problems, Fazel, Hindi, and Boyd; Candès and Tao; Recht, Fazel, and Parrilo (2001; 2010; 2010) have suggested to relax the rank function by its convex envelope, i.e., the nuclear norm. In fact, the nuclear norm is equivalent to the l1-norm on singular values of a matrix, and thus it promotes a low-rank solution. However, it has been shown in (Fan and Li 2001) that the l1-norm regularization over-penalizes large entries of vectors, and results in a biased solution. By realizing the intimate relationship between them, the nuclear norm penalty also over-penalizes large singular values, that is, it may make the solution deviate from the original solution as the l1-norm does (Nie, Huang, and Ding 2012; Lu et al. 2015). Compared with the nuclear norm, the Schatten-p quasi-norm for 0 < p < 1 makes a closer Copyright c © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. approximation to the rank function. Consequently, the Schatten-p quasi-norm minimization has attracted a great deal of attention in images recovery (Lu and Zhang 2014; Lu et al. 2014), collaborative filtering (Nie et al. 2012; Lu et al. 2015; Mohan and Fazel 2012) and MRI analysis (Majumdar and Ward 2011). In addition, many non-convex surrogate functions of the l0-norm listed in (Lu et al. 2014; Lu et al. 2015) have been extended to approximate the rank function, such as SCAD (Fan and Li 2001) and MCP (Zhang 2010). All non-convex surrogate functions mentioned above for low-rank minimization lead to some non-convex, nonsmooth, even non-Lipschitz optimization problems. Therefore, it is crucial to develop fast and scalable algorithms which are specialized to solve some alternative formulations. So far, Lai, Xu, and Yin (2013) proposed an iterative reweighted lease squares (IRucLq) algorithm to approximate the Schatten-p quasi-norm minimization problem, and proved that the limit point of any convergent subsequence generated by their algorithm is a critical point. Moreover, Lu et al. (2014) proposed an iteratively reweighted nuclear norm (IRNN) algorithm to solve many non-convex surrogate minimization problems. For matrix completion problems, the Schatten-p quasi-norm has been shown to be empirically superior to the nuclear norm (Marjanovic and Solo 2012). In addition, Zhang, Huang, and Zhang (2013) theoretically proved that the Schatten-p quasi-norm minimization with small p requires significantly fewer measurements than the convex nuclear norm minimization. However, all existing algorithms have to be solved iteratively and involve SVD or EVD in each iteration, which incurs high computational cost and is too expensive for solving large-scale problems (Cai and Osher 2013; Liu et al. 2014). In contrast, as an alternative non-convex formulation of the nuclear norm, the bilinear spectral regularization as in (Srebro, Rennie, and Jaakkola 2004; Recht, Fazel, and Parrilo 2010) has been successfully applied in many large-scale applications, e.g., collaborative filtering (Mitra, Sheorey, and Chellappa 2010). As the Schatten-p quasi-norm is equivalent to the lp quasi-norm on singular values of a matrix, it is natural to ask the following question: can we design equivalent matrix factorization forms for the cases of the Schatten quasi-norm, e.g., p = 2/3 or 1/2? In order to answer the above question, in this paper we<lb>first define two tractable Schatten quasi-norms, i.e., the<lb>Frobenius/nuclear hybrid and bi-nuclear quasi-norms. We<lb>then prove that they are in essence the Schatten-2/3 and 1/2<lb>quasi-norms, respectively, for solving whose minimization<lb>we only need to perform SVDs on two much smaller fac-<lb>tor matrices as contrary to the larger ones used in existing<lb>algorithms, e.g., IRNN. Therefore, our method is particu-<lb>larly useful for many “big data” applications that need to<lb>deal with large, high dimensional data with missing values.<lb>To the best of our knowledge, this is the first paper to scale<lb>Schatten quasi-norm solvers to the Netflix dataset. More-<lb>over, we provide the global convergence and recovery per-<lb>formance guarantees for our algorithms. In other words, this<lb>is the best guaranteed convergence for algorithms that solve<lb>such challenging problems. Notations and Background<lb>The Schatten-p norm (0 < p < ∞) of a matrix X ∈ Rm×n<lb>(m ≥ n) is defined as ‖X‖Sp ,<lb>(<lb>n<lb>∑ i=1<lb>σ<lb>i (X)<lb>)1/p",
            "output": [
                "Scalable Algorithms for Tractable Schatten Quasi-Norm Minimization"
            ]
        },
        {
            "id": "task1540-49e5844853614e959d6c4b5856544f8a",
            "input": "We present a sequential model for temporal relation classification between intrasentence events. The key observation is that the overall syntactic structure and compositional meanings of the multi-word context between events are important for distinguishing among fine-grained temporal relations. Specifically, our approach first extracts a sequence of context words that indicates the temporal relation between two events, which well align with the dependency path between two event mentions. The context word sequence, together with a parts-of-speech tag sequence and a dependency relation sequence that are generated corresponding to the word sequence, are then provided as input to bidirectional recurrent neural network (LSTM) models. The neural nets learn compositional syntactic and semantic representations of contexts surrounding the two events and predict the temporal relation between them. Evaluation of the proposed approach on TimeBank corpus shows that sequential modeling is capable of accurately recognizing temporal relations between events, which outperforms a neural net model using various discrete features as input that imitates previous feature based models.",
            "output": [
                "A Sequential Model for Classifying Temporal Relations between Intra-Sentence Events"
            ]
        },
        {
            "id": "task1540-9c88545d245e4baea5ef81fe07d9d7d1",
            "input": "Distant speech recognition is a challenge, particularly due to the corruption of speech signals by reverberation caused by large distances between the speaker and microphone. In order to cope with a wide range of reverberations in real-world situations, we present novel approaches for acoustic modeling including an ensemble of deep neural networks (DNNs) and an ensemble of jointly trained DNNs. First, multiple DNNs are established, each of which corresponds to a different reverberation time 60 (RT60) in a setup step. Also, each model in the ensemble of DNN acoustic models is further jointly trained, including both feature mapping and acoustic modeling, where the feature mapping is designed for the dereverberation as a front-end. In a testing phase, the two most likely DNNs are chosen from the DNN ensemble using maximum a posteriori (MAP) probabilities, computed in an online fashion by using maximum likelihood (ML)-based blind RT60 estimation and then the posterior probability outputs from two DNNs are combined using the ML-based weights as a simple average. Extensive experiments demonstrate that the proposed approach leads to substantial improvements in speech recognition accuracy over the conventional DNN baseline systems under diverse reverberant conditions.",
            "output": [
                "Ensemble of Jointly Trained Deep Neural Network-Based Acoustic Models for Reverberant Speech Recognition"
            ]
        },
        {
            "id": "task1540-2ec91f882ae048d390bb376e1e493c62",
            "input": "Discovering the set of closed frequent patterns is one of the fundamental problems in Data Mining. Recent Constraint Programming (CP) approaches for declarative itemset mining have proven their usefulness and flexibility. But the wide use of reified constraints in current CP approaches raises many difficulties to cope with high dimensional datasets. This paper proposes CLOSEDPATTERN global constraint which does not require any reified constraints nor any extra variables to encode efficiently the Closed Frequent Pattern Mining (CFPM) constraint. CLOSEDPATTERN captures the particular semantics of the CFPM problem in order to ensure a polynomial pruning algorithm ensuring domain consistency. The computational properties of our constraint are analyzed and their practical effectiveness is experimentally evaluated.",
            "output": [
                "A global constraint for closed itemset mining"
            ]
        },
        {
            "id": "task1540-4debc447ce1b4f40ae1fd045329d5c53",
            "input": "In this paper, we propose a context-aware keyword spotting model employing a character-level recurrent neural network (RNN) for spoken term detection in continuous speech. The RNN is end-toend trained with connectionist temporal classification (CTC) to generate the probabilities of character and word-boundary labels. There is no need for the phonetic transcription, senone modeling, or system dictionary in training and testing. Also, keywords can easily be added and modified by editing the text based keyword list without retraining the RNN. Moreover, the unidirectional RNN processes an infinitely long input audio streams without pre-segmentation and keywords are detected with low-latency before the utterance is finished. Experimental results show that the proposed keyword spotter significantly outperforms the deep neural network (DNN) and hidden Markov model (HMM) based keyword-filler model even with less computations.",
            "output": [
                "Online Keyword Spotting with a Character-Level Recurrent Neural Network"
            ]
        },
        {
            "id": "task1540-2964ed3d9d034fcbbd5636caa26b55ff",
            "input": "In many applications spanning from sensor to social networks, transportation systems, gene regulatory networks or big data, the signals of interest are defined over the vertices of a graph. The aim of this paper is to propose a least mean square (LMS) strategy for adaptive estimation of signals defined over graphs. Assuming the graph signal to be band-limited, over a known bandwidth, the method enables reconstruction, with guaranteed performance in terms of mean-square error, and tracking from a limited number of observations over a subset of vertices. A detailed mean square analysis provides the performance of the proposed method, and leads to several insights for designing useful sampling strategies for graph signals. Numerical results validate our theoretical findings, and illustrate the performance of the proposed method. Furthermore, to cope with the case where the bandwidth is not known beforehand, we propose a method that performs a sparse online estimation of the signal support in the (graph) frequency domain, which enables online adaptation of the graph sampling strategy. Finally, we apply the proposed method to build the power spatial density cartography of a given operational region in a cognitive network environment.",
            "output": [
                "Least Mean Squares Estimation of Graph Signals"
            ]
        },
        {
            "id": "task1540-e31e3134dedb4809a6f822646b7e0285",
            "input": "We consider the problem of approximate Bayesian inference in log-supermodular models. These models encompass regular pairwise MRFs with binary variables, but allow to capture highorder interactions, which are intractable for existing approximate inference techniques such as belief propagation, mean field, and variants. We show that a recently proposed variational approach to inference in log-supermodular models –L-FIELD– reduces to the widely-studied minimum norm problem for submodular minimization. This insight allows to leverage powerful existing tools, and hence to solve the variational problem orders of magnitude more efficiently than previously possible. We then provide another natural interpretation of L-FIELD, demonstrating that it exactly minimizes a specific type of Rényi divergence measure. This insight sheds light on the nature of the variational approximations produced by L-FIELD. Furthermore, we show how to perform parallel inference as message passing in a suitable factor graph at a linear convergence rate, without having to sum up over all the configurations of the factor. Finally, we apply our approach to a challenging image segmentation task. Our experiments confirm scalability of our approach, high quality of the marginals, and the benefit of incorporating higher-order potentials.",
            "output": [
                "Scalable Variational Inference in Log-supermodular Models"
            ]
        },
        {
            "id": "task1540-33d54828d4c24fe796c251f125681ae7",
            "input": "We develop novel firstand second-order features for dependency parsing based on the Google Syntactic Ngrams corpus, a collection of subtree counts of parsed sentences from scanned books. We also extend previous work on surface n-gram features from Web1T to the Google Books corpus and from first-order to second-order, comparing and analysing performance over newswire and web treebanks. Surface and syntactic n-grams both produce substantial and complementary gains in parsing accuracy across domains. Our best system combines the two feature sets, achieving up to 0.8% absolute UAS improvements on newswire and 1.4% on web text.",
            "output": [
                "Web-scale Surface and Syntactic n-gram Features for Dependency Parsing"
            ]
        },
        {
            "id": "task1540-51a86805219744779c8ca85079545aaf",
            "input": "Incidents of organized cybercrime are rising because of criminals are reaping high financial rewards while incurring low costs to commit crime. As the digital landscape broadens to accommodate more internet-enabled devices and technologies like social media, more cybercriminals who are not native English speakers are invading cyberspace to cash in on quick exploits. In this paper we evaluate the performance of three machine learning classifiers in detecting 419 scams in a bilingual Nigerian cybercriminal community. We use three popular classifiers in text processing namely: Naïve Bayes, k-nearest neighbors (IBK) and Support Vector Machines (SVM). The preliminary results on a real world dataset reveal the SVM significantly outperforms Naïve Bayes and IBK at 95% confidence level. Keywords-Machine Learning; Bilingual Cybercriminals; 419 Scams;",
            "output": [
                "Evaluating Classifiers in Detecting 419 Scams in Bilingual Cybercriminal Communities"
            ]
        },
        {
            "id": "task1540-d4cc4ae381704a218207b0dcbfa37776",
            "input": "This paper introduces an automated skill acquisition framework in reinforcement learning which involves identifying a hierarchical description of the given task in terms of abstract states and extended actions between abstract states. Identifying such structures present in the task provides ways to simplify and speed up reinforcement learning learning algorithms. These structures also help to generalize such algorithms over multiple tasks without relearning policies from scratch. We use ideas from dynamical systems to find metastable regions in the state space and associate them with abstract states. The spectral clustering algorithm PCCA+ is used to identify suitable abstractions aligned to the underlying structure. Skills are defined in terms of the transitions between such abstract states. The connectivity information from PCCA+ is used to generate these skills or options. The skills are independent of the learning task and can be efficiently reused across a variety of tasks defined over a common state space. Another major advantage of the approach is that it does not need a prior model of the MDP and can work well even when the MDPs are constructed from sampled trajectories. Finally, we present our attempts to extend the automated skills acquisition framework to complex tasks such as learning to play video games where we use deep learning techniques for representation learning to aid our spatio-temporal abstraction framework. Proceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s). 1. Motivation and Introduction The core idea of hierarchical reinforcement learning is to break down the reinforcement learning problem into subtasks through a hierarchy of abstractions. Typically, in the full reinforcement learning problem, the agent is assumed to be in one state of the Markov Decision Process at every time step. The agent then performs one of several possible primitive actions. Based on the agent’s state at time t, and the action it takes from that state, the agent’s state at time t + 1 is determined. For large problems, however, this can lead to too much granularity: when the agent has to decide on each and every primitive action at every granular state, it can often lose sight of the bigger picture. However, if a series of actions can be abstracted out as an abstract action, the agent can just remember the series of actions that was useful in getting it to a temporally distant useful state from the initial state. This is typically referred to as an option or a skill in the reinforcement learning literature. A good analogy is a human planning his movement for a traversal from current location A to a destination B. We identify intermediate destinations Ci to lead us fromA toB when planning fromA, instead of worrying about the exact mechanisms of immediate movement at A which are abstracted over. Options are a convenient way of formalising this abstraction. In keeping with the general philosophy of reinforcement learning, we want to build agents that can automatically discover options with no prior knowledge, purely by exploring the environment. Thus, our approach falls into the broad category of automated discovery of skills. In order to exploit task structure, hierarchical decomposition introduces models defined by stand-alone policies (also known as temporally-extended actions, options, or skills) that can take multiple time steps to execute. Skills can exploit representing structure by representing subroutines that are executed multiple times during execution of a task. Such skills which are learnt in one task can be reused ar X iv :1 60 5. 05 35 9v 1 [ cs .L G ] 1 7 M ay 2 01 6 Submission and Formatting Instructions for ICML 2016 in a different task as long as it requires execution of the same subroutine. Options also make exploration more efficient by providing the decision maker with a high-level behaviour to look ahead to the completion of the corresponding subroutine. Automated discovery of skills or options has been an active area of research and several approaches have been proposed for the same. The current methods could be broadly classified into sample trajectory based and partition based methods. Some of them are: • Identifying bottlenecks in the state space, where the state space is partitioned into sets and the transitions between two sets of states that are rare can be seen as introducing bottleneck sets at the respective points of such rare transitions. Policies to reach such states are cached as options (McGovern & Barto, 2001). • Using the structure present in a factored state representation to identify sequences of actions that cause what are otherwise infrequent changes in the state variables: these sequences are cached away as options (Hengst, 2004). • Obtaining a graphical representation of an agent’s interaction with its environment and using betweenness centrality measures to identify subtasks (Simsek & Barto, 2008). • Using clustering methods (spectral or otherwise) to separate out different strongly connected components of the Markov Decision Process (MDP) and identifying access-states that connect different clusters (Menache et al., 2002). While these methods have had varying amounts of success, they have certain deficiencies. Bottleneck based approaches don’t have a natural way of identifying the part of the state space where options are applicable without external knowledge about the problem domain. Spectral methods need some form of regularization in order to prevent unequal splits that might lead to arbitrary splitting of the state space. We present a framework that detects well-connected or meta stable regions of the state space from a MDP model estimated from trajectories. We use PCCA+, a spectral clustering algorithm from conformal dynamics (Weber et al., 2004) that not only partitions the MDP but also returns the connectivity information between the regions. We then propose a very effective way of composing options using the same framework to take us from one metastable region to another, giving us the policy for free. Once we have these options, we can use standard reinforcement learning algorithms to learn a policy over subtasks to solve the given task. Specifically, we show results using SMDP Qlearning on the 2-room domain. For our attempt at extending it to higher dimensional state space tasks such as Atari 2600 video games, we append the learnt options to the set of primitive actions using Intra-Option Value learning to learn a policy solving the given task. One major advantage of the approach is that we get the policy for the options for free while doing the partitioning by exploiting the membership functions returned by PCCA+. Our approach is able to learn reasonably good skills even with limited sampling which makes it useful in situations where exploration is limited by the environment costs. It also provides a way to refine the abstractions in an online fashion without explicitly reconstructing the entire MDP. More importantly, we extend it to the case where the state space is so large that exact modeling is not possible. In this case, we take inspiration from the recent work on forward prediction to learn the model (Oh et al., 2015) to use Deep Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) to learn spatio-temporal representations of the state space. Using the learnt representation, we perform state-aggregation using clustering techniques and estimate our transitional model for the abstract space on these aggregated states. We list the advantages of this approach below: • Skills are acquired online, from sampled trajectories instead of requiring a prior model of the MDP. • Instead of looking for bottleneck states, we look for well connected regions and hence, the discovered options are better aligned to the structure of the state space. • The approach returns connectivity information between the metastable regions which can be used to construct an abstract graph of the state space, combining spatial and temporal information meaningfully. • The clustering algorithm provides a fuzzy membership for every state in belonging to a particular metastable region, which provides a powerful way to compose options naturally. We organize the rest of the paper as follows: We first explain the Option Generation Framework that we propose, by delving on the important aspects of the spectral clustering algorithm PCCA+ and how PCCA+ can be used to generate options. We show results on the 2-room domain for this framework. The next part of the paper focuses on our attempt to extend this framework for more complex tasks such as playing video games like Seaquest on the Atari 2600 domain with options. We explain the motivation and usage of deep networks, the clustering algorithms used for state-aggregation, followed by the model used and Submission and Formatting Instructions for ICML 2016 initial results. We then conclude with a discussion on the challenges in this approach and also comparison with other recent attempts at Hierarchical reinforcement learning for higher dimensional tasks. 2. Option Generation Framework We divide this section into two parts: We first explain the spectral clustering algorithm PCCA+ and motivate its usage for spatial abstraction. The second part discusses the option generation using PCCA+. 2.1. Spatial Abstraction using PCCA+ Given an algebraic representation of the graph representing a MDP we want to find suitable abstractions aligned to the underlying structure. We use a spectral clustering algorithm to do this. Central to the idea of spectral clustering is the graph Laplacian which is obtained from the similarity graph. There are many tight connections between the topological properties of graphs and the graph Laplacian matrices, which spectral clustering methods exploit to partition the data into clusters. However, although the spectra of the Laplacian preserves the structural properties of the graph, clustering data in the eigenspace of the Laplacian does not guarantee this. For example, k-means clustering (Ng et al., 2001) in the eigenspace of the Laplacian will only work if the clusters lie in disjoint convex sets of the underlying eigenspace. Partitioning the data into clusters by projecting onto the largest k-eigenvectors (Meila & Shi, 2001) does not preserve the topological properties of the data in the eigenspace of the Laplacian. For the task of spatial abstraction, the proposed framework requires a clustering approach that exploits the structural properties in the configurational space of objects as well as the spectral subspace, quite unlike earlier methods. Therefore, we take inspiration from the conformal dynamics literature, where (Weber et al., 2004) do a similar analysis to detect conformal states of a dynamical system. They propose a spectral clustering algorithm PCCA+, which is based on the the principles of Perron Cluster Analysis of the transition structure of the system. We extend their analysis to detect spatial abstractions in autonomous controlled dynamical systems. In this approach, the spectra of the Laplacian L (derived from the adjacency matrix S) is constructed and the best transformation of the spectra is found such that the transformed basis aligns itself with the clusters of data points in the eigenspace. A projection method described in (Weber et al., 2004) is used to find the membership of each of the states to a set of special points lying on the transformed basis, which are identified as vertices of a simplex in the R subspace (the Spectral Gap method is used to estimate the number of clusters k). For the first order perturbation, the simplex is just a linear transformation around the origin and to find the simplex vertices, one needs to find the k points which form a convex hull such that the deviation of all the points from this hull is minimized. This is achieved by finding the data point which is farthest located from the origin and iteratively identify data points which are located farthest from the hyperplane fit to the current set of vertices. Figure 1. Simplex First order and Higher order Perturbation Algorithm 1 PCCA+ 1: Construct Laplacian L 2: Compute n (number of vertices) eigenvalues of L in descending order 3: Choose first k eigenvalues for which ek−ek+1 1−ek+1 > tc (Spectral Gap Threshold). 4: Compute the eigenvectors for corresponding eigenvalues (e1, e2, · · · , ek) and stack them as column vectors in eigenvector matrix Y . 5: Let’s denote the rows of Y as Y(1),Y(2), · · · ,Y(N) ∈ R 6: Define π(1) as that index, for which ||Y (π(1))||2 is maximal. Define γ1 = span{Y (π(1))} 7: For i = 2, · · · , k: Define πi as that index, for which the distance to the hyperplane γi−1, i.e., ||Y (πi) − γi−1||2 is maximal. Define γi = span{Y (π1), · · · , Y (πi)}. ||Y (πi) − γi−1||2 = ||Y (πi)− γ i−1((γi−1γ i−1)γi−1)Y (πi) )|| The PCCA+ algorithm returns a membership function, χ, defining the degree of membership of each state s to an abstract state Sj . The connectivity information between two abstract states (Si, Sj) is given by (i, j) entry of χLχ while the diagonal entries provide relative connectivity information within a cluster. The connectivity information is utilized to learn decision policies across abstract states which is described in the next section. There is an intrinsic mechanism to return information about the goodness of clustering of states from the presence of sharp peaks (indicates good clustering) in the eigenvalue distribution. Submission and Formatting Instructions for ICML 2016 2.2. Option generation from PCCA+",
            "output": [
                "Hierarchical Reinforcement Learning using Spatio-Temporal Abstractions and Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-d112107f64cf418cb37258b5aff5915a",
            "input": "Recent research has shown that surprisingly rich models of human activity can be learned from GPS (positional) data. However, most effort to date has concentrated on modeling single individuals or statistical properties of groups of people. Moreover, prior work focused solely on modeling actual successful executions (and not failed or attempted executions) of the activities of interest. We, in contrast, take on the task of understanding human interactions, attempted interactions, and intentions from noisy sensor data in a fully relational multi-agent setting. We use a real-world game of capture the flag to illustrate our approach in a well-defined domain that involves many distinct cooperative and competitive joint activities. We model the domain using Markov logic, a statistical-relational language, and learn a theory that jointly denoises the data and infers occurrences of high-level activities, such as a player capturing an enemy. Our unified model combines constraints imposed by the geometry of the game area, the motion model of the players, and by the rules and dynamics of the game in a probabilistically and logically sound fashion. We show that while it may be impossible to directly detect a multi-agent activity due to sensor noise or malfunction, the occurrence of the activity can still be inferred by considering both its impact on the future behaviors of the people involved as well as the events that could have preceded it. Further, we show that given a model of successfully performed multi-agent activities, along with a set of examples of failed attempts at the same activities, our system automatically learns an augmented model that is capable of recognizing success and failure, as well as goals of people’s actions with high accuracy. We compare our approach with other alternatives and show that our unified model, which takes into account not only relationships among individual players, but also relationships among activities over the entire length of a game, although more computationally costly, is significantly more accurate. Finally, we demonstrate that explicitly modeling unsuccessful attempts boosts performance on other important recognition tasks.",
            "output": [
                "Location-Based Reasoning about Complex Multi-Agent Behavior"
            ]
        },
        {
            "id": "task1540-625e3832faa7419a949e515647ad8ea3",
            "input": "We describe a technique to minimize weighted tree automata (WTA), a powerful formalisms that subsumes probabilistic context-free grammars (PCFGs) and latent-variable PCFGs. Our method relies on a singular value decomposition of the underlying Hankel matrix defined by the WTA. Our main theoretical result is an efficient algorithm for computing the SVD of an infinite Hankel matrix implicitly represented as a WTA. We provide an analysis of the approximation error induced by the minimization, and we evaluate our method on real-world data originating in newswire treebank. We show that the model achieves lower perplexity than previous methods for PCFG minimization, and also is much more stable due to the absence of local optima.",
            "output": [
                "Weighted Tree Automata Approximation by Singular Value Truncation"
            ]
        },
        {
            "id": "task1540-9e325969154642bba2d085798b56b071",
            "input": "We study the best-arm identification problem in linear bandit, where the rewards of the arms depend linearly on an unknown parameter θ and the objective is to return the arm with the largest reward. We characterize the complexity of the problem and introduce sample allocation strategies that pull arms to identify the best arm with a fixed confidence, while minimizing the sample budget. In particular, we show the importance of exploiting the global linear structure to improve the estimate of the reward of near-optimal arms. We analyze the proposed strategies and compare their empirical performance. Finally, as a by-product of our analysis, we point out the connection to the G-optimality criterion used in optimal experimental design.",
            "output": [
                "Best-Arm Identification in Linear Bandits"
            ]
        },
        {
            "id": "task1540-42b05617d9d244a39444452af6e46a0a",
            "input": "Most provably-efficient reinforcement learning algorithms introduce optimism about poorly-understood states and actions to encourage exploration. We study an alternative approach for efficient exploration: posterior sampling for reinforcement learning (PSRL). This algorithm proceeds in repeated episodes of known duration. At the start of each episode, PSRL updates a prior distribution over Markov decision processes and takes one sample from this posterior. PSRL then follows the policy that is optimal for this sample during the episode. The algorithm is conceptually simple, computationally efficient and allows an agent to encode prior knowledge in a natural way. We establish an Õ(τS √ AT ) bound on expected regret, where T is time, τ is the episode length and S and A are the cardinalities of the state and action spaces. This bound is one of the first for an algorithm not based on optimism, and close to the state of the art for any reinforcement learning algorithm. We show through simulation that PSRL significantly outperforms existing algorithms with similar regret bounds.",
            "output": [
                "(More) Efficient Reinforcement Learning via Posterior Sampling"
            ]
        },
        {
            "id": "task1540-7d46e723f16d44beb5c79f548c33a994",
            "input": "This paper presents an information theoretic approach to the concept of intelligence in the computational sense. We introduce a probabilistic framework from which computational intelligence is shown to be an entropy minimizing process at the local level. Using this new scheme, we develop a simple data driven clustering example and discuss its applications.",
            "output": [
                "The Computational Theory of Intelligence: Information Entropy"
            ]
        },
        {
            "id": "task1540-9a4db66a25f6449db43282104471a8a8",
            "input": "This paper presents a model based on an hybrid system to numerically simulate the climbing phase of an aircraft. This model is then used within a trajectory prediction tool. Finally, the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) optimization algorithm is used to tune five selected parameters, and thus improve the accuracy of the model. Incorporated within a trajectory prediction tool, this model can be used to derive the order of magnitude of the prediction error over time, and thus the domain of validity of the trajectory prediction. A first validation experiment of the proposed model is based on the errors along time for a one-time trajectory prediction at the take off of the flight with respect to the default values of the theoretical BADA model. This experiment, assuming complete information, also shows the limit of the model. A second experiment part presents an on-line trajectory prediction, in which the prediction is continuously updated based on the current aircraft position. This approach raises several issues, for which improvements of the basic model are proposed, and the resulting trajectory prediction tool shows statistically significantly more accurate results than those of the default model.",
            "output": [
                "Online Learning for Ground Trajectory Prediction"
            ]
        },
        {
            "id": "task1540-98e4951443494f24861f0b2a1e66888a",
            "input": "Given samples from a distribution, how many new elements should we expect to find if we continue sampling this distribution? This is an important and actively studied problem, with many applications ranging from unseen species estimation to genomics. We generalize this extrapolation and related unseen estimation problems to the multiple population setting, where population j has an unknown distributionDj from which we observe nj samples. We derive an optimal estimator for the total number of elements we expect to find among new samples across the populations. Surprisingly, we prove that our estimator’s accuracy is independent of the number of populations. We also develop an efficient optimization algorithm to solve the more general problem of estimating multi-population frequency distributions. We validate our methods and theory through extensive experiments. Finally, on a real dataset of human genomes across multiple ancestries, we demonstrate how our approach for unseen estimation can enable cohort designs that can discover interesting mutations with greater efficiency.",
            "output": [
                "Estimating the unseen from multiple populations"
            ]
        },
        {
            "id": "task1540-c428ed26c2bd4132ac4661814f64524b",
            "input": "Knowing where people live is a fundamental component of many decision making processes such as urban development, infectious disease containment, evacuation planning, risk management, conservation planning, and more. While bottom-up, survey driven censuses can provide a comprehensive view into the population landscape of a country, they are expensive to realize, are infrequently performed, and only provide population counts over broad areas. Population disaggregation techniques and population projection methods individually address these shortcomings, but also have shortcomings of their own. To jointly answer the questions of “where do people live” and “how many people live there,” we propose a deep learning model for creating high-resolution population estimations from satellite imagery. Specifically, we train convolutional neural networks to predict population in the USA at a 0.01◦ × 0.01◦ resolution grid from 1-year composite Landsat imagery. We validate these models in two ways: quantitatively, by comparing our model’s grid cell estimates aggregated at a county-level to several US Census county-level population projections, and qualitatively, by directly interpreting the model’s predictions in terms of the satellite image inputs. We find that aggregating our model’s estimates gives comparable results to the Census county-level population projections and that the predictions made by our model can be directly interpreted, which give it advantages over traditional population disaggregation methods. In general, our model is an example of how machine learning techniques can be an effective tool for extracting information from inherently unstructured, remotely sensed data to provide effective solutions to social problems.",
            "output": [
                "A Deep Learning Approach for Population Estimation from Satellite Imagery"
            ]
        },
        {
            "id": "task1540-5fd9d5d771f34e429b3f43de34fd4a3b",
            "input": "<lb>We consider stochastic bandit problems with a continuous set of arms and where the expected re-<lb>ward is a continuous and unimodal function of the arm. No further assumption is made regarding<lb>the smoothness and the structure of the expected reward function. For these problems, we propose<lb>the Stochastic Pentachotomy (SP) algorithm, and derive finite-time upper bounds on its regret and<lb>optimization error. In particular, we show that, for any expected reward function μ that behaves as<lb>μ(x) = μ(x)− C|x− x| locally around its maximizer x for some ξ, C > 0, the SP algorithm is<lb>order-optimal. Namely its regret and optimization error scale as O(<lb>√<lb>T log(T )) and O(<lb>√<lb>log(T )/T ),<lb>respectively, when the time horizon T grows large. These scalings are achieved without the knowledge<lb>of ξ and C. Our algorithm is based on asymptotically optimal sequential statistical tests used to suc-<lb>cessively trim an interval that contains the best arm with high probability. To our knowledge, the SP<lb>algorithm constitutes the first sequential arm selection rule that achieves a regret and optimization error<lb>scaling as O(<lb>√<lb>T ) and O(1/<lb>√<lb>T ), respectively, up to a logarithmic factor for non-smooth expected<lb>reward functions, as well as for smooth functions with unknown smoothness.",
            "output": [
                "Unimodal Bandits without Smoothness"
            ]
        },
        {
            "id": "task1540-5fec2d676c1d477a828e445affe886c3",
            "input": "In this paper, we analyze the spectrum occupancy using different machine learning techniques. Both supervised techniques (naive Bayesian classifier (NBC), decision trees (DT), support vector machine (SVM), linear regression (LR)) and unsupervised algorithm (hidden markov model (HMM)) are studied to find the best technique with the highest classification accuracy (CA). A detailed comparison of the supervised and unsupervised algorithms in terms of the computational time and classification accuracy is performed. The classified occupancy status is further utilized to evaluate the probability of secondary user outage for the future time slots, which can be used by system designers to define spectrum allocation and spectrum sharing policies. Numerical results show that SVM is the best algorithm among all the supervised and unsupervised classifiers. Based on this, we proposed a new SVM algorithm by combining it with fire fly algorithm (FFA), which is shown to outperform all other algorithms. Index Terms Fire fly algorithm, hidden markov model, spectrum occupancy and support vector machine. March 25, 2015 DRAFT",
            "output": [
                "Analysis of Spectrum Occupancy Using Machine Learning Algorithms"
            ]
        },
        {
            "id": "task1540-22623baf7f1340de886d4eeac76ef48e",
            "input": "We describe TweeTIME, a temporal tagger for recognizing and normalizing time expressions in Twitter. Most previous work in social media analysis has to rely on temporal resolvers that are designed for well-edited text, and therefore suffer from the reduced performance due to domain mismatch. We present a minimally supervised method that learns from large quantities of unlabeled data and requires no hand-engineered rules or hand-annotated training corpora. TweeTIME achieves 0.68 F1 score on the end-to-end task of resolving date expressions, outperforming a broad range of state-of-the-art systems.1",
            "output": [
                "A Minimally Supervised Method for Recognizing and Normalizing Time Expressions in Twitter"
            ]
        },
        {
            "id": "task1540-d2211bc024ed4575a32c808b018e4614",
            "input": "We present a new theoretical framework for analyzing and learning artificial neural networks. Our approach simultaneously and adaptively learns both the structure of the network as well as its weights. The methodology is based upon and accompanied by strong data-dependent theoretical learning guarantees, so that the final network architecture provably adapts to the complexity of any given problem.",
            "output": [
                "AdaNet: Adaptive Structural Learning of Artificial Neural Networks"
            ]
        },
        {
            "id": "task1540-14dbe0950f814d48b7972219a8b6c7ee",
            "input": "In this paper we present our exploratory findings related to extracting knowledge and experiences from a community of senior tourists. By using tools of qualitative analysis as well as review of literature, we managed to verify a set of hypotheses related to the content created by senior tourists when participating in on-line communities. We also produced a codebook, representing various themes one may encounter in such communities. This codebook, derived from our own qualitative research, as well a literature review will serve as a basis for further development of automated tools of knowledge extraction. We also managed to find that older adults more often than other poster in tourists forums, mention their age in discussion, more often share their experiences and motivation to travel, however they do not differ in relation to describing barriers encountered while traveling.",
            "output": [
                "Golden Years, Golden Shores: A Study of Elders in Online Travel Communities"
            ]
        },
        {
            "id": "task1540-69370b10a3a04170ba18474cab4888c3",
            "input": "This paper focuses on style transfer on the basis of non-parallel text. This is an instance of a broader family of problems including machine translation, decipherment, and sentiment modification. The key technical challenge is to separate the content from desired text characteristics such as sentiment. We leverage refined alignment of latent representations across mono-lingual text corpora with different characteristics. We deliberately modify encoded examples according to their characteristics, requiring the reproduced instances to match available examples with the altered characteristics as a population. We demonstrate the effectiveness of this cross-alignment method on three tasks: sentiment modification, decipherment of word substitution ciphers, and recovery of word order.",
            "output": [
                "Style Transfer from Non-Parallel Text by Cross-Alignment"
            ]
        },
        {
            "id": "task1540-8b6f727a83b742788e8d299ada45d657",
            "input": "The Minimum Vertex Cover (MinVC) problem is a well-known NP-hard problem. Recently there has been great interest in solving this problem on real-world massive graphs. For such graphs, local search is a promising approach to finding optimal or near-optimal solutions. In this paper we propose a local search algorithm that exploits reduction rules and data structures to solve the MinVC problem in such graphs. Experimental results on a wide range of real-word massive graphs show that our algorithm finds better covers than state-of-theart local search algorithms for MinVC. Also we present interesting results about the complexities of some wellknown heuristics.",
            "output": [
                "Exploiting Reduction Rules and Data Structures: Local Search for Minimum Vertex Cover in Massive Graphs"
            ]
        },
        {
            "id": "task1540-d94af19ba75f4ae7b8ef6765d6c84fc3",
            "input": "A major challenge in paraphrase research is the lack of parallel corpora. In this paper, we present a new method to collect large-scale sentential paraphrases from Twitter by linking tweets through shared URLs. The main advantage of our method is its simplicity, as it gets rid of the classifier or human in the loop needed to select data before annotation and subsequent application of paraphrase identification algorithms in the previous work. We present the largest human-labeled paraphrase corpus to date of 51,524 sentence pairs and the first cross-domain benchmarking for automatic paraphrase identification. In addition, we show that more than 30,000 new sentential paraphrases can be easily and continuously captured every month at ∼70% precision, and demonstrate their utility for downstream NLP tasks through phrasal paraphrase extraction. We make our code and data freely available.1",
            "output": [
                "A Continuously Growing Dataset of Sentential Paraphrases"
            ]
        },
        {
            "id": "task1540-619ae3e2960b4afd8cbc356eb9747ee6",
            "input": "Implicit discourse relation recognition is a crucial component for automatic discourse-level analysis and nature language understanding. Previous studies exploit discriminative models that are built on either powerful manual features or deep discourse representations. In this paper, instead, we explore generative models and propose a variational neural discourse relation recognizer. We refer to this model as VIRILE. VIRILE establishes a directed probabilistic model with a latent continuous variable that generates both a discourse and the relation between the two arguments of the discourse. In order to perform efficient inference and learning, we introduce a neural discourse relation model to approximate the posterior of the latent variable, and employ this approximated posterior to optimize a reparameterized variational lower bound. This allows VIRILE to be trained with standard stochastic gradient methods. Experiments on the benchmark data set show that VIRILE can achieve competitive results against state-of-the-art baselines.",
            "output": [
                "Variational Neural Discourse Relation Recognizer"
            ]
        },
        {
            "id": "task1540-897edcc5b256414291231e96b3979eba",
            "input": "In action domains where agents may have erroneous beliefs, reasoning about the effects of actions involves reasoning about belief change. In this paper, we use a transition system approach to reason about the evolution of an agent’s beliefs as actions are executed. Some actions cause an agent to perform belief revision while others cause an agent to perform belief update, but the interaction between revision and update can be nonelementary. We present a set of rationality properties describing the interaction between revision and update, and we introduce a new class of belief change operators for reasoning about alternating sequences of revisions and updates. Our belief change operators can be characterized in terms of a natural shifting operation on total pre-orderings over interpretations. We compare our approach with related work on iterated belief change due to action, and we conclude with some directions for future research.",
            "output": [
                "Iterated Belief Change Due to Actions and Observations"
            ]
        },
        {
            "id": "task1540-d4886a94edf346fa8424a616e44765e7",
            "input": "In this paper we present a model for email authorship identification (EAI) by employing a Cluster-based Classification (CCM) technique. Traditionally, stylometric features have been successfully employed in various authorship analysis tasks; we extend the traditional feature-set to include some more interesting and effective features for email authorship identification (e.g. the last punctuation mark used in an email, the tendency of an author to use capitalization at the start of an email, or the punctuation after a greeting or farewell). We also included Info Gain feature selection based content features. It is observed that the use of such features in the authorship identification process has a positive impact on the accuracy of the authorship identification task. We performed experiments to justify our arguments and compared the results with other base line models. Experimental results reveal that the proposed CCM -based email authorship identification model, along with the proposed feature set, outperforms the state-of-the-art support vector machine (SVM)-based models, as well as the models proposed by Iqbal et al. [1, 2]. The proposed model attains an accuracy rate of 94% for 10 authors, 89% for 25 authors, and 81% for 50 authors, respectively on Enron dataset, while 89.5% accuracy has been achieved on authors' constructed real email dataset. The results on Enron dataset have been achieved on quite a large number of authors as compared to the models proposed by Iqbal et al. [1, 2].",
            "output": [
                "CEAI: CCM based Email Authorship Identification Model"
            ]
        },
        {
            "id": "task1540-690561439c35445eae904b2a313d3a78",
            "input": "In this paper we present applications of different machine learning algorithms in aquaculture. Machine learning algorithms learn models from historical data. In aquaculture historical data are obtained from farm practices, yields, and environmental data sources. Associations between these different variables can be obtained by applying machine learning algorithms to historical data. In this paper we present applications of different machine learning algorithms in aquaculture applications.",
            "output": [
                "Application of Machine Learning Techniques in Aquaculture"
            ]
        },
        {
            "id": "task1540-c703b90efb484578b54b3913192ffea9",
            "input": "We present decentralized rollout sampling policy iteration (DecRSPI) — a new algorithm for multi-agent decision problems formalized as DEC-POMDPs. DecRSPI is designed to improve scalability and tackle problems that lack an explicit model. The algorithm uses MonteCarlo methods to generate a sample of reachable belief states. Then it computes a joint policy for each belief state based on the rollout estimations. A new policy representation allows us to represent solutions compactly. The key benefits of the algorithm are its linear time complexity over the number of agents, its bounded memory usage and good solution quality. It can solve larger problems that are intractable for existing planning algorithms. Experimental results confirm the effectiveness and scalability of the approach.",
            "output": [
                "Rollout Sampling Policy Iteration for Decentralized POMDPs"
            ]
        },
        {
            "id": "task1540-f3f3d48492f741f4be3a301d2f7f9dca",
            "input": "Deep neural networks can be obscenely wasteful. When processing video, a convolutional network expends a fixed amount of computation for each frame with no regard to the similarity between neighbouring frames. As a result, it ends up repeatedly doing very similar computations. To put an end to such waste, we introduce SigmaDelta networks. With each new input, each layer in this network sends a discretized form of its change in activation to the next layer. Thus the amount of computation that the network does scales with the amount of change in the input and layer activations, rather than the size of the network. We introduce an optimization method for converting any pre-trained deep network into an optimally efficient Sigma-Delta network, and show that our algorithm, if run on the appropriate hardware, could cut at least an order of magnitude from the computational cost of processing video data.",
            "output": [
                "SIGMA-DELTA QUANTIZED NETWORKS"
            ]
        },
        {
            "id": "task1540-efd2fcbc1ce148249d346d7a93aebb0a",
            "input": "Although, the fair amount of works in sentiment analysis (SA) and opinion mining (OM) systems in the last decade and with respect to the performance of these systems, but it still not desired performance, especially for morphologically-Rich Language (MRL) such as Arabic, due to the complexities and challenges exist in the nature of the languages itself. One of these challenges is the detection of idioms or proverbs phrases within the writer text or comment. An idiom or proverb is a form of speech or an expression that is peculiar to itself. Grammatically, it cannot be understood from the individual meanings of its elements and can yield different sentiment when treats as separate words. Consequently, In order to facilitate the task of detection and classification of lexical phrases for automated SA systems, this paper presents AIPSeLEX a novel idioms/ proverbs sentiment lexicon for modern standard Arabic (MSA) and colloquial. AIPSeLEX is manually collected and annotated at sentence level with semantic orientation (positive or negative). The efforts of manually building and annotating the lexicon are reported. Moreover, we build a classifier that extracts idioms and proverbs, phrases from text using n-gram and similarity measure methods. Finally, several experiments were carried out on various data, including Arabic tweets and Arabic microblogs (hotel reservation, product reviews, and TV program comments) from publicly available Arabic online reviews websites (social media, blogs, forums, e-commerce web sites) to evaluate the coverage and accuracy of AIPSeLEX. General Terms Sentiment Analysis, modern standard Arabic, colloquial, natural language processing.",
            "output": [
                "Idioms-Proverbs Lexicon for Modern Standard Arabic and Colloquial Sentiment Analysis"
            ]
        },
        {
            "id": "task1540-d30c28ad40784ea1814929e517196461",
            "input": "One way to approach end-to-end autonomous driving is to learn a policy function that maps from a sensory input, such as an image frame from a front-facing camera, to a driving action, by imitating an expert driver, or a reference policy. This can be done by supervised learning, where a policy function is tuned to minimize the difference between the predicted and ground-truth actions. A policy function trained in this way however is known to suffer from unexpected behaviours due to the mismatch between the states reachable by the reference policy and trained policy functions. More advanced algorithms for imitation learning, such as DAgger, addresses this issue by iteratively collecting training examples from both reference and trained policies. These algorithms often requires a large number of queries to a reference policy, which is undesirable as the reference policy is often expensive. In this paper, we propose an extension of the DAgger, called SafeDAgger, that is query-efficient and more suitable for end-to-end autonomous driving. We evaluate the proposed SafeDAgger in a car racing simulator and show that it indeed requires less queries to a reference policy. We observe a significant speed up in convergence, which we conjecture to be due to the effect of automated curriculum learning.",
            "output": [
                "Query-Efficient Imitation Learning for End-to-End Autonomous Driving"
            ]
        },
        {
            "id": "task1540-e776a681c20f43a29fe49f623371c77c",
            "input": "NLP tasks differ in the semantic information they require, and at this time no single semantic representation fulfills all requirements. Logic-based representations characterize sentence structure, but do not capture the graded aspect of meaning. Distributional models give graded similarity ratings for words and phrases, but do not adequately capture overall sentence structure. So it has been argued that the two are complementary. In this paper, we adopt a hybrid approach that combines logic-based and distributional semantics through probabilistic logic inference in Markov Logic Networks (MLNs). We focus on textual entailment (RTE), a task that can utilize the strengths of both representations. Our system is three components, 1) parsing and task representation, where input RTE problems are represented in probabilistic logic. This is quite different from representing them in standard first-order logic. 2) knowledge base construction in the form of weighted inference rules from different sources like WordNet, paraphrase collections, and lexical and phrasal distributional rules generated on the fly. We use a variant of Robinson resolution to determine the necessary inference rules. More sources can easily be added by mapping them to logical rules; our system learns a resource-specific weight that counteract scaling differences between resources. 3) inference, where we show how to solve the inference problems efficiently. In this paper we focus on the SICK dataset, and we achieve a state-of-the-art result. Our system handles overall sentence structure and phenomena like negation in the logic, then uses our Robinson resolution variant to query distributional systems about words and short phrases. Therefor, we use our system to evaluate distributional lexical entailment approaches. We also publish the set of rules queried from the SICK dataset, which can be a good resource to evaluate them.",
            "output": [
                "Representing Meaning with a Combination of Logical Form and Vectors"
            ]
        },
        {
            "id": "task1540-1b95f71cecbf4f4d95b8aaedb87c496d",
            "input": "There has been a long history of using fuzzy language equivalence to compare the behavior of fuzzy systems, but the comparison at this level is too coarse. Recently, a finer behavioral measure, bisimulation, has been introduced to fuzzy finite automata. However, the results obtained are applicable only to finite-state systems. In this paper, we consider bisimulation for general fuzzy systems which may be infinite-state or infiniteevent, by modeling them as fuzzy transition systems. To help understand and check bisimulation, we characterize it in three ways by enumerating whole transitions, comparing individual transitions, and using a monotonic function. In addition, we address composition operations, subsystems, quotients, and homomorphisms of fuzzy transition systems and discuss their properties connected with bisimulation. The results presented here are useful for comparing the behavior of general fuzzy systems. In particular, this makes it possible to relate an infinite fuzzy system to a finite one, which is easier to analyze, with the same behavior.",
            "output": [
                "Bisimulations for Fuzzy Transition Systems"
            ]
        },
        {
            "id": "task1540-b606834326eb4824a119df365f048631",
            "input": "In this paper, we present the DifferenceBased Causality Learner (DBCL), an algorithm for learning a class of discrete-time dynamic models that represents all causation across time by means of difference equations driving change in a system. We motivate this representation with real-world mechanical systems and prove DBCL’s correctness for learning structure from time series data, an endeavour that is complicated by the existence of latent derivatives that have to be detected. We also prove that, under common assumptions for causal discovery, DBCL will identify the presence or absence of feedback loops, making the model more useful for predicting the effects of manipulating variables when the system is in equilibrium. We argue analytically and show empirically the advantages of DBCL over vector autoregression (VAR) and Granger causality models as well as modified forms of Bayesian and constraintbased structure discovery algorithms. Finally, we show that our algorithm can discover causal directions of alpha rhythms in human brains from EEG data.",
            "output": [
                "Learning Why Things Change: The Difference-Based Causality Learner"
            ]
        },
        {
            "id": "task1540-c75e1ea32ffc421a881e646e0e4aeee7",
            "input": "This paper aims to introduces a new algorithm for automatic speech-to-text summarization based on statistical divergences of probabilities and graphs. The input is a text from speech conversations with noise, and the output a compact text summary. Our results, on the pilot task CCCS Multiling 2015 French corpus are very encouraging.",
            "output": [
                "LIA-RAG: a system based on graphs and divergence of probabilities applied to Speech-To-Text Summarization"
            ]
        },
        {
            "id": "task1540-cc06c796a2f44c6a93f26c236b6eb012",
            "input": "Generating texts from structured data (e.g., a table) is important for various natural language processing tasks such as question answering and dialog systems. In recent studies, researchers use neural language models and encoder-decoder frameworks for table-to-text generation. However, these neural network-based approaches do not model the order of contents during text generation. When a human writes a summary based on a given table, he or she would probably consider the content order before wording. In a biography, for example, the nationality of a person is typically mentioned before occupation in a biography. In this paper, we propose an order-planning text generation model to capture the relationship between different fields and use such relationship to make the generated text more fluent and smooth. We conducted experiments on the WIKIBIO dataset and achieve significantly higher performance than previous methods in terms of BLEU, ROUGE, and NIST scores.",
            "output": [
                "Order-Planning Neural Text Generation From Structured Data"
            ]
        },
        {
            "id": "task1540-f62c798362144a35b83552c351b1294c",
            "input": "The first step of processing a question in Question Answering(QA) Systems is to carry out a detailed analysis of the question for the purpose of determining what it is asking for and how to perfectly approach answering it. Our Question analysis uses several techniques to analyze any question given in natural language: a Stanford POS Tagger & parser for Arabic language, a named entity recognizer, tokenizer, Stop-word removal, Question expansion, Question classification and Question focus extraction components. We employ numerous detection rules and trained classifier using features from this analysis to detect important elements of the question, including: 1) the portion of the question that is a referring to the answer (the focus); 2) different terms in the question that identify what type of entity is being asked for (the lexical answer types); 3) Question expansion ; 4) a process of classifying the question into one or more of several and different types; and We describe how these elements are identified and evaluate the effect of accurate detection on our question-answering system using the Mean Reciprocal Rank(MRR) accuracy measure.",
            "output": [
                "QUESTION ANALYSIS FOR ARABIC QUESTION ANSWERING SYSTEMS"
            ]
        },
        {
            "id": "task1540-efedc6daba27493b85e792a1996bf62a",
            "input": "In this paper, we theoretically justify an approach popular among participants of the Higgs Boson Machine Learning Challenge to optimize approximate median significance (AMS). The approach is based on the following two-stage procedure. First, a real-valued function f is learned by minimizing a surrogate loss for binary classification, such as logistic loss, on the training sample. Then, given f , a threshold θ̂ is tuned on a separate validation sample, by direct optimization of AMS. We show that the regret of the resulting classifier (obtained from thresholding f on θ̂) measured with respect to the squared AMS, is upperbounded by the regret of f measured with respect to the logistic loss. Hence, we prove that minimizing logistic surrogate is a consistent method of optimizing AMS.",
            "output": [
                "Consistent optimization of AMS by logistic loss minimization"
            ]
        },
        {
            "id": "task1540-eb7579d813e14f10a19070317703a9bf",
            "input": "The current trend in object detection and localization is to learn predictions with high capacity deep neural networks trained on a very large amount of annotated data and using a high amount of processing power. In this work, we propose a new neural model which directly predicts bounding box coordinates. The particularity of our contribution lies in the local computations of predictions with a new form of local parameter sharing which keeps the overall amount of trainable parameters low. Key components of the model are spatial 2D-LSTM recurrent layers which convey contextual information between the regions of the image. We show that this model is more powerful than the state of the art in applications where training data is not as abundant as in the classical configuration of natural images and Imagenet/Pascal VOC tasks. We particularly target the detection of text in document images, but our method is not limited to this setting. The proposed model also facilitates the detection of many objects in a single image and can deal with inputs of variable sizes without resizing.",
            "output": [
                "Learning to detect and localize many objects from few examples"
            ]
        },
        {
            "id": "task1540-93913c1765ab40ffaaf732f9c44ed6b4",
            "input": "The attention model has become a standard component in neural machine translation (NMT) and it guides translation process by selectively focusing on parts of the source sentence when predicting each target word. However, we find that the generation of a target word does not only depend on the source sentence, but also rely heavily on the previous generated target words, especially the distant words which are difficult to model by using recurrent neural networks. To solve this problem, we propose in this paper a novel look-ahead attention mechanism for generation in NMT, which aims at directly capturing the dependency relationship between target words. We further design three patterns to integrate our look-ahead attention into the conventional attention model. Experiments on NIST Chinese-to-English and WMT English-to-German translation tasks show that our proposed look-ahead attention mechanism achieves substantial improvements over state-of-the-art baselines.",
            "output": [
                "Look-ahead Attention for Generation in Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-1082937af4e649d4805e913b9c9911fd",
            "input": "We evaluate the character-level translation method for neural semantic parsing on a large corpus of sentences annotated with Abstract Meaning Representations (AMRs). Using a seq2seq model, and some trivial preprocessing and postprocessing of AMRs, we obtain a baseline accuracy of 53.1 (F-score on AMR-triples). We examine four different approaches to improve this baseline result: (i) reordering AMR branches to match the word order of the input sentence increases performance to 58.3; (ii) adding part-of-speech tags (automatically produced) to the input shows improvement as well (57.2); (iii) So does the introduction of super characters (conflating frequent sequences of characters to a single character), reaching 57.4; (iv) adding silver-standard training data obtained by an off-the-shelf parser yields the biggest improvement, resulting in an F-score of 64.0. Combining all four techniques leads to an F-score of 69.0, which is state-of-the-art in AMR parsing. This is remarkable because of the relatively simplicity of the approach: the only explicit linguistic knowledge that we use are part-of-speech tags.",
            "output": [
                "Neural Semantic Parsing by Character-based Translation: Experiments with Abstract Meaning Representations"
            ]
        },
        {
            "id": "task1540-0fbb72b334cd44aabae34fcbd0f75565",
            "input": "Theoretical analyses of the Dendritic Cell Algorithm (DCA) have yielded several criticisms about its underlying structure and operation. As a result, several alterations and fixes have been suggested in the literature to correct for these findings. A contribution of this work is to investigate the effects of replacing the classification stage of the DCA (which is known to be flawed) with a traditional machine learning technique. This work goes on to question the merits of those unique properties of the DCA that are yet to be thoroughly analysed. If none of these properties can be found to have a benefit over traditional approaches, then “fixing” the DCA is arguably less efficient than simply creating a new algorithm. This work examines the dynamic filtering property of the DCA and questions the utility of this unique feature for the anomaly detection problem. It is found that this feature, while advantageous for noisy, time-ordered classification, is not as useful as a traditional static filter for processing a synthetic dataset. It is concluded that there are still unique features of the DCA left to investigate. Areas that may be of benefit to the Artificial Immune Systems community are suggested.",
            "output": [
                "Quiet in Class : Classification, Noise and the Dendritic Cell Algorithm"
            ]
        },
        {
            "id": "task1540-da64b9af2ba049b8b402d47d96af4950",
            "input": "We present a suite of algorithms for Dimension Independent Similarity Computation (DISCO) to compute all pairwise similarities between very high dimensional sparse vectors. All of our results are provably independent of dimension, meaning apart from the initial cost of trivially reading in the data, all subsequent operations are independent of the dimension, thus the dimension can be very large. We study Cosine, Dice, Overlap, Conditional, and the Jaccard similarity measures. For Jaccard similiarity we include an improved version of MinHash. Our results are geared toward the MapReduce framework. We empirically validate our theorems at large scale using data from the social networking site Twitter.",
            "output": [
                "Dimension Independent Similarity Computation"
            ]
        },
        {
            "id": "task1540-11e977ff07b84639b28f5ebe4b10d670",
            "input": "Auto-encoders are perhaps the best-known non-probabilistic methods for representation learning. They are conceptually simple and easy to train. Recent theoretical work has shed light on their ability to capture manifold structure, and drawn connections to density modeling. This has motivated researchers to seek ways of auto-encoder scoring, which has furthered their use in classification. Gated auto-encoders (GAEs) are an interesting and flexible extension of auto-encoders which can learn transformations among different images or pixel covariances within images. However, they have been much less studied, theoretically or empirically. In this work, we apply a dynamical systems view to GAEs, deriving a scoring function, and drawing connections to Restricted Boltzmann Machines. On a set of deep learning benchmarks, we also demonstrate their effectiveness for single and multi-label classification.",
            "output": [
                "Scoring and Classifying with Gated Auto-encoders"
            ]
        },
        {
            "id": "task1540-67c6be8069cf4e54b461cfce36858d32",
            "input": "We propose a method for embedding twodimensional locations in a continuous vector space using a neural network-based model incorporating mixtures of Gaussian distributions, presenting two model variants for text-based geolocation and lexical dialectology. Evaluated over Twitter data, the proposed model outperforms conventional regression-based geolocation and provides a better estimate of uncertainty. We also show the effectiveness of the representation for predicting words from location in lexical dialectology, and evaluate it using the DARE dataset.",
            "output": [
                "Continuous Representation of Location for Geolocation and Lexical Dialectology using Mixture Density Networks"
            ]
        },
        {
            "id": "task1540-7496c276b2bb4fcd9186d04b77e251ee",
            "input": "We explore beyond existing work on learning from demonstration by asking the question: “Can robots learn to teach?”, that is, can a robot autonomously learn an instructional policy from expert demonstration and use it to instruct or collaborate with humans in executing complex tasks in uncertain environments? In this paper we pursue a solution to this problem by leveraging the idea that humans often implicitly decompose a higher level task into several subgoals whose execution brings the task closer to completion. We propose Dirichlet process based non-parametric Inverse Reinforcement Learning (DPMIRL) approach for reward based unsupervised clustering of task space into subgoals. This approach is shown to capture the latent subgoals that a human teacher would have utilized to train a novice. The notion of “action primitive” is introduced as the means to communicate instruction policy to humans in the least complicated manner, and as a computationally efficient tool to segment demonstration data. We evaluate our approach through experiments on hydraulic actuated scaled model of an excavator and evaluate and compare different teaching strategies utilized by the robot.",
            "output": [
                "Can Co-robots Learn to Teach?"
            ]
        },
        {
            "id": "task1540-e1bab8fbcfa94fbbb3acd66565648f0f",
            "input": "With the advancement of web technology and its growth, there is a huge volume of data present in the web for internet users and a lot of data is generated too. Internet has become a platform for online learning, exchanging ideas and sharing opinions. Social networking sites like Twitter, Facebook, Google+ are rapidly gaining popularity as they allow people to share and express their views about topics,have discussion with different communities, or post messages across the world. There has been lot of work in the field of sentiment analysis of twitter data. This survey focuses mainly on sentiment analysis of twitter data which is helpful to analyze the information in the tweets where opinions are highly unstructured, heterogeneous and are either positive or negative, or neutral in some cases. In this paper, we provide a survey and a comparative analyses of existing techniques for opinion mining like machine learning and lexicon-based approaches, together with evaluation metrics. Using various machine learning algorithms like Naive Bayes, Max Entropy, and Support Vector Machine, we provide a research on twitter data streams. We have also discussed general challenges and applications of Sentiment Analysis on Twitter.",
            "output": [
                "Sentiment Analysis of Twitter Data :A Survey of Techniques"
            ]
        },
        {
            "id": "task1540-008fd29a66954f549b0e306d0ce0894a",
            "input": "Path planning is typically considered in Artificial Intelligence as a graph searching problem and R* is state-of-the-art algorithm tailored to solve it. The algorithm decomposes given path finding task into the series of subtasks each of which can be easily (in computational sense) solved by well-known methods (such as A*). Parameterized random choice is used to perform the decomposition and as a result R* performance largely depends on the choice of its input parameters. In our work we formulate a range of assumptions concerning possible upper and lower bounds of R* parameters, their interdependency and their influence on R* performance. Then we evaluate these assumptions by running a large number of experiments. As a result we formulate a set of heuristic rules which can be used to initialize the values of R* parameters in a way that leads to algorithm’s best performance.",
            "output": [
                "Finetuning Randomized Heuristic Search For 2D Path Planning: Finding The Best Input Parameters For R* Algorithm Through Series Of Experiments"
            ]
        },
        {
            "id": "task1540-752c20d5b2874f63a7fb97f03ce2f2e8",
            "input": "This paper presents an approach to formalizing and enforcing a class of use privacy properties in data-driven systems. In contrast to prior work, we focus on use restrictions on proxies (i.e. strong predictors) of protected information types. Our definition relates proxy use to intermediate computations that occur in a program, and identify two essential properties that characterize this behavior: 1) its result is strongly associated with the protected information type in question, and 2) it is likely to causally affect the final output of the program. For a specific instantiation of this definition, we present a program analysis technique that detects instances of proxy use in a model, and provides a witness that identifies which parts of the corresponding program exhibit the behavior. Recognizing that not all instances of proxy use of a protected information type are inappropriate, we make use of a normative judgment oracle that makes this inappropriateness determination for a given witness. Our repair algorithm uses the witness of an inappropriate proxy use to transform the model into one that provably does not exhibit proxy use, while avoiding changes that unduly affect classification accuracy. Using a corpus of social datasets, our evaluation shows that these algorithms are able to detect proxy use instances that would be difficult to find using existing techniques, and subsequently remove them while maintaining acceptable classification performance.",
            "output": [
                "Use Privacy in Data-Driven Systems"
            ]
        },
        {
            "id": "task1540-0c92a1de0fe34584acc1249252c38d71",
            "input": "A language independent Stemmer has always been looked for. Single N-gram tokenization technique works well, however, it often generates stems that start with intermediate characters, rather than initial ones. We present a novel technique that takes the concept of N-grams one step ahead and compare our method with an established algorithm in the fieldPorter’s Stemmer. Porter’s Stemmer is language dependent, and performance of our proposed method is not inferior to it.",
            "output": [
                "Generation, Implementation and Appraisal of a Language Independent Stemming Algorithm"
            ]
        },
        {
            "id": "task1540-42463462c5044da59a6074ff95d2e284",
            "input": "The early classifications of the computational complexity of planning under various restrictions in STRIPS (Bylander) and SAS (Bäckström and Nebel) have influenced following research in planning in many ways. We go back and reanalyse their subclasses, but this time using the more modern tool of parameterized complexity analysis. This provides new results that together with the old results give a more detailed picture of the complexity landscape. We demonstrate separation results not possible with standard complexity theory, which contributes to explaining why certain cases of planning have seemed simpler in practice than theory has predicted. In particular, we show that certain restrictions of practical interest are tractable in the parameterized sense of the term, and that a simple heuristic is sufficient to make a well-known partial-order planner exploit this fact.",
            "output": [
                "The Complexity of Planning Revisited – A Parameterized Analysis"
            ]
        },
        {
            "id": "task1540-de650fd0ec3a42cba8841fc1ade92500",
            "input": "Opinion mining from customer reviews has become pervasive in recent years. Sentences in reviews, however, are usually classified independently, even though they form part of a review’s argumentative structure. Intuitively, sentences in a review build and elaborate upon each other; knowledge of the review structure and sentential context should thus inform the classification of each sentence. We demonstrate this hypothesis for the task of aspect-based sentiment analysis by modeling the interdependencies of sentences in a review with a hierarchical bidirectional LSTM. We show that the hierarchical model outperforms two non-hierarchical baselines, obtains results competitive with the state-of-the-art, and outperforms the state-of-the-art on five multilingual, multi-domain datasets without any handengineered features or external resources.",
            "output": [
                "A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis"
            ]
        },
        {
            "id": "task1540-8b6ca43179bb482d94ccf6e03c19c849",
            "input": "We consider the task of identifying attitudes towards a given set of entities from text. Conventionally, this task is decomposed into two separate subtasks: target detection that identifies whether each entity is mentioned in the text, either explicitly or implicitly, and polarity classification that classifies the exact sentiment towards an identified entity (the target) into positive, negative, or neutral. Instead, we show that attitude identification can be solved with an end-to-end machine learning architecture, in which the two subtasks are interleaved by a deep memory network. In this way, signals produced in target detection provide clues for polarity classification, and reversely, the predicted polarity provides feedback to the identification of targets. Moreover, the treatments for the set of targets also influence each other – the learned representations may share the same semantics for some targets but vary for others. The proposed deep memory network, the AttNet, outperforms methods that do not consider the interactions between the subtasks or those among the targets, including conventional machine learning methods and the state-of-the-art deep learning models.",
            "output": [
                "Deep Memory Networks for Attitude Identification"
            ]
        },
        {
            "id": "task1540-7656a75d7f8040c98367575c42c84eb7",
            "input": "The shortest path between two concepts in a taxonomic ontology is commonly used to represent the semantic distance between concepts in the edge-based semantic similarity measures. In the past, the edge counting is considered to be the default method for the path computation, which is simple, intuitive and has low computational complexity. However, a large lexical taxonomy of such as WordNet has the irregular densities of links between concepts due to its broad domain but. The edge counting-based path computation is powerless for this non-uniformity problem. In this paper, we advocate that the path computation is able to be separated from the edge-based similarity measures and form various general computing models. Therefore, in order to solve the problem of non-uniformity of concept density in a large taxonomic ontology, we propose a new path computing model based on the compensation of local area density of concepts, which is equal to the number of direct hyponyms of the subsumers of concepts in their shortest path. This path model considers the local area density of concepts as an extension of the edge-based path and converts the local area density divided by their depth into the compensation for edge-based path with an adjustable parameter, which idea has been proven to be consistent with the information theory. This model is a general path computing model and can be applied in various edge-based similarity algorithms. The experiment results show that the proposed path model improves the average correlation between edge-based measures with human judgments on Miller and Charles benchmark from less than 0.8 to more than 0.85, and has a big advantage in efficiency than information content (IC) computation in a dynamic ontology, thereby successfully solving the non-uniformity problem of taxonomic ontology.",
            "output": [
                "A density compensation-based path computing model for measuring semantic similarity"
            ]
        },
        {
            "id": "task1540-eacfb44c73e145f09f8027c2e96d8a18",
            "input": "Learning in probabilistic models is often severely hampered by the general intractability of the normalization factor and its derivatives. Here we propose a new learning technique that obviates the need to compute an intractable normalization factor or sample from the equilibrium distribution of the model. This is achieved by establishing dynamics that would transform the observed data distribution into the model distribution, and then setting as the objective the minimization of the initial flow of probability away from the data distribution. Score matching, minimum velocity learning, and certain forms of contrastive divergence are shown to be special cases of this learning technique. We demonstrate the application of minimum probability flow learning to parameter estimation in Ising models, deep belief networks, multivariate Gaussian distributions and a continuous model with a highly general energy function defined as a power series. In the Ising model case, minimum probability flow learning outperforms current state of the art techniques by approximately two orders of magnitude in learning time, with comparable error in the recovered parameters. It is our hope that this technique will alleviate existing restrictions on the classes of probabilistic models that are practical for use.",
            "output": [
                "Minimum Probability Flow Learning"
            ]
        },
        {
            "id": "task1540-68ed2d7534b3466793a8662826beb3bd",
            "input": "We examine the meaning and the complexity of probabilistic logic programs that consist of a set of rules and a set of independent probabilistic facts (that is, programs based on Sato’s distribution semantics). We focus on two semantics, respectively based on stable and on well-founded models. We show that the semantics based on stable models (referred to as the “credal semantics”) produces sets of probability models that dominate infinitely monotone Choquet capacities; we describe several useful consequences of this result. We then examine the complexity of inference with probabilistic logic programs. We distinguish between the complexity of inference when a probabilistic program and a query are given (the inferential complexity), and the complexity of inference when the probabilistic program is fixed and the query is given (the query complexity, akin to data complexity as used in database theory). We obtain results on the inferential and query complexity for acyclic, stratified, and cyclic propositional and relational programs; complexity reaches various levels of the counting hierarchy and even exponential levels.",
            "output": [
                "On the Semantics and Complexity of Probabilistic Logic Programs"
            ]
        },
        {
            "id": "task1540-b59287e247d84eb8b185f797c5c3579f",
            "input": "Multi-instance multi-label (MIML) learning is a challenging problem in many aspects. Such learning approaches might be useful for many medical diagnosis applications including breast cancer detection and classification. In this study subset of digiPATH dataset (whole slide digital breast cancer histopathology images) are used for training and evaluation of six state-ofthe-art MIML methods. At the end, performance comparison of these approaches are given by means of effective evaluation metrics. It is shown that MIML-kNN achieve the best performance that is %65.3 average precision, where most of other methods attain acceptable results as well.",
            "output": [
                "Evaluation of Joint Multi-Instance Multi-Label Learning For Breast Cancer Diagnosis"
            ]
        },
        {
            "id": "task1540-0c011bfbb8b64048919d3b2497938cbc",
            "input": "We introduce a new approach for disfluency detection using a Bidirectional Long-Short Term Memory neural network (BLSTM). In addition to the word sequence, the model takes as input pattern match features that were developed to reduce sensitivity to vocabuary size in training, which lead to improved performance over the word sequence alone. The BLSTM takes advantage of explicit repair states in addition to the standard reparandum states. The final output leverages integer linear programming to incorporate constraints of disluency structure. In experiments on the Switchboard corpus, the model achieves state-of-the-art performance for both the standard disfluency detection task and the correction detection task. Analysis shows that the model has better detection of non-repetition disfluencies, which tend to be much harder to detect.",
            "output": [
                "Disfluency Detection using a Bidirectional LSTM"
            ]
        },
        {
            "id": "task1540-74652770153a4a1e9745c5563d9e2bb7",
            "input": "This paper presents an investigation of the entropy of the Telugu script. Since this script is syllabic, and not alphabetic, the computation of entropy is somewhat complicated.",
            "output": [
                "Entropy of Telugu"
            ]
        },
        {
            "id": "task1540-e0b3dafd0136493fbeaf8d50d208363d",
            "input": "In this paper we introduce RankPL, a modeling language that can be thought of as a qualitative variant of a probabilistic programming language with a semantics based on Spohn’s ranking theory. Broadly speaking, RankPL can be used to represent and reason about processes that exhibit uncertainty expressible by distinguishing “normal” from “surprising” events. RankPL allows (iterated) revision of rankings over alternative program states and supports various types of reasoning, including abduction and causal inference. We present the language, its denotational semantics, and a number of practical examples. We also discuss an implementation of RankPL that is available for download.",
            "output": [
                "RankPL: A Qualitative Probabilistic Programming Language"
            ]
        },
        {
            "id": "task1540-2a78bcf9e0254440a60afb1d99ceeed1",
            "input": "We create a transition-based dependency parser using a general purpose learning to search system. The result is a fast and accurate parser for many languages. Compared to other transition-based dependency parsing approaches, our parser provides similar statistical and computational performance with best-known approaches while avoiding various downsides including randomization, extra feature requirements, and custom learning algorithms. We show that it is possible to implement a dependency parser with an open-source learning to search library in about 300 lines of C++ code, while existing systems often requires several thousands of lines.",
            "output": [
                "Learning to Search for Dependencies"
            ]
        },
        {
            "id": "task1540-5f87dca6bead4cd98f5201eee8f7fb70",
            "input": "Knowledge base (KB) completion adds new facts to a KB by making inferences from existing facts, for example by inferring with high likelihood nationality(X,Y) from bornIn(X,Y). Most previous methods infer simple one-hop relational synonyms like this, or use as evidence a multi-hop relational path treated as an atomic feature, like bornIn(X,Z)→ containedIn(Z,Y). This paper presents an approach that reasons about conjunctions of multi-hop relations non-atomically, composing the implications of a path using a recurrent neural network (RNN) that takes as inputs vector embeddings of the binary relation in the path. Not only does this allow us to generalize to paths unseen at training time, but also, with a single high-capacity RNN, to predict new relation types not seen when the compositional model was trained (zero-shot learning). We assemble a new dataset of over 52M relational triples, and show that our method improves over a traditional classifier by 11%, and a method leveraging pre-trained embeddings by 7%.",
            "output": [
                "Compositional Vector Space Models for Knowledge Base Completion"
            ]
        },
        {
            "id": "task1540-5681dcf9cbae47b2b4fe6fc40bdd4a70",
            "input": "Sequence-to-sequence neural translation models learn semantic and syntactic relations between sentence pairs by optimizing the likelihood of the target given the source, i.e., p(y|x), an objective that ignores other potentially useful sources of information. We introduce an alternative objective function for neural MT that maximizes the mutual information between the source and target sentences, modeling the bi-directional dependency of sources and targets. We implement the model with a simple re-ranking method, and also introduce a decoding algorithm that increases diversity in the N-best list produced by the first pass. Applied to the WMT German/English and French/English tasks, the proposed models offers a consistent performance boost on both standard LSTM and attention-based neural MT architectures.",
            "output": [
                "Mutual Information and Diverse Decoding Improve Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-a9efca9a29224a669624ac4b6fd8357b",
            "input": "This paper presents Centre for Development of Advanced Computing Mumbai’s (CDACM) submission to the NLP Tools Contest on Part-Of-Speech (POS) Tagging For Code-mixed Indian Social Media Text (POSCMISMT) 2015 (collocated with ICON 2015). We submitted results for Hindi (hi), Bengali (bn), and Telugu (te) languages mixed with English (en). In this paper, we have described our approaches to the POS tagging techniques, we exploited for this task. Machine learning has been used to POS tag the mixed language text. For POS tagging, distributed representations of words in vector space (word2vec) for feature extraction and Log-linear models have been tried. We report our work on all three languages hi, bn, and te mixed with en.",
            "output": [
                "Experiments with POS Tagging Code-mixed Indian Social Media Text"
            ]
        },
        {
            "id": "task1540-d1445ebe52cf4840a6bbc66dc6181981",
            "input": "A key issue in statistics and machine learning is to automatically select the “right” model complexity, e.g., the number of neighbors to be averaged over in k nearest neighbor (kNN) regression or the polynomial degree in regression with polynomials. We suggest a novel principle the Loss Rank Principle (LoRP) for model selection in regression and classification. It is based on the loss rank, which counts how many other (fictitious) data would be fitted better. LoRP selects the model that has minimal loss rank. Unlike most penalized maximum likelihood variants (AIC, BIC, MDL), LoRP depends only on the regression functions and the loss function. It works without a stochastic noise model, and is directly applicable to any non-parametric regressor, like kNN.",
            "output": [
                "Model Selection with the Loss Rank Principle"
            ]
        },
        {
            "id": "task1540-88a0408a37324570a51a70998dc89a59",
            "input": "Direct quantile regression involves estimating a given quantile of a response variable as a function of input variables. We present a new framework for direct quantile regression where a Gaussian process model is learned, minimising the expected tilted loss function. The integration required in learning is not analytically tractable so to speed up the learning we employ the Expectation Propagation algorithm. We describe how this work relates to other quantile regression methods and apply the method on both synthetic and real data sets. The method is shown to be competitive with state of the art methods whilst allowing for the leverage of the full Gaussian process probabilistic framework.",
            "output": [
                "Direct Gaussian Process Quantile Regression  using Expectation Propagation"
            ]
        },
        {
            "id": "task1540-89f815b4c7ae44f4a68deda205128000",
            "input": "This paper is an empirical study of the distributed deep learning for a question answering subtask: answer selection. Comparison studies of SGD, MSGD, DOWNPOUR and EASGD/EAMSGD algorithms have been presented. Experimental results show that the message passing interface based distributed framework can accelerate the convergence speed at a sublinear scale. This paper demonstrates the importance of distributed training: with 120 workers, an 83x speedup is achievable and running time is decreased from 107.9 hours to 1.3 hours, which will benefit the productivity significantly.",
            "output": [
                "Distributed Deep Learning for Answer Selection"
            ]
        },
        {
            "id": "task1540-1cf961df4be04ff6b9e76698656b2bb5",
            "input": "This paper introduces conceptual relations tlrat syntlresizc utilitarian and logical con­ cepts, extending the logics of preference of [{escher. We define first, in the context of a possible­ worlds modeL constraint-dependent mea­ sures that quantify the relative quality of al­ temative solutions of reasoning problems or the relative desirabi lity of various policies in coutrol. decision, and planning problerns. \\Yc sho\\\\' tbat. these llH�asures rnay be inter­ preted as truth values in a multivaluecl logic ami propose rnechanisms for the representa­ tion of complex constraints as combinations of simpler restrictions. These extended log­ iced operations permit also the combination and Rggregation of goal-specific quality l11ea. ­ sures into global measnres of utility . We iden­ tify also relations that represent differential prd!'rcnces hdll\"ecn ill t ernativ<' solutions and rel<1tc thcrrr to t.IJ<• pr< ' viously defined desir­ ability tne<IS\\nes.",
            "output": [
                "TRUTH AS UTILITY: A CONCEPTUAL SYNTHESIS"
            ]
        },
        {
            "id": "task1540-cbc1663348eb4c9d80c7667f92cea2eb",
            "input": "Despite the huge spread and economical importance of configurable software systems, there is unsatisfactory support in utilizing the full potential of these systems with respect to finding performance-optimal configurations. Prior work on predicting the performance of software configurations suffered from either (a) requiring far too many sample configurations or (b) large variances in their predictions. Both these problems can be avoided using the WHAT spectral learner. WHAT’s innovation is the use of the spectrum (eigenvalues) of the distance matrix between the configurations of a configurable software system, to perform dimensionality reduction. Within that reduced configuration space, many closely associated configurations can be studied by executing only a few sample configurations. For the subject systems studied here, a few dozen samples yield accurate and stable predictors—less than 10 % prediction error, with a standard deviation of less than 2 %. When compared to the state of the art, WHAT (a) requires 2 to 10 times fewer samples to achieve similar prediction accuracies, and (b) its predictions are more stable (i.e., have lower standard deviation). Furthermore, we demonstrate that predictive models generated by WHAT can be used by optimizers to discover system configurations that closely approach the optimal performance.",
            "output": [
                "Faster Discovery of Faster System Configurations with Spectral Learning"
            ]
        },
        {
            "id": "task1540-6e9f96de0fb1439f9a1ccce598d77146",
            "input": "Several sparsity-constrained algorithms such as Orthogonal Matching Pursuit or the Frank-Wolfe algorithm with sparsity constraints work by iteratively selecting a novel atom to add to the current non-zero set of variables. This selection step is usually performed by computing the gradient and then by looking for the gradient component with maximal absolute entry. This step can be computationally expensive especially for large-scale and high-dimensional data. In this work, we aim at accelerating these sparsity-constrained optimization algorithms by exploiting the key observation that, for these algorithms to work, one only needs the coordinate of the gradient’s top entry. Hence, we introduce algorithms based on greedy methods and randomization approaches that aim at cheaply estimating the gradient and its top entry. Another of our contribution is to cast the problem of finding the best gradient entry as a best arm identification in a multi-armed bandit problem. Owing to this novel insight, we are able to provide a bandit-based algorithm that directly estimates the top entry in a very efficient way. Theoretical observations stating that the resulting inexact FrankWolfe or Orthogonal Matching Pursuit algorithms act, with high probability, similarly to their exact versions are also given. We have carried out several experiments showing that the greedy deterministic and the bandit approaches we propose can achieve an acceleration of an order of magnitude while being as efficient as the exact gradient when used in algorithms such as OMP, Frank-Wolfe or CoSaMP.",
            "output": [
                "Greedy methods, randomization approaches and multi-arm bandit algorithms for efficient sparsity-constrained optimization"
            ]
        },
        {
            "id": "task1540-4373e1458f57432db5419104cc9851e7",
            "input": "We examine three different algorithms that enable the collision certificate method from [1] to handle the case of a centralized multi-robot team. By taking advantage of symmetries in the configuration space of multi-robot teams, our methods can significantly reduce the number of collision checks vs. both [1] and standard collision checking implementations.",
            "output": [
                "Fast Collision Checking: From Single Robots to Multi-Robot Teams"
            ]
        },
        {
            "id": "task1540-80f79ba6719b4e29a23f13b51f366da3",
            "input": "Predictive coding (PDC) has recently attracted attention in the neuroscience and computing community as a candidate unifying paradigm for neuronal studies and artificial neural network implementations particularly targeted at unsupervised learning systems. The Mismatch Negativity (MMN) has also recently been studied in relation to PC and found to be a useful ingredient in neural predictive coding systems. Backed by the behavior of living organisms, such networks are particularly useful in forming spatio-temporal transitions and invariant representations of the input world. However, most neural systems still do not account for large number of synapses even though this has been shown by a few machine learning researchers as an effective and very important component of any neural system if such a system is to behave properly. Our major point here is that PDC systems with the MMN effect in addition to a large number of synapses can greatly improve any neural learning system's performance and ability to make decisions in the machine world. In this paper, we propose a novel bio-mimetic computational intelligence algorithm – the Deviant Learning Algorithm, inspired by these key ideas and functional properties of recent brain-cognitive discoveries and theories. We also show by numerical experiments guided by theoretical insights, how our invented bio-mimetic algorithm can achieve competitive predictions with even with very small problem specific data.",
            "output": [
                "Deviant Learning Algorithm: Learning Sparse Mismatch Representations through Time and Space"
            ]
        },
        {
            "id": "task1540-47c9024a36a74996ab54defeafa080d5",
            "input": "Although many machine learning algorithms involve learning subspaces with particular characteristics, optimizing a parameter matrix that is constrained to represent a subspace can be challenging. One solution is to use Riemannian optimization methods that enforce such constraints implicitly, leveraging the fact that the feasible parameter values form a manifold. While Riemannian methods exist for some specific problems, such as learning a single subspace, there are more general subspace constraints that offer additional flexibility when setting up an optimization problem but have not been formulated as a manifold. We propose the partitioned subspace (PS) manifold for optimizing matrices that are constrained to represent one or more subspaces. Each point on the manifold defines a partitioning of the input space into mutually orthogonal subspaces, where the number of partitions and their sizes are defined by the user. As a result, distinct groups of features can be learned by defining different objective functions for each partition. We illustrate the properties of the manifold through experiments on multiple dataset analysis and domain adaptation.",
            "output": [
                "A Manifold Approach to Learning Mutually Orthogonal Subspaces"
            ]
        },
        {
            "id": "task1540-76c68a88f27048c39ecb89c8f40d0a66",
            "input": "Deliberating on large or continuous state spaces have been long standing challenges in reinforcement learning. Temporal Abstraction have somewhat made this possible, but efficiently planing using temporal abstraction still remains an issue. Moreover using spatial abstractions to learn policies for various situations at once while using temporal abstraction models is an open problem. We propose here an efficient algorithm which is convergent under linear function approximation while planning using temporally abstract actions. We show how this algorithm can be used along with randomly generated option models over multiple time scales to plan agents which need to act real time. Using these randomly generated option models over multiple time scales are shown to reduce number of decision epochs required to solve the given task, hence effectively reducing the time needed for deliberation. ar X iv :1 70 3. 06 47 1v 1 [ cs .A I] 1 9 M ar 2 01 7",
            "output": [
                "Multi-Timescale, Gradient Descent, Temporal Difference Learning with Linear Options"
            ]
        },
        {
            "id": "task1540-0ff212b786be426db559bfe6fdb92a63",
            "input": "Automatic speech recognition (ASR) allows a natural and intuitive interface for robotic educational applications for children. However there are a number of challenges to overcome to allow such an interface to operate robustly in realistic settings, including the intrinsic difficulties of recognising child speech and high levels of background noise often present in classrooms. As part of the EU EASEL project we have provided several contributions to address these challenges, implementing our own ASR module for use in robotics applications. We used the latest deep neural network algorithms which provide a leap in performance over the traditional GMM approach, and apply data augmentation methods to improve robustness to noise and speaker variation. We provide a close integration between the ASR module and the rest of the dialogue system, allowing the ASR to receive in real-time the language models relevant to the current section of the dialogue, greatly improving the accuracy. We integrated our ASR module into an interactive, multimodal system using a small humanoid robot to help children learn about exercise and energy. The system was installed at a public museum event as part of a research study where 320 children (aged 3 to 14) interacted with the robot, with our ASR achieving 90% accuracy for fluent and near-fluent speech.",
            "output": [
                "Automatic recognition of child speech for robotic applications in noisy environments"
            ]
        },
        {
            "id": "task1540-4f8e3c6d231e4b079a988057384d06da",
            "input": "We present a tool, simplify-defun, that transforms the definition of a given function into a simplified definition of a new function, providing a proof checked by ACL2 that the old and new functions are equivalent. When appropriate it also generates termination and guard proofs for the new function. We explain how the tool is engineered so that these proofs will succeed. Examples illustrate its utility, in particular for program transformation in synthesis and verification.",
            "output": [
                "A Versatile, Sound Tool for Simplifying Definitions"
            ]
        },
        {
            "id": "task1540-647ae619e7f74c58819c6d822dcd29dc",
            "input": "In this paper we explore a class of belief update operators, in which the definition of the operator is compositional with respect to the sentence to be added. The goal is to provide an update operator that is intuitive, in that its definition is based on a recursive decomposition of the update sentence’s structure, and that may be reasonably implemented. In addressing update, we first provide a definition phrased in terms of the models of a knowledge base. While this operator satisfies a core group of the benchmark Katsuno-Mendelzon update postulates, not all of the postulates are satisfied. Other Katsuno-Mendelzon postulates can be obtained by suitably restricting the syntactic form of the sentence for update, as we show. In restricting the syntactic form of the sentence for update, we also obtain a hierarchy of update operators with Winslett’s standard semantics as the most basic interesting approach captured. We subsequently give an algorithm which captures this approach; in the general case the algorithm is exponential, but with some not-unreasonable assumptions we obtain an algorithm that is linear in the size of the knowledge base. Hence the resulting approach has much better complexity characteristics than other operators in some situations. We also explore other compositional belief change operators: erasure is developed as a dual operator to update; we show that a forget operator is definable in terms of update; and we give a definition of the compositional revision operator. We obtain that compositional revision, under the most natural definition, yields the Satoh revision operator.",
            "output": [
                "Compositional Belief Update"
            ]
        },
        {
            "id": "task1540-f53dd9215fe94f70835e4a8413ae4fd5",
            "input": "In this paper, we propose a novel neural approach for paraphrase generation. Conventional paraphrase generation methods either leverage hand-written rules and thesauri-based alignments, or use statistical machine learning principles. To the best of our knowledge, this work is the first to explore deep learning models for paraphrase generation. Our primary contribution is a stacked residual LSTM network, where we add residual connections between LSTM layers. This allows for efficient training of deep LSTMs. We experiment with our model and other state-of-the-art deep learning models on three different datasets: PPDB, WikiAnswers and MSCOCO. Evaluation results demonstrate that our model outperforms sequence to sequence, attention-based and bi-directional LSTM models on BLEU, METEOR, TER and an embedding-based sentence similarity metric.",
            "output": [
                "Neural Paraphrase Generation with Stacked Residual LSTM Networks"
            ]
        },
        {
            "id": "task1540-67435538f83d4adda62308b619f792a6",
            "input": "This paper proposes a new method for the K-armed dueling bandit problem, a variation on the regular K-armed bandit problem that offers only relative feedback about pairs of arms. Our approach extends the Upper Confidence Bound algorithm to the relative setting by using estimates of the pairwise probabilities to select a promising arm and applying Upper Confidence Bound with the winner as a benchmark. We prove a finite-time regret bound of order O(log t). In addition, our empirical results using real data from an information retrieval application show that it greatly outperforms the state of the art.",
            "output": [
                "Relative Upper Confidence Bound for the K-Armed Dueling Bandit Problem"
            ]
        },
        {
            "id": "task1540-0ef4cfd5a11c4acb859862d736b69dfa",
            "input": "The Complete Tang Poems (CTP) is the most important source to study Tang poems. We look into CTP with computational tools from specific linguistic perspectives, including distributional semantics and collocational analysis. From such quantitative viewpoints, we compare the usage of “wind” and “moon” in the poems of Li Bai (李白) and Du Fu (杜甫). Colors in poems function like sounds in movies, and play a crucial role in the imageries of poems. Thus, words for colors are studied, and “白” (bai2, white) is the main focus because it is the most frequent color in CTP. We also explore some cases of using colored words in antithesis(對仗) pairs that were central for fostering the imageries of the poems. CTP also contains useful historical information, and we extract person names in CTP to study the social networks of the Tang poets. Such information can then be integrated with the China Biographical Database of Harvard University.",
            "output": [
                "Color Aesthetics and Social Networks in Complete Tang Poems: Explorations and Discoveries"
            ]
        },
        {
            "id": "task1540-c2222454f0794c2ea2ace638642da20f",
            "input": "Sparse coding is a common approach to learning local features for object recognition. Recently, there has been an increasing interest in learning features from spatio-temporal, binocular, or other multi-observation data, where the goal is to encode the relationship between images rather than the content of a single image. We provide an analysis of multi-view feature learning, which shows that hidden variables encode transformations by detecting rotation angles in the eigenspaces shared among multiple image warps. Our analysis helps explain recent experimental results showing that transformation-specific features emerge when training complex cell models on videos. Our analysis also shows that transformation-invariant features can emerge as a by-product of learning representations of transformations.",
            "output": [
                "On multi-view feature learning"
            ]
        },
        {
            "id": "task1540-2ee66070b9744190b3f82d59bc54098c",
            "input": "This document describes the Odin framework, which is a domain-independent platform for developing rule-based event extraction models. Odin aims to be powerful (the rule language allows the modeling of complex syntactic structures) and robust (to recover from syntactic parsing errors, syntactic patterns can be freely mixed with surface, token-based patterns), while remaining simple (some domain grammars can be up and running in minutes), and fast (Odin processes over 100 sentences/second in a real-world domain with over 200 rules). Here we include a thorough definition of the Odin rule language, together with a description of the Odin API in the Scala language, which allows one to apply these rules to arbitrary texts. 1 ar X iv :1 50 9. 07 51 3v 1 [ cs .C L ] 2 4 Se p 20 15",
            "output": [
                "Description of the Odin Event Extraction Framework and Rule Language"
            ]
        },
        {
            "id": "task1540-1e79f937bffb49c5a6c6a7b0598eb256",
            "input": "We extend previous work on efficiently training linear models by applying stochastic updates to non-zero features only, lazily bringing weights current as needed. To date, only the closed form updates for the l1, l∞, and the rarely used l2 norm have been described. We extend this work by showing the proper closed form updates for the popular l22 and elastic net regularized models. We show a dynamic programming algorithm to calculate the proper elastic net update with only one constant-time subproblem computation per update. Our algorithm handles both fixed and decreasing learning rates and we derive the result for both stochastic gradient descent (SGD) and forward backward splitting (FoBoS). We empirically validate the algorithm, showing that on a bag-of-words dataset with 260, 941 features and 88 nonzero features on average per example, our method trains a logistic regression classifier with elastic net regularization 612 times faster than an otherwise identical implementation with dense updates.",
            "output": [
                "Efficient Elastic Net Regularization for Sparse Linear Models"
            ]
        },
        {
            "id": "task1540-af3fe5d254fc45f5a7a05713ab94bcb8",
            "input": "Question answering (QA) has been the subject of a resurgence over the past years. The said resurgence has led to a multitude of question answering (QA) systems being developed both by companies and research facilities. While a few components of QA systems get reused across implementations, most systems do not leverage the full potential of component reuse. Hence, the development of QA systems is currently still a tedious and time-consuming process. We address the challenge of accelerating the creation of novel or tailored QA systems by presenting a concept for a self-wiring approach to composing QA systems. Our approach will allow the reuse of existing, web-based QA systems or modules while developing new QA platforms. To this end, it will rely on QA modules being described using the Web Ontology Language. Based on these descriptions, our approach will be able to automatically compose QA systems using a data-driven approach automatically.",
            "output": [
                "Self-Wiring Question Answering Systems"
            ]
        },
        {
            "id": "task1540-a7dd754cb4434e98bf51806d8c687174",
            "input": "The semigraphoid closure of every couple of CI-statements (CI=conditional indepen­ dence) is a stochastic CI-model. As a con­ sequence of this result it is shown that ev­ ery probabilistically sound inference rule for CI-models, having at most two antecedents, is derivable from the semigraphoid inference rules. This justifies the use of semigraphoids as approximations of stochastic CI-models in probabilistic reasoning. The list of all 19 po­ tential dominant elements of the mentioned semigraphoid closure is given as a byproduct.",
            "output": [
                "Semigraphoids are Two-Antecedental Approximations of Stochastic Conditional Independence Models"
            ]
        },
        {
            "id": "task1540-b5e04af88cb648c1a06cfba5259e7ba5",
            "input": "We study the problem of learning classifiers with a fairness constraint, with three main contributions towards the goal of quantifying the problem’s inherent tradeoffs. First, we relate two existing fairness measures to cost-sensitive risks. Second, we show that for cost-sensitive classification and fairness measures, the optimal classifier is an instance-dependent thresholding of the class-probability function. Third, we show how the tradeoff between accuracy and fairness is determined by the alignment between the class-probabilities for the target and sensitive features. Underpinning our analysis is a general framework that casts the problem of learning with a fairness requirement as one of minimising the difference of two statistical risks.",
            "output": [
                "The cost of fairness in classification"
            ]
        },
        {
            "id": "task1540-723d09c98a1c43dcaf45585deb4a489c",
            "input": "Classical higher-order logic, when utilized as a meta-logic in which various other (classical and non-classical) logics can be shallowly embedded, is well suited for realising a universal logic reasoning approach. Universal logic reasoning in turn, as envisioned already by Leibniz, may support the rigorous formalisation and deep logical analysis of rational arguments within machines. A respective universal logic reasoning framework is described and a range of exemplary applications are discussed. In the future, universal logic reasoning in combination with appropriate, controlled forms of rational argumentation may serve as a communication layer between humans and intelligent machines. 1 Rational Argumentation – Communication Interface between Humans and Machines The ambition to understand, model and implement rational argumentation and universal logical reasoning independent of the human brain has a long tradition in the history of humankind. It reaches back at least to the prominent study of syllogistic arguments by Aristoteles. Today, with the event of increasingly intelligent computer technology, the question is more topical than ever: if humans and intelligent machines are supposed to amicably coexists, interact and collaborate, appropriate forms of communication between them are required. For example, machines should be able to depict, assess and defend their (options for) actions and decisions in a form that is accessible to human understanding and judgement. This will be crucial for achieving a reconcilable and socially accepted integration of intelligent machines into everyday (human) life. The communication means between machines and humans should ideally be based on human-level, rational argumentation, which since ages forms the fundament of our social, juridical and scientific processes. Current developments in artificial intelligence, in contrast, put a strong focus on statistical information, machine learning and subsymbolic representations, all of which are rather detached from human-level rational explanation, understanding and judgement. The challenge thus is to complement and enhance these human-unfriendly forms of reasoning and knowledge representation in todays artificial intelligence systems with suitable explanations amenable to human cognition, that is, rational arguments. Via exchange of rational arguments at human-intuitive level the much needed mutual understanding and acceptance between humans and intelligent machines can eventually be guaranteed. This is particularly relevant for the assessment of machine actions in terms of legal, ethical, moral, social and cultural norms purported by humans. But what formalisms are available that could serve as a most general basis for the modeling of human-level rational arguments in machines?",
            "output": [
                "Universal Reasoning, Rational Argumentation and Human-Machine Interaction"
            ]
        },
        {
            "id": "task1540-3cd453b302ca458b99dd31a52d74665a",
            "input": "Normalized random measures (NRMs) provide a broad class of discrete random measures that are often used as priors for Bayesian nonparametric models. Dirichlet process is a well-known example of NRMs. Most of posterior inference methods for NRM mixture models rely on MCMC methods since they are easy to implement and their convergence is well studied. However, MCMC often suffers from slow convergence when the acceptance rate is low. Tree-based inference is an alternative deterministic posterior inference method, where Bayesian hierarchical clustering (BHC) or incremental Bayesian hierarchical clustering (IBHC) have been developed for DP or NRM mixture (NRMM) models, respectively. Although IBHC is a promising method for posterior inference for NRMM models due to its efficiency and applicability to online inference, its convergence is not guaranteed since it uses heuristics that simply selects the best solution after multiple trials are made. In this paper, we present a hybrid inference algorithm for NRMM models, which combines the merits of both MCMC and IBHC. Trees built by IBHC outlines partitions of data, which guides Metropolis-Hastings procedure to employ appropriate proposals. Inheriting the nature of MCMC, our tree-guided MCMC (tgMCMC) is guaranteed to converge, and enjoys the fast convergence thanks to the effective proposals guided by trees. Experiments on both synthetic and realworld datasets demonstrate the benefit of our method.",
            "output": [
                "Tree-Guided MCMC Inference for Normalized Random Measure Mixture Models"
            ]
        },
        {
            "id": "task1540-b6426582452e446b897130bc4be6024b",
            "input": "The decision variable selection policy used by the most competitive CDCL (Conflict-Driven Clause Learning) SAT solvers is either VSIDS (Variable State Independent Decaying Sum) or its variants such as exponential version EVSIDS. The common characteristic of VSIDS and its variants is to make use of statistical information in the solving process, but ignore structure information of the problem. For this reason, this paper modifies the decision variable selection policy, and presents a SAT solving technique based on BCD (Blocked Clause Decomposition). Its basic idea is that a part of decision variables are selected by VSIDS heuristic, while another part of decision variables are selected by blocked sets that are obtained by BCD. Compared with the existing BCD-based technique, our technique is simple, and need not to reencode CNF formulas. SAT solvers for certified UNSAT track can apply also our BCD-based technique. Our experiments on application benchmarks demonstrate that the new variables selection policy based on BCD can increase the performance of SAT solvers such as abcdSAT. The solver with BCD solved an instance from the SAT Race 2015 that was not solved by any solver so far. This shows that in some cases, the heuristic based on structure information is more efficient than that based on statistical information.",
            "output": [
                "Improving SAT Solvers via Blocked Clause Decomposition"
            ]
        },
        {
            "id": "task1540-57482606565b46179b997fe5b79c4bae",
            "input": "In this paper, we present a preliminary work on an approach to fill the gap between logic-based argumentation and the numerous approaches to tackle the dynamics of abstract argumentation frameworks. Our idea is that, even when arguments and attacks are defined by means of a logical belief base, there may be some uncertainty about how accurate is the content of an argument, and so the presence (or absence) of attacks concerning it. We use enthymemes to illustrate this notion of uncertainty of arguments and attacks. Indeed, as argued in the literature, real arguments are often enthymemes instead of completely specified deductive arguments. This means that some parts of the pair (support, claim) may be missing because they are supposed to belong to some “common knowledge”, and then should be deduced by the agent which receives the enthymeme. But the perception that agents have of the common knowledge may be wrong, and then a first agent may state an enthymeme that her opponent is not able to decode in an accurate way. It is likely that the decoding of the enthymeme by the agent leads to mistaken attacks between this new argument and the existing ones. In this case, the agent can receive some information about attacks or arguments acceptance statuses which disagree with her argumentation framework. We exemplify a way to incorporate this new piece of information by means of existing works on the dynamics of abstract argumentation frameworks.",
            "output": [
                "Using Enthymemes to Fill the Gap between Logical Argumentation and Revision of Abstract Argumentation Frameworks"
            ]
        },
        {
            "id": "task1540-90de648a334749a2b9206c662ccfc609",
            "input": "Named Entity Recognition (NER) models for language L are typically trained using annotated data in that language. We study cross-lingual NER, where a model for NER in L is trained on a source language (or multiple source languages). We introduce a language independent method for NER, building on cross-lingual wikification, a technique that grounds words and phrases in a non-English text into English Wikipedia entries. Thus, mentions in text in any language can be described using a set of categories and FreeBase types, yielding, as we show, strong languageindependent features. With this insight, we propose an NER model that can be applied to all languages in Wikipedia. When trained on English, our model outperforms comparable approaches on the standard CoNLL datasets (Spanish, German, and Dutch) and also performs very well on low-resource languages (Turkish, Tagalog, Yoruba, Bengali, and Tamil) that have significantly smaller Wikipedia. Moreover, our methods allows us to train on multiple source languages, typically improving NER results on the target languages. Finally, we show that our languageindependent features can be used also to enhance monolingual NER systems, yielding improved results for all 9 languages.",
            "output": [
                "Cross-Lingual Named Entity Recognition via Wikification"
            ]
        },
        {
            "id": "task1540-cc2088f1c90f4534b929af259d2234ec",
            "input": "Sequence model learning algorithms typically maximize log-likelihood minus the norm of the model (or minimize Hamming loss + norm). In cross-lingual part-ofspeech (POS) tagging, our target language training data consists of sequences of sentences with word-by-word labels projected from translations in k languages for which we have labeled data, via word alignments. Our training data is therefore very noisy, and if Rademacher complexity is high, learning algorithms are prone to overfit. Norm-based regularization assumes a constant width and zero mean prior. We instead propose to use the k source language models to estimate the parameters of a Gaussian prior for learning new POS taggers. This leads to significantly better performance in multi-source transfer set-ups. We also present a drop-out version that injects (empirical) Gaussian noise during online learning. Finally, we note that using empirical Gaussian priors leads to much lower Rademacher complexity, and is superior to optimally weighted model interpolation. 1 Cross-lingual transfer learning of sequence models The people of the world speak about 6,900 different languages. Open-source off-the-shelf natural language processing (NLP) toolboxes like OpenNLP1 and CoreNLP2 cover only 6–7 languages, and we have sufficient labeled training data for inducing models for about 20–30 languages. In other words, supervised sequence learning algorithms are not sufficient to induce POS models for but a small minority of the world’s languages. What can we do for all the languages for which no training data is available? Unsupervised POS induction algorithms have methodological problems (in-sample evaluation, community-wide hyperparameter tuning, etc.), and performance is prohibitive of downstream applications. Some work on unsupervised POS tagging has assumed other resources such as tag dictionaries [Li et al., 2012], but such resources are also only available for a limited number of languages. In our experiments, we assume that no training data or tag dictionaries are available. Our only assumption is a bit of text translated into multiple languages, specifically, fragments of the Bible. We will use Bible data for annotation projection, as well as for learning cross-lingual word embeddings (§3). Unsupervised learning with typologically informed priors [Naseem et al., 2010] is an interesting approach to unsupervised POS induction that is more applicable to low-resource languages. Our work is related to this work, but we learn informed priors rather than stipulate them and combine these priors with annotation projection (learning from noisy labels) rather than unsupervised learning. https://opennlp.apache.org/ http://nlp.stanford.edu/software/corenlp.shtml",
            "output": [
                "Empirical Gaussian priors for cross-lingual transfer learning"
            ]
        },
        {
            "id": "task1540-7ee564a6d1194340b4ff3cdea2dfa1c2",
            "input": "Tang (618-907 AD) and Song (960-1279) dynasties are two very important periods in the development of Chinese literary. The majority forms of the poetry in Tang and Song were Shi (詩) and Ci (詞), respectively. Tang Shi and Song Ci established crucial foundations of the Chinese literature, and their influences in both literary works and daily lives of the Chinese communities last until today. Recognizing the importance of Tang Shi, a Chinese emperor of the Qing dynasty (1644-1912), Kangxi, ordered to compile a collection of Tang poems, Quan-Tang-Shi (QTS, 全唐詩). QTS contains nearly 50 thousand works of about 2200 poets. A similar effort for compiling a collection of Song Ci from the private sector began in the Ming dynasty (1368-1644), and achieved in a collection called Quan-Song-Ci (QSC, 全宋詞) in the early Republican period of China (ca. 1937). QSC contains around 20 thousand works of about 1330 poets. The exact statistics about QTS and QSC may vary slightly depending on the sources. In the past more than a thousand years, literary and linguistic researchers have had done a myriad of research about the poetry of the Tang and Song dynasties. Hence, it is beyond our capacity and not our objective to review the literature in this abstract. Traditional researchers studied and compared poetic works that were produced by different authors and in different time periods to produce insightful and invaluable analyses and commentaries. Most of the time, the researchers focused on the poems of selected poets. Even when computing supports become available, studying poems of specific poets is still an important and popular type of research in poetry. Software tools facilitate the analysis of poetry from a panoramic perspective, and may lead to applications that would be very challenging in the past. For instance, Zhou and his colleagues analyze the contents of collected couplets and Tang poems for creating couplets. Yan and his",
            "output": [
                "Quantitative Analyses of Chinese Poetry of Tang and Song Dynasties: Using Changing Colors and Innovative Terms as Examples"
            ]
        },
        {
            "id": "task1540-ba2d272edd1b4c22a19541d2970d0ef1",
            "input": "Convolutional neural networks excel in image recognition tasks, but this comes at the cost of high computational and memory complexity. To tackle this problem, [1] developed a tensor factorization framework to compress fully-connected layers. In this paper, we focus on compressing convolutional layers. We show that while the direct application of the tensor framework [1] to the 4-dimensional kernel of convolution does compress the layer, we can do better. We reshape the convolutional kernel into a tensor of higher order and factorize it. We combine the proposed approach with the previous work to compress both convolutional and fully-connected layers of a network and achieve 80× network compression rate with 1.1% accuracy drop on the CIFAR-10 dataset.",
            "output": [
                "Ultimate tensorization: compressing convolutional and FC layers alike"
            ]
        },
        {
            "id": "task1540-d2645add112e4272bb1a05319cdbdd78",
            "input": "We propose a technique to detect and generate patterns in a network of locally interacting dynamical systems. Central to our approach is a novel spatial superposition logic, whose semantics is defined over the quad-tree of a partitioned image. We show that formulas in this logic can be efficiently learned from positive and negative examples of several types of patterns. We also demonstrate that pattern detection, which is implemented as a model checking algorithm, performs very well for test data sets different from the learning sets. We define a quantitative semantics for the logic and integrate the model checking algorithm with particle swarm optimization in a computational framework for synthesis of parameters leading to desired patterns in reaction-diffusion systems.",
            "output": [
                "A Formal Methods Approach to Pattern Synthesis in Reaction Diffusion Systems"
            ]
        },
        {
            "id": "task1540-2f42915807bf408296dfe4776435a42b",
            "input": "Semantic segmentation tasks can be well modeled by Markov Random Field (MRF). This paper addresses semantic segmentation by incorporating high-order relations and mixture of label contexts into MRF. Unlike previous works that optimized MRFs using iterative algorithm, we solve MRF by proposing a Convolutional Neural Network (CNN), namely Deep Parsing Network (DPN), which enables deterministic end-to-end computation in a single forward pass. Specifically, DPN extends a contemporary CNN to model unary terms and additional layers are devised to approximate the mean field (MF) algorithm for pairwise terms. It has several appealing properties. First, different from the recent works that required many iterations of MF during back-propagation, DPN is able to achieve high performance by approximating one iteration of MF. Second, DPN represents various types of pairwise terms, making many existing models as its special cases. Furthermore, pairwise terms in DPN provide a unified framework to encode rich contextual information in high-dimensional data, such as images and videos. Third, DPN makes MF easier to be parallelized and speeded up, thus enabling efficient inference. DPN is thoroughly evaluated on standard semantic image/video segmentation benchmarks, where a single DPN model yields state-of-the-art segmentation accuracies on PASCAL VOC 2012, Cityscapes dataset and CamVid dataset.",
            "output": [
                "Deep Learning Markov Random Field for Semantic Segmentation"
            ]
        },
        {
            "id": "task1540-440379a2befd43589f92367caacca10b",
            "input": "Predicting protein secondary structure is a fundamental problem in protein structure prediction. Here we present a new supervised generative stochastic network (GSN) based method to predict local secondary structure with deep hierarchical representations. GSN is a recently proposed deep learning technique (Bengio & Thibodeau-Laufer, 2013) to globally train deep generative model. We present the supervised extension of GSN, which learns a Markov chain to sample from a conditional distribution, and applied it to protein structure prediction. To scale the model to full-sized, high-dimensional data, like protein sequences with hundreds of aminoacids, we introduce a convolutional architecture, which allows efficient learning across multiple layers of hierarchical representations. Our architecture uniquely focuses on predicting structured low-level labels informed with both low and high-level representations learned by the model. In our application this corresponds to labeling the secondary structure state of each amino-acid residue. We trained and tested the model on separate sets of non-homologous proteins sharing less than 30% sequence identity. Our model achieves 66.4% Q8 accuracy on the CB513 dataset, better than the previously reported best performance 64.9% (Wang et al., 2011) for this challenging secondary structure prediction problem.",
            "output": [
                "Deep Supervised and Convolutional Generative Stochastic Network for Protein Secondary Structure Prediction"
            ]
        },
        {
            "id": "task1540-80581f087cff4701acf6150360610305",
            "input": "Parameterized algorithms are a way to solve hard problems more efficiently, given that a specific parameter of the input is small. In this paper, we apply this idea to the field of answer set programming (ASP). To this end, we propose two kinds of graph representations of programs to exploit their treewidth as a parameter. Treewidth roughly measures to which extent the internal structure of a program resembles a tree. Our main contribution is the design of parameterized dynamic programming algorithms, which run in linear time if the treewidth and weights of the given program are bounded. Compared to previous work, our algorithms handle the full syntax of ASP. Finally, we report on an empirical evaluation that shows good runtime behaviour for benchmark instances of low treewidth, especially for counting answer sets.",
            "output": [
                "Answer Set Solving with Bounded Treewidth Revisited∗"
            ]
        },
        {
            "id": "task1540-3e7e764e5c6b451ca33e40a64f46731d",
            "input": "Clustering is a useful data exploratory method with its wide applicability in multiple fields. However, data clustering greatly relies on initialization of cluster centers that can result in large intra-cluster variance and dead centers, therefore leading to sub-optimal solutions. This paper proposes a novel variance based version of the conventional Moving K-Means (MKM) algorithm called Variance Based Moving K-Means (VMKM) that can partition data into optimal homogeneous clusters, irrespective of cluster initialization. The algorithm utilizes a novel distance metric and a unique data element selection criteria to transfer the selected elements between clusters to achieve low intra-cluster variance and subsequently avoid dead centers. Quantitative and qualitative comparison with various clustering techniques is performed on four datasets selected from image processing, bioinformatics, remote sensing and the stock market respectively. An extensive analysis highlights the superior performance of the proposed method over other techniques.",
            "output": [
                "Variance Based Moving K-Means Algorithm"
            ]
        },
        {
            "id": "task1540-dc1b08d6af8d4970a5b8e8c57680ceca",
            "input": "We propose a novel module, the reviewer module, to improve the encoder-decoder learning framework. The reviewer module is generic, and can be plugged into an existing encoder-decoder model. The reviewer module performs a number of review steps with attention mechanism on the encoder hidden states, and outputs a fact vector after each review step; the fact vectors are used as the input of the attention mechanism in the decoder. We show that the conventional encoderdecoders are a special case of our framework. Empirically, we show that our framework can improve over state-of-the-art encoder-decoder systems on the tasks of image captioning and source code captioning.",
            "output": [
                "Encode, Review, and Decode: Reviewer Module for Caption Generation"
            ]
        },
        {
            "id": "task1540-2c4b1009fa8a482189c1f25d4008af83",
            "input": "Sentence similarity is considered the basis of many natural language tasks such as information retrieval, question answering and text summarization. The semantic meaning between compared text fragments is based on the words’ semantic features and their relationships. This article reviews a set of word and sentence similarity measures and compares them on benchmark datasets. On the studied datasets, results showed that hybrid semantic measures perform better than both knowledge and corpus based measures. General Terms Semantic Similarity, Natural Language Processing, Computational Linguistics, Text Similarity",
            "output": [
                "A Comprehensive Comparative Study of Word and Sentence Similarity Measures"
            ]
        },
        {
            "id": "task1540-00f16a8f7150426b85a1244894f98879",
            "input": "This work introduces a probabilistic-based model for binary CSP that provides a fine grained analysis of its internal structure. Assuming that a domain modification could occur in the CSP, it shows how to express, in a predictive way, the probability that a domain value becomes inconsistent, then it express the expectation of the number of arc-inconsistent values in each domain of the constraint network. Thus, it express the expectation of the number of arc-inconsistent values for the whole constraint network. Next, it provides bounds for each of these three probabilistic indicators. Finally, a polytime algorithm, which propagates the probabilistic information, is presented.",
            "output": [
                "A Probabilistic-Based Model for Binary CSP"
            ]
        },
        {
            "id": "task1540-a8f4c643c0864d55a449ab35d5463a6c",
            "input": "For any deep computational processing of language we need evidences, and one such set of evidences is corpus. This paper describes the development of a textbased corpus for the Bishnupriya Manipuri language. A Corpus is considered as a building block for any language processing tasks. Due to the lack of awareness like other Indian languages, it is also studied less frequently. As a result the language still lacks a good corpus and basic language processing tools. As per our knowledge this is the first effort to develop a corpus for Bishnupriya Manipuri language. KeywordsCorpus, language, Bishnupriya Manipuri, word analysis, word frequency",
            "output": [
                "Towards The Development of a Bishnupriya Manipuri Corpus"
            ]
        },
        {
            "id": "task1540-f1fe773df89145c394a8bac8aa3eb804",
            "input": "Collaborative security initiatives are increasingly often ad-<lb>vocated to improve timeliness and effectiveness of threat mit-<lb>igation. Among these, collaborative predictive blacklisting<lb>(CPB) aims to forecast attack sources based on alerts con-<lb>tributed by multiple organizations that might be targeted in<lb>similar ways. Alas, CPB proposals thus far have only fo-<lb>cused on improving hit counts, but overlooked the impact of<lb>collaboration on false positives and false negatives. More-<lb>over, sharing threat intelligence often prompts important pri-<lb>vacy, confidentiality, and liability issues. In this paper, we<lb>first provide a comprehensive measurement analysis of two<lb>state-of-the-art CPB systems: one that uses a trusted cen-<lb>tral party to collect alerts [Soldo et al., Infocom’10] and a<lb>peer-to-peer one relying on controlled data sharing [Freudi-<lb>ger et al., DIMVA’15], studying the impact of collaboration<lb>on both correct and incorrect predictions. Then, we present<lb>a novel privacy-friendly approach that significantly improves<lb>over previous work, achieving a better balance of true and<lb>false positive rates, while minimizing information disclosure.<lb>Finally, we present an extension that allows our system to<lb>scale to very large numbers of organizations.",
            "output": [
                "Building and Measuring Privacy-Preserving Predictive Blacklists"
            ]
        },
        {
            "id": "task1540-5a6338f3e42d44d09f5dedcdbe6c55bc",
            "input": "This essay investigates the question of how the naive Bayes classifier and the support vector machine compare in their ability to forecast the Stock Exchange of Thailand. The theory behind the SVM and the naive Bayes classifier is explored. The algorithms are trained using data from the month of January 2010, extracted from the MarketWatch.com website. Input features are selected based on previous studies of the SET100 Index. The Weka 3 software is used to create models from the labeled training data. Mean squared error and proportion of correctly classified instances, and a number of other error measurements are the used to compare the two algorithms. This essay shows that these two algorithms are currently not advanced enough to accurately model the stock exchange. Nevertheless, the naive Bayes is better than the support vector machine at predicting the Stock Exchange of Thailand.",
            "output": [
                "How do the naive Bayes classifier and the Support Vector Machine compare in their ability to forecast the Stock Exchange of Thailand?"
            ]
        },
        {
            "id": "task1540-8e640ed3991f469c8e8b6ad234f2e286",
            "input": "We develop a framework for post model selection inference, via marginal screening, in linear regression. At the core of this framework is a result that characterizes the exact distribution of linear functions of the response y, conditional on the model being selected (“condition on selection” framework). This allows us to construct valid confidence intervals and hypothesis tests for regression coefficients that account for the selection procedure. In contrast to recent work in highdimensional statistics, our results are exact (non-asymptotic) and require no eigenvalue-like assumptions on the design matrix X. Furthermore, the computational cost of marginal regression, constructing confidence intervals and hypothesis testing is negligible compared to the cost of linear regression, thus making our methods particularly suitable for extremely large datasets. Although we focus on marginal screening to illustrate the applicability of the condition on selection framework, this framework is much more broadly applicable. We show how to apply the proposed framework to several other selection procedures including orthogonal matching pursuit, non-negative least squares, and marginal screening+Lasso.",
            "output": [
                "Exact Post Model Selection Inference for Marginal Screening"
            ]
        },
        {
            "id": "task1540-03898ba47e3542f0b6977310751a4348",
            "input": "In this paper we describe a deep network architecture that maps visual input to control actions for a robotic planar reaching task with 100% reliability in real-world trials. Our network is trained in simulation and fine-tuned with a limited number of real-world images. The policy search is guided by a kinematics-based controller (K-GPS), which works more effectively and efficiently than ε-Greedy. A critical insight in our system is the need to introduce a bottleneck in the network between the perception and control networks, and to initially train these networks independently.",
            "output": [
                "Vision-Based Reaching Using Modular Deep Networks: from Simulation to the Real World"
            ]
        },
        {
            "id": "task1540-4f4b2eb7477740deb2830dc93a0f95ad",
            "input": "Automatic image annotation is one of the most challenging problems in machine vision areas. The goal of this task is to predict number of keywords automatically for images captured in real data. Many methods are based on visual features in order to calculate similarities between image samples. But the computation cost of these approaches is very high. These methods require many training samples to be stored in memory. To lessen this burden, a number of techniques have been developed to reduce the number of features in a dataset. Manifold learning is a popular approach to nonlinear dimensionality reduction. In this paper, we investigate Diffusion maps manifold learning method for web image auto-annotation task. Diffusion maps manifold learning method is used to reduce the dimension of some visual features. Extensive experiments and analysis on NUS-WIDE-LITE web image dataset with different visual features show how this manifold learning dimensionality reduction method can be applied effectively to image annotation.",
            "output": [
                "WEB IMAGE ANNOTATION BY DIFFUSION MAPS MANIFOLD LEARNING ALGORITHM"
            ]
        },
        {
            "id": "task1540-5d3a835a52904da4b82dfc1df0379db4",
            "input": "e success of deep learning depends on nding an architecture to t the task. As deep learning has scaled up to more challenging tasks, the architectures have become dicult to design by hand. is paper proposes an automated method, CoDeepNEAT, for optimizing deep learning architectures through evolution. By extending existing neuroevolution methods to topology, components, and hyperparameters, this method achieves results comparable to best human designs in standard benchmarks in object recognition and language modeling. It also supports building a real-world application of automated image captioning on a magazine website. Given the anticipated increases in available computing power, evolution of deep networks is promising approach to constructing deep learning applications in the future.",
            "output": [
                "Evolving Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-540d4fd402ed419f910fec1d4e50ceda",
            "input": "In this paper, we consider the patient similarity matching problem over a cancer cohort of more than 220,000 patients. Our approach first leverages on Word2Vec framework to embed ICD codes into vector-valued representation. We then propose a sequential algorithm for case-control matching on this representation space of diagnosis codes. The novel practice of applying the sequential matching on the vector representation lifted the matching accuracy measured through multiple clinical outcomes. We reported the results on a large-scale dataset to demonstrate the effectiveness of our method. For such a large dataset where most clinical information has been codified, the new method is particularly relevant.",
            "output": [
                "Control Matching via Discharge Code Sequences"
            ]
        },
        {
            "id": "task1540-21db2a00cf774d3189599cc3c3b4d27b",
            "input": "Joint extraction of entities and relations is an important task in information extraction. To tackle this problem, we firstly propose a novel tagging scheme that can convert the joint extraction task to a tagging problem. Then, based on our tagging scheme, we study different end-toend models to extract entities and their relations directly, without identifying entities and relations separately. We conduct experiments on a public dataset produced by distant supervision method and the experimental results show that the tagging based methods are better than most of the existing pipelined and joint learning methods. What’s more, the end-to-end model proposed in this paper, achieves the best results on the public dataset.",
            "output": [
                "Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme"
            ]
        },
        {
            "id": "task1540-91a5e27770c74f8c9a61964568635f47",
            "input": "We introduce a powerful recurrent neural network based method for novelty detection to the application of detecting radio anomalies. This approach holds promise in significantly increasing the ability of naive anomaly detection to detect small anomalies in highly complex complexity multi-user radio bands. We demonstrate the efficacy of this approach on a number of common real over the air radio communications bands of interest and quantify detection performance in terms of probability of detection an false alarm rates across a range of interference to band power ratios and compare to baseline methods.",
            "output": [
                "Recurrent Neural Radio Anomaly Detection"
            ]
        },
        {
            "id": "task1540-1502f5bebc5a4f42afa73776aa59281e",
            "input": "The activation function of Deep Neural Networks (DNNs) has undergone many changes during the last decades. Since the advent of the well-known non-saturated Rectified Linear Unit (ReLU), many have tried to further improve the performance of the networks with more elaborate functions. Examples are the Leaky ReLU (LReLU) to remove zero gradients and Exponential Linear Unit (ELU) to reduce bias shift. In this paper, we introduce the Parametric ELU (PELU), an adaptive activation function that allows the DNNs to adopt different non-linear behaviors throughout the training phase. We contribute in three ways: (1) we show that PELU increases the network flexibility to counter vanishing gradient, (2) we provide a gradient-based optimization framework to learn the parameters of the function, and (3) we conduct several experiments on MNIST, CIFAR-10/100 and ImageNet with different network architectures, such as NiN, Overfeat, All-CNN, ResNet and Vgg, to demonstrate the general applicability of the approach. Our proposed PELU has shown relative error improvements of 4.45% and 5.68% on CIFAR10 and 100, and as much as 7.28% with only 0.0003% parameter increase on ImageNet, along with faster convergence rate in almost all test scenarios. We also observed that Vgg using PELU tended to prefer activations saturating close to zero, as in ReLU, except at last layer, which saturated near -2. These results suggest that varying the shape of the activations during training along with the other parameters helps to control vanishing gradients and bias shift, thus facilitating learning.",
            "output": [
                "Parametric Exponential Linear Unit for Deep Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-022b50d0c200416c944330bb71f5ed7b",
            "input": "Successive elimination of candidates is often a route to making manipulation intractable to compute. We prove that eliminating candidates does not necessarily increase the computational complexity of manipulation. However, for many voting rules used in practice, the computational complexity increases. For example, it is already known that it is NP-hard to compute how a single voter can manipulate the result of single transferable voting(the elimination version of plurality voting). We show here that it is NP-hard to compute how a single voter can manipulate the result of the elimination version of veto voting, of the closely related Coombs’ rule, and of the elimination versions of a general class of scoring rules.",
            "output": [
                "Eliminating the Weakest Link: Making Manipulation Intractable?"
            ]
        },
        {
            "id": "task1540-dc2fbcbf2b2e4ecbbc80b05e0ecec850",
            "input": "Network embedding (NE) is playing a critical role in network analysis, due to its ability to represent vertices with efficient low-dimensional embedding vectors. However, existing NE models aim to learn a fixed context-free embedding for each vertex, and neglect the diverse roles when interacting with other vertices. In this paper, we assume that one vertex usually shows different aspects when interacting with different neighbor vertices, and should own different embeddings respectively. Therefore, we present ContextAware Network Embedding (CANE), a novel NE model to address this issue. CANE learns context-aware embeddings for vertices with mutual attention mechanism and is expected to model the semantic relationships between vertices more precisely. In experiments, we compare our model with existing NE models on three real-world datasets. Experimental results shows that CANE achieves significant improvement than state-of-the-art methods on link prediction, and comparable performance on vertex classification.",
            "output": [
                "CANE: Context-Aware Network Embedding for Relation Modeling"
            ]
        },
        {
            "id": "task1540-89c65ec0227344169927ba4a750a9e28",
            "input": "We describe a question answering model that applies to both images and structured knowledge bases.The model uses natural language strings to automatically assemble neural networks from a collection of composable modules. Parameters for these modules are learned jointly with network-assembly parameters via reinforcement learning, with only (world, question, answer) triples as supervision. Our approach, which we term a dynamic neural module network, achieves state-of-the-art results on benchmark datasets in both visual and structured domains.",
            "output": [
                "Learning to Compose Neural Networks for Question Answering"
            ]
        },
        {
            "id": "task1540-7ae2de528d4241988eeb7a31db70a582",
            "input": "Recurrent neural network(RNN) has been broadly applied to natural language processing(NLP) problems. This kind of neural network is designed for modeling sequential data and has been testified to be quite efficient in sequential tagging tasks. In this paper, we propose to use bi-directional RNN with long short-term memory(LSTM) units for Chinese word segmentation, which is a crucial preprocess task for modeling Chinese sentences and articles. Classical methods focus on designing and combining hand-craft features from context, whereas bi-directional LSTM network(BLSTM) does not need any prior knowledge or pre-designing, and it is expert in keeping the contextual information in both directions. Experiment result shows that our approach gets stateof-the-art performance in word segmentation on both traditional Chinese datasets and simplified Chinese datasets.",
            "output": [
                "Bi-directional LSTM Recurrent Neural Network for Chinese Word Segmentation"
            ]
        },
        {
            "id": "task1540-7117175e9d524a83a092300a1bd28387",
            "input": "Motivated by concerns for user privacy, we design a steganographic system (“stegosystem”) that enables two users to exchange encrypted messages without an adversary detecting that such an exchange is taking place. We propose a new linguistic stegosystem based on a Long ShortTerm Memory (LSTM) neural network. We demonstrate our approach on the Twitter and Enron email datasets and show that it yields high-quality steganographic text while significantly improving capacity (encrypted bits per word) relative to the state-of-the-art.",
            "output": [
                "Generating Steganographic Text with LSTMs"
            ]
        },
        {
            "id": "task1540-247de27ed10f471681e2ed97d76be4d0",
            "input": "The Swiss avalanche bulletin is produced twice a day in four languages. Due to the lack of time available for manual translation, a fully automated translation system is employed, based on a catalogue of predefined phrases and predetermined rules of how these phrases can be combined to produce sentences. Because this catalogue of phrases is limited to a small sublanguage, the system is able to automatically translate such sentences from German into the target languages French, Italian and English without subsequent proofreading or correction. Having been operational for two winter seasons, we assess here the quality of the produced texts based on two different surveys where participants rated texts from real avalanche bulletins from both origins, the catalogue of phrases versus manually written and translated texts. With a mean recognition rate of 55%, users can hardly distinguish between the two types of texts, and give very similar ratings with respect to their language quality. Overall, the output from the catalogue system can be considered virtually equivalent to a text written by avalanche forecasters and then manually translated by professional translators. Furthermore, forecasters declared that all relevant situations were captured by the system with sufficient accuracy. Forecaster's working load did not change with the introduction of the catalogue: the extra time to find matching sentences is compensated by the fact that they no longer need to double-check manually translated texts. The reduction of daily translation costs is expected to offset the initial development costs within a few years.",
            "output": [
                "Fully automatic multi-language translation with a catalogue of phrases – successful employment for the Swiss avalanche bulletin"
            ]
        },
        {
            "id": "task1540-cc972eb250c3497ba4d581d9eb8e801b",
            "input": "Programs to solve so-called constraint problems are complex pieces of software which require many design decisions to be made more or less arbitrarily by the implementer. These decisions affect the performance of the finished solver significantly [13]. Once a design decision has been made, it cannot easily be reversed, although a different decision may be more appropriate for a particular problem. We investigate using machine learning to make these decisions automatically depending on the problem to solve with the alldifferent constraint as an example. Our system is capable of making non-trivial, multi-level decisions that improve over always making a default choice.",
            "output": [
                "Using machine learning to make constraint solver implementation decisions"
            ]
        },
        {
            "id": "task1540-8c74c95d7f2a42c8b1d98aa95c27e163",
            "input": "In this paper, we develop a framework for information theoretic learning based on infinitely divisible matrices. We formulate an entropy-like functional on positive definite matrices based on Renyi’s axiomatic definition of entropy and examine some key properties of this functional that lead to the concept of infinite divisibility. The proposed formulation avoids the plug in estimation of density and brings along the representation power of reproducing kernel Hilbert spaces. As an application example, we derive a supervised metric learning algorithm using a matrix based analogue to conditional entropy achieving results comparable with the state of the art.",
            "output": [
                "Information Theoretic Learning with Infinitely Divisible Kernels"
            ]
        },
        {
            "id": "task1540-ed3406b83ef24a7a97adc859d861fb5d",
            "input": "Special-purpose constraint propagation algorithms frequently make implicit use of short supports — by examining a subset of the variables, they can infer support (a justification that a variable-value pair may still form part of an assignment that satisfies the constraint) for all other variables and values and save substantial work – but short supports have not been studied in their own right. The two main contributions of this paper are the identification of short supports as important for constraint propagation, and the introduction of HaggisGAC, an efficient and effective general purpose propagation algorithm for exploiting short supports. Given the complexity of HaggisGAC, we present it as an optimised version of a simpler algorithm ShortGAC. Although experiments demonstrate the efficiency of ShortGAC compared with other general-purpose propagation algorithms where a compact set of short supports is available, we show theoretically and experimentally that HaggisGAC is even better. We also find that HaggisGAC performs better than GAC-Schema on full-length supports. We also introduce a variant algorithm HaggisGACStable, which is adapted to avoid work on backtracking and in some cases can be faster and have significant reductions in memory use. All the proposed algorithms are excellent for propagating disjunctions of constraints. In all experiments with disjunctions we found our algorithms to be faster than Constructive Or and GAC-Schema by at least an order of magnitude, and up to three orders of magnitude.",
            "output": [
                "Short and Long Supports for Constraint Propagation"
            ]
        },
        {
            "id": "task1540-a6f9ea0e8d254353acb1d359eca75811",
            "input": "Functional neuroimaging can measure the brain’s response to an external stimulus. It is used to perform brain mapping: identifying from these observations the brain regions involved. This problem can be cast into a linear supervised learning task where the neuroimaging data are used as predictors for the stimulus. Brain mapping is then seen as a support recovery problem. On functional MRI (fMRI) data, this problem is particularly challenging as i) the number of samples is small due to limited acquisition time and ii) the variables are strongly correlated. We propose to overcome these difficulties using sparse regression models over new variables obtained by clustering of the original variables. The use of randomization techniques, e.g. bootstrap samples, and clustering of the variables improves the recovery properties of sparse methods. We demonstrate the benefit of our approach on an extensive simulation study as well as two fMRI datasets.",
            "output": [
                "Small-sample brain mapping: sparse recovery on spatially correlated designs with randomization and clustering"
            ]
        },
        {
            "id": "task1540-e82b6e804ec74c509db7c0f4e7243195",
            "input": "A dictionary defines words in terms of other words. Definitions can tell you the meanings of words you don’t know, but only if you know the meanings of the defining words. How many words do you need to know (and which ones) in order to be able to learn all the rest from definitions? We reduced dictionaries to their “grounding kernels” (GKs), about 10% of the dictionary, from which all the other words could be defined. The GK words turned out to have psycholinguistic correlates: they were learned at an earlier age and more concrete than the rest of the dictionary. But one can compress still more: the GK turns out to have internal structure, with a strongly connected “kernel core” (KC) and a surrounding layer, from which a hierarchy of definitional distances can be derived, all the way out to the periphery of the full dictionary. These definitional distances, too, are correlated with psycholinguistic variables (age of acquisition, concreteness, imageability, oral and written frequency) and hence perhaps with the “mental lexicon” in each of our heads.",
            "output": [
                "Hierarchies in Dictionary Definition Space"
            ]
        },
        {
            "id": "task1540-c34e1eddc8e4445f90ca0418995cb3fb",
            "input": "Nanson’s and Baldwin’s voting rules select a winner by successively eliminating candidates with low Borda scores. We show that these rules have a number of desirable computational properties. In particular, with unweighted votes, it is NP-hard to manipulate either rule with one manipulator, whilst with weighted votes, it is NP-hard to manipulate either rule with a small number of candidates and a coalition of manipulators. As only a couple of other voting rules are known to be NP-hard to manipulate with a single manipulator, Nanson’s and Baldwin’s rules appear to be particularly resistant to manipulation from a theoretical perspective. We also propose a number of approximation methods for manipulating these two rules. Experiments demonstrate that both rules are often difficult to manipulate in practice. These results suggest that elimination style voting rules deserve further study.",
            "output": [
                "Manipulation of Nanson’s and Baldwin’s Rules"
            ]
        },
        {
            "id": "task1540-b1de149cef83451984a7545a25732f95",
            "input": "<lb>We study the problem of stochastic optimization for deep learning in the paral-<lb>lel computing environment under communication constraints. A new algorithm<lb>is proposed in this setting where the communication and coordination of work<lb>among concurrent processes (local workers), is based on an elastic force which<lb>links the parameters they compute with a center variable stored by the parameter<lb>server (master). The algorithm enables the local workers to perform more explo-<lb>ration, i.e. the algorithm allows the local variables to fluctuate further from the<lb>center variable by reducing the amount of communication between local workers<lb>and the master. We empirically demonstrate that in the deep learning setting, due<lb>to the existence of many local optima, allowing more exploration can lead to the<lb>improved performance. We propose synchronous and asynchronous variants of<lb>the new algorithm. We provide the stability analysis of the asynchronous vari-<lb>ant in the round-robin scheme and compare it with the more common parallelized<lb>method ADMM. We show that the stability of EASGD is guaranteed when a simple<lb>stability condition is satisfied, which is not the case for ADMM. We additionally<lb>propose the momentum-based version of our algorithm that can be applied in both<lb>synchronous and asynchronous settings. Asynchronous variant of the algorithm<lb>is applied to train convolutional neural networks for image classification on the<lb>CIFAR and ImageNet datasets. Experiments demonstrate that the new algorithm<lb>accelerates the training of deep architectures compared to DOWNPOUR and other<lb>common baseline approaches and furthermore is very communication efficient.",
            "output": [
                "Deep learning with Elastic Averaging SGD"
            ]
        },
        {
            "id": "task1540-38b1194cf0ed4ede90fa35ba66e04715",
            "input": "The follow the leader (FTL) algorithm, perhaps the simplest of all online learning algorithms, is known to perform well when the loss functions it is used on are convex and positively curved. In this paper we ask whether there are other “lucky” settings when FTL achieves sublinear, “small” regret. In particular, we study the fundamental problem of linear prediction over a non-empty convex, compact domain. Amongst other results, we prove that the curvature of the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for polytope domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL.",
            "output": [
                "Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities∗"
            ]
        },
        {
            "id": "task1540-6156e1681a154896ab270381293a3c53",
            "input": "Supervised (linear) embedding models like Wsabie [5] and PSI [1] have proven successful at ranking, recommendation and annotation tasks. However, despite being scalable to large datasets they do not take full advantage of the extra data due to their linear nature, and typically underfit. We propose a new class of models which aim to provide improved performance while retaining many of the benefits of the existing class of embedding models. Our new approach works by iteratively learning a linear embedding model where the next iteration’s features and labels are reweighted as a function of the previous iteration. We describe several variants of the family, and give some initial results. 1 (Supervised) Linear Embedding Models Standard linear embedding models are of the form: f(x, y) = xUV y = ∑",
            "output": [
                "Affinity Weighted Embedding"
            ]
        },
        {
            "id": "task1540-7b52bc54d7f042caa5d1bbf24bd54619",
            "input": "We propose a method combining relational-logic representations with neural network learning. A general lifted architecture, possibly reflecting some background domain knowledge, is described through relational rules which may be handcrafted or learned. The relational rule-set serves as a template for unfolding possibly deep neural networks whose structures also reflect the structures of given training or testing relational examples. Different networks corresponding to different examples share their weights, which co-evolve during training by stochastic gradient descent algorithm. The framework allows for hierarchical relational modeling constructs and learning of latent relational concepts through shared hidden layers weights corresponding to the rules. Discovery of notable relational concepts and experiments on 78 relational learning benchmarks demonstrate favorable performance of the method.",
            "output": [
                "Lifted Relational Neural Networks"
            ]
        },
        {
            "id": "task1540-5d61aab168334d4bb4d502eee98a75b5",
            "input": "This paper addresses the question of how language use affects community reaction to comments in online discussion forums, and the relative importance of the message vs. the messenger. A new comment ranking task is proposed based on community annotated karma in Reddit discussions, which controls for topic and timing of comments. Experimental work with discussion threads from six subreddits shows that the importance of different types of language features varies with the community of interest.",
            "output": [
                "Talking to the crowd: What do people react to in online discussions?"
            ]
        },
        {
            "id": "task1540-b143c3da71f448dca5cfe2f72651374d",
            "input": "Texts present coherent stories that have a particular theme or overall setting, for example science fiction or western. In this paper, we present a text generation method called rewriting that edits existing human-authored narratives to change their theme without changing the underlying story. We apply the approach to math word problems, where it might help students stay more engaged by quickly transforming all of their homework assignments to the theme of their favorite movie without changing the math concepts that are being taught. Our rewriting method uses a twostage decoding process, which proposes new words from the target theme and scores the resulting stories according to a number of factors defining aspects of syntactic, semantic, and thematic coherence. Experiments demonstrate that the final stories typically represent the new theme well while still testing the original math concepts, outperforming a number of baselines. We also release a new dataset of human-authored rewrites of math word problems in several themes.",
            "output": [
                "A Theme-Rewriting Approach for Generating Algebra Word Problems"
            ]
        },
        {
            "id": "task1540-edbc878b32a54849b37549eab4890430",
            "input": "Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledgebased inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the analogical properties of the embedded entities and relations. By formulating the learning objective in a differentiable fashion, our model enjoys both theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework.",
            "output": [
                "Analogical Inference for Multi-relational Embeddings"
            ]
        },
        {
            "id": "task1540-3ac962f640df49418ffe0d1c75ec7af9",
            "input": "In many domains it is desirable to assess the pref­ erences of users in a qualitative rather than quan­ titative way. Such representations of qualitative preference orderings form an important compo­ nent of automated decision tools. We propose a graphical representation of preferences that re­ flects conditional dependence and independence of preference statements under a ceteris paribus (all else being equal) interpretation. Such a rep­ resentation is often compact and arguably natural. We describe several search algorithms for domi­ nance testing based on this representation; these algorithms are quite effective, especially in spe­ cific network topologies, such as chainand tree­ structured networks, as well as polytrees.",
            "output": [
                "Reasoning With Conditional Ceteris Paribus Preference Statements"
            ]
        },
        {
            "id": "task1540-f9b919e89aba41debac58653b2dd29d7",
            "input": "Determining semantic textual similarity is a core research subject in natural language processing. Since vector-based models for sentence representation often use shallow information, capturing accurate semantics is difficult. By contrast, logical semantic representations capture deeper levels of sentence semantics, but their symbolic nature does not offer graded notions of textual similarity. We propose a method for determining semantic textual similarity by combining shallow features with features extracted from natural deduction proofs of bidirectional entailment relations between sentence pairs. For the natural deduction proofs, we use ccg2lambda, a higherorder automatic inference system, which converts Combinatory Categorial Grammar (CCG) derivation trees into semantic representations and conducts natural deduction proofs. Experiments show that our system was able to outperform other logicbased systems and that features derived from the proofs are effective for learning textual similarity.",
            "output": [
                "Determining Semantic Textual Similarity using Natural Deduction Proofs"
            ]
        },
        {
            "id": "task1540-8526ca693e51427e8ebe15e888568394",
            "input": "Visual question answering (VQA) has witnessed great progress since May, 2015 as a classic problem unifying visual and textual data into a system. Many enlightening VQA works explore deep into the image and question encodings and fusing methods, of which attention is the most effective and infusive mechanism. Current attention based methods focus on adequate fusion of visual and textual features, but lack the attention to where people focus to ask questions about the image. Traditional attention based methods attach a single value to the feature at each spatial location, which losses many useful information. To remedy these problems, we propose a general method to perform saliency-like pre-selection on overlapped region features by the interrelation of bidirectional LSTM (BiLSTM), and use a novel element-wise multiplication based attention method to capture more competent correlation information between visual and textual features. We conduct experiments on the large-scale COCO-VQA dataset and analyze the effectiveness of our model demonstrated by strong empirical results.",
            "output": [
                "Task-driven Visual Saliency and Attention-based Visual Question Answering"
            ]
        },
        {
            "id": "task1540-bada9d32be964727941883b8a0b59cdb",
            "input": "To cope with the high level of ambiguity faced in domains such as Computer<lb>Vision or Natural Language processing, robust prediction methods often search<lb>for a diverse set of high-quality candidate solutions or proposals. In structured<lb>prediction problems, this becomes a daunting task, as the solution space (image<lb>labelings, sentence parses, etc.) is exponentially large. We study greedy algo-<lb>rithms for finding a diverse subset of solutions in structured-output spaces by<lb>drawing new connections between submodular functions over combinatorial item<lb>sets and High-Order Potentials (HOPs) studied for graphical models. Specifically,<lb>we show via examples that when marginal gains of submodular diversity functions<lb>allow structured representations, this enables efficient (sub-linear time) approxi-<lb>mate maximization by reducing the greedy augmentation step to inference in a<lb>factor graph with appropriately constructed HOPs. We discuss benefits, trade-<lb>offs, and show that our constructions lead to significantly better proposals.",
            "output": [
                "Submodular meets Structured: Finding Diverse Subsets in Exponentially-Large Structured Item Sets"
            ]
        },
        {
            "id": "task1540-689114d1eb4a4796b9b4cf0db6ea6c28",
            "input": "Time series is attracting more attention across statistics, machine learning and pattern recognition as it appears widely in both industry and academia, but few advances has been achieved in effective time series visualization due to its temporal dimensionality and complex dynamics. Inspired by recent effort on using network metrics to characterize time series for classification, we present an approach to visualize time series as complex networks based on first order Markov process and temporal ordering. Different to classical bar charts, line plots and other statistics based graph, our approach delivers more intuitive visualization that better preserves both the temporal dependency and frequency structures. It provides a natural inverse operation to map the graph back to time series, making it possible to use graph statistics to characterize time series for better visual exploration and statistical analysis. Our experimental results suggest the effectiveness on various tasks such as system identification, classification and anomaly detection on both synthetic and the real time series data.",
            "output": [
                "Encoding Temporal Markov Dynamics in Graph for Time Series Visualization"
            ]
        },
        {
            "id": "task1540-520416eb622e4ee6959ce7499f112d02",
            "input": "The article deals with the issue of modification of metric classification algorithms. In particular, it studies the algorithm k-Nearest Neighbours for its application to sequential data. A method of generalization of metric classification algorithms is proposed. As a part of it, there has been developed an algorithm for solving the problem of classification and labelling of sequential data. The advantages of the developed algorithm of classification in comparison with the existing one are also discussed in the article. There is a comparison of the effectiveness of the proposed algorithm with the algorithm of CRF in the task of chunking in the open data set CoNLL2000.",
            "output": [
                "Generalization of metric classification algorithms for sequences classification and labelling"
            ]
        },
        {
            "id": "task1540-3396e9a8972c40ccba1f8f4f7a4c4c3d",
            "input": "This is a machine learning application paper involving big data. We present high-accuracy prediction methods of rare events in semi-structured machine log files, which are produced at high velocity and high volume by NORC’s computer-assisted telephone interviewing (CATI) network for conducting surveys. We judiciously apply natural language processing (NLP) techniques and data-mining strategies to train effective learning and prediction models for classifying uncommon error messages in the log—without access to source code, updated documentation or dictionaries. In particular, our simple but effective approach of features preallocation for learning from imbalanced data coupled with naive Bayes classifiers can be conceivably generalized to supervised or semisupervised learning and prediction methods for other critical events such as cyberattack detection.",
            "output": [
                "Machine Learning for Machine Data from a CATI Network"
            ]
        },
        {
            "id": "task1540-8e5c72a9cfa2432fab9e05a1388cc32f",
            "input": "Mental health forums are online communities where people express their issues and seek help from moderators and other users. In such forums, there are often posts with severe content indicating that the user is in acute distress and there is a risk of attempted self-harm. Moderators need to respond to these severe posts in a timely manner to prevent potential selfharm. However, the large volume of daily posted content makes it difficult for the moderators to locate and respond to these critical posts. We present a framework for triaging user content into four severity categories which are defined based on indications of self-harm ideation. Our models are based on a feature-rich classification framework which includes lexical, psycholinguistic, contextual and topic modeling features. Our approaches improve the state of the art in triaging the content severity in mental health forums by large margins (up to 17% improvement over the F-1 scores). Using the proposed model, we analyze the mental state of users and we show that overall, long-term users of the forum demonstrate a decreased severity of risk over time. Our analysis on the interaction of the moderators with the users further indicates that without an automatic way to identify critical content, it is indeed challenging for the moderators to provide timely response to the users in",
            "output": [
                "Triaging Content Severity in Online Mental Health Forums∗"
            ]
        },
        {
            "id": "task1540-3232e505472d4c3bbac4330f7f9ce344",
            "input": "In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model for generating novel image captions. It directly models the probability distribution of generating a word given previous words and an image. Image captions are generated according to this distribution. The model consists of two sub-networks: a deep recurrent neural network for sentences and a deep convolutional network for images. These two sub-networks interact with each other in a multimodal layer to form the whole m-RNN model. The effectiveness of our model is validated on four benchmark datasets (IAPR TC-12, Flickr 8K, Flickr 30K and MS COCO). Our model outperforms the state-of-the-art methods. In addition, we apply the m-RNN model to retrieval tasks for retrieving images or sentences, and achieves significant performance improvement over the state-of-the-art methods which directly optimize the ranking objective function for retrieval. The project page of this work is: www.stat.ucla.edu/ ̃junhua.mao/m-RNN.html. 1",
            "output": [
                "DEEP CAPTIONING WITH MULTIMODAL RECURRENT NEURAL NETWORKS (M-RNN)"
            ]
        },
        {
            "id": "task1540-67cea3dc682248768099fff2b7e65d56",
            "input": "We present a self-training approach to unsupervised dependency parsing that reuses existing supervised and unsupervised parsing algorithms. Our approach, called ‘iterated reranking’ (IR), starts with dependency trees generated by an unsupervised parser, and iteratively improves these trees using the richer probability models used in supervised parsing that are in turn trained on these trees. Our system achieves 1.8% accuracy higher than the stateof-the-part parser of Spitkovsky et al. (2013) on the WSJ corpus.",
            "output": [
                "Unsupervised Dependency Parsing: Let’s Use Supervised Parsers"
            ]
        },
        {
            "id": "task1540-3800588ab60e4836b41c919c5bca44db",
            "input": "This paper presents an empirical study of two widely-used sequence prediction models, Conditional Random Fields (CRFs) and Long Short-Term Memory Networks (LSTMs), on two fundamental tasks for Vietnamese text processing, including part-of-speech tagging and named entity recognition. We show that a strong lower bound for labeling accuracy can be obtained by relying only on simple word-based features with minimal handcrafted feature engineering, of 90.65% and 86.03% performance scores on the standard test sets for the two tasks respectively. In particular, we demonstrate empirically the surprising efficiency of word embeddings in both of the two tasks, with both of the two models. We point out that the state-of-the-art LSTMs model does not always outperform significantly the traditional CRFs model, especially on moderate-sized data sets. Finally, we give some suggestions and discussions for efficient use of sequence labeling models in practical applications.",
            "output": [
                "An Empirical Study of Discriminative Sequence Labeling Models for Vietnamese Text Processing"
            ]
        },
        {
            "id": "task1540-4fc419c4352e44e2bff5e53132cdedde",
            "input": "Variational inference provides a powerful tool for approximate probabilistic inference on complex, structured models. Typical variational inference methods, however, require to use inference networks with computationally tractable probability density functions. This largely limits the design and implementation of variational inference methods. We consider wild variational inference methods that do not require tractable density functions on the inference networks, and hence can be applied in more challenging cases. As an example of application, we treat stochastic gradient Langevin dynamics (SGLD) as an inference network, and use our methods to automatically adjust the step sizes of SGLD, yielding significant improvement over the hand-designed step size schemes.",
            "output": [
                "TWO METHODS FOR WILD VARIATIONAL INFERENCE"
            ]
        },
        {
            "id": "task1540-658b47d86c754477b66413a2aa160f22",
            "input": "Sleep stages pattern provides important clues in diagnosing the presence of sleep disorder. By analyzing sleep stages pattern and extracting its features from EEG, EOG, and EMG signals, we can classify sleep stages. This study presents a novel classification model for predicting sleep stages with a high accuracy. The main idea is to combine the generative capability of Deep Belief Network (DBN) with a discriminative ability and sequence pattern recognizing capability of Long Short-term Memory (LSTM). We use DBN that is treated as an automatic higher level features generator. The input to DBN is 28 ”handcrafted” features as used in previous sleep stages studies. We compared our method with other techniques which combined DBN with Hidden Markov Model (HMM).In this study, we exploit the sequence or time series characteristics of sleep dataset. To the best of our knowledge, most of the present sleep analysis from polysomnogram relies only on single instanced label (nonsequence) for classification. In this study, we used two datasets: an open data set that is treated as a benchmark; the other dataset is our sleep stages dataset (available for download) to verify the results further. Our experiments showed that the combination of DBN with LSTM gives better overall accuracy 98.75% (Fscore=0.9875) for benchmark dataset and 98.94% (Fscore=0.9894) for MKG dataset. This result is better than the state of the art of sleep stages classification that was 91.31%i. Keywords— sleep stages classification, long short term memory, deep belief network, deep learning",
            "output": [
                "Combining Generative and Discriminative Neural Networks for Sleep Stages Classification"
            ]
        },
        {
            "id": "task1540-66ba3e4a1f624745952497574af3cc95",
            "input": "In supervised binary hashing, one wants to learn a function that maps a high-dimensional feature vector to a vector of binary codes, for application to fast image retrieval. This typically results in a difficult optimization problem, nonconvex and nonsmooth, because of the discrete variables involved. Much work has simply relaxed the problem during training, solving a continuous optimization, and truncating the codes a posteriori. This gives reasonable results but is quite suboptimal. Recent work has tried to optimize the objective directly over the binary codes and achieved better results, but the hash function was still learned a posteriori, which remains suboptimal. We propose a general framework for learning hash functions using affinity-based loss functions that uses auxiliary coordinates. This closes the loop and optimizes jointly over the hash functions and the binary codes so that they gradually match each other. The resulting algorithm can be seen as a corrected, iterated version of the procedure of optimizing first over the codes and then learning the hash function. Compared to this, our optimization is guaranteed to obtain better hash functions while being not much slower, as demonstrated experimentally in various supervised datasets. In addition, our framework facilitates the design of optimization algorithms for arbitrary types of loss and hash functions.",
            "output": [
                "Optimizing affinity-based binary hashing using auxiliary coordinates"
            ]
        },
        {
            "id": "task1540-c234ca3491d14cfc829edd02db16a9f8",
            "input": "Abstract This paper reconsiders the problem of the absent-minded driver who must choose between alternatives with different payoff with imperfect recall and varying degrees of knowledge of the system. The classical absent-minded driver problem represents the case with limited information and it has bearing on the general area of communication and learning, social choice, mechanism design, auctions, theories of knowledge, belief, and rational agency. Within the framework of extensive games, this problem has applications to many artificial intelligence scenarios. It is obvious that the performance of the agent improves as information available increases. It is shown that a non-uniform assignment strategy for successive choices does better than a fixed probability strategy. We consider both classical and quantum approaches to the problem. We argue that the superior performance of quantum decisions with access to entanglement cannot be fairly compared to a classical algorithm. If the cognitive systems of agents are taken to have access to quantum resources, or have a quantum mechanical basis, then that can be leveraged into superior performance.",
            "output": [
                "The Absent-Minded Driver Problem Redux"
            ]
        },
        {
            "id": "task1540-7d019255d8fe4b2dbf44084e0f798005",
            "input": "Parsimony, including sparsity and low rank, has been shown to successfully model data in numerous machine learning and signal processing tasks. Traditionally, such modeling approaches rely on an iterative algorithm that minimizes an objective function with parsimony-promoting terms. The inherently sequential structure and data-dependent complexity and latency of iterative optimization constitute a major limitation in many applications requiring real-time performance or involving large-scale data. Another limitation encountered by these modeling techniques is the difficulty of their inclusion in discriminative learning scenarios. In this work, we propose to move the emphasis from the model to the pursuit algorithm, and develop a process-centric view of parsimonious modeling, in which a learned deterministic fixed-complexity pursuit process is used in lieu of iterative optimization. We show a principled way to construct learnable pursuit process architectures for structured sparse and robust low rank models, derived from the iteration of proximal descent algorithms. These architectures learn to approximate the exact parsimonious representation at a fraction of the complexity of the standard optimization methods. We also show that appropriate training regimes allow to naturally extend parsimonious models to discriminative settings. State-ofthe-art results are demonstrated on several challenging problems in image and audio processing with several orders of magnitude speedup compared to the exact optimization algorithms. ∗P. Sprechmann and G. Sapiro are with the Department of Electrical and Computer Engineering, Duke University, Durham 27708, USA. Email: pablo.sprechmann@duke.edu, guillermo.sapiro@duke.edu. †A. M. Bronsteind is with School of Electrical Engineering, Tel Aviv University, Tel Aviv 69978, Israel.Email: bron@eng.tau.ac.il. ‡Work partially supported by NSF, ONR, NGA, DARPA, AFOSR, ARO, and BSF. 1 ar X iv :1 21 2. 36 31 v1 [ cs .L G ] 1 4 D ec 2 01 2",
            "output": [
                "Learning Efficient Sparse and Low Rank Models"
            ]
        },
        {
            "id": "task1540-9b277def86cc48bfb46560fd9c543dc1",
            "input": "We present a practical, differentially private algorithm for answering a large number of queries on high dimensional datasets. Like all algorithms for this task, ours necessarily has worst-case complexity exponential in the dimension of the data. However, our algorithm packages the computationally hard step into a concisely defined integer program, which can be solved non-privately using standard solvers. We prove accuracy and privacy theorems for our algorithm, and then demonstrate experimentally that our algorithm performs well in practice. For example, our algorithm can efficiently and accurately answer millions of queries on the Netflix dataset, which has over 17,000 attributes; this is an improvement on the state of the art by multiple orders of magnitude.",
            "output": [
                "Dual Query: Practical Private Query Release for High Dimensional Data"
            ]
        },
        {
            "id": "task1540-0faeab4be6c347adbe0b3dae4bf2b5e2",
            "input": "We present a method for inducing new dialogue systems from very small amounts of unannotated dialogue data, showing how word-level exploration using Reinforcement Learning (RL), combined with an incremental and semantic grammar Dynamic Syntax (DS) allows systems to discover, generate, and understand many new dialogue variants. The method avoids the use of expensive and time-consuming dialogue act annotations, and supports more natural (incremental) dialogues than turn-based systems. Here, language generation and dialogue management are treated as a joint decision/optimisation problem, and the MDP model for RL is constructed automatically. With an implemented system, we show that this method enables a wide range of dialogue variations to be automatically captured, even when the system is trained from only a single dialogue. The variants include questionanswer pairs, overand under-answering, selfand other-corrections, clarification interaction, split-utterances, and ellipsis. This generalisation property results from the structural knowledge and constraints present within the DS grammar, and highlights some limitations of recent systems built using machine learning techniques only.",
            "output": [
                "Bootstrapping incremental dialogue systems: using linguistic knowledge to learn from minimal data"
            ]
        },
        {
            "id": "task1540-aad47cd34e6f4956b343636a055b2ce3",
            "input": "In this paper, we propose the distributed tree kernels (DTK) as a novel method to reduce time and space complexity of tree kernels. Using a linear complexity algorithm to compute vectors for trees, we embed feature spaces of tree fragments in low-dimensional spaces where the kernel computation is directly done with dot product. We show that DTKs are faster, correlate with tree kernels, and obtain a statistically similar performance in two natural language processing tasks.",
            "output": [
                "Distributed Tree Kernels"
            ]
        },
        {
            "id": "task1540-ced13fb2be94465a80303086130f6715",
            "input": "Potential games and decentralised partially observable MDPs (Dec–POMDPs) are two commonly used models of multi–agent interaction, for static optimisation and sequential decision– making settings, respectively. In this paper we introduce filtered fictitious play for solving repeated potential games in which each player’s observations of others’ actions are perturbed by random noise, and use this algorithm to construct an online learning method for solving Dec–POMDPs. Specifically, we prove that noise in observations prevents standard fictitious play from converging to Nash equilibrium in potential games, which also makes fictitious play impractical for solving Dec–POMDPs. To combat this, we derive filtered fictitious play, and provide conditions under which it converges to a Nash equilibrium in potential games with noisy observations. We then use filtered fictitious play to construct a solver for Dec–POMDPs, and demonstrate our new algorithm’s performance in a box pushing problem. Our results show that we consistently outperform the state–of–the–art Dec– POMDP solver by an average of 100% across the range of noise in the observation function.",
            "output": [
                "Filtered Fictitious Play for Perturbed Observation Potential Games and Decentralised POMDPs"
            ]
        },
        {
            "id": "task1540-669ceed5aa8c44b9963f9047c57263f4",
            "input": "Lifting attempts to speedup probabilistic inference by exploiting symmetries in the model. Exact lifted inference methods, like their propositional counterparts, work by recursively decomposing the model and the problem. In the propositional case, there exist formal structures, such as decomposition trees (dtrees), that represent such a decomposition and allow us to determine the complexity of inference a priori. However, there is currently no equivalent structure nor analogous complexity results for lifted inference. In this paper, we introduce FO-dtrees, which upgrade propositional dtrees to the first-order level. We show how these trees can characterize a lifted inference solution for a probabilistic logical model (in terms of a sequence of lifted operations), and make a theoretical analysis of the complexity of lifted inference in terms of the novel notion of lifted width for the tree.",
            "output": [
                "First-Order Decomposition Trees"
            ]
        },
        {
            "id": "task1540-2434223fa7f24155bf504076ffff4974",
            "input": "We introduce a novel framework for an approximate recovery of data matrices which are low-rank on graphs, from sampled measurements. The rows and columns of such matrices belong to the span of the first few eigenvectors of the graphs constructed between their rows and columns. We leverage this property to recover the non-linear low-rank structures efficiently from sampled data measurements, with a low cost (linear in n). First, a Resrtricted Isometry Property (RIP) condition is introduced for efficient uniform sampling of the rows and columns of such matrices based on the cumulative coherence of graph eigenvectors. Secondly, a state-of-the-art fast low-rank recovery method is suggested for the sampled data. Finally, several efficient, parallel and parameter-free decoders are presented along with their theoretical analysis for decoding the low-rank and cluster indicators for the full data matrix. Thus, we overcome the computational limitations of the standard linear low-rank recovery methods for big datasets. Our method can also be seen as a major step towards efficient recovery of nonlinear low-rank structures. For a matrix of size n × p, on a single core machine, our method gains a speed up of p/k over Robust Principal Component Analysis (RPCA), where k p is the subspace dimension. Numerically, we can recover a low-rank matrix of size 10304×1000, 100 times faster than Robust PCA.",
            "output": [
                "Compressive PCA for Low-Rank Matrices on Graphs"
            ]
        },
        {
            "id": "task1540-65d425dcca0d41da917e66b9355c1f82",
            "input": "We apply the principle of maximum entropy to select a unique joint probability distribution from the set of all joint probability distributions speci­ fied by a credal network. In detail, we start by showing that the unique joint distribution of a Bayesian tree coincides with the maximum en­ tropy model of its conditional distributions. This result, however, does not hold anymore for gen­ eral Bayesian networks. We thus present a new kind of maximum entropy models, which are computed sequentially. We then show that for all general Bayesian networks, the sequential max­ imum entropy model coincides with the unique joint distribution. Moreover, we apply the new principle of sequential maximum entropy to in­ terval Bayesian networks and more generally to credal networks. We especially show that this ap­ plication is equivalent to a number of small local entropy maximizations.",
            "output": [
                "Credal Networks under Maximum Entropy"
            ]
        },
        {
            "id": "task1540-e4d878550127431dbcc4a779cad8f55b",
            "input": "We evaluate a semantic parser based on a character-based sequence-to-sequence model in the context of the SemEval2017 shared task on semantic parsing for AMRs. With data augmentation, super characters, and POS-tagging we gain major improvements in performance compared to a baseline character-level model. Although we improve on previous character-based neural semantic parsing models, the overall accuracy is still lower than a state-of-the-art AMR parser. An ensemble combining our neural semantic parser with an existing, traditional parser, yields a small gain in performance.",
            "output": [
                "The Meaning Factory at SemEval-2017 Task 9: Producing AMRs with Neural Semantic Parsing"
            ]
        },
        {
            "id": "task1540-6f7ff285d1f3451fa4977e84061bf44f",
            "input": "The theory of actual causality, defined by Halpern and Pearl, and its quantitative measure – the degree of responsibility – was shown to be extremely useful in various areas of computer science due to a good match between the results it produces and our intuition. In this paper, I describe the applications of causality to formal verification, namely, explanation of counter-examples, refinement of coverage metrics, and symbolic trajectory evaluation. I also briefly discuss recent applications of causality to legal reasoning.",
            "output": [
                "Causality and Responsibility for Formal Verification and Beyond"
            ]
        },
        {
            "id": "task1540-9f6bd4d6092f44b69baf1659ad38b803",
            "input": "Lifelong reinforcement learning provides a promising framework for developing versatile agents that can accumulate knowledge over a lifetime of experience and rapidly learn new tasks by building upon prior knowledge. However, current lifelong learning methods exhibit non-vanishing regret as the amount of experience increases, and include limitations that can lead to suboptimal or unsafe control policies. To address these issues, we develop a lifelong policy gradient learner that operates in an adversarial setting to learn multiple tasks online while enforcing safety constraints on the learned policies. We demonstrate, for the first time, sublinear regret for lifelong policy search, and validate our algorithm on several benchmark dynamical systems and an application to quadrotor control.",
            "output": [
                "Safe Policy Search for Lifelong Reinforcement Learning with Sublinear Regret"
            ]
        },
        {
            "id": "task1540-9c95be2258054a3f850fb5fd36f17fe0",
            "input": "While deep learning has led to remarkable advances across diverse applications, it struggles in domains where the data distribution changes over the course of learning. In stark contrast, biological neural networks continually adapt to changing domains, possibly by leveraging complex molecular machinery to solve many tasks simultaneously. In this study, we introduce intelligent synapses that bring some of this biological complexity into artificial neural networks. Each synapse accumulates task relevant information over time, and exploits this information to rapidly store new memories without forgetting old ones. We evaluate our approach on continual learning of classification tasks, and show that it dramatically reduces forgetting while maintaining computational efficiency.",
            "output": [
                "Continual Learning Through Synaptic Intelligence"
            ]
        },
        {
            "id": "task1540-63a315c8f877453e850b40f4904e7c0e",
            "input": "Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in Ranjay Krishna Stanford University, Stanford, CA, USA E-mail: ranjaykrishna@cs.stanford.edu Yuke Zhu Stanford University, Stanford, CA, USA Oliver Groth Dresden University of Technology, Dresden, Germany Justin Johnson Stanford University, Stanford, CA, USA Kenji Hata Stanford University, Stanford, CA, USA Joshua Kravitz Stanford University, Stanford, CA, USA Stephanie Chen Stanford University, Stanford, CA, USA Yannis Kalantidis Yahoo Inc., San Francisco, CA, USA Li-Jia Li Snapchat Inc., Los Angeles, CA, USA David A. Shamma Yahoo Inc., San Francisco, CA, USA Michael S. Bernstein Stanford University, Stanford, CA, USA Li Fei-Fei Stanford University, Stanford, CA, USA an image. When asked “What vehicle is the person riding?”, computers will need to identify the objects in an image as well as the relationships riding(man, carriage) and pulling(horse, carriage) in order to answer correctly that “the person is riding a horse-drawn carriage.” In this paper, we present the Visual Genome dataset to enable the modeling of such relationships. We collect dense annotations of objects, attributes, and relationships within each image to learn these models. Specifically, our dataset contains over 100K images where each image has an average of 21 objects, 18 attributes, and 18 pairwise relationships between objects. We canonicalize the objects, attributes, relationships, and noun phrases in region descriptions and questions answer pairs to WordNet synsets. Together, these annotations represent the densest and largest dataset of image descriptions, objects, attributes, relationships, and question answers.",
            "output": [
                "Connecting Language and Vision Using Crowdsourced Dense Image Annotations"
            ]
        },
        {
            "id": "task1540-5de7d386c07a4dd784f9c1593b7871ef",
            "input": "Neural machine translation aims at building a single large neural network that can be trained to maximize translation performance. The encoder-decoder architecture with an attention mechanism achieves a translation performance comparable to the existing state-of-the-art phrase-based systems. However, the use of large vocabulary becomes the bottleneck in both training and improving the performance. In this paper, we propose a novel architecture which learns morphology by using two recurrent networks and a hierarchical decoder which translates at character level. This gives rise to a deep character-level model consisting of six recurrent networks. Such a deep model has two major advantages. It avoids the large vocabulary issue radically; at the same time, it is more efficient in training than word-based models. Our model obtains a higher BLEU score than the bpe-based model after training for one epoch on En-Fr and En-Cs translation tasks. Further analyses show that our model is able to learn morphology.",
            "output": [
                "DEEP CHARACTER-LEVEL NEURAL MACHINE TRANSLATION BY LEARNING MORPHOLOGY"
            ]
        },
        {
            "id": "task1540-b11e513d5c7c4c149db54a6be8b8a4a9",
            "input": "Optunity is a free software package dedicated to hyperparameter optimization. It contains various types of solvers, ranging from undirected methods to direct search, particle swarm and evolutionary optimization. The design focuses on ease of use, flexibility, code clarity and interoperability with existing software in all machine learning environments. Optunity is written in Python and contains interfaces to environments such as R and MATLAB. Optunity uses a BSD license and is freely available online at http://www.optunity.net.",
            "output": [
                "Easy Hyperparameter Search Using Optunity"
            ]
        },
        {
            "id": "task1540-023fd03f9ad641498898501a0f9b61ee",
            "input": "The downfall of many supervised learning algorithms, such as neural networks, is the inherent need for a large amount of training data (Benediktsson et al., 1993). Although there is a lot of buzz about big data, there is still the problem of doing classification from a small data-set. Other methods such as support vector machines, although capable of dealing with few samples, are inherently binary classifiers (Cortes and Vapnik, 1995), and are in need of learning strategies such as One vs All in the case of multi-classification. In the presence of a large number of classes this can become problematic. In this paper we present, a novel approach to supervised learning through the method of clustering. Unlike traditional methods such as K-Means (MacQueen, 1967), Gravitational Clustering does not require the initial number of clusters, and automatically builds the clusters, individual samples can be arbitrarily weighted and it requires only few samples while staying resilient to over-fitting. Keywords—Machine Learning, Classification, Clustering.",
            "output": [
                "Introduction to Gravitational Clustering"
            ]
        },
        {
            "id": "task1540-5ca135acd3644802ba185c03842f36ed",
            "input": "Populations of neurons in inferotemporal cortex (IT) maintain an explicit code for object identity that also tolerates transformations of object appearance e.g., position, scale, viewing angle [1, 2, 3]. Though the learning rules are not known, recent results [4, 5, 6] suggest the operation of an unsupervised temporal-association-based method e.g., Foldiak’s trace rule [7]. Such methods exploit the temporal continuity of the visual world by assuming that visual experience over short timescales will tend to have invariant identity content. Thus, by associating representations of frames from nearby times, a representation that tolerates whatever transformations occurred in the video may be achieved. Many previous studies verified that such rules can work in simple situations without background clutter, but the presence of visual clutter has remained problematic for this approach. Here we show that temporal association based on large class-specific filters (templates) avoids the problem of clutter. Our system learns in an unsupervised way from natural videos gathered from the internet, and is able to perform a difficult unconstrained face recognition task on natural images: Labeled Faces in the Wild [8]. This work was supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF 1231216. ar X iv :1 40 9. 38 79 v2 [ cs .C V ] 2 4 A pr 2 01 5",
            "output": [
                "Unsupervised learning of clutter-resistant visual representations from natural videos"
            ]
        },
        {
            "id": "task1540-5774120f216b48e398f7897fd8b16cc3",
            "input": "Fine-grained entity type classification (FETC) is the task of classifying an entity mention to a broad set of types. Distant supervision paradigm is extensively used to generate training data for this task. However, generated training data assigns same set of labels to every mention of an entity without considering its local context. Existing FETC systems have two major drawbacks: assuming training data to be noise free and use of hand crafted features. Our work overcomes both drawbacks. We propose a neural network model that jointly learns entity mentions and their context representation to eliminate use of hand crafted features. Our model treats training data as noisy and uses non-parametric variant of hinge loss function. Experiments show that the proposed model outperforms previous stateof-the-art methods on two publicly available datasets, namely FIGER(GOLD) and BBN with an average relative improvement of 2.69% in micro-F1 score. Knowledge learnt by our model on one dataset can be transferred to other datasets while using same model or other FETC systems. These approaches of transferring knowledge further improve the performance of respective models.",
            "output": [
                "Fine-Grained Entity Type Classification by Jointly Learning Representations and Label Embeddings"
            ]
        },
        {
            "id": "task1540-4562ac714e1046e48fef17a6c9fa6617",
            "input": "This paper proposes an efficient algorithm (HOLRR) to handle regression tasks where the outputs have a tensor structure. We formulate the regression problem as the minimization of a least square criterion under a multilinear rank constraint, a difficult non convex problem. HOLRR computes efficiently an approximate solution of this problem, with solid theoretical guarantees. A kernel extension is also presented. Experiments on synthetic and real data show that HOLRR outperforms multivariate and multilinear regression methods and is considerably faster than existing tensor methods.",
            "output": [
                "Higher-Order Low-Rank Regression"
            ]
        },
        {
            "id": "task1540-4ea5d4e07d9c44ffae643ee98dd1f022",
            "input": "In this paper we investigate an emerging application, 3D scene understanding, likely to be significant in the mobile space in the near future. The goal of this exploration is to reduce execution time while meeting our quality of result objectives. In previous work, we showed for the first time that it is possible to map this application to power constrained embedded systems, highlighting that decision choices made at the algorithmic designlevel have the most significant impact. As the algorithmic design space is too large to be exhaustively evaluated, we use a previously introduced multi-objective random forest active learning prediction framework dubbed HyperMapper, to find good algorithmic designs. We show that HyperMapper generalizes on a recent cutting edge 3D scene understanding algorithm and on a modern GPU-based computer architecture. HyperMapper is able to beat an expert human hand-tuning the algorithmic parameters of the class of computer vision applications taken under consideration in this paper automatically. In addition, we use crowd-sourcing using a 3D scene understanding Android app to show that the Pareto front obtained on an embedded system can be used to accelerate the same application on all the 83 smart-phones and tablets with speedups ranging from 2x to over 12x.",
            "output": [
                "Algorithmic Performance-Accuracy Trade-off in 3D Vision Applications Using HyperMapper"
            ]
        },
        {
            "id": "task1540-949a4960246742169197d2d9e418a818",
            "input": "Anomaly detection is an important task in many real world applications such as fraud detection, suspicious activity detection, health care monitoring etc. In this paper, we tackle this problem from supervised learning perspective in online learning setting. We maximize well known Gmean metric for classimbalance learning in online learning framework. Specifically, we show that maximizing Gmean is equivalent to minimizing a convex surrogate loss function and based on that we propose novel online learning algorithm for anomaly detection. We then show, by extensive experiments, that the performance of the proposed algorithm with respect to sum metric is as good as a recently proposed Cost-Sensitive Online Classification(CSOC) algorithm for class-imbalance learning over various benchmarked data sets while keeping running time close to the perception algorithm. Our another conclusion is that other competitive online algorithms do not perform consistently over data sets of varying size. This shows the potential applicability of our proposed approach.",
            "output": [
                "Online Anomaly Detection via Class-Imbalance Learning"
            ]
        },
        {
            "id": "task1540-439cba0897c04303a79250ddc92f4f93",
            "input": "Recurrent sequence generators conditioned on input data through an attention mechanism have recently shown very good performance on a range of tasks including machine translation, handwriting synthesis [1, 2] and image caption generation [3]. We extend the attention-mechanism with features needed for speech recognition. We show that while an adaptation of the model used for machine translation in [2] reaches a competitive 18.7% phoneme error rate (PER) on the TIMIT phoneme recognition task, it can only be applied to utterances which are roughly as long as the ones it was trained on. We offer a qualitative explanation of this failure and propose a novel and generic method of adding location-awareness to the attention mechanism to alleviate this issue. The new method yields a model that is robust to long inputs and achieves 18% PER in single utterances and 20% in 10-times longer (repeated) utterances. Finally, we propose a change to the attention mechanism that prevents it from concentrating too much on single frames, which further reduces PER to 17.6% level.",
            "output": [
                "Attention-Based Models for Speech Recognition"
            ]
        },
        {
            "id": "task1540-fe05383d0148420183c103818008806e",
            "input": "Artificial General Intelligence (AGI) is a field of research aiming to distill the principles of intelligence that operate independently of a specific problem domain or a predefined context and utilize these principles in order to synthesize systems capable of performing any intellectual task a human being is capable of and eventually go beyond that. While “narrow” artificial intelligence that focuses on solving specific problems such as speech recognition, text comprehension, visual pattern recognition, robotic motion, etc. has shown quite a few impressive breakthroughs lately, understanding general intelligence remains elusive. In this paper we offer a novel theoretical approach to understanding general intelligence. We start with a brief introduction of the current conceptual approach. Our critique exposes a number of serious limitations that are traced back to the ontological roots of the concept of intelligence. We then propose a paradigm shift from intelligence perceived as a competence of individual agents defined in relation to an a priori given problem domain or a goal, to intelligence perceived as a formative process of self-organization by which intelligent agents are individuated. We call this process open-ended intelligence. This paradigmatic shift significantly extends the concept of intelligence beyond its current conventional definitions and overcomes the difficulties exposed in the critique. Open-ended intelligence is developed as an abstraction of the process of cognitive development so its application can be extended to general agents and systems. We introduce and discuss three facets of the idea: the philosophical concept of individuation, sense-making – the bringing forth of a world of objects and relations, and the individuation of general cognitive agents in the light of the enactive approach to cognition and assemblage theory. We study these in order to establish in what sense formative individuating processes are indeed intelligent and why they are open-ended. We further show how open-ended intelligence can be framed in terms of a distributed, self-organizing network of interacting elements (i.e. a complex adaptive system) and how such a process is scalable. The framework highlights an important relation between coordination and intelligence and a new understanding of values. We conclude with a number of questions for future research.",
            "output": [
                "The individuation of Intelligent Agents"
            ]
        },
        {
            "id": "task1540-96913c801efa4cd59257b70d0bd32783",
            "input": "We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task involving finding rewards in random 3D mazes using a visual input.",
            "output": [
                "Asynchronous Methods for Deep Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-c523abd944c241609263664cd0c8548c",
            "input": "Mobile robots are increasingly being employed for performing complex tasks in dynamic environments. Reinforcement learning (RL) methods are recognized to be promising for specifying such tasks in a relatively simple manner. However, the strong dependency between the learning method and the task to learn is a well-known problem that restricts practical implementations of RL in robotics, often requiring major modifications of parameters and adding other techniques for each particular task. In this paper we present a practical core implementation of RL which enables the learning process for multiple robotic tasks with minimal per-task tuning or none. Based on value iteration methods, this implementation includes a novel approach for action selection, called Q-biased softmax regression (QBIASSR), which avoids poor performance of the learning process when the robot reaches new unexplored states. Our approach takes advantage of the structure of the state space by attending the physical variables involved (e.g., distances to obstacles, X ,Y , θ pose, etc.), thus experienced sets of states may favor the decision-making process of unexplored or rarely-explored states. This improvement has a relevant role in reducing the tuning of the algorithm for particular tasks. Experiments with real and simulated robots, performed with the software framework also introduced here, show that our implementation is effectively able to learn different robotic tasks without tuning the learning method. Results also suggest that the combination of true online SARSA(λ) (TOSL) with QBIASSR can outperform the existing RL core algorithms in low-dimensional robotic tasks.",
            "output": [
                "Towards a Common Implementation of Reinforcement Learning for Multiple Robotic Tasks"
            ]
        },
        {
            "id": "task1540-1b459570f974418595ca85fd860fd428",
            "input": "To improve the efficiency of Monte Carlo estimation, practitioners are turning to biased Markov chain Monte Carlo procedures that trade off asymptotic exactness for computational speed. The reasoning is sound: a reduction in variance due to more rapid sampling can outweigh the bias introduced. However, the inexactness creates new challenges for sampler and parameter selection, since standard measures of sample quality like effective sample size do not account for asymptotic bias. To address these challenges, we introduce a new computable quality measure based on Stein’s method that quantifies the maximum discrepancy between sample and target expectations over a large class of test functions. We use our tool to compare exact, biased, and deterministic sample sequences and illustrate applications to hyperparameter selection, convergence rate assessment, and quantifying bias-variance tradeoffs in posterior inference.",
            "output": [
                "Measuring Sample Quality with Stein’s Method"
            ]
        },
        {
            "id": "task1540-f20bdd65a8c545b0a26deb53b913e1f3",
            "input": "The scale of modern datasets necessitates the development of efficient distributed optimization methods for machine learning. We present a general-purpose framework for the distributed environment, CoCoA, that has an efficient communication scheme and is applicable to a wide variety of problems in machine learning and signal processing. We extend the framework to cover general non-strongly convex regularizers, including L1-regularized problems like lasso, sparse logistic regression, and elastic net regularization, and show how earlier work can be derived as a special case. We provide convergence guarantees for the class of convex regularized loss minimization objectives, leveraging a novel approach in handling non-strongly convex regularizers and non-smooth loss functions. The resulting framework has markedly improved performance over state-of-the-art methods, as we illustrate with an extensive set of experiments on real distributed datasets.",
            "output": [
                "CoCoA: A General Framework for Communication-Efficient Distributed Optimization"
            ]
        },
        {
            "id": "task1540-74c839aa0fef4e9890dd30235bf90bd8",
            "input": "Marginal MAP inference involves making MAP predictions in systems defined<lb>with latent variables or missing information. It is significantly more difficult than<lb>pure marginalization and MAP tasks, for which a large class of efficient and con-<lb>vergent variational algorithms, such as dual decomposition, exist. In this work, we<lb>generalize dual decomposition to a generic power sum inference task, which in-<lb>cludes marginal MAP, along with pure marginalization and MAP, as special cases.<lb>Our method is based on a block coordinate descent algorithm on a new convex<lb>decomposition bound, that is guaranteed to converge monotonically, and can be<lb>parallelized efficiently. We demonstrate our approach on marginal MAP queries<lb>defined on real-world problems from the UAI approximate inference challenge,<lb>showing that our framework is faster and more reliable than previous methods.",
            "output": [
                "Decomposition Bounds for Marginal MAP"
            ]
        },
        {
            "id": "task1540-f410ed0fcdca4629b201203d22dafd55",
            "input": "Our work addresses two important issues with recurrent neural networks: (1) they are over-parameterized, and (2) the recurrence matrix is ill-conditioned. The former increases the sample complexity of learning and the training time. The latter causes the vanishing and exploding gradient problem. We present a flexible recurrent neural network model called Kronecker Recurrent Units (KRU). KRU achieves parameter efficiency in RNNs through a Kronecker factored recurrent matrix. It overcomes the ill-conditioning of the recurrent matrix by enforcing soft unitary constraints on the factors. Thanks to the small dimensionality of the factors, maintaining these constraints is computationally efficient. Our experimental results on five standard data-sets reveal that KRU can reduce the number of parameters by three orders of magnitude in the recurrent weight matrix compared to the existing recurrent models, without trading the statistical performance. These results in particular show that while there are advantages in having a high dimensional recurrent space, the capacity of the recurrent part of the model can be dramatically reduced.",
            "output": [
                "Kronecker Recurrent Units"
            ]
        },
        {
            "id": "task1540-9b2db386825e479aa263566f26bf762c",
            "input": "The fastest known exact algorithms for scorebased structure discovery in Bayesian networks on n nodes run in time and space 2n. The usage of these algorithms is limited to networks on at most around 25 nodes mainly due to the space requirement. Here, we study space–time tradeoffs for finding an optimal network structure. When little space is available, we apply the Gurevich– Shelah recurrence—originally proposed for the Hamiltonian path problem—and obtain time 2n in space 2n for any s = n/2, n/4, n/8, . . .; we assume the indegree of each node is bounded by a constant. For the more practical setting with moderate amounts of space, we present a novel scheme. It yields running time 2(3/2)n in space 2(3/4)n for any p = 0, 1, . . . , n/2; these bounds hold as long as the indegrees are at most 0.238n. Furthermore, the latter scheme allows easy and efficient parallelization beyond previous algorithms. We also explore empirically the potential of the presented techniques.",
            "output": [
                "Exact Structure Discovery in Bayesian Networks with Less Space"
            ]
        },
        {
            "id": "task1540-1340950c9c2447ac9d0d065c06ce0e57",
            "input": "We address the problem of planning collision-free paths for multiple agents using optimization methods known as proximal algorithms. Recently this approach was explored in Bento et al. (2013), which demonstrated its ease of parallelization and decentralization, the speed with which the algorithms generate good quality solutions, and its ability to incorporate different proximal operators, each ensuring that paths satisfy a desired property. Unfortunately, the operators derived only apply to paths in 2D and require that any intermediate waypoints we might want agents to follow be preassigned to specific agents, limiting their range of applicability. In this paper we resolve these limitations. We introduce new operators to deal with agents moving in arbitrary dimensions that are faster to compute than their 2D predecessors and we introduce landmarks, spacetime positions that are automatically assigned to the set of agents under different optimality criteria. Finally, we report the performance of the new operators in several numerical experiments.",
            "output": [
                "Proximal Operators for Multi-Agent Path Planning"
            ]
        },
        {
            "id": "task1540-6f5e91c63d124a5aa3dc522655c24b65",
            "input": "Many natural language generation tasks, such as abstractive summarization and text simplification, are paraphrase-orientated. In these tasks, copying and rewriting are two main writing modes. Most previous sequence-to-sequence (Seq2Seq) models use a single decoder and neglect this fact. In this paper, we develop a novel Seq2Seq model to fuse a copying decoder and a restricted generative decoder. The copying decoder finds the position to be copied based on a typical attention model. The generative decoder produces words limited in the source-specific vocabulary. To combine the two decoders and determine the final output, we develop a predictor to predict the mode of copying or rewriting. This predictor can be guided by the actual writing mode in the training data. We conduct extensive experiments on two different paraphrase datasets. The result shows that our model outperforms the stateof-the-art approaches in terms of both informativeness and language quality.",
            "output": [
                "Joint Copying and Restricted Generation for Paraphrase"
            ]
        },
        {
            "id": "task1540-28150498f9f047f29f4838357a564b66",
            "input": "Fixed-vocabulary language models fail to account for one of the most characteristic statistical facts of natural language: the frequent creation and reuse of new word types. Although character-level language models offer a partial solution in that they can create word types not attested in the training corpus, they do not capture the “bursty” distribution of such words. In this paper, we augment a hierarchical LSTM language model that generates sequences of word tokens character by character with a caching mechanism that learns to reuse previously generated words. To validate our model we construct a new open-vocabulary language modeling corpus (the Multilingual Wikipedia Corpus; MWC) from comparable Wikipedia articles in 7 typologically diverse languages and demonstrate the effectiveness of our model across this range of languages.",
            "output": [
                "Learning to Create and Reuse Words in Open-Vocabulary Neural Language Modeling"
            ]
        },
        {
            "id": "task1540-9c1bc8ec4118475dbe99dc5e126dfd36",
            "input": "The domain of single crossing preference profiles is a widely studied domain in social choice theory. It has been generalized to the domain of single crossing preference profiles with respect to trees which inherits many desirable properties from the single crossing domain, for example, transitivity of majority relation, existence of polynomial time algorithms for finding winners of Kemeny voting rule, etc. In this paper, we consider a further generalization of the domain of single crossing preference profiles on trees to the domain consisting of all preference profiles which can be extended to single crossing preference profiles with respect to some tree by adding more preference orderings to it. We call this domain the weakly single crossing domain on trees. It is known that most of the desirable properties of the single crossing domain on trees continue to hold for the weakly single crossing domain on trees. In this paper, we prove several interesting structural properties of the weakly single crossing domain on trees and exploit them to design efficient algorithms for recognizing and eliciting weakly single crossing preference profiles on trees. In particular, we begin with showing that, for every weakly single crossing preference profile P on trees, there exists a unique inclusion-minimal set of preference orderings Q whose inclusion in P makes the resulting profile P = P ⊎Q single crossing with respect to some tree. We call the profile P the closure of P. Using this uniqueness of closure property of weakly single crossing preference profiles on trees and the known recognition algorithm of single crossing preference profiles on trees due to Clearwater et al. [CPS15], we design a polynomial time algorithm for recognizing weakly single crossing profiles on trees. We then move on to develop a polynomial time algorithm with low query complexity for eliciting weakly single crossing preference profiles on trees even when we do not know any tree with respect to which the closure of the input preference profile is single crossing and the preferences can be queried only sequentially; moreover, the sequential order of the input preference profile is also unknown. We complement the performance of our preference elicitation algorithm by proving that our algorithm makes an optimal number of queries up to constant factors when the number of preference orderings in the input preference profile is large compared to the number of candidates, even if the",
            "output": [
                "Recognizing and Eliciting Weakly Single Crossing Profiles on Trees"
            ]
        },
        {
            "id": "task1540-a49724dba444448ea6508d2f04cc7292",
            "input": "We consider emphatic temporal-difference learning algorithms for policy evaluation in discounted Markov decision processes with finite spaces. Such algorithms were recently proposed by Sutton, Mahmood, and White (2015) as an improved solution to the problem of divergence of off-policy temporal-difference learning with linear function approximation. We present in this paper the first convergence proofs for two emphatic algorithms, ETD(λ) and ELSTD(λ). We prove, under general off-policy conditions, the convergence in L for ELSTD(λ) iterates, and the almost sure convergence of the approximate value functions calculated by both algorithms using a single infinitely long trajectory. Our analysis involves new techniques with applications beyond emphatic algorithms leading, for example, to the first proof that standard TD(λ) also converges under off-policy training for λ sufficiently large.",
            "output": [
                "On Convergence of Emphatic Temporal-Difference Learning∗"
            ]
        },
        {
            "id": "task1540-ca1dbd031a854b5f8612ecbe84ed958d",
            "input": "This manuscript shows that AdaBoost and its immediate variants can produce approximate maximum margin classifiers simply by scaling step size choices with a fixed small constant. In this way, when the unscaled step size is an optimal choice, these results provide guarantees for Friedman’s empirically successful “shrinkage” procedure for gradient boosting (Friedman, 2000). Guarantees are also provided for a variety of other step sizes, affirming the intuition that increasingly regularized line searches provide improved margin guarantees. The results hold for the exponential loss and similar losses, most notably the logistic loss.",
            "output": [
                "Margins, Shrinkage, and Boosting"
            ]
        },
        {
            "id": "task1540-be3b5390bdd74ee1bbbae90a9e6844cb",
            "input": "Mixability is a property of a loss which characterizes when fast convergence is possible in the game of prediction with expert advice. We show that a key property of mixability generalizes, and the exp and log operations present in the usual theory are not as special as one might have thought. In doing this we introduce a more general notion of Φ-mixability where Φ is a general entropy (i.e., any convex function on probabilities). We show how a property shared by the convex dual of any such entropy yields a natural algorithm (the minimizer of a regret bound) which, analogous to the classical aggregating algorithm, is guaranteed a constant regret when used with Φ-mixable losses. We characterize precisely which Φ have Φ-mixable losses and put forward a number of conjectures about the optimality and relationships between different choices of entropy.",
            "output": [
                "Generalized Mixability via Entropic Duality"
            ]
        },
        {
            "id": "task1540-37e0c85ba5764b30a295eb5c9fdce38f",
            "input": "We establish optimal bounds on the number of nested propagation steps in k-consistency tests. It is known that local consistency algorithms such as arc-, pathand k-consistency are not efficiently parallelizable. Their inherent sequential nature is caused by long chains of nested propagation steps, which cannot be executed in parallel. This motivates the question “What is the minimum number of nested propagation steps that have to be performed by k-consistency algorithms on (binary) constraint networks with n variables and domain size d?” It was known before that 2-consistency requires Ω(nd) and 3-consistency requires Ω(n) sequential propagation steps. We answer the question exhaustively for every k ≥ 2: there are binary constraint networks where any k-consistency procedure has to perform Ω(nk−1dk−1) nested propagation steps before local inconsistencies were detected. This bound is tight, because the overall number of propagation steps performed by k-consistency is at most nk−1dk−1.",
            "output": [
                "The Propagation Depth of Local Consistency"
            ]
        },
        {
            "id": "task1540-224547d165eb4942be1959e768f34d0a",
            "input": "In this paper, we empirically explore the effects of various kinds of skip connections in stacked bidirectional LSTMs for sequential tagging. We investigate three kinds of skip connections connecting to LSTM cells: (a) skip connections to the gates, (b) skip connections to the internal states and (c) skip connections to the cell outputs. We present comprehensive experiments showing that skip connections to cell outputs outperform the remaining two. Furthermore, we observe that using gated identity functions as skip mappings works pretty well. Based on this novel skip connections, we successfully train deep stacked bidirectional LSTM models and obtain state-ofthe-art results on CCG supertagging and comparable results on POS tagging.",
            "output": [
                "An Empirical Exploration of Skip Connections for Sequential Tagging"
            ]
        },
        {
            "id": "task1540-8b35da8d03c5420090c276d7ebfaca56",
            "input": "Bayesian networks can be used to extract explanations about the observed state of a subset of variables. In this paper, we explicate the desiderata of an explanation and confront them with the concept of explanation proposed by existing methods. The necessity of taking into account causal approaches when a causal graph is available is discussed. We then introduce causal explanation trees, based on the construction of explanation trees using the measure of causal information ow (Ay and Polani, 2006). This approach is compared to several other methods on known networks.",
            "output": [
                "Explanation Trees for Causal Bayesian Networks"
            ]
        },
        {
            "id": "task1540-23e9a48dd8c54a1c8f3c0beff9734f22",
            "input": "​The ​Electromyography (EMG) signal is the electrical manifestation of a neuromuscular activation that provides access to physiological processes which cause the muscle to generate force and produce movement. Non-invasive prostheses use such signals detected by electrodes placed on the user’s stump, as input to generate hand posture movements according to the intentions of the prosthesis wearer. The aim of this pilot study is to explore the repeatability issue, i.e. the ability to classify 17 different hand postures, represented by EMG signal, across a time span of days by a control algorithm. Data collection experiments lasted four days and signals were collected from the forearm of a single subject. We find that Support Vector Machine (SVM) classification results are high enough to guarantee a correct classification of more than 10 postures in each moment of the considered time span.",
            "output": [
                "Studying the control of non-invasive prosthetic hands over large time spans"
            ]
        },
        {
            "id": "task1540-ce2ff4a041da4a3f8e0bcf6432472ffa",
            "input": "In the wake of the vast population of smart device users worldwide, mobile health (mHealth) technologies are hopeful to generate positive and wide influence on people’s health. They are able to provide flexible, affordable and portable health guides to device users. Current online decision-making methods for mHealth assume that the users are completely heterogeneous. They share no information among users and learn a separate policy for each user. However, data for each user is very limited in size to support the separate online learning, leading to unstable policies that contain lots of variances. Besides, we find the truth that a user may be similar with some, but not all, users, and connected users tend to have similar behaviors. In this paper, we propose a network cohesion constrained (actor-critic) Reinforcement Learning (RL) method for mHealth. The goal is to explore how to share information among similar users to better convert the limited user information into sharper learned policies. To the best of our knowledge, this is the first online actor-critic RL for mHealth and first network cohesion constrained (actor-critic) RL method in all applications. The network cohesion is important to derive effective policies. We come up with a novel method to learn the network by using the warm start trajectory, which directly reflects the users’ property. The optimization of our model is difficult and very different from the general supervised learning due to the indirect observation of values. As a contribution, we propose two algorithms for the proposed online RLs. Apart from mHealth, the proposed methods can be easily applied or adapted to other health-related tasks. Extensive experiment results on the HeartSteps dataset demonstrates that in a variety of parameter settings, the proposed two methods obtain obvious improvements over the state-of-the-art methods.",
            "output": [
                "Cohesion-based Online Actor-Critic Reinforcement Learning for mHealth Intervention"
            ]
        },
        {
            "id": "task1540-8b028d209451428998e4e330322d7a3c",
            "input": "Modern conflict-driven clause-learning (CDCL) Boolean SAT solvers provide efficient automatic analysis of real-world feature models (FM) of systems ranging from cars to operating systems. It is well-known that solver-based analysis of real-world FMs scale very well even though SAT instances obtained from such FMs are large, and the corresponding analysis problems are known to be NP-complete. To better understand why SAT solvers are so effective, we systematically studied many syntactic and semantic characteristics of a representative set of large real-world FMs. We discovered that a key reason why large real-world FMs are easy-toanalyze is that the vast majority of the variables in these models are unrestricted, i.e., the models are satisfiable for both true and false assignments to such variables under the current partial assignment. Given this discovery and our understanding of CDCL SAT solvers, we show that solvers can easily find satisfying assignments for such models without too many backtracks relative to the model size, explaining why solvers scale so well. Further analysis showed that the presence of unrestricted variables in these real-world models can be attributed to their high-degree of variability. Additionally, we experimented with a series of well-known nonbacktracking simplifications that are particularly effective in solving FMs. The remaining variables/clauses after simplifications, called the core, are so few that they are easily solved even with backtracking, further strengthening our conclusions. We explain the connection between our findings and backdoors, an idea posited by theorists to explain the power of SAT solvers. This connection strengthens our hypothesis that SAT-based analysis of FMs is easy. In contrast to our findings, previous research characterizes the difficulty of analyzing randomly-generated FMs in terms of treewidth. Our experiments suggest that the difficulty of analyzing realworld FMs cannot be explained in terms of treewidth. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SPLC 2015, July 20 24, 2015, Nashville, TN, USA c © 2015 ACM. ISBN 978-1-4503-3613-0/15/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2791060.2791070 CCS Concepts •Software and its engineering → Software product lines;",
            "output": [
                "SAT-based Analysis of Large Real-world Feature Models is Easy"
            ]
        },
        {
            "id": "task1540-0563d47da5a2474da10890a40f1f4550",
            "input": "A framework is presented for unsupervised learning of representations based on infomax principle for large-scale neural populations. We use an asymptotic approximation to the Shannon’s mutual information for a large neural population to demonstrate that a good initial approximation to the global information-theoretic optimum can be obtained by a hierarchical infomax method. Starting from the initial solution, an efficient algorithm based on gradient descent of the final objective function is proposed to learn representations from the input datasets, and the method works for complete, overcomplete, and undercomplete bases. As confirmed by numerical experiments, our method is robust and highly efficient for extracting salient features from input datasets. Compared with the main existing methods, our algorithm has a distinct advantage in both the training speed and the robustness of unsupervised representation learning. Furthermore, the proposed method is easily extended to the supervised or unsupervised model for training deep structure networks.",
            "output": [
                "NEURAL POPULATION INFOMAX"
            ]
        },
        {
            "id": "task1540-3d111207d9184b05b64502395d10dc87",
            "input": "We study the generalization properties of stochastic gradient methods for learning with convex loss functions and linearly parameterized functions. We show that, in the absence of penalizations or constraints, the stability and approximation properties of the algorithm can be controlled by tuning either the step-size or the number of passes over the data. In this view, these parameters can be seen to control a form of implicit regularization. Numerical results complement the theoretical findings.",
            "output": [
                "Generalization Properties and Implicit Regularization for Multiple Passes SGM"
            ]
        },
        {
            "id": "task1540-8ef4a6826a834ab485d1e0f78a56cc92",
            "input": "Offline handwriting recognition systems require cropped text line images for both<lb>training and recognition. On the one hand, the annotation of position and tran-<lb>script at line level is costly to obtain. On the other hand, automatic line seg-<lb>mentation algorithms are prone to errors, compromising the subsequent recogni-<lb>tion. In this paper, we propose a modification of the popular and efficient multi-<lb>dimensional long short-term memory recurrent neural networks (MDLSTM-<lb>RNNs) to enable end-to-end processing of handwritten paragraphs. More partic-<lb>ularly, we replace the collapse layer transforming the two-dimensional represen-<lb>tation into a sequence of predictions by a recurrent version which can recognize<lb>one line at a time. In the proposed model, a neural network performs a kind of<lb>implicit line segmentation by computing attention weights on the image represen-<lb>tation. The experiments on paragraphs of Rimes and IAM database yield results<lb>that are competitive with those of networks trained at line level, and constitute a<lb>significant step towards end-to-end transcription of full documents.",
            "output": [
                "Joint Line Segmentation and Transcription for End-to-End Handwritten Paragraph Recognition"
            ]
        },
        {
            "id": "task1540-22667e06f21c451e83cea7f14cd08631",
            "input": "The role of sentiment analysis is increasingly emerging to study software developers’ emotions by mining crowdgenerated content within social software engineering tools. However, off-the-shelf sentiment analysis tools have been trained on non-technical domains and general-purpose social media, thus resulting in misclassifications of technical jargon and problem reports. Here, we present Senti4SD, a classifier specifically trained to support sentiment analysis in developers’ communication channels. Senti4SD is trained and validated using a gold standard of Stack Overflow questions, answers, and comments manually annotated for sentiment polarity. It exploits a suite of both lexiconand keyword-based features, as well as semantic features based on word embedding. With respect to a mainstream off-the-shelf tool, which we use as a baseline, Senti4SD reduces the misclassifications of neutral and positive posts as emotionally negative. To encourage replications, we release a lab package including the classifier, the word embedding space, and the gold standard with annotation guidelines.",
            "output": [
                "Sentiment Polarity Detection for Software Development"
            ]
        },
        {
            "id": "task1540-5d94cb6abca54b25949c5246f5090a2a",
            "input": "The human perceptual system can make complex inferences on faces, ranging from the objective evaluations regarding gender, ethnicity, expression, age, identity, etc. to subjective judgments on facial attractiveness, trustworthiness, sociability, friendliness, etc. Whereas the objective aspects have been extensively studied, less attention has been paid to modeling the subjective perception of faces. Here, we adapt 6 state-of-the-art neural networks pretrained on various image tasks (object classification, face identification, face localization) to predict human ratings on 40 social judgments of faces in the 10k US Adult Face Database. Supervised ridge regression on PCA of the conv5 2 layer in VGG-16 network gives best predictions on the average human ratings. Human group agreement was evaluated by repeatedly randomly splitting the raters into two halves for each face, and calculating the Pearson correlation between the two sets of averaged ratings. Due to this methodology, the models correlations with the average human ratings can exceed this score. We find that 1) model performance grows as the consensus on a face trait increases, and 2) model correlations are always higher than human correlations with each other. These results illustrate the learnability of the subjective perception of faces, especially when there is consensus, and the striking versatility and transferability of representations learned for object recognition. This work has strong applications to social robotics, allowing robots to infer human judgments of each other.",
            "output": [
                "Learning to see people like people"
            ]
        },
        {
            "id": "task1540-144cfaaf08a64d45a530fdfadb2cf3de",
            "input": "This work aims to address the problem of imagebased question-answering (QA) with new models and datasets. In our work, we propose to use recurrent neural networks and visual semantic embeddings without intermediate stages such as object detection and image segmentation. Our model performs 1.8 times better than the recently published results on the same dataset. Another main contribution is an automatic question generation algorithm that converts the currently available image description dataset into QA form, resulting in a 10 times bigger dataset with more evenly distributed answers.",
            "output": [
                "Image Question Answering: A Visual Semantic Embedding Model and a New Dataset"
            ]
        },
        {
            "id": "task1540-5228a14c579b4303a52415d2881f6b91",
            "input": "ABSTRACT: The \"easy\" problem of cognitive science is explaining how and why we can do what we can do. The \"hard\" problem is explaining how and why we feel. Turing's methodology for cognitive science (the Turing Test) is based on doing: Design a model that can do anything a human can do, indistinguishably from a human, to a human, and you have explained cognition. Searle has shown that the successful model cannot be solely computational. Sensory-motor robotic capacities are necessary to ground some, at least, of the model's words, in what the robot can do with the things in the world that the words are about. But even grounding is not enough to guarantee that -nor to explain how and why -the model feels (if it does). That problem is much harder to solve (and perhaps insoluble).",
            "output": [
                "Alan Turing and the “Hard” and “Easy” Problem of Cognition: Doing and Feeling"
            ]
        },
        {
            "id": "task1540-f49e94297b2e480697ea6b2a22be6f83",
            "input": "Multi Expression Programming (MEP) is an evolutionary technique that may be used for solving computationally difficult problems. MEP uses a linear solution representation. Each MEP individual is a string encoding complex expressions (computer programs). A MEP individual may encode multiple solutions of the current problem. In this paper MEP is used for evolving a Traveling Salesman Problem (TSP) heuristic for graphs satisfying triangle inequality. Evolved MEP heuristic is compared with Nearest Neighbor Heuristic (NN) and Minimum Spanning Tree Heuristic (MST) on some difficult problems in TSPLIB. For most of the considered problems the evolved MEP heuristic outperforms NN and MST. The obtained algorithm was tested against some problems in TSPLIB. The results emphasizes that evolved MEP heuristic is a powerful tool for solving difficult TSP instances.",
            "output": [
                "Evolving TSP heuristics using Multi Expression Programming"
            ]
        },
        {
            "id": "task1540-a6f48ad58d064892b29b2aa975245840",
            "input": "The purpose of this paper is to serve as a reference guide for the development of chatterbots implemented with the AIML language. In order to achieve this, the main concepts in Pattern Recognition area are described because the AIML uses such theoretical framework in their syntactic and semantic structures. After that, AIML language is described and each AIML command/tag is followed by an application example. Also, the usage of AIML embedded tags for the handling of sequence dialogue limitations between humans and machines is shown. Finally, computer systems that assist in the design of chatterbots with the AIML language are classified and described.",
            "output": [
                "ARTIFICIAL INTELLIGENCE MARKUP LANGUAGE: A BRIEF TUTORIAL"
            ]
        },
        {
            "id": "task1540-06f2a986f5a14b5a91112e82b83ffe51",
            "input": "This paper explores an incremental training strategy for the skip-gram model with negative sampling (SGNS) from both empirical and theoretical perspectives. Existing methods of neural word embeddings, including SNGS, are multi-pass algorithms and thus cannot perform incremental model update. To address this problem, we present a simple incremental extension of SNGS and provide a thorough theoretical analysis to demonstrate its validity. Empirical experiments demonstrated the correctness of the theoretical analysis as well as the practical usefulness of the incremental algorithm.",
            "output": [
                "Incremental Skip-gram Model with Negative Sampling"
            ]
        },
        {
            "id": "task1540-719530ffa7214d318a2236d49d606f0d",
            "input": "SentiWordNet is an important lexical resource supporting sentiment analysis in opinion mining applications. In this paper, we propose a novel approach to construct a Vietnamese SentiWordNet (VSWN). SentiWordNet is typically generated from WordNet in which each synset has numerical scores to indicate its opinion polarities. Many previous studies obtained these scores by applying a machine learning method to WordNet. However, Vietnamese WordNet is not available unfortunately by the time of this paper. Therefore, we propose a method to construct VSWN from a Vietnamese dictionary, not from WordNet. We show the effectiveness of the proposed method by generating a VSWN with 39,561 synsets automatically. The method is experimentally tested with 266 synsets with aspect of positivity and negativity. It attains a competitive result compared with English SentiWordNet that is 0.066 and 0.052 differences for positivity and negativity sets respectively.",
            "output": [
                "Construction of Vietnamese SentiWordNet by using Vietnamese Dictionary"
            ]
        },
        {
            "id": "task1540-97df4508968b47a58f7d0f7ed5d8119f",
            "input": "Text categorization is the process of grouping documents into categories based on their contents. This process is important to make information retrieval easier, and it became more important due to the huge textual information available online. The main problem in text categorization is how to improve the classification accuracy. Although Arabic text categorization is a new promising field, there are a few researches in this field. This paper proposes a new method for Arabic text categorization using vector evaluation. The proposed method uses a categorized Arabic documents corpus, and then the weights of the tested document's words are calculated to determine the document keywords which will be compared with the keywords of the corpus categorizes to determine the tested document's best category.",
            "output": [
                "ARABIC TEXT CATEGORIZATION ALGORITHM USING VECTOR EVALUATION METHOD"
            ]
        },
        {
            "id": "task1540-1a95e56d89324ab5b4c8d26e465407ca",
            "input": "<lb>Sequentially learning to place items in multi-position displays or lists is a task that can be cast into the<lb>multiple-play semi-bandit setting. However, a major concern in this context is when the system cannot decide<lb>whether the user feedback for each item is actually exploitable. Indeed, much of the content may have been<lb>simply ignored by the user. The present work proposes to exploit available information regarding the display<lb>position bias under the so-called Position-based click model (PBM). We first discuss how this model differs<lb>from the Cascade model and its variants considered in several recent works on multiple-play bandits. We<lb>then provide a novel regret lower bound for this model as well as computationally efficient algorithms that<lb>display good empirical and theoretical performance.",
            "output": [
                "Multiple-Play Bandits in the Position-Based Model"
            ]
        },
        {
            "id": "task1540-91e0508e58c6421984d18bc0cb1fc122",
            "input": "Knowledge representation is a key component to the success of all rule based systems including learning classifier systems (LCSs). This component brings insight into how to partition the problem space what in turn seeks prominent role in generalization capacity of the system as a whole. Recently, knowledge representation component has received great deal of attention within data mining communities due to its impacts on rule based systems in terms of efficiency and efficacy. The current work is an attempt to find a comprehensive and yet elaborate view into the existing knowledge representation techniques in LCS domain in general and XCS in specific. To achieve the objectives, knowledge representation techniques are grouped into different categories based on the classification approach in which they are incorporated. In each category, the underlying rule representation schema and the format of classifier condition to support the corresponding representation are presented. Furthermore, a precise explanation on the way that each technique partitions the problem space along with the extensive experimental results is provided. To have an elaborated view on the functionality of each technique, a comparative analysis of existing techniques on some conventional problems is provided. We expect F. Shoeleh Computer Science and Engineering Dept. Shiraz University, Shiraz, Iran. E-mail: shoeleh@cse.shirazu.ac.ir M. Majd E-mail: majd@cse.shirazu.ac.ir A. Hamzeh E-mail: ali@cse.shirazu.ac.ir S. Hashemi E-mail: s hashemi@shirazu.ac.ir this survey to be of interest to the LCS researchers and practitioners since it provides a guideline for choosing a proper knowledge representation technique for a given problem and also opens up new streams of research on this topic.",
            "output": [
                "Knowledge Representation in Learning Classifier Systems: A Survey"
            ]
        },
        {
            "id": "task1540-0a1310dd7c5d4aaa920b9fbd75830909",
            "input": "Stochastic local search (SLS) algorithms have exhibited great effectiveness in finding models of random instances of the Boolean satisfiability problem (SAT). As one of the most widely known and used SLS algorithm, WalkSAT plays a key role in the evolutions of SLS for SAT, and also hold stateof-the-art performance on random instances. This work proposes a novel implementation for WalkSAT which decreases the redundant calculations leading to a dramatically speeding up, thus dominates the latest version of WalkSAT including its advanced variants.",
            "output": [
                "An Efficient Implementation for WalkSAT"
            ]
        },
        {
            "id": "task1540-5ab0cb9e59f74ae2bbb548cd692a4da4",
            "input": "Artificial intelligence is commonly defined as the ability to achieve goals in the world. In the reinforcement learning framework, goals are encoded as reward functions that guide agent behaviour, and the sum of observed rewards provide a notion of progress. However, some domains have no such reward signal, or have a reward signal so sparse as to appear absent. Without reward feedback, agent behaviour is typically random, often dithering aimlessly and lacking intentionality. In this paper we present an algorithm capable of learning purposeful behaviour in the absence of rewards. The algorithm proceeds by constructing temporally extended actions (options), through the identification of purposes that are “just out of reach” of the agents current behaviour. These purposes establish intrinsic goals for the agent to learn, ultimately resulting in a suite of behaviours that encourage the agent to visit different parts of the state space. Moreover, the approach is particularly suited for settings where rewards are very sparse, and such behaviours can help in the exploration of the environment until reward is observed.",
            "output": [
                "Learning Purposeful Behaviour in the Absence of Rewards"
            ]
        },
        {
            "id": "task1540-c940ee5b185e4dccbc93da71a0fcbd3b",
            "input": "<lb>We study a general version of the adversarial online learning problem. We are given a decision<lb>set X in a reflexive Banach space X and a sequence of reward vectors in the dual space of X . At<lb>each iteration, we choose an action from X , based on the observed sequence of previous rewards.<lb>Our goal is to minimize regret, defined as the gap between the realized reward and the reward<lb>of the best fixed action in hindsight. Using results from infinite dimensional convex analysis, we<lb>generalize the method of Dual Averaging (or Follow the Regularized Leader) to our setting and<lb>obtain general upper bounds on the worst-case regret that subsume a wide range of results from the<lb>literature. Under the assumption of uniformly continuous rewards, we obtain explicit anytime regret<lb>bounds in a setting where the decision set is the set of probability distributions on a compact metric<lb>space S whose Radon-Nikodym derivatives are elements of L(S) for some p > 1. Importantly,<lb>we make no convexity assumptions on either the set S or the reward functions. We also prove<lb>a general lower bound on the worst-case regret for any online algorithm. We then apply these<lb>results to the problem of learning in repeated continuous two-player zero-sum games, in which<lb>players’ strategy sets are compact metric spaces. In doing so, we first prove that if both players<lb>play a Hannan-consistent strategy, then with probability 1 the empirical distributions of play weakly<lb>converge to the set of Nash equilibria of the game. We then show that, under mild assumptions,<lb>Dual Averaging on the (infinite-dimensional) space of probability distributions indeed achieves<lb>Hannan-consistency. Finally, we illustrate our results through numerical examples.<lb>",
            "output": [
                "Minimizing Regret on Reflexive Banach Spaces and Learning Nash Equilibria in Continuous Zero-Sum Games"
            ]
        },
        {
            "id": "task1540-d42fb5913f384a108ff9ff9c0319796f",
            "input": "Nowadays, engineers have to develop software often without even knowing which hardware it will eventually run on in numerous mobile phones, tablets, desktops, laptops, data centers, supercomputers and cloud services. Unfortunately, optimizing compilers are not keeping pace with ever increasing complexity of ever changing computer systems anymore and may produce severely underperforming executable codes while wasting expensive resources and energy. We present the first to our knowledge practical, collaborative and publicly available solution to this problem. We help the software engineering community gradually implement and share light-weight wrappers around any software piece with more than one implementation or optimization choice available. These wrappers are connected with a public Collective Mind autotuning infrastructure and repository of knowledge to continuously monitor all important characteristics of these pieces (computational species) across numerous existing hardware configurations in realistic environments together with randomly selected optimizations. At the same time, Collective Mind Node) allows to easily crowdsource time-consuming autotuning across existing Android-based mobile device including commodity mobile phones and tables. Similar to natural sciences, we can now continuously track all winning solutions (optimizations for a given hardware such as compiler flags, OpenCL/CUDA/OpenMP/MPI/skeleton parameters, number of threads and any other exposed by users) that minimize all costs of a computation (execution time, energy spent, code size, failures, memory and storage footprint, optimization time, faults, contentions, inaccuracy and so on) of a given species on a Pareto frontier along with any unexpected behavior at c-mind.org/repo . Furthermore, the community can continuously classify solutions, prune redundant ones, and correlate them with various features of software, its inputs (data sets) and used hardware either manually (similar to Wikipedia) or using available big data analytics and machine learning techniques. Our approach can also help computer engineering community create the first public, realistic, large, diverse, distributed, representative, and continuously evolving benchmark with related optimization knowledge while gradually covering all possible software and hardware to be able to predict best optimizations and improve compilers depending on usage scenarios and requirements. Such continuously growing collective knowledge accessible via simple web service can become an integral part of the practical software and hardware co-design of self-tuning computer systems as we demonstrate in several real usage scenarios validated in industry..",
            "output": [
                "Collective Mind, Part II: Towards Performance- and Cost-Aware Software Engineering as a Natural Science"
            ]
        },
        {
            "id": "task1540-86cb11d28c87416bb5764de25273995b",
            "input": "We study truthful mechanisms for matching and related problems in a partial information<lb>setting, where the agents’ true utilities are hidden, and the algorithm only has access to ordi-<lb>nal preference information. Our model is motivated by the fact that in many settings, agents<lb>cannot express the numerical values of their utility for different outcomes, but are still able<lb>to rank the outcomes in their order of preference. Specifically, we study problems where the<lb>ground truth exists in the form of a weighted graph of agent utilities, but the algorithm can<lb>only elicit the agents’ private information in the form of a preference ordering for each agent<lb>induced by the underlying weights. Against this backdrop, we design truthful algorithms to<lb>approximate the true optimum solution with respect to the hidden weights. Our techniques<lb>yield universally truthful algorithms for a number of graph problems: a 1.76-approximation<lb>algorithm for Max-Weight Matching, 2-approximation algorithm for Max k-matching, a 6-<lb>approximation algorithm for Densest k-subgraph, and a 2-approximation algorithm for Max<lb>Traveling Salesman as long as the hidden weights constitute a metric. We also provide im-<lb>proved approximation algorithms for such problems when the agents are not able to lie about<lb>their preferences. Our results are the first non-trivial truthful approximation algorithms for<lb>these problems, and indicate that in many situations, we can design robust algorithms even<lb>when the agents may lie and only provide ordinal information instead of precise utilities.",
            "output": [
                "Truthful Mechanisms for Matching and Clustering in an Ordinal World"
            ]
        },
        {
            "id": "task1540-46602327cb9c451c87ed45b29ae3bd2b",
            "input": "The Cmabrigde Uinervtisy (Cambridge University) effect from the psycholinguistics literature has demonstrated a robust word processing mechanism in humans, where jumbled words (e.g. Cmabrigde / Cambridge) are recognized with little cost. Inspired by the findings from the Cmabrigde Uinervtisy effect, we propose a word recognition model based on a semi-character level recursive neural network (scRNN). In our experiments, we demonstrate that scRNN has significantly more robust performance in word spelling correction (i.e. word recognition) compared to existing spelling checkers. Furthermore, we demonstrate that the model is cognitively plausible by replicating a psycholinguistics experiment about human reading difficulty using our model.",
            "output": [
                "Robsut Wrod Reocginiton via semi-Character Recurrent Neural Network"
            ]
        },
        {
            "id": "task1540-6125427bb74c44bdbbc1decc3aabfd7b",
            "input": "Segmental conditional random fields (SCRFs) and connectionist temporal classification (CTC) are two sequence labeling objectives used for end-to-end training of speech recognition models. Both models define the transcription probability by marginalizing decisions about latent segmentation alternatives to derive a sequence probability: the former uses a globally normalized joint model of segment labels and durations, and the latter classifies each frame as either an output symbol or a “continuation” of the previous label. In this paper, we train a recognition model by optimizing an interpolation between the SCRF and CTC losses, where the same recurrent neural network (RNN) encoder used for feature extraction for both outputs. We find that this multi-task objective improves recognition accuracy when decoding with either the SCRF or CTC models. Additionally, we show that CTC can also be used to pretrain the RNN encoder, which improves the convergence rate when learning the joint model.",
            "output": [
                "Multi-task Learning with CTC and Segmental CRF for Speech Recognition"
            ]
        },
        {
            "id": "task1540-c742c611b7a54441aa1498697334f7d9",
            "input": "We present a novel approach to learning an HMM whose outputs are distributed according to a parametric family. This is done by decoupling the learning task into two steps: first estimating the output parameters, and then estimating the hidden states transition probabilities. The first step is accomplished by fitting a mixture model to the output stationary distribution. Given the parameters of this mixture model, the second step is formulated as the solution of an easily solvable convex quadratic program. We provide an error analysis for the estimated transition probabilities and show they are robust to small perturbations in the estimates of the mixture parameters. Finally, we support our analysis with some encouraging empirical results.",
            "output": [
                "On learning parametric-output HMMs"
            ]
        },
        {
            "id": "task1540-1eb071206c0b4a8f8a0f62be907a4a0a",
            "input": "In many real tasks the features are evolving, with some features being vanished and some other features augmented. For example, in environment monitoring some sensors expired whereas some new ones deployed; in mobile game recommendation some games dropped whereas some new ones added. Learning with such incremental and decremental features is crucial but rarely studied, particularly when the data coming like a stream and thus it is infeasible to keep the whole data for optimization. In this paper, we study this challenging problem and present the OPID approach. Our approach attempts to compress important information of vanished features into functions of survived features, and then expand to include the augmented features. It is the one-pass learning approach, which only needs to scan each instance once and does not need to store the whole data, and thus satisfy the evolving streaming data nature. The effectiveness of our approach is validated theoretically and empirically.",
            "output": [
                "One-Pass Learning with Incremental and Decremental Features"
            ]
        },
        {
            "id": "task1540-7a97d92881c64cca84a506a623f5ae8b",
            "input": "RDF and Description Logics work in an open-world setting where absence of information is not information about absence. Nevertheless, Description Logic axioms can be interpreted in a closed-world setting and in this setting they can be used for both constraint checking and closed-world recognition against information sources. When the information sources are expressed in well-behaved RDF or RDFS (i.e., RDF graphs interpreted in the RDF or RDFS semantics) this constraint checking and closed-world recognition is simple to describe. Further this constraint checking can be implemented as SPARQL querying and thus effectively per-",
            "output": [
                "Using Description Logics for RDF Constraint Checking and Closed-World Recognition"
            ]
        },
        {
            "id": "task1540-944d7b8ba5df4d5b9e75ac0d31e972cb",
            "input": "This paper deals with the problem of esti­ mating the probability that one event was a cause of another in a given scenario. Us­ ing structural-semantical definitions of the probabilities of necessary or sufficient cau­ sation (or both), we show how to optimally bound these quantities from data obtained in experimental and observational studies, making minimal assumptions concerning the data-generating process. In particular, we strengthen the results of Pearl (1999) by weakening the data-generation assumptions and deriving theoretically sharp bounds on the probabilities of causation. These results delineate precisely how empirical data can be used both in settling questions of attribution and in solving attribution-related problems of decision making.",
            "output": [
                "Probabilities of Causation: Bounds and Identification"
            ]
        },
        {
            "id": "task1540-37d19fa314bd4bf08516da57b9ca913d",
            "input": "We study the use of greedy feature selection methods for morphosyntactic tagging under a number of different conditions. We compare a static ordering of features to a dynamic ordering based on mutual information statistics, and we apply the techniques to standalone taggers as well as joint systems for tagging and parsing. Experiments on five languages show that feature selection can result in more compact models as well as higher accuracy under all conditions, but also that a dynamic ordering works better than a static ordering and that joint systems benefit more than standalone taggers. We also show that the same techniques can be used to select which morphosyntactic categories to predict in order to maximize syntactic accuracy in a joint system. Our final results represent a substantial improvement of the state of the art for several languages, while at the same time reducing both the number of features and the running time by up to 80% in some cases.",
            "output": [
                "Static and Dynamic Feature Selection in Morphosyntactic Analyzers"
            ]
        },
        {
            "id": "task1540-33d1ad9685f04f85b97a287c19083120",
            "input": "We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We first show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both taskspecific and static word vectors. The CNN models discussed herein improve upon the state-of-the-art on 4 out of 7 tasks, which include sentiment analysis and question classification.",
            "output": [
                "Convolutional Neural Networks for Sentence Classification"
            ]
        },
        {
            "id": "task1540-10d25a05a31c4fbaa882a8d7ada2879c",
            "input": "Chinese word segmentation is a fundamental task for Chinese language processing. The granularity mismatch problem is the main cause of the errors. This paper showed that the binary tree representation can store outputs with different granularity. A binary tree based framework is also designed to overcome the granularity mismatch problem. There are two steps in this framework, namely tree building and tree pruning. The tree pruning step is specially designed to focus on the granularity problem. Previous work for Chinese word segmentation such as the sequence tagging can be easily employed in this framework. This framework can also provide quantitative error analysis methods. The experiments showed that after using a more sophisticated tree pruning function for a state-of-the-art conditional random field based baseline, the error reduction can be up to 20%.",
            "output": [
                "Binary Tree based Chinese Word Segmentation"
            ]
        },
        {
            "id": "task1540-476c9c7793454f059041a4963c8ad286",
            "input": "As statistical classifiers become integrated into realworld applications, it is important to consider not only their accuracy but also their robustness to changes in the data distribution. In this paper, we consider the case where there is an unobserved confounding variable z that influences both the features x and the class variable y. When the influence of z changes from training to testing data, we find that the classifier accuracy can degrade rapidly. In our approach, we assume that we can predict the value of z at training time with some error. The prediction for z is then fed to Pearl’s back-door adjustment to build our model. Because of the attenuation bias caused by measurement error in z, standard approaches to controlling for z are ineffective. In response, we propose a method to properly control for the influence of z by first estimating its relationship with the class variable y, then updating predictions for z to match that estimated relationship. By adjusting the influence of z, we show that we can build a model that exceeds competing baselines on accuracy as well as on robustness over a range of confounding relationships.",
            "output": [
                "Controlling for Unobserved Confounds in Classification Using Correlational Constraints"
            ]
        },
        {
            "id": "task1540-d81b06c16e4b4cb3a44b4651fba5cf20",
            "input": "A rich coreset is a subset of the data which contains nearly all the essential information. We give deterministic, low order polynomial-time algorithms to construct rich coresets for simple and multiple response linear regression, together with lower bounds indicating that there is not much room for improvement upon our results.",
            "output": [
                "Rich Coresets For Constrained Linear Regression"
            ]
        },
        {
            "id": "task1540-dd2bad1a1f78480ea7c6e061d6c8f330",
            "input": "This paper describes our participation in Task 5 track 2 of SemEval 2017 to predict the sentiment of financial news headlines for a specific company on a continuous scale between -1 and 1. We tackled the problem using a number of approaches, utilising a Support Vector Regression (SVR) and a Bidirectional Long Short-Term Memory (BLSTM). We found an improvement of 4-6% using the LSTM model over the SVR and came fourth in the track. We report a number of different evaluations using a finance specific word embedding model and reflect on the effects of using different evaluation metrics.",
            "output": [
                "Lancaster A at SemEval-2017 Task 5: Evaluation metrics matter: predicting sentiment from financial news headlines"
            ]
        },
        {
            "id": "task1540-54d07114e9f046f69315764bf6ff3134",
            "input": "The ability of robots to estimate their location is crucial for a wide variety of autonomous operations. In settings where GPS is unavailable, rangeor bearing-only observations relative to a set of fixed beacons provide an effective means of estimating a robot’s location as it navigates. The accuracy of such a beacon-based localization system depends both on how beacons are spatially distributed in the environment, and how the robot’s location is inferred based on noisy measurements of range or bearing. However, it is computationally challenging to search for a placement and an inference strategy that, together, are optimal. Existing methods decouple these decisions, forgoing optimality for tractability. We propose a new optimization approach to jointly determine the beacon placement and inference algorithm. We model inference as a neural network and incorporate beacon placement as a differentiable neural layer. This formulation allows us to optimize placement and inference by jointly training the inference network and beacon layer. We evaluate our method on different localization problems and demonstrate performance that exceeds hand-crafted baselines.",
            "output": [
                "Jointly Optimizing Placement and Inference for Beacon-based Localization "
            ]
        },
        {
            "id": "task1540-7b15d6208dfd46c79762adcd1217e143",
            "input": "In this paper a new heuristic optimization algorithm has been introduced based on the performance of the major football leagues within each season in EU countries. The algorithm starts with an initial population including three different groups of teams: the wealthiest (strongest), the regular, the poorest (weakest). Each individual of population constitute a football team while each player is an indication of a player in a post. The optimization can hopefully occurs when the competition among the teams in all the leagues is imitated as the strongest teams usually purchase the best players of the regular teams and in turn, regular teams purchase the best players of the weakest who should always discover young players instead of buying professionals. It has been shown that the algorithm can hopefully converge to an acceptable solution solving various benchmarks.",
            "output": [
                "Soccer League Optimization: A heuristic Algorithm Inspired by the Football System in European Countries"
            ]
        },
        {
            "id": "task1540-85208e2b6a6243faaa1d8ff4784e2a56",
            "input": "Framing is a political strategy in which politicians carefully word their statements in order to control public perception of issues. Previous works exploring political framing typically analyze frame usage in longer texts, such as Congressional speeches. We present a collection of weakly supervised models which harness collective classification to predict the frames used in political discourse on the microblogging platform, Twitter. Our global probabilistic models show that by combining both lexical features of tweets and network-based behavioral features of Twitter, we are able to increase the average, unsupervised F1 score by 21.52 points over a lexical baseline alone.",
            "output": [
                "Leveraging Behavioral and Social Information for Weakly Supervised Collective Classification of Political Discourse on Twitter"
            ]
        },
        {
            "id": "task1540-687259fef8434f9f85ab4a0007bbd01f",
            "input": "For most reinforcement learning approaches, the learning is performed by maximizing an accumulative reward that is expectedly and manually defined for specific tasks. However, in real world, rewards are emergent phenomena from the complex interactions between agents and environments. In this paper, we propose an implicit generic reward model for reinforcement learning. Unlike those rewards that are manually defined for specific tasks, such implicit reward is task independent. It only comes from the deviation from the agents’ previous experiences.",
            "output": [
                "Experience enrichment based task independent reward model"
            ]
        },
        {
            "id": "task1540-b879a327f2ad4144b5cf972cd8123178",
            "input": "We consider the problem of Bayesian parameter estimation for deep neural networks, which is important in problem settings where we may have little data, and/ or where we need accurate posterior predictive densities p(y|x,D), e.g., for applications involving bandits or active learning. One simple approach to this is to use online Monte Carlo methods, such as SGLD (stochastic gradient Langevin dynamics). Unfortunately, such a method needs to store many copies of the parameters (which wastes memory), and needs to make predictions using many versions of the model (which wastes time). We describe a method for “distilling” a Monte Carlo approximation to the posterior predictive density into a more compact form, namely a single deep neural network. We compare to two very recent approaches to Bayesian neural networks, namely an approach based on expectation propagation [HLA15] and an approach based on variational Bayes [BCKW15]. Our method performs better than both of these, is much simpler to implement, and uses less computation at test time.",
            "output": [
                "Bayesian Dark Knowledge"
            ]
        },
        {
            "id": "task1540-75a0ab0784724d7fa8a04aebbf4b4efe",
            "input": "<lb>This work addresses the problem of regret minimization in non-stochastic multi-<lb>armed bandit problems, focusing on performance guarantees that hold with high<lb>probability. Such results are rather scarce in the literature since proving them re-<lb>quires a large deal of technical effort and significant modifications to the standard,<lb>more intuitive algorithms that come only with guarantees that hold on expectation.<lb>One of these modifications is forcing the learner to sample arms from the uniform<lb>distribution at least Ω(<lb>√<lb>T ) times over T rounds, which can adversely affect per-<lb>formance if many of the arms are suboptimal. While it is widely conjectured that<lb>this property is essential for proving high-probability regret bounds, we show in<lb>this paper that it is possible to achieve such strong results without this undesirable<lb>exploration component. Our result relies on a simple and intuitive loss-estimation<lb>strategy called Implicit eXploration (IX) that allows a remarkably clean analy-<lb>sis. To demonstrate the flexibility of our technique, we derive several improved<lb>high-probability bounds for various extensions of the standard multi-armed bandit<lb>framework. Finally, we conduct a simple experiment that illustrates the robustness<lb>of our implicit exploration technique.",
            "output": [
                "Explore no more: Improved high-probability regret bounds for non-stochastic bandits"
            ]
        },
        {
            "id": "task1540-48425edfdf5e478ea3b38ffd46b40913",
            "input": "Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network’s simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.",
            "output": [
                "Deep Learning and the Information Bottleneck Principle"
            ]
        },
        {
            "id": "task1540-859ec65ea47143329cbc87d336137411",
            "input": "OmniGraph, a novel representation to support a range of NLP classification tasks, integrates lexical items, syntactic dependencies and frame semantic parses into graphs. Feature engineering is folded into the learning through convolution graph kernel learning to explore different extents of the graph. A high-dimensional space of features includes individual nodes to complex networks. In experiments on a text-forecasting problem that predicts stock price change from news for company mentions, OmniGraph beats several benchmarks based on bag-of-words, syntactic dependencies, and semantic trees. The highly expressive features OmniGraph discovers provide insights into the semantics across distinct market sectors. To demonstrate the method’s generality, we also report its high performance results on a fine-grained sentiment corpus.",
            "output": [
                "OmniGraph: Rich Representation and Graph Kernel Learning"
            ]
        },
        {
            "id": "task1540-fb3119e4f050432da4cc2297d7be30f7",
            "input": "Although end-to-end Neural Machine Translation (NMT) has achieved remarkable progress in the past two years, it suffers from a major drawback: translations generated by NMT systems often lack of adequacy. It has been widely observed that NMT tends to repeatedly translate some source words while mistakenly ignoring other words. To alleviate this problem, we propose a novel encoder-decoder-reconstructor framework for NMT. The reconstructor, incorporated into the NMT model, manages to reconstruct the input source sentence from the hidden layer of the output target sentence, to ensure that the information in the source side is transformed to the target side as much as possible. Experiments show that the proposed framework significantly improves the adequacy of NMT output and achieves superior translation result over state-of-theart NMT and statistical MT systems.",
            "output": [
                "Neural Machine Translation with Reconstruction"
            ]
        },
        {
            "id": "task1540-97bb9fe718294e38bdee2b32a502c77a",
            "input": "One of the most prominent challenges in clustering is “the user’s dilemma,” which is the problem of selecting an appropriate clustering algorithm for a specific task. A formal approach for addressing this problem relies on the identification of succinct, user-friendly properties that formally capture when certain clustering methods are preferred over others. Until now these properties focused on advantages of classical Linkage-Based algorithms, failing to identify when other clustering paradigms, such as popular center-based methods, are preferable. We present surprisingly simple new properties that delineate the differences between common clustering paradigms, which clearly and formally demonstrates advantages of centerbased approaches for some applications. These properties address how sensitive algorithms are to changes in element frequencies, which we capture in a generalized setting where every element is associated with a real-valued weight. ∗E-mail: mackerman@fsu.edu †E-mail: shai@cs.uwaterloo.ca ‡E-mail: simina.branzei@gmail.com §E-mail: dloker@cs.uwaterloo.ca 1 ar X iv :1 10 9. 18 44 v2 [ cs .L G ] 4 O ct 2 01 6",
            "output": [
                "Weighted Clustering"
            ]
        },
        {
            "id": "task1540-44970a41414b4c2ebf5c03dda6459c01",
            "input": "We introduce a new discrepancy score between two distributions that gives an indi-<lb>cation on their similarity. While much research has been done to determine if two<lb>samples come from exactly the same distribution, much less research considered<lb>the problem of determining if two finite samples come from similar distributions.<lb>The new score gives an intuitive interpretation of similarity; it optimally perturbs<lb>the distributions so that they best fit each other. The score is defined between<lb>distributions, and can be efficiently estimated from samples. We provide conver-<lb>gence bounds of the estimated score, and develop hypothesis testing procedures<lb>that test if two data sets come from similar distributions. The statistical power of<lb>this procedures is presented in simulations. We also compare the score’s capacity<lb>to detect similarity with that of other known measures on real data.",
            "output": [
                "The Perturbed Variation"
            ]
        },
        {
            "id": "task1540-fc21cb99bc9c4535a523786ddc4d6cdb",
            "input": "We address the problem of localizing noncollaborative WiFi devices in a large region. Our main motive is to localize humans by localizing their WiFi devices, e.g. during search-and-rescue operations after a natural disaster. We use an active sensing approach that relies on Unmanned Aerial Vehicles (UAVs) to collect signal-strength measurements at informative locations. The problem is challenging since the measurement is received at arbitrary times and they are received only when the UAV is in close proximity to the device. For these reasons, it is extremely important to make prudent decision with very few measurements. We use the Bayesian optimization approach based on Gaussian process (GP) regression. This approach works well for our application since GPs give reliable predictions with very few measurements while Bayesian optimization makes a judicious trade-off between exploration and exploitation. In field experiments conducted over a region of 1000 × 1000 m, we show that our approach reduces the search area to less than 100 meters around the WiFi device within 5 minutes only. Overall, our approach localizes the device in less than 15 minutes with an error of less than 20 meters.",
            "output": [
                "UAVs using Bayesian Optimization to Locate WiFi Devices"
            ]
        },
        {
            "id": "task1540-b08fad757fe447fb94dfe3388d212d3f",
            "input": "Relation classification is an important research arena in the field of natural language processing (NLP). In this paper, we present SDP-LSTM, a novel neural network to classify the relation of two entities in a sentence. Our neural architecture leverages the shortest dependency path (SDP) between two entities; multichannel recurrent neural networks, with long short term memory (LSTM) units, pick up heterogeneous information along the SDP. Our proposed model has several distinct features: (1) The shortest dependency paths retain most relevant information (to relation classification), while eliminating irrelevant words in the sentence. (2) The multichannel LSTM networks allow effective information integration from heterogeneous sources over the dependency paths. (3) A customized dropout strategy regularizes the neural network to alleviate overfitting. We test our model on the SemEval 2010 relation classification task, and achieve an F1-score of 83.7%, higher than competing methods in the literature.",
            "output": [
                "Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths"
            ]
        },
        {
            "id": "task1540-97f06ae5ec1c465d98b51240b4cc1ca5",
            "input": "We present a work-in-progress snapshot of learning with a 15 billion parameter deep learning network on HPC architectures applied to the largest publicly available natural image and video dataset released to-date. Recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers. We train our three-layer deep neural network on the Yahoo! Flickr Creative Commons 100M dataset. The dataset comprises approximately 99.2 million images and 800, 000 user-created videos from Yahoo’s Flickr image and video sharing platform. Training of our network takes eight days on 98 GPU nodes at the High Performance Computing Center at Lawrence Livermore National Laboratory. Encouraging preliminary results and future research directions are presented and discussed.",
            "output": [
                "LARGE-SCALE DEEP LEARNING ON THE YFCC100M DATASET"
            ]
        },
        {
            "id": "task1540-c7d821d483384bb69f4aec65d339ea9c",
            "input": "Texts are complex structures emerging from an intricate system consisting of syntactical constraints and semantical relationships. While the complete modeling of such structures is impractical owing to the high level of complexity inherent to linguistic constructions, under a limited domain, certain tasks can still be performed. Recently, statistical techniques aiming at analysis of texts, referred to as text analytics, have departed from the use of simple word count statistics towards a new paradigm. Text mining now hinges on a more sophisticate set of methods, including the representation of texts as complex networks. In this perspective, networks represent a set of textual elements, typically words; and links are established via adjacency relationships. While current word-adjacency (co-occurrence) methods successfully grasp syntactical and stylistic features of written texts, they are unable to represent important aspects of textual data, such as its topical structure. As a consequence, the mesoscopic structure of texts is often overlooked by current methodologies. In order to grasp mesoscopic characteristics of semantical content in written texts, we devised a network approach which is able to analyze documents in a multi-scale, mesoscopic fashion. In the proposed model, a limited amount of adjacent paragraphs are represented as nodes, which are connected whenever they share a minimum semantical content. To illustrate the capabilities of our model, we present, as a use case, a qualitative analysis of “Alice’s Adventures in Wonderland”, a novel by Lewis Carroll. We show that the mesoscopic structure of documents modeled as networks reveals many semantic traits of texts, a feature that could be explored in a myriad of semantic-based applications.",
            "output": [
                "Mesoscopic representation of texts as complex networks"
            ]
        },
        {
            "id": "task1540-e96b7528dac94d899fe995b649dd3436",
            "input": "We give an interpretation of the Maxi­ mum Entropy (MaxEnt) Principle in game­ theoretic terms. Based on this interpretation, we make a formal distinction between differ­ ent ways of applying Maximum Entropy dis­ tributions. MaxEnt has frequently been crit­ icized on the grounds that it leads to highly representation dependent results. Our dis­ tinction allows us to avoid this problem in many cases.",
            "output": [
                "Maximum Entropy and the Glasses You are Looking Through"
            ]
        },
        {
            "id": "task1540-b2f4bdba99324ecb8efec005128180af",
            "input": "Language learning is thought to be a highly complex process. One of the hurdles in learning a language is to learn the rules of syntax of the language. Rules of syntax are often ordered in that before one rule can applied one must apply another. It has been thought that to learn the order of n rules one must go through all n! permutations. Thus to learn the order of 27 rules would require 27! steps or 1.08889x10 steps. This number is much greater than the number of seconds since the beginning of the universe! In an insightful analysis the linguist Block ([Block 86], pp. 62-63, p.238) showed that with the assumption of transitivity this vast number of learning steps reduces to a mere 377 steps. We present a mathematical analysis of the complexity of Block’s algorithm. The algorithm has a complexity of order n given n rules. In addition, we improve Block’s results exponentially, by introducing an algorithm that has complexity of order less than n log n.",
            "output": [
                "On the complexity of learning a language: An improvement of Block’s algorithm"
            ]
        },
        {
            "id": "task1540-dbd86802baa04ef68e490c6d396a3f83",
            "input": "Partial monitoring games are repeated games where the learner receives feedback that might be different from adversary’s move or even the reward gained by the learner. Recently, a general model of combinatorial partial monitoring (CPM) games was proposed [1], where the learner’s action space can be exponentially large and adversary samples its moves from a bounded, continuous space, according to a fixed distribution. The paper gave a confidence bound based algorithm (GCB) that achieves O(T 2/3 logT ) distribution independent and O(log T ) distribution dependent regret bounds. The implementation of their algorithm depends on two separate offline oracles and the distribution dependent regret additionally requires existence of a unique optimal action for the learner. Adopting their CPM model, our first contribution is a Phased Exploration with Greedy Exploitation (PEGE) algorithmic framework for the problem. Different algorithms within the framework achieve O(T 2/3 √ logT ) distribution independent and O(log T ) distribution dependent regret respectively. Crucially, our framework needs only the simpler “argmax” oracle from GCB and the distribution dependent regret does not require existence of a unique optimal action. Our second contribution is another algorithm, PEGE2, which combines gap estimation with a PEGE algorithm, to achieve an O(log T ) regret bound, matching the GCB guarantee but removing the dependence on size of the learner’s action space. However, like GCB, PEGE2 requires access to both offline oracles and the existence of a unique optimal action. Finally, we discuss how our algorithm can be efficiently applied to a CPM problem of practical interest: namely, online ranking with feedback at the top.",
            "output": [
                "Phased Exploration with Greedy Exploitation in Stochastic Combinatorial Partial Monitoring Games"
            ]
        },
        {
            "id": "task1540-5fd388839a9f48da928b6197389b5f39",
            "input": "Word embeddings are used with success for a variety of tasks involving lexical semantic similarities between individual words. Using unsupervised methods and just cosine similarity, encouraging results were obtained for analogical similarities. In this paper, we explore the potential of pre-trained word embeddings to identify generic types of semantic relations in an unsupervised experiment. We propose a new relational similarity measure based on the combination of word2vec’s CBOW input and output vectors which outperforms concurrent vector representations, when used for unsupervised clustering on SemEval 2010 Relation Classification data.",
            "output": [
                "Exploring Vector Spaces for Semantic Relations"
            ]
        },
        {
            "id": "task1540-24a8973e3d0949af8693af22ebd26046",
            "input": "Many sequential processing tasks require complex nonlinear transition functions from one step to the next. However, recurrent neural networks with such “deep\" transition functions remain difficult to train, even when using Long Short-Term Memory networks. We introduce a novel theoretical analysis of recurrent networks based on Geršgorin’s circle theorem that illuminates several modeling and optimization issues and improves our understanding of the LSTM cell. Based on this analysis we propose Recurrent Highway Networks (RHN), which are long not only in time but also in space, generalizing LSTMs to larger step-to-step depths. Experiments indicate that the proposed architecture results in complex but efficient models, beating previous models for character prediction on the Hutter Prize dataset with less than half of the parameters.",
            "output": [
                "Recurrent Highway Networks"
            ]
        },
        {
            "id": "task1540-58417a7e005f4ea6a973e49c450c358d",
            "input": "Many popular knowledge graphs such as Freebase, YAGO or DBPedia maintain a list of non-discrete aributes for each entity. Intuitively, these aributes such as height, price or population count are able to richly characterize entities in knowledge graphs. is additional source of information may help to alleviate the inherent sparsity and incompleteness problem that are prevalent in knowledge graphs. Unfortunately, many state-of-the-art relational learning models ignore this information due to the challenging nature of dealing with non-discrete data types in the inherently binary-natured knowledge graphs. In this paper, we propose a novel multi-task neural network approach for both encoding and prediction of non-discrete aribute information in a relational setting. Specically, we train a neural network for triplet prediction along with a separate network for aribute value regression. Via multi-task learning, we are able to learn representations of entities, relations and aributes that encode information about both tasks. Moreover, such aributes are not only central to many predictive tasks as an information source but also as a prediction target. erefore, models that are able to encode, incorporate and predict such information in a relational learning context are highly aractive as well. We show that our approach outperforms many state-ofthe-art methods for the tasks of relational triplet classication and aribute value prediction.",
            "output": [
                "Multi-Task Neural Network for Non-discrete Aribute Prediction in Knowledge Graphs"
            ]
        },
        {
            "id": "task1540-6f344cb1352f4456ab8c1f54d38791d6",
            "input": "Critical Infrastructures like power and communication networks are highly interdependent on each other for their full functionality. Many significant research have been pursued to model the interdependency and failure analysis of these interdependent networks. However most of these models fail to capture the complex interdependencies that might actually exist between the infrastructures. The Implicative Interdependency Model that utilizes Boolean Logic to capture complex interdependencies was recently proposed which overcome the limitations of the existing models. A number of problems were studies based on this model. In this paper we study the Robustness problem in Interdependent Power and Communication Network. The robustness is defined with respect to two parameters K ∈ I ∪ {0} and ρ ∈ (0, 1]. We utilized the Implicative Interdependency Model model to capture the complex interdependency between the two networks. The model classifies the interdependency relations into four cases. Computational complexity of the problem is analyzed for each of these cases. A polynomial time algorithm is designed for the first case that outputs the optimal solution. All the other cases are proved to be NP-complete. An in-approximability bound is provided for the third case. For the general case we formulate an Integer Linear Program to get the optimal solution and a polynomial time heuristic. The applicability of the heuristic is evaluated using power and communication network data of Maricopa County, Arizona. The experimental results showed that the heuristic almost always produced near optimal value of parameter K for ρ < 0.42.",
            "output": [
                "On Robustness in Multilayer Interdependent Network"
            ]
        },
        {
            "id": "task1540-432689a9cf554c078a36b625d2780a60",
            "input": "This paper describes several results of Wimmics, a research lab which names stands for: web-instrumented man-machine interactions, communities, and semantics. The approaches introduced here rely on graph-oriented knowledge representation, reasoning and operationalization to model and support actors, actions and interactions in web-based epistemic communities. The research results are applied to support and foster interactions in online communities and manage their resources.",
            "output": [
                "Challenges in bridging Social Semantics and Formal Semanticson the Web"
            ]
        },
        {
            "id": "task1540-c0576782083247599b462fea6507a074",
            "input": "External neural memory structures have recently become a popular tool for algorithmic deep learning (Graves et al., 2014; Weston et al., 2014). These models generally utilize differentiable versions of traditional discrete memory-access structures (random access, stacks, tapes) to provide the storage necessary for computational tasks. In this work, we argue that these neural memory systems lack specific structure important for relative indexing, and propose an alternative model, Lieaccess memory, that is explicitly designed for the neural setting. In this paradigm, memory is accessed using a continuous head in a key-space manifold. The head is moved via Lie group actions, such as shifts or rotations, generated by a controller, and memory access is performed by linear smoothing in key space. We argue that Lie groups provide a natural generalization of discrete memory structures, such as Turing machines, as they provide inverse and identity operators while maintaining differentiability. To experiment with this approach, we implement a simplified Lie-access neural Turing machine (LANTM) with different Lie groups. We find that this approach is able to perform well on a range of algorithmic tasks.",
            "output": [
                "LIE-ACCESS NEURAL TURING MACHINES"
            ]
        },
        {
            "id": "task1540-e7e6e97015f74f959bdc474d39255f49",
            "input": "In this paper we propose a simple yet powerful method for learning representations in supervised learning scenarios where an input datapoint is described by a set of feature vectors and its associated output may be given by soft labels indicating, for example, class probabilities. We represent an input datapoint as a K-dimensional vector, where each component is a mixture of probabilities over its corresponding set of feature vectors. Each probability indicates how likely a feature vector is to belong to one-out-of-K unknown prototype patterns. We propose a probabilistic model that parameterizes these prototype patterns in terms of hidden variables and therefore it can be trained with conventional approaches based on likelihood maximization. More importantly, both the model parameters and the prototype patterns can be learned from data in a discriminative way. We show that our model can be seen as a probabilistic generalization of learning vector quantization (LVQ). We apply our method to the problems of shape classification, hyperspectral imaging classification and people’s work class categorization, showing the superior performance of our method compared to the standard prototype-based classification approach and other competitive benchmarks.",
            "output": [
                "Discriminative Probabilistic Prototype Learning"
            ]
        },
        {
            "id": "task1540-97375a901eea4541b53f27bb72ab3a23",
            "input": "Ever growing number of image documents available on the Internet continuously motivates research in better annotation models and more efficient retrieval methods. Formal knowledge representation of objects and events in pictures, their interaction as well as context complexity becomes no longer an option for a quality image repository, but a necessity. We present an ontologybased online image annotation tool WNtags and demonstrate its usefulness in several typical multimedia retrieval tasks using International Affective Picture System emotionally annotated image database. WNtags is built around WordNet lexical ontology but considers Suggested Upper Merged Ontology as the preferred labeling formalism. WNtags uses sets of weighted WordNet synsets as high-level image semantic descriptors and query matching is performed with word stemming and node distance metrics. We also elaborate our near future plans to expand image content description with induced affect as in stimuli for research of human emotion and attention.",
            "output": [
                "WNtags: A Web-Based Tool For Image Labeling And Retrieval With Lexical Ontologies"
            ]
        },
        {
            "id": "task1540-d5364ab9f3a1460889ac182daa614eb3",
            "input": "Whereas acausal Bayesian networks rep­ resent probabilistic independence, causal Bayesian networks represent causal relation­ ships. In this paper, we examine Bayesian methods for learning both types of networks. Bayesian methods for learning acausal net­ works are fairly well developed. These meth­ ods often employ assumptions to facilitate the construction of priors, including the as­ sumptions of parameter independence, pa­ rameter modularity, and likelihood equiva­ lence. We show that although these assump­ tions also can be appropriate for learning causal networks, we need additional assump­ tions in order to learn causal networks. We introduce two sufficient assumptions, called mechanism independence and component in­ dependence. We show that these new as­ sumptions, when combined with parame­ ter independence, parameter modularity, and likelihood equivalence, allow us to apply methods for learning acausal networks to learn causal networks.",
            "output": [
                "A Bayesian Approach to Learning Causal Networks"
            ]
        },
        {
            "id": "task1540-079ff52ce1404f4a8f8bc52624fd69e9",
            "input": "The folksonomy is the result of free personal information or assignment of tags to an object (determined by the URI) in order to find them. The practice of tagging is done in a collective environment. Folksonomies are self constructed, based on co-occurrence of definitions, rather than a hierarchical structure of the data. The downside of this was that a few sites and applications are able to successfully exploit the sharing of bookmarks. The need for tools that are able to resolve the ambiguity of the definitions is becoming urgent as the need of simple instruments for their visualization, editing and exploitation in web applications still hinders their diffusion and wide adoption. An intelligent interactive interface design for folksonomies should consider the contextual design and inquiry based on a concurrent interaction for a perceptual user interfaces. To represent folksonomies a new concept structure called \"Folksodriven\" is used in this paper. While it is presented the Folksodriven Structure Network (FSN) to resolve the ambiguity of definitions of folksonomy tags suggestions for the user. On this base a Human-Computer Interactive (HCI) systems is developed for the visualization, navigation, updating and maintenance of folksonomies Knowledge Bases – the FSN – through the web. System functionalities as well as its internal architecture will be introduced.",
            "output": [
                "Intelligent Interface Architectures for Folksonomy Driven Structure Network"
            ]
        },
        {
            "id": "task1540-2246461daffb45e9b7fbefe4e1ea6ff7",
            "input": "We introduce the value iteration network: a fully differentiable neural network with a ‘planning module’ embedded within. Value iteration networks are suitable for making predictions about outcomes that involve planning-based reasoning, such as predicting a desired trajectory from an observation of a map. Key to our approach is a novel differentiable approximation of the valueiteration algorithm, which can be represented as a convolutional neural network, and trained endto-end using standard backpropagation. We evaluate our value iteration networks on the task of predicting optimal obstacle-avoiding trajectories from an image of a landscape, both on synthetic data, and on challenging raw images of the Mars terrain.",
            "output": [
                "Value Iteration Networks"
            ]
        },
        {
            "id": "task1540-a0003542905e4b9d84be7c7c34748d1a",
            "input": "The popular Alternating Least Squares (ALS) algorithm for tensor decomposition is extremely efficient, but often converges to poor local optima, particularly when the weights of the factors are non-uniform. We propose a modification of the ALS approach that is as efficient as standard ALS, but provably recovers the true factors with random initialization under standard incoherence assumptions on the factors of the tensor. We demonstrate the significant practical superiority of our approach over traditional ALS (with both random initialization and SVDbased initialization) for a variety of tasks on synthetic data—including tensor factorization on exact, noisy and over-complete tensors, as well as tensor completion—and for computing word embeddings from a third-order word tri-occurrence tensor.",
            "output": [
                "Orthogonalized ALS: A Theoretically Principled Tensor Decomposition Algorithm for Practical Use"
            ]
        },
        {
            "id": "task1540-7df46f30095b44809dcffa7d42e23a61",
            "input": "We present a concrete design for Solomonoff’s incremental machine learning system suitable for desktop computers. We use R5RS Scheme and its standard library with a few omissions as the reference machine. We introduce a Levin Search variant based on a stochastic Context Free Grammar together with new update algorithms that use the same grammar as a guiding probability distribution for incremental machine learning. The updates include adjusting production probabilities, re-using previous solutions, learning programming idioms and discovery of frequent subprograms. The issues of extending the a priori probability distribution and bootstrapping are discussed. We have implemented a good portion of the proposed algorithms. Experiments with toy problems show that the update algorithms work as expected.",
            "output": [
                "Gigamachine: incremental machine learning on desktop computers"
            ]
        },
        {
            "id": "task1540-7f63afca4ed64fe3b235b0b290a87733",
            "input": "Kernel canonical correlation analysis (KCCA) is a nonlinear multi-view representation learning technique with broad applicability in statistics and machine learning. Although there is a closed-form solution for the KCCA objective, it involves solving an N × N eigenvalue system where N is the training set size, making its computational requirements in both memory and time prohibitive for large-scale problems. Various approximation techniques have been developed for KCCA. A commonly used approach is to first transform the original inputs to an M -dimensional random feature space so that inner products in the feature space approximate kernel evaluations, and then apply linear CCA to the transformed inputs. In many applications, however, the dimensionality M of the random feature space may need to be very large in order to obtain a sufficiently good approximation; it then becomes challenging to perform the linear CCA step on the resulting very high-dimensional data matrices. We show how to use a stochastic optimization algorithm, recently proposed for linear CCA and its neuralnetwork extension, to further alleviate the computation requirements of approximate KCCA. This approach allows us to run approximate KCCA on a speech dataset with 1.4 million training samples and a random feature space of dimensionality M = 100000 on a typical workstation.",
            "output": [
                "LARGE-SCALE APPROXIMATE KERNEL CANONICAL CORRELATION ANALYSIS"
            ]
        },
        {
            "id": "task1540-7ad7038fe240409b9b5a41a202bb15fd",
            "input": "The 2002 Trading Agent Competition (TAC) presented a challenging market game in the domain of travel shopping. One of the pivotal issues in this domain is uncertainty about hotel prices, which have a significant influence on the relative cost of alternative trip schedules. Thus, virtually all participants employ some method for predicting hotel prices. We survey approaches employed in the tournament, finding that agents apply an interesting diversity of techniques, taking into account differing sources of evidence bearing on prices. Based on data provided by entrants on their agents’ actual predictions in the TAC-02 finals and semifinals, we analyze the relative efficacy of these approaches. The results show that taking into account game-specific information about flight prices is a major distinguishing factor. Machine learning methods effectively induce the relationship between flight and hotel prices from game data, and a purely analytical approach based on competitive equilibrium analysis achieves equal accuracy with no historical data. Employing a new measure of prediction quality, we relate absolute accuracy to bottom-line performance in the game.",
            "output": [
                "Price Prediction in a Trading Agent Competition"
            ]
        },
        {
            "id": "task1540-48f17c238b0a45879d96a5b9e51814a5",
            "input": "A Support Vector Machine (SVM) has become a very popular machine learning method for text classification. One reason for this relates to the range of existing kernels which allow for classifying data that is not linearly separable. The linear, polynomial and RBF (Gaussian Radial Basis Function) kernel are commonly used and serve as a basis of comparison in our study. We show how to derive the primal form of the quadratic Power Kernel (PK) – also called the Negative Euclidean Distance Kernel (NDK) – by means of complex numbers. We exemplify the NDK in the framework of text categorization using the Dewey Document Classification (DDC) as the target scheme. Our evaluation shows that the power kernel produces F-scores that are comparable to the reference kernels, but is – except for the linear kernel – faster to compute. Finally, we show how to extend the NDK-approach by including the Mahalanobis distance. Keywords—SVM, kernel function, text categorization",
            "output": [
                "Complex Decomposition of the Negative Distance Kernel"
            ]
        },
        {
            "id": "task1540-bf6386f97d9a416cb9bdfe58e25e9d5c",
            "input": "Deep neural networks (DNNs) are powerful types of artificial neural networks (ANNs) that use several hidden layers. They have recently gained considerable attention in the speech transcription and image recognition community (Krizhevsky et al., 2012) for their superior predictive properties including robustness to overfitting. However their application to algorithmic trading has not been previously researched, partly because of their computational complexity. This paper describes the application of DNNs to predicting financial market movement directions. In particular we describe the configuration and training approach and then demonstrate their application to backtesting a simple trading strategy over 43 different Commodity and FX future mid-prices at 5-minute intervals. All results in this paper are generated using a C++ implementation on the Intel Xeon Phi co-processor which is 11.4x faster than the serial version and a Python strategy backtesting environment both of which are available as open source code written by the authors.",
            "output": [
                "Classification-based Financial Markets Prediction using Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-ef386156b5254f7589f3d62b3dc751ba",
            "input": "We consider relative error low rank approximation of tensors with respect to the Frobenius norm. Namely, given an order-q tensor A ∈ R ∏q i=1 ni , output a rank-k tensor B for which ‖A − B‖F ≤ (1 + ) OPT, where OPT = infrank-k A′ ‖A − A‖F . Despite much success on obtaining relative error low rank approximations for matrices, no such results were known for tensors. One structural issue is that there may be no rank-k tensor Ak achieving the above infinum. Another, computational issue, is that an efficient relative error low rank approximation algorithm for tensors would allow one to compute the rank of a tensor, which is NP-hard. We bypass these two issues via (1) bicriteria and (2) parameterized complexity solutions: 1. We give an algorithm which outputs a rank k′ = O((k/ )q−1) tensor B for which ‖A − B‖F ≤ (1+ ) OPT in nnz(A)+n ·poly(k/ ) time in the real RAM model, whenever either Ak exists or OPT > 0. Here nnz(A) denotes the number of non-zero entries in A. If both Ak does not exist and OPT = 0, then B instead satisfies ‖A − B‖F < γ, where γ is any positive, arbitrarily small function of n. 2. We give an algorithm for any δ > 0 which outputs a rank k tensor B for which ‖A−B‖F ≤ (1+ ) OPT and runs in (nnz(A)+n poly(k/ )+exp(k/ )) ·nδ time in the unit cost RAM model, whenever OPT > 2−O(n ) and there is a rank-k tensor B = ∑k i=1 ui ⊗ vi ⊗ wi for which ‖A − B‖F ≤ (1 + /2) OPT and ‖ui‖2, ‖vi‖2, ‖wi‖2 ≤ 2 δ). If OPT ≤ 2−Ω(nδ), then B instead satisfies ‖A−B‖F ≤ 2−Ω(n δ). Our first result is polynomial time, and in fact input sparsity time, in n, k, and 1/ , for any k ≥ 1 and any 0 < < 1, while our second result is fixed parameter tractable in k and 1/ . For outputting a rank-k tensor, or even a bicriteria solution with rank-Ck for a certain constant C > 1, we show a 2 1−o(1)) time lower bound under the Exponential Time Hypothesis. Our results are based on an “iterative existential argument”, and give the first relative error low rank approximations for tensors for a large number of error measures for which nothing was known. In particular, we give the first relative error approximation algorithms on tensors for: column row and tube subset selection, entrywise `p-low rank approximation for 1 ≤ p < 2, low rank approximation with respect to sum of Euclidean norms of faces or tubes, weighted low rank approximation, and low rank approximation in distributed and streaming models. We also obtain several new results for matrices, such as nnz(A)-time CUR decompositions, improving the previous nnz(A) log n-time CUR decompositions, which may be of independent interest. ∗Work done while visiting IBM Almaden, and supported in part by UTCS TAship (CS361 Spring 17 Introduction to Computer Security). †Supported in part by Simons Foundation, and NSF CCF-1617955. ar X iv :1 70 4. 08 24 6v 1 [ cs .D S] 2 6 A pr 2 01 7",
            "output": [
                "Relative Error Tensor Low Rank Approximation"
            ]
        },
        {
            "id": "task1540-81803e5a331e4118ae86c804a11908a6",
            "input": "In this paper we propose a unified framework for structured prediction with latent variables which includes hidden conditional random fields and latent structured support vector machines as special cases. We describe a local entropy approximation for this general formulation using duality, and derive an efficient message passing algorithm that is guaranteed to converge. We demonstrate its effectiveness in the tasks of image segmentation as well as 3D indoor scene understanding from single images, showing that our approach is superior to latent structured support vector machines and hidden conditional random fields.",
            "output": [
                "Efficient Structured Prediction with Latent Variables for General Graphical Models"
            ]
        },
        {
            "id": "task1540-4dea9013c533438f8b863c9bc6cb69d9",
            "input": "This paper presents the input convex neural network architecture. These are scalar-valued (potentially deep) neural networks with constraints on the network parameters such that the output of the network is a convex function of (some of) the inputs. The networks allow for efficient inference via optimization over some inputs to the network given others, and can be applied to settings including structured prediction, data imputation, reinforcement learning, and others. In this paper we lay the basic groundwork for these models, proposing methods for inference, optimization and learning, and analyze their representational power. We show that many existing neural network architectures can be made input-convex with only minor modification, and develop specialized optimization algorithms tailored to this setting. Finally, we highlight the performance of the methods on multi-label prediction, image completion, and reinforcement learning problems, where we show improvement over the existing state of the art in many cases.",
            "output": [
                "Input Convex Neural Networks"
            ]
        },
        {
            "id": "task1540-692ca237acb445b38b23ec8d57ed8168",
            "input": "Abstract. We study the learning algorithm corresponding to the incremental gradient descent defined by the empirical risk over an infinite dimensional hypotheses space. We consider a statistical learning setting and show that, provided with a universal step-size and a suitable early stopping rule, the learning algorithm thus obtained is universally consistent and derive finite sample bounds. Our results provide a theoretical foundation for considering early stopping in online learning algorithms and shed light on the effect of allowing for multiple passes over the data.",
            "output": [
                "REGULARIZATION BY EARLY STOPPING FOR ONLINE LEARNING ALGORITHMS"
            ]
        },
        {
            "id": "task1540-388ec181bbed4262982cee313ed311bb",
            "input": "The role of kernels is central to machine learning. Motivated by the importance of power law distributions in modeling, simulation and learning, in this paper, we propose a powerlaw generalization of the Gaussian kernel. This generalization is based on q-Gaussian distribution, which is a power-law distribution studied in context of nonextensive statistical mechanics. We prove that the proposed kernel is positive definite, and provide some insights regarding the corresponding Reproducing Kernel Hilbert Space (RKHS). We also study practical significance of qGaussian kernels in classification, regression and clustering, and present some simulation results.",
            "output": [
                "On q-Gaussian kernel and its Reproducing Kernel Hilbert Space"
            ]
        },
        {
            "id": "task1540-24229694c5e042b585e375f116397913",
            "input": "Existing deep embedding methods in vision tasks are capable of learning a compact Euclidean space from images, where Euclidean distances correspond to a similarity metric. To make learning more effective and efficient, hard sample mining is usually employed, with samples identified through computing the Euclidean feature distance. However, the global Euclidean distance cannot faithfully characterize the true feature similarity in a complex visual feature space, where the intraclass distance in a high-density region may be larger than the interclass distance in low-density regions. In this paper, we introduce a Position-Dependent Deep Metric (PDDM) unit, which is capable of learning a similarity metric adaptive to local feature structure. The metric can be used to select genuinely hard samples in a local neighborhood to guide the deep embedding learning in an online and robust manner. The new layer is appealing in that it is pluggable to any convolutional networks and is trained end-to-end. Our local similarity-aware feature embedding not only demonstrates faster convergence and boosted performance on two complex image retrieval datasets, its large margin nature also leads to superior generalization results under the large and open set scenarios of transfer learning and zero-shot learning on ImageNet 2010 and ImageNet-10K datasets.",
            "output": [
                "Local Similarity-Aware Deep Feature Embedding"
            ]
        },
        {
            "id": "task1540-11cfaddcbfb2487a8974d2dcf72ed948",
            "input": "<lb>We consider the problem of subspace clustering: given points that lie on or near the union of<lb>many low-dimensional linear subspaces, recover the subspaces. To this end, one first identifies<lb>sets of points close to the same subspace and uses the sets to estimate the subspaces. As the<lb>geometric structure of the clusters (linear subspaces) forbids proper performance of general<lb>distance based approaches such as K-means, many model-specific methods have been proposed.<lb>In this paper, we provide new simple and efficient algorithms for this problem. Our statistical<lb>analysis shows that the algorithms are guaranteed exact (perfect) clustering performance under<lb>certain conditions on the number of points and the affinity between subspaces. These conditions<lb>are weaker than those considered in the standard statistical literature. Experimental results on<lb>synthetic data generated from the standard unions of subspaces model demonstrate our theory.<lb>We also show that our algorithm performs competitively against state-of-the-art algorithms on<lb>real-world applications such as motion segmentation and face clustering, with much simpler<lb>implementation and lower computational cost.",
            "output": [
                "Greedy Subspace Clustering"
            ]
        },
        {
            "id": "task1540-ca2aee8a07b745c28878d3a267a986f0",
            "input": "In this paper, we propose to employ the convolutional neural network (CNN) for the image question answering (QA). Our proposed CNN provides an end-to-end framework with convolutional architectures for learning not only the image and question representations, but also their inter-modal interactions to produce the answer. More specifically, our model consists of three CNNs: one image CNN to encode the image content, one sentence CNN to compose the words of the question, and one multimodal convolution layer to learn their joint representation for the classification in the space of candidate answer words. We demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QA datasets, which are two benchmark datasets for the image QA, with the performances significantly outperforming the state-of-the-art.",
            "output": [
                "Learning to Answer Questions From Image Using Convolutional Neural Network"
            ]
        },
        {
            "id": "task1540-9f8a7513bbe040678d5de9b05aea361b",
            "input": "The amount of data available in the world is growing faster and bigger than our ability to deal with it. However, if we take advantage of the internal structure, data may become much smaller for machine learning purposes. In this paper we focus on one of the most fundamental machine learning tasks, empirical risk minimization (ERM), and provide faster algorithms with the help from the clustering structure of the data. We introduce a simple notion of raw clustering that can be efficiently obtained with just one pass of the data, and propose two algorithms. Our variance-reduction based algorithm ClusterSVRG introduces a new gradient estimator using the clustering information, and our accelerated algorithm ClusterACDM is built on a novel Haar transformation applied to the dual space of each cluster. Our algorithms outperform their classical counterparts both in theory and practice.",
            "output": [
                "Exploiting the Structure: Stochastic Gradient Methods Using Raw Clusters"
            ]
        },
        {
            "id": "task1540-da7be85762304c6a9c03f205c801a886",
            "input": "We consider the problem of off-policy evaluation—estimating the value of a target policy using data collected by another policy—under the contextual bandit model. We establish a minimax lower bound on the mean squared error (MSE), and show that it is matched up to constant factors by the inverse propensity scoring (IPS) estimator. Since in the multi-armed bandit problem the IPS is suboptimal [Li et al., 2015], our result highlights the difficulty of the contextual setting with non-degenerate context distributions. We further consider improvements on this minimax MSE bound, given access to a reward model. We show that the existing doubly robust approach, which utilizes such a reward model, may continue to suffer from high variance even when the reward model is perfect. We propose a new estimator called SWITCH which more effectively uses the reward model and achieves a superior bias-variance tradeoff compared with prior work. We prove an upper bound on its MSE and demonstrate its benefits empirically on a diverse collection of datasets, often seeing orders of magnitude improvements over a number of baselines.",
            "output": [
                "Optimal and Adaptive Off-policy Evaluation in Contextual Bandits"
            ]
        },
        {
            "id": "task1540-286305d3b6a74eba9d963f7128f1a55a",
            "input": "Electronic health records capture patient information using structured controlled vocabularies and unstructured narrative text. While structured data typically encodes lab values, encounters and medication lists, unstructured data captures the physician’s interpretation of the patient’s condition, prognosis, and response to therapeutic intervention. In this paper, we demonstrate that information extraction from unstructured clinical narratives is essential to most clinical applications. We perform an empirical study to validate the argument and show that structured data alone is insufficient in resolving eligibility criteria for recruiting patients onto clinical trials for chronic lymphocytic leukemia (CLL) and prostate cancer. Unstructured data is essential to solving 59% of the CLL trial criteria and 77% of the prostate cancer trial criteria. More specifically, for resolving eligibility criteria with temporal constraints, we show the need for temporal reasoning and information integration with medical events within and across unstructured clinical narratives and structured data.",
            "output": [
                "How essential are unstructured clinical narratives and information fusion to clinical trial recruitment?"
            ]
        },
        {
            "id": "task1540-6a12f816f2284fdebd7e40ba960e5086",
            "input": "We revisit the leaderboard problem introduced by Blum and Hardt (2015) in an effort to reduce overfitting in machine learning benchmarks. We show that a randomized version of their Ladder algorithm achieves leaderboard error O(1/n0.4) compared with the previous best rate of O(1/n1/3). Short of proving that our algorithm is optimal, we point out a major obstacle toward further progress. Specifically, any improvement to our upper bound would lead to asymptotic improvements in the general adaptive estimation setting as have remained elusive in recent years. This connection also directly leads to lower bounds for specific classes of algorithms. In particular, we exhibit a new attack on the leaderboard algorithm that both theoretically and empirically distinguishes between our algorithm and previous leaderboard algorithms.",
            "output": [
                "Climbing a shaky ladder: Better adaptive risk estimation"
            ]
        },
        {
            "id": "task1540-c824401e179247659962c1a7944b2155",
            "input": "Deep Neural Networks (DNNs) are presently the state-of-the-art for image classification tasks. However, recent works have shown that these systems can be easily fooled to misidentify images by modifying the image in particular ways, often rendering them practically useless. Moreover, defense mechanisms proposed in the literature so far are mostly attack-specific and prove to be ineffective against new attacks. Indeed, recent work on universal perturbations can generate a single modification for all test images that is able to make existing networks misclassify 90% of the time. Presently, to our knowledge, no defense mechanisms are effective in preventing this. As such, the design of a general defense strategy against a wide range of attacks for Neural Networks becomes a challenging problem. In this paper, we derive inspiration from recent advances in the field of cybersecurity and multi-agent systems, and propose to use the concept of Moving Target Defense (MTD) for increasing the robustness of well-known deep networks trained on the ImageNet dataset towards such adversarial attacks. In using this technique, we formalize and exploit the notion of differential immunity of different networks to specific attacks. To classify a single test image, we pick one of the trained networks each time and then use its classification output. To ensure maximum robustness, we generate an effective strategy by formulating this interaction as a Repeated Bayesian Stackelberg Game (BSG) with a Defender (who hosts the classification networks) and Users (both Legitimate users and Attackers). As a network switching strategy, we compute a Strong Stackelberg Equilibrium that optimizes the accuracy of prediction while at the same time reduces the misclassification rate on adversarial modification of test images. We show that while our approach produces an accuracy of 92.79% for the legitimate users, attackers can only misclassify images 58% (instead of 93.7%) of the time even when they select the best attack available to them. This is at least twice as good, to sometimes even an order of magnitude better, compared the accuracy rates of the worst affected networks.",
            "output": [
                "Securing Deep Neural Nets against Adversarial Attacks with Moving Target Defense"
            ]
        },
        {
            "id": "task1540-44147bf862b74c0c93cc42aecf3c123d",
            "input": "One of the better studied properties for operators in judgment aggregation is independence, which essentially dictates that the collective judgment on one issue should not depend on the individual judgments given on some other issue(s) in the same agenda. Independence, although considered a desirable property, is too strong, because together with mild additional conditions it implies dictatorship. We propose here a weakening of independence, named agenda separability: a judgment aggregation rule satisfies it if, whenever the agenda is composed of several independent sub-agendas, the resulting collective judgment sets can be computed separately for each sub-agenda and then put together. We show that this property is discriminant, in the sense that among judgment aggregation rules so far studied in the literature, some satisfy it and some do not. We briefly discuss the implications of agenda separability on the computation of judgment aggregation rules.",
            "output": [
                "Agenda Separability in Judgment Aggregation"
            ]
        },
        {
            "id": "task1540-ce5181a4e45e4759aa2017187673233f",
            "input": "We prove in this paper that the expected value of the objective function of the k-means++ algorithm for samples converges to population expected value. As k-means++, for samples, provides with constant factor approximation for k-means objectives, such an approximation can be achieved for the population with increase of the sample size. This result is of potential practical relevance when one is considering using subsampling when clustering large data sets (large data bases).",
            "output": [
                "On the Consistency of k-means++ algorithm"
            ]
        },
        {
            "id": "task1540-a3db446d0f3944009019383c266188c7",
            "input": "In this paper, we propose a novel neural network model called RNN Encoder–Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder–Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
            "output": [
                "Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation"
            ]
        },
        {
            "id": "task1540-862e88a5b496413aa3ab5dc42a8ae7a5",
            "input": "Based on NFL game data we try to predict the outcome of a play in multiple different ways including Decision and Classification Trees, Nearest Neighbors, Naive Bayes, Linear Discriminant Analysis, Support Vector Machines and Regression, and Artificial Neural Networks. An application of this is the following: by plugging in various play options one could determine the best play for a given situation in real time. While the outcome of a play can be described in many ways we had the most promising results with a newly defined measure that we call progress. We see this work as a first step to include predictive analysis into NFL playcalling.",
            "output": [
                "NFL Play Prediction"
            ]
        },
        {
            "id": "task1540-ada8703572234204b4103a84325b45f6",
            "input": "Deep neural networks are capable of modelling highly nonlinear functions by capturing different levels of abstraction of data hierarchically. While training deep networks, first the system is initialized near a good optimum by greedy layer-wise unsupervised pre-training. However, with burgeoning data and increasing dimensions of the architecture, the time complexity of this approach becomes enormous. Also, greedy pre-training of the layers often turns detrimental by over-training a layer causing it to lose harmony with the rest of the network. In this paper a synchronized parallel algorithm for pre-training deep networks on multi-core machines has been proposed. Different layers are trained by parallel threads running on different cores with regular synchronization. Thus the pre-training process becomes faster and chances of overtraining are reduced. This is experimentally validated using a stacked autoencoder for dimensionality reduction of MNIST handwritten digit database. The proposed algorithm achieved 26% speed-up compared to greedy layer-wise pre-training for achieving the same reconstruction accuracy substantiating its potential as an alternative.",
            "output": [
                "Faster learning of deep stacked autoencoders on multi-core systems using synchronized layer-wise pre-training"
            ]
        },
        {
            "id": "task1540-fba279a0122442c095feb254eec8d004",
            "input": "In this paper we discuss a novel framework for multiclass learning, defined by a suitable coding/decoding strategy, namely the simplex coding, that allows to generalize to multiple classes a relaxation approach commonly used in binary classification. In this framework, a relaxation error analysis can be developed avoiding constraints on the considered hypotheses class. Moreover, we show that in this setting it is possible to derive the first provably consistent regularized method with training/tuning complexity which is independent to the number of classes. Tools from convex analysis are introduced that can be used beyond the scope of this paper.",
            "output": [
                "Multiclass Learning with Simplex Coding"
            ]
        },
        {
            "id": "task1540-9095b39e92ab47629f9911f26990715c",
            "input": "A pseudo independent (PI) model is a proba­ bilistic domain model (PDM) where proper subsets of a set of collectively dependent variables display marginal independence. PI models cannot be learned correctly by many algorithms that rely on a single link search. Earlier work on learning PI models has sug­ gested a straightforward multi-link search al­ gorithm. However, when a domain contains recursively embedded PI submodels, it may escape the detection of such an algorithm. In this paper, we propose an improved al­ gorithm that ensures the learning of all em­ bedded PI submodels whose sizes are upper bounded by a predetermined parameter. We show that this improved learning capability only increases the complexity slightly beyond that of the previous algorithm. The perfor­ mance of the new algorithm is demonstrated through experiment.",
            "output": [
                "Learning Belief Networks in Domains with Recursively Embedded Pseudo Independent Submodels"
            ]
        },
        {
            "id": "task1540-1b91d52d17d248739b086e8f07d39a6c",
            "input": "In this paper we present a new way of predicting the performance of a reinforcement learning policy given historical data that may have been generated by a different policy. The ability to evaluate a policy from historical data is important for applications where the deployment of a bad policy can be dangerous or costly. We show empirically that our algorithm produces estimates that often have orders of magnitude lower mean squared error than existing methods—it makes more efficient use of the available data. Our new estimator is based on two advances: an extension of the doubly robust estimator (Jiang & Li, 2015), and a new way to mix between model based estimates and importance sampling based estimates.",
            "output": [
                "Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-0f929186dbf541b896176c945445f2a8",
            "input": "Monte Carlo sampling has become a major vehicle for approximate inference in Bayesian networks. In this paper, we investigate a fam­ ily of related simulation approaches, known collectively as quasi-Monte Carlo methods based on deterministic low-discrepancy se­ quences. We first outline several theoreti­ cal aspects of deterministic low-discrepancy sequences, show three examples of such se­ quences, and then discuss practical issues re­ lated to applying them to belief updating in Bayesian networks. We propose an algorithm for selecting direction numbers for Sobol se­ quence. Our experimental results show that low-discrepancy sequences (especially Sobol sequence) significantly improve the perfor­ mance of simulation algorithms in Bayesian networks compared to Monte Carlo sampling.",
            "output": [
                "Computational Investigation of Low-Discrepancy Sequences in Simulation Algorithms for Bayesian Networks"
            ]
        },
        {
            "id": "task1540-6e51ec8aaaa54b12bfe82e8337ec0298",
            "input": "Crowdsourcing platforms enable to propose simple human intelligence tasks to a large number of participants who realise these tasks. The workers often receive a small amount of money or the platforms include some other incentive mechanisms, for example they can increase the workers reputation score, if they complete the tasks correctly. We address the problem of identifying experts among participants, that is, workers, who tend to answer the questions correctly. Knowing who are the reliable workers could improve the quality of knowledge one can extract from responses. As opposed to other works in the literature, we assume that participants can give partial or incomplete responses, in case they are not sure that their answers are correct. We model such partial or incomplete responses with the help of belief functions, and we derive a measure that characterizes the expertise level of each participant. This measure is based on precise and exactitude degrees that represent two parts of the expertise level. The precision degree reflects the reliability level of the participants and the exactitude degree reflects the knowledge level of the participants. We also analyze our model through simulation and demonstrate that our richer model can lead to more reliable identification of experts.",
            "output": [
                "Characterization of experts in crowdsourcing platforms"
            ]
        },
        {
            "id": "task1540-34592f07058f4bc39f41962832bfdf0d",
            "input": "We study properties of particular non-redundant sets of if-then rules describing dependencies between graded attributes. We introduce notions of saturation and witnessed non-redundancy of sets of graded attribute implications are show that bases of graded attribute implications given by systems of pseudo-intents correspond to non-redundant sets of graded attribute implications with saturated consequents where the nonredundancy is witnessed by antecedents of the contained graded attribute implications. We introduce an algorithm which transforms any complete set of graded attribute implications parameterized by globalization into a base given by pseudo-intents. Experimental evaluation is provided to compare the method of obtaining bases for general parameterizations by hedges with earlier graph-based approaches.",
            "output": [
                "On sets of graded attribute implications with witnessed non-redundancy"
            ]
        },
        {
            "id": "task1540-413242eb66d04776bee75b6f70b4a0e1",
            "input": "Temporal information conveyed by language describes how the world around us changes through time. Events, durations and times are all temporal elements that can be viewed as intervals. These intervals are sometimes temporally related in text. Automatically determining the nature of such relations is a complex and unsolved problem. Some words can act as “signals” which suggest a temporal ordering between intervals. In this paper, we use these signal words to improve the accuracy of a recent approach to classification of temporal links.",
            "output": [
                "Using Signals to Improve Automatic Classification of Temporal Relations"
            ]
        },
        {
            "id": "task1540-bc3dc6d804d7404b82037876bf8d7603",
            "input": "We introduce a new framework for unsupervised learning of deep representations based on a novel hierarchical decomposition of information. Intuitively, data is passed through a series of progressively fine-grained sieves. Each layer of the sieve recovers a single latent factor that is maximally informative about multivariate dependence in the data. The data is transformed after each pass so that the remaining unexplained information trickles down to the next layer. Ultimately, we are left with a set of latent factors explaining all the dependence in the original data and remainder information consisting of independent noise. We present a practical implementation of this framework for discrete variables and apply it to a variety of tasks including independent component analysis, lossy and lossless compression, and predicting missing values in data. The hope of finding a succinct principle that elucidates the brain’s information processing abilities has often kindled interest in information-theoretic ideas [1, 2]. In machine learning, on the other hand, the past decade has witnessed a shift in focus towards expressive, hierarchical models with tractable update rules, with successes driven by increasingly effective ways to leverage labeled data to learn rich models [3, 4]. Information-theoretic ideas like the venerable InfoMax principle [5, 6] can be and are applied in both contexts but they do not shed much light on the questions of when and why deep representations are useful for learning. We introduce a novel incremental and hierarchical decomposition of information and show that it defines a framework for unsupervised learning of deep representations in which the contribution of each layer can be precisely quantified. Moreover, this scheme automatically determines the structure and depth among hidden units in the representation based only on local learning rules. The shift in perspective that enables our information decomposition is to focus on how well the learned representation explains multivariate mutual information in the data (a measure originally introduced as “total correlation” [7]). Intuitively, our approach constructs a hierarchical representation of data by passing it through a sequence of progressively fine-grained sieves. At the first layer of the sieve we learn a factor that explains as much of the dependence in the data as possible. The data is then transformed into the “remainder information”, which has this dependence extracted. The next layer of the sieve looks for the largest source of dependence in the remainder information, and the cycle repeats. At each step, we obtain a successively tighter upper and lower bound on the multivariate information in the data, with convergence between the bounds obtained when the remaining information consists of nothing but independent factors. Because we end up with independent factors, one can also view this decomposition as a new way to do independent component analysis (ICA) [8, 9]. Unlike traditional methods, we do not assume a specific generative model of the data (i.e., that it consists of a linear transformation of independent sources) and we extract independent factors incrementally rather than all at once. The implementation we develop here uses only discrete variables and is therefore most relevant for the challenging problem of ICA with discrete variables, which has applications to compression [10]. 1 ar X iv :1 50 7. 02 28 4v 1 [ st at .M L ] 8 J ul 2 01 5 After introducing some background in Sec. 1, we introduce a new way to iteratively decompose the information in data in Sec. 2, and show how to use these decompositions to define a practical and incremental framework for unsupervised representation learning in Sec. 3. We demonstrate the versatility of this framework by applying it first to independent component analysis (Sec. 4). Next, we use the sieve as a lossy compression to mimic the traditional strengths of generative models including in-painting and generating new samples (Sec. 5). Finally, we cast the sieve as a lossless compression and show that it beats standard compression schemes on a benchmark task (Sec. 6). 1 Information-theoretic learning background Using standard notation [11], capital Xi denotes a random variable taking values in some domain and whose instances are denoted in lowercase, xi. In this paper, the domain of all variables are considered to be discrete and finite. We abbreviate multivariate random variables, X ≡ X1:n ≡ X1, . . . , Xn, with an associated probability distribution, pX(X1 = x1, . . . , Xn = xn), which is typically abbreviated to p(x). We will index different groups of multivariate random variables with superscripts, X, as defined in Fig. 1. We let X denote the original observed variables and we often omit the superscript in this case for readability. Entropy is defined in the usual way as H(X) ≡ EX [log 1/p(x)]. We use base two logarithms so that the unit of information is bits. Higher-order entropies can be constructed in various ways from this standard definition. For instance, the mutual information between two groups of random variables, X and Y can be written as the reduction of uncertainty in one variable, given information about the other, I(X;Y ) = H(X)−H(X|Y ). The “InfoMax” principle [5, 6] suggests that for unsupervised learning we should construct Y ’s to maximize their mutual information with X , the data. Despite its intuitive appeal, this approach has several potential problems (see [12] for one example). Here we focus on the fact that the InfoMax principle is not very useful for characterizing “deep representations”, even though it is often invoked in this context [13]. This follows directly from the data processing inequality (a similar argument appears in [14]). Namely, if we start with X , construct a layer of hidden units Y 1 that are a function of X , and continue adding layers to a stacked representation so that X → Y 1 → Y 2 . . . Y , then the information that the Y ’s have about X cannot increase after the first layer, I(X;Y ) = I(X;Y ). From the point of view of mutual information, Y 1 is a copy and Y 2 is just a copy of a copy. While a coarse-grained copy might be useful, the InfoMax principle does not quantify how or why. Instead of maximizing I(X;Y ), the recently introduced principle of total Correlation Explanation (CorEx) [15, 16] suggests to construct Y ’s that explain the multivariate dependence in X according to a multivariate measure of mutual information first introduced as “total correlation” [7]. TC(X) ≡ DKL ( p(x)|| n ∏",
            "output": [
                "The Information Sieve"
            ]
        },
        {
            "id": "task1540-af4d5b68f9204e099cb7005315b999cb",
            "input": "Sequence-to-sequence neural network models for generation of conversational responses tend to generate safe, commonplace responses (e.g., I don’t know) regardless of the input. We suggest that the traditional objective function, i.e., the likelihood of output (responses) given input (messages) is unsuited to response generation tasks. Instead we propose using Maximum Mutual Information (MMI) as objective function in neural models. Experimental results demonstrate that the proposed objective function produces more diverse, interesting, and appropriate responses, yielding substantive gains in BLEU scores on two conversational datasets.",
            "output": [
                "A Diversity-Promoting Objective Function for Neural Conversation Models"
            ]
        },
        {
            "id": "task1540-d23d6d584776468392920576c0942dca",
            "input": "With the increasing empirical success of distributional models of compositional semantics, it is timely to consider the types of textual logic that such models are capable of capturing. In this paper, we address shortcomings in the ability of current models to capture logical operations such as negation. As a solution we propose a tripartite formulation for a continuous vector space representation of semantics and subsequently use this representation to develop a formal compositional notion of negation within such models.",
            "output": [
                "“Not not bad” is not “bad”: A distributional account of negation"
            ]
        },
        {
            "id": "task1540-6350b7fc88394bb29317611e0c846bea",
            "input": "We consider regret minimization in repeated games with non-convex loss functions. Minimizing the standard notion of regret is computationally intractable. Thus, we define a natural notion of regret which permits efficient optimization and generalizes offline guarantees for convergence to an approximate local optimum. We give gradient-based methods that achieve optimal regret, which in turn guarantee convergence to equilibrium in this framework.",
            "output": [
                "Efficient Regret Minimization in Non-Convex Games"
            ]
        },
        {
            "id": "task1540-c0bc391131254f0398dee4ca6ede38b4",
            "input": "In this paper we initiate the study of whether or not sparse estimation tasks can be performed efficiently in high dimensions, in the robust setting where an ε-fraction of samples are corrupted adversarially. We study the natural robust version of two classical sparse estimation problems, namely, sparse mean estimation and sparse PCA in the spiked covariance model. For both of these problems, we provide the first efficient algorithms that provide non-trivial error guarantees in the presence of noise, using only a number of samples which is similar to the number required for these problems without noise. In particular, our sample complexities are sublinear in the ambient dimension d. Our work also suggests evidence for new computational-vs-statistical gaps for these problems (similar to those for sparse PCA without noise) which only arise in the presence of noise.",
            "output": [
                "Robust Sparse Estimation Tasks in High Dimensions"
            ]
        },
        {
            "id": "task1540-0cec2a6261b24d168553d70269abdd3b",
            "input": "Clinicians are expected to have up-to-date and broad knowledge of disease treatment options for a patient. Online<lb>health knowledge resources contain a wealth of information. However, because of the time investment needed to<lb>disseminate and rank pertinent information, there is a need to summarize the information in a more concise format.<lb>Our aim of the study is to provide clinicians with a concise overview of popular treatments for a given disease using<lb>information automatically computed from Medline abstracts. We analyzed the treatments of two disorders – Atrial<lb>Fibrillation and Congestive Heart Failure. We calculated the precision, recall, and f-scores of our two ranking<lb>methods to measure the accuracy of the results. For Atrial Fibrillation disorder, maximum f-score for the New<lb>Treatments weighing method is 0.611, which occurs at 60 treatments. For Congestive Heart Failure disorder,<lb>maximum f-score for the New Treatments weighing method is 0.503, which occurs at 80 treatments.",
            "output": [
                "Automatically extracting, ranking and visually summarizing the treatments for a disease"
            ]
        },
        {
            "id": "task1540-b7537d13822940f5bbaf52edcd5092f8",
            "input": "For large, real-world inductive learning problems, the number of training examples often must be limited due to the costs associated with procuring, preparing, and storing the training examples and/or the computational costs associated with learning from them. In such circumstances, one question of practical importance is: if only n training examples can be selected, in what proportion should the classes be represented? In this article we help to answer this question by analyzing, for a fixed training-set size, the relationship between the class distribution of the training data and the performance of classification trees induced from these data. We study twenty-six data sets and, for each, determine the best class distribution for learning. The naturally occurring class distribution is shown to generally perform well when classifier performance is evaluated using undifferentiated error rate (0/1 loss). However, when the area under the ROC curve is used to evaluate classifier performance, a balanced distribution is shown to perform well. Since neither of these choices for class distribution always generates the best-performing classifier, we introduce a “budget-sensitive” progressive sampling algorithm for selecting training examples based on the class associated with each example. An empirical analysis of this algorithm shows that the class distribution of the resulting training set yields classifiers with good (nearly-optimal) classification performance.",
            "output": [
                "Learning When Training Data are Costly: The Effect of Class Distribution on Tree Induction"
            ]
        },
        {
            "id": "task1540-1f7aada6e8064f178b22e8d12a51ee14",
            "input": "We present a novel spectral learning algorithm for simultaneous localization and mapping (SLAM) from range data with known correspondences. This algorithm is an instance of a general spectral system identification framework, from which it inherits several desirable properties, including statistical consistency and no local optima. Compared with popular batch optimization or multiple-hypothesis tracking (MHT) methods for range-only SLAM, our spectral approach offers guaranteed low computational requirements and good tracking performance. Compared with popular extended Kalman filter (EKF) or extended information filter (EIF) approaches, and many MHT ones, our approach does not need to linearize a transition or measurement model; such linearizations can cause severe errors in EKFs and EIFs, and to a lesser extent MHT, particularly for the highly non-Gaussian posteriors encountered in range-only SLAM. We provide a theoretical analysis of our method, including finite-sample error bounds. Finally, we demonstrate on a real-world robotic SLAM problem that our algorithm is not only theoretically justified, but works well in practice: in a comparison of multiple methods, the lowest errors come from a combination of our algorithm with batch optimization, but our method alone produces nearly as good a result at far lower computational cost.",
            "output": [
                "A Spectral Learning Approach to Range-Only SLAM"
            ]
        },
        {
            "id": "task1540-a9b6bfdb13d348f5898d84080dcad66c",
            "input": "Code super-optimization is the task of transforming any given program to a more efficient version while preserving its input-output behaviour. In some sense, it is similar to the paraphrase problem from natural language processing where the intention is to change the syntax of an utterance without changing its semantics. Code-optimization has been the subject of years of research that has resulted in the development of rule-based transformation strategies that are used by compilers. More recently, however, a class of stochastic search based methods have been shown to outperform these strategies. This approach involves repeated sampling of modifications to the program from a proposal distribution, which are accepted or rejected based on whether they preserve correctness and the improvement they achieve. These methods, however, neither learn from past behaviour nor do they try to leverage the semantics of the program under consideration. Motivated by this observation, we present a novel learning based approach for code super-optimization. Intuitively, our method works by learning the proposal distribution using unbiased estimators of the gradient of the expected improvement. Experiments on benchmarks comprising of automatically generated as well as existing (“Hacker’s Delight”) programs show that the proposed method is able to significantly outperform state of the art approaches for code super-optimization.",
            "output": [
                "Learning to superoptimize programs"
            ]
        },
        {
            "id": "task1540-f071b05586d340f085587fe89b7e1246",
            "input": "We define the concept of an internal symmetry. This is a symmety within a solution of a constraint satisfaction problem. We compare this to solution symmetry, which is a mapping between different solutions of the same problem. We argue that we may be able to exploit both types of symmetry when finding solutions. We illustrate the potential of exploiting internal symmetries on two benchmark domains: Van der Waerden numbers and graceful graphs. By identifying internal symmetries we are able to extend the state of the art in both cases.",
            "output": [
                "Symmetry within Solutions"
            ]
        },
        {
            "id": "task1540-b5eda0ffc4ac4406841896f0f30df967",
            "input": "We describe Swapout, a new stochastic training method, that outperforms ResNets of identical network structure yielding impressive results on CIFAR-10 and CIFAR100. Swapout samples from a rich set of architectures including dropout [17], stochastic depth [6] and residual architectures [4, 5] as special cases. When viewed as a regularization method swapout not only inhibits co-adaptation of units in a layer, similar to dropout, but also across network layers. We conjecture that swapout achieves strong regularization by implicitly tying the parameters across layers. When viewed as an ensemble training method, it samples a much richer set of architectures than existing methods such as dropout or stochastic depth. We propose a parameterization that reveals connections to exiting architectures and suggests a much richer set of architectures to be explored. We show that our formulation suggests an efficient training method and validate our conclusions on CIFAR-10 and CIFAR-100 matching state of the art accuracy. Remarkably, our 32 layer wider model performs similar to a 1001 layer ResNet model.",
            "output": [
                "Swapout: Learning an ensemble of deep architectures"
            ]
        },
        {
            "id": "task1540-a3f6af099dc3464eb696ad40fe1b4472",
            "input": "Two types of low cost-per-iteration gradient descent methods have been extensively studied in parallel. One is online or stochastic gradient descent ( OGD/SGD), and the other is randomzied coordinate descent (RBCD). In this paper, for the first time, we combine the two types of methods together and propose online randomized block coordinate descent (ORBCD). At each iteration, ORBCD only computes the partial gradient of one block coordinate of one mini-batch samples. ORBCD is well suited for the composite minimization problem where one function is the average of the losses of a large number of samples and the other is a simple regularizer defined on high dimensional variables. We show that the iteration complexity of ORBCD has the same order as OGD or SGD. For strongly convex functions, by reducing the variance of stochastic gradients, we show that ORBCD can converge at a geometric rate in expectation, matching the convergence rate of SGD with variance reduction and RBCD.",
            "output": [
                "Randomized Block Coordinate Descent for Online and Stochastic Optimization"
            ]
        },
        {
            "id": "task1540-7907aeba57584168b131636fcf82e037",
            "input": "Deep learning models are often successfully trained using gradient descent, despite the worst<lb>case hardness of the underlying non-convex optimization problem. The key question is then under<lb>what conditions can one prove that optimization will succeed. Here we provide a strong result<lb>of this kind. We consider a neural net with one hidden layer and a convolutional structure with<lb>no overlap and a ReLU activation function. For this architecture we show that learning is NP-<lb>complete in the general case, but that when the input distribution is Gaussian, gradient descent<lb>converges to the global optimum in polynomial time. To the best of our knowledge, this is the<lb>first global optimality guarantee of gradient descent on a convolutional neural network with ReLU<lb>activations.",
            "output": [
                "Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs"
            ]
        },
        {
            "id": "task1540-4c10838b116345b69decd1ce52f20e14",
            "input": "Planning for distributed agents with partial state information is considered from a decision­ theoretic perspective. We describe generaliza­ tions of both the MDP and POMDP models that allow for decentralized control. For even a small number of agents, the finite-horizon prob­ lems corresponding to both of our models are complete for nondeterministic exponential time. These complexity results illustrate a fundamen­ tal difference between centralized and decentral­ ized control of Markov processes. In contrast to the MDP and POMDP problems, the problems we consider provably do not admit polynomial­ time algorithms and most likely require doubly exponential time to solve in the worst case. We have thus provided mathematical evidence corre­ sponding to the intuition that decentralized plan­ ning problems cannot easily be reduced to cen­ tralized problems and solved exactly using estab­ lished techniques.",
            "output": [
                "The Complexity of Decentralized Control of Markov Decision Processes"
            ]
        },
        {
            "id": "task1540-3d6e84b2bf1e48dc80869dfc4ba9100b",
            "input": "We develop T-SKIRT: a temporal, structuredknowledge, IRT-based method for predicting student responses online. By explicitly accounting for student learning and employing a structured, multidimensional representation of student proficiencies, the model outperforms standard IRTbased methods on an online response prediction task when applied to real responses collected from students interacting with diverse pools of educational content.",
            "output": [
                "T-SKIRT: Online Estimation of Student Proficiency in an Adaptive Learning System"
            ]
        },
        {
            "id": "task1540-23353a0a7c4d43f5a18fbb91ee25f5cc",
            "input": "A widely-used tool for binary classification is the Support Vector Machine (SVM), a supervised learning technique that finds the “maximum margin” linear separator between the two classes. While SVMs have been well studied in the batch (offline) setting, there is considerably less work on the streaming (online) setting, which requires only a single pass over the data using sub-linear space. Existing streaming algorithms are not yet competitive with the batch implementation. In this paper, we use the formulation of the SVM as a minimum enclosing ball (MEB) problem to provide a streaming SVM algorithm based off of the blurred ball cover originally proposed by Agarwal and Sharathkumar. Our implementation consistently outperforms existing streaming SVM approaches and provides higher accuracies than libSVM on several datasets, thus making it competitive with the standard SVM batch implementation.",
            "output": [
                "Accurate Streaming Support Vector Machines"
            ]
        },
        {
            "id": "task1540-a251c991aee64f818e3e67dec8329fa6",
            "input": "We propose a new framework for single-channel source separation that lies between the fully supervised and unsupervised setting. Instead of supervision, we provide input features for each source signal and use convex methods to estimate the correlations between these features and the unobserved signal decomposition. We analyze the case of `2 loss theoretically and show that recovery of the signal components depends only on cross-correlation between features for different signals, not on correlations between features for the same signal. Contextually supervised source separation is a natural fit for domains with large amounts of data but no explicit supervision; our motivating application is energy disaggregation of hourly smart meter data (the separation of whole-home power signals into different energy uses). Here we apply contextual supervision to disaggregate the energy usage of thousands homes over four years, a significantly larger scale than previously published efforts, and demonstrate on synthetic data that our method outperforms the unsupervised approach.",
            "output": [
                "Contextually Supervised Source Separation with Application to Energy Disaggregation"
            ]
        },
        {
            "id": "task1540-be30e0f880de4e5ca41dd6423c8bc6c9",
            "input": "Discriminative translation models utilizing source context have been shown to help statistical machine translation performance. We propose a novel extension of this work using target context information. Surprisingly, we show that this model can be efficiently integrated directly in the decoding process. Our approach scales to large training data sizes and results in consistent improvements in translation quality on four language pairs. We also provide an analysis comparing the strengths of the baseline source-context model with our extended source-context and targetcontext model and we show that our extension allows us to better capture morphological coherence. Our work is freely available as part of Moses.",
            "output": [
                "Target-Side Context for Discriminative Models in Statistical Machine Translation"
            ]
        },
        {
            "id": "task1540-10145db1ec014a7fa741a5d8209ff65c",
            "input": "We propose a probabilistic framework for domain adaptation that blends both generative and discriminative modeling in a principled way. By maximizing both the marginal and the conditional log-likelihoods, models derived from this framework can use both labeled instances from the source domain as well as unlabeled instances from both source and target domains. Under this framework, we show that the popular reconstruction loss of autoencoder corresponds to an upper bound of the negative marginal log-likelihoods of unlabeled instances, where marginal distributions are given by proper kernel density estimations. This provides a way to interpret the empirical success of autoencoders in domain adaptation and semi-supervised learning. We instantiate our framework using neural networks, and build a concrete model, DAuto. Empirically, we demonstrate the effectiveness of DAuto on text, image and speech datasets, showing that it outperforms related competitors when domain adaptation is possible.",
            "output": [
                "Principled Hybrids of Generative and Discriminative Domain Adaptation"
            ]
        },
        {
            "id": "task1540-ad21ecd1d1a34ead915e06a3ccdd9ca9",
            "input": "The task of computing approximate Nash equilibria in large zero-sum extensive-form games has received a tremendous amount of attention due mainly to the Annual Computer Poker Competition. Immediately after its inception, two competing and seemingly different approaches emerged—one an application of noregret online learning, the other a sophisticated gradient method applied to a convex-concave saddle-point formulation. Since then, both approaches have grown in relative isolation with advancements on one side not effecting the other. In this paper, we rectify this by dissecting and, in a sense, unify the two views.",
            "output": [
                "A Unified View of Large-scale Zero-sum Equilibrium Computation"
            ]
        },
        {
            "id": "task1540-862bd01c09a24970973ea854ddad0f72",
            "input": "We present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space. We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaningbased linguistic knowledge from the input signal. We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of formrelated aspects of the language input tends to initially increase and then plateau or decrease.",
            "output": [
                "Representations of language in a model of visually grounded speech signal"
            ]
        },
        {
            "id": "task1540-bf34f96f7eee499eaf35dbf9c87752f0",
            "input": "We describe efforts towards getting better resources for EnglishArabic machine translation of spoken text. In particular, we look at movie subtitles as a unique, rich resource, as subtitles in one language often get translated into other languages. Movie subtitles are not new as a resource and have been explored in previous research; however, here we create a much larger bi-text (the biggest to date), and we further generate better quality alignment for it. Given the subtitles for the same movie in different languages, a key problem is how to align them at the fragment level. Typically, this is done using length-based alignment, but for movie subtitles, there is also time information. Here we exploit this information to develop an original algorithm that outperforms the current best subtitle alignment tool, subalign. The evaluation results show that adding our bi-text to the IWSLT training bi-text yields an improvement of over two BLEU points absolute.",
            "output": [
                "Bi-Text Alignment of Movie Subtitles for Spoken English-Arabic Statistical Machine Translation"
            ]
        },
        {
            "id": "task1540-8c649678a24f479b8a34f2e3c939d722",
            "input": "This article describes the systems jointly submitted by Institute for Infocomm (IR), the Laboratoire d’Informatique de l’Universit du Maine (LIUM), Nanyang Technology University (NTU) and the University of Eastern Finland (UEF) for 2015 NIST Language Recognition Evaluation (LRE). The submitted system is a fusion of nine sub-systems based on i-vectors [1] extracted from different types of features. Given the i-vectors, several classifiers are adopted for the language detection task including support vector machines (SVM) [2], multi-class logistic regression (MCLR), Probabilistic Linear Discriminant Analysis (PLDA) [3] and Deep Neural Networks (DNN).",
            "output": [
                "Fantastic 4 system for NIST 2015 Language Recognition Evaluation"
            ]
        },
        {
            "id": "task1540-8928a74b6c7f41c7889fb0f2d6b69e71",
            "input": "Sparse methods for supervised learning aim at finding good linear predictors from as few variables as possible, i.e., with small cardinality of their supports. This combinatorial selection problem is often turned into a convex optimization problem by replacing the cardinality function by its convex envelope (tightest convex lower bound), in this case the l1-norm. In this paper, we investigate more general set-functions than the cardinality, that may incorporate prior knowledge or structural constraints which are common in many applications: namely, we show that for nondecreasing submodular set-functions, the corresponding convex envelope can be obtained from its Lovász extension, a common tool in submodular analysis. This defines a family of polyhedral norms, for which we provide generic algorithmic tools (subgradients and proximal operators) and theoretical results (conditions for support recovery or high-dimensional inference). By selecting specific submodular functions, we can give a new interpretation to known norms, such as those based on rank-statistics or grouped norms with potentially overlapping groups; we also define new norms, in particular ones that can be used as non-factorial priors for supervised learning.",
            "output": [
                "Structured sparsity-inducing norms through submodular functions"
            ]
        },
        {
            "id": "task1540-25b6d6dffbbc4a758ad3e672b7904f97",
            "input": "This paper presents a new algorithm for online linear regression whose efficiency guarantees satisfy the requirements of the KWIK (Knows What It Knows) framework. The algorithm improves on the complexity bounds of the current state-of-the-art procedure in this setting. We explore several applications of this algorithm for learning compact reinforcement-learning representations. We show that KWIK linear regression can be used to learn the reward function of a factored MDP and the probabilities of action outcomes in Stochastic STRIPS and Object Oriented MDPs, none of which have been proven to be efficiently learnable in the RL setting before. We also combine KWIK linear regression with other KWIK learners to learn larger portions of these models, including experiments on learning factored MDP transition and reward functions together.",
            "output": [
                "Exploring compact reinforcement-learning representations with linear regression"
            ]
        },
        {
            "id": "task1540-4e3e934f6678401f8c5605158e3db2b8",
            "input": "This paper proposes and experimentally validates a Bayesian network model of a range finder adapted to dynamic environments. All modeling assumptions are rigorously explained, and all model parameters have a physical interpretation. This approach results in a transparent and intuitive model. With respect to the state of the art beam model this paper: (i) proposes a different functional form for the probability of range measurements caused by unmodeled objects, (ii) intuitively explains the discontinuity encountered in the state of the art beam model, and (iii) reduces the number of model parameters, while maintaining the same representational power for experimental data. The proposed beam model is called RBBM, short for Rigorously Bayesian Beam Model. A maximum likelihood and a variational Bayesian estimator (both based on expectation-maximization) are proposed to learn the model parameters. Furthermore, the RBBM is extended to a full scan model in two steps: first, to a full scan model for static environments and next, to a full scan model for general, dynamic environments. The full scan model accounts for the dependency between beams and adapts to the local sample density when using a particle filter. In contrast to Gaussian-based state of the art models, the proposed full scan model uses a sample-based approximation. This sample-based approximation enables handling dynamic environments and capturing multimodality, which occurs even in simple static environments.",
            "output": [
                "A Rigorously Bayesian Beam Model and an Adaptive Full Scan Model for Range Finders in Dynamic Environments"
            ]
        },
        {
            "id": "task1540-b10a5b29e758454985d6f6772a955624",
            "input": "The report presents the process of planning, designing and the development of a database of spoken children’s speech whose native language is Bulgarian. The proposed model is designed for children between the age of 4 and 6 without speech disorders, and reflects their specific capabilities. At this age most children cannot read, there is no sustained concentration, they are emotional, etc. The aim is to unite all the media information accompanying the recording and processing of spoken speech, thereby to facilitate the work of researchers in the field of speech recognition. This database will be used for the development of systems for children’s speech recognition, children's speech synthesis systems, games which allow voice control, etc. As a result of the proposed model a prototype system for speech recognition is presented.",
            "output": [
                "Design and development a children’s speech database"
            ]
        },
        {
            "id": "task1540-47bb7477919a47bdb157956f7091fdf9",
            "input": "Deep learning has been shown as a successful machine learning method for a variety of tasks, and its popularity results in numerous open-source deep learning software tools coming to public. Training a deep network is usually a very time-consuming process. To address the huge computational challenge in deep learning, many tools exploit hardware features such as multi-core CPUs and many-core GPUs to shorten the training time. However, different tools exhibit different features and running performance when training different types of deep networks on different hardware platforms, which makes it difficult for end users to select an appropriate pair of software and hardware. In this paper, we aim to make a comparative study of the state-of-the-art GPU-accelerated deep learning software tools, including Caffe, CNTK, TensorFlow, and Torch. We benchmark the running performance of these tools with three popular types of neural networks on two CPU platforms and three GPU platforms. Our contribution is twofold. First, for deep learning end users, our benchmarking results can serve as a guide to selecting appropriate software tool and hardware platform. Second, for deep learning software developers, our in-depth analysis points out possible future directions to further optimize the training performance.",
            "output": [
                "Benchmarking State-of-the-Art Deep Learning Software Tools"
            ]
        },
        {
            "id": "task1540-9948c75eef674b3cb89f52b8275700ff",
            "input": "Harnessing the statistical power of neural networks to perform language understanding and symbolic reasoning is difficult, when it requires executing efficient discrete operations against a large knowledge-base. In this work, we introduce a Neural Symbolic Machine, which contains (a) a neural “programmer”, i.e., a sequence-to-sequence model that maps language utterances to programs and utilizes a key-variable memory to handle compositionality (b) a symbolic “computer”, i.e., a Lisp interpreter that performs program execution, and helps find good programs by pruning the search space. We apply REINFORCE to directly optimize the task reward of this structured prediction problem. To train with weak supervision and improve the stability of REINFORCE we augment it with an iterative maximum-likelihood process. NSM outperforms state-of-the-art on the WEBQUESTIONSSP dataset when trained from question-answer pairs only, without requiring any feature engineering or domain-specific knowledge.",
            "output": [
                "Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision"
            ]
        },
        {
            "id": "task1540-21d296e8721a476ba90615abe5c6d295",
            "input": "Recently, there has been much interest in spectral approaches to learning manifolds— so-called kernel eigenmap methods. These methods have had some successes, but their applicability is limited because they are not robust to noise. To address this limitation, we look at two-manifold problems, in which we simultaneously reconstruct two related manifolds, each representing a different view of the same data. By solving these interconnected learning problems together and allowing information to flow between them, two-manifold algorithms are able to succeed where a non-integrated approach would fail: each view allows us to suppress noise in the other, reducing bias in the same way that an instrumental variable allows us to remove bias in a linear dimensionality reduction problem. We propose a class of algorithms for two-manifold problems, based on spectral decomposition of cross-covariance operators in Hilbert space. Finally, we discuss situations where two-manifold problems are useful, and demonstrate that solving a two-manifold problem can aid in learning a nonlinear dynamical system from limited data.",
            "output": [
                "Two-Manifold Problems"
            ]
        },
        {
            "id": "task1540-517cb47827054753846e90628b496441",
            "input": "Measuring the effectiveness of corporate environmental reports, it being highly qualitative and less regulated, is often considered as a daunting task. The task becomes more complex if comparisons are to be performed. This study is undertaken to overcome the physical verification problems by implementing data mining technique. It further explores on the effectiveness by performing exploratory analysis and structural equation model to bring out the significant linkages between the selected 10 variables. Samples of 539 reports across various countries are used from an international directory to perform the statistical analysis like – One way ANOVA (Analysis of Variance), MDA (Multivariate Discriminant Analysis) and SEM (Structural Equation Modeling). The results indicate the significant differences among the various types of industries in their environmental reporting, and the exploratory factors like stakeholder, organization strategy and industrial oriented factors, proved significant. The major accomplishment is that the findings correlate with the conceptual frame work of GRI.",
            "output": [
                "Analysis of Corporate Environmental Reports using Statistical Techniques and Data Mining"
            ]
        },
        {
            "id": "task1540-84c4f29b917549e1973c81a8bdc585db",
            "input": "We describe how to use propositional model counting for a quantitative analysis of product configuration data. Our approach computes valuable meta information such as the total number of valid configurations or the relative frequency of components. This information can be used to assess the severity of documentation errors or to measure documentation quality. As an application example we show how we apply these methods to product documentation formulas of the Mercedes-Benz line of vehicles. In order to process these large formulas we developed and implemented a new model counter for non-CNF formulas. Our model counter can process formulas, whose CNF representations could not be processed up till now.",
            "output": [
                "Model Counting in Product Configuration"
            ]
        },
        {
            "id": "task1540-d94c6bed5a104201b9268d9d5e6ea614",
            "input": "Faced with continuously increasing scale of data, original back-propagation neural network based machine learning algorithm presents two non-trivial challenges: huge amount of data makes it difficult to maintain both efficiency and accuracy; redundant data aggravates the system workload. This project is mainly focused on the solution to the issues above, combining deep learning algorithm with cloud computing platform to deal with large-scale data. A MapReduce-based handwriting character recognizer will be designed in this project to verify the efficiency improvement this mechanism will achieve on training and practical large-scale data. Careful discussion and experiment will be developed to illustrate how deep learning algorithm works to train handwritten digits data, how MapReduce is implemented on deep learning neural network, and why this combination accelerates computation. Besides performance, the scalability and robustness will be mentioned in this report as well. Our system comes with two demonstration software that visually illustrates our handwritten digit recognition/encoding application. 1",
            "output": [
                "Large-scale Artificial Neural Network: MapReduce-based Deep Learning"
            ]
        },
        {
            "id": "task1540-14ade5c522c6413085c686581a3eff98",
            "input": "Embedding and visualizing large-scale high-dimensional data in a two-dimensional space is an important problem since such visualization can reveal deep insights out of complex data. Most of the existing embedding approaches, however, run on an excessively high precision, ignoring the fact that at the end, embedding outputs are converted into coarsegrained discrete pixel coordinates in a screen space. Motivated by such an observation and directly considering pixel coordinates in an embedding optimization process, we accelerate Barnes-Hut tree-based t-distributed stochastic neighbor embedding (BH-SNE), known as a state-of-the-art 2D embedding method, and propose a novel method called PixelSNE, a highly-efficient, screen resolution-driven 2D embedding method with a linear computational complexity in terms of the number of data items. Our experimental results show the significantly fast running time of PixelSNE by a large margin against BH-SNE, while maintaining the minimal degradation in the embedding quality. Finally, the source code of our method is publicly available at https: //github.com/awesome-davian/sasne.",
            "output": [
                "PixelSNE: Visualizing Fast with Just Enough Precision via Pixel-Aligned Stochastic Neighbor Embedding"
            ]
        },
        {
            "id": "task1540-cfdc3756317048749198fd62c2f6e95c",
            "input": "In this work we use the recent advances in representation learning to propose a neural architecture for the problem of natural language inference. Our approach is aligned to mimic how a human does the natural language inference process given two statements. The model uses variants of Long Short Term Memory (LSTM), attention mechanism and composable neural networks, to carry out the task. Each part of our model can be mapped to a clear functionality humans do for carrying out the overall task of natural language inference. The model is end-to-end differentiable enabling training by stochastic gradient descent. On Stanford Natural Language Inference(SNLI) dataset, the proposed model achieves better accuracy numbers than all published models in literature.",
            "output": [
                "A Neural Architecture Mimicking Humans End-to-End for Natural Language Inference"
            ]
        },
        {
            "id": "task1540-27337b91ce914945b49549a27c7b75fd",
            "input": "We consider log-supermodular models on binary variables, which are probabilistic models with negative log-densities which are submodular. These models provide probabilistic interpretations of common combinatorial optimization tasks such as image segmentation. In this paper, we focus primarily on parameter estimation in the models from known upper-bounds on the intractable log-partition function. We show that the bound based on separable optimization on the base polytope of the submodular function is always inferior to a bound based on “perturb-and-MAP” ideas. Then, to learn parameters, given that our approximation of the log-partition function is an expectation (over our own randomization), we use a stochastic subgradient technique to maximize a lower-bound on the log-likelihood. This can also be extended to conditional maximum likelihood. We illustrate our new results in a set of experiments in binary image denoising, where we highlight the flexibility of a probabilistic model to learn with missing data.",
            "output": [
                "Parameter Learning for Log-supermodular Distributions"
            ]
        },
        {
            "id": "task1540-55fe65513e834a23a2217ac30885da8f",
            "input": "One major deficiency of most semantic representation techniques is that they usually model a word type as a single point in the semantic space, hence conflating all the meanings that the word can have. Addressing this issue by learning distinct representations for individual meanings of words has been the subject of several research studies in the past few years. However, the generated sense representations are either not linked to any sense inventory or are unreliable for infrequent word senses. We propose a technique that tackles these problems by de-conflating the representations of words based on the deep knowledge it derives from a semantic network. Our approach provides multiple advantages in comparison to the past work, including its high coverage and the ability to generate accurate representations even for infrequent word senses. We carry out evaluations on six datasets across two semantic similarity tasks and report state-of-the-art results on most of them.",
            "output": [
                "De-Conflated Semantic Representations"
            ]
        },
        {
            "id": "task1540-779749e2297648e1997a055a87d354b1",
            "input": "Bridging the ‘reality gap’ that separates simulated robotics from experiments on hardware could accelerate robotic research through improved data availability. This paper explores domain randomization, a simple technique for training models on simulated images that transfer to real images by randomizing rendering in the simulator. With enough variability in the simulator, the real world may appear to the model as just another variation. We focus on the task of object localization, which is a stepping stone to general robotic manipulation skills. We find that it is possible to train a real-world object detector that is accurate to 1.5 cm and robust to distractors and partial occlusions using only data from a simulator with non-realistic random textures. To demonstrate the capabilities of our detectors, we show they can be used to perform grasping in a cluttered environment. To our knowledge, this is the first successful transfer of a deep neural network trained only on simulated RGB images (without pre-training on real images) to the real world for the purpose of robotic control.",
            "output": [
                "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World"
            ]
        },
        {
            "id": "task1540-5de714d833344391a074b50ff5bb7b9f",
            "input": "Structural correspondence learning (SCL) is an effective method for cross-lingual sentiment classification. This approach uses unlabeled documents along with a word translation oracle to automatically induce task specific, cross-lingual correspondences. It transfers knowledge through identifying important features, i.e., pivot features. For simplicity, however, it assumes that the word translation oracle maps each pivot feature in source language to exactly only one word in target language. This one-to-one mapping between words in different languages is too strict. Also the context is not considered at all. In this paper, we propose a cross-lingual SCL based on distributed representation of words; it can learn meaningful one-to-many mappings for pivot words using large amounts of monolingual data and a small dictionary. We conduct experiments on NLP&CC 2013 cross-lingual sentiment analysis dataset, employing English as source language, and Chinese as target language. Our method does not rely on the parallel corpora and the experimental results show that our approach is more competitive than the state-of-the-art methods in cross-lingual sentiment classification.",
            "output": [
                "Structural Correspondence Learning for Cross-lingual Sentiment Classification with One-to-many Mappings"
            ]
        },
        {
            "id": "task1540-14015d1e6ae441a2aea01c8737208f12",
            "input": "To mitigate the uncertainty of variable renewable<lb>resources, two off-the-shelf machine learning tools are deployed<lb>to forecast the solar power output of a solar photovoltaic system.<lb>The support vector machines generate the forecasts and the<lb>random forest acts as an ensemble learning method to combine<lb>the forecasts. The common ensemble technique in wind and solar<lb>power forecasting is the blending of meteorological data from<lb>several sources. In this study though, the present and the past<lb>solar power forecasts from several models, as well as the<lb>associated meteorological data, are incorporated into the random<lb>forest to combine and improve the accuracy of the day-ahead<lb>solar power forecasts. The performance of the combined model is<lb>evaluated over the entire year and compared with other<lb>combining techniques. Keywords—Ensemble learning, post-processing, random forest,<lb>solar power, support vector regression.",
            "output": [
                "Random Forest Ensemble of Support Vector Regression Models for Solar Power Forecasting"
            ]
        },
        {
            "id": "task1540-4837ade0b9aa4915be70ac40056a8afb",
            "input": "In this paper, we introduce a new distributional method for modeling predicateargument thematic fit judgments. We use a syntax-based DSM to build a prototypical representation of verb-specific roles: for every verb, we extract the most salient second order contexts for each of its roles (i.e. the most salient dimensions of typical role fillers), and then we compute thematic fit as a weighted overlap between the top features of candidate fillers and role prototypes. Our experiments show that our method consistently outperforms a baseline re-implementing a state-of-theart system, and achieves better or comparable results to those reported in the literature for the other unsupervised systems. Moreover, it provides an explicit representation of the features characterizing verbspecific semantic roles.",
            "output": [
                "Measuring Thematic Fit with Distributional Feature Overlap"
            ]
        },
        {
            "id": "task1540-ef9e56dd2ac540c48075f10d3934b7a0",
            "input": "Background: Allowing patients to access their own electronic health record (EHR) notes through online patient portals has the potential to improve patient-centered care. However, EHR notes contain abundant medical jargon that can be difficult for patients to comprehend. One way to help patients is to reduce information overload and help them focus on medical terms that matter most to them. Targeted education can then be developed to improve patient EHR comprehension and the quality of care. Objective: The aim of this work was to develop FIT (Finding Important Terms for patients), an unsupervised natural language processing (NLP) system that ranks medical terms in EHR notes based on their importance to patients. Methods: We built FIT on a new unsupervised ensemble ranking model derived from the biased random walk algorithm to combine heterogeneous information resources for ranking candidate terms from each EHR note. Specifically, FIT integrates four single views (rankers) for term importance: patient use of medical concepts, document-level term salience, word-occurrence based term relatedness, and topic coherence. It also incorporates partial information of term importance as conveyed by terms’ unfamiliarity levels and semantic types. We evaluated FIT on 90 expert-annotated EHR notes and used the four single-view rankers as baselines. In addition, we implemented three benchmark unsupervised ensemble ranking methods as strong baselines. Results: FIT achieved 0.885 AUC-ROC for ranking candidate terms from EHR notes to identify important terms. When including term identification, the performance of FIT for identifying important terms from EHR notes was 0.813 AUC-ROC. Both performance scores significantly exceeded the corresponding scores from the four single rankers (P<.001). FIT also outperformed the three ensemble rankers for most metrics. Its performance is relatively insensitive to its parameter. Conclusions: FIT can automatically identify EHR terms important to patients. It may help develop future interventions to improve quality of care. By using unsupervised learning as well as a robust and flexible framework for information fusion, FIT can be readily applied to other domains and applications.",
            "output": [
                "Unsupervised Ensemble Ranking of Terms in Electronic Health Record Notes Based on Their Importance to Patients"
            ]
        },
        {
            "id": "task1540-87abb999c7d54a0186942348442a7c21",
            "input": "We study dueling bandits with weak utility-based regret when preferences over arms have a total order and carry observable feature vectors. The order is assumed to be determined by these feature vectors, an unknown preference vector, and a known utility function. This structure introduces dependence between preferences for pairs of arms, and allows learning about the preference over one pair of arms from the preference over another pair of arms. We propose an algorithm for this setting called Comparing The Best (CTB), which we show has constant expected cumulative weak utility-based regret. We provide a Bayesian interpretation for CTB, an implementation appropriate for a small number of arms, and an alternate implementation for many arms that can be used when the input parameters satisfy a decomposability condition. We demonstrate through numerical experiments that CTB with appropriate input parameters outperforms all benchmarks considered.",
            "output": [
                "Dueling Bandits with Dependent Arms"
            ]
        },
        {
            "id": "task1540-d2a934cb9ab94c239c56bea0a8656a38",
            "input": "Reason and inference require process as well as memory skills by humans. Neural networks are able to process tasks like image recognition (better than humans) but in memory aspects are still limited (by attention mechanism, size). Recurrent Neural Network (RNN) and it’s modified version LSTM are able to solve small memory contexts, but as context becomes larger than a threshold, it is difficult to use them. The Solution is to use large external memory. Still, it poses many challenges like, how to train neural networks for discrete memory representation, how to describe long term dependencies in sequential data etc. Most prominent neural architectures for such tasks are Memory networks: inference components combined with long term memory and Neural Turing Machines: neural networks using external memory resources. Also, additional techniques like attention mechanism, end to end gradient descent on discrete memory representation are needed to support these solutions. Preliminary results of above neural architectures on simple algorithms (sorting, copying) and Question Answering (based on story, dialogs) application are comparable with the state of the art. In this paper, I explain these architectures (in general), the additional techniques used and the results of their application.",
            "output": [
                "Seminar in Collaborative Intelligence: Reasoning using Neural Networks"
            ]
        },
        {
            "id": "task1540-dde25e0b368c421792da677747f4968c",
            "input": "Designing and implementing efficient, provably correct parallel neural network processing is challenging. Existing high-level parallel abstractions like MapReduce are insufficiently expressive while low-level tools like MPI and Pthreads leave ML experts repeatedly solving the same design challenges. However, the diversity and large-scale data size have posed a significant challenge to construct a flexible and high-performance implementation of deep learning neural networks. To improve the performance and maintain the scalability, we present CNNLab, a novel deep learning framework using GPU and FPGA-based accelerators. CNNLab provides a uniform programming model to users so that the hardware implementation and the scheduling are invisible to the programmers. At runtime, CNNLab leverages the trade-offs between GPU and FPGA before offloading the tasks to the accelerators. Experimental results on the state-of-the-art Nvidia K40 GPU and Altera DE5 FPGA board demonstrate that the CNNLab can provide a universal framework with efficient support for diverse applications without increasing the burden of the programmers. Moreover, we analyze the detailed quantitative performance, throughput, power, energy, and performance density for both approaches. Experimental results leverage the trade-offs between GPU and FPGA and provide useful practical experiences for the deep learning research community.",
            "output": [
                "CNNLab: a Novel Parallel Framework for Neural Networks using GPU and FPGA"
            ]
        },
        {
            "id": "task1540-1aec9763b7f44b1192c8a53b45adda4e",
            "input": "One weakness of machine-learned NLP models is that they typically perform poorly on out-of-domain data. In this work, we study the task of identifying products being bought and sold in online cybercrime forums, which exhibits particularly challenging cross-domain effects. We formulate a task that represents a hybrid of slot-filling information extraction and named entity recognition and annotate datasets consisting of data from four different forums. Each of these forums constitutes its own “fine-grained domain” in that the forums cover different market sectors with different properties, even though all forums are in the broad domain of cybercrime. We characterize these domain differences in the context of a learning-based system: supervised models see decreased accuracy when applied to new forums, and standard techniques for semisupervised learning and domain adaptation have limited effectiveness on this data, which suggests the need to improve these techniques. We release a dataset of 93,924 posts from across 4 forums, with annotations for 1,938 posts.",
            "output": [
                "Identifying Products in Online Cybercrime Marketplaces: A Dataset and Fine-grained Domain Adaptation Task"
            ]
        },
        {
            "id": "task1540-d6861fb741314fbd99faefbd2171b51d",
            "input": "Convolutional Neural Networks (CNNs) can be shifted across 2D images or 3D videos to segment them. They have a fixed input size and typically perceive only small local contexts of the pixels to be classified as foreground or background. In contrast, Multi-Dimensional Recurrent NNs (MD-RNNs) can perceive the entire spatio-temporal context of each pixel in a few sweeps through all pixels, especially when the RNN is a Long Short-Term Memory (LSTM). Despite these theoretical advantages, however, unlike CNNs, previous MD-LSTM variants were hard to parallelize on GPUs. Here we re-arrange the traditional cuboid order of computations in MD-LSTM in pyramidal fashion. The resulting PyraMiD-LSTM is easy to parallelize, especially for 3D data such as stacks of brain slice images. PyraMiD-LSTM achieved best known pixel-wise brain image segmentation results on MRBrainS13 (and competitive results on EM-ISBI12).",
            "output": [
                "Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation"
            ]
        },
        {
            "id": "task1540-41312b1488014d04b99031cb1516f18b",
            "input": "There has been a recent explosion in the capabilities of game-playing artificial intelligence. Many classes of RL tasks, from Atari games to motor control to board games, are now solvable by fairly generic algorithms, based on deep learning, that learn to play from experience with minimal knowledge of the specific domain of interest. In this work, we will investigate the performance of these methods on Super Smash Bros. Melee (SSBM), a popular console fighting game. The SSBM environment has complex dynamics and partial observability, making it challenging for human and machine alike. The multi-player aspect poses an additional challenge, as the vast majority of recent advances in RL have focused on single-agent environments. Nonetheless, we will show that it is possible to train agents that are competitive against and even surpass human professionals, a new result for the multi-player video game setting.",
            "output": [
                "Beating the World’s Best at Super Smash Bros. Melee with Deep Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-2c13b80e874841eca49c20cc4d7d8e67",
            "input": "Solving algebraic word problems requires executing a series of arithmetic operations—a program—to obtain a final answer. However, since programs can be arbitrarily complicated, inducing them directly from question-answer pairs is a formidable challenge. To make this task more feasible, we solve these problems by generating answer rationales, sequences of natural language and human-readable mathematical expressions that derive the final answer through a series of small steps. Although rationales do not explicitly specify programs, they provide a scaffolding for their structure via intermediate milestones. To evaluate our approach, we have created a new 100,000-sample dataset of questions, answers and rationales. Experimental results show that indirect supervision of program learning via answer rationales is a promising strategy for inducing arithmetic programs.",
            "output": [
                "Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems"
            ]
        },
        {
            "id": "task1540-37269f686c2b4477a63004f18e15ab1e",
            "input": "Currently there are lots of plagiarism detection approaches. But few of them implemented and adapted for Persian languages. In this paper, our work on designing and implementation of a plagiarism detection system based on preprocessing and NLP technics will be described. And the results of testing on a corpus will be presented. Keywords— External Plagiarism, Plagiarism, Copy detection, natural language processing, Artificial intelligence , Persian language.",
            "output": [
                "Design a Persian Automated Plagiarism Detector (AMZPPD)"
            ]
        },
        {
            "id": "task1540-95f1e94fa54b422c89b4aa2aac52a7a1",
            "input": "Learning features from massive unlabelled data is a vast prevalent topic for highlevel tasks in many machine learning applications. The recent great improvements on benchmark data sets achieved by increasingly complex unsupervised learning methods and deep learning models with lots of parameters usually requires many tedious tricks and much expertise to tune. However, filters learned by these complex architectures are quite similar to standard hand-crafted features visually. In this paper, unsupervised learning methods, such as PCA or auto-encoder, are employed as the building block to learn filter banks at each layer. The lower layer responses are transferred to the last layer (trans-layer) to form a more complete representation retaining more information. In addition, some beneficial methods such as local contrast normalization and whitening are added to the proposed deep trans-layer networks to further boost performance. The trans-layer representations are followed by block histograms with binary encoder schema to learn translation and rotation invariant representations, which are utilized to do high-level tasks such as recognition and classification. Compared to traditional deep learning methods, the implemented feature learning method has much less parameters and is validated in several typical experiments, such as digit recognition on MNIST and MNIST variations, object recognition on Caltech 101 dataset, face verification on LFW dataset. The deep trans-layer unsupervised learning achieves 99.45 % accuracy on MNIST dataset, 67.11 % accuracy on 15 samples per class and 75.98 % accuracy on 30 samples per class on Caltech 101 dataset, 87.10 % on LFW dataset.",
            "output": [
                "Deep Trans-layer Unsupervised Networks for Representation Learning"
            ]
        },
        {
            "id": "task1540-babbba7c97174c158911e919baf212ed",
            "input": "Causality has been recently introduced in databases, to model, characterize and possibly compute causes for query results (answers). Connections between queryanswer causality, consistency-based diagnosis, database repairs (wrt. integrity constraint violations), abductive diagnosis and the view-update problem have been established. In this work we further investigate connections between query-answer causality and abductive diagnosis and the view-update problem. In this context, we also define and investigate the notion of query-answer causality in the presence of integrity constraints.",
            "output": [
                "Causes for Query Answers from Databases, Datalog Abduction and View-Updates: The Presence of Integrity Constraints"
            ]
        },
        {
            "id": "task1540-faa7c0444b8e4cb6bb435610719eaac5",
            "input": "In this paper we study lifted inference for the Weighted First-Order Model Counting problem (WFOMC), which counts the assignments that satisfy a given sentence in firstorder logic (FOL); it has applications in Statistical Relational Learning (SRL) and Probabilistic Databases (PDB). We present several results. First, we describe a lifted inference algorithm that generalizes prior approaches in SRL and PDB. Second, we provide a novel dichotomy result for a non-trivial fragment of FO CNF sentences, showing that for each sentence the WFOMC problem is either in PTIME or #P-hard in the size of the input domain; we prove that, in the first case our algorithm solves the WFOMC problem in PTIME, and in the second case it fails. Third, we present several properties of the algorithm. Finally, we discuss limitations of lifted inference for symmetric probabilistic databases (where the weights of ground literals depend only on the relation name, and not on the constants of the domain), and prove the impossibility of a dichotomy result for the complexity of probabilistic inference for the entire language FOL.",
            "output": [
                "Understanding the Complexity of Lifted Inference and Asymmetric Weighted Model Counting"
            ]
        },
        {
            "id": "task1540-e36165cd993c4c6a87e981fc48931e7d",
            "input": "Jake Ryland Williams, ∗ James P. Bagrow, † Andrew J. Reagan, ‡ Sharon E. Alajajian, § Christopher M. Danforth, ¶ and Peter Sheridan Dodds ∗∗ School of Information, University of California, Berkeley 102 South Hall #4600 Berkeley, CA 94720-4600. Department of Mathematics & Statistics, Vermont Complex Systems Center, Computational Story Lab, & the Vermont Advanced Computing Core, The University of Vermont, Burlington, VT 05401. (Dated: September 29, 2017)",
            "output": [
                "Selection models of language production support informed text partitioning: an intuitive and practical, bag-of-phrases framework for text analysis"
            ]
        },
        {
            "id": "task1540-3cb3c3a98e284173b7da0861ca4dd164",
            "input": "Given an image, humans effortlessly run the image formation process backwards in their minds: they can tell albedo from shading, foreground from background, and imagine the occluded parts of the scene behind foreground objects. In this work, we propose a weakly supervised inversion machine trained to generate similar imaginations that when rendered using differentiable, graphics-like decoders, produce the original visual input. We constrain the imagination spaces by providing exemplar memory repositories in the form of foreground segmented objects, albedo, shading, background scenes and imposing adversarial losses on the imagination spaces. Our model learns to perform such inversion with weak supervision, without ever having seen paired annotated data, that is, without having seen the image paired with the corresponding ground-truth imaginations. We demonstrate our method by applying it to three Computer Vision tasks: image in-painting, intrinsic decomposition and object segmentation, each task having its own differentiable renderer. Data driven adversarial imagination priors effectively guide inversion, minimize the need for hand designed priors of smoothness or good continuation, or the need for paired annotated data. Consider Figure 1. We imagine a missing triangle occluding three small black circles rather than three carefully arranged pacman shapes – which is what the pixels depict. In (b), we do not perceive two parts of the sea separated by a standing person, rather a continuous sea landscape. In (c), we explain the input as a ”masked 8” rather than two semicircles. Consistent explanations of visual observations in terms of familiar concepts and memories we call “imaginations”. Imaginations invert the image formation process and propose 3D shape, camera pose, scene layering, spatial layout, albedo, shading, inpainted, un-occluded perceptions of the world, necessary for the understanding of the visual scene and interaction with it. Gestalt philosophers (Smith (1988)) proposed a set or principles to explain formation of such percepts, such as, closure, center surround pop-out, good continuity, smoothness etc, which many works attempt to hand design principles to incorporate those into computational frameworks of e.g., perceptual grouping (Yu (2003)). In this work, we present a learning-based inversion model that uses data-driven priors instead. We propose a computational model that addresses inverse problems in Computer Vision using adversarial imagination priors. Figure 2 illustrates our model. It is comprised of a generator neural network that given a visual input predicts visual imaginations, such as, in-painted image, un-occluded background scene, object segmentation, albedo and shading etc. Relevant memories, assumed to +",
            "output": [
                "ADVERSARIAL IMAGINATION PRIORS"
            ]
        },
        {
            "id": "task1540-b93e2ef23feb4d948c0a49c9169a33fc",
            "input": "Learning neural network architectures is a way to discover new highly predictive models. We propose to focus on this problem from a different perspective where the goal is to discover architectures efficient in terms of both prediction quality and computation cost, e.g time in milliseconds, number of operations... For instance, our approach is able to solve the following task: find the best neural network architecture (in a very large set of possible architectures) able to predict well in less than 100 milliseconds on my mobile phone. Our contribution is based on a new family of models called Budgeted Super Networks that are learned using reinforcement-learning inspired techniques applied to a budgeted learning objective function which includes the computation cost during disk/memory operations at inference. We present a set of experiments on computer vision problems and show the ability of our method to discover efficient architectures in terms of both predictive quality and computation time.",
            "output": [
                "Learning Time-Efficient Deep Architectures with Budgeted Super Networks"
            ]
        },
        {
            "id": "task1540-3acec2391779416282a4d5ba85b3dde6",
            "input": "The validation of any database mining methodology goes through an evaluation process where benchmarks availability is essential. In this paper, we aim to randomly generate relational database benchmarks that allow to check probabilistic dependencies among the attributes. We are particularly interested in Probabilistic Relational Models (PRMs), which extend Bayesian Networks (BNs) to a relational data mining context and enable effective and robust reasoning over relational data. Even though a panoply of works have focused, separately, on the generation of random Bayesian networks and relational databases, no work has been identified for PRMs on that track. This paper provides an algorithmic approach for generating random PRMs from scratch to fill this gap. The proposed method allows to generate PRMs as well as synthetic relational data from a randomly generated relational schema and a random set of probabilistic dependencies. This can be of interest not only for machine learning researchers to evaluate their proposals in a common framework, but also for databases designers to evaluate the effectiveness of the components of a database management system.",
            "output": [
                "Probabilistic Relational Model Benchmark Generation"
            ]
        },
        {
            "id": "task1540-01521f70500c4747950732cc8d67a0a2",
            "input": "While known algorithms for sensitivity analysis and parameter tuning in probabilistic networks have a running time that is exponential in the size of the network, the exact computational complexity of these problems has not been established as yet. In this paper we study several variants of the tuning problem and show that these problems are NP-complete in general. We further show that the problems remain NP-complete or PP-complete, for a number of restricted variants. These complexity results provide insight in whether or not recent achievements in sensitivity analysis and tuning can be extended to more general, practicable methods.",
            "output": [
                "The Computational Complexity of Sensitivity Analysis and Parameter Tuning"
            ]
        },
        {
            "id": "task1540-4bfeb9a1b25e4cbe9b6cfd7cc2683255",
            "input": "Learning acoustic models directly from the raw waveform data with minimal processing is challenging. Current waveform-based models have generally used very few (∼2) convolutional layers, which might be insufficient for building high-level discriminative features. In this work, we propose very deep convolutional neural networks (CNNs) that directly use time-domain waveforms as inputs. Our CNNs, with up to 34 weight layers, are efficient to optimize over very long sequences (e.g., vector of size 32000), necessary for processing acoustic waveforms. This is achieved through batch normalization, residual learning, and a careful design of down-sampling in the initial layers. Our networks are fully convolutional, without the use of fully connected layers and dropout, to maximize representation learning. We use a large receptive field in the first convolutional layer to mimic bandpass filters, but very small receptive fields subsequently to control the model capacity. We demonstrate the performance gains with the deeper models. Our evaluation shows that the CNN with 18 weight layers outperform the CNN with 3 weight layers by over 15% in absolute accuracy for an environmental sound recognition task and matches the performance of models using log-mel features.",
            "output": [
                "VERY DEEP CONVOLUTIONAL NEURAL NETWORKS FOR RAW WAVEFORMS"
            ]
        },
        {
            "id": "task1540-be449d8c7de6422d9465933be4fe54d4",
            "input": "Deep residual learning (ResNet) (He et al., 2016) is a new method for training very deep neural networks using identity mapping for shortcut connections. ResNet has won the ImageNet ILSVRC 2015 classification task, and achieved state-of-theart performances in many computer vision tasks. However, the effect of residual learning on noisy natural language processing tasks is still not well understood. In this paper, we design a novel convolutional neural network (CNN) with residual learning, and investigate its impacts on the task of distantly supervised noisy relation extraction. In contradictory to popular beliefs that ResNet only works well for very deep networks, we found that even with 9 layers of CNNs, using identity mapping could significantly improve the performance for distantly-supervised relation extraction.",
            "output": [
                "Deep Residual Learning for Weakly-Supervised Relation Extraction"
            ]
        },
        {
            "id": "task1540-84d4fe8a23d747c0ab1b1ba49f52cfaa",
            "input": "The application of Deep Neural Networks for ranking in search engines may obviate the need for the extensive feature engineering common to current learning-to-rank methods. However, we show that combining simple relevance matching features like BM25 with existing Deep Neural Net models often substantially improves the accuracy of these models, indicating that they do not capture essential local relevance matching signals. We describe a novel deep Recurrent Neural Net-based model that we call Match-Tensor. The architecture of the Match-Tensor model simultaneously accounts for both local relevance matching and global topicality signals allowing for a rich interplay between them when computing the relevance of a document to a query. On a large held-out test set consisting of social media documents, we demonstrate not only that Match-Tensor outperforms BM25 and other classes of DNNs but also that it largely subsumes signals present in these models.",
            "output": [
                "Match-Tensor: a Deep Relevance Model for Search"
            ]
        },
        {
            "id": "task1540-c149b2a7dac44966825399f509ab1d99",
            "input": "By utilizing different communication channels, such as verbal language, gestures or facial expressions, virtually embodied interactive humans hold a unique potential to bridge the gap between human-computer interaction and actual interhuman communication. The use of virtual humans is consequently becoming increasingly popular in a wide range of areas where such a natural communication might be beneficial, including entertainment, education, mental health research and beyond. Behind this development lies a series of technological advances in a multitude of disciplines, most notably natural language processing, computer vision, and speech synthesis. In this paper we discuss a Virtual Human Journalist, a project employing a number of novel solutions from these disciplines with the goal to demonstrate their viability by producing a humanoid conversational agent capable of naturally eliciting and reacting to information from a human user. A set of qualitative and quantitative evaluation sessions demonstrated the technical feasibility of the system whilst uncovering a number of deficits in its capacity to engage users in a way that would be perceived as natural and emotionally engaging. We argue that naturalness should not always be seen as a desirable goal and suggest that deliberately suppressing the naturalness of virtual human interactions, such as by altering its personality cues, might in some cases yield more desirable results.",
            "output": [
                "I Probe, Therefore I Am: Designing a Virtual Journalist with Human Emotions"
            ]
        },
        {
            "id": "task1540-260aebbf01824ab49fd6d05ade0150a7",
            "input": "The k-fold cross-validation is commonly used to evaluate the effectiveness of SVMs with the selected hyperparameters. It is known that the SVM k-fold crossvalidation is expensive, since it requires training k SVMs. However, little work has explored reusing the h SVM for training the (h+1) SVM for improving the efficiency of k-fold cross-validation. In this paper, we propose three algorithms that reuse the h SVM for improving the efficiency of training the (h + 1) SVM. Our key idea is to efficiently identify the support vectors and to accurately estimate their associated weights (also called alpha values) of the next SVM by using the previous SVM. Our experimental results show that our algorithms are several times faster than the k-fold cross-validation which does not make use of the previously trained SVM. Moreover, our algorithms produce the same results (hence same accuracy) as the k-fold cross-validation which does not make use of the previously trained SVM.",
            "output": [
                "Improving Efficiency of SVM k-fold Cross-validation by Alpha Seeding"
            ]
        },
        {
            "id": "task1540-74ae1b3396be46b2b2acd504e47ca0bc",
            "input": "The weighted Maximum Satisfiability problem (weighted MAX-SAT) is a NP-hard problem with numerous applications arising in artificial intelligence. As an efficient tool for heuristic design, the backbone has been applied to heuristics design for many NP-hard problems. In this paper, we investigated the computational complexity for retrieving the backbone in weighted MAX-SAT and developed a new algorithm for solving this problem. We showed that it is intractable to retrieve the full backbone under the assumption that NP P  . Moreover, it is intractable to retrieve a fixed fraction of the backbone as well. And then we presented a backbone guided local search (BGLS) with Walksat operator for weighted MAX-SAT. BGLS consists of two phases: the first phase samples the backbone information from local optima and the backbone phase conducts local search under the guideline of backbone. Extensive experimental results on the benchmark showed that BGLS outperforms the existing heuristics in both solution quality and runtime.",
            "output": [
                "Approximating the Backbone in the Weighted Maximum Satisfiability Problem"
            ]
        },
        {
            "id": "task1540-b6da8c3f8594416e9440b51acdd30d0d",
            "input": "Modern classification problems frequently present mild to severe label imbalance as well as specific requirements on classification characteristics, and require optimizing performance measures that are non-decomposable over the dataset, such as F-measure. Such measures have spurred much interest and pose specific challenges to learning algorithms since their non-additive nature precludes a direct application of well-studied large scale optimization methods such as stochastic gradient descent. In this paper we reveal that for two large families of performance measures that can be expressed as functions of true positive/negative rates, it is indeed possible to implement point stochastic updates. The families we consider are concave and pseudo-linear functions of TPR, TNR which cover several popularly used performance measures such as F-measure, G-mean and H-mean. Our core contribution is an adaptive linearization scheme for these families, using which we develop optimization techniques that enable truly point-based stochastic updates. For concave performance measures we propose SPADE, a stochastic primal dual solver; for pseudo-linear measures we propose STAMP, a stochastic alternate maximization procedure. Both methods have crisp convergence guarantees, demonstrate significant speedups over existing methods often by an order of magnitude or more, and give similar or more accurate predictions on test data.",
            "output": [
                "Optimizing Non-decomposable Performance Measures: A Tale of Two Classes"
            ]
        },
        {
            "id": "task1540-d5294deb1793459a9635aebb8f32ead7",
            "input": "Information fusion is an advanced research area which can assist decision makers in enhancing their decisions. This paper aims at designing a new multi-layer framework that can support the process of performing decisions from the obtained beliefs using information fusion. Since it is not an easy task to cross the gap between computed beliefs of certain hypothesis and decisions, the proposed framework consists of the following layers in order to provide a suitable architecture (ordered bottom up): 1. A layer for combination of basic belief assignments using an information fusion approach. Such approach exploits Dezert-Smarandache Theory, DSmT, and proportional conflict redistribution to provide more realistic final beliefs. 2. A layer for computation of pignistic probability of the underlying propositions from the corresponding final beliefs. 3. A layer for performing probabilistic reasoning using a Bayesian network that can obtain the probable reason of a proposition from its pignistic probability. 4. Ranking the system decisions is ultimately used to support decision making. A case study has been accomplished at various operational conditions in order to prove the concept, in addition it pointed out that: 1. The use of DSmT for information fusion yields not only more realistic beliefs but also reliable pignistic probabilities for the underlying propositions. 2. Exploiting the pignistic probability for the integration of the information fusion with the Bayesian network provides probabilistic inference and enable decision making on the basis of both belief based probabilities for the underlying propositions and Bayesian based probabilities for the corresponding reasons. Vol. 8, No. 28, July 2013, 1237-1250",
            "output": [
                "Design of a Framework to Facilitate Decisions Using Information Fusion"
            ]
        },
        {
            "id": "task1540-1a2c48bdf0e54a1382491d8613a7856b",
            "input": "Mined Semantic Analysis (MSA) is a novel concept space model which employs unsupervised learning to generate semantic representations of text. MSA represents textual structures (terms, phrases, documents) as a bag-of-concepts where concepts are derived from concept rich encyclopedic corpora. Traditional concept space models exploit only target corpus content to construct the concept space. MSA, alternatively, uncovers implicit relations between concepts by mining for their associations (e.g., mining Wikipedia’s \"See also\" link graph). We evaluate MSA’s performance on benchmark data sets for measuring lexical semantic relatedness. Empirical results show competitive performance of MSA compared to prior stateof-the-art methods. Additionally, we introduce the first analytical study to examine statistical significance of results reported by different semantic relatedness methods. Our study shows that, the nuances of results across top performing methods could be statistically insignificant. The study positions MSA as one of state-of-theart methods for measuring semantic relatedness.",
            "output": [
                "Measuring Semantic Relatedness using Mined Semantic Analysis"
            ]
        },
        {
            "id": "task1540-51c9f8f6ba6e41748277179face56aff",
            "input": "Every field of research consists of multiple application areas with various techniques routinely used to solve problems in these wide range of application areas. With the exponential growth in research volumes, it has become difficult to keep track of the ever-growing number of application areas as well as the corresponding problem solving techniques. In this paper, we consider the computational linguistics domain and present a novel information extraction system that automatically constructs a pool of all application areas in this domain and appropriately links them with corresponding problem solving techniques. Further, we categorize individual research articles based on their application area and the techniques proposed/used in the article. k-gram based discounting method along with handwritten rules and bootstrapped pattern learning is employed to extract application areas. Subsequently, a language modelling approach is proposed to characterize each article based on its application area. Similarly, regular expressions and high-scoring noun phrases are used for the extraction of the problem solving techniques. We propose a greedy approach to characterize each article based on the techniques. Towards the end, we present a table representing the most frequent techniques adopted for a particular application area. Finally, we propose three use cases presenting an extensive temporal analysis of the usage of techniques and application areas.",
            "output": [
                "Which techniques does your application use?: An information extraction framework for scientific articles"
            ]
        },
        {
            "id": "task1540-785647416af34ca9a9479fafa295452d",
            "input": "Dropout and other feature noising schemes control overfitting by artificially cor-<lb>rupting the training data. For generalized linear models, dropout performs a form<lb>of adaptive regularization. Using this viewpoint, we show that the dropout regular-<lb>izer is first-order equivalent to an L2 regularizer applied after scaling the features<lb>by an estimate of the inverse diagonal Fisher information matrix. We also establish<lb>a connection to AdaGrad, an online learning algorithm, and find that a close rel-<lb>ative of AdaGrad operates by repeatedly solving linear dropout-regularized prob-<lb>lems. By casting dropout as regularization, we develop a natural semi-supervised<lb>algorithm that uses unlabeled data to create a better adaptive regularizer. We ap-<lb>ply this idea to document classification tasks, and show that it consistently boosts<lb>the performance of dropout training, improving on state-of-the-art results on the<lb>IMDB reviews dataset.",
            "output": [
                "Dropout Training as Adaptive Regularization"
            ]
        },
        {
            "id": "task1540-fcbc93956fce4d8684f7e8484600d313",
            "input": "In this paper, the idea of applying Computational Intelligence in the process of creation board games, in particular mazes, is presented. For two different algorithms the proposed idea has been examined. The results of the experiments are shown and discussed to present advantages and disadvantages. Keywords—Computational Intelligence, Heuristic Algorithm",
            "output": [
                "Is swarm intelligence able to create mazes?"
            ]
        },
        {
            "id": "task1540-0625f68492a94327a8df098572b725cb",
            "input": "Collaborative ltering is an e ective recommendation technique wherein the preference of an individual can potentially be predicted based on preferences of other members. Early algorithms often relied on the strong locality in the preference data, that is, it is enough to predict preference of a user on a particular item based on a small subset of other users with similar tastes or of other items with similar properties. More recently, dimensionality reduction techniques have proved to be equally competitive, and these are based on the co-occurrence patterns rather than locality. This paper explores and extends a probabilistic model known as Boltzmann Machine for collaborative ltering tasks. It seamlessly integrates both the similarity and cooccurrence in a principled manner. In particular, we study parameterisation options to deal with the ordinal nature of the preferences, and propose a joint modelling of both the user-based and item-based processes. Experiments on moderate and large-scale movie recommendation show that our framework rivals existing well-known methods.",
            "output": [
                "Ordinal Boltzmann Machines for Collaborative Filtering"
            ]
        },
        {
            "id": "task1540-163040f5d4654110a8ab50320541d59f",
            "input": "A large number of experimental data shows that Support Vector Machine (SVM) algorithm has obvious a large advantages in text classification, handwriting recognition, image classification, bioinformatics, and some other fields. To some degree, the optimization of SVM depends on its kernel function and Slack variable, the determinant of which is its parameters δ and c in the classification function. That is to say, to optimize the SVM algorithm, the optimization of the two parameters play a huge role. Ant Colony Optimization (ACO) is optimization algorithm which simulate ants to find the optimal path. In the available literature, we mix the ACO algorithm and Parallel algorithm together to find a well parameters. Keyword: SVM, Parameters, ACO, OpenCL, Parallel I. SUPPORT VECTOR CLASSIFICATION AND PARAMETERS SVM is based on the principle of structural risk minimization,using limited training samples to obtain the higher generalization ability of decision function. Suppose a sample set (xi, yi) , where i = 1, 2...N means the number of training samples, x∈R means the sample characteristics, y ∈ {+1,−1} means the sample classification. SVM Classification function: y = ωx+ b (ω means weight vector,b means setover)",
            "output": [
                "A Parallel Way to Select the Parameters of SVM Based on the Ant Optimization Algorithm"
            ]
        },
        {
            "id": "task1540-f133d437eadf4c3492d15522c77ff050",
            "input": "A popular approach to topic modeling involves extracting co-occurring n-grams of a corpus into semantic themes. The set of n-grams in a theme represents an underlying topic, but most topic modeling approaches are not able to label these sets of words with a single n-gram. Such labels are useful for topic identification in summarization systems. This paper introduces a novel approach to labeling a group of n-grams comprising an individual topic. The approach taken is to complement the existing topic distributions over words with a known distribution based on a predefined set of topics. This is done by integrating existing labeled knowledge sources representing known potential topics into the probabilistic topic model. These knowledge sources are translated into a distribution and used to set the hyperparameters of the Dirichlet generated distribution over words. In the inference these modified distributions guide the convergence of the latent topics to conform with the complementary distributions. This approach ensures that the topic inference process is consistent with existing knowledge. The label assignment from the complementary knowledge sources are then transferred to the latent topics of the corpus. The results show both accurate label assignment to topics as well as improved topic generation than those obtained using various labeling approaches of Latent Dirichlet allocation (LDA) when compared by pointwise mutual information (PMI) assessment.",
            "output": [
                "Source-LDA: Enhancing probabilistic topic models using prior knowledge sources"
            ]
        },
        {
            "id": "task1540-d3a40733635540648e1e7c0f140a16f4",
            "input": "Network Intrusion Detection Systems (NIDS) monitor a network with the aim of discerning malicious from benign activity on that network. While a wide range of approaches have met varying levels of success, most IDS’s rely on having access to a database of known attack signatures which are written by security experts. Nowadays, in order to solve problems with false positive alerts, correlation algorithms are used to add additional structure to sequences of IDS alerts. However, such techniques are of no help in discovering novel attacks or variations of known attacks, something the human immune system (HIS) is capable of doing in its own specialised domain. This paper presents a novel immune algorithm for application to an intrusion detection problem. The goal is to discover packets containing novel variations of attacks covered by an existing signature base.",
            "output": [
                "Integrating Innate and Adaptive Immunity for Intrusion Detection"
            ]
        },
        {
            "id": "task1540-b90a64227da047a3aaebc81a6791e48b",
            "input": "Latent tree analysis seeks to model the correlations among a set of random variables using a tree of latent variables. It was proposed as an improvement to latent class analysis — a method widely used in social sciences and medicine to identify homogeneous subgroups in a population. It provides new and fruitful perspectives on a number of machine learning areas, including cluster analysis, topic detection, and deep probabilistic modeling. This paper gives an overview of the research on latent tree analysis and various ways it is used in practice. Much of machine learning is about modeling and utilizing correlations among variables. In classification, the task is to establish relationships between attributes and class variables so that unseen data can be classified accurately. In Bayesian networks, dependencies among variables are represented as directed acyclic graphs and the graphs are used to facilitate efficient probabilistic inference. In topic models, word cooccurrences are accounted for by assuming that all words are generated probabilistically from the same set of topics, and the generation process is reverted via statistical inference to determine the topics. In deep belief networks, correlations among observed units are modeled using multiple levels of hidden units, and the top-level hidden units are used as a representation of the data for further analysis. Latent tree analysis (LTA) seeks to model the correlations among a set of observed variables using a tree model, called latent tree model (LTM), where the leaf nodes represent observed variables and the internal nodes represent latent variables.The dependence between two observed variables is explained by the path between them. Despite their simplicity, LTMs subsume two classes of models widely used in academic research. The first one is latent class models (LCMs) (Lazarsfeld and Henry, 1968; Knott and Bartholomew, 1999), which are LTMs with a single latent variable. They are used for categorical data clustering in social sciences and medicine. The second class is probabilistic phylogenetic trees (Durbin et al., 1998), which are a tool for determining the evolution history of a set of species. Phylogenetic trees are special LTMs where the model structures are binary (bifurcating) trees and all the Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. variables have the same number of possible states. LTA also provides new and fruitful perspectives on a number of machine learning areas. One area is cluster analysis. Here finite mixture models such as LCMs are commonly used. A finite mixture model has one latent variable and consequently it gives one soft partition of data. An LTM typically has multiple latent variables and hence LTA yields multiple soft partitions of data simultaneously. In other words, LTA performs multidimensional clustering (Chen et al., 2012; Liu et al., 2013). It is interesting because complex data usually have multiple facets and can be meaningfully clustered in multiple ways. Another area is topic detection. Applying LTA to text data, we can partition a collection of documents in multiple ways. The document clusters in the partitions can be interpreted as topics. Furthermore, it is possible to learn hierarchical LTMs where the latent variables are organized into multiple layers. This leads to an alternative method for hierarchical topic detection (Liu, Zhang, and Chen, 2014; Chen et al., 2016a), which has been shown to find more meaningful topics and topic hierarchies than the state-of-the-art method based on latent Dirichlet allocation (Paisley et al., 2015). The third area is deep probabilistic modeling. Hierarchical LTM and deep belief network (DBN) (Hinton, Osindero, and Teh, 2006) are similar in that they both consist of multiple layers of variables, with an observed layer at the bottom and multiple layers of hidden units on top of it. One difference is that, in DBN, units from adjacent layers are fully connected, while HLTM is tree-structured. It would be interesting to explore the middle ground between the two extreme and develop algorithms for learning what might be called sparse DBNs. Learning structures for deep models is an interesting open problem. Extension of LTA might offer one solution (Chen et al., 2016b). The concept of latent tree models was introduced in (Zhang, 2002, 2004), where they were referred to as hierarchical latent class models. The term “latent tree models” first appeared in (Zhang et al., 2008; Wang, Zhang, and Chen, 2008). Mourad et al. (2013) surveyed the research on latent tree models as of 2012 in details. This paper provides a concise overview of the methodology. The exposition are more conceptual and less technical than (Mourad et al., 2013). Developments after 2012 are also included. ar X iv :1 61 0. 00 08 5v 1 [ cs .L G ] 1 O ct 2 01 6",
            "output": [
                "Latent Tree Analysis"
            ]
        },
        {
            "id": "task1540-5bc3170ea2b44d2cb64706740b6af7bc",
            "input": "Advances in artificial intelligence (AI) will transform modern life by reshaping transportation, health, science, finance, and the military [1, 2, 3]. To adapt public policy, we need to better anticipate these advances [4, 5]. Here we report the results from a large survey of machine learning researchers on their beliefs about progress in AI. Researchers predict AI will outperform humans in many activities in the next ten years, such as translating languages (by 2024), writing high-school essays (by 2026), driving a truck (by 2027), working in retail (by 2031), writing a bestselling book (by 2049), and working as a surgeon (by 2053). Researchers believe there is a 50% chance of AI outperforming humans in all tasks in 45 years and of automating all human jobs in 120 years, with Asian respondents expecting these dates much sooner than North Americans. These results will inform discussion amongst researchers and policymakers about anticipating and managing trends in AI.",
            "output": [
                "When Will AI Exceed Human Performance? Evidence from AI Experts"
            ]
        },
        {
            "id": "task1540-30be581ad42046bba3efe3fc2b25dd30",
            "input": "The skip-thought model has been proven to be effective at learning sentence representations and capturing sentence semantics. In this paper, we propose a suite of techniques to trim and improve it. First, we validate a hypothesis that, given a current sentence, inferring the previous and inferring the next sentence provide similar supervision power, therefore only one decoder for predicting the next sentence is preserved in our trimmed skip-thought model. Second, we present a connection layer between encoder and decoder to help the model to generalize better on semantic relatedness tasks. Third, we found that a good word embedding initialization is also essential for learning better sentence representations. We train our model unsupervised on a large corpus with contiguous sentences, and then evaluate the trained model on 7 supervised tasks, which includes semantic relatedness, paraphrase detection, and text classification benchmarks. We empirically show that, our proposed model is a faster, lighter-weight and equally powerful alternative to the original skip-thought model.",
            "output": [
                "Trimming and Improving Skip-thought Vectors"
            ]
        },
        {
            "id": "task1540-068917b902d942259395794985e3be9a",
            "input": "Although the CSP (constraint satisfaction problem) is NP-complete, even in the case when all constraints are binary, certain classes of instances are tractable. We study classes of instances defined by excluding subproblems. This approach has recently led to the discovery of novel tractable classes. The complete characterisation of all tractable classes defined by forbidding patterns (where a pattern is simply a compact representation of a set of subproblems) is a challenging problem. We demonstrate a dichotomy in the case of forbidden patterns consisting of either one or two constraints. This has allowed us to discover new tractable classes including, for example, a novel generalisation of 2SAT.",
            "output": [
                "A Dichotomy for 2-Constraint Forbidden CSP Patterns"
            ]
        },
        {
            "id": "task1540-d0e20d84b4764bb8a99ef26cebbd85a3",
            "input": "A new architecture and learning algorithms for the multidimensional hybrid cascade neural network with neuron pool optimization in each cascade are proposed in this paper. The proposed system differs from the well-known cascade systems in its capability to process multidimensional time series in an online mode, which makes it possible to process non-stationary stochastic and chaotic signals with the required accuracy. Compared to conventional analogs, the proposed system provides computational simplicity and possesses both tracking and filtering capabilities.",
            "output": [
                "A Multidimensional Cascade Neuro-Fuzzy System with Neuron Pool Optimization in Each Cascade"
            ]
        },
        {
            "id": "task1540-7cdf8b4be71d4d178140b4f3886d4600",
            "input": "As part of Smart Cities initiatives, national, regional and local governments all over the globe are under the mandate of being more open regarding how they share their data. Under this mandate, many of these governments are publishing data under the umbrella of open government data, which includes measurement data from city-wide sensor networks. Furthermore, many of these data are published in so-called data portals as documents that may be spreadsheets, comma-separated value (CSV) data files, or plain documents in PDF or Word documents. The sharing of these documents may be a convenient way for the data provider to convey and publish data but it is not the ideal way for data consumers to reuse the data. For example, the problems of reusing the data may range from difficulty opening a document that is provided in any format that is not plain text, to the actual problem of understanding the meaning of each piece of knowledge inside of the document. Our proposal tackles those challenges by identifying metadata that has been regarded to be relevant for measurement data and providing a schema for this metadata. We further leverage the Human-Aware Sensor Network Ontology (HASNetO) to build an architecture for data collected in urban environments. We discuss the use of HASNetO and the supporting infrastructure to manage both data and metadata in support of the City of Fortaleza, a large metropolitan area in Brazil.",
            "output": [
                "Contextual Data Collection for Smart Cities"
            ]
        },
        {
            "id": "task1540-8c7241a258e743daabe3508b7536a039",
            "input": "For Markov chain Monte Carlo methods, one of the greatest discrepancies between theory and system is the scan order — while most theoretical development on the mixing time analysis deals with random updates, real-world systems are implemented with systematic scans. We bridge this gap for models that exhibit a bipartite structure, including, most notably, the Restricted/Deep Boltzmann Machine. The de facto implementation for these models scans variables in a layer-wise fashion. We show that the Gibbs sampler with a layerwise alternating scan order has its relaxation time (in terms of epochs) no larger than that of a random-update Gibbs sampler (in terms of variable updates). We also construct examples to show that this bound is asymptotically tight. Through standard inequalities, our result also implies a comparison on the mixing times.",
            "output": [
                "LAYERWISE SYSTEMATIC SCAN: DEEP BOLTZMANN MACHINES AND BEYOND"
            ]
        },
        {
            "id": "task1540-08122e4cee834888a22dd386b6f4ffd2",
            "input": "We assess the performance of generic text summarization algorithms applied to films and documentaries, using extracts from news articles produced by reference models of extractive summarization. We use three datasets: (i) news articles, (ii) film scripts and subtitles, and (iii) documentary subtitles. Standard ROUGE metrics are used for comparing generated summaries against news abstracts, plot summaries, and synopses. We show that the best performing algorithms are LSA, for news articles and documentaries, and LexRank and Support Sets, for films. Despite the different nature of films and documentaries, their relative behavior is in accordance with that obtained for news articles. c © 2016 Elsevier Ltd. All rights reserved.",
            "output": [
                "Summarization of Films and Documentaries Based on Subtitles and Scripts"
            ]
        },
        {
            "id": "task1540-2740d7c9c89945649fe223c4d5d3bb39",
            "input": "The segmentation, seen as the association of a partition with an image, is a difficult task. It can be decomposed in two steps: at first, a family of contours associated with a series of nested partitions (or hierarchy) is created and organized, then pertinent contours are extracted. A coarser partition is obtained by merging adjacent regions of a finer partition. The strength of a contour is then measured by the level of the hierarchy for which its two adjacent regions merge. We present an automatic segmentation strategy using a wide range of stochastic watershed hierarchies. For a given set of homogeneous images, our approach selects automatically the best hierarchy and cut level to perform image simplification given an evaluation score. Experimental results illustrate the advantages of our approach on several real-life images datasets.",
            "output": [
                "AUTOMATIC SELECTION OF STOCHASTIC WATERSHED HIERARCHIES"
            ]
        },
        {
            "id": "task1540-a7e9e4451dc14bc9a77af197fa17c811",
            "input": "Online model-free reinforcement learning (RL) methods with continuous actions are playing a prominent role when dealing with real-world applications such as Robotics. However, when confronted to non-stationary environments, these methods crucially rely on an exploration-exploitation trade-off which is rarely dynamically and automatically adjusted to changes in the environment. Here we propose an active exploration algorithm for RL in structured (parameterized) continuous action space. This framework deals with a set of discrete actions, each of which is parameterized with continuous variables. Discrete exploration is controlled through a Boltzmann softmax function with an inverse temperature β parameter. In parallel, a Gaussian exploration is applied to the continuous action parameters. We apply a meta-learning algorithm based on the comparison between variations of short-term and long-term reward running averages to simultaneously tune β and the width of the Gaussian distribution from which continuous action parameters are drawn. When applied to a simple virtual human-robot interaction task, we show that this algorithm outperforms continuous parameterized RL both without active exploration and with active exploration based on uncertainty variations measured by a Kalman-Q-learning algorithm.",
            "output": [
                "Active exploration in parameterized reinforcement learning"
            ]
        },
        {
            "id": "task1540-a81913cf161f4c079b43cccc301130e1",
            "input": "We present a case study of artificial intelligence techniques applied to the control of production printing equipment. Like many other real-world applications, this complex domain requires high-speed autonomous decision-making and robust continual operation. To our knowledge, this work represents the first successful industrial application of embedded domain-independent temporal planning. Our system handles execution failures and multiobjective preferences. At its heart is an on-line algorithm that combines techniques from state-space planning and partial-order scheduling. We suggest that this general architecture may prove useful in other applications as more intelligent systems operate in continual, on-line settings. Our system has been used to drive several commercial prototypes and has enabled a new product architecture for our industrial partner. When compared with state-of-the-art off-line planners, our system is hundreds of times faster and often finds better plans. Our experience demonstrates that domain-independent AI planning based on heuristic search can flexibly handle time, resources, replanning, and multiple objectives in a high-speed practical application without requiring hand-coded control knowledge.",
            "output": [
                "On-line Planning and Scheduling: An Application to Controlling Modular Printers"
            ]
        },
        {
            "id": "task1540-ecd1067e894a492980600713f13fa385",
            "input": "In this paper, we explore SPPIM-based text classification method, and the experiment reveals that the SPPIM method is equal to or even superior than SGNS method in text classification task on three international and standard text datasets, namely 20newsgroups, Reuters52 and WebKB. Comparing to SGNS, although SPPMI provides a better solution, it is not necessarily better than SGNS in text classification tasks.. Based on our analysis, SGNS takes into the consideration of weight calculation during decomposition process, so it has better performance than SPPIM in some standard datasets. Inspired by this, we propose a WL-SPPIM semantic model based on SPPIM model, and experiment shows that WL-SPPIM approach has better classification and higher scalability in the text classification task compared with LDA, SGNS and SPPIM approaches.",
            "output": [
                "A WL-SPPIM Semantic Model for Document Classification"
            ]
        },
        {
            "id": "task1540-845cfebca39a442b9f9cbab196eaacd9",
            "input": "This paper develops a model that addresses syntactic embedding for machine comprehension, a key task of natural language understanding. Our proposed model, structural embedding of syntactic trees (SEST), takes each word in a sentence, constructs a sequence of syntactic nodes extracted from syntactic parse trees, and encodes the sequence into a vector representation. The learned vector is then incorporated into neural attention models, which allows learning the mapping of syntactic structures between question and context pairs. We evaluate our approach on SQuAD dataset and demonstrate that our model can accurately identify the syntactic boundaries of the sentences and to extract answers that are syntactically coherent over the baseline methods.",
            "output": [
                "Structural Embedding of Syntactic Trees for Machine Comprehension"
            ]
        },
        {
            "id": "task1540-a48782df04f243d486325dbda5b2cacf",
            "input": "Recently, recurrent neural networks (RNNs) as powerful sequence models have re-emerged as a potential acoustic model for statistical parametric speech synthesis (SPSS). The long short-term memory (LSTM) architecture is particularly attractive because it addresses the vanishing gradient problem in standard RNNs, making them easier to train. Although recent studies have demonstrated that LSTMs can achieve significantly better performance on SPSS than deep feedforward neural networks, little is known about why. Here we attempt to answer two questions: a) why do LSTMs work well as a sequence model for SPSS; b) which component (e.g., input gate, output gate, forget gate) is most important. We present a visual analysis alongside a series of experiments, resulting in a proposal for a simplified architecture. The simplified architecture has significantly fewer parameters than an LSTM, thus reducing generation complexity considerably without degrading quality.",
            "output": [
                "INVESTIGATING GATED RECURRENT NETWORKS FOR SPEECH SYNTHESIS"
            ]
        },
        {
            "id": "task1540-f4c2914553324dfc908a92c64c5839cd",
            "input": "We propose randomized least-squares value iteration (RLSVI) – a new reinforcement learning algorithm designed to explore and generalize efficiently via linearly parameterized value functions. We explain why versions of least-squares value iteration that use Boltzmann or -greedy exploration can be highly inefficient, and we present computational results that demonstrate dramatic efficiency gains enjoyed by RLSVI. Further, we establish an upper bound on the expected regret of RLSVI that demonstrates nearoptimality in a tabula rasa learning context. More broadly, our results suggest that randomized value functions offer a promising approach to tackling a critical challenge in reinforcement learning: synthesizing efficient exploration and effective generalization.",
            "output": [
                "Generalization and Exploration via Randomized Value Functions"
            ]
        },
        {
            "id": "task1540-bf9c2e1b3c1045e4ab40b9d0b23670d7",
            "input": "This paper reveals the results of an analysis of the accuracy of developed software for automatic lemmatization for the Bulgarian language. This lemmatization software is written entirely in Java and is distributed as a GATE plugin. Certain statistical methods are used to define the accuracy of this software. The results of the analysis show 95% lemmatization accuracy.",
            "output": [
                "Evaluation of the Accuracy of the BGLemmatizer"
            ]
        },
        {
            "id": "task1540-4a2d5a1087f34049a5ae6cb18aef2ab9",
            "input": "We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic backpropagation – rules for back-propagation through stochastic variables – and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.",
            "output": [
                "Stochastic Back-propagation and Variational Inference in  Deep Latent Gaussian Models"
            ]
        },
        {
            "id": "task1540-e7d5b5de89034c38b2d196e8a78d502a",
            "input": "A common approach in positive-unlabeled learning is to train a classification model between labeled and unlabeled data. This strategy is in fact known to give an optimal classifier under mild conditions; however, it results in biased empirical estimates of the classifier performance. In this work, we show that the typically used performance measures such as the receiver operating characteristic curve, or the precisionrecall curve obtained on such data can be corrected with the knowledge of class priors; i.e., the proportions of the positive and negative examples in the unlabeled data. We extend the results to a noisy setting where some of the examples labeled positive are in fact negative and show that the correction also requires the knowledge of the proportion of noisy examples in the labeled positives. Using state-of-the-art algorithms to estimate the positive class prior and the proportion of noise, we experimentally evaluate two correction approaches and demonstrate their efficacy on real-life data. Introduction Performance estimation in binary classification is tightly related to the nature of the classification task. As a result, different performance measures may be directly optimized during training. When (mis)classification costs are available, the classifier is ideally trained and evaluated in a costsensitive mode to minimize the expected cost (Whalen 1971; Elkan 2001). More often, however, classification costs are unknown and the overall performance is assessed by averaging the performance over a range of classification modes. The most extensively studied and widely used performance evaluation in binary classification involves estimating the Receiver Operating Characteristic (ROC) curve that plots the true positive rate of a classifier as a function of its false positive rate (Fawcett 2006). The ROC curve provides insight into trade-offs between the classifier’s accuracies on positive versus negative examples over a range of decision thresholds. Furthermore, the area under the ROC curve (AUC) has a meaningful probabilistic interpretation that correlates with the ability of the classifier to separate classes and is often used to rank classifiers (Hanley and McNeil 1982). Another important performance criterion generally used in information retrieval relies on the precision-recall Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. (pr-rc) curve, a plot of precision as a function of recall. The precision-recall evaluation, including summary statistics derived from the pr-rc curve, may be preferred to ROC curves when classes are heavily skewed (Davis and Goadrich 2006). Although model learning and performance evaluation in a supervised setting are well understood (Hastie et al. 2001), the availability of unlabeled data gives additional options and also presents new challenges. A typical semi-supervised scenario involves the availability of positive, negative and (large quantities of) unlabeled data. Here, the unlabeled data can be used to improve training (Blum and Mitchell 1998) or unbias the labeled data (Cortes et al. 2008); e.g., to estimate class proportions that are necessary to calibrate the model and accurately estimate precision when class balances (but not class-conditional distributions) in labeled data are not representative (Saerens et al. 2002). This is often the case when it is more expensive or difficult to label examples of one class than the examples of the other. A special case of the semi-supervised setting arises when the examples of only one class are labeled. It includes open-world domains such as molecular biology where, for example, wet lab experiments determining a protein’s activity are generally conclusive; however, the absence of evidence about a protein’s function cannot be interpreted as the evidence of absence. This is because, even when the labeling is attempted, a functional assay may not lead to the desired activity for a number of experimental reasons. In other domains, such as social networks, only positive examples can be collected (such as ‘liking’ a particular product) because, by design, the negative labeling is not allowed. The development of classification models in this setting is often referred to as positiveunlabeled learning (Denis et al. 2005). State-of-the-art techniques in positive-unlabeled learning tackle this problem by treating the unlabeled sample as negatives and training a classifier to distinguish between labeled (positive) and unlabeled examples. Following Elkan and Noto (2008), we refer to the classifiers trained on a labeled sample from the true distribution of inputs, containing both positive and negative examples, as traditional classifiers. Similarly, we refer to the classifiers trained on the labeled versus unlabeled data as non-traditional classifiers. In theory, the true performance of both traditional and non-traditional classifiers can be evaluated on a labeled samar X iv :1 70 2. 00 51 8v 1 [ st at .M L ] 2 F eb 2 01 7 ple from the true distribution (traditional evaluation). However, this is infeasible for non-traditional learners because such a sample is not available in positive-unlabeled learning. As a result, the non-traditional classifiers are evaluated by using the unlabeled sample as substitute for labeled negatives (non-traditional evaluation). Surprisingly, for a variety of performance criteria, non-traditional classifiers achieve similar performance under traditional evaluation as optimal traditional classifiers (Blanchard et al. 2010; Menon et al. 2015). The intuition for these results comes from the fact that in many practical situations, the posterior distributions in traditional and non-traditional setting provide the same optimal ranking of data points on a given test sample (Jain et al. 2016; Jain, White, and Radivojac 2016). Furthermore, the widely-accepted evaluation approaches using ROC or pr-rc curves are insensitive to the variation of raw prediction scores unless they affect the ranking. Though the efficacy of non-traditional classifiers has been thoroughly studied (Peng et al. 2003; Elkan and Noto 2008; Ward et al. 2009; Menon et al. 2015), estimating their true performance has been much less explored. Such performance estimation often involves computing the fraction(s) of correctly and incorrectly classified examples from both classes; however, in absence of labeled negatives, the fractions computed under the non-traditional evaluation are incorrect, resulting in biased estimates. Figure 1 illustrates the effect of this bias by showing the traditional and nontraditional ROC curves on a handmade data set. Because some of the unlabeled examples in the training set are in fact positive, the area under the ROC curve estimated when the unlabeled examples were considered negative (nontraditional setting) underestimates the true performance for positive versus negative classification (traditional setting). This paper formalizes and evaluates performance estimation of a non-traditional classifier in the traditional setting when the only available training data are (possibly noisy) positive examples and unlabeled data. We show that the true (traditional) performance of such a classifier can be recovered with the knowledge of class priors and the fraction of mislabeled examples in the positive set. We derive formulas for converting the ROC and pr-rc curves from the nontraditional to the traditional setting. Using these recovery formulas, we present methods to estimate true classification performance. Our experiments provide evidence that the methods for the recovery of a classifier’s performance are sound and effective. Problem formulation Consider a binary classification problem from input x ∈ X to output y ∈ Y = {0, 1} in a positive-unlabeled setting. Let f be the true distribution over the input space X from which the unlabeled sample is drawn and let f1 and f0 be the distributions of the positive and negative examples, respectively. It follows that f can be expressed as a two-component mixture containing f1 and f0 as f(x) = αf1(x) + (1− α)f0(x), for all x ∈ X where α ∈ [0, 1) is the mixing proportion (positive class prior) giving the proportion of positives in f . ́ ́ ° ° AUC = 0.8000 AUC = 0.9375 B. Positive vs. unlabeled A. Data set: prediction scores and class labels C. Positive vs. negative 0.986 yes, as 1 0.943 no 0.863 yes, as 1 0.789 no 0.009 no 0.699 yes, as 1 0.473 no 0.211 no 1 1 1 0 1 0 0 0 Prediction Labeled True class label",
            "output": [
                "Recovering True Classifier Performance in Positive-Unlabeled Learning"
            ]
        },
        {
            "id": "task1540-df434477e0cb40468f86e193e3546453",
            "input": "In this paper we present the first empirical study of the emphatic temporaldifference learning algorithm (ETD), comparing it with conventional temporaldifference learning, in particular, with linear TD(0), on on-policy and off-policy variations of the Mountain Car problem. The initial motivation for developing ETD was that it has good convergence properties under off -policy training (Sutton, Mahmood & White 2016), but it is also a new algorithm for the on-policy case. In both our on-policy and off-policy experiments, we found that each method converged to a characteristic asymptotic level of error, with ETD better than TD(0). TD(0) achieved a still lower error level temporarily before falling back to its higher asymptote, whereas ETD never showed this kind of “bounce”. In the off-policy case (in which TD(0) is not guaranteed to converge), ETD was significantly slower. 1 Emphatic Temporal Difference Learning We consider the problem of learning the value function for a Markov decision process and a given policy. An agent and environment interact at discrete time steps, t = 0, 1, 2, . . ., at each of which the environment is in a state St, the agent selects an action At and as a result the environment emits a reward Rt+1 and a next state St+1. States are represented to the agent as feature vectors φt = φ(St) ∈ R. We seek to find a parameter vector, θt ∈ R such that the inner product θ> t φt approximates the expected return E [ Rt+1 + γRt+2 + γ Rt+3 + · · · | At:∞ ∼ π ] , where π : A × S → [0, 1] is a policy for selecting the future actions. In fact, all actions are selected by an alternate policy μ. If π = μ, then the training is called on-policy, whereas if the two policies are different the training is called off-policy. We consider the special case of the emphatic temporal difference learning algorithm (ETD) in which bootstrapping is complete (λ(s) = 0,∀s) and there is no discounting (γ(s) = 1,∀s). Studying TD and ETD methods with complete bootstrapping is suitable because in this case the differences between them are maximized. As λ approaches 1, the methods behave more similarly up to the point where they become equivalent when λ = 1. By setting λ = 0 and γ = 1, the ETD algorithm can be 30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. ar X iv :1 70 5. 04 18 5v 2 [ cs .A I] 1 2 M ay 2 01 7 completely described by: θt+1 . = θt + αρtFt ( Rt+1 + θ T t φt+1 − θ t φt ) φt, Ft . = ρt−1Ft−1 + 1, with F0 . = 1, ρt . = π(At|St) μ(At|St) , where α > 0 is a step size parameter. F is the followon trace according to which the update at each time step is emphasized or de-emphasized. TD is obtained by removing the F from the first equation. Because of F , ETD is different from TD even in the on-policy case in which ρ is always 1. For a thorough explanation of ETD see (Sutton, Mahmood & White 2016). 2 Stability of On-policy TD with Variable λ: A Counterexample In this section we show that although the initial motivation for developing ETD was that it has good convergence properties under off-policy training (Yu 2015), it is also a different algorithm under on-policy training. To emphasize the difference between the two, we present a simple example for which TD(λ) is not convergent under on-policy training but ETD is. It has long been known that TD(λ) converges with any constant value of λ under on-policy training (Tsitsiklis & Van Roy 1997). Surprisingly, TD(λ) is not assured to converge with varying λ even under on-policy training. Yu has recently presented a counterexample (personal communication) with state dependent λ for which on-policy TD(λ) is not convergent. The example is a simple Markov decision process consisting of two states in which the system simply moves from one state to another in a cycle. The process starts in each of the states with equal probability. Let λ(S1) = 0 and λ(S2) = 1, φ(S1) = (3, 1) and φ(S2) = (1, 1) and γ = 0.95. As shown below, the TD(λ) key matrix for this problem is not positive definite. Moreover, both eigenvalues of the key matrix have negative real parts and thus TD(λ) diverges in this case. S1 S2 Key matrix = ( −0.4862 0.1713 −0.7787 0.0738 ) This is while ETD is convergent under both off-policy and on-policy training with variable λ. This example appears in more detail in the supplementary material. 3 Fixed-policy Mountain Car Testbed For our experimental study, we used a new variation of the mountain car control problem (Sutton & Barto 1998) to form a prediction problem. The original mountain car problem has a 2-dimensional space, position (between -1.2 and 0.6), and velocity (between -0.07 and 0.07) with three actions, full throttle forward, full throttle backward, and 0 throttle. Each episode starts around the bottom of a hill (a uniform random number between -0.4 and -0.6). The reward is -1 on all time steps until the car pasts its goal at the top of the hill, which ends the episode. The task is undiscounted. Our variation of the mountain car problem has a fixed target policy which is to always push towards the direction of the velocity and not to push in any direction when the velocity is 0. We call the new variation of the mountain car problem, the fixed-policy mountain car testbed. The performance measure we used is an estimation of the mean squared value error (MSVE) which reflects the mean squared difference between the true value function and the estimated value function, weighted according to how often each state is visited in the state space following the behavior policy:",
            "output": [
                "A First Empirical Study of Emphatic Temporal Difference Learning"
            ]
        },
        {
            "id": "task1540-077906c4aeda40f8aec357006bc2696f",
            "input": "Most Software Defined Networks (SDN) traffic engineering applications use excessive and frequent global monitoring in order to find the optimal Quality-of-Service (QoS) paths for the current state of the network. In this work, we present the motivations, architecture and initial evaluation of a SDN application called Cognitive Routing Engine (CRE) which is able to find near-optimal paths for a user-specified QoS while using a very small monitoring overhead compared to global monitoring which is required to guarantee that optimal paths are found. Smaller monitoring overheads bring the advantage of smaller response time for the SDN controllers and switches. The initial evaluation of CRE on a SDN representation of the GEANT academic network shows that it is possible to find near-optimal paths with a small optimality gap of 1.65% while using 9.5 times less monitoring.",
            "output": [
                "Towards a Cognitive Routing Engine for Software Defined Networks"
            ]
        },
        {
            "id": "task1540-e087be83c7474c37a896cc0db4459006",
            "input": "We consider the design of online learning algorithms in a general learning setting, with the goal of obtaining computationally efficient no-regret algorithms, when given access to an oracle for the offline optimization version of the problem. We present an algorithm that we call Generalized Follow-thePerturbed-Leader (Generalized FTPL) and provide conditions under which it achieves vanishing regret and is efficiently implementable with an oracle. Our second main contribution is the introduction of a new online adversarial auction-design framework for revenue maximization and an application of our oracle-efficient learning results to the adaptive optimization of auctions. Our learning algorithm is a generalization of the classic FTPL algorithm of Kalai and Vempala [27], playing at every iteration the historically best-performing action after adding some perturbation to the performance of each of its actions. The crux of our design is adding perturbations in a manner that leads to oracle-efficiency. We reduce this to designing a translation matrix, which translates a low dimensional vector with independent noise components into a high dimensional vector of perturbations on the learner’s action space. Our approach generalizes prior work on oracle-efficient online learning [11, 22, 27, 35], ranging from online combinatorial optimization, learning in simultaneous auctions, and contextual learning. Our auction-design framework considers an auctioneer learning an optimal auction rule in an online manner, every day observing an adversarially chosen vector of valuations. The auctioneer’s goal is to achieve revenue that competes with the revenue of the optimal auction in hindsight among those in some target class. We give oracle-efficient learning results for: (1) VCG auctions with bidder-specific reserves in single-parameter settings with matroid constraints, (2) envy-free item pricing in multi-item auctions with unlimited supply, and (3) s-level auctions of Morgenstern and Roughgarden [28] for singleitem settings. The last result implies good regret against the optimal overall auction when valuations are coming from a fast mixing Markov chain, that is independent across bidders. We also extend our results to the case when the learner observes side information on the bidders before running the auction (contextual learning). We present additional extensions to contextual learning and learning with approximate oracles, implemented by FPTAS or Maximal-in-Range algorithms. We provide further applications in online welfare maximization in multi-unit auctions and in no-regret learning in simultaneous item auctions, answering an open question from prior work. ∗Microsoft Research, New York, mdudik@microsoft.com †Computer Science Department, Carnegie Mellon University, nhaghtal@cs.cmu.edu ‡Microsoft Research, New York, haipeng@microsoft.com §Microsoft Research, New York, schapire@microsoft.com ¶Microsoft Research, New England, vasy@microsoft.com ‖Microsoft Research, New York, jenn@microsoft.com ar X iv :1 61 1. 01 68 8v 1 [ cs .L G ] 5 N ov 2 01 6",
            "output": [
                "Oracle-Efficient Learning and Auction Design"
            ]
        },
        {
            "id": "task1540-e0b4cce6e9dc4c75913c75f61f261662",
            "input": "In a controlled experiment of sequence-tosequence approaches for the task of sentence correction, we find that characterbased models are generally more effective than word-based models and models that encode subword information via convolutions, and that modeling the output data as a series of diffs improves effectiveness over standard approaches. Our strongest sequence-to-sequence model improves over our strongest phrase-based statistical machine translation model, with access to the same data, by 6 M2 (0.5 GLEU) points. Additionally, in the data environment of the standard CoNLL-2014 setup, we demonstrate that modeling (and tuning against) diffs yields similar or better M2 scores with simpler models and/or significantly less data than previous sequence-to-sequence approaches.",
            "output": [
                "Adapting Sequence Models for Sentence Correction"
            ]
        },
        {
            "id": "task1540-d9a5612250e0425f80652f7d68803fa3",
            "input": "We report efforts to interpret a Long-Short Term Memory neural network trained to recognize gender and writing instructions on a set of essays from a psychological educational intervention known as a values affirmation. Adjusting the model at test time to output sequential probabilities as each new token is encountered, rather than predicting the class holistically, we query the model with carefully constructed sentences designed to test a theoretically informed hypothesis: male versus female students write in a way that reflects a greater emphasis on independence versus interdependence, respectively. The LSTM model outperforms the baseline, and the model’s predictions to our constructed test sentences suggest modest support for these hypotheses.",
            "output": [
                "Interpreting Neural Networks to Understand Written Justifications in Values-Affirmation Essays"
            ]
        },
        {
            "id": "task1540-b1db843d6b5343b4a6dd52c7dc3fd38e",
            "input": "Discrete Fourier transforms provide a significant speedup in the computation of convolutions in deep learning. In this work, we demonstrate that, beyond its advantages for efficient computation, the spectral domain also provides a powerful representation in which to model and train convolutional neural networks (CNNs). We employ spectral representations to introduce a number of innovations to CNN design. First, we propose spectral pooling, which performs dimensionality reduction by truncating the representation in the frequency domain. This approach preserves considerably more information per parameter than other pooling strategies and enables flexibility in the choice of pooling output dimensionality. This representation also enables a new form of stochastic regularization by randomized modification of resolution. We show that these methods achieve competitive results on classification and approximation tasks, without using any dropout or max-pooling. Finally, we demonstrate the effectiveness of complex-coefficient spectral parameterization of convolutional filters. While this leaves the underlying model unchanged, it results in a representation that greatly facilitates optimization. We observe on a variety of popular CNN configurations that this leads to significantly faster convergence during training.",
            "output": [
                "Spectral Representations for Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-19d9ec37b1bf41b1b9d7a48525d50621",
            "input": "A standard model for Recommender Systems is the Matrix Completion setting: given partially known matrix of ratings given by users (rows) to items (columns), infer the unknown ratings. In the last decades, few attempts where done to handle that objective with Neural Networks, but recently an architecture based on Autoencoders proved to be a promising approach. In current paper, we enhanced that architecture (i) by using a loss function adapted to input data with missing values, and (ii) by incorporating side information. The experiments demonstrate that while side information only slightly improve the test error averaged on all users/items, it has more impact on cold users/items.",
            "output": [
                "Hybrid Recommender System based on Autoencoders"
            ]
        },
        {
            "id": "task1540-bfae07d767ce4f6284ebe5649f79256a",
            "input": "The field of speech recognition is in the midst of a paradigm shift: end-to-end neural networks are challenging the dominance of hidden Markov models as a core technology. Using an attention mechanism in a recurrent encoder-decoder architecture solves the dynamic time alignment problem, allowing joint end-to-end training of the acoustic and language modeling components. In this paper we extend the end-to-end framework to encompass microphone array signal processing for noise suppression and speech enhancement within the acoustic encoding network. This allows the beamforming components to be optimized jointly within the recognition architecture to improve the end-to-end speech recognition objective. Experiments on the noisy speech benchmarks (CHiME-4 and AMI) show that our multichannel end-to-end system outperformed the attention-based baseline with input from a conventional adaptive beamformer.",
            "output": [
                "Multichannel End-to-end Speech Recognition "
            ]
        },
        {
            "id": "task1540-382340f342d14392939a1e8707c9d794",
            "input": "Domain similarity measures can be used<lb>to gauge adaptability and select suitable<lb>data for transfer learning, but existing ap-<lb>proaches define ad hoc measures that are deemed suitable for respective tasks. In-<lb>spired by work on curriculum learning, we<lb>propose to learn data selection measures<lb>using Bayesian Optimization and evaluate<lb>them across models, domains and tasks. Our learned measures outperform existing<lb>domain similarity measures significantly<lb>on three tasks: sentiment analysis, part-<lb>of-speech tagging, and parsing. We show<lb>the importance of complementing similarity with diversity, and that learned mea-<lb>sures are—to some degree—transferable<lb>across models, domains, and even tasks.",
            "output": [
                "Learning to select data for transfer learning with Bayesian Optimization"
            ]
        },
        {
            "id": "task1540-71c00f5bb72048ceb74537b00de41f53",
            "input": "Given a set of conflicting arguments, there can exist multiple plausible opinions about which arguments should be accepted, rejected, or deemed undecided. We study the problem of how multiple such judgments can be aggregated. We define the problem by adapting various classical social-choice-theoretic properties for the argumentation domain. We show that while argument-wise plurality voting satisfies many properties, it fails to guarantee the collective rationality of the outcome. We then present more general results, proving multiple impossibility results on the existence of any good aggregation operator. After characterising the sufficient and necessary conditions for satisfying collective rationality, we study whether restricting the domain of argument-wise plurality voting to classical semantics allows us to escape the impossibility result. We close by mentioning a couple of graph-theoretical restrictions under which the argument-wise plurality rule does produce collectively rational outcomes. In addition to identifying fundamental barriers to collective argument evaluation, our results contribute to research at the intersection of the argumentation and computational social choice fields. 1 ar X iv :1 40 5. 65 09 v3 [ cs .A I] 1 9 Ju l 2 01 5",
            "output": [
                "Judgment Aggregation in Multi-Agent Argumentation"
            ]
        },
        {
            "id": "task1540-7e9dc36b0ad0430580a5b3a7aa649f31",
            "input": "Authorship attribution refers to the task of automatically determining the author based on a given sample of text. It is a problem with a long history and has a wide range of application. Building author profiles using language models is one of the most successful methods to automate this task. New language modeling methods based on neural networks alleviate the curse of dimensionality and usually outperform conventional N-gram methods. However, there have not been much research applying them to authorship attribution. In this paper, we present a novel setup of a Neural Network Language Model (NNLM) and apply it to a database of text samples from different authors. We investigate how the NNLM performs on a task with moderate author set size and relatively limited training and test data, and how the topics of the text samples affect the accuracy. NNLM achieves nearly 2.5% reduction in perplexity, a measurement of fitness of a trained language model to the test data. Given 5 random test sentences, it also increases the author classification accuracy by 3.43% on average, compared with the N-gram methods using SRILM tools. An open source implementation of our methodology is freely available at https://github.com/zge/authorship-attribution/.",
            "output": [
                "Domain Specific Author Attribution Based on Feedforward Neural Network Language Models"
            ]
        },
        {
            "id": "task1540-4e745c885f65437b8fe31e1bc2705ad7",
            "input": "The rough-set theory proposed by Pawlak, has been widely used in dealing with data classification problems. The original rough-set model is, however, quite sensitive to noisy data. Tzung thus proposed deals with the problem of producing a set of fuzzy certain and fuzzy possible rules from quantitative data with a predefined tolerance degree of uncertainty and misclassification. This model allowed , which combines the variable precision rough-set model and the fuzzy set theory, is thus proposed to solve this problem. This paper thus deals with the problem of producing a set of fuzzy certain and fuzzy possible rules from incomplete quantitative data with a predefined tolerance degree of uncertainty and misclassification. A new method, incomplete quantitative data for rough-set model and the fuzzy set theory, is thus proposed to solve this problem. It first transforms each quantitative value into a fuzzy set of linguistic terms using membership functions and then finding incomplete quantitative data with lower and the fuzzy upper approximations. It second calculates the fuzzy β-lower and the fuzzy β-upper approximations. The certain and possible rules are then generated based on these fuzzy approximations. These rules can then be used to classify unknown objects. Keywords-component: Fuzzy set; Rough set; Data mining; Certain rule; Possible rule; Quantitative value; incomplete data",
            "output": [
                "Mining Fuzzy β-Certain and β-Possible rules from incomplete quantitative data by rough sets"
            ]
        },
        {
            "id": "task1540-508c10cfe9444a88bb2e8fe643820ebb",
            "input": "Rapid progress has been made towards question answering (QA) systems that can extract answers from text. Existing neural approaches make use of expensive bidirectional attention mechanisms or score all possible answer spans, limiting scalability. We propose instead to cast extractive QA as an iterative search problem: select the answer’s sentence, start word, and end word. This representation reduces the space of each search step and allows computation to be conditionally allocated to promising search paths. We show that globally normalizing the decision process and back-propagating through beam search makes this representation viable and learning efficient. We empirically demonstrate the benefits of this approach using our model, Globally Normalized Reader (GNR), which achieves the second highest single model performance on the Stanford Question Answering Dataset (68.4 EM, 76.21 F1 dev) and is 24.7x faster than bi-attention-flow. We also introduce a data-augmentation method to produce semantically valid examples by aligning named entities to a knowledge base and swapping them with new entities of the same type. This method improves the performance of all models considered in this work and is of independent interest for a variety of NLP tasks.",
            "output": [
                "Globally Normalized Reader"
            ]
        },
        {
            "id": "task1540-bb298ebd6a6648ce842f403a78db2b8d",
            "input": "This paper is motivated by the automation of neuropsychological tests involving discourse analysis in the retellings of narratives by patients with potential cognitive impairment. In this scenario the task of sentence boundary detection in speech transcripts is important as discourse analysis involves the application of Natural Language Processing tools, such as taggers and parsers, which depend on the sentence as a processing unit. Our aim in this paper is to verify which embedding induction method works best for the sentence boundary detection task, specifically whether it be those which were proposed to capture semantic, syntactic or morphological similarities.",
            "output": [
                "Evaluating Word Embeddings for Sentence Boundary Detection in Speech Transcripts"
            ]
        },
        {
            "id": "task1540-a64d7090954a4120b9b64e4bf792e0c3",
            "input": "The belief bias effect is a phenomenon which occurs when we think that we judge an argument based on our reasoning, but are actually influenced by our beliefs and prior knowledge. Evans, Barston and Pollard carried out a psychological syllogistic reasoning task to prove this effect. Participants were asked whether they would accept or reject a given syllogism. We discuss one specific case which is commonly assumed to be believable but which is actually not logically valid. By introducing abnormalities, abduction and background knowledge, we adequately model this case under the weak completion semantics. Our formalization reveals new questions about possible extensions in abductive reasoning. For instance, observations and their explanations might include some relevant prior abductive contextual information concerning some side-effect or leading to a contestable or refutable side-effect. A weaker notion indicates the support of some relevant consequences by a prior abductive context. Yet another definition describes jointly supported relevant consequences, which captures the idea of two observations containing mutually supportive side-effects. Though motivated with and exemplified by the running psychology application, the various new general abductive context definitions are introduced here and given a declarative semantics for the first time, and have a much wider scope of application. Inspection points, a concept introduced by Pereira and Pinto, allows us to express these definitions syntactically and intertwine them into an operational semantics.",
            "output": [
                "Contextual Abductive Reasoning with Side-Effects"
            ]
        },
        {
            "id": "task1540-af3c30997c124889a31e913e92d1136c",
            "input": "We design a new nonparametric method that allows one to estimate the matrix of integrated kernels of a multivariate Hawkes process. This matrix not only encodes the mutual influences of each node of the process, but also disentangles the causality relationships between them. Our approach is the first that leads to an estimation of this matrix without any parametric modeling and estimation of the kernels themselves. As a consequence, it can give an estimation of causality relationships between nodes (or users), based on their activity timestamps (on a social network for instance), without knowing or estimating the shape of the activities lifetime. For that purpose, we introduce a moment matching method that fits the second-order and the third-order integrated cumulants of the process. A theoretical analysis allows us to prove that this new estimation technique is consistent. Moreover, we show, on numerical experiments, that our approach is indeed very robust with respect to the shape of the kernels and gives appealing results on the MemeTracker database and on financial order book data.",
            "output": [
                "Uncovering Causality from Multivariate Hawkes Integrated Cumulants"
            ]
        },
        {
            "id": "task1540-468664ae1cc54dbfa8236e7401b11de9",
            "input": "Recent research has shown that one can train a neural network with binary weights and activations at train time by augmenting the weights with a high-precision continuous latent variable that accumulates small changes from stochastic gradient descent. However, there is a dearth of theoretical analysis to explain why we can effectively capture the features in our data with binary weights and activations. Our main result is that the neural networks with binary weights and activations trained using the method of Courbariaux, Hubara et al. (2016) work because of the highdimensional geometry of binary vectors. In particular, the ideal continuous vectors that extract out features in the intermediate representations of these BNNs are wellapproximated by binary vectors in the sense that dot products are approximately preserved. Compared to previous research that demonstrated the viability of such BNNs, our work explains why these BNNs work in terms of the HD geometry. Our theory serves as a foundation for understanding not only BNNs but a variety of methods that seek to compress traditional neural networks. Furthermore, a better understanding of multilayer binary neural networks serves as a starting point for generalizing BNNs to other neural network architectures such as recurrent neural networks.",
            "output": [
                "The High-Dimensional Geometry of Binary Neural Networks"
            ]
        },
        {
            "id": "task1540-c967db7e3a6646918d3229ddcdd80f1d",
            "input": "Metric learning has been shown to be highly effective to improve the performance of nearest neighbor classification. In this paper, we address the problem of metric learning for symmetric positive definite (SPD) matrices such as covariance matrices, which arise in many real-world applications. Naively using standard Mahalanobis metric learning methods under the Euclidean geometry for SPD matrices is not appropriate, because the difference of SPD matrices can be a non-SPD matrix and thus the obtained solution can be uninterpretable. To cope with this problem, we propose to use a properly parameterized LogEuclidean distance and optimize the metric with respect to kernel-target alignment, which is a supervised criterion for kernel learning. Then the resulting non-trivial optimization problem is solved by utilizing the Riemannian geometry. Finally, we experimentally demonstrate the usefulness of our LogEuclidean metric learning algorithm on real-world classification tasks for EEG signals and texture patches.",
            "output": [
                "Supervised LogEuclidean Metric Learning for Symmetric Positive Definite Matrices"
            ]
        },
        {
            "id": "task1540-4405b66a448249269a3ff9213587fc7f",
            "input": "Stochastic neurons can be useful for a number of reasons in deep learning models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such stochastic neurons, i.e., can we “back-propagate” through these stochastic neurons? We examine this question, existing approaches, and present two novel families of solutions, applicable in different settings. In particular, it is demonstrated that a simple biologically plausible formula gives rise to an an unbiased (but noisy) estimator of the gradient with respect to a binary stochastic neuron firing probability. Unlike other estimators which view the noise as a small perturbation in order to estimate gradients by finite differences, this estimator is unbiased even without assuming that the stochastic perturbation is small. This estimator is also interesting because it can be applied in very general settings which do not allow gradient back-propagation, including the estimation of the gradient with respect to future rewards, as required in reinforcement learning setups. We also propose an approach to approximating this unbiased but high-variance estimator by learning to predict it using a biased estimator. The second approach we propose assumes that an estimator of the gradient can be back-propagated and it provides an unbiased estimator of the gradient, but can only work with non-linearities unlike the hard threshold, but like the rectifier, that are not flat for all of their range. This is similar to traditional sigmoidal units but has the advantage that for many inputs, a hard decision (e.g., a 0 output) can be produced, which would be convenient for conditional computation and achieving sparse representations and sparse gradients.",
            "output": [
                "Estimating or Propagating Gradients Through Stochastic Neurons"
            ]
        },
        {
            "id": "task1540-d66597a42c8f4907b7be551a3a5b567a",
            "input": "In this paper, we extend a symbolic association framework to being able to handle missing elements in multimodal sequences. The general scope of the work is the symbolic associations of object-word mappings as it happens in language development on infants. In other words, two different representations of the same abstract concepts can be associated in both directions. This scenario has been long interested in Artificial Intelligence, Psychology, and Neuroscience. In this work, we extend a recent approach for multimodal sequences (visual and audio) to also cope with missing elements in one or both modalities. Our approach uses two parallel Long Short-Term Memories (LSTMs) with a learning rule based on EM-algorithm. It aligns both LSTM outputs via Dynamic Time Warping (DTW). We propose to include an extra step for the combination with max operation for exploiting the common elements between both sequences. The intuition behind is that the combination acts as a condition selector for choosing the best representation from both LSTMs. We evaluated the proposed extension in the following scenarios: missing elements in one modality (visual or audio) and missing elements in both modalities (visual and audio). The performance of our extension reaches better results than the original model and similar results to individual LSTM trained in each modality.",
            "output": [
                "Symbol Grounding Association in Multimodal Sequences with Missing Elements"
            ]
        },
        {
            "id": "task1540-c28b2c32b81c47bb86b6fa4ce4da16b6",
            "input": "This paper proposes DRL-Sense—a multisense word representation learning model, to address the word sense ambiguity issue, where a sense selection module and a sense representation module are jointly learned in a reinforcement learning fashion. A novel reward passing procedure is proposed to enable joint training on the selection and representation modules. The modular design implements pure senselevel representation learning with linear time sense selection (decoding). We further develop a non-parametric learning algorithm and a sense exploration mechanism for better flexibility and robustness. The experiments on benchmark data show that the proposed approach achieves the state-of-the-art performance on contextual word similarities and comparable performance with Google’s word2vec while using much less training data.",
            "output": [
                "DRL-Sense: Deep Reinforcement Learning for Multi-Sense Word Representations"
            ]
        },
        {
            "id": "task1540-4682ca7ca7794e8c91530512b8b0933f",
            "input": "We propose a simple, elegant solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no change in the model architecture from our base system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. The rest of the model, which includes encoder, decoder and attention, remains unchanged and is shared across all languages. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT using a single model without any increase in parameters, which is significantly simpler than previous proposals for Multilingual NMT. Our method often improves the translation quality of all involved language pairs, even while keeping the total number of model parameters constant. On the WMT’14 benchmarks, a single multilingual model achieves comparable performance for English→French and surpasses state-of-the-art results for English→German. Similarly, a single multilingual model surpasses state-of-the-art results for French→English and German→English on WMT’14 and WMT’15 benchmarks respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. In addition to improving the translation quality of language pairs that the model was trained with, our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and show some interesting examples when mixing languages.",
            "output": [
                "Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation"
            ]
        },
        {
            "id": "task1540-68d9345467a548b7ba2f79e8b20815f1",
            "input": "Recent progress on many imaging and vision tasks has been driven by the use of deep feed-forward neural networks, which are trained by propagating gradients of a loss defined on the final output, back through the network up to the first layer that operates directly on the image. We propose back-propagating one step further—to learn camera sensor designs jointly with networks that carry out inference on the images they capture. In this paper, we specifically consider the design and inference problems in a typical color camera—where the sensor is able to measure only one color channel at each pixel location, and computational inference is required to reconstruct a full color image. We learn the camera sensor’s color multiplexing pattern by encoding it as layer whose learnable weights determine which color channel, from among a fixed set, will be measured at each location. These weights are jointly trained with those of a reconstruction network that operates on the corresponding sensor measurements to produce a full color image. Our network achieves significant improvements in accuracy over the traditional Bayer pattern used in most color cameras. It automatically learns to employ a sparse color measurement approach similar to that of a recent design, and moreover, improves upon that design by learning an optimal layout for these measurements.",
            "output": [
                "Learning Sensor Multiplexing Design through Back-propagation"
            ]
        },
        {
            "id": "task1540-299c248f533042a1b62b1df78a56207d",
            "input": "Natural language understanding and dialogue policy learning are both essential in conversational systems that predict the next system actions in response to a current user utterance. Conventional approaches aggregate separate models of natural language understanding (NLU) and system action prediction (SAP) as a pipeline that is sensitive to noisy outputs of error-prone NLU. To address the issues, we propose an end-to-end deep recurrent neural network with limited contextual dialogue memory by jointly training NLU and SAP on DSTC4 multi-domain human-human dialogues. Experiments show that our proposed model significantly outperforms the state-of-the-art pipeline models for both NLU and SAP, which indicates that our joint model is capable of mitigating the affects of noisy NLU outputs, and NLU model can be refined by error flows backpropagating from the extra supervised signals of system actions.",
            "output": [
                "END-TO-END JOINT LEARNING OF NATURAL LANGUAGE UNDERSTANDING AND DIALOGUE MANAGER"
            ]
        },
        {
            "id": "task1540-fb2ec5c938a840f891408fcec9f8a3de",
            "input": "This paper takes an information visualization perspective to visual representations in the general SOM paradigm. This involves viewing SOM-based visualizations through the eyes of Bertin's and Tufte's theories on data graphics. The regular grid shape of the Self-Organizing Map (SOM), while being a virtue for linking visualizations to it, restricts representation of cluster structures. From the viewpoint of information visualization, this paper provides a general, yet simple, solution to projection-based coloring of the SOM that reveals structures. First, the proposed color space is easy to construct and customize to the purpose of use, while aiming at being perceptually correct and informative through two separable dimensions. Second, the coloring method is not dependent on any specific method of projection, but is rather modular to fit any objective function suitable for the task at hand. The cluster coloring is illustrated on two datasets: the iris data, and welfare and poverty indicators. KeywordsSelf-Organizing Maps (SOMs); cluster coloring;",
            "output": [
                "Cluster coloring of the Self-Organizing Map: An information visualization perspective"
            ]
        },
        {
            "id": "task1540-49fc4532d29347d9b97d960f8be1a0dc",
            "input": "The goal of this paper is to investigate the connection between the performance gain that can be obtained by selftraining and the similarity between the corpora used in this approach. Self-training is a semi-supervised technique designed to increase the performance of machine learning algorithms by automatically classifying instances of a task and adding these as additional training material to the same classifier. In the context of language processing tasks, this training material is mostly an (annotated) corpus. Unfortunately self-training does not always lead to a performance increase and whether it will is largely unpredictable. We show that the similarity between corpora can be used to identify those setups for which self-training can be beneficial. We consider this research as a step in the process of developing a classifier that is able to adapt itself to each new test corpus that it is presented with.",
            "output": [
                "Predicting the Effectiveness of Self-Training: Application to Sentiment Classification"
            ]
        },
        {
            "id": "task1540-22c4d7c9162c4bc6985201d011cdda70",
            "input": "In this era of digitization, knowing the user’s sociolect aspects have become essential features to build the user specific recommendation systems. These sociolect aspects could be found by mining the user’s language sharing in the form of text in social media and reviews. This paper describes about the experiment that was performed in PAN Author Profiling 2017 shared task. The objective of the task is to find the sociolect aspects of the users from their tweets. The sociolect aspects considered in this experiment are user’s gender and native language information. Here user’s tweets written in a different language from their native language are represented as Document Term Matrix with document frequency as the constraint. Further classification is done using the Support Vector Machine by taking gender and native language as target classes. This experiment attains the average accuracy of 73.42% in gender prediction and 76.26% in the native language identification task.",
            "output": [
                "Vector Space Model as Cognitive Space for Text Classification"
            ]
        },
        {
            "id": "task1540-aa07353f6794459f84204d821b7bd473",
            "input": "Methods based on representation learning currently hold the state-of-the-art in many natural language processing and knowledge base inference tasks. Yet, a major challenge is how to efficiently incorporate commonsense knowledge into such models. A recent approach regularizes relation and entity representations by propositionalization of first-order logic rules. However, propositionalization does not scale beyond domains with only few entities and rules. In this paper we present a highly efficient method for incorporating implication rules into distributed representations for automated knowledge base construction. We map entity-tuple embeddings into an approximately Boolean space and encourage a partial ordering over relation embeddings based on implication rules mined from WordNet. Surprisingly, we find that the strong restriction of the entity-tuple embedding space does not hurt the expressiveness of the model and even acts as a regularizer that improves generalization. By incorporating few commonsense rules, we achieve an increase of 2 percentage points mean average precision over a matrix factorization baseline, while observing a negligible increase in runtime.",
            "output": [
                "Lifted Rule Injection for Relation Embeddings"
            ]
        },
        {
            "id": "task1540-a37dd55286a34f5aa8ae4890a95c2d3d",
            "input": "In many computer vision tasks, the relevant information to solve the problem at hand is mixed with irrelevant, distracting information. This has motivated researchers to design attentional models that can dynamically focus on parts of images or videos that are salient, e.g., by down-weighting irrelevant pixels. In this work, we propose a spatiotemporal attentional model that learns where to look in a video directly from human fixation data. We model visual attention with a mixture of Gaussians at each frame. This distribution is used to express the probability of saliency for each pixel. Time consistency in videos is modeled hierarchically by: 1) deep 3D convolutional features to represent spatial and short-term time relations at clip level and 2) a long short-term memory network on top that aggregates the clip-level representation of sequential clips and therefore expands the temporal domain from few frames to seconds. The parameters of the proposed model are optimized via maximum likelihood estimation using human fixations as training data, without knowledge of the action in each video. Our experiments on Hollywood2 show state-of-the-art performance on saliency prediction for video. We also show that our attentional model trained on Hollywood2 generalizes well to UCF101 and it can be leveraged to improve action classification accuracy on both datasets.",
            "output": [
                "RECURRENT MIXTURE DENSITY NETWORK FOR SPATIOTEMPORAL VISUAL ATTENTION"
            ]
        },
        {
            "id": "task1540-f73d845584ba4fd5a34d553bcf728cd8",
            "input": "In this paper we present a new computational technique to detect and analyze statistically significant geographic variation in language. While previous approaches have primarily focused on lexical variation between regions, our method identifies words that demonstrate semantic and syntactic variation as well. Our meta-analysis approach captures statistical properties of word usage across geographical regions and uses statistical methods to identify significant changes specific to regions. We extend recently developed techniques for neural language models to learn word representations which capture differing semantics across geographical regions. In order to quantify this variation and ensure robust detection of true regional differences, we formulate a null model to determine whether observed changes are statistically significant. Our method is the first such approach to explicitly account for random variation due to chance while detecting regional variation in word meaning. To validate our model, we study and analyze two different massive online data sets: millions of tweets from Twitter spanning not only four different countries but also fifty states, as well as millions of phrases contained in the Google Book Ngrams. Our analysis reveals interesting facets of language change at multiple scales of geographic resolution – from neighboring states to distant continents. Finally, using our model, we propose a measure of semantic distance between languages. Our analysis of British and American English over a period of 100 years reveals that semantic variation between these dialects is shrinking.",
            "output": [
                "Freshman or Fresher? Quantifying the Geographic Variation of Language in Online Social Media"
            ]
        },
        {
            "id": "task1540-cd776a5aa8e940298f4cf756fed36b93",
            "input": "<lb>Nonlinear component analysis such as kernel Principle Component Analysis (KPCA) and kernel<lb>Canonical Correlation Analysis (KCCA) are widely used in machine learning, statistics and data analysis,<lb>but they can not scale up to big datasets. Recent attempts have employed random feature approximations<lb>to convert the problem to the primal form for linear computational complexity. However, to obtain high<lb>quality solutions, the number of random features should be the same order of magnitude as the number<lb>of data points, making such approach not directly applicable to the regime with millions of data points.<lb>We propose a simple, computationally efficient, and memory friendly algorithm based on the “doubly<lb>stochastic gradients” to scale up a range of kernel nonlinear component analysis, such as kernel PCA, CCA<lb>and SVD. Despite the non-convex nature of these problems, our method enjoys theoretical guarantees<lb>that it converges at the rate Õ(1/t) to the global optimum, even for the top k eigen subspace. Unlike<lb>many alternatives, our algorithm does not require explicit orthogonalization, which is infeasible on big<lb>datasets. We demonstrate the effectiveness and scalability of our algorithm on large scale synthetic and<lb>real world datasets.",
            "output": [
                "Scale Up Nonlinear Component Analysis with Doubly Stochastic Gradients"
            ]
        },
        {
            "id": "task1540-174a9f72e96342019838e59832fe4bc0",
            "input": "We study the power index voting game design problem for weighted voting games: the problem of finding a weighted voting game in which the power of the players is as close as possible to a certain target distribution. Our goal is to find algorithms that solve this problem exactly. Thereto, we consider various subclasses of simple games, and their associated representation methods. We survey algorithms and impossibility results for the synthesis problem, i.e., converting a representation of a simple game into another representation. We contribute to the synthesis problem by showing that it is impossible to compute in polynomial time the list of ceiling coalitions (also known as shift-maximal losing coalitions) of a game from its list of roof coalitions (also known as shift-minimal winning coalitions), and vice versa. Then, we proceed by studying the problem of enumerating the set of weighted voting games. We present first a naive algorithm for this, running in doubly exponential time. Using our knowledge of the synthesis problem, we then improve on this naive algorithm, and we obtain an enumeration algorithm that runs in quadratic exponential time (that is, O(2 2 · p(n)) for a polynomial p). Moreover, we show that this algorithm runs in output-polynomial time, making it the best possible enumeration algorithm up to a polynomial factor. Finally, we propose an exact anytime algorithm for the power index voting game design problem that runs in exponential time. This algorithm is straightforward and general: it computes the error for each game enumerated, and outputs the game that minimizes this error. By the genericity of our approach, our algorithm can be used to find a weighted voting game that optimizes any exponential time computable function. We implement our algorithm for the case of the normalized Banzhaf in∗Algorithms, Combinatorics and Optimization; Centrum Wiskunde & Informatica; The Netherlands; Email: keijzer@cwi.nl. †Algorithmics; Delft University of Technology; The Netherlands; Email: T.B.Klos@tudelft.nl. ‡Department of Econometrics; Erasmus University Rotterdam; The Netherlands; Email:",
            "output": [
                "Solving Weighted Voting Game Design Problems Optimally: Representations, Synthesis, and Enumeration"
            ]
        },
        {
            "id": "task1540-7c88d994c4d7466ab90469596d73f5fc",
            "input": "In visual recognition tasks, supervised learning shows excellent performance. On the other hand, unsupervised learning exploits cheap unlabeled data and can help to solve the same tasks more efficiently. We show that the recursive autoconvolutional operator, adopted from physics, boosts existing unsupervised methods to learn more powerful filters. We use a well established multilayer convolutional network and train filters layer-wise. To build a stronger classifier, we design a very light committee of SVM models. The total number of trainable parameters is also greatly reduced by using shared filters in higher layers. We evaluate our networks on the MNIST, CIFAR-10 and STL-10 benchmarks and report several state of the art results among other unsupervised methods.",
            "output": [
                "Autoconvolution for Unsupervised Feature Learning"
            ]
        },
        {
            "id": "task1540-a85a764b9674483696779a58e3476507",
            "input": "The ubiquity of metaphor in our everyday communication makes it an important problem for natural language understanding. Yet, the majority of metaphor processing systems to date rely on handengineered features and there is still no consensus in the field as to which features are optimal for this task. In this paper, we present the first deep learning architecture designed to capture metaphorical composition. Our results demonstrate that it outperforms the existing approaches in the metaphor identification task.",
            "output": [
                "Grasping the Finer Point: A Supervised Similarity Network for Metaphor Detection"
            ]
        },
        {
            "id": "task1540-286c758f81604be4a35e7fc1dde62ab3",
            "input": "The convergence of Stochastic Gradient Descent (SGD) using convex loss functions has been widely studied. However, vanilla SGD methods using convex losses cannot perform well with noisy labels, which adversely affect the update of the primal variable in SGD methods. Unfortunately, noisy labels are ubiquitous in real world applications such as crowdsourcing. To handle noisy labels, in this paper, we present a family of robust losses for SGD methods. By employing our robust losses, SGD methods successfully reduce negative effects caused by noisy labels on each update of the primal variable. We not only reveal that the convergence rate is O(1/T ) for SGD methods using robust losses, but also provide the robustness analysis on two representative robust losses. Comprehensive experimental results on six real-world datasets show that SGD methods using robust losses are obviously more robust than other baseline methods in most situations with fast convergence.",
            "output": [
                "On the Convergence of A Family of Robust Losses for Stochastic Gradient Descent"
            ]
        },
        {
            "id": "task1540-4d6bf42ce42d403391f3489034362461",
            "input": "In this paper we argue for the fundamental importance of the value distribution: the distribution of the random return received by a reinforcement learning agent. This is in contrast to the common approach to reinforcement learning which models the expectation of this return, or value. Although there is an established body of literature studying the value distribution, thus far it has always been used for a specific purpose such as implementing risk-aware behaviour. We begin with theoretical results in both the policy evaluation and control settings, exposing a significant distributional instability in the latter. We then use the distributional perspective to design a new algorithm which applies Bellman’s equation to the learning of approximate value distributions. We evaluate our algorithm using the suite of games from the Arcade Learning Environment. We obtain both state-of-the-art results and anecdotal evidence demonstrating the importance of the value distribution in approximate reinforcement learning. Finally, we combine theoretical and empirical evidence to highlight the ways in which the value distribution impacts learning in the approximate setting.",
            "output": [
                "A Distributional Perspective on Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-762474123cad43d4bee1ad6ec671291f",
            "input": "We propose a new, nonparametric approach to learning and representing transition dynamics in Markov decision processes (MDPs), which can be combined easily with dynamic programming methods for policy optimisation and value estimation. This approach makes use of a recently developed representation of conditional distributions as embeddings in a reproducing kernel Hilbert space (RKHS). Such representations bypass the need for estimating transition probabilities or densities, and apply to any domain on which kernels can be defined. This avoids the need to calculate intractable integrals, since expectations are represented as RKHS inner products whose computation has linear complexity in the number of points used to represent the embedding. We provide guarantees for the proposed applications in MDPs: in the context of a value iteration algorithm, we prove convergence to either the optimal policy, or to the closest projection of the optimal policy in our model class (an RKHS), under reasonable assumptions. In experiments, we investigate a learning task in a typical classical control setting (the under-actuated pendulum), and on a navigation problem where only images from a sensor are observed. For policy optimisation we compare with leastsquares policy iteration where a Gaussian process is used for value function estimation. For value estimation we also compare to the NPDP method. Our approach achieves better performance in all experiments. Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).",
            "output": [
                "Modelling transition dynamics in MDPs with RKHS embeddings"
            ]
        },
        {
            "id": "task1540-e3b278301ee94b4d91ff705ad8fd0d61",
            "input": "In business analytics, measure values, such as sales numbers or volumes of cargo transported, are often summed along values of one or more corresponding categories, such as time or shipping container. However, not every measure should be added by default (e.g., one might more typically want a mean over the heights of a set of people); similarly, some measures should only be summed within certain constraints (e.g., population measures need not be summed over years). In systems such as Watson Analytics, the exact additive behaviour of a measure is often determined by a human expert. In this work, we propose a small set of features for this issue. We use these features in a case-based reasoning approach, where the system suggests an aggregation behaviour, with 86% accuracy in our collected dataset.",
            "output": [
                "Learning measures of semi-additive behaviour"
            ]
        },
        {
            "id": "task1540-8c91735f4d0141638e36314bbb5c72f2",
            "input": "This paper describes the realization of the Ontology Web Search Engine. The Ontology Web Search Engine is realizable as independent project and as a part of other projects. The main purpose of this paper is to present the Ontology Web Search Engine realization details as the part of the Semantic Web Expert System and to present the results of the Ontology Web Search Engine functioning. It is expected that the Semantic Web Expert System will be able to process ontologies from the Web, generate rules from these ontologies and develop its knowledge base.",
            "output": [
                "REALIZATION OF ONTOLOGY WEB SEARCH ENGINE"
            ]
        },
        {
            "id": "task1540-22d4d255b34347339e737a8ba817f4a8",
            "input": "Binary embedding of high-dimensional data requires long codes to preserve the discriminative power of the input space. Traditional binary coding methods often suffer from very high computation and storage costs in such a scenario. To address this problem, we propose Circulant Binary Embedding (CBE) which generates binary codes by projecting the data with a circulant matrix. The circulant structure enables the use of Fast Fourier Transformation to speed up the computation. Compared to methods that use unstructured matrices, the proposed method improves the time complexity from O(d2) to O(d log d), and the space complexity from O(d2) to O(d) where d is the input dimensionality. We also propose a novel time-frequency alternating optimization to learn data-dependent circulant projections, which alternatively minimizes the objective in original and Fourier domains. We show by extensive experiments that the proposed approach gives much better performance than the state-of-the-art approaches for fixed time, and provides much faster computation with no performance degradation for fixed number of bits.",
            "output": [
                "Circulant Binary Embedding"
            ]
        },
        {
            "id": "task1540-dd866619ea6a4c34a4e05086bf4d984e",
            "input": "We present two novel and contrasting Recurrent Neural Network (RNN) based architectures for extractive summarization of documents. The Classifier based architecture sequentially accepts or rejects each sentence in the original document order for its membership in the final summary. The Selector architecture, on the other hand, is free to pick one sentence at a time in any arbitrary order to piece together the summary. Our models under both architectures jointly capture the notions of salience and redundancy of sentences. In addition, these models have the advantage of being very interpretable, since they allow visualization of their predictions broken up by abstract features such as information content, salience and redundancy. We show that our models reach or outperform state-of-the-art supervised models on two different corpora. We also recommend the conditions under which one architecture is superior to the other based on experimental evidence.",
            "output": [
                "EXTRACTIVE DOCUMENT SUMMARIZATION"
            ]
        },
        {
            "id": "task1540-44603acbedd644a4835d4bd956b27fef",
            "input": "We propose new methods to speed up convergence of the Alternating Direction Method of Multipliers (ADMM), a common optimization tool in the context of large scale and distributed learning. The proposed method accelerates the speed of convergence by automatically deciding the constraint penalty needed for parameter consensus in each iteration. In addition, we also propose an extension of the method that adaptively determines the maximum number of iterations to update the penalty. We show that this approach effectively leads to an adaptive, dynamic network topology underlying the distributed optimization. The utility of the new penalty update schemes is demonstrated on both synthetic and real data, including a computer vision application of distributed structure from motion.",
            "output": [
                "Fast ADMM Algorithm for Distributed Optimization with Adaptive Penalty"
            ]
        },
        {
            "id": "task1540-586d7f5a3cdb43d38ef42fb67a5153a3",
            "input": "A key problem of robotic environmental sensing and moni-<lb>toring is that of active sensing: How can a team of robots<lb>plan the most informative observation paths to minimize<lb>the uncertainty in modeling and predicting an environmen-<lb>tal phenomenon? This paper presents two principled ap-<lb>proaches to efficient information-theoretic path planning based<lb>on entropy and mutual information criteria for in situ ac-<lb>tive sensing of an important broad class of widely-occurring<lb>environmental phenomena called anisotropic fields. Our pro-<lb>posed algorithms are novel in addressing a trade-off between<lb>active sensing performance and time efficiency. An impor-<lb>tant practical consequence is that our algorithms can exploit<lb>the spatial correlation structure of Gaussian process-based<lb>anisotropic fields to improve time efficiency while preserv-<lb>ing near-optimal active sensing performance. We analyze<lb>the time complexity of our algorithms and prove analyti-<lb>cally that they scale better than state-of-the-art algorithms<lb>with increasing planning horizon length. We provide the-<lb>oretical guarantees on the active sensing performance of<lb>our algorithms for a class of exploration tasks called tran-<lb>sect sampling, which, in particular, can be improved with<lb>longer planning time and/or lower spatial correlation along<lb>the transect. Empirical evaluation on real-world anisotropic<lb>field data shows that our algorithms can perform better or<lb>at least as well as the state-of-the-art algorithms while of-<lb>ten incurring a few orders of magnitude less computational<lb>time, even when the field conditions are less favorable.",
            "output": [
                "Multi-Robot Informative Path Planning for Active Sensing of Environmental Phenomena: A Tale of Two Algorithms"
            ]
        },
        {
            "id": "task1540-4170174e784049568b34e3b5b0852c53",
            "input": "The similarity between trajectory patterns in clustering has played an important role in discovering movement behaviour of different groups of mobile objects. Several approaches have been proposed to measure the similarity between sequences in trajectory data. Most of these measures are based on Euclidean space or on spatial network and some of them have been concerned with temporal aspect or ordering types. However, they are not appropriate to characteristics of spatiotemporal mobility patterns in wireless networks. In this paper, we propose a new similarity measure for mobility patterns in cellular space of wireless network. The framework for constructing our measure is composed of two phases as follows. First, we present formal definitions to capture mathematically two spatial and temporal similarity measures for mobility patterns. And then, we define the total similarity measure by means of a weighted combination of these similarities. The truth of the partial and total similarity measures are proved in mathematics. Furthermore, instead of the time interval or ordering, our work makes use of the timestamp at which two mobility patterns share the same cell. A case study is also described to give a comparison of the combination measure with other ones.",
            "output": [
                "A WEIGHTED COMBINATION SIMILARITY MEASURE FOR MOBILITY PATTERNS IN WIRELESS NETWORKS"
            ]
        },
        {
            "id": "task1540-648ec5dc46f24e40877c18df0439b50e",
            "input": "CMA-ES [7, 8] is the state-of-the-art evolutionary optimization method, at least in the area of continuous black-box optimization. Basically, it consists in generating new search points by sampling from a multidimensional normal distribtion, the mean and variance of which are updated from generation to generation. In particular, the population x (g+1) 1 , . . . , x (g+1) λ ∈ R d of the g + 1-st generation, g ≥ 1, follows the normal distribution with mean m ∈ R and variance (σ)C ∈ R resulting from the update in the g-th generation,",
            "output": [
                "Two Gaussian Approaches to Black-Box Optomization"
            ]
        },
        {
            "id": "task1540-fc0f3072f3584ca2a1e75040cb6ca50b",
            "input": "In recent years, total variation (TV) and Euler’s elastica (EE) have been successfully applied to image processing tasks such as denoising and inpainting. This paper investigates how to extend TV and EE to the supervised learning settings on high dimensional data. The supervised learning problem can be formulated as an energy functional minimization under Tikhonov regularization scheme, where the energy is composed of a squared loss and a total variation smoothing (or Euler’s elastica smoothing). Its solution via variational principles leads to an Euler-Lagrange PDE. However, the PDE is always high-dimensional and cannot be directly solved by common methods. Instead, radial basis functions are utilized to approximate the target function, reducing the problem to finding the linear coefficients of basis functions. We apply the proposed methods to supervised learning tasks (including binary classification, multi-class classification, and regression) on benchmark data sets. Extensive experiments have demonstrated promising results of the proposed methods.",
            "output": [
                "Total Variation and Euler’s Elastica for Supervised Learning"
            ]
        },
        {
            "id": "task1540-a306a974822242fc9bfcb18830380fa2",
            "input": "Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data.",
            "output": [
                "Cold Fusion: Training Seq2Seq Models Together with Language Models"
            ]
        },
        {
            "id": "task1540-4140bd680c3a42bcb44885e22f4b8abb",
            "input": "In this work, we develop a simple algorithm for semi-supervised regression. The key idea is to use the top eigenfunctions of integral operator derived from both labeled and unlabeled examples as the basis functions and learn the prediction function by a simple linear regression. We show that under appropriate assumptions about the integral operator, this approach is able to achieve an improved regression error bound better than existing bounds of supervised learning. We also verify the effectiveness of the proposed algorithm by an empirical study.",
            "output": [
                "A Simple Algorithm for Semi-supervised Learning with Improved Generalization Error Bound"
            ]
        },
        {
            "id": "task1540-1535e6db41f641aeb12fc80f5603360a",
            "input": "Machine translation is the discipline concerned with developing automated tools for translating from one human language to another. Statistical machine translation (SMT) is the dominant paradigm in this field. In SMT, translations are generated by means of statistical models whose parameters are learned from bilingual data. Scalability is a key concern in SMT, as one would like to make use of as much data as possible to train better translation systems. In recent years, mobile devices with adequate computing power have become widely available. Despite being very successful, mobile applications relying on NLP systems continue to follow a client-server architecture, which is of limited use because access to internet is often limited and expensive. The goal of this dissertation is to show how to construct a scalable machine translation system that can operate with the limited resources available on a mobile device. The main challenge for porting translation systems on mobile devices is memory usage. The amount of memory available on a mobile device is far less than what is typically available on the server side of a client-server application. In this thesis, we investigate alternatives for the two components which prevent standard translation systems from working on mobile devices due to high memory usage. We show that once these standard components are replaced with our proposed alternatives, we obtain a scalable translation system that can work on a device with limited memory. The first two chapters of this thesis are introductory. Chapter 1 discusses the task we undertake in greater detail and highlights our contributions. Chapter 2 provides a brief introduction to statistical machine translation. In Chapter 3, we explore online grammar extractors as a memory efficient alternative to phrase tables. We propose a faster and simpler extraction algorithm for translation rules containing gaps, thereby improving the extraction time for hierarchical phase-based translation systems. In Chapter 4, we conduct a thorough investigation on how neural language models should be integrated in translation systems. We settle on a novel combination of noise contrastive estimation and factoring the output layer using Brown clusters. We obtain a high quality translation system that is fast both when training and decoding and we use it to show that neural language models outperform traditional n-gram models in memory constrained environments. Chapter 5 concludes our work showing that online grammar extractors and neural language models allow us to build scalable, high quality systems that can translate text with the limited resources available on a mobile device.",
            "output": [
                "Scalable Machine Translation in Memory Constrained Environments"
            ]
        },
        {
            "id": "task1540-e9461ce95cbb4eb788e47775aa55f00c",
            "input": "Even for common NLP tasks, sufficient supervision is not available in many languages—morphological tagging is no exception. In the work presented here, we explore a transfer learning scheme, whereby we train character-level recurrent neural taggers to predict morphological taggings for high-resource languages and low-resource languages together. Learning joint character representations among multiple related languages successfully enables knowledge transfer from the high-resource languages to the low-resource ones, improving accuracy by up to 30%.",
            "output": [
                "Cross-lingual, Character-Level Neural Morphological Tagging"
            ]
        },
        {
            "id": "task1540-5367e9191c2542c6a32390cba114d0f4",
            "input": "An important subclass of hybrid Bayesian networks are those that represent Conditional Linear Gaussian (CLG) distributionsa distribution with a multivari­ ate Gaussian component for each instantiation of the discrete variables. In this paper we explore the prob­ lem of inference in CLGs, and provide complexity re­ sults for an important class of CLGs, which includes Switching Kalman Filters. In particular, we prove that even if the CLG is restricted to an extremely simple structure of a polytree, the inference task is NP-hard. Furthermore, we show that, unless P=NP, even ap­ proximate inference on these simple networks is in­ tractable. Given the often prohibitive computational cost of even approximate inference, we must take advantage of spe­ cial domain properties which may enable efficient in­ ference. We concentrate on the fault diagnosis domain, and explore several approximate inference algorithms. These algorithms try to find a small subset of Gaus­ sians which are a good approximation to the full mix­ ture distribution. We consider two Monte Carlo ap­ proaches and a novel approach that enumerates mix­ ture components in order of prior probability. We com­ pare these methods on a variety of problems and show that our novel algorithm is very promising for large, hybrid diagnosis problems.",
            "output": [
                "Inference in Hybrid Networks: Theoretical Limits and Practical Algorithms"
            ]
        },
        {
            "id": "task1540-3735905baef54d80a82a99af6d35c377",
            "input": "Data quality assessment and data cleaning are context-dependent activities. Motivated by this observation, we propose the Ontological Multidimensional Data Model (OMD model), which can be used to model and represent contexts as logic-based ontologies. e data under assessment is mapped into the context, for additional analysis, processing, and quality data extraction. e resulting contexts allow for the representation of dimensions, and multidimensional data quality assessment becomes possible. At the core of a multidimensional context we include a generalized multidimensional data model and a Datalog± ontology with provably good properties in terms of query answering. ese main components are used to represent dimension hierarchies, dimensional constraints, dimensional rules, and dene predicates for quality data specication. ery answering relies upon and triggers navigation through dimension hierarchies, and becomes the basic tool for the extraction of quality data. e OMD model is interesting per se, beyond applications to data quality. It allows for a logic-based, and computationally tractable representation of multidimensional data, extending previous multidimensional data models with additional expressive power and functionalities.",
            "output": [
                "Ontological Multidimensional Data Models and Contextual Data Quality"
            ]
        },
        {
            "id": "task1540-bc91d2b9383f4e80a9c3fa42f08a9e94",
            "input": "Typical techniques for sequence classification are designed for well-segmented sequences which have been edited to remove noisy or irrelevant parts. Therefore, such methods cannot be easily applied on noisy sequences expected in real-world applications. In this paper, we present the Temporal Attention-Gated Model (TAGM) which integrates ideas from attention models and gated recurrent networks to better deal with noisy or unsegmented sequences. Specifically, we extend the concept of attention model to measure the relevance of each observation (time step) of a sequence. We then use a novel gated recurrent network to learn the hidden representation for the final prediction. An important advantage of our approach is interpretability since the temporal attention weights provide a meaningful value for the salience of each time step in the sequence. We demonstrate the merits of our TAGM approach, both for prediction accuracy and interpretability, on three different tasks: spoken digit recognition, text-based sentiment analysis and visual event recognition.",
            "output": [
                "Temporal Attention-Gated Model for Robust Sequence Classification"
            ]
        },
        {
            "id": "task1540-e29e32fce6344342b447706688ec6810",
            "input": "We introduce a novel latent vector space model that jointly learns<lb>the latent representations of words, e-commerce products and a<lb>mapping between the two without the need for explicit annotations.<lb>The power of the model lies in its ability to directly model the dis-<lb>criminative relation between products and a particular word. We<lb>compare our method to existing latent vector space models (LSI,<lb>LDA and word2vec) and evaluate it as a feature in a learning to<lb>rank setting. Our latent vector space model achieves its enhanced<lb>performance as it learns better product representations. Further-<lb>more, the mapping from words to products and the representations<lb>of words benefit directly from the errors propagated back from the<lb>product representations during parameter estimation. We provide<lb>an in-depth analysis of the performance of our model and analyze<lb>the structure of the learned representations.",
            "output": [
                "Learning Latent Vector Spaces for Product Search"
            ]
        },
        {
            "id": "task1540-c57ba9c9c3844889b7844a172f887f22",
            "input": "Documents exhibit sequential structure at multiple levels of abstraction (e.g., sentences, paragraphs, sections). These abstractions constitute a natural hierarchy for representing the context in which to infer the meaning of words and larger fragments of text. In this paper, we present CLSTM (Contextual LSTM), an extension of the recurrent neural network LSTM (Long-Short Term Memory) model, where we incorporate contextual features (e.g., topics) into the model. We evaluate CLSTM on three specific NLP tasks: word prediction, next sentence selection, and sentence topic prediction. Results from experiments run on two corpora, English documents in Wikipedia and a subset of articles from a recent snapshot of English Google News, indicate that using both words and topics as features improves performance of the CLSTM models over baseline LSTM models for these tasks. For example on the next sentence selection task, we get relative accuracy improvements of 21% for the Wikipedia dataset and 18% for the Google News dataset. This clearly demonstrates the significant benefit of using context appropriately in natural language (NL) tasks. This has implications for a wide variety of NL applications like question answering, sentence completion, paraphrase generation, and next utterance prediction in dialog systems.",
            "output": [
                "Contextual LSTM (CLSTM) models for Large scale NLP tasks"
            ]
        },
        {
            "id": "task1540-8d84395fb96e4ddc8a1e79c177091485",
            "input": "Languages for open-universe probabilistic models (OUPMs) can represent situations with an unknown number of objects and identity uncertainty. While such cases arise in a wide range of important real-world applications, existing general purpose inference methods for OUPMs are far less efficient than those available for more restricted languages and model classes. This paper goes some way to remedying this deficit by introducing, and proving correct, a generalization of Gibbs sampling to partial worlds with possibly varying model structure. Our approach draws on and extends previous generic OUPM inference methods, as well as auxiliary variable samplers for nonparametric mixture models. It has been implemented for BLOG, a well-known OUPM language. Combined with compile-time optimizations, the resulting algorithm yields very substantial speedups over existing methods on several test cases, and substantially improves the practicality of OUPM languages generally.",
            "output": [
                "Gibbs Sampling in Open-Universe Stochastic Languages"
            ]
        },
        {
            "id": "task1540-0c63f6f23fc14232b3d16b4cf1f01761",
            "input": "Graph matching is a challenging problem with very important applications in a wide range of fields, from image and video analysis to biological and biomedical problems. We propose a robust graph matching algorithm inspired in sparsityrelated techniques. We cast the problem, resembling group or collaborative sparsity formulations, as a non-smooth convex optimization problem that can be efficiently solved using augmented Lagrangian techniques. The method can deal with weighted or unweighted graphs, as well as multimodal data, where different graphs represent different types of data. The proposed approach is also naturally integrated with collaborative graph inference techniques, solving general network inference problems where the observed variables, possibly coming from different modalities, are not in correspondence. The algorithm is tested and compared with state-of-the-art graph matching techniques in both synthetic and real graphs. We also present results on multimodal graphs and applications to collaborative inference of brain connectivity from alignment-free functional magnetic resonance imaging (fMRI) data. The code is publicly available.",
            "output": [
                "Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching"
            ]
        },
        {
            "id": "task1540-e93a8d0a9de24601a62a57af138492d1",
            "input": "We present a method for solving implicit (factored) Markov decision processes (MDPs) with very large state spaces. We intro­ duce a property of state space partitions which we call f-homogeneity. Intuitively, an f-homogeneous partition groups together states that behave approximately the same under all or some subset of policies. Borrow­ ing from recent work on model minimization in computer-aided software verification, we present an algorithm that takes a factored representation of an MDP and an 0 � f � I and computes a factored f-homogeneous par­ tition of the state space. This partition defines a family of related MOPs-those MOP's with state space equal to the blocks of the partition, and transition probabilities \"appro:X:imately\" like those of any (original MDP) state in the source block. To formally study such families of MDPs, we introduce the new notion of a \"bounded parameter MDP\" (BMDP), which is a fam­ ily of (traditional) MOPs defined by speci­ fying upper and lower bounds on the transi­ tion probabilities and rewards. We describe algorithms that operate on BMDPs to find policies that are approximately optimal with respect to the original MDP. In combination, our method for reducing a large implicit MDP to a possibly much smaller BMDP using an f-homogeneous par­ tition, and our methods for selecting actions in BMDP's constitute a new approach for an­ alyzing large implicit MOP's. Among its ad­ vantages, this new approach provides insight into existing algorithms to solving implicit MDPs, provides useful connections to work in automata theory and model minimization, and suggests methods, which involve vary­ ing f, to trade time and space (specifically in terms of the size of the corresponding state space) for solution quality.",
            "output": [
                "Model Reduction Techniques for Computing Approximately Optimal Solutions for Markov Decision Processes"
            ]
        },
        {
            "id": "task1540-b722e55a7a804bc189d26e693e54c586",
            "input": "Planning is concerned with the automated solution of action sequencing problems described in declarative languages giving the action preconditions and effects. One important application area for such technology is the creation of new processes in Business Process Management (BPM), which is essential in an ever more dynamic business environment. A major obstacle for the application of Planning in this area lies in the modeling. Obtaining a suitable model to plan with – ideally a description in PDDL, the most commonly used planning language – is often prohibitively complicated and/or costly. Our core observation in this work is that this problem can be ameliorated by leveraging synergies with model-based software development. Our application at SAP, one of the leading vendors of enterprise software, demonstrates that even one-to-one model re-use is possible. The model in question is called Status and Action Management (SAM). It describes the behavior of Business Objects (BO), i.e., large-scale data structures, at a level of abstraction corresponding to the language of business experts. SAM covers more than 400 kinds of BOs, each of which is described in terms of a set of status variables and how their values are required for, and affected by, processing steps (actions) that are atomic from a business perspective. SAM was developed by SAP as part of a major model-based software engineering effort. We show herein that one can use this same model for planning, thus obtaining a BPM planning application that incurs no modeling overhead at all. We compile SAM into a variant of PDDL, and adapt an off-the-shelf planner to solve this kind of problem. Thanks to the resulting technology, business experts may create new processes simply by specifying the desired behavior in terms of status variable value changes: effectively, by describing the process in their own language.",
            "output": [
                "SAP Speaks PDDL: Exploiting a Software-Engineering Model for Planning in Business Process Management"
            ]
        },
        {
            "id": "task1540-faed27de8a474ba58a7de281225f79a8",
            "input": "Variational autoencoders are a powerful framework for unsupervised learning. However, previous work has been restricted to shallow models with one or two layers of fully factorized stochastic latent variables, limiting the flexibility of the latent representation. We propose three advances in training algorithms of variational autoencoders, for the first time allowing to train deep models of up to five stochastic layers, (1) using a structure similar to the Ladder network as the inference model, (2) warm-up period to support stochastic units staying active in early training, and (3) use of batch normalization. Using these improvements we show state-of-the-art log-likelihood results for generative modeling on several benchmark datasets.",
            "output": [
                "How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks"
            ]
        },
        {
            "id": "task1540-88f66154934f4ec2bfe9845d39f49536",
            "input": "We develop a novel preconditioning method for ridge regression, based on recent linear sketching methods. By equipping Stochastic Variance Reduced Gradient (SVRG) with this preconditioning process, we obtain a significant speed-up relative to fast stochastic methods such as SVRG, SDCA and SAG.",
            "output": [
                "Solving Ridge Regression using Sketched Preconditioned SVRG"
            ]
        },
        {
            "id": "task1540-8051db58aaab46d78acaeae82bbe0f24",
            "input": "A number of representation schemes have been presented for use within Learning Classifier Systems, ranging from binary encodings to Neural Networks, and more recently Dynamical Genetic Programming (DGP). This paper presents results from an investigation into using a fuzzy DGP representation within the XCSF Learning Classifier System. In particular, asynchronous Fuzzy Logic Networks are used to represent the traditional condition-action production system rules. It is shown possible to use self-adaptive, open-ended evolution to design an ensemble of such fuzzy dynamical systems within XCSF to solve several well-known continuousvalued test problems.",
            "output": [
                "Fuzzy Dynamical Genetic Programming in XCSF"
            ]
        },
        {
            "id": "task1540-e49a16cd82774abf878ebe0ce612df1e",
            "input": "We examine an important setting for engineered systems in which low-power distributed sensors are each making highly noisy measurements of some unknown target function. A center wants to accurately learn this function by querying a small number of sensors, which ordinarily would be impossible due to the high noise rate. The question we address is whether local communication among sensors, together with natural best-response dynamics in an appropriately-defined game, can denoise the system without destroying the true signal and allow the center to succeed from only a small number of active queries. By using techniques from game theory and empirical processes, we prove positive (and negative) results on the denoising power of several natural dynamics. We then show experimentally that when combined with recent agnostic active learning algorithms, this process can achieve low error from very few queries, performing substantially better than active or passive learning without these denoising dynamics as well as passive learning with denoising.",
            "output": [
                "Active Learning and Best-Response Dynamics"
            ]
        },
        {
            "id": "task1540-0c364f0894cc4ac382a0f768ab76a55b",
            "input": "In the era of big data, it is becoming common to have data with multiple modalities or coming from multiple sources, known as “multi-view data”. Since multi-view data are usually unlabeled and come from high-dimensional spaces (such as language vocabularies), unsupervised multi-view feature selection is crucial to many applications such as model interpretation and storage reduction. However, it is nontrivial due to the following challenges. First, the data may not fit in memory, because there are too many instances or the feature dimensionality is too large. How to select useful features with limited memory space? Second, the data may come in as streams and concept drift may happen. How to select features from streaming data and handles the concept drift? Third, different views may share some consistent and complementary information. How to leverage the consistent and complementary information from different views to improve the feature selection in the situation when the data are too big or come in as streams? To the best of our knowledge, none of the previous works can solve all the challenges simultaneously. In this paper, we propose an Online unsupervised MultiView Feature Selection, OMVFS, which deals with largescale/streaming multi-view data in an online fashion. OMVFS embeds unsupervised feature selection into a clustering algorithm via nonnegative matrix factorizatio with sparse learning. It further incorporates the graph regularization to preserve the local structure information and help select discriminative features. Instead of storing all the historical data, OMVFS processes the multi-view data chunk by chunk and aggregates all the necessary information into several small matrices. By using the buffering technique, the proposed OMVFS can reduce the computational and storage cost while taking advantage of the structure information. Furthermore, OMVFS can capture the concept drifts in the data streams. Extensive experiments on four real-world datasets show the effectiveness and efficiency of the proposed OMVFS method. More importantly, OMVFS is about 100 times faster than the off-line methods.",
            "output": [
                "Online Unsupervised Multi-view Feature Selection"
            ]
        },
        {
            "id": "task1540-ab2cdace8adf4f8686fef878f44a4f36",
            "input": "Data mining practitioners are facing challenges from data with network structure. In this paper, we address a specific class of global-state networks which comprises of a set of network instances sharing a similar structure yet having different values at local nodes. Each instance is associated with a global state which indicates the occurrence of an event. The objective is to uncover a small set of discriminative subnetworks that can optimally classify global network values. Unlike most existing studies which explore an exponential subnetwork space, we address this difficult problem by adopting a space transformation approach. Specifically, we present an algorithm that optimizes a constrained dualobjective function to learn a low-dimensional subspace that is capable of discriminating networks labelled by different global states, while reconciling with common network topology sharing across instances. Our algorithm takes an appealing approach from spectral graph learning and we show that the globally optimum solution can be achieved via matrix eigen-decomposition.",
            "output": [
                "Discriminative Subnetworks with Regularized Spectral Learning for Global-state Network Data"
            ]
        },
        {
            "id": "task1540-d96135393fba46598f5e34d49a5ac4f6",
            "input": "This paper introduces SGNMT, our experimental platform for machine translation research. SGNMT provides a generic interface to neural and symbolic scoring modules (predictors) with left-to-right semantic such as translation models like NMT, language models, translation lattices, n-best lists or other kinds of scores and constraints. Predictors can be combined with other predictors to form complex decoding tasks. SGNMT implements a number of search strategies for traversing the space spanned by the predictors which are appropriate for different predictor constellations. Adding new predictors or decoding strategies is particularly easy, making it a very efficient tool for prototyping new research ideas. SGNMT is actively being used by students in the MPhil program in Machine Learning, Speech and Language Technology at the University of Cambridge for course work and theses, as well as for most of the research work in our group.",
            "output": [
                "SGNMT – A Flexible NMT Decoding Platform for Quick Prototyping of New Models and Search Strategies"
            ]
        },
        {
            "id": "task1540-776ebce04e8e4bd6812eadc1476504f6",
            "input": "The success of deep learning in numerous application domains created the desire to run and train them on mobile devices. This however, conflicts with their computationally, memory and energy intense nature, leading to a growing interest in compression. Recent work by Han et al. (2015a) propose a pipeline that involves retraining, pruning and quantization of neural network weights, obtaining state-of-the-art compression rates. In this paper, we show that competitive compression rates can be achieved by using a version of ”soft weight-sharing” (Nowlan & Hinton, 1992). Our method achieves both quantization and pruning in one simple (re-)training procedure. This point of view also exposes the relation between compression and the minimum description length (MDL) principle.",
            "output": [
                "NEURAL NETWORK COMPRESSION"
            ]
        },
        {
            "id": "task1540-11a05d38d2e1446a8ed6a2e1e092bc53",
            "input": "The organizer of a machine learning competition faces the problem of maintaining an accurate leaderboard that faithfully represents the quality of the best submission of each competing team. What makes this estimation problem particularly challenging is its sequential and adaptive nature. As participants are allowed to repeatedly evaluate their submissions on the leaderboard, they may begin to overfit to the holdout data that supports the leaderboard. Few theoretical results give actionable advice on how to design a reliable leaderboard. Existing approaches therefore often resort to poorly understood heuristics such as limiting the bit precision of answers and the rate of re-submission. In this work, we introduce a notion of leaderboard accuracy tailored to the format of a competition. We introduce a natural algorithm called the Ladder and demonstrate that it simultaneously supports strong theoretical guarantees in a fully adaptive model of estimation, withstands practical adversarial attacks, and achieves high utility on real submission files from an actual competition hosted by Kaggle. Notably, we are able to sidestep a powerful recent hardness result for adaptive risk estimation that rules out algorithms such as ours under a seemingly very similar notion of accuracy. On a practical note, we provide a completely parameter-free variant of our algorithm that can be deployed in a real competition with no tuning required whatsoever.",
            "output": [
                "The Ladder: A Reliable Leaderboard for Machine Learning Competitions"
            ]
        },
        {
            "id": "task1540-ed6b3860764442999d77675fe5c6fccd",
            "input": "An open challenge in constructing dialogue systems is developing methods for automatically learning dialogue strategies from large amounts of unlabelled data. Recent work has proposed NextUtterance-Classification (NUC) as a surrogate task for building dialogue systems from text data. In this paper we investigate the performance of humans on this task to validate the relevance of NUC as a method of evaluation. Our results show three main findings: (1) humans are able to correctly classify responses at a rate much better than chance, thus confirming that the task is feasible, (2) human performance levels vary across task domains (we consider 3 datasets) and expertise levels (novice vs experts), thus showing that a range of performance is possible on this type of task, (3) automated dialogue systems built using state-of-the-art machine learning methods have similar performance to the human novices, but worse than the experts, thus confirming the utility of this class of tasks for driving further research in automated dialogue systems.",
            "output": [
                "On the Evaluation of Dialogue Systems with Next Utterance Classification"
            ]
        },
        {
            "id": "task1540-09d0b8aaa3b4406f9e07b8e1419ba2f3",
            "input": "In 2015, stroke was the number one cause of death in Indonesia. The majority type of stroke is ischemic. The standard tool for diagnosing stroke is CT-Scan. For developing countries like Indonesia, the availability of CT-Scan is very limited and still relatively expensive. Because of the availability, another device that potential to diagnose stroke in Indonesia is EEG. Ischemic stroke occurs because of obstruction that can make the cerebral blood flow (CBF) on a person with stroke has become lower than CBF on a normal person (control) so that the EEG signal have a deceleration. On this study, we perform the ability of 1D Convolutional Neural Network (1DCNN) to construct classification model that can distinguish the EEG and EOG stroke data from EEG and EOG control data. To accelerate training process our model we use Batch Normalization. Involving 62 person data object and from leave one out the scenario with five times repetition of measurement we obtain the average of accuracy 0.86 (F-Score 0.861) only at 200 epoch. This result is better than all over shallow and popular classifiers as the comparator (the best result of accuracy 0.69 and F-Score 0.72 ). The feature used in our study were only 24 ‘handcrafted’ feature with simple feature extraction process.",
            "output": [
                "Ischemic Stroke Identification Based on EEG and EOG using 1D Convolutional Neural Network and Batch Normalization"
            ]
        },
        {
            "id": "task1540-9c3c817dba9347648d6578b60adedb71",
            "input": "amLite is a framework developed to map ASCII transliterated Amharic texts back to the original Amharic letter texts. The aim of such a framework is to make existing Amharic linguistic data consistent and interoperable among researchers. For achieving the objective, a key map dictionary is constructed using the possible ASCII combinations actively in use for transliterating Amharic letters; and a mapping of the combinations to the corresponding Amharic letters is done. The mapping is then used to replace the Amharic linguistic text back to form the original Amharic letters text. The framework indicated 97.7, 99.7 and 98.4 percentage accuracy on converting the three sample random test data. It is; however, possible to improve the accuracy of the framework by adding an exception to the implementation of the algorithm, or by preprocessing the input text prior to conversion. This paper outlined the rationales behind the need for developing the framework and the processes undertaken in the development.",
            "output": [
                "amLite: Amharic Transliteration Using Key\r Map Dictionary"
            ]
        },
        {
            "id": "task1540-211692abfb1142bca9e1483f12cf4a45",
            "input": "Management of chronic diseases such as heart failure, diabetes, and chronic obstructive pulmonary disease (COPD) is a major problem in health care. A standard approach that the medical community has devised to manage widely prevalent chronic diseases such as chronic heart failure (CHF) is to have a committee of experts develop guidelines that all physicians should follow. These guidelines typically consist of a series of complex rules that make recommendations based on a patient’s information. Due to their complexity, often the guidelines are either ignored or not complied with at all, which can result in poor medical practices. It is not even clear whether it is humanly possible to follow these guidelines due to their length and complexity. In the case of CHF management, the guidelines run nearly 80 pages. In this paper we describe a physicianadvisory system for CHF management that codes the entire set of clinical practice guidelines for CHF using answer set programming. Our approach is based on developing reasoning templates (that we call knowledge patterns) and using these patterns to systemically code the clinical guidelines for CHF as ASP rules. Use of the knowledge patterns greatly facilitates the development of our system. Given a patient’s medical information, our system generates a recommendation for treatment just as a human physician would, using the guidelines. Our system will work even in the presence of incomplete information. Our work makes two contributions: (i) it shows that highly complex guidelines can be successfully coded as ASP rules, and (ii) it develops a series of knowledge patterns that facilitate the coding of knowledge expressed in a natural language and that can be used for other application domains. This paper is under consideration for acceptance in TPLP.",
            "output": [
                "A Physician Advisory System for Chronic Heart Failure Management Based on Knowledge Patterns"
            ]
        },
        {
            "id": "task1540-16052384d2134b95acc419bde780758d",
            "input": "Weighted finite automata and transducers (including hidden Markov models and conditional random fields) are widely used in natural language processing (NLP) to perform tasks such as morphological analysis, part-of-speech tagging, chunking, named entity recognition, speech recognition, and others. Parallelizing finite state algorithms on graphics processing units (GPUs) would benefit many areas of NLP. Although researchers have implemented GPU versions of basic graph algorithms, limited previous work, to our knowledge, has been done on GPU algorithms for weighted finite automata. We introduce a GPU implementation of the Viterbi and forward-backward algorithm, achieving decoding speedups of up to 5.2x over our serial implementation running on different computer architectures and 6093x over OpenFST.",
            "output": [
                "Decoding with Finite-State Transducers on GPUs"
            ]
        },
        {
            "id": "task1540-8deee8083ec645bfb0bd43636185eb86",
            "input": "This paper presents an analysis of data from a gift-exchange-game experiment. The experiment was described in ‘The Impact of Social Comparisons on Reciprocity’ by Gächter et al. 2012. Since this paper uses state-of-art data science techniques, the results provide a different point of view on the problem. As already shown in relevant literature from experimental economics, human decisions deviate from rational payoff maximization. The average gift rate was 31%. Gift rate was under no conditions zero. Further, we derive some special findings and calculate their significance.",
            "output": [
                "Reciprocity in Gift-Exchange-Games"
            ]
        },
        {
            "id": "task1540-95b61fa951174f29bc73f149baa012d3",
            "input": "An exhaustive study on neural network language modeling (NNLM) is performed in this paper. Different architectures of basic neural network language models are described and examined. A number of different improvements over basic neural network language models, including importance sampling, word classes, caching and bidirectional recurrent neural network (BiRNN), are studied separately, and the advantages and disadvantages of every technique are evaluated. Then, the limits of neural network language modeling are explored from the aspects of model architecture and knowledge representation. Part of the statistical information from a word sequence will loss when it is processed word by word in a certain order, and the mechanism of training neural network by updating weight matrixes and vectors imposes severe restrictions on any significant enhancement of NNLM. For knowledge representation, the knowledge represented by neural network language models is the approximate probabilistic distribution of word sequences from a certain training data set rather than the knowledge of a language itself or the information conveyed by word sequences in a natural language. Finally, some directions for improving neural network language modeling further is discussed.",
            "output": [
                "A Study on Neural Network Language Modeling"
            ]
        },
        {
            "id": "task1540-dc960104922a4c698e799ef155259800",
            "input": "We propose Novel Object Captioner (NOC), a deep visual semantic captioning model that can describe a large number of object categories not present in existing image-caption datasets. Recent captioning models are limited in their ability to scale and describe concepts outside of paired image-text corpora. Our model takes advantage of external sources labeled images from object recognition datasets, and semantic knowledge extracted from unannotated text and combines them to generate descriptions about novel objects. We propose minimizing a joint objective which can learn from diverse data sources and leverage distributional semantic embeddings, enabling the model to generalize and describe novel objects outside of imagecaption datasets. We demonstrate that our model exploits semantic information to generate captions for hundreds of object categories in the ImageNet object recognition dataset that are not observed in imagecaption training data, as well as many categories that are observed very rarely.",
            "output": [
                "Captioning Images with Diverse Objects"
            ]
        },
        {
            "id": "task1540-ba0e4709766845f99ab4fa21214bdbc8",
            "input": "Recent years have witnessed increasing interest in the potential benefits of ‘intelligent’ autonomous machines such as robots. Honda’s Asimo humanoid robot, iRobot’s Roomba robot vacuum cleaner and Google’s driverless cars have fired the imagination of the general public, and social media buzz with speculation about a utopian world of helpful robot assistants or the coming robot apocalypse! However, there is a long way to go before autonomous systems reach the level of capabilities required for even the simplest of tasks involving human-robot interaction especially if it involves communicative behaviour such as speech and language. Of course the field of Artificial Intelligence (AI) has made great strides in these areas, and has moved on from abstract high-level rule-based paradigms to embodied architectures whose operations are grounded in real physical environments. What is still missing, however, is an overarching theory of intelligent communicative behaviour that informs system-level design decisions in order to provide a more coherent approach to system integration. This chapter introduces the beginnings of such a framework inspired by the principles of Perceptual Control Theory (PCT). In particular, it is observed that PCT has hitherto tended to view perceptual processes as a relatively straightforward series of transformations from sensation to perception, and has overlooked the potential of powerful generative model-based solutions that have emerged in practical fields such as visual or auditory scene analysis. Starting from first principles, a sequence of arguments is presented which not only shows how these ideas might be integrated into PCT, but which also extend PCT towards a remarkably symmetric architecture for a needs-driven communicative agent. It is concluded that, if behaviour is the control of perception (the central tenet of PCT), then perception (at least for communicative agents) is the simulation of behaviour.",
            "output": [
                "PCT and Beyond: Towards a Computational Framework for ‘Intelligent’ Communicative Systems"
            ]
        },
        {
            "id": "task1540-66012be768da485ca61d7daeab19a11d",
            "input": "Progress in Multiple Object Tracking (MOT) has been historically limited by the size of the available datasets. We present an efficient framework to annotate trajectories and use it to produce a MOT dataset of unprecedented size. In our novel path supervision the annotator loosely follows the object with the cursor while watching the video, providing a path annotation for each object in the sequence. Our approach is able to turn such weak annotations into dense box trajectories. Our experiments on existing datasets prove that our framework produces more accurate annotations than the state of the art, in a fraction of the time. We further validate our approach by crowdsourcing the PathTrack dataset, with more than 15,000 person trajectories in 720 sequences1. Tracking approaches can benefit training on such large-scale datasets, as did object recognition. We prove this by re-training an off-the-shelf person matching network, originally trained on the MOT15 dataset, almost halving the misclassification rate. Additionally, training on our data consistently improves tracking results, both on our dataset and on MOT15. On the latter, we improve the top-performing tracker (NOMT) dropping the number of ID Switches by 18% and fragments by 5%.",
            "output": [
                "PathTrack: Fast Trajectory Annotation with Path Supervision"
            ]
        },
        {
            "id": "task1540-6466a78b20604bfd95ce3b4bd71802b8",
            "input": "Various families of malware use domain generation algorithms (DGAs) to generate a large number of pseudo-random domain names to connect to a command and control (C2) server. In order to block DGA C2 traffic, security organizations must first discover the algorithm by reverse engineering malware samples, then generate a list of domains for a given seed. The domains are then either preregistered, sink-holed or published in a DNS blacklist. This process is not only tedious, but can be readily circumvented by malware authors. An alternative approach to stop malware from using DGAs is to intercept DNS queries on a network and predict whether domains are DGA generated. Much of the previous work in DGA detection is based on finding groupings of like domains and using their statistical properties to determine if they are DGA generated. However, these techniques are run over large time windows and cannot be used for real-time detection and prevention. In addition, many of these techniques also use contextual information such as passive DNS and aggregations of all NXDomains throughout a network. Such requirements are not only costly to integrate, they may not be possible due to real-world constraints of many systems (such as endpoint detection). An alternative to these systems is a much harder problem: detect DGA generation on a per domain basis with no information except for the domain name. Previous work to solve this harder problem exhibits poor performance and many of these systems rely heavily on manual creation of features; a time consuming process that can easily be circumvented by malware authors. This paper presents a DGA classifier that leverages long short-term memory (LSTM) networks for real-time prediction of DGAs without the need for contextual information or manually created features. In addition, the presented technique can accurately perform multiclass classification giving the ability to attribute a DGA generated domain to a specific malware family. The technique is extremely easy to implement using open source tools allowing the technique to be deployed in almost any setting. Results are significantly better than all state-of-the-art techniques, providing 0.9993 area under the receiver operating characteristic curve for binary classification and a micro-averaged F1 score of 0.9906. In other terms, the LSTM technique can provide a 90% detection rate with a 1:10000 false positive (FP) rate—a twenty times FP improvement over the next best method. Experiments in this paper are run on open datasets and code snippets are provided to reproduce the results.",
            "output": [
                "Predicting Domain Generation Algorithms with Long Short-Term Memory Networks"
            ]
        },
        {
            "id": "task1540-7a3269a954414eb8807aa9136e954a31",
            "input": "An approach to incorporate deep learning within an iterative image reconstruction framework to reconstruct images from severely incomplete measurement data is presented. Specifically, we utilize a convolutional neural network (CNN) as a quasi-projection operator within a least squares minimization procedure. The CNN is trained to encode high level information about the class of images being imaged; this information is utilized to mitigate artifacts in intermediate images produced by use of an iterative method. The structure of the method was inspired by the proximal gradient descent method, where the proximal operator is replaced by a deep CNN and the gradient descent step is generalized by use of a linear reconstruction operator. It is demonstrated that this approach improves image quality for several cases of limited-view image reconstruction and that using a CNN in an iterative method increases performance compared to conventional image reconstruction approaches. We test our method on several limited-view image reconstruction problems. Qualitative and quantitative results demonstrate state-of-the-art performance.",
            "output": [
                "Deep Learning-Guided Image Reconstruction from Incomplete Data"
            ]
        },
        {
            "id": "task1540-475b6194aa6943dbb9b028107112cfda",
            "input": "In the event that a bacteriological or chemical toxin is introduced to a water distribution network, a large population of consumers may become exposed to the contaminant. A contamination event may be poorly predictable dynamic process due to the interactions of consumers and utility managers during an event. Consumers that become aware of a threat may select protective actions that change their water demands from typical demand patterns, and new hydraulic conditions can arise that differ from conditions that are predicted when demands are considered as exogenous inputs. Consequently, the movement of the contaminant plume in the pipe network may shift from its expected trajectory. A sociotechnical model is developed here to integrate agent-based models of consumers with an engineering water distribution system model and capture the dynamics between consumer behaviors and the water distribution system for predicting contaminant transport and public exposure. Consumers are simulated as agents with behaviors defined for water use activities, mobility, word-of-mouth communication, and demand reduction, based on a set of rules representing an agents autonomy and reaction to health impacts, the environment, and the actions of other agents. As consumers decrease their water use, the demand exerted on the water distribution system is updated; as the flow directions and volumes shift in response, the location of the contaminant plume is updated and the amount of contaminant consumed by each agent is calculated. The framework is tested through simulating realistic contamination scenarios for a virtual city and water distribution system.",
            "output": [
                "An Agent-based Modeling Framework for Sociotechnical Simulation of Water Distribution Contamination Events"
            ]
        },
        {
            "id": "task1540-e8b9dcb486a44464a171356c23720bf8",
            "input": "Based on the in-depth analysis of the essence and features of vague phenomena, this paper focuses on establishing the axiomatical foundation of membership degree theory for vague phenomena, presents an axiomatic system to govern membership degrees and their interconnections. On this basis, the concept of vague partition is introduced, further, the concept of fuzzy set introduced by Zadeh in 1965 is redefined based on vague partition from the perspective of axiomatization. The thesis defended in this paper is that the relationship among vague attribute values should be the starting point to recognize and model vague phenomena from a quantitative view.",
            "output": [
                "Redefinition of the concept of fuzzy set based on vague partition from the perspective of axiomatization"
            ]
        },
        {
            "id": "task1540-94d569e6630b49a78fb57256faf00c63",
            "input": "Policies for complex visual tasks have been successfully learned with deep reinforcement learning, using an approach called deep Q-networks (DQN), but relatively large (task-specific) networks and extensive training are needed to achieve good performance. In this work, we present a novel method called policy distillation that can be used to extract the policy of a reinforcement learning agent and train a new network that performs at the expert level while being dramatically smaller and more efficient. Furthermore, the same method can be used to consolidate multiple task-specific policies into a single policy. We demonstrate these claims using the Atari domain and show that the multi-task distilled agent outperforms the single-task teachers as well as a jointly-trained DQN agent.",
            "output": [
                "POLICY DISTILLATION"
            ]
        },
        {
            "id": "task1540-b03f69ae9b3e4e13b3db01640405a1e1",
            "input": "We propose an attention-enabled encoder-decoder model for the problem of grapheme-to-phoneme conversion. Most previous work has tackled the problem via joint sequence models that require explicit alignments for training. In contrast, the attention-enabled encoder-decoder model allows for jointly learning to align and convert characters to phonemes. We explore different types of attention models, including global and local attention, and our best models achieve state-of-the-art results on three standard data sets (CMUDict, Pronlex, and NetTalk).",
            "output": [
                "JOINTLY LEARNING TO ALIGN AND CONVERT GRAPHEMES TO PHONEMES WITH NEURAL ATTENTION MODELS"
            ]
        },
        {
            "id": "task1540-8d8ecad6e04a4af0814c293465e17ca1",
            "input": "In this paper, we discuss how machine learning could be used to produce a systematic and more objective political discourse analysis. Political footprints are vector space models (VSMs) applied to political discourse. Each of their vectors represents a word, and is produced by training the English lexicon on large text corpora. This paper presents a simple implementation of political footprints, some heuristics on how to use them, and their application to four cases: the U.N. Kyoto Protocol and Paris Agreement, and two U.S. presidential elections. The reader will be offered a number of reasons to believe that political footprints produce meaningful results, along with some suggestions on how to improve their implementation.",
            "output": [
                "Political Footprints: Political Discourse Analysis using Pre-Trained Word Vectors"
            ]
        },
        {
            "id": "task1540-2dbf55ba1b1943e08804906a392b7a6a",
            "input": "The interest in the combination of probability with logics for modeling the world has rapidly increased in the last few years. One of the most effective approaches is the Distribution Semantics which was adopted by many logic programming languages and in Descripion Logics. In this paper, we illustrate the work we have done in this research field by presenting a probabilistic semantics for description logics and reasoning and learning algorithms. In particular, we present in detail the system TRILL , which computes the probability of queries w.r.t. probabilistic knowledge bases, which has been implemented in Prolog. Note: An extended abstract / full version of a paper accepted to be presented at the Doctoral Consortium of the 30th International Conference on Logic Programming (ICLP 2014), July 19-22, Vienna, Austria",
            "output": [
                "Reasoning with Probabilistic Logics"
            ]
        },
        {
            "id": "task1540-80f254dac9064f58b2cbfd85436fdd18",
            "input": "A novel method for learning optimal, orthonormal wavelet bases for representing 1and 2D signals, based on parallels between the wavelet transform and fully connected artificial neural networks, is described. The structural similarities between these two concepts are reviewed and combined to a “wavenet”, allowing for the direct learning of optimal wavelet filter coefficient through stochastic gradient descent with back-propagation over ensembles of training inputs, where conditions on the filter coefficients for constituting orthonormal wavelet bases are cast as quadratic regularisations terms. We describe the practical implementation of this method [1], and study its performance for high-energy physics collision events for QCD 2 → 2 processes. It is shown that an optimal solution is found, even in a high-dimensional search space, and the implications of the result are discussed.",
            "output": [
                "Learning optimal wavelet bases using a neural network approach"
            ]
        },
        {
            "id": "task1540-47f359ef376b4b4dbd7498b230baaddc",
            "input": "We address the problem of contour detection via per-pixel classifications of edge point. To facilitate the process, the proposed approach leverages with DenseNet, an efficient implementation of multiscale convolutional neural networks (CNNs), to extract an informative feature vector for each pixel and uses an SVM classifier to accomplish contour detection. The main challenge lies in adapting a pre-trained per-image CNN model for yielding per-pixel image features. We propose to base on the DenseNet architecture to achieve pixelwise fine-tuning and then consider a cost-sensitive strategy to further improve the learning with a small dataset of edge and non-edge image patches. In the experiment of contour detection, we look into the effectiveness of combining per-pixel features from different CNN layers and obtain comparable performances to the state-of-the-art on BSDS500.",
            "output": [
                "CONTOUR DETECTION USING COST-SENSITIVE CON-"
            ]
        },
        {
            "id": "task1540-f42eb4df6a1b42a1880e66ee9e31b87c",
            "input": "In this paper we present an approach to polyphonic sound event detection in real life recordings based on bi-directional long short term memory (BLSTM) recurrent neural networks (RNNs). A single multilabel BLSTM RNN is trained to map acoustic features of a mixture signal consisting of sounds from multiple classes, to binary activity indicators of each event class. Our method is tested on a large database of real-life recordings, with 61 classes (e.g. music, car, speech) from 10 different everyday contexts. The proposed method outperforms previous approaches by a large margin, and the results are further improved using data augmentation techniques. Overall, our system reports an average F1-score of 65.5% on 1 second blocks and 64.7% on single frames, a relative improvement over previous state-of-the-art approach of 6.8% and 15.1% respectively.",
            "output": [
                "RECURRENT NEURAL NETWORKS FOR POLYPHONIC SOUND EVENT DETECTION IN REAL LIFE RECORDINGS"
            ]
        },
        {
            "id": "task1540-13d45ec9f9594e04b6da9886f14d7062",
            "input": "An RNN-based forecasting approach is used to early detect anomalies in industrial multivariate time series data from a simulated Tennessee Eastman Process (TEP) with many cyberattacks. This work continues a previously proposed LSTM-based approach to the fault detection in simpler data. It is considered necessary to adapt the RNN network to deal with data containing stochastic, stationary, transitive and a rich variety of anomalous behaviours. There is particular focus on early detection with special NABmetric. A comparison with the DPCA approach is provided. The generated data set is made publicly available.",
            "output": [
                "RNN-based Early Cyber-Attack Detection for the Tennessee Eastman Process"
            ]
        },
        {
            "id": "task1540-213ee5a3570d41f9ad224355474b9199",
            "input": "With the advent of modern computer networks, fault diagnosis has been a focus of research activity. This paper reviews the history of fault diagnosis in networks and discusses the main methods in information gathering section, information analyzing section and diagnosing and revolving section of fault diagnosis in networks. Emphasis will be placed upon knowledge-based methods with discussing the advantages and shortcomings of the different methods. The survey is concluded with a description of some open problems. Keywords-fault diagnosis in networks; expert system; Bayesian networks; artificial neural network",
            "output": [
                "Survey of modern Fault Diagnosis methods in networks"
            ]
        },
        {
            "id": "task1540-03e9a778b61945e9839d5f4253c50e3f",
            "input": "In this study, an Artificial Neural Network (ANN) approach is utilized to perform a parametric study on the process of extraction of lubricants from heavy petroleum cuts. To train the model, we used field data collected from an industrial plant. Operational conditions of feed and solvent flow rate, Temperature of streams and mixing rate were considered as the input to the model, whereas the flow rate of the main product was considered as the output of the ANN model. A feed-forward Multi-Layer Perceptron Neural Network was successfully applied to capture the relationship between inputs and output parameters.",
            "output": [
                "On the Parametric Study of Lubricating Oil Production using an Artificial Neural Network (ANN) Approach"
            ]
        },
        {
            "id": "task1540-26c04705ad98458a8a3d08f4b059e2b9",
            "input": "Modern machine-learning techniques greatly reduce the efforts required to conduct high-quality program compilation, which, without the aid of machine learning, would otherwise heavily rely on human manipulation as well as expert intervention. The success of the application of machine-learning techniques to compilation tasks can be largely attributed to the recent development and advancement of program characterization, a process that numerically or structurally quantifies a target program. While great achievements have been made in identifying key features to characterize programs, choosing a correct set of features for a specific compiler task remains an ad hoc procedure. In order to guarantee a comprehensive coverage of features, compiler engineers usually need to select excessive number of features. This, unfortunately, would potentially lead to a selection of multiple similar features, which in turn could create a new problem of bias that emphasizes certain aspects of a program’s characteristics, hence reducing the accuracy and performance of the target compiler task. In this paper, we propose FEAture Selection for compilation Tasks (FEAST), an efficient and automated framework for determining the most relevant and representative features from a feature pool. Specifically, FEAST utilizes widely used statistics and machine-learning tools, including LASSO, sequential forward and backward selection, for automatic feature selection, and can in general be applied to any numerical feature set. This paper further proposes an automated approach to compiler parameter assignment for assessing the performance of FEAST. Intensive experimental results demonstrate that, under the compiler parameter assignment task, FEAST can achieve comparable results with about 18% of features that are automatically selected from the entire feature pool. We also inspect these selected features and discuss their roles in program execution.",
            "output": [
                "FEAST: An Automated Feature Selection Framework for Compilation Tasks"
            ]
        },
        {
            "id": "task1540-a37ae1b26bdb42e38b875aef0d443f66",
            "input": "Bayesian network structure learning is the notoriously difficult problem of discovering a Bayesian network that optimally represents a given set of training data. In this paper we study the computational worst-case complexity of exact Bayesian network structure learning under graph theoretic restrictions on the (directed) super-structure. The super-structure is an undirected graph that contains as subgraphs the skeletons of solution networks. We introduce the directed super-structure as a natural generalization of its undirected counterpart. Our results apply to several variants of score-based Bayesian network structure learning where the score of a network decomposes into local scores of its nodes. Results: We show that exact Bayesian network structure learning can be carried out in non-uniform polynomial time if the super-structure has bounded treewidth, and in linear time if in addition the super-structure has bounded maximum degree. Furthermore, we show that if the directed super-structure is acyclic, then exact Bayesian network structure learning can be carried out in quadratic time. We complement these positive results with a number of hardness results. We show that both restrictions (treewidth and degree) are essential and cannot be dropped without loosing uniform polynomial time tractability (subject to a complexity-theoretic assumption). Similarly, exact Bayesian network structure learning remains NP-hard for “almost acyclic” directed super-structures. Furthermore, we show that the restrictions remain essential if we do not search for a globally optimal network but aim to improve a given network by means of at most k arc additions, arc deletions, or arc reversals (k-neighborhood local search).",
            "output": [
                "Parameterized Complexity Results for Exact Bayesian Network Structure Learning"
            ]
        },
        {
            "id": "task1540-50a9237266b64da6aee5bac8a211f5ad",
            "input": "Consider an ill-posed inverse problem of estimating causal factors from observations, one of which is known to lie near some (unknown) low-dimensional, nonlinear manifold expressed by a predefined Mercer-kernel. Solving this problem requires simultaneous estimation of these factors and learning the low-dimensional representation for them. In this work, we introduce a novel non-linear dimensionality regularization technique for solving such problems without pre-training. We re-formulate Kernel-PCA as an energy minimization problem in which low dimensionality constraints are introduced as regularization terms in the energy. To the best of our knowledge, ours is the first attempt to create a dimensionality regularizer in the KPCA framework. Our approach relies on robustly penalizing the rank of the recovered factors directly in the implicit feature space to create their low-dimensional approximations in closed form. Our approach performs robust KPCA in the presence of missing data and noise. We demonstrate state-of-the-art results on predicting missing entries in the standard oil flow dataset. Additionally, we evaluate our method on the challenging problem of Non-Rigid Structure from Motion and our approach delivers promising results on CMU mocap dataset despite the presence of significant occlusions and noise.",
            "output": [
                "SOLVING INVERSE PROBLEMS"
            ]
        },
        {
            "id": "task1540-795f7f3b0aca42bcb2a354ab0031a3dd",
            "input": "We introduce a new approach to solving path-finding problems under uncertainty by representing them as probabilistic models and applying domain-independent inference algorithms to the models. This approach separates problem representation from the inference algorithm and provides a framework for efficient learning of path-finding policies. We evaluate the new approach on the Canadian Traveller Problem, which we formulate as a probabilistic model, and show how probabilistic inference allows high performance stochastic policies to be obtained for this problem.",
            "output": [
                "Path Finding under Uncertainty through Probabilistic Inference"
            ]
        },
        {
            "id": "task1540-14ead77e69794f71ada5de48d083db58",
            "input": "Automated Lymph Node (LN) detection is an important clinical diagnostic task but very challenging due to the low contrast of surrounding structures in Computed Tomography (CT) and to their varying sizes, poses, shapes and sparsely distributed locations. State-of-the-art studies show the performance range of 52.9% sensitivity at 3.1 false-positives per volume (FP/vol.), or 60.9% at 6.1 FP/vol. for mediastinal LN, by one-shot boosting on 3D HAAR features. In this paper, we first operate a preliminary candidate generation stage, towards ∼100% sensitivity at the cost of high FP levels (∼40 per patient), to harvest volumes of interest (VOI). Our 2.5D approach consequently decomposes any 3D VOI by resampling 2D reformatted orthogonal views N times, via scale, random translations, and rotations with respect to the VOI centroid coordinates. These random views are then used to train a deep Convolutional Neural Network (CNN) classifier. In testing, the CNN is employed to assign LN probabilities for all N random views that can be simply averaged (as a set) to compute the final classification probability per VOI. We validate the approach on two datasets: 90 CT volumes with 388 mediastinal LNs and 86 patients with 595 abdominal LNs. We achieve sensitivities of 70%/83% at 3 FP/vol. and 84%/90% at 6 FP/vol. in mediastinum and abdomen respectively, which drastically improves over the previous state-of-the-art work. ∗holger.roth@nih.gov, h.roth@ucl.ac.uk",
            "output": [
                "A New 2.5D Representation for Lymph Node Detection using Random Sets of Deep Convolutional Neural Network Observations"
            ]
        },
        {
            "id": "task1540-46078e19589c4191a62e259fd2c191d6",
            "input": "We frame Question Answering as a Reinforcement Learning task, an approach that we call Active Question Answering. We propose an agent that sits between the user and a black box question-answering system an which learns to reformulate questions to elicit the best possible answers. The agent probes the system with, potentially many, natural language reformulations of an initial question and aggregates the returned evidence to yield the best answer. The reformulation system is trained end-to-end to maximize answer quality using policy gradient. We evaluate on SearchQA, a dataset of complex questions extracted from Jeopardy!. Our agent improves F1 by 11% over a state-of-the-art base model that uses the original question/answer pairs.",
            "output": [
                "Ask the Right Questions: Active Question Reformulation with Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-d905a20f34d844349e25490cbfdd36c5",
            "input": "In this paper, we present a robotic prediction agent including a darkforest Go engine, a fuzzy markup language (FML) assessment engine, an FML-based decision support engine, and a robot engine for game of Go application. The knowledge base and rule base of FML assessment engine are constructed by referring the information from the darkforest Go engine located in NUTN and OPU, for example, the number of MCTS simulations and winning rate prediction. The proposed robotic prediction agent first retrieves the database of Go competition website, and then the FML assessment engine infers the winning possibility based on the information generated by darkforest Go engine. The FML-based decision support engine computes the winning possibility based on the partial game situation inferred by FML assessment engine. Finally, the robot engine combines with the human-friendly robot partner PALRO, produced by Fujisoft incorporated, to report the game situation to human Go players. Experimental results show that the FML-based prediction agent can work effectively. Keywords—Fuzzy markup language; prediction agent; decision support engine; robot engine; darkforest Go engine",
            "output": [
                "FML-based Prediction Agent and Its Application to Game of Go"
            ]
        },
        {
            "id": "task1540-6f35377c993a417fbaab2a147bedf2c9",
            "input": "We study the responses of two tactile sensors, the fingertip sensor from the iCub and the BioTac under different external stimuli. The question of interest is to which degree both sensors i) allow the estimation of force exerted on the sensor and ii) enable the recognition of differing degrees of curvature. Making use of a force controlled linear motor affecting the tactile sensors we acquire several high-quality data sets allowing the study of both sensors under exactly the same conditions. We also examined the structure of the representation of tactile stimuli in the recorded tactile sensor data using t-SNE embeddings. The experiments show that both the iCub and the BioTac excel in different settings.",
            "output": [
                "ML-based tactile sensor calibration: A universal approach"
            ]
        },
        {
            "id": "task1540-e04943327ad8411a9ff8921ff451cc1d",
            "input": "This paper describes an application of Bayesian programming to the control of an autonomous avatar in a multiplayer role-playing game (the example is based on World of Warcraft). We model a particular task, which consists of choosing what to do and to select which target in a situation where allies and foes are present. We explain the model in Bayesian programming and show how we could learn the conditional probabilities from data gathered during human-played sessions.",
            "output": [
                "Bayesian Modeling Of An Human MMORPG Player"
            ]
        },
        {
            "id": "task1540-9ce1c080dc5a4a3ca21cf59449a16839",
            "input": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batchnormalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters.",
            "output": [
                "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
            ]
        },
        {
            "id": "task1540-31447f40113a429e9cf559446fcb9f40",
            "input": "A metonym is a word with a figurative meaning, similar to a metaphor. Because metonyms are closely related to metaphors, we apply features that are used successfully for metaphor recognition to the task of detecting metonyms. On the ACL SemEval 2007 Task 8 data with gold standard metonym annotations, our system achieved 86.45% accuracy on the location metonyms. Our code can be found on GitHub.",
            "output": [
                "Exploring Metaphorical Senses and Word Representations for Identifying Metonyms"
            ]
        },
        {
            "id": "task1540-3606573e10ea41858525ceb380b94dd4",
            "input": "Twitter has become one of the main sources of news for many people. As real-world events and emergencies unfold, Twitter is abuzz with hundreds of thousands of stories about the events. Some of these stories are harmless, while others could potentially be lifesaving or sources of malicious rumors. Thus, it is critically important to be able to efficiently track stories that spread on Twitter during these events. In this paper, we present a novel semi-automatic tool that enables users to efficiently identify and track stories about real-world events on Twitter. We ran a user study with 25 participants, demonstrating that compared to more conventional methods, our tool can increase the speed and the accuracy with which users can track stories about real-",
            "output": [
                "A Semi-automatic Method for Efficient Detection of Stories on Social Media"
            ]
        },
        {
            "id": "task1540-be7c365fd1914aa284b86ca10b0a1195",
            "input": "Symmetry breaking has been proven to be an efficient preprocessing technique for satisfiability solving (SAT). In this paper, we port the state-of-the-art SAT symmetry breaker BreakID to answer set programming (ASP). The result is a lightweight tool that can be plugged in between the grounding and the solving phases that are common when modelling in ASP. We compare our tool with sbass, the current stateof-the-art symmetry breaker for ASP.",
            "output": [
                "BreakID: Static Symmetry Breaking for ASP (System Description)"
            ]
        },
        {
            "id": "task1540-098ac218d70d49b7885d9ffea090806d",
            "input": "Automatic headline generation is an important research area within text summarization and sentence compression. Recently, neural headline generation models have been proposed to take advantage of well-trained neural networks in learning sentence representations and mapping sequence to sequence. Nevertheless, traditional neural network encoder utilizes maximum likelihood estimation for parameter optimization, which essentially constraints the expected training objective within word level instead of sentence level. Moreover, the performance of model prediction significantly relies on training data distribution. To overcome these drawbacks, we employ minimum risk training strategy in this paper, which directly optimizes model parameters with respect to evaluation metrics and statistically leads to significant improvements for headline generation. Experiment results show that our approach outperforms state-of-the-art systems on both English and Chinese headline generation tasks.",
            "output": [
                "Neural Headline Generation with Minimum Risk Training"
            ]
        },
        {
            "id": "task1540-e828e94105e440ef8f2a7df8ae5b16cf",
            "input": "We consider Markov decision processes under parameter uncertainty. Previous studies all restrict to the case that uncertainties among different states are uncoupled, which leads to conservative solutions. In contrast, we introduce an intuitive concept, termed “Lightning Does not Strike Twice,” to model coupled uncertain parameters. Specifically, we require that the system can deviate from its nominal parameters only a bounded number of times. We give probabilistic guarantees indicating that this model represents real life situations and devise tractable algorithms for computing optimal control policies.",
            "output": [
                "Lightning Does Not Strike Twice:  Robust MDPs with Coupled Uncertainty"
            ]
        },
        {
            "id": "task1540-fb351cd0d06644ddaefd8d0c6e1be150",
            "input": "Speaker intent detection and semantic slot filling are two critical tasks in spoken language understanding (SLU) for dialogue systems. In this paper, we describe a recurrent neural network (RNN) model that jointly performs intent detection, slot filling, and language modeling. The neural network model keeps updating the intent prediction as word in the transcribed utterance arrives and uses it as contextual features in the joint model. Evaluation of the language model and online SLU model is made on the ATIS benchmarking data set. On language modeling task, our joint model achieves 11.8% relative reduction on perplexity comparing to the independent training language model. On SLU tasks, our joint model outperforms the independent task training model by 22.3% on intent detection error rate, with slight degradation on slot filling F1 score. The joint model also shows advantageous performance in the realistic ASR settings with noisy speech input.",
            "output": [
                "Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-cfcfafb4fdbe449ab0444d97c8e3e5b7",
            "input": "In cocktail party listening scenarios, the human brain is able to separate competing speech signals. However, the signal processing implemented by the brain to perform cocktail party listening is not well understood. Here, we trained two separate convolutive autoencoder deep neural networks (DNN) to separate monaural and binaural mixtures of two concurrent speech streams. We then used these DNNs as convolutive deep transform (CDT) devices to perform probabilistic re-synthesis. The CDTs operated directly in the time-domain. Our simulations demonstrate that very simple neural networks are capable of exploiting monaural and binaural information available in a cocktail party listening scenario.",
            "output": [
                "Deep Transform: Cocktail Party Source Separation via Probabilistic Re-Synthesis"
            ]
        },
        {
            "id": "task1540-6c7385d309e54e0480a829a342951aeb",
            "input": "Boolean matrix factorisation (BooMF) infers interpretable decompositions of a binary data matrix into a pair of low-rank, binary matrices: One containing meaningful patterns, the other quantifying how the observations can be expressed as a combination of these patterns. We introduce the OrMachine, a probabilistic generative model for BooMF and derive a Metropolised Gibbs sampler that facilitates very efficient parallel posterior inference. Our method outperforms all currently existing approaches for Boolean Matrix factorization and completion, as we show on simulated and real world data. This is the first method to provide full posterior inference for BooMF which is relevant in applications, e.g. for controlling false positive rates in collaborative filtering, and crucially it improves the interpretability of the inferred patterns. The proposed algorithm scales to large datasets as we demonstrate by analysing single cell gene expression data in 1.3 million mouse brain cells across 11,000 genes on commodity hardware.",
            "output": [
                "Bayesian Boolean Matrix Factorisation"
            ]
        },
        {
            "id": "task1540-e9de0342a48446bcbcb236a9540859f9",
            "input": "Machine learning is used in a number of security related applications such as biometric user authentication, speaker identification etc. A type of causative integrity attack against machine le arning called Poisoning attack works by injecting specially crafted data points in the training data so as to increase the false positive rate of the classifier. In the context of the biometric authentication, this means that more intruders will be classified as valid user, and in case of speaker identification system, user A will be classified user B. In this paper, we examine poisoning attack against SVM and introduce Curie a method to protect the SVM classifier from the poisoning attack. The basic idea of our method is to identify the poisoned data points injected by the adversary and filter them out. Our method is light weight and can be easily integrated into existing systems. Experimental results show that it works very well in filtering out the poisoned data.",
            "output": [
                "Curie: A method for protecting SVM Classifier from Poisoning Attack"
            ]
        },
        {
            "id": "task1540-1181b2e2d75b4a6db06a2a1d4271a58f",
            "input": "As artificial agents proliferate, it is becoming increasingly important to ensure that their interactions with one another are well-behaved. In this paper, we formalize a common-sense notion of when algorithms are well-behaved: an algorithm is safe if it does no harm. Motivated by recent progress in deep learning, we focus on the specific case where agents update their actions according to gradient descent. The first result is that gradient descent converges to a Nash equilibrium in safe games. The paper provides sufficient conditions that guarantee safe interactions. The main contribution is to define strongly-typed agents and show they are guaranteed to interact safely. A series of examples show that strong-typing generalizes certain key features of convexity and is closely related to blind source separation. The analysis introduce a new perspective on classical multilinear games based on tensor decomposition.",
            "output": [
                "Strongly-Typed Agents are Guaranteed to Interact Safely"
            ]
        },
        {
            "id": "task1540-3f030bde72954ee9b7ee222bf8d10bf2",
            "input": "The Kaldi 1 toolkit is becoming popular for constructing automated speech recognition (ASR) systems. Meanwhile, in recent years, deep neural networks (DNNs) have shown state-of-the-art performance on various ASR tasks. This document describes our recipes to implement fully-fledged DNN acoustic modeling using Kaldi and PDNN. PDNN is a lightweight deep learning toolkit developed under the Theano environment. Using these recipes, we can build up multiple systems including DNN hybrid systems, convolutional neural network (CNN) systems and bottleneck feature systems. These recipes are directly based on the Kaldi Switchboard 110-hour setup. However, adapting them to new datasets is easy to achieve.",
            "output": [
                "Kaldi+PDNN: Building DNN-based ASR Systems with Kaldi and PDNN"
            ]
        },
        {
            "id": "task1540-d3fc79b1b3b045e890147fc2e13bd20e",
            "input": "Recently, the rapid development of word embedding and neural networks has brought new inspiration to various NLP and IR tasks. In this paper, we describe a staged hybrid model combining Recurrent Convolutional Neural Networks (RCNN) with highway layers. The highway network module is incorporated in the middle takes the output of the bidirectional Recurrent Neural Network (Bi-RNN) module in the first stage and provides the Convolutional Neural Network (CNN) module in the last stage with the input. The experiment shows that our model outperforms common neural network models (CNN, RNN, Bi-RNN) on a sentiment analysis task. Besides, the analysis of how sequence length influences the RCNN with highway layers shows that our model could learn good representation for the long text.",
            "output": [
                "Learning text representation using recurrent convolutional neural network with highway layers"
            ]
        },
        {
            "id": "task1540-3dfaa4d914c74af3a3702377bb7b07ec",
            "input": "Traditional image clustering methods take a two-step approach, feature learning and clustering, sequentially. However, recent research results demonstrated that combining the separated phases in a unified framework and training them jointly can achieve a better performance. In this paper, we first introduce fully convolutional auto-encoders for image feature learning and then propose a unified clustering framework to learn image representations and cluster centers jointly based on a fully convolutional auto-encoder and soft k-means scores. At initial stages of the learning procedure, the representations extracted from the auto-encoder may not be very discriminative for latter clustering. We address this issue by adopting a boosted discriminative distribution, where high score assignments are highlighted and low score ones are de-emphasized. With the gradually boosted discrimination, clustering assignment scores are discriminated and cluster purities are enlarged. Experiments on several vision benchmark datasets show that our methods can achieve a state-of-the-art performance.",
            "output": [
                "Discriminatively Boosted Image Clustering with Fully Convolutional Auto-Encoders"
            ]
        },
        {
            "id": "task1540-72231651c504413e884458ea096c8480",
            "input": "A currently successful approach to computational semantics is to represent words as embeddings in a machine-learned vector space. We present an ensemble method that combines embeddings produced by GloVe (Pennington et al., 2014) and word2vec (Mikolov et al., 2013) with structured knowledge from the semantic networks ConceptNet (Speer and Havasi, 2012) and PPDB (Ganitkevitch et al., 2013), merging their information into a common representation with a large, multilingual vocabulary. The embeddings it produces achieve state-of-the-art performance on many word-similarity evaluations. Its score of ρ = .596 on an evaluation of rare words (Luong et al., 2013) is 16% higher than the previous best known system.",
            "output": [
                "An Ensemble Method to Produce High-Quality Word Embeddings"
            ]
        },
        {
            "id": "task1540-b0d39ad86fe04330ae78e3f30427a566",
            "input": "More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles. In contrast to traditional, monologic Natural Language Processing resources such as news, highly social dialogue is frequent in social media, making it a challenging context for NLP. This paper tests a bootstrapping method, originally proposed in a monologic domain, to train classifiers to identify two different types of subjective language in dialogue: sarcasm and nastiness. We explore two methods of developing linguistic indicators to be used in a first level classifier aimed at maximizing precision at the expense of recall. The best performing classifier for the first phase achieves 54% precision and 38% recall for sarcastic utterances. We then use general syntactic patterns from previous work to create more general sarcasm indicators, improving precision to 62% and recall to 52%. To further test the generality of the method, we then apply it to bootstrapping a classifier for nastiness dialogic acts. Our first phase, using crowdsourced nasty indicators, achieves 58% precision and 49% recall, which increases to 75% precision and 62% recall when we bootstrap over the first level with generalized syntactic patterns.",
            "output": [
                "Really? Well. Apparently Bootstrapping Improves the Performance of Sarcasm and Nastiness Classifiers for Online Dialogue"
            ]
        },
        {
            "id": "task1540-6c6754d912a14331ac8b6c4459ab7a97",
            "input": "The Teacher Forcing algorithm trains recurrent networks by supplying observed sequence values as inputs during training and using the network’s own one-stepahead predictions to do multi-step sampling. We introduce the Professor Forcing algorithm, which uses adversarial domain adaptation to encourage the dynamics of the recurrent network to be the same when training the network and when sampling from the network over multiple time steps. We apply Professor Forcing to language modeling, vocal synthesis on raw waveforms, handwriting generation, and image generation. Empirically we find that Professor Forcing acts as a regularizer, improving test likelihood on character level Penn Treebank and sequential MNIST. We also find that the model qualitatively improves samples, especially when sampling for a large number of time steps. This is supported by human evaluation of sample quality. Trade-offs between Professor Forcing and Scheduled Sampling are discussed. We produce T-SNEs showing that Professor Forcing successfully makes the dynamics of the network during training and sampling more similar.",
            "output": [
                "Professor Forcing: A New Algorithm for Training Recurrent Networks"
            ]
        },
        {
            "id": "task1540-6cc193e89adf4784805c6abccf6bdcd2",
            "input": "We introduce the lifted Generalized Belief Propagation (GBP) message passing algorithm, for the computation of sum-product queries in Probabilistic Relational Models (e.g. Markov logic network). The algorithm forms a compact region graph and establishes a modified version of message passing, which mimics the GBP behavior in a corresponding ground model. The compact graph is obtained by exploiting a graphical representation of clusters, which reduces cluster symmetry detection to isomorphism tests on small local graphs. The framework is thus capable of handling complex models, while remaining domain-size independent.",
            "output": [
                "Lifted Message Passing for the Generalized Belief Propagation"
            ]
        },
        {
            "id": "task1540-cd6727f41d69429c9b050b4b5e1c3c95",
            "input": "A perfectly rational decision-maker chooses the best action with the highest utility gain from a set of possible actions. The optimality principles that describe such decision processes do not take into account the computational costs of finding the optimal action. Bounded rational decision-making addresses this problem by specifically trading off information-processing costs and expected utility. Interestingly, a similar trade-off between energy and entropy arises when describing changes in thermodynamic systems. This similarity has been recently used to describe bounded rational agents. Crucially, this framework assumes that the environment does not change while the decision-maker is computing the optimal policy. When this requirement is not fulfilled, the decision-maker will suffer inefficiencies in utility, that arise because the current policy is optimal for an environment in the past. Here we borrow concepts from non-equilibrium thermodynamics to quantify these inefficiencies and illustrate with simulations its relationship with computational resources.",
            "output": [
                "Bounded Rational Decision-Making in Changing Environments"
            ]
        },
        {
            "id": "task1540-c3aa2946924d4b4780819a2c7a63f9f8",
            "input": "Since the first online demonstration of Neural Machine Translation (NMT) by LISA (Bahdanau et al., 2014), NMT development has recently moved from laboratory to production systems as demonstrated by several entities announcing rollout of NMT engines to replace their existing technologies. NMT systems have a large number of training configurations and the training process of such systems is usually very long, often a few weeks, so role of experimentation is critical and important to share. In this work, we present our approach to production-ready systems simultaneously with release of online demonstrators covering a large variety of languages (12 languages, for 32 language pairs). We explore different practical choices: an efficient and evolutive open-source framework; data preparation; network architecture; additional implemented features; tuning for production; etc. We discuss about evaluation methodology, present our first findings and we finally outline further work. Our ultimate goal is to share our expertise to build competitive production systems for ”generic” translation. We aim at contributing to set up a collaborative framework to speed-up adoption of the technology, foster further research efforts and enable the delivery and adoption to/by industry of use-case specific engines integrated in real production workflows. Mastering of the technology would allow us to build translation engines suited for particular needs, outperforming current simplest/uniform systems.",
            "output": [
                "SYSTRAN’s Pure Neural Machine Translation Systems"
            ]
        },
        {
            "id": "task1540-14ee3a8c578444d892d483c2694eaed3",
            "input": "We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypotheses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with maintaining version spaces, yet still allows for substantial improvements over supervised learning for classification.",
            "output": [
                "Agnostic Active Learning Without Constraints"
            ]
        },
        {
            "id": "task1540-5ba63c4dbffd487baff7626a536bf4f1",
            "input": "Near-data processing (NDP) refers to augmenting memory or storage with processing power. Despite its potential for acceleration computing and reducing power requirements, only limited progress has been made in popularizing NDP for various reasons. Recently, two major changes have occurred that have ignited renewed interest and caused a resurgence of NDP. The first is the success of machine learning (ML), which often demands a great deal of computation for training, requiring frequent transfers of big data. The second is the popularity of NAND flash-based solid-state drives (SSDs) containing multicore processors that can accommodate extra computation for data processing. In this paper, we evaluate the potential of NDP for ML using a new SSD platform that allows us to simulate instorage processing (ISP) of ML workloads. Our platform (named ISP-ML) is a full-fledged simulator of a realistic multi-channel SSD that can execute various ML algorithms using data stored in the SSD. To conduct a thorough performance analysis and an in-depth comparison with alternative techniques, we focus on a specific algorithm: stochastic gradient descent (SGD), which is the de facto standard for training differentiable models such as logistic regression and neural networks. We implement and compare three SGD variants (synchronous, Downpour, and elastic averaging) using ISP-ML, exploiting the multiple NAND channels to parallelize SGD. In addition, we compare the performance of ISP and that of conventional in-host processing, revealing the advantages of ISP. Based on the advantages and limitations identified through our experiments, we further discuss directions for future research on ISP for accelerating ML.",
            "output": [
                "Near-Data Processing for Differentiable Machine Learning Models"
            ]
        },
        {
            "id": "task1540-7fb93f4307bb4aab99c4495acdb4f030",
            "input": "We introduce a new type of graphical model that we call a “memory factor network” (MFN). We show how to use MFNs to model the structure inherent in many types of data sets. We also introduce an associated message-passing style algorithm called “proactive message passing” (PMP) that performs inference on MFNs. PMP comes with convergence guarantees and is efficient in comparison to competing algorithms such as variants of belief propagation. We specialize MFNs and PMP to a number of distinct types of data (discrete, continuous, labelled) and inference problems (interpolation, hypothesis testing), provide examples, and discuss approaches for efficient implementation.",
            "output": [
                "Proactive Message Passing on Memory Factor Networks Proactive Message Passing on Memory Factor Networks"
            ]
        },
        {
            "id": "task1540-787a8a009b0a42119eba6e987b548b81",
            "input": "The Correlation Filter is an algorithm that trains a linear template to discriminate between images and their translations. It is well suited to object tracking because its formulation in the Fourier domain provides a fast solution, enabling the detector to be re-trained once per frame. Previous works that use the Correlation Filter, however, have adopted features that were either manually designed or trained for a different task. This work is the first to overcome this limitation by interpreting the Correlation Filter learner, which has a closed-form solution, as a differentiable layer in a deep neural network. This enables learning deep features that are tightly coupled to the Correlation Filter. Experiments illustrate that our method has the important practical benefit of allowing lightweight architectures to achieve state-of-the-art performance at high framerates.",
            "output": [
                "End-to-end representation learning for Correlation Filter based tracking"
            ]
        },
        {
            "id": "task1540-b43752ab34b940f39a1cb7f59524599e",
            "input": "In this paper, we introduce a new notion of algorithmic stability called typical stability. When our goal is to release real-valued queries (statistics) computed over a dataset, this notion does not require the queries to be of bounded sensitivity – a condition that is generally assumed under a standard notion of algorithmic stability known as differential privacy [DMNS06, Dwo06]. Instead, typical stability requires the output of the query, when computed on a dataset drawn from the underlying distribution, to be “well-concentrated” around its expected value with respect to that distribution. Typical stability can also be motivated as an alternative definition for database privacy (in such case, we call it typical privacy). Like differential privacy, this notion enjoys several important properties including robustness to post-processing and adaptive composition. We also discuss the guarantees of typical stability on the generalization error (i.e., the difference between the value of the query computed on the dataset and the expected value of the query with respect to the true data distribution). We show that these guarantees hold for a broader class of queries than that of bounded-sensitivity queries. This class contains all queries whose output distributions have a “light” tail, e.g., subgaussian and subexponential queries. In particular, we show that if a typically stable interaction with a dataset yields a query from that class, then this query when evaluated on the same dataset will have small generalization error with high probability (i.e., it will not overfit to the dataset). We discuss the composition guarantees of typical stability and prove a composition theorem that gives a characterization of the degradation of the parameters of typical stability/privacy under k-fold adaptive composition. We also give simple noise-addition algorithms that achieve this notion. These algorithms are similar to their differentially private counterparts, however, the added noise is calibrated differently. ∗University of California San Diego, Center for Information Theory and Applications and Department of Computer Science and Engineering. rbassily@ucsd.edu †University of California San Diego, Department of Computer Science and Engineering. yfreund@eng.ucsd.edu ar X iv :1 60 4. 03 33 6v 1 [ cs .L G ] 1 2 A pr 2 01 6",
            "output": [
                "Typicality-Based Stability and Privacy"
            ]
        },
        {
            "id": "task1540-9e4f4ea6d194479cb1558933769ef0d7",
            "input": "Sentiment analysis (SA) using code-mixed data from social media has several applications in opinion mining ranging from customer satisfaction to social campaign analysis in multilingual societies. Advances in this area are impeded by the lack of a suitable annotated dataset. We introduce a Hindi-English (Hi-En) code-mixed dataset for sentiment analysis and perform empirical analysis comparing the suitability and performance of various state-of-the-art SA methods in social media. In this paper, we introduce learning sub-word level representations in LSTM (Subword-LSTM) architecture instead of character-level or word-level representations. This linguistic prior in our architecture enables us to learn the information about sentiment value of important morphemes. This also seems to work well in highly noisy text containing misspellings as shown in our experiments which is demonstrated in morpheme-level feature maps learned by our model. Also, we hypothesize that encoding this linguistic prior in the Subword-LSTM architecture leads to the superior performance. Our system attains accuracy 4-5% greater than traditional approaches on our dataset, and also outperforms the available system for sentiment analysis in Hi-En code-mixed text by 18%.",
            "output": [
                "Towards Sub-Word Level Compositions for Sentiment Analysis of Hindi-English Code Mixed Text"
            ]
        },
        {
            "id": "task1540-0505dd3ae4ef47d5ac7274a6ac73b5eb",
            "input": "Understanding the ways in which information achieves widespread public awareness is a research question of significant interest. We consider whether, and how, the way in which the information is phrased — the choice of words and sentence structure — can affect this process. To this end, we develop an analysis framework and build a corpus of movie quotes, annotated with memorability information, in which we are able to control for both the speaker and the setting of the quotes. We find significant differences between memorable and non-memorable quotes in several key dimensions. One is lexical distinctiveness: in aggregate, memorable quotes use less common word choices, but at the same time are built upon a scaffolding of common syntactic patterns; another is that memorable quotes tend to be more general in ways that make them easy to apply in new contexts. We also show how the concept of “memorable language” can be extended across domains. To appear at ACL 2012 1 Hello. My name is Inigo Montoya. Understanding what items will be retained in the public consciousness, and why, is a question of fundamental interest in many domains, including marketing, politics, entertainment, and social media; as we all know, many items barely register, whereas others catch on and take hold in many people’s minds. An active line of recent computational work has employed a variety of perspectives on this question. Building on a foundation in the sociology of diffusion [27, 31], researchers have explored the ways in which network structure affects the way information spreads, with domains of interest including blogs [1, 11], email [37], on-line commerce [22], and social media [2, 28, 33, 38]. There has also been recent research addressing temporal aspects of how different media sources convey information [23, 30, 39] and ways in which people react differently to information on different topics [28, 36]. Beyond all these factors, however, one’s everyday experience with these domains suggests that the way in which a piece of information is expressed — the choice of words, the way it is phrased — might also have a fundamental effect on the extent to which it takes hold in people’s minds. Concepts that attain wide reach are often carried in messages such as political slogans, marketing phrases, or aphorisms whose language seems intuitively to be memorable, “catchy,” or otherwise compelling. Our first challenge in exploring this hypothesis is to develop a notion of “successful” language that is precise enough to allow for quantitative evaluation. We also face the challenge of devising an evaluation setting that separates the phrasing of a message from the conditions in which it was delivered — highlycited quotes tend to have been delivered under compelling circumstances or fit an existing cultural, political, or social narrative, and potentially what appeals to us about the quote is really just its invocation of these extra-linguistic contexts. Is the form of the language adding an effect beyond or independent of these (obviously very crucial) factors? To investigate the question, one needs a way of controlar X iv :1 20 3. 63 60 v1 [ cs .C L ] 2 8 M ar 2 01 2 ling — as much as possible — for the role that the surrounding context of the language plays. The present work (i): Evaluating language-based memorability Defining what makes an utterance memorable is subtle, and scholars in several domains have written about this question. There is a rough consensus that an appropriate definition involves elements of both recognition — people should be able to retain the quote and recognize it when they hear it invoked — and production — people should be motivated to refer to it in relevant situations [15]. One suggested reason for why some memes succeed is their ability to provoke emotions [16]. Alternatively, memorable quotes can be good for expressing the feelings, mood, or situation of an individual, a group, or a culture (the zeitgeist): “Certain quotes exquisitely capture the mood or feeling we wish to communicate to someone. We hear them ... and store them away for future use” [10]. None of these observations, however, serve as definitions, and indeed, we believe it desirable to not pre-commit to an abstract definition, but rather to adopt an operational formulation based on external human judgments. In designing our study, we focus on a domain in which (i) there is rich use of language, some of which has achieved deep cultural penetration; (ii) there already exist a large number of external human judgments — perhaps implicit, but in a form we can extract; and (iii) we can control for the setting in which the text was used. Specifically, we use the complete scripts of roughly 1000 movies, representing diverse genres, eras, and levels of popularity, and consider which lines are the most “memorable”. To acquire memorability labels, for each sentence in each script, we determine whether it has been listed as a “memorable quote” by users of the widely-known IMDb (the Internet Movie Database), and also estimate the number of times it appears on the Web. Both of these serve as memorability metrics for our purposes. When we evaluate properties of memorable quotes, we compare them with quotes that are not assessed as memorable, but were spoken by the same character, at approximately the same point in the same movie. This enables us to control in a fairly fine-grained way for the confounding effects of context discussed above: we can observe differences that persist even after taking into account both the speaker and the setting. In a pilot validation study, we find that human subjects are effective at recognizing the more IMDbmemorable of two quotes, even for movies they have not seen. This motivates a search for features intrinsic to the text of quotes that signal memorability. In fact, comments provided by the human subjects as part of the task suggested two basic forms that such textual signals could take: subjects felt that (i) memorable quotes often involve a distinctive turn of phrase; and (ii) memorable quotes tend to invoke general themes that aren’t tied to the specific setting they came from, and hence can be more easily invoked for future (out of context) uses. We test both of these principles in our analysis of the data. The present work (ii): What distinguishes memorable quotes Under the controlled-comparison setting sketched above, we find that memorable quotes exhibit significant differences from nonmemorable quotes in several fundamental respects, and these differences in the data reinforce the two main principles from the human pilot study. First, we show a concrete sense in which memorable quotes are indeed distinctive: with respect to lexical language models trained on the newswire portions of the Brown corpus [21], memorable quotes have significantly lower likelihood than their nonmemorable counterparts. Interestingly, this distinctiveness takes place at the level of words, but not at the level of other syntactic features: the part-ofspeech composition of memorable quotes is in fact more likely with respect to newswire. Thus, we can think of memorable quotes as consisting, in an aggregate sense, of unusual word choices built on a scaffolding of common part-of-speech patterns. We also identify a number of ways in which memorable quotes convey greater generality. In their patterns of verb tenses, personal pronouns, and determiners, memorable quotes are structured so as to be more “free-standing,” containing fewer markers that indicate references to nearby text. Memorable quotes differ in other interesting aspects as well, such as sound distributions. Our analysis of memorable movie quotes suggests a framework by which the memorability of text in a range of different domains could be investigated. We provide evidence that such cross-domain properties may hold, guided by one of our motivating applications in marketing. In particular, we analyze a corpus of advertising slogans, and we show that these slogans have significantly greater likelihood at both the word level and the part-of-speech level with respect to a language model trained on memorable movie quotes, compared to a corresponding language model trained on non-memorable movie quotes. This suggests that some of the principles underlying memorable text have the potential to apply across different areas. Roadmap §2 lays the empirical foundations of our work: the design and creation of our movie-quotes dataset, which we make publicly available (§2.1), a pilot study with human subjects validating IMDbbased memorability labels (§2.2), and further study of incorporating search-engine counts (§2.3). §3 details our analysis and prediction experiments, using both movie-quotes data and, as an exploration of cross-domain applicability, slogans data. §4 surveys related work across a variety of fields. §5 briefly summarizes and indicates some future directions. 2 I’m ready for my close-up.",
            "output": [
                "You had me at hello: How phrasing affects memorability"
            ]
        },
        {
            "id": "task1540-55077fe95e3742ff8db5c9f92c32549c",
            "input": "We propose a new algorithm for topic modeling, Vec2Topic, that identifies the main topics in a corpus using semantic information captured via high-dimensional distributed word embeddings. Our technique is unsupervised and generates a list of topics ranked with respect to importance. We find that it works better than existing topic modeling techniques such as Latent Dirichlet Allocation for identifying key topics in user-generated content, such as emails, chats, etc., where topics are diffused across the corpus. We also find that Vec2Topic works equally well for non-user generated content, such as papers, reports, etc., and for small corpora such as a single-document.",
            "output": [
                "Topic Modeling Using Distributed Word Embeddings"
            ]
        },
        {
            "id": "task1540-1aa0336b774c44bda5ed521fa5d60257",
            "input": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies of multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model’s ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.",
            "output": [
                "VARIATIONAL RECURRENT ADVERSARIAL DEEP DOMAIN ADAPTATION"
            ]
        },
        {
            "id": "task1540-667e411d7d644f89b9d0290bd76b61f6",
            "input": "A recommender system is an information filtering technology which can be used to predict preference ratings of items (products, services, movies, etc) and/or to output a ranking of items that are likely to be of interest to the user. Context-aware recommender systems (CARS) learn and predict the tastes and preferences of users by incorporating available contextual information in the recommendation process. One of the major challenges in context-aware recommender systems research is the lack of automatic methods to obtain contextual information for these systems. Considering this scenario, in this paper, we propose to use contextual information from topic hierarchies of the items (web pages) to improve the performance of context-aware recommender systems. The topic hierarchies are constructed by an extension of the LUPI-based Incremental Hierarchical Clustering method that considers three types of information: traditional bag-of-words (technical information), and the combination of named entities (privileged information I) with domain terms (privileged information II). We evaluated the contextual information in four context-aware recommender systems. Different weights were assigned to each type of information. The empirical results demonstrated that topic hierarchies with the combination of the two kinds of privileged information can provide better recommendations. Keywords—Contextual Information; Context-Aware Recommender Systems; Text Mining; Topic Hierarchy; Named Entities; Domain Terms",
            "output": [
                "Combining Privileged Information to Improve Context-Aware Recommender Systems"
            ]
        },
        {
            "id": "task1540-e85f6afdbe2145eabf33038cd8c5a2c1",
            "input": "ions of these networks, eg, cube on cube (The Society of Mind by Marvin Minsky, MIT, 1985) and “learning” mechanisms (The Organization of Behavior by Donald O Hebb, 1949) may not constitute intelligence. These processes populate fields with values from the user environment which can be selectively used (per contra hard coded defined sets). For example, NEST Learning Thermostat uses input values to tune your preferred temperatures. Page 2 ● I am an AI optimist. My article on AI (Agents: Where Artificial Intelligence Meets Natural Stupidity) is here http://dspace.mit.edu/handle/1721.1/41914 (2002) ▪ Dr Shoumen Palit Austin Datta, Research Affiliate, MIT Auto-ID Labs, Department of Mechanical Engineering, MIT ▪ Please explore website http://autoid.mit.edu Is Intelligence an Illusion in Artificial Intelligence? It’s better to keep your mouth closed and be thought a fool than to open your mouth and remove all doubt ● Twain Elements of the equation/rule -based (brittle and static) structures caused the bust of the expert systems and ended The AI Business (Winston and Prendergast, MIT, 1984) lure before the rise of artificial neural networks (ANN popularity circa 1990). Topology and synaptic weights, if combined, offered a flexible infrastructure to acquire more relevant values and profit from data. This is an important advancement. But, is it really intelligence? Rather than partial differential equations exploding due to increase in state functions (due to the large number of parameters), Agents allowed each variable to be represented as a single-function entity. The collective output from an Agency of Agents improved predictive or prescriptive precision compared to operations research applications (see illustration below). The behavior of Agents and Agencies using “AI” concepts originated from the foundation laid by the principles of stigmergy (Pierre-Paul Grasse, 1959) which continues to evolve as artificial life and are able to address complex business problems. The recent surge in the hype associated with “big data” has navigated profitability from analytics to the front and center. Intelligence is marketed as a commodity in this scenario. In order to market intelligence as a service, the AI paradigm is being refurbished as a commodity (brain in a box) and touted to business and industry as an essential tool to reach the luminous summit [$]. Winning at games using ANN is advocated as intelligence. Smart and intelligence are emerging as speculative tabloid fodder. Witnessing the rapid transmutation of tabloid fodder about speculation to (business) truth is deeply troubling. Claims about “original” thinking in containerization of data and process are good ideas but appeared as concepts proposed almost half a century ago by Marvin Minsky (page 315 in the original book or search page 311 in this PDF version of the book). Connecting entities (containers) using IPv6 resonates with ideas suggested about a decade ago. However, it is reassuring that the concepts are not lost but are being developed to advance the march of digital transformation (see Digital Twins https://dspace.mit.edu/handle/1721.1/104429). Page 3 ● I am an AI optimist. My article on AI (Agents: Where Artificial Intelligence Meets Natural Stupidity) is here http://dspace.mit.edu/handle/1721.1/41914 (2002) ▪ Dr Shoumen Palit Austin Datta, Research Affiliate, MIT Auto-ID Labs, Department of Mechanical Engineering, MIT ▪ Please explore website http://autoid.mit.edu Is Intelligence an Illusion in Artificial Intelligence? It’s better to keep your mouth closed and be thought a fool than to open your mouth and remove all doubt ● Twain Is Learning a Myth in “Human-level” AI Systems? I cannot improve the content from Rodney Brooks, hence, I shall quote verbatim as follows: “We have found a way to build fixed topology networks of our finite state machines which can perform learning, as an isolated subsystem, at levels comparable to these examples. At the moment of course we are in the very position we lambasted most AI workers for earlier in this paper. We have an isolated module of a system working and the inputs and outputs have been left dangling.” (Intelligence without Representation, 1991) Learning triggers profound, sustained, often long term changes in our neural networks at many levels that we cannot even begin to understand or grasp its cognitive repercussions. Thus, almost all assumptions made by McCulloch & Pitts (1943) are violated (Appendix 1). The “all or none” phenomena assumed by McCulloch & Pitts (1943) is only relevant from a mechanical perspective if one assumes (incorrectly, of course) that input data is supposed to transduce a signal and the resultant action potential (neuronal activation) may be one form of a proof of learning. Neurologists will strenuously and vociferously take exception. AI experts may wish adopt this view to claim learning in the AI context. The neurological state of learning, cognition and behavior is usually a continuous function modulated by evolutionary weights, which are not subject, in the least, to the limitations of discrete-state machines. Application of machine learning models are often inconsistent and incorrect. Discrete systems have a finite (countable) number of states which may be described in precise mathematical models. The computer is a finite state machine which may be viewed as a discrete system. The brain is not a computer. The neural infrastructure and networks are not finite state machines. Imposing any such model (real-world continuous systems) or ill-advised abstraction or gross extrapolation (by those not so well informed) may only perpetrate great lengths of fantasy about intelligence and learning related to AI systems. “Of the vast stream of sense data that pour into our nervous systems we are aware of few and we name still fewer. For it is the fact that even percepta are wordless. Only by necessity do we put a vocabulary to what we touch, see, taste, and smell, and to such sounds as we hear that are not themselves words. We look at a landscape, at the rich carving and majestic architecture of a cathedral, listen to the development of harmonies in a symphony, or admire special skill in games and find ourselves woefully lacking in ability to describe our percepts. Words, as we very rightly say, fail us either to describe the plain facts of these experiences or to impart to others, our feelings.” (G Jefferson CBE, FRS, MS, FRCS, Professor of Neurosurgery in The Mind of Mechanical Man in British Medical Journal, 25th June 1949). The author was aware of “Dr Wiener of Boston, his entertaining book Cybernetics (1948).” Page 4 ● I am an AI optimist. My article on AI (Agents: Where Artificial Intelligence Meets Natural Stupidity) is here http://dspace.mit.edu/handle/1721.1/41914 (2002) ▪ Dr Shoumen Palit Austin Datta, Research Affiliate, MIT Auto-ID Labs, Department of Mechanical Engineering, MIT ▪ Please explore website http://autoid.mit.edu Is Intelligence an Illusion in Artificial Intelligence? It’s better to keep your mouth closed and be thought a fool than to open your mouth and remove all doubt ● Twain Alan Turing was cognizant of the over-reach in claiming “intelligence” in AI and outlined potential objections including Godel's theorem (mathematical objection) and “Argument from Consciousness” which he reproduced from Professor Geoffrey Jefferson as a quote (from his Lister Oration, 1949) \"Not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt, and not by the chance fall of symbols, could we agree that machine equals brain that is not only write it but know that it had written it. No mechanism could feel (and not merely artificially signal, an easy contrivance) pleasure at its successes, grief when its valves fuse, be warmed by flattery, be made miserable by its mistakes, be charmed by sex, be angry or depressed when it cannot get what it wants.\" A. M. Turing (1950) Computing Machinery and Intelligence. Mind 49 433-460 (PDF) Page 452 (see Appendix 2) removes any doubt that Turing had grave doubts regarding claims of intelligence in the context of computers. Turing’s suggested starting point is “the child machine” (Appendix 2). Then he proposes to add the roles or processes of “evolution” “hereditary material” “mutation” “education” and “natural selection” in order to mature “the child machine” to “imitate an adult human mind” as a path forward to intelligence. To understand even vaguely what happens after “the initial state of mind, say at birth” the reader is urged to review Patterns in the Mind by Ray Jackendoff (1966) and then take into consideration the field of linguistics and natural language development (1970, PhD thesis of Terry Winograd, MIT http://hci.stanford.edu/winograd/shrdlu/AITR-235.pdf). For all this to happen, we must process information encoded via developmental and environmental signals. Hence, the suggestion, research and convergence on the concept of molecular logic gates. The complexity of the process may help deter one from concluding that we are dealing with intelligence with respect to computers, machinery or AI systems. However, the human spirit and the fabric of scientific research cannot step away from problems even if all available reason suggests that something is impossible, at the time. It is with this fervor the 1956 Dartmouth Summer Research Project on Artificial Intelligence (June 17 August 16) was proposed in 1955 by a visionary group of eminent and erudite academic scholars (www.aaai.org/ojs/index.php/aimagazine/article/view/1904/1802). The proposal (see Appendix 3) admits it is a “conjecture” but continued “that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.” Great strides (Appendix 4) have been made, yet the 1956 Summer Research “conjecture” looms overhead. But, our “faith” in progress of AI is evident from the 1145 page book by Russell and Norvig (AI A Modern Approach, 3rd ed). We are learning how decisions can be made without a brain in cognitive organisms (unicellular mould Physarum polycephalum). Page 5 ● I am an AI optimist. My article on AI (Agents: Where Artificial Intelligence Meets Natural Stupidity) is here http://dspace.mit.edu/handle/1721.1/41914 (2002) ▪ Dr Shoumen Palit Austin Datta, Research Affiliate, MIT Auto-ID Labs, Department of Mechanical Engineering, MIT ▪ Please explore website http://autoid.mit.edu Is Intelligence an Illusion in Artificial Intelligence? It’s better to keep your mouth closed and be thought a fool than to open your mouth and remove all doubt ● Twain Neurobiology 101 neurons their numbers and networks Topology and weights are the foundational underpinnings of artificial neural nets (ANN) which are the mainstay of AI systems. How reliable are these extrapolations? Are we still talking about AI? Let me reiterate what Rodney Brooks has stated but in a different vein. Structural design of network topology aims to mimic the commonly observed organization of neurons. Topology based on neural organization (small world networks) may be fraught with errors as evidenced by studies on wiring configuration and neuroanatomical analysis which reveals differences in circuit architecture and connectivity if viewed at mesoscopic vs microscopic scale. On a mesoscopic scale, seemingly random networks exhibit consistent properties. It may be difficult, if not impossible, to extract useful/meaningful abstractions from these counter-intuitive non-linear yet dynamic structure-function complementarities. In ANN, weights are assigned to signify connectivity strengths (the links between the perceptrons). These are arbitrary, at best, because synaptic weights between neurons and clusters are subjected to conditions that we think we know only by name. Even if one acquired neurophysiological data related to frequency variations of action potentials (~200 Hertz) in an attempt to understand synaptic weights between neurons, the results may not be revealing. The complexity may be compounded by the fact nerve transmissions are modified by ions, electrical threshold potential and chemical neuro-transmitters. In synaptic design, one assumes the all-or-none process (Appendix 1) and the weights are modeled based on extrapolation from “inferential changes” which are in the order of milliseconds to seconds (hence, subject to observation, data collection and extrapolation). But, the nature of the connectivity and resultant weight is also influenced by epigenetic factors (time scale – seconds to days), ontogenic factors (days to years) and phylogenetic factors which are the result of generations or are derived from the evolutionary time scale, as noted in Appendix 2. Hence, the nature of the weight deduced from “inferential” changes (primarily sense and response mechanisms) are only the tip of the iceberg. We are almost completely in the dark about the nature of the influence from these other three factors. Taken together, perhaps we are starting out on the wrong foot about the design of ANN by holding on to assumptions which are generally incorrect because we remain significantly uninformed. Having said that, one must hasten to add, that, no matter how approximately correct the synthetic weights, may be, it may not be impossible to conceive building ANNs with partially unqualified numbers and unsure topologies. Using tools eg back propagation algorithms, the AI system may be tuned and re-tuned in a dynamic data-driven manner (some may still refer to it as “learning”) to yield actionable information from higher order systems. Over-fitting the model may cause harm, for example, collision avoidance systems. Page 6 ● I am an AI optimist. My article on AI (Agents: Where Artificial Intelligence Meets Natural Stupidity) is here http://dspace.mit.edu/handle/1721.1/41914 (2002) ▪ Dr Shoumen Palit Austin Datta, Research Affiliate, MIT Auto-ID Labs, Department of Mechanical Engineering, MIT ▪ Please explore website http://autoid.mit.edu Is Intelligence an Illusion in Artificial Intelligence? It’s better to keep your mouth closed and be thought a fool than to open your mouth and remove all doubt ● Twain Scholars continue to discuss new ways of using robots to make robots, create self-healing intelligent machines and adaptive machines to optimize up-time. Thinkers are conjuring up ways to harness the developmental foundations of neurons – neurogenesis. Emulation of neural development using computational AI systems can incorporate characteristics of natural neural systems into engineering design. Scientists are claiming that rather than designing neural networks, emulation of neurogenesis shall enable us to generate neural networks to serve dynamic and even more complex systems of the future. This emerging field of programmable artificial neurogenesis appears to call for a metadesign paradigm which may begin with components (object oriented?). It aims to build higher order intelligent systems which will adapt (to demands, environment, resource) without re-programming component level entities. When components are updated, the changes will be propagated, via appropriate “learning” functions, up/down hierarchies. The great desire to emulate the grand vision latent in intelligence, cognition and the brain, works almost as an aphrodisiac. The immense powers of biology and the ability to distil and capture even an iota of that potential in bio-inspired systems through convergence with computation will continue to be a Holy Grail. Here is one example of bio-power: We have about 3 million base pairs (A-T, G-C) in the human genome (3x106) which codes for about 10,000 – 20,000 genes resulting in a human body with 100 trillion cells (1x1014). At least a third of the approximately 20,000 different genes that make up the human genome are active (expressed) in the brain. We have about 8.5x1010 neural cells (there are an equivalent number of glial cells). Each neural cell connects on an average with 1,000 other neural cells to create about 1x1014 neural connections. This is the neural network which makes us human, creates intelligence and cognition. If we may think in terms of a compression ratio, the ratio approaches 1011 (7,000 genes creating 1x1014 connections). The most effective compression algorithm CMIX doesn’t even come close. The illegal 42.zip bomb which unfolds to 4.5 petabytes (pb) from a 42 kilobytes (kb) single symbol zip approaches a compression ratio of 1011 but in an artificial circumstance devoid of any intelligence. The human compression of 1011 offers sustainable, real, life-long intelligence. Conclusion – These ‘intelligent’ machines may never be intelligent in a human sense (p339) A quantum leap, still cryptic within the unknown unknowns, may unleash intelligence in AI, in the future. We must continue to explore far and wide, emulate insects and think about the Octopus. “We can only see a short distance ahead, but we can see plenty there that needs to be done.” Convergence of tools (statistics, math) with data curation (noise vs signal) is replete with promise and profitability even if it lacks (human-level) intelligence. Page 7 ● I am an AI optimist. My article on AI (Agents: Where Artificial Intelligence Meets Natural Stupidity) is here http://dspace.mit.edu/handle/1721.1/41914 (2002) ▪ Dr Shoumen Palit Austin Datta, Research Affiliate, MIT Auto-ID Labs, Department of Mechanical Engineering, MIT ▪ Please explore website http://autoid.mit.edu Is Intelligence an Illusion in Artificial Intelligence? It’s better to keep your mouth closed and be thought a fool than to open your mouth and remove all doubt ● Twain",
            "output": [
                "The Elusive Quest for Intelligence in Artificial Intelligence"
            ]
        },
        {
            "id": "task1540-0bc1856ae330485ba403450a719d5010",
            "input": "We consider the problem of learning good trajectories for manipulation tasks. This is challenging because the criterion defining a good trajectory varies with users, tasks and environments. In this paper, we propose a co-active online learning framework for teaching robots the preferences of its users for object manipulation tasks. The key novelty of our approach lies in the type of feedback expected from the user: the human user does not need to demonstrate optimal trajectories as training data, but merely needs to iteratively provide trajectories that slightly improve over the trajectory currently proposed by the system. We argue that this co-active preference feedback can be more easily elicited from the user than demonstrations of optimal trajectories, which are often challenging and non-intuitive to provide on high degrees of freedom manipulators. Nevertheless, theoretical regret bounds of our algorithm match the asymptotic rates of optimal trajectory algorithms. We demonstrate the generalizability of our algorithm on a variety of grocery checkout tasks, for whom, the preferences were not only influenced by the object being manipulated but also by the surrounding environment.1",
            "output": [
                "Learning Trajectory Preferences for Manipulators via Iterative Improvement"
            ]
        },
        {
            "id": "task1540-a43254aae729496b80eeef970dc19480",
            "input": "Social Internet content plays an increasingly critical role in many domains, including public health, disaster management, and politics. However, its utility is limited by missing geographic information; for example, fewer than 1.6% of Twitter messages (tweets) contain a geotag. We propose a scalable, content-based approach to estimate the location of tweets using a novel yet simple variant of gaussian mixture models. Further, because real-world applications depend on quantified uncertainty for such estimates, we propose novel metrics of accuracy, precision, and calibration, and we evaluate our approach accordingly. Experiments on 13 million global, comprehensively multi-lingual tweets show that our approach yields reliable, well-calibrated results competitive with previous computationally intensive methods. We also show that a relatively small number of training data are required for good estimates (roughly 30,000 tweets) and models are quite time-invariant (effective on tweets many weeks newer than the training set). Finally, we show that toponyms and languages with small geographic footprint provide the most useful location signals.",
            "output": [
                "Inferring the Origin Locations of Tweets with Quantitative Confidence"
            ]
        },
        {
            "id": "task1540-2fffbec47c244330a18be55aa49b4813",
            "input": "Discriminative latent-variable models are typically learned using EM or gradient-based optimization, which suffer from local optima. In this paper, we develop a new computationally efficient and provably consistent estimator for a mixture of linear regressions, a simple instance of a discriminative latentvariable model. Our approach relies on a lowrank linear regression to recover a symmetric tensor, which can be factorized into the parameters using a tensor power method. We prove rates of convergence for our estimator and provide an empirical evaluation illustrating its strengths relative to local optimization (EM). Last Modified: June 18, 2013",
            "output": [
                "Spectral Experts for Estimating Mixtures of Linear Regressions"
            ]
        },
        {
            "id": "task1540-ff9fee13dcfc46358adc8c823a1bdb81",
            "input": "Task-oriented dialogue focuses on conversational agents that participate in userinitiated dialogues on domain-specific topics. In contrast to chatbots, which simply seek to sustain open-ended meaningful discourse, existing task-oriented agents usually explicitly model user intent and belief states. This paper examines bypassing such an explicit representation by depending on a latent neural embedding of state and learning selective attention to dialogue history together with copying to incorporate relevant prior context. We complement recent work by showing the effectiveness of simple sequence-to-sequence neural architectures with a copy mechanism. Our model outperforms more complex memory-augmented models by 7% in per-response generation and is on par with the current state-of-the-art on DSTC2.",
            "output": [
                "A Copy-Augmented Sequence-to-Sequence Architecture Gives Good Performance on Task-Oriented Dialogue"
            ]
        },
        {
            "id": "task1540-b5c256581eb4417e91570ec636b187c4",
            "input": "To harness modern multicore processors, it is imperative to develop parallel versions of fundamental algorithms. In this paper, we compare different approaches to parallel best-first search in a shared-memory setting. We present a new method, PBNF, that uses abstraction to partition the state space and to detect duplicate states without requiring frequent locking. PBNF allows speculative expansions when necessary to keep threads busy. We identify and fix potential livelock conditions in our approach, proving its correctness using temporal logic. Our approach is general, allowing it to extend easily to suboptimal and anytime heuristic search. In an empirical comparison on STRIPS planning, grid pathfinding, and sliding tile puzzle problems using 8-core machines, we show that A*, weighted A* and Anytime weighted A* implemented using PBNF yield faster search than improved versions of previous parallel search proposals.",
            "output": [
                "Best-First Heuristic Search for Multicore Machines"
            ]
        },
        {
            "id": "task1540-d40ef7c5847f449f97c2eea94406d81b",
            "input": "A large body of work in machine learning has focused on the problem of learning a close approximation to an underlying combinatorial function, given a small set of labeled examples. However, for real-valued functions, cardinal labels might not be accessible, or it may be difficult for an expert to consistently assign real-valued labels over the entire set of examples. For instance, it is notoriously hard for consumers to reliably assign values to bundles of merchandise. Instead, it might be much easier for a consumer to report which of two bundles she likes better. With this motivation in mind, we consider an alternative learning model, wherein the algorithm must learn the underlying function up to pairwise comparisons, from pairwise comparisons. In this model, we present a series of novel algorithms that learn over a wide variety of combinatorial function classes. These range from graph functions to broad classes of valuation functions that are fundamentally important in microeconomic theory, the analysis of social networks, and machine learning, such as coverage, submodular, XOS, and subadditive functions, as well as functions with sparse Fourier support.",
            "output": [
                "Learning Combinatorial Functions from Pairwise Comparisons"
            ]
        },
        {
            "id": "task1540-fad4e8a5f17d4c889e129015f4574630",
            "input": "In the existing evidential networks with belief functions, the relations among the variables are always represented by joint belief functions on the product space of the involved variables. In this paper, we use conditional belief functions to represent such relations in the network and show some relations of these two kinds of representations. We also present a propagation algorithm for such networks. By analyzing the properties of some special evidential networks with conditional belief functions, we show that the reasoning process can be simplified in such",
            "output": [
                "Evidential Reasoning with Conditional Belief Functions"
            ]
        },
        {
            "id": "task1540-6fd6487fa0894c0b80f88b732a251803",
            "input": "In this paper we propose a novel model for unconditional audio generation based on generating one audio sample at a time. We show that our model, which profits from combining memory-less modules, namely autoregressive multilayer perceptrons, and stateful recurrent neural networks in a hierarchical structure is able to capture underlying sources of variations in the temporal sequences over very long time spans, on three datasets of different nature. Human evaluation on the generated samples indicate that our model is preferred over competing models. We also show how each component of the model contributes to the exhibited performance.",
            "output": [
                "SAMPLERNN: AN UNCONDITIONAL END-TO-END NEURAL AUDIO GENERATION MODEL"
            ]
        },
        {
            "id": "task1540-c2ca48b89a184c568cb0c99731e157dd",
            "input": "With applications to many disciplines, the traveling salesman problem (TSP) is a classical computer science optimization problem with applications to industrial engineering, theoretical computer science, bioinformatics, and several other disciplines [2]. In recent years, there have been a plethora of novel approaches for approximate solutions ranging from simplistic greedy to cooperative distributed algorithms derived from artificial intelligence. In this paper, we perform an evaluation and analysis of cornerstone algorithms for the Euclidean TSP. We evaluate greedy, 2opt, and genetic algorithms. We use several datasets as input for the algorithms including a small dataset, a mediumsized dataset representing cities in the United States, and a synthetic dataset consisting of 200 cities to test algorithm scalability. We discover that the greedy and 2-opt algorithms efficiently calculate solutions for smaller datasets. Genetic algorithm has the best performance for optimality for medium to large datasets, but generally have longer runtime. Our implementations is public available 1.",
            "output": [
                "An Empirical Analysis of Approximation Algorithms for the Euclidean Traveling Salesman Problem"
            ]
        },
        {
            "id": "task1540-ff07d1348c1a48c4bb1ccc882318437c",
            "input": "A major challenge in the training of recurrent neural networks is the so-called vanishing or exploding gradient problem. The use of a norm-preserving transition operator can address this issue, but parametrization is challenging. In this work we focus on unitary operators and describe a parametrization using the Lie algebra u(n) associated with the Lie group U(n) of n × n unitary matrices. The exponential map provides a correspondence between these spaces, and allows us to define a unitary matrix using n real coefficients relative to a basis of the Lie algebra. The parametrization is closed under additive updates of these coefficients, and thus provides a simple space in which to do gradient descent. We demonstrate the effectiveness of this parametrization on the problem of learning arbitrary unitary operators, comparing to several baselines and outperforming a recently-proposed lower-dimensional parametrization. We additionally use our parametrization to generalize a recently-proposed unitary recurrent neural network to arbitrary unitary matrices, using it to solve standard long-memory tasks. Introduction While recurrent neural networks (RNNs) are seeing widespread success across many tasks, the fundamental architecture presents challenges to typical training algorithms. In particular, the problem of ‘vanishing/exploding gradients’ (Hochreiter 1991) in gradient-based optimization persists, where gradients either vanish or diverge as one goes deeper into the network, resulting in slow training or numerical instability. The long short-term memory (LSTM) network (Hochreiter and Schmidhuber 1997) was designed to overcome this issue. Recently, the use of norm-preserving operators in the transition matrix the matrix of weights connecting subsequent internal states of the RNN have been explored (Arjovsky, Shah, and Bengio 2016; Mikolov et al. 2015; Le, Jaitly, and Hinton 2015). Using operators with bounded eigenvalue spectrum should, as demonstrated by Arjovsky, Shah, and Bengio (2016), bound the norms of the gradients in the network, assuming an appropriate nonlinearity is applied. Unitary matrices satisfy this requirement and are the focus of this work. Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Imposing unitarity (or orthogonality) on this transition matrix is however challenging for gradient-based optimization methods, as additive updates typically do not preserve unitarity. Solutions include re-unitarizing after each batch, or using a parametrization of unitary matrices closed under addition. In this work we propose a solution in the second category, using results from the theory of Lie algebras and Lie groups to define a general parametrization of unitary matrices in terms of skew-Hermitian matrices (elements of the Lie algebra associated to the Lie group of unitary matrices). As explained in more detail below, elements of this Lie algebra can be identified with unitary matrices, while the algebra is closed under addition, forming a vector space over real numbers. While we are motivated by the issues of RNNs, and we consider an application in RNNs, our primary focus here is on a core question: how can unitary matrices be learned? Assuming the choice of a unitary transition matrix is an appropriate modelling choice, the gradients on this operator should ultimately guide it towards unitarity, if it is possible under the parametrization or learning scheme used. It is therefore useful to know which approach is best. We distil the problem into its simplest form (a learning task described in detail later), so that our findings cannot be confounded by other factors specific to the RNN long-term memory task, before demonstrating our parametrization in that setting. Related work We draw most inspiration from the recent work of Arjovsky, Shah, and Bengio (2016), who proposed a specific parametrization of unitary matrices and demonstrated its utility in standard long-term memory tasks for RNNs. We describe their parametrization here, as we use it later. Citing the difficulty of obtaining a general and efficient parametrization of unitary matrices, they use the fact that the unitary group is closed under matrix multiplication to form a composite operator: U = D3R2FD2ΠR1FD1 (1) where each component is unitary and easily parametrized: • D is a diagonal matrix with entries of the form e, α ∈ R • R is a complex reflection operator; R = I − 2 vv † ‖v‖2 († denotes Hermitian conjugate) ar X iv :1 60 7. 04 90 3v 3 [ st at .M L ] 1 0 Ja n 20 17 • F andF−1 are the Fourier and inverse Fourier transforms (or, in practice, their discrete matrix representations) • Π is a fixed permutation matrix In total, this parametrization has 7n real learnable parameters (2n for each reflection and n for each diagonal operator), so describes a subspace of unitary matrices (which have n real parameters). Nonetheless, they find that an RNN using this operator as its transition matrix outperforms LSTMs on the adding and memory tasks described first in Hochreiter and Schmidhuber (1997). This prompted us to consider other parametrizations of unitary matrices which might be more expressive or interpretable. Mikolov et al. (2015) constrain a part of the transition matrix to be close to the identity, acting as a form of long-term memory store, while Le, Jaitly, and Hinton (2015) initialize it to the identity, and then use ReLUs as non-linearities. Henaff, Szlam, and LeCun (2016) study analytic solutions to the long-term memory task, supporting observations and intuitions that orthogonal (or unitary) matrices would be appropriate as transition matrices for this task. They also study initializations to orthogonal and identity matrices, and consider experiments where an additional term in the loss function encourages an orthogonal solution to the transition matrix, without using an explicit parametrization. Saxe, McClelland, and Ganguli (2014) study exact solutions to learning dynamics in deep networks and find that orthogonal weight initializations at each layer lead to depth-independent learning (thus escaping the vanishing/exploding gradient problem). Interestingly, they attribute this to the eigenvalue spectrum of orthogonal matrices lying on the unit circle. They compare with weights initialized to random, scaled Gaussian values, which preserve norms in expectation (over values of the random matrix) and find orthogonal matrices superior. It therefore appears that preserving norms is not sufficient to stabilize gradients over network depth, but that the eigenvalue spectrum must also be strictly controlled. In a related but separate vein, Krueger and Memisevic (2016) penalize the difference of difference of norms between subsequent hidden states in the network. This is not equivalent to imposing orthogonality of the transition matrix, as the norm of the hidden state may be influenced by the inputs and non-linearities, and their method directly addresses this norm. The theory of Lie groups and Lie algebras has seen most application in machine learning for its use in capturing notions of invariance. For example, Miao and Rao (2007), learn infinitesimal Lie group generators (elements of the Lie algebra) associated with affine transformations of images, corresponding to visual perceptual invariances. This is different to our setting as our generators are already known (we assume the Lie group U(n)) and wish to learn the coefficients of a given transformation relative to that basis set of generators. However, our approach could be extended to the case where the basis of u(n) is unknown, and must be learned. As we find later (appendix B), the choice of basis can impact performance, and so may be an important consideration. Cohen and Welling (2014) learn commutative subgroups of SO(n) (known as toroidal subgroups), motivated by learning the irreducible representations of the symmetry group corresponding to invariant properties of images. Their choice of group parametrization is equivalent to selecting a particular basis of the corresponding Lie algebra, as they describe, but primarily exploit the algebra to understand properties of toroidal subgroups. Tuzel, Porikli, and Meer (2008) perform motion estimation by defining a regression function in terms of a function on the Lie algebra of affine transformations, and then learning this. This is similar to our approach in the sense that they do optimization in the Lie algebra, although as they consider two-dimensional affine transformations only, their parametrization of the Lie algebra is straight forward. Finally, Hazan, Kale, and Warmuth (2016) describe an online learning algorithm for orthogonal matrices – which are the real-valued equivalent to unitary matrices. They also claim that the approach is extends easily to unitary matrices. Structure of this paper We begin with an introduction to the relevant facts and definitions from the theory of Lie groups and Lie algebras, to properly situate this work in its mathematical context. Further exposition is beyond the scope of this paper, and we refer the interested reader to any of the comprehensive introductory texts on the matter. We explain our parametrization in detail and describe a method to calculate the derivative of the matrix exponential a quantity otherwise computationally intractable. Then, we describe a simple but clear experiment designed to test our core question of learning unitary matrices. We compare to an approach using the parametrization of Arjovsky, Shah, and Bengio (2016) and one using polar decomposition to ‘backproject’ to the closest unitary matrix. We use this experimental set-up to probe aspects of our model, studying the importance of the choice of basis (appendix B), and the impact of the restricted parameter set used by one of the alternate approaches. We additionally implement our parametrization in a recurrent neural network as a ‘general unitary RNN’, and evaluate its performance on standard long-memory tasks. The Lie algebra u(n) Basics of Lie groups and Lie algebras A Lie group is a group which is also a differentiable manifold, with elements of the group corresponding to points on the manifold. The group operations (multiplication and inversion) must be smooth maps (infinitely differentiable) back to the group. In this work we consider the group U(n): the set of n × n unitary matrices, with matrix multiplication. These are the complex-valued analogue to orthogonal matrices, satisfying the property U†U = UU† = I (2) where † denotes the conjugate transpose (or Hermitian conjugate). Unitary matrices preserve matrix norms, and have eigenvalues lying on the (complex) unit circle, which is the desired property of the transition matrix in a RNN. The differentiable manifold property of Lie groups opens the door for the study of the Lie algebra. This object is the tangent space to the Lie group at the identity (the group must<lb>have an identity element). Consider a curve through the Lie<lb>group U(n) a one-dimensional subspace parametrized by<lb>a variable t, where U(t = 0) = I (this is a matrix U(t) in<lb>U(n) parametrised by t, not a group). Consider the defin-<lb>ing property of unitary matrices (Equation 2), and take the<lb>derivative along this curve:<lb>U(t)†U(t) = I→ U̇(t)†U(t) + U†(t)U̇(t) = 0 (3)<lb>Taking t→ 0, U(t)→ I, we have<lb>U̇(0)†I + I†U̇(0) = 0⇒ U̇(0)† = −U̇(0) (4)<lb>The elements U̇(0) belong to the Lie algebra. We refer to<lb>this Lie algebra as u(n), and an arbitrary element as L. Then<lb>Equation 4 defines the properites of these Lie algebra ele-<lb>ments; they are n× n skew-Hermitian matrices: L† = −L.<lb>As vector spaces, Lie algebras are closed under addition.<lb>In particular u(n) is a vector space over R, so a real linear<lb>combination of its elements is once again in u(n) (this is also<lb>clear from the definition of skew-Hermitian). We exploit this<lb>fact later.<lb>Lie algebras are also endowed with an operation known as<lb>the Lie bracket, which has many interesting properties, but is<lb>beyond the scope of this work. Lie algebras are interesting<lb>algebraic objects and have been studied deeply, but in this<lb>work we use u(n) because of the exponential map.<lb>Above, it was shown that elements of the algebra can be<lb>derived from the group (considering infinitesimal steps away<lb>from the identity). There is a reverse operation, allowing el-<lb>ements of the group to be recovered from the algebra: this is<lb>the exponential map. In the case of matrix groups, the expo-<lb>nential map is simply the matrix exponential:<lb>exp(L) =<lb>∞<lb>∑ j=0<lb>L<lb>j!<lb>(5)<lb>Very simply, L ∈ u(n), then exp(L) ∈ U(n). While this<lb>map is not in general surjective, it so happens that U(n) is<lb>a compact, connected group and so exp is indeed surjective<lb>(Tao 2011). That is, for any U ∈ U(n), there exists some<lb>L ∈ u(n) such that exp(L) = U . Notably, while orthogonal<lb>matrices also form a Lie group O(n), with associated Lie<lb>algebra o(n) consisting of skew-symmetric matrices, O(n)<lb>is not connected, and so the exponential map can only pro-<lb>duce special orthogonal matrices those with determinant<lb>one SO(n) being the component of O(n) containing the<lb>identity.<lb>Parametrization of U(n) in terms of u(n)<lb>The dimension of u(n) as a real vector space is n. This is<lb>readily derived from noting that an arbitrary n× n complex<lb>matrix has 2n free real parameters, and the requirement of<lb>L† = −L imposes n constraints. So, a set of n linearly-<lb>independent skew-Hermitian matrices defines a basis for the<lb>space;<lb>{Tj}j={1,...,n2}. Then any element L can be written<lb>as<lb>L =<lb>n<lb>∑ j=1<lb>λjTj<lb>(6)<lb>where<lb>{λj}j=1,...,n2 are n real numbers; the coefficients of<lb>L with respect to the basis. Using the exponential map,<lb>U = exp(L) = exp  n<lb>∑ j=1<lb>λjTj <lb>(7)<lb>we see that these<lb>{λj}j=1,...,n2 suffice as parameters of U<lb>(given the basis Tj). This is the parametrization we propose.<lb>It has two attractive properties:<lb>1. It is a fully general parametrization, as the exponential<lb>map is surjective<lb>2. Gradient updates on<lb>{λj}j=1,...,n2 preserve unitarity au-<lb>tomatically, as the algebra is closed under addition<lb>This parametrization means gradient steps are taken in the<lb>vector space of u(n), rather than the manifold of U(n),<lb>which may provide a flatter cost landscape although con-<lb>firming this intuition would require further analysis. This<lb>work is intended to explore the use of this parametrization<lb>for learning arbitrary unitary matrices.<lb>There are many possible choices of basis for u(n). We<lb>went for the following set of sparse matrices:<lb>1. n diagonal, imaginary matrices: Ta is i on the a-th diago-<lb>nal, else zero.<lb>2. n(n−1)<lb>2 symmetric, imaginary matrices with two non-zero<lb>elements, e.g., for n = 2,<lb>(<lb>0 i<lb>i 0<lb>)<lb>3. n(n−1)<lb>2 anti-symmetric, real matrices with two non-zero<lb>elements, e.g., for n = 2,<lb>(<lb>0 1<lb>−1 0<lb>) We explore the effects of choice of basis in appendix B.<lb>Derivatives of the matrix exponential<lb>The matrix exponential appearing in Equation 7 poses an is-<lb>sue for gradient calculations. In general, the derivative of the<lb>matrix exponential does not have a closed-form expression,<lb>so computing gradients is intractable.<lb>In early stages of this work, we used the method of finite<lb>differences to approximate gradients, which would prohibit<lb>its use in larger-scale applications (such as RNNs). In the ap-<lb>pendix we describe an investigation into using random pro-<lb>jections to overcome this limitation, which while promising<lb>turned out to yield minimal benefit.<lb>We therefore sought mathematical solutions to this com-<lb>plexity issue, which we describe here and in further detail in<lb>the appendix. Exploiting the fact that L is skew-Hermitian,<lb>we can derive an analytical expression for the derivative of<lb>U with respect to each of its parameters, negating the need<lb>for finite differences.<lb>This expression takes the form:<lb>∂U<lb>∂λa<lb>= WVaW †<lb>(8)<lb>where W is a unitary matrix of eigenvectors obtained in<lb>the eigenvalue decomposition of U ; U = WDW †, (D =<lb>diag(d1, . . . , dn2 ); di are the eigenvalues of U ). Each Va is a matrix defined component-wise<lb>i = j :Vii = (W<lb>TaW )iie di<lb>(9)<lb>i 6= j :Vij = (W<lb>TaW )ij<lb>(<lb>ei − ej<lb>di − dj<lb>)<lb>(10)<lb>Where Ta is the basis matrix of the Lie algebra in the a-th<lb>direction.<lb>We provide the derivation, based on work<lb>from Kalbfleisch and Lawless (1985) and Jennrich and<lb>Bright (1976) in Appendix A.<lb>We can simplify the expression W<lb>TaW for each Ta, de-<lb>pending on the type of basis element. In these expressions,<lb>wa refers to the a-th row of W.<lb>1. Ta purely imaginary; W<lb>TaW = i · outer(w∗<lb>a,wa)<lb>2. Ta symmetric imaginary, nonzero in positions (r, s) and<lb>(s, r): W<lb>TrsW = i · (outer(w∗<lb>s ,wr) + outer(w∗<lb>r ,ws))<lb>3. Ta antisymmetric real, nonzero in positions (r, s) and<lb>(s, r): W<lb>TrsW = outer(w∗<lb>r ,ws)− outer(w∗<lb>s ,wr)<lb>These expressions follow from the sparsity of the basis and<lb>are derived in appendix A. Thus, we reduce the calculation<lb>of W<lb>TaW from two matrix multplications to at most two<lb>vector outer products.<lb>Overall, we have reduced the cost of calculating gradi-<lb>ents to a single eigenvalue decomposition, and for each pa-<lb>rameter two matrix multiplications (equation 8), one or two<lb>vector outer products, and element-wise multiplication of<lb>two matrices (equations 9, 10). As we see in the RNN ex-<lb>periments, this actually makes our approach faster than the<lb>(restricted)uRNN of (Arjovsky, Shah, and Bengio 2016) for<lb>roughly equivalent numbers of parameters.<lb>Supervised Learning of Unitary Operators<lb>We consider the supervised learning problem of learning the<lb>unitary matrix U that generated a y from x; y = Ux, given<lb>examples of such xs and ys. This is the core learning prob-<lb>lem that needs to be solved for the state-transformation ma-<lb>trix in RNNs. It is similar to the setting considered in Hazan,<lb>Kale, and Warmuth (2016) (they consider an online learning<lb>problem). We compare a number of methods for learning U<lb>at different values of n. We further consider the case where<lb>we have artificially restricted the number of learnable vari-<lb>ables in our parametrization (for the sake of comparison),<lb>and generate a pathological change of basis to demonstrate<lb>the relevance of selecting a good basis (appendix B).<lb>Task<lb>The experimental setup is as follows: we create a n×n uni-<lb>tary matrix U (the next section describes how this is done),<lb>then sample vectors x ∈ C with normally-distributed coef-<lb>ficients. We create yj = Uxj + j where ∼ N (0, σ). The<lb>objective is to recover U from the<lb>{xj ,yj} pairs by min-<lb>imizing the squared Euclidean distance between predicted<lb>and true y values;<lb>U = argmin<lb>U<lb>1<lb>N<lb>N<lb>∑ j<lb>‖ŷj−yj‖ = argmin<lb>U<lb>1<lb>N<lb>N<lb>∑ j<lb>‖Uxj−yj‖<lb>(11)<lb>While this problem is easily solved in the batch setting us-<lb>ing least-squares, we wish to learn U through mini-batch<lb>stochastic gradient descent, to emulate a deep learning sce-<lb>nario.<lb>For each experimental run (a single U ), we generate one<lb>million training<lb>{xj ,yj} pairs, divided into batches of size<lb>20. The test and validation sets both contain 100, 000 ex-<lb>amples. In practice we set σ = 0.01 and use a fixed<lb>learning rate of 0.001. For larger dimensions, we run the<lb>model through the data for multiple epochs, shuffling and<lb>re-batching each time.<lb>All experiments were implemented<lb>in Python. The code is available here:<lb>https://github.com/ratschlab/uRNN. For<lb>the matrix exponential, we use the scipy builtin expm,<lb>which uses Pade approximation (Al-Mohy and Higham<lb>2009). We make use of the fact that iL is Hermitian to use<lb>eigh (also in scipy) to perform eigenvalue decompositions.<lb>Generating the ground-truth unitary matrix<lb>The U we wish to recover is generated by one of three meth-<lb>ods:<lb>1. QR decomposition: we create a n × n complex matrix<lb>with normally-distributed entries and then perform a QR<lb>decomposition, producing a unitary matrix U and an up-<lb>per triangular matrix (which is discarded). This approach<lb>is also used to sample orthogonal matrices in Hazan, Kale,<lb>and Warmuth (2016), noting a result from Stewart (1980)<lb>demonstrating that this is equivalent to sampling from the<lb>appropriate Haar measure.<lb>2. Lie algebra: given the standard basis of u(n), we sam-<lb>ple n normally-distributed real λj to produce U =<lb>exp<lb>(∑<lb>j λjTj<lb>)<lb>3. Unitary composition: we compose parametrized unitary<lb>operators as in Arjovsky, Shah, and Bengio (2016) (Equa-<lb>tion 1). The parameters are sampled as follows: angles in<lb>D come from U(−π, π). The complex reflection vectors<lb>in R come from U(−s, s) where s =<lb>√<lb>6<lb>2n .<lb>We study the effects of this generation method on test-set<lb>loss in a later section. While we find no significant associ-<lb>ation between generation method and learning approach, in<lb>our experiments we nonetheless average over an equal num-<lb>ber of experiments using each method, to compensate for<lb>possible unseen bias.<lb>Approaches<lb>We compare the following approaches for learning U :<lb>1. projection: U is represented as an unconstrained<lb>n × n complex matrix, but after each gradient update we<lb>project it to the closest unitary matrix, using polar decom-<lb>position (Keller 1975). This amounts to 2n real parame-<lb>ters.<lb>2. arjovsky: U is parametrized as in Equation 1, which<lb>comes to 7n real parameters. 3. lie algebra: (we refer to this as u(n)) U is<lb>parametrized by its n real coefficients<lb>{λj} in the Lie<lb>algebra, as in Equation 7.<lb>As baselines we use the true matrix U , and a random<lb>unitary matrix UR generated by the same method as U (in<lb>that experimental run).<lb>We also implemented the algorithm described in Hazan,<lb>Kale, and Warmuth (2016) and considered both unitary and<lb>orthogonal learning tasks (our parametrization contains or-<lb>thogonal matrices as a special case) but found it too numer-<lb>ically unstable and therefore excluded it from our analyses.<lb>Comparison of Approaches<lb>Table 1 shows the test-set loss for different values of n and<lb>different approaches for learning U . We performed between<lb>6 and 18 replicates of each experiment, and show bootstrap<lb>estimates of means and standard errors over these replicates.<lb>As we can see, the learning task becomes more challenging<lb>as n increases, but our parametrization (u(n)) consistently<lb>outperforms the other approaches.<lb>Restricting to 7n parameters<lb>As mentioned, arjovsky uses only 7n parameters. To<lb>check if this difference accounts for the differences in<lb>loss observed in Table 1, we ran experiments where we<lb>fixed all but 7n (selected randomly) of the<lb>{λj} in the<lb>lie algebra parametrization. The fixed parameters re-<lb>tained their initial values throughout the experiment. We<lb>observe that, as suspected, restricting to 7n parameters re-<lb>sults in a performance degradation equivalent to that of<lb>arjovsky.<lb>Table 2 shows the results for n = 8, 14, 20. The fact<lb>that the restricted case is consistently within error of the<lb>arjovsky model supports our hypothesis that the differ-<lb>ence in learnable parameters accounts for the difference in<lb>performance. This suggests that generalising the model of<lb>Arjovsky, Shah, and Bengio to allow for n parameters may<lb>result in performance similar to our approach. However, how<lb>to go about such a generalisation is unclear, as a naive ap-<lb>proach would simply use a composition of n operators, and<lb>this would likely become computationally intractable.<lb>Method of generating U<lb>As described, we used three methods to generate the true<lb>U . One of these produces U in the subspace available to<lb>the composition parametrization (Equation 1), so we were<lb>curious to see if this parametrization performed better on<lb>experiments using that method. We were also concerned that<lb>generating U using the Lie algebra parametrization might<lb>make the task too ‘easy’ for our approach, as its random<lb>initialization could lie close to the true solution.<lb>Figure 1 shows box-plots of the distribution of test losses<lb>from these approaches for the three methods, comparing<lb>our approach (u(n)) with that of Arjovsky, Shah, and Ben-<lb>gio (2016), denoted arjovsky. To combine results from<lb>experiments using different values of n, we first scaled test-<lb>set losses by the performance of rand (the random uni-<lb>tary matrix), so the y-axis ranges from 0 (perfect) to 1 (ran-<lb>dom performance). The dotted line denotes the average (over<lb>0.00<lb>0.05<lb>0.10<lb>0.15 0.000<lb>0.001<lb>0.002<lb>0.003 u(n) u(n) (restricted)<lb>method to<lb>generate U<lb>composition<lb>Lie algebra<lb>QR arjovsky u(n)<lb>te<lb>st<lb>lo<lb>ss<lb>(f<lb>ra<lb>ct<lb>io<lb>n<lb>of<lb>ra<lb>nd<lb>om<lb>lo<lb>ss<lb>) learning approach<lb>Figure 1: We ask whether the method used to generate U<lb>influences performance for different approaches to learning<lb>U . Error bars are bootstrap estimates of 95% confidence in-<lb>tervals. To compare across different n’s, we normalise each<lb>loss by the loss of rand for that n, and reporrt fractions.<lb>The dotted line is the true loss, similarly normalised. the<lb>choice of method to generate U does not appear to affect<lb>test-set loss for the different approaches. Right: Finer reso-<lb>lution on the u(n) result in left panel. We also include the<lb>case where we restrict to 7n learnable parameters. methods) of the test-set loss for true, similarly scaled. The<lb>right panel in Figure 1 shows a zoomed-in version of the<lb>u(n) result where the comparison with true is more mean-<lb>ingful, and a comparison with the case where we have re-<lb>stricted to 7n learnable parameters (see earlier).<lb>We do not observe a difference (within error) between the<lb>methods, which is consistent between u(n) and arjovsky.<lb>Our concern that using the Lie algebra to generate U would<lb>make the task ‘too easy’ for u(n) was seemingly unfounded.<lb>Unitary Recurrent Neural Network for Long<lb>Memory Tasks<lb>To demonstrate that our approach is practical for use in deep<lb>learning, we incorporate it into a recurrent neural network to<lb>solve standard long-memory tasks. Specifically, we define a<lb>general unitary RNN with recurrence relation<lb>ht = f (βUht−1 + V xt + b)<lb>(12)<lb>where f is a nonlinearity, β is a free scaling factor, U is our<lb>unitary matrix parametrised as in equation 7, ht is the hidden<lb>state of the RNN and xt is the input data at ‘time-point’ t.<lb>We refer to this as a ‘general unitary RNN’ (guRNN), to<lb>distinguish it from the restricted uRNN of Arjovsky, Shah,<lb>and Bengio (2016).<lb>We use the guRNN on two tasks: the ‘adding problem’<lb>and the ‘memory problem’, first described in (Hochreiter<lb>and Schmidhuber 1997). For the sake of brevity we refer<lb>to (Arjovsky, Shah, and Bengio 2016) for specific exper-<lb>imental details, as we use an identical experimental setup<lb>(reproduced in TensorFlow; see above github link for code).<lb>We compare our model (guRNN) with the restricted uRNN<lb>(ruRNN) parametrised as in equation 1, a LSTM (Hochre-<lb>iter and Schmidhuber 1997), and the IRNN of Le, Jaitly,<lb>and Hinton (2015). Figure 2 shows the results for each n<lb>true<lb>projection<lb>arjovsky<lb>lie algebra<lb>rand<lb>3 6.004± 0.005× 10−4 8 ± 1 6.005± 0.003× 10−4 6.003± 0.003× 10−4 12.5± 0.4<lb>6<lb>∼ 0.001<lb>15± 1<lb>0.09± 0.01<lb>0.03± 0.01<lb>24 ± 1<lb>8<lb>∼ 0.002<lb>14± 1<lb>1.17± 0.06<lb>0.014± 0.006 31.6± 0.6<lb>14<lb>∼ 0.003<lb>24± 4<lb>10.8± 0.3<lb>0.07± 0.02<lb>52± 1<lb>20<lb>∼ 0.004<lb>38± 3<lb>29.0± 0.5<lb>0.47± 0.03<lb>81± 2<lb>Table 1: Loss (mean l2-norm between ŷi and yi) on the test set for the different approaches as the dimension of the unitary<lb>matrix changes. true refers to the matrix used to generate the data, projection is the approach of ‘re-unitarizing’ using<lb>a polar decomposition after gradient updates, arjovsky is the composition approach defined in Equation 1, u(n) is our<lb>parametrization (Equation 7) and rand is a random unitary matrix generated in the same manner as true. Values in bold are<lb>the best for that n (excluding true). The error for true is typically very small, so we omit it.<lb>n<lb>arjovsky lie restricted lie unrestricted<lb>8 1.2± 0.1<lb>1.0± 0.2<lb>0.04± 0.01<lb>14<lb>11.6± 0.3 12.6± 0.4<lb>0.25± 0.03<lb>20 27.8± 0.7 28.0± 0.6<lb>0.19± 0.03<lb>Table 2: We observe that restricting our approach to the same number of learnable parameters as that of (Arjovsky, Shah, and<lb>Bengio 2016) causes a similar degradation in performance on the task. This indicates that the relatively superior performance<lb>of our model is explained by its generality in capturing arbitrary unitary matrices. task where the sequence length or the memory duration is<lb>T = 100.<lb>While our model guarantees unitarity of U , this is not<lb>sufficient to prevent gradients from vanishing. Consider the<lb>norm of the gradient of the cost C with respect to the data at<lb>time τ , and use submultiplicativity of the norm to write;<lb>∥∥∥∥ ∂C<lb>∂xτ ∥∥∥∥ ≤<lb>∥∥∥∥ ∂C<lb>∂xT ∥∥∥∥ (<lb>T−1<lb>∏ t=τ<lb>‖f ′ (Uht + V xt + b) ‖‖U‖<lb>∥∥∥∥∂hτ<lb>xτ ∥∥∥∥<lb>where f ′ is a diagonal matrix giving the derivatives of the<lb>nonlinearity. Using a unitary matrix fixes ‖U‖ = 1, but be-<lb>yond further restrictions (on V and b) does nothing to con-<lb>trol the norm of f ′, which is at most 1 for common nonlin-<lb>earities. Designing a nonlinearity to better preserve gradient<lb>norms is beyond the scope of this work, so we simply scaled<lb>U by a constant multiplicative factor β to counteract the ten-<lb>dency of the nonlinearity to shrink gradients. In Figure 2 we<lb>denote this setup by guRNNβ . Confirming our intuition, this<lb>simple modification greatly improves performance on both<lb>tasks.<lb>Perhaps owing to our efficient gradient calculation (ap-<lb>pendix A) and simpler recurrence relation, our model runs<lb>faster than that of (Arjovsky, Shah, and Bengio 2016) (in our<lb>implementation), by a factor of 4.8 and 2.6 in the adding and<lb>memory tasks shown in Figure 2 respectively. This amounts<lb>to the guRNN processing 61.2 and 37.0 examples per second<lb>in the two tasks, on a GeForce GTX 1080 GPU.<lb>Discussion<lb>Drawing from the rich theory of Lie groups and Lie algebras,<lb>we have described a parametrization of unitary matrices ap-<lb>propriate for use in deep learning. This parametrization ex-<lb>ploits the Lie group-Lie algebra correspondence through the<lb>exponential map to represent unitary matrices in terms of<lb>real coefficients relative to a given basis of the Lie alge-<lb>bra u(n). As this map from u(n) to U(n) is surjective, the<lb>parametrization can describe any unitary matrix.<lb>We have demonstrated that unitary matrices can be<lb>learned with high accuracy using simple gradient de-<lb>scent, and that this approach outperforms a recently-<lb>proposed parametrization (from Arjovsky, Shah, and Ben-<lb>gio (2016)) and significantly outperforms the approach of<lb>‘re-unitarizing’ after gradient updates. This experimental de-<lb>sign is quite simple, designed to probe a core problem, be-<lb>fore considering the broader setting of RNNs.<lb>Our experiments with general unitary RNNs using this<lb>parametrization showed that this approach is practical for<lb>deep learning. With a fraction of the parameters, our model<lb>outperforms LSTMs on the standard ‘memory problem’ and<lb>attains comparable (although inferior) performance on the<lb>adding problem (Hochreiter and Schmidhuber 1997). Fur-<lb>ther work is required to understand the difference in perfor-<lb>mance between our approach and the ruRNN of (Arjovsky,<lb>Shah, and Bengio 2016) perhaps the 7n-dimensional sub-<lb>space captured by their parametrization is serendipitously<lb>beneficial for these RNN tasks although we note that the<lb>results presented here are not the fruit of exhaustive hyperpa-<lb>rameter exploration. Of particular interest is the impressive<lb>performance of both uRNNs on the memory task, where the<lb>LSTM and IRNN appear to fail to learn.<lb>While our RNN experiments have demonstrated the util-<lb>ity of using a unitary operator for these tasks, we believe<lb>that the role of the nonlinearity in the vanishing and ex-<lb>ploding gradient problem must not be discounted. We have<lb>shown that a simple scaling factor can help reduce the van-<lb>ishing gradient problem induced by the choice of nonlinear-<lb>ity. More analysis considering the combination of nonlinear-<lb>ity and transition operator must be performed to better tackle<lb>this problem.<lb>The success of our parametrization for unitary operator<lb>learning suggests that the approach of performing gradient",
            "output": [
                "Learning Unitary Operators with Help From u(n)"
            ]
        },
        {
            "id": "task1540-28aa1afad79841b692739f8a5c131464",
            "input": "In this paper, we propose a novel technique for direct recognition of multiple speech streams given the single channel of mixed speech, without first separating them. Our technique is based on permutation invariant training (PIT) for automatic speech recognition (ASR). In PIT-ASR, we compute the average cross entropy (CE) over all frames in the whole utterance for each possible output-target assignment, pick the one with the minimum CE, and optimize for that assignment. PIT-ASR forces all the frames of the same speaker to be aligned with the same output layer. This strategy elegantly solves the label permutation problem and speaker tracing problem in one shot. Our experiments on artificially mixed AMI data showed that the proposed approach is very promising.",
            "output": [
                "Recognizing Multi-talker Speech with Permutation Invariant Training"
            ]
        },
        {
            "id": "task1540-2183e61640f242f0b2336e47f5d60b2a",
            "input": "Recent work (Bengio et al., 2013) has shown how Denoising Auto-Encoders(DAE) become generative models as a density estimator. However, in practice, the framework suffers from a mixing problem in the MCMC sampling process and no direct method to estimate the test loglikelihood. We consider a directed model with an stochastic identity mapping (simple corruption process) as an inference model and a DAE as a generative model. By cascading these models, we propose Cascading Denoising AutoEncoders(CDAE) which can generate samples of data distribution from tractable prior distribution under the assumption that probabilistic distribution of corrupted data approaches tractable prior distribution as the level of corruption increases. This work tries to answer two questions. On the one hand, can deep directed models be successfully trained without intractable posterior inference and difficult optimization of very deep neural networks in inference and generative models? These are unavoidable when recent successful directed model like VAE (Kingma & Welling, 2014) is trained on complex dataset like real images. On the other hand, can DAEs get clean samples of data distribution from heavily corrupted samples which can be considered of tractable prior distribution far from data manifold? so-called global denoising scheme. Our results show positive responses of these questions and this work can provide fairly simple framework for generative models of very complex dataset. Proceedings of the 32 International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).",
            "output": [
                "Cascading Denoising Auto-Encoder as a Deep Directed Generative Model"
            ]
        },
        {
            "id": "task1540-f4d9c5735c7e40f19286f693023c0b7c",
            "input": "In Distributional Semantic Models (DSMs), Vector Cosine is widely used to estimate similarity between word vectors, although this measure was noticed to suffer from several shortcomings. The recent literature has proposed other methods which attempt to mitigate such biases. In this paper, we intend to investigate APSyn, a measure that computes the extent of the intersection between the most associated contexts of two target words, weighting it by context relevance. We evaluated this metric in a similarity estimation task on several popular test sets, and our results show that APSyn is in fact highly competitive, even with respect to the results reported in the literature for word embeddings. On top of it, APSyn addresses some of the weaknesses of Vector Cosine, performing well also on genuine similarity estimation.",
            "output": [
                "Testing APSyn against Vector Cosine on Similarity Estimation"
            ]
        },
        {
            "id": "task1540-755400e4d5884d959a2739e70be92410",
            "input": "We present a skill analysis with time series image data using data mining methods, focused on table tennis. We do not use body model, but use only hi-speed movies, from which time series data are obtained and analyzed using data mining methods such as C4.5 and so on. We identify internal models for technical skills as evaluation skillfulness for the forehand stroke of table tennis, and discuss mono and meta-functional skills for improving skills. Keywords—component; Time Series Data, Sport Skill, Data Mining, Image Processing, Knowledge Acquisition",
            "output": [
                "Skill Analysis with Time Series Image Data"
            ]
        },
        {
            "id": "task1540-ac16b2fd1c2a41eab6706e6b93cbedc0",
            "input": "We present a method for extracting depth information from a rectified image pair. Our approach focuses on the first stage of many stereo algorithms: the matching cost computation. We approach the problem by learning a similarity measure on small image patches using a convolutional neural network. Training is carried out in a supervised manner by constructing a binary classification data set with examples of similar and dissimilar pairs of patches. We examine two network architectures for this task: one tuned for speed, the other for accuracy. The output of the convolutional neural network is used to initialize the stereo matching cost. A series of post-processing steps follow: cross-based cost aggregation, semiglobal matching, a left-right consistency check, subpixel enhancement, a median filter, and a bilateral filter. We evaluate our method on the KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that it outperforms other approaches on all three data sets.",
            "output": [
                "Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches"
            ]
        },
        {
            "id": "task1540-2acd20017a2d4e08a548ad0cded147f2",
            "input": "Understanding user instructions in natural language is an active research topic in AI and robotics. Typically, natural user instructions are high-level and can be reduced into low-level tasks expressed in common verbs (e.g., ‘take’, ‘get’, ‘put’). For robots understanding such instructions, one of the key challenges is to process high-level user instructions and achieve the specified tasks with robots’ primitive actions. To address this, we propose novel algorithms by utilizing semantic roles of common verbs defined in semantic dictionaries and integrating multiple open knowledge to generate task plans. Specifically, we present a new method for matching and recovering semantics of user instructions and a novel task planner that exploits functional knowledge of robot’s action model. To verify and evaluate our approach, we implemented a prototype system using knowledge from several open resources. Experiments on our system confirmed the correctness and efficiency of our algorithms. Notably, our system has been deployed in the KeJia robot, which participated the annual RoboCup@Home competitions in the past three years and achieved encouragingly high scores in the benchmark tests.",
            "output": [
                "Understanding User Instructions by Utilizing Open Knowledge for Service Robots"
            ]
        },
        {
            "id": "task1540-654a479817b84fa5bcad002a0e20e80b",
            "input": "A central task in many applications is reasoning about processes that change over continuous time. Recently, Nodelman et al. introduced continuous time Bayesian networks (CTBNs), a structured representation for representing Continuous Time Markov Processes over a structured state space. In this paper, we introduce continuous time Markov networks (CTMNs), an alternative representation language that represents a different type of continuous-time dynamics, particularly appropriate for modeling biological and chemical systems. In this language, the dynamics of the process is described as an interplay between two forces: the tendency of each entity to change its state, which we model using a continuous-time proposal process that suggests possible local changes to the state of the system at different rates; and a global fitness or energy function of the entire system, governing the probability that a proposed change is accepted, which we capture by a Markov network that encodes the fitness of different states. We show that the fitness distribution is also the stationary distribution of the Markov process, so that this representation provides a characterization of a temporal process whose stationary distribution has a compact graphical representation. We describe the semantics of the representation, its basic properties, and how it compares to CTBNs. We also provide an algorithm for learning such models from data, and demonstrate its potential benefit over other learning approaches.",
            "output": [
                "Continuous Time Markov Networks"
            ]
        },
        {
            "id": "task1540-13d9796e7c03458facd22253cbff1bc1",
            "input": "First-order probabilistic models combine representational power of first-order logic with graphical models. There is an ongoing effort to design lifted inference algorithms for first-order probabilistic models. We analyze lifted inference from the perspective of constraint processing and, through this viewpoint, we analyze and compare existing approaches and expose their advantages and limitations. Our theoretical results show that the wrong choice of constraint processing method can lead to exponential increase in computational complexity. Our empirical tests confirm the importance of constraint processing in lifted inference. This is the first theoretical and empirical study of constraint processing in lifted inference.",
            "output": [
                "Constraint Processing in Lifted Probabilistic Inference"
            ]
        },
        {
            "id": "task1540-1f0d19f140f2470f9b555f5146664227",
            "input": "A selective classifier ( f ,g) comprises a classification function f and a binary selection function g, which determines if the classifier abstains from prediction, or uses f to predict. The classifier is called pointwise-competitive if it classifies each point identically to the best classifier in hindsight (from the same class), whenever it does not abstain. The quality of such a classifier is quantified by its rejection mass, defined to be the probability mass of the points it rejects. A “fast” rejection rate is achieved if the rejection mass is bounded from above by Õ(1/m) where m is the number of labeled examples used to train the classifier (and Õ hides logarithmic factors). Pointwise-competitive selective (PCS) classifiers are intimately related to disagreement-based active learning and it is known that in the realizable case, a fast rejection rate of a known PCS algorithm (called Consistent Selective Strategy) is equivalent to an exponential speedup of the well-known CAL active algorithm. We focus on the agnostic setting, for which there is a known algorithm called LESS that learns a PCS classifier and achieves a fast rejection rate (depending on Hanneke’s disagreement coefficient) under strong assumptions. We present an improved PCS learning algorithm called ILESS for which we show a fast rate (depending on Hanneke’s disagreement coefficient) without any assumptions. Our rejection bound smoothly interpolates the realizable and agnostic settings. The main result of this paper is an equivalence between the following three entities: (i) the existence of a fast rejection rate for any PCS learning algorithm (such as ILESS); (ii) a poly-logarithmic bound for Hanneke’s disagreement coefficient; and (iii) an exponential speedup for a new disagreement-based active learner called Active-ILESS.",
            "output": [
                "The Relationship Between Agnostic Selective Classification Active Learning and the Disagreement Coefficient"
            ]
        },
        {
            "id": "task1540-06d39fca64db4dd88367cda0882fd995",
            "input": "Quality control at each stage of production in textile industry has become a key factor to retaining the existence in the highly competitive global market. Problems of manual fabric defect inspection are lack of accuracy and high time consumption, where early and accurate fabric defect detection is a significant phase of quality control. Computer vision based, i.e. automated fabric defect inspection systems are thought by many researchers of different countries to be very useful to resolve these problems. There are two major challenges to be resolved to attain a successful automated fabric defect inspection system. They are defect detection and defect classification. In this work, we discuss different techniques used for automated fabric defect classification, then show a survey of classifiers used in automated fabric defect inspection systems, and finally, compare these classifiers by using performance metrics. This work is expected to be very useful for the researchers in the area of automated fabric defect inspection to understand and evaluate the many potential options in this field.",
            "output": [
                "AUTOMATED FABRIC DEFECT INSPECTION: A SURVEY OF CLASSIFIERS"
            ]
        },
        {
            "id": "task1540-dd95b487861f4fce99b456e994b56810",
            "input": "A basic problem in the design of privacy-preserving algorithms is the private maximization problem: the goal is to pick an item from a universe that (approximately) maximizes a data-dependent function, all under the constraint of differential privacy. This problem has been used as a sub-routine in many privacy-preserving algorithms for statistics and machine-learning. Previous algorithms for this problem are either range-dependent—i.e., their utility diminishes with the size of the universe—or only apply to very restricted function classes. This work provides the first general-purpose, range-independent algorithm for private maximization that guarantees approximate differential privacy. Its applicability is demonstrated on two fundamental tasks in data mining and machine learning.",
            "output": [
                "The Large Margin Mechanism for Differentially Private Maximization"
            ]
        },
        {
            "id": "task1540-b61ac95b4d044e5c89df6e585018235b",
            "input": "In many applications of black-box optimization, one can evaluate multiple points simultaneously, e.g. when evaluating the performances of several different neural networks in a parallel computing environment. In this paper, we develop a novel batch Bayesian optimization algorithm — the parallel knowledge gradient method. By construction, this method provides the one-step Bayes optimal batch of points to sample. We provide an efficient strategy for computing this Bayes-optimal batch of points, and we demonstrate that the parallel knowledge gradient method finds global optima significantly faster than previous batch Bayesian optimization algorithms on both synthetic test functions and when tuning hyperparameters of practical machine learning algorithms, especially when function evaluations are noisy.",
            "output": [
                "The Parallel Knowledge Gradient Method for Batch Bayesian Optimization"
            ]
        },
        {
            "id": "task1540-a1d9744b5af24645a79a13516d6bed1c",
            "input": "A significant performance reduction is often observed in speech recognition when the rate of speech (ROS) is too low or too high. Most of present approaches to addressing the ROS variation focus on the change of speech signals in dynamic properties caused by ROS, and accordingly modify the dynamic model, e.g., the transition probabilities of the hidden Markov model (HMM). However, an abnormal ROS changes not only the dynamic but also the static property of speech signals, and thus can not be compensated for purely by modifying the dynamic model. This paper proposes an ROS learning approach based on deep neural networks (DNN), which involves an ROS feature as the input of the DNN model and so the spectrum distortion caused by ROS can be learned and compensated for. The experimental results show that this approach can deliver better performance for too slow and too fast utterances, demonstrating our conjecture that ROS impacts both the dynamic and the static property of speech. In addition, the proposed approach can be combined with the conventional HMM transition adaptation method, offering additional performance gains.",
            "output": [
                "Learning Speech Rate in Speech Recognition"
            ]
        },
        {
            "id": "task1540-b2980b6f3c4f41fb894f6fdf9f61698c",
            "input": "The cascade model is a well-established model of user interaction with content. In this work, we propose cascading bandits, a learning variant of the model where the objective is to learn K most attractive items out of L ground items. We cast the problem as a stochastic combinatorial bandit with a non-linear reward function and partially observed weights of items. Both of these are challenging in the context of combinatorial bandits. We propose two computationally-efficient algorithms for our problem, CascadeUCB1 and CascadeKL-UCB, and prove gap-dependent upper bounds on their regret. We also derive a lower bound for cascading bandits and show that it matches the upper bound of CascadeKL-UCB up to a logarithmic factor. Finally, we evaluate our algorithms on synthetic problems. Our experiments demonstrate that the algorithms perform well and robustly even when our modeling assumptions are violated.",
            "output": [
                "Cascading Bandits"
            ]
        },
        {
            "id": "task1540-bd7a4ca9e88f4cdeaf35a2ab10fd121d",
            "input": "Coordinate descent is one of the most popular approaches for solving Lasso and its extensions due to its simplicity and efficiency. When applying coordinate descent to solving Lasso, we update one coordinate at a time while fixing the remaining coordinates. Such an update, which is usually easy to compute, greedily decreases the objective function value. In this paper, we aim to improve its computational efficiency by reducing the number of coordinate descent iterations. To this end, we propose a novel technique called Successive Ray Refinement (SRR). SRR makes use of the following ray continuation property on the successive iterations: for a particular coordinate, the value obtained in the next iteration almost always lies on a ray that starts at its previous iteration and passes through the current iteration. Motivated by this ray-continuation property, we propose that coordinate descent be performed not directly on the previous iteration but on a refined search point that has the following properties: on one hand, it lies on a ray that starts at a history solution and passes through the previous iteration, and on the other hand, it achieves the minimum objective function value among all the points on the ray. We propose two schemes for defining the search point and show that the refined search point can be efficiently obtained. Empirical results for real and synthetic data sets show that the proposed SRR can significantly reduce the number of coordinate descent iterations, especially for small Lasso regularization parameters.",
            "output": [
                "Successive Ray Refinement and Its Application to Coordinate Descent for LASSO"
            ]
        },
        {
            "id": "task1540-0e25116f627c4c5dbe6ed54b7b170516",
            "input": "Automation and computer intelligence to support<lb>complex human decisions becomes essential to manage large and<lb>distributed systems in the Cloud and IoT era. Understanding<lb>the root cause of an observed symptom in a complex system<lb>has been a major problem for decades. As industry dives into<lb>the IoT world and the amount of data generated per year<lb>grows at an amazing speed, an important question is how to<lb>find appropriate mechanisms to determine root causes that can<lb>handle huge amounts of data or may provide valuable feedback<lb>in real-time. While many survey papers aim at summarizing<lb>the landscape of techniques for modelling system behavior and<lb>infering the root cause of a problem based in the resulting<lb>models, none of those focuses on analyzing how the different<lb>techniques in the literature fit growing requirements in terms<lb>of performance and scalability. In this survey, we provide a<lb>review of root-cause analysis, focusing on these particular aspects.<lb>We also provide guidance to choose the best root-cause analysis<lb>strategy depending on the requirements of a particular system<lb>and application.",
            "output": [
                "Survey on Models and Techniques for Root-Cause Analysis"
            ]
        },
        {
            "id": "task1540-0d660a89545140a9b297ed00049b4c03",
            "input": "We consider apprenticeship learning — i.e., having an agent learn a task by observing an expert demonstrating the task — in a partially observable environment when the model of the environment is uncertain. This setting is useful in applications where the explicit modeling of the environment is difficult, such as a dialogue system. We show that we can extract information about the environment model by inferring action selection process behind the demonstration, under the assumption that the expert is choosing optimal actions based on knowledge of the true model of the target environment. Proposed algorithms can achieve more accurate estimates of POMDP parameters and better policies from a short demonstration, compared to methods that learns only from the reaction from the environment.",
            "output": [
                "Apprenticeship Learning for Model Parameters of  Partially Observable Environments"
            ]
        },
        {
            "id": "task1540-f679a8cdf2b3488e954d97891a52fcc2",
            "input": "Human interactions are characterized by explicit as well as implicit channels of communication. While the explicit channel transmits overt messages, the implicit ones transmit hidden messages about the communicator (e.g., his/her intentions and attitudes). There is a growing consensus that providing a computer with the ability to manipulate implicit affective cues should allow for a more meaningful and natural way of studying particular non-verbal signals of human-human communications by human-computer interactions [1], [2]. In this pilot study, we created a non-dynamic human-computer interaction while manipulating three specific non-verbal channels of communication: gaze pattern, facial expression, and gesture. Participants rated the virtual agent on affective dimensional scales (pleasure, arousal, and dominance) while their physiological signal (electrodermal activity, EDA) was captured during the interaction. Assessment of the behavioral data revealed a significant and complex three-way interaction between gaze, gesture, and facial configuration on the dimension of pleasure, as well as a main effect of gesture on the dimension of dominance. These results suggest a complex relationship between different non-verbal cues and the social context in which they are interpreted. Qualifying considerations as well as possible next steps are further discussed in light of these exploratory findings.",
            "output": [
                "Using Virtual Humans to Understand Real Ones"
            ]
        },
        {
            "id": "task1540-1be1be609d7247478cdbf7c0e0363dda",
            "input": "Connectionist Temporal Classification has recently attracted a lot of interest as it offers an elegant approach to building acoustic models (AMs) for speech recognition. The CTC loss function maps an input sequence of observable feature vectors to an output sequence of symbols. Output symbols are conditionally independent of each other under CTC loss, so a language model (LM) can be incorporated conveniently during decoding, retaining the traditional separation of acoustic and linguistic components in ASR. For fixed vocabularies, Weighted Finite State Transducers provide a strong baseline for efficient integration of CTC AMs with n-gram LMs. Character-based neural LMs provide a straight forward solution for open vocabulary speech recognition and all-neural models, and can be decoded with beam search. Finally, sequence-to-sequence models can be used to translate a sequence of individual sounds into a word string. We compare the performance of these three approaches, and analyze their error patterns, which provides insightful guidance for future research and development in this important area.",
            "output": [
                "Comparison of Decoding Strategies for CTC Acoustic Models"
            ]
        },
        {
            "id": "task1540-68a492b2e1474ae298fa380353aefb89",
            "input": "Neural attention models have achieved great success in different NLP tasks. However, they have not fulfilled their promise on the AMR parsing task due to the data sparsity issue. In this paper, we describe a sequence-to-sequence model for AMR parsing and present different ways to tackle the data sparsity problem. We show that our methods achieve significant improvement over a baseline neural attention model and our results are also competitive against state-of-the-art systems that do not use extra linguistic resources.",
            "output": [
                "Addressing the Data Sparsity Issue in Neural AMR Parsing"
            ]
        },
        {
            "id": "task1540-0389c7b4c13a4fef939916fff9cfd6c6",
            "input": "We consider the problem of rank loss minimization in the setting of multilabel classification, which is usually tackled by means of convex surrogate losses defined on pairs of labels. Very recently, this approach was put into question by a negative result showing that commonly used pairwise surrogate losses, such as exponential and logistic losses, are inconsistent. In this paper, we show a positive result which is arguably surprising in light of the previous one: the simpler univariate variants of exponential and logistic surrogates (i.e., defined on single labels) are consistent for rank loss minimization. Instead of directly proving convergence, we give a much stronger result by deriving regret bounds and convergence rates. The proposed losses suggest efficient and scalable algorithms, which are tested experimentally.",
            "output": [
                "Consistent Multilabel Ranking through Univariate Loss Minimization"
            ]
        },
        {
            "id": "task1540-120a9ce93c764797825318a09b30ea11",
            "input": "The continuing development of Semantic Web technologies and the increasing user adoption in the recent years have accelerated the progress incorporating explicit semantics with data on the Web. With the rapidly growing RDF (Resource Description Framework) data on the Semantic Web, processing large semantic graph data have become more challenging. Constructing a summary graph structure from the raw RDF can help obtain semantic type relations and reduce the computational complexity for graph processing purposes. In this paper, we addressed the problem of graph summarization in RDF graphs, and we proposed an approach for building summary graph structures automatically from RDF graph data. Moreover, we introduced a measure to help discover optimum class dissimilarity thresholds and an effective method to discover the type classes automatically. In future work, we plan to investigate further improvement options on the scalability of the proposed method.",
            "output": [
                "Dynamic Discovery of Type Classes and Relations in Semantic Web Data"
            ]
        },
        {
            "id": "task1540-f09e84051a2646a3a4d5f508e8cfb79d",
            "input": "We consider the problem of search through comparisons, where a user is presented with two candidate objects and reveals which is closer to her intended target. We study adaptive strategies for finding the target, that require knowledge of rank relationships but not actual distances between objects. We propose a new strategy based on rank nets, and show that for target distributions with a bounded doubling constant, it finds the target in a number of comparisons close to the entropy of the target distribution and, hence, of the optimum. We extend these results to the case of noisy oracles, and compare this strategy to prior art over multiple datasets.",
            "output": [
                "Comparison-Based Learning with Rank Nets"
            ]
        },
        {
            "id": "task1540-5c3834d6ebde429e8f07ac5b912e1d44",
            "input": "One of the common artificial intelligence applications in electronic games consists of making an artificial agent learn how to execute some determined task successfully in a game environment. One way to perform this task is through machine learning algorithms capable of learning the sequence of actions required to win in a given game environment. There are several supervised learning techniques able to learn the correct answer for a problem through examples. However, when learning how to play electronic games, the correct answer might only be known by the end of the game, after all the actions were already taken. Thus, not being possible to measure the accuracy of each individual action to be taken at each time step. A way for dealing with this problem is through Neuroevolution, a method which trains Artificial Neural Networks using evolutionary algorithms. In this article, we introduce a framework for testing optimization algorithms with artificial agent controllers in electronic games, called EvoMan, which is inspired in the action-platformer game Mega Man II. The environment can be configured to run in different experiment modes, as single evolution, coevolution and others. To demonstrate some challenges regarding the proposed platform, as initial experiments we applied Neuroevolution using Genetic Algorithms and the NEAT algorithm, in the context of competitively coevolving two distinct agents in this game. 1",
            "output": [
                "An electronic-game framework for evaluating coevolutionary algorithms"
            ]
        },
        {
            "id": "task1540-0484eae34a064d6baaa91e850d568519",
            "input": "Online learning algorithms are designed to learn even when their input is generated by an adversary. The widely-accepted formal definition of an online algorithm’s ability to learn is the game-theoretic notion of regret. We argue that the standard definition of regret becomes inadequate if the adversary is allowed to adapt to the online algorithm’s actions. We define the alternative notion of policy regret, which attempts to provide a more meaningful way to measure an online algorithm’s performance against adaptive adversaries. Focusing on the online bandit setting, we show that no bandit algorithm can guarantee a sublinear policy regret against an adaptive adversary with unbounded memory. On the other hand, if the adversary’s memory is bounded, we present a general technique that converts any bandit algorithm with a sublinear regret bound into an algorithm with a sublinear policy regret bound. We extend this result to other variants of regret, such as switching regret, internal regret, and swap regret.",
            "output": [
                "Online Bandit Learning against an Adaptive Adversary: from Regret to Policy Regret"
            ]
        },
        {
            "id": "task1540-1a449315d2cb4064aed43a6ddffd7efd",
            "input": "We propose an algorithm to uncover the intrinsic low-rank component of a high-dimensional, graph-smooth and grossly-corrupted dataset, under the situations that the underlying graph is unknown. Based on a model with a low-rank component plus a sparse perturbation, and an initial graph estimation, our proposed algorithm simultaneously learns the low-rank component and refines the graph. The refined graph improves the effectiveness of the graph smoothness constraint and increases the accuracy of the low-rank estimation. We derive the learning steps using ADMM. Our evaluations using synthetic and real brain imaging data in a supervised classification task demonstrate encouraging performance.",
            "output": [
                "SIMULTANEOUS LOW-RANK COMPONENT AND GRAPH ESTIMATION FOR HIGH-DIMENSIONAL GRAPH SIGNALS: APPLICATION TO BRAIN IMAGING"
            ]
        },
        {
            "id": "task1540-407a11151dd6486786456d431e4ce913",
            "input": "The computational mechanisms by which nonlinear recurrent neural networks (RNNs) achieve their goals remains an open question. There exist many problem domains where intelligibility of the network model is crucial for deployment. Here we introduce a recurrent architecture composed of input-switched affine transformations, in other words an RNN without any nonlinearity and with one set of weights per input. We show that this architecture achieves near identical performance to traditional architectures on language modeling of Wikipedia text, for the same number of model parameters. It can obtain this performance with the potential for computational speedup compared to existing methods, by precomputing the composed affine transformations corresponding to longer input sequences. As our architecture is affine, we are able to understand the mechanisms by which it functions using linear methods. For example, we show how the network linearly combines contributions from the past to make predictions at the current time step. We show how representations for words can be combined in order to understand how context is transferred across word boundaries. Finally, we demonstrate how the system can be executed and analyzed in arbitrary bases to aid understanding.",
            "output": [
                "INTELLIGIBLE LANGUAGE MODELING WITH INPUT SWITCHED AFFINE NETWORKS"
            ]
        },
        {
            "id": "task1540-2401b856b88543e187be68c6d4bc3a32",
            "input": "We study the classic online learning problem of predicting with expert advice, and propose a truly parameter-free and adaptive algorithm that achieves several objectives simultaneously without using any prior information. The main component of this work is an improved version of the NormalHedge.DT algorithm [Luo and Schapire, 2014], called AdaNormalHedge. On one hand, this new algorithm ensures small regret when the competitor has small loss and almost constant regret when the losses are stochastic. On the other hand, the algorithm is able to compete with any convex combination of the experts simultaneously, with a regret in terms of the relative entropy of the prior and the competitor. This resolves an open problem proposed by Chaudhuri et al. [2009] and Chernov and Vovk [2010]. Moreover, we extend the results to the sleeping expert setting and provide two applications to illustrate the power of AdaNormalHedge: 1) competing with time-varying unknown competitors and 2) predicting almost as well as the best pruning tree. Our results on these applications significantly improve previous work from different aspects, and a special case of the first application resolves another open problem proposed by Warmuth and Koolen [2014] on whether one can simultaneously achieve optimal shifting regret for both adversarial and stochastic losses.",
            "output": [
                "Achieving All with No Parameters: Adaptive NormalHedge"
            ]
        },
        {
            "id": "task1540-b88fe70e24614df2b775bd4cd7d41e1e",
            "input": "Events and entities are closely related; entities are often actors or participants in events and events without entities are uncommon. The interpretation of events and entities is highly contextually dependent. Existing work in information extraction typically models events separately from entities, and performs inference at the sentence level, ignoring the rest of the document. In this paper, we propose a novel approach that models the dependencies among variables of events, entities, and their relations, and performs joint inference of these variables across a document. The goal is to enable access to document-level contextual information and facilitate contextaware predictions. We demonstrate that our approach substantially outperforms the stateof-the-art methods for event extraction as well as a strong baseline for entity extraction.",
            "output": [
                "Joint Extraction of Events and Entities within a Document Context"
            ]
        },
        {
            "id": "task1540-e978cb2391e6438c8fc492776954e3b8",
            "input": "In a variety of applications, one desires to detect groups of anomalous data samples, with a group potentially manifesting its atypicality (relative to a reference model) on a low-dimensional subset of the full measured set of features. Samples may only be weakly atypical individually, whereas they may be strongly atypical when considered jointly. What makes this group anomaly detection problem quite challenging is that it is a priori unknown which subset of features jointly manifests a particular group of anomalies. Moreover, it is unknown how many anomalous groups are present in a given data batch. In this work, we develop a group anomaly detection (GAD) scheme to identify the subset of samples and subset of features that jointly specify an anomalous cluster. We apply our approach to network intrusion detection to detect BotNet and peer-to-peer flow clusters. Unlike previous studies, our approach captures and exploits statistical dependencies that may exist between the measured features. Experiments on real world network traffic data demonstrate the advantage of our proposed system, and highlight the importance of exploiting feature dependency structure, compared to the feature (or test) independence assumption made in previous studies.",
            "output": [
                "Detecting Clusters of Anomalies on Low-Dimensional Feature Subsets with Application to Network Traffic Flow Data"
            ]
        },
        {
            "id": "task1540-5bfcecf5f0ee49f2a6f278d9120d1a2b",
            "input": "Knowledge graph embedding aims to embed entities and relations of knowledge graphs into low-dimensional vector spaces. Translating embedding methods regard relations as the translation from head entities to tail entities, which achieve the state-of-the-art results among knowledge graph embedding methods. However, a major limitation of these methods is the time consuming training process, which may take several days or even weeks for large knowledge graphs, and result in great diculty in practical applications. In this paper, we propose an ecient parallel framework for translating embedding methods, called ParTrans-X, which enables the methods to be paralleled without locks by utilizing the distinguished structures of knowledge graphs. Experiments on two datasets with three typical translating embedding methods, i.e., TransE [3], TransH [19], and a more ecient variant TransEAdaGrad [11] validate that ParTrans-X can speed up the training process by more than an order of magnitude.",
            "output": [
                "Eicient Parallel Translating Embedding For Knowledge Graphs"
            ]
        },
        {
            "id": "task1540-19d1ee4d83a54c42abd9d0a4f0a1ddb0",
            "input": "Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition. Historical milestones have been frequently associated with computers matching or outperforming humans in difficult cognitive tasks (e.g. face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.g. Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast, less attention has been given to developing autonomous machines that establish mutually cooperative relationships with people who may not share the machine’s preferences. A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts. Here, we combine a state-of-the-art machine-learning algorithm with novel mechanisms for generating and acting on signals to produce a new learning algorithm that cooperates with people and other machines at levels that rival human cooperation in a variety of two-player repeated stochastic games. This is the first general-purpose algorithm that is capable, given a description of a previously unseen game environment, of learning to cooperate with people within short timescales in scenarios previously unanticipated by algorithm designers. This is achieved without complex opponent modeling or higher-order theories of mind, thus showing that flexible, fast, and general human-machine cooperation is computationally achievable using a non-trivial, but ultimately simple, set of algorithmic mechanisms. ∗Correspondence should be addressed to crandall@cs.byu.edu and irahwan@mit.edu ar X iv :1 70 3. 06 20 7v 1 [ cs .A I] 1 7 M ar 2 01 7",
            "output": [
                "Cooperating with Machines"
            ]
        },
        {
            "id": "task1540-1d335e26be4c4966ad779040323a0497",
            "input": "Collaborative human activities are grounded in social and moral norms, which humans consciously and subconsciously use to guide and constrain their behavior: they undergird human societies by prescribing what is obligatory, permitted, prohibited, and optional [1]. In doing so, they enable effective collaboration and prevent emotional and physical harm. Consider a restaurant kitchen where cooks and assistants perform tasks such as passing knives and cutting vegetables. When handing over a knife to the chef, assistants do so in a way that does not look like they are about to stab the chef. Not only will they orient the knife in the right way, but they should take care not to approach the chef menacingly and without prior warning, while the chef has their back to them. The underlying normative principle could be roughly stated as a rule: “If you need to hand over a potentially dangerous object with a sharp blade, do not point it with the blade at the other person, but rather grasp it carefully by the blade and hand it over with the bland side or handle facing the other person”. The tacit understanding among the kitchen staff is that everyone will abide by this principle, thus enabling safe exchanges of knives and other potentially dangerous objects. Failing to follow the rule will likely result in blame and reprimand from the chef, which then has to be addressed either by apologizing or by offering an explanation as to why the rule violation was justified [2]. Clearly, social and moral norms play an important functional role in the human cognitive architecture: they are at work in perception to detect morally charged contexts and norm violations, they are employed during decision-making and behavior execution, and they are referred to in communications about normative behavior and norm violations. In other words, normative processing is deeply integrated into the human cognitive system and affects virtually every aspect of the architecture (from perception, to reasoning, to action, to communication). Hence, this type of norm-based processing is also critical for robots in many human-robot interaction scenarios (e.g., when helping elderly and disabled persons in assisted living facilities, or assisting humans in assembly tasks in factories or even the space station). Human beings expect their interactants, including intelligent robots, to follow social and moral norms, and disappointing those expectations will lead to impoverished interactions at best, but can lead to emotional and physical harm in the worst cases. In this position paper, we will briefly describe how several components in an integrated cognitive architecture can be used to implement processes that are required for normative human-robot interactions, especially in collaborative tasks where actions and situations could potentially be perceived as threatening and thus need a change in course of action to mitigate the perceived threats. We will focus on affordancebased reasoning to infer complex affordance relationships between an agent and objects in the environment, and analogical reasoning to decide the appropriateness of the action plan by comparing against other past situations.",
            "output": [
                "Enabling Basic Normative HRI in a Cognitive Robotic Architecture"
            ]
        },
        {
            "id": "task1540-9e19a2759d544edfa00174a283fc0477",
            "input": "Vulnerability of state-of-the-art deep neural networks to adversarial attacks has been attracting a lot of attention recently. In this work we propose a new algorithm for constructing universal adversarial perturbations. Our approach is based on computing the so called (p, q)-singular vectors of the Jacobian matrices of hidden layers of a network. Resulting perturbations present interesting visual patterns and by using a batch of just 64 images we can construct adversarial perturbations with relatively high fooling rate. We also investigate a correlation between the singular values of the Jacobian matrices and the fooling rate of a corresponding singular vector.",
            "output": [
                "Art of singular vectors and universal adversarial perturbations"
            ]
        },
        {
            "id": "task1540-47f4b63ba40a44efb9f0a662704c228c",
            "input": "A new computationally efficient dependence measure, and an adaptive statistical test of independence, are proposed. The dependence measure is the difference between analytic embeddings of the joint distribution and the product of the marginals, evaluated at a finite set of locations (features). These features are chosen so as to maximize a lower bound on the test power, resulting in a test that is data-efficient, and that runs in linear time (with respect to the sample size n). The optimized features can be interpreted as evidence to reject the null hypothesis, indicating regions in the joint domain where the joint distribution and the product of the marginals differ most. Consistency of the independence test is established, for an appropriate choice of features. In real-world benchmarks, independence tests using the optimized features perform comparably to the state-of-the-art quadratictime HSIC test, and outperform competing O(n) and O(n log n) tests.",
            "output": [
                "An Adaptive Test of Independence with Analytic Kernel Embeddings"
            ]
        },
        {
            "id": "task1540-fc8556c5ff3647f686192a04f28acffc",
            "input": "In this paper, we provide all information to participate to the Second International Nurse Rostering Competition (INRC-II). First, we describe the problem formulation, which, differently from INRC-I, is a multi-stage procedure. Second, we illustrate all the necessary infrastructure do be used together with the participant’s solver, including the testbed, the file formats, and the validation/simulation tools. Finally, we state the rules of the competition. All update-to-date information about the competition is available at http://mobiz.vives.be/inrc2/.",
            "output": [
                "Second International Nurse Rostering Competition (INRC-II) — Problem Description and Rules —"
            ]
        },
        {
            "id": "task1540-39656f4691874e69a360bbea4dc34280",
            "input": "To be considered for the 2017 IEEE Jack Keil Wolf ISIT Student Paper Award. Interaction information is one of the multivariate generalizations of mutual information, which expresses the amount information shared among a set of variables, beyond the information, which is shared in any proper subset of those variables. Unlike (conditional) mutual information, which is always non-negative, interaction information can be negative. We utilize this property to find the direction of causal influences among variables in a triangle topology under some mild assumptions.",
            "output": [
                "Interaction Information for Causal Inference: The Case of Directed Triangle"
            ]
        },
        {
            "id": "task1540-b55a95dfa1a542c4a6d597724ad6dd26",
            "input": "We provide two fundamental results on the population (infinite-sample) likelihood function of Gaussian mixture models with M ≥ 3 components. Our first main result shows that the population likelihood function has bad local maxima even in the special case of equally-weighted mixtures of well-separated and spherical Gaussians. We prove that the log-likelihood value of these bad local maxima can be arbitrarily worse than that of any global optimum, thereby resolving an open question of Srebro [21]. Our second main result shows that the EM algorithm (or a first-order variant of it) with random initialization will converge to bad critical points with probability at least 1 − e. We further establish that a first-order variant of EM will not converge to strict saddle points almost surely, indicating that the poor performance of the first-order method can be attributed to the existence of bad local maxima rather than bad saddle points. Overall, our results highlight the necessity of careful initialization when using the EM algorithm in practice, even when applied in highly favorable settings.",
            "output": [
                "Local Maxima in the Likelihood of Gaussian Mixture Models: Structural Results and Algorithmic Consequences"
            ]
        },
        {
            "id": "task1540-fe180377011e4f90a775624ad3272b36",
            "input": "Inspired by the hierarchical hidden Markov models (HHMM), we present the hierarchical semi-Markov conditional random field (HSCRF), a generalisation of embedded undirected Markov chains to model complex hierarchical, nested Markov processes. It is parameterised in a discriminative framework and has polynomial time algorithms for learning and inference. Importantly, we consider partiallysupervised learning and propose algorithms for generalised partially-supervised learning and constrained inference. We demonstrate the HSCRF in two applications: (i) recognising human activities of daily living (ADLs) from indoor surveillance cameras, and (ii) noun-phrase chunking. We show that the HSCRF is capable of learning rich hierarchical models with reasonable accuracy in both fully and partially observed data cases.",
            "output": [
                "Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data"
            ]
        },
        {
            "id": "task1540-14fc61bf764b4819a1302403d2677518",
            "input": "Probabilistic Linear Discriminant Analysis (PLDA) has become state-of-the-art method for modeling i-vector space in speaker recognition task. However the performance degradation is observed if enrollment data size differs from one speaker to another. This paper presents a solution to such problem by introducing new PLDA scoring normalization technique. Normalization parameters are derived in a blind way, so that, unlike traditional ZT-norm, no extra development data is required. Moreover, proposed method has shown to be optimal in terms of detection cost function. The experiments conducted on NIST SRE 2014 database demonstrate an improved accuracy in a mixed enrollment number condition.",
            "output": [
                "Blind score normalization method for PLDA based speaker recognition"
            ]
        },
        {
            "id": "task1540-f3168427945d417cb5a828623193bbf3",
            "input": "We introduce a simple and accurate neural model for dependency-based semantic role labeling. Our model predicts predicate-argument dependencies relying on states of a bidirectional LSTM encoder. The semantic role labeler achieves respectable performance on English even without any kind of syntactic information and only using local inference. However, when automatically predicted part-of-speech tags are provided as input, it substantially outperforms all previous local models and approaches the best reported results on the CoNLL-2009 dataset. Syntactic parsers are unreliable on out-of-domain data, so standard (i.e. syntactically-informed) SRL models are hindered when tested in this setting. Our syntax-agnostic model appears more robust, resulting in the best reported results on the standard out-of-domain test set.1",
            "output": [
                "A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling"
            ]
        },
        {
            "id": "task1540-b6bcdb4925174175b19492a392cd92fa",
            "input": "The significant computational costs of deploying neural networks in large-scale or resource constrained environments, such as data centers and mobile devices, has spurred interest in model compression, which can achieve a reduction in both arithmetic operations and storage memory. Several techniques have been proposed for reducing or compressing the parameters for feed-forward and convolutional neural networks, but less is understood about the effect of parameter compression on recurrent neural networks (RNN). In particular, the extent to which the recurrent parameters can be compressed and the impact on short-term memory performance, is not well understood. In this paper, we study the effect of complexity reduction, through singular value decomposition rank reduction, on RNN and minimal gated recurrent unit (MGRU) networks for several tasks. We show that considerable rank reduction is possible when compressing recurrent weights, even without fine tuning. Furthermore, we propose a perturbation model for the effect of general perturbations, such as a compression, on the recurrent parameters of RNNs. The model is tested against a noiseless memorization experiment that elucidates the short-term memory performance. In this way, we demonstrate that the effect of compression of recurrent parameters is dependent on the degree of temporal coherence present in the data and task. This work can guide on-the-fly RNN compression for novel environments or tasks, and provides insight for applying RNN compression in low-power devices, such as hearing aids. Keywords—compression; recurrent neural networks; complexity reduction; SVD; RNN; MGRU; MRU",
            "output": [
                "Parameter Compression of Recurrent Neural Networks and Degredation of Short-term Memory"
            ]
        },
        {
            "id": "task1540-fe3cb0d7087e4dada1b627e9dea6e032",
            "input": "We define a notion of rational closure for the logic SHIQ, which does not enjoys the finite model property, building on the notion of rational closure introduced by Lehmann and Magidor in [23]. We provide a semantic characterization of rational closure in SHIQ in terms of a preferential semantics, based on a finite rank characterization of minimal models. We show that the rational closure of a TBox can be computed in EXPTIME using entailment in SHIQ.",
            "output": [
                "Rational closure in SHIQ"
            ]
        },
        {
            "id": "task1540-e3cddcbba26f41f4b79b44618ec61c1d",
            "input": "To what extent is the success of deep visualization due to the training? Could we do deep visualization using untrained, random weight networks? To address this issue, we explore new and powerful generative models for three popular deep visualization tasks using untrained, random weight convolutional neural networks. First we invert representations in feature spaces and reconstruct images from white noise inputs. The reconstruction quality is statistically higher than that of the same method applied on well trained networks with the same architecture. Next we synthesize textures using scaled correlations of representations in multiple layers and our results are almost indistinguishable with the original natural texture and the synthesized textures based on the trained network. Third, by recasting the content of an image in the style of various artworks, we create artistic images with high perceptual quality, highly competitive to the prior work of Gatys et al. on pretrained networks. To our knowledge this is the first demonstration of image representations using untrained deep neural networks. Our work provides a new and fascinating tool to study the representation of deep network architecture and sheds light on new understandings on deep visualization.",
            "output": [
                "A Powerful Generative Model Using Random Weights for the Deep Image Representation"
            ]
        },
        {
            "id": "task1540-4c5794a5a03a462b9a7223d7f71449df",
            "input": "Estimating student proficiency is an important task for computer based learning systems. We compare a family of IRTbased proficiency estimation methods to Deep Knowledge Tracing (DKT), a recently proposed recurrent neural network model with promising initial results. We evaluate how well each model predicts a student’s future response given previous responses using two publicly available and one proprietary data set. We find that IRT-based methods consistently matched or outperformed DKT across all data sets at the finest level of content granularity that was tractable for them to be trained on. A hierarchical extension of IRT that captured item grouping structure performed best overall. When data sets included non-trivial autocorrelations in student response patterns, a temporal extension of IRT improved performance over standard IRT while the RNNbased method did not. We conclude that IRT-based models provide a simpler, better-performing alternative to existing RNN-based models of student interaction data while also affording more interpretability and guarantees due to their formulation as Bayesian probabilistic models.",
            "output": [
                "Back to the basics: Bayesian extensions of IRT outperform neural networks for proficiency estimation"
            ]
        },
        {
            "id": "task1540-7b86ddbcbe9f43fcaa414b0756a886c1",
            "input": "In this paper, we propose several improvements on the block-coordinate Frank-Wolfe (BCFW) algorithm from Lacoste-Julien et al. (2013) recently used to optimize the structured support vector machine (SSVM) objective in the context of structured prediction, though it has wider applications. The key intuition behind our improvements is that the estimates of block gaps maintained by BCFW reveal the block suboptimality that can be used as an adaptive criterion. First, we sample objects at each iteration of BCFW in an adaptive non-uniform way via gapbased sampling. Second, we incorporate pairwise and away-step variants of Frank-Wolfe into the block-coordinate setting. Third, we cache oracle calls with a cache-hit criterion based on the block gaps. Fourth, we provide the first method to compute an approximate regularization path for SSVM. Finally, we provide an exhaustive empirical evaluation of all our methods on four structured prediction datasets.",
            "output": [
                "Minding the Gaps for Block Frank-Wolfe Optimization of Structured SVMs"
            ]
        },
        {
            "id": "task1540-ebc163d1a40e4b8a8fb5c36973762266",
            "input": "Machine learning relies on the assumption that unseen test instances of a classification problem follow the same distribution as observed training data. However, this principle can break down when machine learning is used to make important decisions about the welfare (employment, education, health) of strategic individuals. Knowing information about the classifier, such individuals may manipulate their attributes in order to obtain a better classification outcome. As a result of this behavior—often referred to as gaming—the performance of the classifier may deteriorate sharply. Indeed, gaming is a well-known obstacle for using machine learning methods in practice; in financial policy-making, the problem is widely known as Goodhart’s law. In this paper, we formalize the problem, and pursue algorithms for learning classifiers that are robust to gaming. We model classification as a sequential game between a player named “Jury” and a player named “Contestant.” Jury designs a classifier, and Contestant receives an input to the classifier drawn from a distribution. Before being classified, Contestant may change his input based on Jury’s classifier. However, Contestant incurs a cost for these changes according to a cost function. Jury’s goal is to achieve high classification accuracy with respect to Contestant’s original input and some underlying target classification function, assuming Contestant plays best response. Contestant’s goal is to achieve a favorable classification outcome while taking into account the cost of achieving it. For a natural class of separable cost functions, and certain generalizations, we obtain computationally efficient learning algorithms which are near optimal, achieving a classification error that is arbitrarily close to the theoretical minimum. Surprisingly, our algorithms are efficient even on concept classes that are computationally hard to learn. For general cost functions, designing an approximately optimal strategy-proof classifier, for inverse-polynomial approximation, is NP-hard. ar X iv :1 50 6. 06 98 0v 1 [ cs .L G ] 2 3 Ju n 20 15",
            "output": [
                "Strategic Classification"
            ]
        },
        {
            "id": "task1540-c06e2b7b8d9a47cc85daf3700971fb67",
            "input": "We apply multilayer bootstrap network (MBN), a recent pro-<lb>posed unsupervised learning method, to unsupervised speaker<lb>recognition. The proposed method first extracts supervectors<lb>from an unsupervised universal background model, then re-<lb>duces the dimension of the high-dimensional supervectors by<lb>multilayer bootstrap network, and finally conducts unsuper-<lb>vised speaker recognition by clustering the low-dimensional<lb>data. The comparison results with 2 unsupervised and 1 su-<lb>pervised speaker recognition techniques demonstrate the ef-<lb>fectiveness and robustness of the proposed method.",
            "output": [
                "MULTILAYER BOOTSTRAP NETWORK FOR UNSUPERVISED SPEAKER RECOGNITION"
            ]
        },
        {
            "id": "task1540-35d5471287c14bd1b55f9ed18bcda302",
            "input": "We present an annotation schema as part of an effort to create a manually annotated corpus for Arabic dialogue language understanding including spoken dialogue and written „chat‟ dialogue for inquiryanswer domain. The proposed schema handles mainly the request and response acts that occurs frequently in inquiry-answer debate conversations expressing request services, suggests, and offers. We applied the proposed schema on 83 Arabic inquiry-answer dialogues.",
            "output": [
                "Arabic Inquiry-Answer Dialogue Acts Annotation Schema"
            ]
        },
        {
            "id": "task1540-b27ed51b84af4c1f816739d2c4b4a158",
            "input": "The development of machine learning in particular and artificial intelligent in general has been strongly conditioned by the lack of an appropriate interface layer between deduction, abduction and induction [1]. In this work we extend traditional algebraic specification methods [2] in this direction. Here we assume that such interface for AI emerges from an adequate Neural-Symbolic integration [3]. This integration is made for universe of discourse described on a Topos[4] governed by a many-valued Lukasiewicz logic. Sentences are integrated in a symbolic knowledge base describing the problem domain, codified using a graphicbased language, wherein every logic connective is defined by a neuron in an artificial network. This allows the integration of first-order formulas into a network architecture as background knowledge, and simplifies symbolic rule extraction from trained networks. For the train of such neural networks we changed the Levenderg-Marquardt algorithm [5], restricting the knowledge dissemination in the network structure using soft crystallization. This procedure reduces neural network plasticity without drastically damaging the learning performance, allowing the emergence of symbolic patterns. This makes the descriptive power of produced neural networks similar to the descriptive power of Lukasiewicz logic language, reducing the information lost on translation between symbolic and connectionist structures. We tested this method on the extraction of knowledge from specified structures. For it, we present the notion of fuzzy state automata, and we use automata behaviour to infer its structure. We use this type of automata on the generation of models for relations specified as symbolic background knowledge. Using the involved automata behaviour as data sets, we used our learning methodology, to extract new insights about the models, and inject them into the specification. This allows the improvement about the problem domain knowledge. ———————————————————————–",
            "output": [
                "KNOWLEDGE EXTRACTION AND KNOWLEDGE INTEGRATION GOVERNED BY LUKASIEWICZ LOGICS"
            ]
        },
        {
            "id": "task1540-149bc602d3084e259923c07599a36557",
            "input": "The user equilibrium in traffic assignment problem is based on the fact that travelers choose the minimum-cost path between every origin-destination pair and on the assumption that such a behavior will lead to an equilibrium of the traffic network. In this paper, we consider this problem when the traffic network links are fuzzy cost. Therefore, a Physarum-type algorithm is developed to unify the Physarum network and the traffic network for taking full of advantage of Physarum Polycephalum’s adaptivity in network design to solve the user equilibrium problem. Eventually, some experiments are used to test the performance of this method. The results demonstrate that our approach is competitive when compared with other existing algorithms.",
            "output": [
                "A bio-inspired algorithm for fuzzy user equilibrium problem by aid of Physarum Polycephalum"
            ]
        },
        {
            "id": "task1540-acc4cc327b8a491b8b2dfd0bee37c675",
            "input": "Neural machine translation has become a major alternative to widely used phrase-based statistical machine translation. We notice however that much of research on neural machine translation has focused on European languages despite its language agnostic nature. In this paper, we apply neural machine translation to the task of Arabic translation (Ar↔En) and compare it against a standard phrase-based translation system. We run extensive comparison using various configurations in preprocessing Arabic script and show that the phrase-based and neural translation systems perform comparably to each other and that proper preprocessing of Arabic script has a similar effect on both of the systems. We however observe that the neural machine translation significantly outperform the phrase-based system on an out-of-domain test set, making it attractive for real-world deployment.",
            "output": [
                "First Result on Arabic Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-863499ce8c0c480784b59bfcff1fed40",
            "input": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learningbased Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User’s question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.",
            "output": [
                "Learning to Query, Reason, and Answer Questions On Ambiguous Texts"
            ]
        },
        {
            "id": "task1540-c8be7cf1e8914b85ab857156e4eb7ef3",
            "input": "We propose a novel framework for the analysis of learning algorithms that allows us to say when such algorithms can and cannot generalize certain patterns from training data to test data. In particular we focus on situations where the rule that must be learned concerns two components of a stimulus being identical. We call such a basis for discrimination an identitybased rule. Identity-based rules have proven to be difficult or impossible for certain types of learning algorithms to acquire from limited datasets. This is in contrast to human behaviour on similar tasks. Here we provide a framework for rigorously establishing which learning algorithms will fail at generalizing identity-based rules to novel stimuli. We use this framework to show that such algorithms are unable to generalize identitybased rules to novel inputs unless trained on virtually all possible inputs. We demonstrate these results computationally with a multilayer feedforward neural network.",
            "output": [
                "Which Learning Algorithms Can Generalize Identity-Based Rules to Novel Inputs?"
            ]
        },
        {
            "id": "task1540-cc94dab537c444f3a2e4f2e872fd024a",
            "input": "Predicting user responses, such as clicks and conversions, is of great importance and has found its usage in many Web applications including recommender systems, web search and online advertising. The data in those applications is mostly categorical and contains multiple fields; a typical representation is to transform it into a high-dimensional sparse binary feature representation via one-hot encoding. Facing with the extreme sparsity, traditional models may limit their capacity of mining shallow patterns from the data, i.e. low-order feature combinations. Deep models like deep neural networks, on the other hand, cannot be directly applied for the high-dimensional input because of the huge feature space. In this paper, we propose a Product-based Neural Networks (PNN) with an embedding layer to learn a distributed representation of the categorical data, a product layer to capture interactive patterns between interfield categories, and further fully connected layers to explore high-order feature interactions. Our experimental results on two large-scale real-world ad click datasets demonstrate that PNNs consistently outperform the state-of-the-art models on various metrics.",
            "output": [
                "Product-based Neural Networks for User Response Prediction"
            ]
        },
        {
            "id": "task1540-d7b9d88e372d4a82b071a2c4852eb9ac",
            "input": "Truth discovery is to resolve conflicts and find the truth from multiple-source statements. Conventional methods mostly research based on the mutual effect between the reliability of sources and the credibility of statements, however, pay no attention to the mutual effect among the credibility of statements about the same object. We propose memory network based models to incorporate these two ideas to do the truth discovery. We use feedforward memory network and feedback memory network to learn the representation of the credibility of statements which are about the same object. Specially, we adopt memory mechanism to learn source reliability and use it through truth prediction. During learning models, we use multiple types of data (categorical data and continuous data) by assigning different weights automatically in the loss function based on their own effect on truth discovery prediction. The experiment results show that the memory network based models much outperform the state-of-the-art method and other baseline methods.",
            "output": [
                "Truth Discovery with Memory Network"
            ]
        },
        {
            "id": "task1540-2ebbd08343954d60af3fbf0b421fb0f8",
            "input": "Stacked denoising auto encoders (DAEs) are well known to learn useful deep representations, which can be used to improve supervised training by initializing a deep network. We investigate a training scheme of a deep DAE, where DAE layers are gradually added and keep adapting as additional layers are added. We show that in the regime of mid-sized datasets, this gradual training provides a small but consistent improvement over stacked training in both reconstruction quality and classification error over stacked training on MNIST and CIFAR datasets. 1 GRADUAL TRAINING OF DENOISING AUTOENCODERS We test here gradual training of deep denoising auto encoders, training the network layer-by-layer, but lower layers keep adapting throughout training. To allow lower layers to adapt continuously, noise is injected at the input level. This training procedure differs from stack-training of auto encoders (Vincent et al., 2010) More specifically, in gradual training, the first layer of the deep DAE is trained as in stacked training, producing a layer of weights w1. Then, when adding the second layer autoencoder, its weights w2 are tuned jointly with the already-trained weights w1. Given a training sample x, we generate a noisy version x̃, feed it to the 2-layered DAE, and compute the activation at the subsequent layers h1 = Sigmoid(w > 1 x), h2 = Sigmoid(w > 2 h1) and y = Sigmoid(w ′> 3 h2). Importantly, the loss function is computed over the input x, and is used to update all the weights including w1. Similarly, if a 3rd layer is trained, it involves tuning w1 and w2 in addition to w3 and w′ 4. 2 EXPERIMENTAL PROCEDURES We compare the performance of gradual and stacked training in two learning setups: an unsupervised denoising task, and a supervised classification task initialized using the weights learned in an unsupervised way. Evaluations were made on three benchmarks: MNIST, CIFAR-10 and CIFAR100, but only show here MNIST results due to space constraints. We used a test subset of 10,000 samples and several sizes of training-set all maintaining the uniform distribution over classes. Hyper parameters were selected using a second level of cross validation, including the learning rate, SGD batch size, momentum and weight decay. In the supervised experiments, training was ’early stopped’ after 35 epochs without improvement. The results reported below are averages over 3 train-validation splits. Since gradual training involves updating lower layers, every presentation of a sample involves more weight updates than in a single-layered DAE. To compare stacked and gradual training on a common ground, we limited gradual training to use the same budget of weight update steps as stacked training. For example, when training the second layer for n epochs in gradual training, we allocate 2n training epochs for stacked training (details in the full paper). 1 ar X iv :1 50 4. 02 90 2v 1 [ cs .L G ] 1 1 A pr 2 01 5 Accepted as a workshop contribution at ICLR 2015 a) Unsupervised Training b) Supervised training 0 0.25 0.5 10.4 10.5 10.6 10.7",
            "output": [
                "GRADUAL TRAINING METHOD FOR DENOISING AUTO ENCODERS"
            ]
        },
        {
            "id": "task1540-3e55ebf394984d258d40694798aeece2",
            "input": "We present a method for implementing an Efficient Unitary Neural Network (EUNN) whose computational complexity is merelyO(1) per parameter and has full tunability, from spanning part of unitary space to all of it. We apply the EUNN in Recurrent Neural Networks, and test its performance on the standard copying task and the MNIST digit recognition benchmark, finding that it significantly outperforms a non-unitary RNN, an LSTM network, an exclusively partial space URNN and a projective URNN with comparable parameter numbers.",
            "output": [
                "Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNN"
            ]
        },
        {
            "id": "task1540-b50e8dbb1dc544aebfbcccb0a02488d8",
            "input": "Without discourse connectives, classifying implicit discourse relations is a challenging task and a bottleneck for building a practical discourse parser. Previous research usually makes use of one kind of discourse framework such as PDTB or RST to improve the classification performance on discourse relations. Actually, under different discourse annotation frameworks, there exist multiple corpora which have internal connections. To exploit the combination of different discourse corpora, we design related discourse classification tasks specific to a corpus, and propose a novel Convolutional Neural Network embedded multi-task learning system to synthesize these tasks by learning both unique and shared representations for each task. The experimental results on the PDTB implicit discourse relation classification task demonstrate that our model achieves significant gains over baseline systems.",
            "output": [
                "Implicit Discourse Relation Classification via Multi-Task Neural Networks"
            ]
        },
        {
            "id": "task1540-bcb103c3e403487fbf69c0efa6d38aa4",
            "input": "Seven years on from OWL becoming a W3C recommendation, and two years on from the more recent OWL 2 W3C recommendation, OWL has still experienced only patchy uptake on the Web. Although certain OWL features (like owl:sameAs) are very popular, other features of OWL are largely neglected by publishers in the Linked Data world. This may suggest that despite the promise of easy implementations and the proposal of tractable profiles suggested in OWL’s second version, there is still no “right” standard fragment for the Linked Data community. In this paper, we (1) analyse uptake of OWL on the Web of Data, (2) gain insights into the OWL fragment that is actually used/usable on the Web, where we arrive at the conclusion that this fragment is likely to be a simplified profile based on OWL RL, (3) propose and discuss such a new fragment, which we call OWL LD (for Linked Data).",
            "output": [
                "OWL: Yet to arrive on the Web of Data?"
            ]
        },
        {
            "id": "task1540-c88fd7f8e454493db695f0194c797496",
            "input": "LP relaxation-based message passing algorithms provide an effective tool for MAP inference over Probabilistic Graphical Models. However, different LP relaxations often have different objective functions and variables of differing dimensions, which presents a barrier to effective comparison and analysis. In addition, the computational complexity of LP relaxation-based methods grows quickly with the number of constraints. Reducing the number of constraints without sacrificing the quality of the solutions is thus desirable. We propose a unified formulation under which existing MAP LP relaxations may be compared and analysed. Furthermore, we propose a new tool called Marginal Polytope Diagrams. Some properties of Marginal Polytope Diagrams are exploited such as node redundancy and edge equivalence. We show that using Marginal Polytope Diagrams allows the number of constraints to be reduced without loosening the LP relaxations. Then, using Marginal Polytope Diagrams and constraint reduction, we develop three novel message passing algorithms, and demonstrate that two of these show a significant improvement in speed over state-of-art algorithms while delivering a competitive, and sometimes higher, quality of solution.",
            "output": [
                "Constraint Reduction using Marginal Polytope Diagrams for MAP LP Relaxations"
            ]
        },
        {
            "id": "task1540-30feef64f3e9474ea42b092e5478b5d0",
            "input": "Approximate Markov chain Monte Carlo (MCMC) offers the promise of more rapid sampling at the cost of more biased inference. Since standard MCMC diagnostics fail to detect these biases, researchers have developed computable Stein discrepancy measures that provably determine the convergence of a sample to its target distribution. This approach was recently combined with the theory of reproducing kernels to define a closed-form kernel Stein discrepancy (KSD) computable by summing kernel evaluations across pairs of sample points. We develop a theory of weak convergence for KSDs based on Stein’s method, demonstrate that commonly used KSDs fail to detect non-convergence even for Gaussian targets, and show that kernels with slowly decaying tails provably determine convergence for a large class of target distributions. The resulting convergence-determining KSDs are suitable for comparing biased, exact, and deterministic sample sequences and simpler to compute and parallelize than alternative Stein discrepancies. We use our tools to compare biased samplers, select sampler hyperparameters, and improve upon existing KSD approaches to one-sample hypothesis testing and sample quality improvement.",
            "output": [
                "Measuring Sample Quality with Kernels"
            ]
        },
        {
            "id": "task1540-8cdbea7ec4fb4a6b98e951450c9cc6a7",
            "input": "Algorithm portfolios represent a strategy of composing multiple heuristic algorithms, each suited to a different class of problems, within a single general solver that will choose the best suited algorithm for each input. This approach recently gained popularity especially for solving combinatoric problems, but optimization applications are still emerging. The COCO platform [6] [5] of the BBOB workshop series is the current standard way to measure performance of continuous black-box optimization algorithms. As an extension to the COCO platform, we present the Python-based COCOpf framework that allows composing portfolios of optimization algorithms and running experiments with different selection strategies. In our framework, we focus on black-box algorithm portfolio and online adaptive selection. As a demonstration, we measure the performance of stock SciPy [8] optimization algorithms and the popular CMA algorithm [4] alone and in a portfolio with two simple selection strategies. We confirm that even a naive selection strategy can provide improved performance across problem classes.",
            "output": [
                "COCOpf: An Algorithm Portfolio Framework"
            ]
        },
        {
            "id": "task1540-3d97915dd6cd4a599509e939957982e4",
            "input": "This paper addresses the problem of detecting coherent motions in crowd scenes and presents its two applications in crowd scene understanding: semantic region detection and recurrent activity mining. It processes input motion fields (e.g., optical flow fields) and produces a coherent motion filed, named as thermal energy field. The thermal energy field is able to capture both motion correlation among particles and the motion trends of individual particles which are helpful to discover coherency among them. We further introduce a two-step clustering process to construct stable semantic regions from the extracted time-varying coherent motions. These semantic regions can be used to recognize pre-defined activities in crowd scenes. Finally, we introduce a cluster-and-merge process which automatically discovers recurrent activities in crowd scenes by clustering and merging the extracted coherent motions. Experiments on various videos demonstrate the effectiveness of our approach.",
            "output": [
                "A Diffusion and Clustering-based Approach for Finding Coherent Motions and Understanding Crowd Scenes"
            ]
        },
        {
            "id": "task1540-0af9797024a84fe6bc037f6c2e0f3f5e",
            "input": "We consider the problem of efficient exploration in finite horizon MDPs. We show that an optimistic modification to modelbased value iteration, can achieve a regret bound Õ( √ HSAT+HSA+H √ T )whereH is the time horizon, S the number of states, A the number of actions and T the time elapsed. This result improves over the best previous known bound Õ(HS √ AT ) achieved by the UCRL2 algorithm Jaksch et al. (2010a). The key significance of our new results is that when T ≥ HSA and SA ≥ H , it leads to a regret of Õ( √ HSAT ) that matches the established lower bounds of Ω( √ HSAT ) up to a logarithmic factor. Our analysis contain two key insights. We use careful application of concentration inequalities to the optimal value function as a whole, rather than to the transitions probabilities (to improve scaling in S), and we use \"exploration bonuses\" based on Bernstein’s inequality, together with using a recursive -Bellman-typeLaw of Total Variance (to improve scaling in H).",
            "output": [
                "Minimax Regret Bounds for Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-25436e02ec2842d4bf67be1956489514",
            "input": "In this work we describe and evaluate methods to learn musical embeddings. Each embedding is a vector that represents four contiguous beats of music and is derived from a symbolic representation. We consider autoencoding-based methods including denoising autoencoders, and context reconstruction, and evaluate the resulting embeddings on a forward prediction and a classification task.",
            "output": [
                "A Unit Selection Methodology for Music Generation Using Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-bf09b7d8abd046b9a83f37d9ff9ccebd",
            "input": "Our objective is to efficiently design a robust projection matrix Φ for the Compressive Sensing (CS) systems when applied to the signals that are not exactly sparse. The optimal projection matrix is obtained by mainly minimizing the average coherence of the equivalent dictionary. In order to drop the requirement of the sparse representation error (SRE) for a set of training data as in [15] [16], we introduce a novel penalty function independent of a particular SRE matrix. Without requiring of training data, we can efficiently design the robust projection matrix and apply it for most of CS systems, like a CS system for image processing with a conventional wavelet dictionary in which the SRE matrix is generally not available. Simulation results demonstrate the efficiency and effectiveness of the proposed approach compared with the state-of-the-art methods. In addition, we experimentally demonstrate with natural images that under similar compression rate, a CS system with a learned dictionary in high dimensions outperforms the one in low dimensions in terms of reconstruction accuracy. This together with the fact that our proposed method can efficiently work in high dimension suggests that a CS system can be potentially implemented beyond the small patches in sparsity-based image processing.",
            "output": [
                "An Efficient Method for Robust Projection Matrix Design"
            ]
        },
        {
            "id": "task1540-e5968256dc044770829983e29290c642",
            "input": "Answer sentence selection is the task of identifying sentences that contain the answer to a given question. This is an important problem in its own right as well as in the larger context of open domain question answering. We propose a novel approach to solving this task via means of distributed representations, and learn to match questions with answers by considering their semantic encoding. This contrasts prior work on this task, which typically relies on classifiers with large numbers of hand-crafted syntactic and semantic features and various external resources. Our approach does not require any feature engineering nor does it involve specialist linguistic data, making this model easily applicable to a wide range of domains and languages. Experimental results on a standard benchmark dataset from TREC demonstrate that—despite its simplicity—our model matches state of the art performance on the answer sentence selection task.",
            "output": [
                "Deep Learning for Answer Sentence Selection"
            ]
        },
        {
            "id": "task1540-44c061fa20e04455b6bfdf6dc3e67015",
            "input": "Network models play an important role in studying complex systems in many scientific disciplines. Graph signal processing is receiving growing interest as to design novel tools to combine the analysis of topology and signals. The graph Fourier transform, defined as the eigendecomposition of the graph Laplacian, allows extending conventional signal-processing operations to graphs. One main feature is to let emerge global organization from local interactions; i.e., the Fiedler vector has the smallest non-zero eigenvalue and is key for Laplacian embedding and graph clustering. Here, we introduce the design of Slepian graph signals, by maximizing energy concentration in a predefined subgraph for a given spectral bandlimit. We also establish a link with classical Laplacian embedding and graph clustering, for which the graph Slepian design can serve as a generalization.",
            "output": [
                "When Slepian Meets Fiedler: Putting a Focus on the Graph Spectrum"
            ]
        },
        {
            "id": "task1540-9fd8ecc113d9460f8a6fa32f98ec4e1b",
            "input": "A new approach called SKYSET (Synthetic Knowledge Yield Social Entities Translation) is proposed to validate completeness and to reduce ambiguity from written instructional documentation. SKYSET utilizes a quintuple set of standardized categories, which differs from traditional approaches that typically use triples. The SKYSET System defines the categories required to form a standard template for representing information that is portable across different domains. It provides a standardized framework that enables sentences from written instructions to be translated into sets of category typed entities on a table or database. The SKYSET entities contain conceptual units or phrases that represent information from the original source documentation. SKYSET enables information concatenation where multiple documents from different domains can be translated and combined into a single common filterable and searchable table of entities. Index Terms – Cognitive Linguistics, Dual Intentional Semantic Decomposition and Reconstruction (DISDR), Frame Semantics, Information Concatenation, Information Integration, Information Summarization, Knowledge Architecture, Knowledge Management Internal External (KMIE), Metalinguistic Awareness, Synthetic Knowledge Yield Social Entities Translation (SKYSET).",
            "output": [
                "Introducing SKYSET - a Quintuple Approach for Improving Instructions"
            ]
        },
        {
            "id": "task1540-fed20d91964e479882ae7167d21e20f4",
            "input": "We study the problem of multiclass classification with an extremely large number<lb>of classes, with the goal of obtaining train and test time complexity logarithmic<lb>in the number of classes. We develop top-down tree construction approaches for<lb>constructing logarithmic depth trees. On the theoretical front, we formulate a new<lb>objective function, which is optimized at each node of the tree and creates dy-<lb>namic partitions of the data which are both pure (in terms of class labels) and<lb>balanced. We demonstrate that under favorable conditions, we can construct loga-<lb>rithmic depth trees that have leaves with low label entropy. However, the objective<lb>function at the nodes is challenging to optimize computationally. We address the<lb>empirical problem with a new online decision tree construction procedure. Exper-<lb>iments demonstrate that this online algorithm quickly achieves small error rates<lb>relative to more common O(k) approaches and simultaneously achieves signif-<lb>icant improvement in test error compared to other logarithmic training time ap-<lb>proaches.",
            "output": [
                "Logarithmic Time Online Multiclass prediction"
            ]
        },
        {
            "id": "task1540-59be0273b1f94c6d8d1da2c0c5efb687",
            "input": "In this work we present a new approach to the treatment of property graphs using neural encoding techniques derived from machine learning. Specifically, we will deal with the problem of embedding property graphs in vector spaces. Throughout this paper we will use the term embedding as an operation that allows to consider a mathematical structure, X, inside another structure Y , through a function, f : X → Y . We are interested on embeddings capable of capturing, within the characteristics of a vector space (distance, linearity, clustering, etc.), the interesting features of the graph. For example, it would be interesting to get embeddings that, when projecting the nodes of the graph into points of a vector space, keep edges with the same type of the graph into the same vectors. In this way, we can interpret that the semantic associated to the relation has been captured by the embedding. Another option is to check if the embedding verifies clustering properties with respect to the types of nodes, types of edges, properties, or some of the metrics that can be measured on the graph. Subsequently, we will use these good embedding features to try to obtain prediction / classification / discovery tools on the original graph. This paper is structured as follows: we will start by giving some preliminary definitions necessary for the presentation of our proposal and a brief introduction to the use of artificial neural networks as encoding machines. After this review, we will present our embedding proposal based on neural encoders, and we will verify if the topological and semantic characteristics of the original graph have been maintained in the new representation. After evaluating the properties of the new representation, it will be used to carry out machine learning and discovery tasks on real databases. Finally, we will present some conclusions and future work proposals that have arisen during the implementation of this work.",
            "output": [
                "Semantic Preserving Embeddings for Generalized Graphs"
            ]
        },
        {
            "id": "task1540-be90d75d13ce4d7da1d96697af98443c",
            "input": "Video captioning has been attracting broad research attention in multimedia community. However, most existing approaches either ignore temporal information among video frames or just employ local contextual temporal knowledge. In this work, we propose a novel video captioning framework, termed as Bidirectional Long-Short Term Memory (BiLSTM), which deeply captures bidirectional global temporal structure in video. Specifically, we first devise a joint visual modelling approach to encode video data by combining a forward LSTM pass, a backward LSTM pass, together with visual features from Convolutional Neural Networks (CNNs). Then, we inject the derived video representation into the subsequent language model for initialization. The benefits are in two folds: 1) comprehensively preserving sequential and visual information; and 2) adaptively learning dense visual features and sparse semantic representations for videos and sentences, respectively. We verify the effectiveness of our proposed video captioning framework on a commonlyused benchmark, i.e., Microsoft Video Description (MSVD) corpus, and the experimental results demonstrate that the superiority of the proposed approach as compared to several state-of-the-art methods.",
            "output": [
                "Bidirectional Long-Short Term Memory for Video Description"
            ]
        },
        {
            "id": "task1540-38242a4e67174946b816fac2c9469692",
            "input": "We show that matrix completion with tracenorm regularization can be significantly hurt when entries of the matrix are sampled nonuniformly. We introduce a weighted version of the trace-norm regularizer that works well also with non-uniform sampling. Our experimental results demonstrate that the weighted trace-norm regularization indeed yields significant gains on the (highly non-uniformly sampled) Netflix dataset.",
            "output": [
                "Collaborative Filtering in a Non-Uniform World:  Learning with the Weighted Trace Norm"
            ]
        },
        {
            "id": "task1540-61a44742e9d14baab92dfbca1c2cfccb",
            "input": "The success of kernel methods has initiated the design of novel positive semidefinite functions, in particular for structured data. A leading design paradigm for this is the convolution kernel, which decomposes structured objects into their parts and sums over all pairs of parts. Assignment kernels, in contrast, are obtained from an optimal bijection between parts, which can provide a more valid notion of similarity. In general however, optimal assignments yield indefinite functions, which complicates their use in kernel methods. We characterize a class of base kernels used to compare parts that guarantees positive semidefinite optimal assignment kernels. These base kernels give rise to hierarchies from which the optimal assignment kernels are computed in linear time by histogram intersection. We apply these results by developing the Weisfeiler-Lehman optimal assignment kernel for graphs. It provides high classification accuracy on widely-used benchmark data sets improving over the original Weisfeiler-Lehman kernel.",
            "output": [
                "On Valid Optimal Assignment Kernels and Applications to Graph Classification"
            ]
        },
        {
            "id": "task1540-afade53ff2d14cc8bf3c02c4cb6a5611",
            "input": "We document a connection between constraint reasoning and probabilistic reasoning. We present an algorithm, called probabilistic arc consistency, which is both a generalization of a well known algorithm for arc consistency used in constraint reasoning, and a specialization of the belief updating algorithm for singly-connected networks. Our algorithm is exact for singly­ connected constraint problems, but can work well as an approximation for arbitrary problems. We briefly discuss some empirical results, and re­ lated methods.",
            "output": [
                "Probabilistic Arc Consistency: A Connection between Constraint Reasoning and Probabilistic Reasoning"
            ]
        },
        {
            "id": "task1540-42fece9d0f464aae926051a73fd5ee35",
            "input": "The ability to predict which patterns are formed in brain scans when imagining a celery or an airplane, based on how these concepts as words co-occur in texts, suggests that it is possible to model mental representations based on word statistics. Whether counting how frequently nouns and verbs combine in Google search queries, or extracting eigenvectors from matrices made up of Wikipedia lines and Shakespeare plots, these latent semantics approximate the associative links that form concepts. However, cognition is fundamentally intertwined with action; even passively reading verbs has been shown to activate the same motor circuits as when we tap a finger or observe actual movements. If languages evolved by adapting to the brain, sensorimotor constraints linking articulatory gestures with aspects of motion might also be reflected in the statistics of word co-occurrences. To probe this hypothesis 3 × 20 emotion, face, and hand related verbs known to activate premotor areas in the brain were selected, and latent semantic analysis LSA was applied to create a weighted adjacency matrix. Hierarchically clustering the verbs and modeling their connectivity within a force directed graph, they divide into modules of mouth and hand motion, facial expressions and negative emotions. Transforming the verbs into their constituent phonemes, the corresponding consonant vowel transitions can be represented in an articulatory space defined by tongue height and formant frequencies. Here the vowels appear positioned along a front to back continuum reflecting aspects of size and intensity related to the actions described by the verbs. More forceful verbs combine plosives and sonorants with fricatives characterized by sustained turbulent airflows, while positive and negative emotional expressions tend to incorporate upor downwards shifts in formant frequencies. Suggesting, that articulatory gestures reflect parameters of size and intensity which might be retrieved from the latent semantics of action verbs.",
            "output": [
                "When push comes to shove verbs literally shake due to latent semantic parameters of size and intensity"
            ]
        },
        {
            "id": "task1540-b884b2b941584ff19c6823a7b673c04d",
            "input": "Previous studies have demonstrated that encoding a Bayesian network into a SAT formula and then performing weighted model counting using a backtracking search algorithm can be an effective method for exact inference. In this paper, we present techniques for improving this approach for Bayesian networks with noisy-OR and noisy-MAX relations— two relations that are widely used in practice as they can dramatically reduce the number of probabilities one needs to specify. In particular, we present two SAT encodings for noisy-OR and two encodings for noisy-MAX that exploit the structure or semantics of the relations to improve both time and space efficiency, and we prove the correctness of the encodings. We experimentally evaluated our techniques on large-scale real and randomly generated Bayesian networks. On these benchmarks, our techniques gave speedups of up to two orders of magnitude over the best previous approaches for networks with noisyOR/MAX relations and scaled up to larger networks. As well, our techniques extend the weighted model counting approach for exact inference to networks that were previously intractable for the approach.",
            "output": [
                "Exploiting Structure in Weighted Model Counting Approaches to Probabilistic Inference"
            ]
        },
        {
            "id": "task1540-c2815caf51fb4989ae2fd56529bd3a9e",
            "input": "The number of computers, tablets and smartphones is increasing rapidly, which entails the ownership and use of multiple devices to perform online tasks. As people move across devices to complete these tasks, their identities becomes fragmented. Understanding the usage and transition between those devices is essential to develop efficient applications in a multi-device world. In this paper we present a solution to deal with the cross-device identification of users based on semi-supervised machine learning methods to identify which cookies belong to an individual using a device. The method proposed in this paper scored third in the ICDM 2015 Drawbridge Cross-Device Connections challenge proving its good performance.",
            "output": [
                "Cross-Device Tracking: Matching Devices and Cookies"
            ]
        },
        {
            "id": "task1540-f89ab245e89d4b9d9f7e1185545c4dea",
            "input": "We describe the class of convexified convolutional neural networks (CCNNs), which capture the parameter sharing of convolutional neural networks in a convex manner. By representing the nonlinear convolutional filters as vectors in a reproducing kernel Hilbert space, the CNN parameters can be represented as a low-rank matrix, which can be relaxed to obtain a convex optimization problem. For learning two-layer convolutional neural networks, we prove that the generalization error obtained by a convexified CNN converges to that of the best possible CNN. For learning deeper networks, we train CCNNs in a layer-wise manner. Empirically, CCNNs achieve performance competitive with CNNs trained by backpropagation, SVMs, fully-connected neural networks, stacked denoising auto-encoders, and other baseline methods.",
            "output": [
                "Convexified Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-17029dc2c7bf4823a9c7e93e3ebf90d9",
            "input": "Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box. c © 2016 Elsevier Ltd. All rights reserved.",
            "output": [
                "Representation learning for very short texts using weighted word embedding aggregation"
            ]
        },
        {
            "id": "task1540-0c2cf6ff005b4da3b9e3986978703705",
            "input": "Distributed dense word vectors have been shown to be effective at capturing tokenlevel semantic and syntactic regularities in language, while topic models can form interpretable representations over documents. In this work, we describe lda2vec, a model that learns dense word vectors jointly with Dirichlet-distributed latent document-level mixtures of topic vectors. In contrast to continuous dense document representations, this formulation produces sparse, interpretable document mixtures through a non-negative simplex constraint. Our method is simple to incorporate into existing automatic differentiation frameworks and allows for unsupervised document representations geared for use by scientists while simultaneously learning word vectors and the linear relationships between them.",
            "output": [
                "Mixing Dirichlet Topic Models and Word Embeddings to Make lda2vec"
            ]
        },
        {
            "id": "task1540-ba488c4a4abc401582cc74e917f77ebd",
            "input": "We address the problem of general supervised learning when data can only be ac-<lb>cessed through an (indefinite) similarity function between data points. Existing<lb>work on learning with indefinite kernels has concentrated solely on binary/multi-<lb>class classification problems. We propose a model that is generic enough to handle<lb>any supervised learning task and also subsumes the model previously proposed for<lb>classification. We give a “goodness” criterion for similarity functions w.r.t. a given<lb>supervised learning task and then adapt a well-known landmarking technique to<lb>provide efficient algorithms for supervised learning using “good” similarity func-<lb>tions. We demonstrate the effectiveness of our model on three important super-<lb>vised learning problems: a) real-valued regression, b) ordinal regression and c)<lb>ranking where we show that our method guarantees bounded generalization error.<lb>Furthermore, for the case of real-valued regression, we give a natural goodness<lb>definition that, when used in conjunction with a recent result in sparse vector re-<lb>covery, guarantees a sparse predictor with bounded generalization error. Finally,<lb>we report results of our learning algorithms on regression and ordinal regression<lb>tasks using non-PSD similarity functions and demonstrate the effectiveness of<lb>our algorithms, especially that of the sparse landmark selection algorithm that<lb>achieves significantly higher accuracies than the baseline methods while offering<lb>reduced computational costs.",
            "output": [
                "Supervised Learning with Similarity Functions"
            ]
        },
        {
            "id": "task1540-02309158448149829a170b96131ffdcc",
            "input": "We study the problem of identifying individuals based on their characteristic gaze patterns during reading of arbitrary text. The motivation for this problem is an unobtrusive biometric setting in which a user is observed during access to a document, but no specific challenge protocol requiring the user’s time and attention is carried out. Existing models of individual differences in gaze control during reading are either based on simple aggregate features of eye movements, or rely on parametric density models to describe, for instance, saccade amplitudes or word fixation durations. We develop flexible semiparametric models of eye movements during reading in which densities are inferred under a Gaussian process prior centered at a parametric distribution family that is expected to approximate the true distribution well. An empirical study on reading data from 251 individuals shows significant improvements over the state of the art.",
            "output": [
                "A Semiparametric Model for Bayesian Reader Identification"
            ]
        },
        {
            "id": "task1540-7464d89a76564b788fe3b53a9923675d",
            "input": "Generating optimal plans in highly dynamic environments is challenging. Plans are predicated on an assumed initial state, but this state can change unexpectedly during plan generation, potentially invalidating the planning effort. In this paper we make three contributions: (1) We propose a novel algorithm for generating optimal plans in settings where frequent, unexpected events interfere with planning. It is able to quickly distinguish relevant from irrelevant state changes, and to update the existing planning search tree if necessary. (2) We argue for a new criterion for evaluating plan adaptation techniques: the relative running time compared to the “size” of changes. This is significant since during recovery more changes may occur that need to be recovered from subsequently, and in order for this process of repeated recovery to terminate, recovery time has to converge. (3) We show empirically that our approach can converge and find optimal plans in environments that would ordinarily defy planning due to their high dynamics.",
            "output": [
                "Generating Optimal Plans in Highly-Dynamic Domains"
            ]
        },
        {
            "id": "task1540-a7b61800f9d142629f5ae26531a3ffd8",
            "input": "In this paper, we claim that Vector Cosine – which is generally considered one of the most efficient unsupervised measures for identifying word similarity in Vector Space Models – can be outperformed by a completely unsupervised measure that evaluates the extent of the intersection among the most associated contexts of two target words, weighting such intersection according to the rank of the shared contexts in the dependency ranked lists. This claim comes from the hypothesis that similar words do not simply occur in similar contexts, but they share a larger portion of their most relevant contexts compared to other related words. To prove it, we describe and evaluate APSyn, a variant of Average Precision that – independently of the adopted parameters – outperforms the Vector Cosine and the co-occurrence on the ESL and TOEFL test sets. In the best setting, APSyn reaches 0.73 accuracy on the ESL dataset and 0.70 accuracy in the TOEFL dataset, beating therefore the non-English US college applicants (whose average, as reported in the literature, is 64.50%) and several state-of-the-art approaches.",
            "output": [
                "What a Nerd! Beating Students and Vector Cosine in the ESL and TOEFL Datasets"
            ]
        },
        {
            "id": "task1540-40c0f0214d704c8c9a362e99a529810e",
            "input": "We provide several applications of Optimistic Mirror Descent, an online learning algorithm based on the idea<lb>of predictable sequences. First, we recover theMirror Prox algorithm for offline optimization, prove an extension<lb>to Hölder-smooth functions, and apply the results to saddle-point type problems. Next, we prove that a version<lb>of Optimistic Mirror Descent (which has a close relation to the Exponential Weights algorithm) can be used by<lb>two strongly-uncoupled players in a finite zero-summatrix game to converge to the minimax equilibrium at the<lb>rate ofO((logT )/T ). This addresses a question of Daskalakis et al [6]. Further, we consider a partial information<lb>version of the problem. We then apply the results to convex programming and exhibit a simple algorithm for the<lb>approximateMax Flow problem.",
            "output": [
                "Optimization, Learning, and Games with Predictable Sequences"
            ]
        },
        {
            "id": "task1540-e82a888c82f345f39348c03238e33db6",
            "input": "Screening rules allow to early discard irrelevant variables from the optimization in Lasso problems, or its derivatives, making solvers faster. In this paper, we propose new versions of the socalled safe rules for the Lasso. Based on duality gap considerations, our new rules create safe test regions whose diameters converge to zero, provided that one relies on a converging solver. This property helps screening out more variables, for a wider range of regularization parameter values. In addition to faster convergence, we prove that we correctly identify the active sets (supports) of the solutions in finite time. While our proposed strategy can cope with any solver, its performance is demonstrated using a coordinate descent algorithm particularly adapted to machine learning use cases. Significant computing time reductions are obtained with respect to previous safe rules.",
            "output": [
                "Mind the duality gap: safer rules for the Lasso"
            ]
        },
        {
            "id": "task1540-e71349e02d164f97889fe3a9dd90c2fc",
            "input": "Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.",
            "output": [
                "Scikit-learn: Machine Learning in Python"
            ]
        },
        {
            "id": "task1540-ddac4ac27c764ceba046c25dd5d327b0",
            "input": "Self-paced learning (SPL) has been attracting increasing attention in machine learning and computer vision. Albeit empirically substantiated to be effective, the investigation on its theoretical insight is still a blank. It is even unknown that what objective a general SPL regime converges to. To this issue, this study attempts to initially provide some new insights under this “heuristic” learning scheme. Specifically, we prove that the solving strategy on SPL exactly accords with a majorization minimization algorithm, a well known technique in optimization and machine learning, implemented on a latent objective. A more interesting finding is that, the loss function contained in this latent objective has a similar configuration with non-convex regularized penalty, an attractive topic in statistics and machine learning. In particular, we show that the previous hard and linear self-paced regularizers are equivalent to the capped norm and minimax concave plus penalties, respectively, both being widely investigated in statistics. Such connections between SPL and previous known researches enhance new insightful comprehension on SPL, like convergence and parameter setting rationality. The correctness of the proposed theory is substantiated by experimental results on synthetic and UCI data sets.",
            "output": [
                "What Objective Does Self-paced Learning Indeed Optimize?"
            ]
        },
        {
            "id": "task1540-ecf7190fdae0430685ced3288fab2f1d",
            "input": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under certain assumptions. Our experiments on convolutional and recurrent neural networks demonstrate that Entropy-SGD compares favorably to state-of-the-art techniques in terms of generalization error and training time.",
            "output": [
                "ENTROPY-SGD: BIASING GRADIENT DESCENT INTO WIDE VALLEYS"
            ]
        },
        {
            "id": "task1540-ada298aad14f4929a1ac98ce37a39a63",
            "input": "Many prediction domains, such as ad placement, recommendation, trajectory prediction, and document summarization, require predicting a set or list of options. Such lists are often evaluated using submodular reward functions that measure both quality and diversity. We propose a simple, efficient, and provably near-optimal approach to optimizing such prediction problems based on noregret learning. Our method leverages a surprising result from online submodular optimization: a single no-regret online learner can compete with an optimal sequence of predictions. Compared to previous work, which either learn a sequence of classifiers or rely on stronger assumptions such as realizability, we ensure both data-efficiency as well as performance guarantees in the fully agnostic setting. Experiments validate the efficiency and applicability of the approach on a wide range of problems including manipulator trajectory optimization, news recommendation and document summarization.",
            "output": [
                "Learning Policies for Contextual Submodular Prediction"
            ]
        },
        {
            "id": "task1540-78d85d67b29d471fb8296dbb69dc5f43",
            "input": "P lanning problems where effects of actions are non-deterministic can be modeled a8 Markov decision processes. Planning prob­ lems are usually goal-directed. This paper proposes several techniques for exploiting the goal-directedness to accelerate value itera­ tion, a standard algorithm for solving Markov decision processes. Empirical studies have shown that the techniques can bring about significant speedups.",
            "output": [
                "Fast Value Iteration for Goal-Directed Markov Decision Processes"
            ]
        },
        {
            "id": "task1540-9e85b7fce23c4408aa5fe4aebe0ab521",
            "input": "Artificial neural networks have gone through a recent rise in popularity, achieving state-of-the-art results in various fields, including image classification, speech recognition, and automated control. Both the performance and computational complexity of such models are heavily dependant on the design of characteristic hyper-parameters (e.g., number of hidden layers, nodes per layer, or choice of activation functions), which have traditionally been optimized manually. With machine learning penetrating low-power mobile and embedded areas, the need to optimize not only for performance (accuracy), but also for implementation complexity, becomes paramount. In this work, we present a multi-objective design space exploration method that reduces the number of solution networks trained and evaluated through response surface modelling. Given spaces which can easily exceed 10 solutions, manually designing a near-optimal architecture is unlikely as opportunities to reduce network complexity, while maintaining performance, may be overlooked. This problem is exacerbated by the fact that hyper-parameters which perform well on specific datasets may yield sub-par results on others, and must therefore be designed on a per-application basis. In our work, machine learning is leveraged by training an artificial neural network to predict the performance of future candidate networks. The method is evaluated on the MNIST and CIFAR-10 image datasets, optimizing for both recognition accuracy and computational complexity. Experimental results demonstrate that the proposed method can closely approximate the Pareto-optimal front, while only exploring a small fraction of the design space.",
            "output": [
                "Neural Networks Designing Neural Networks: Multi-Objective Hyper-Parameter Optimization"
            ]
        },
        {
            "id": "task1540-c34ac15f71124e5b8abd433de0c475b7",
            "input": "We present a new algorithm to model and investigate the learning process of a learner mastering a set of grammatical rules from an inconsistent source. The compelling interest of human language acquisition is that the learning succeeds in virtually every case, despite the fact that the input data are formally inadequate to explain the success of learning. Our model explains how a learner can successfully learn from or even surpass its imperfect source without possessing any additional biases or constraints about the types of patterns that exist in the language. We use the data collected by Singleton & Newport (2004) on the performance of a 7-year boy Simon, who mastered the American Sign Language (ASL) by learning it from his parents, both of whom were imperfect speakers of ASL. We show that the algorithm possesses a frequency-boosting property, whereby the frequency of the most common form of the source is increased by the learner. We also explain several key features of Simon’s ASL.",
            "output": [
                "When learners surpass their models: mathematical modeling of learning from an inconsistent source"
            ]
        },
        {
            "id": "task1540-2df08e9bf29f479591c1ab567316771b",
            "input": "Square grids are commonly used in robotics and game development to model an agent’s environment, and well known in Artificial Intelligence heuristic search algorithms (A*, JPS, Theta* etc.) are utilized for grid path planning. A lot of research in this area has been focused so far on finding the shortest paths while in many applications producing smooth paths is preferable. In our work, we study the problem of generating smooth grid paths and concentrate on angle constrained path planning. We put angle constrained path planning problem formally and present a new algorithm of solving it – LIAN. We examine LIAN both theoretically and empirically. On the theoretical side, we prove that LIAN is sound and complete (under well-defined restrictions). On the experimental side, we show that LIAN significantly outperforms competitors in ability to find solutions under tough resource constraints and in computational efficiency.",
            "output": [
                "Grid-based angle-constrained path planning"
            ]
        },
        {
            "id": "task1540-38af7d151e844905be39fba66c710f7d",
            "input": "Normalized web distance (NWD) is a similarity or normalized semantic distance based on the World Wide Web or any other large electronic database, for instance Wikipedia, and a search engine that returns reliable aggregate page counts. For sets of search terms the NWD gives a similarity on a scale from 0 (identical) to 1 (completely different). The NWD approximates the similarity according to all (upper semi)computable properties. We develop the theory and give applications. The derivation of the NWD method is based on Kolmogorov complexity.",
            "output": [
                "Web Similarity"
            ]
        },
        {
            "id": "task1540-eaef42dfa1c6457b96e757cbc69e208e",
            "input": "Clustering evaluation measures are frequently used to evaluate the performance of algorithms. However, most measures are not properly normalized and ignore some information in the inherent structure of clusterings. We model the relation between two clusterings as a bipartite graph and propose a general component-based decomposition formula based on the components of the graph. Most existing measures are examples of this formula. In order to satisfy consistency in the component, we further propose a split-merge framework for comparing clusterings of different data sets. Our framework gives measures that are conditionally normalized, and it can make use of data point information, such as feature vectors and pairwise distances. We use an entropy-based instance of the framework and a coreference resolution data set to demonstrate empirically the utility of our framework over other measures.",
            "output": [
                "A Split-Merge Framework for Comparing Clusterings "
            ]
        },
        {
            "id": "task1540-70a79c0b299a46cb86e9b26fc70d40b5",
            "input": "Recently, there has been a growing interest in modeling planning with information constraints. Accordingly, an agent maximizes a regularized expected utility known as the free energy, where the regularizer is given by the information divergence from a prior to a posterior policy. While this approach can be justified in various ways, including from statistical mechanics and information theory, it is still unclear how it relates to decisionmaking against adversarial environments. This connection has previously been suggested in work relating the free energy to risk-sensitive control and to extensive form games. Here, we show that a single-agent free energy optimization is equivalent to a game between the agent and an imaginary adversary. The adversary can, by paying an exponential penalty, generate costs that diminish the decision maker’s payoffs. It turns out that the optimal strategy of the adversary consists in choosing costs so as to render the decision maker indifferent among its choices, which is a definining property of a Nash equilibrium, thus tightening the connection between free energy optimization and game theory.",
            "output": [
                "An Adversarial Interpretation of Information-Theoretic Bounded Rationality"
            ]
        },
        {
            "id": "task1540-4a28bdd6d34d4ebf891673d8c549543f",
            "input": "We present an asymptotic analysis of Viterbi Training (VT) and contrast it with a more conventional Maximum Likelihood (ML) approach to parameter estimation in Hidden Markov Models. While ML estimator works by (locally) maximizing the likelihood of the observed data, VT seeks to maximize the probability of the most likely hidden state sequence. We develop an analytical framework based on a generating function formalism and illustrate it on an exactly solvable model of HMM with one unambiguous symbol. For this particular model the ML objective function is continuously degenerate. VT objective, in contrast, is shown to have only finite degeneracy. Furthermore, VT converges faster and results in sparser (simpler) models, thus realizing an automatic Occam’s razor for HMM learning. For more general scenario VT can be worse compared to ML but still capable of correctly recovering most of the parameters.",
            "output": [
                "Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs"
            ]
        },
        {
            "id": "task1540-3b8908e0ff824e228350f7c23ab00a22",
            "input": "Well-established automatic analyses of texts mainly consider frequencies of linguistic units, e.g. letters, words and bigrams, while methods based on cooccurrence networks consider the structure of texts regardless of the nodes label (i.e. the words semantics). In this paper, we reconcile these distinct viewpoints by introducing a generalized similarity measure to compare texts which accounts for both the network structure of texts and the role of individual words in the networks. We use the similarity measure for authorship attribution of three collections of books, each composed of 8 authors and 10 books per author. High accuracy rates were obtained with typical values from 90% to 98.75%, much higher than with the traditional the TF-IDF approach for the same collections. These accuracies are also higher than taking only the topology of networks into account. We conclude that the different properties of specific words on the macroscopic scale structure of a whole text are as relevant as their frequency of appearance; conversely, considering the identity of nodes brings further knowledge about a piece of text represented as a network.",
            "output": [
                "On the role of words in the network structure of texts: application to authorship attribution"
            ]
        },
        {
            "id": "task1540-34c24945941d4640b37ac06b76da2b64",
            "input": "Deep neural networks have dramatically advanced the state of the art for many<lb>areas of machine learning. Recently they have been shown to have a remarkable<lb>ability to generate highly complex visual artifacts such as images and text rather<lb>than simply recognize them.<lb>In this work we use neural networks to effectively invert low-dimensional face<lb>embeddings while producing realistically looking consistent images. Our contri-<lb>bution is twofold, first we show that a gradient ascent style approaches can be<lb>used to reproduce consistent images, with a help of a guiding image. Second, we<lb>demonstrate that we can train a separate neural network to effectively solve the<lb>minimization problem in one pass, and generate images in real-time. We then<lb>evaluate the loss imposed by using a neural network instead of the gradient descent<lb>by comparing the final values of the minimized loss function.",
            "output": [
                "Inverting face embeddings with convolutional neural networks"
            ]
        },
        {
            "id": "task1540-056e97dad445452ebd9033e69c171f67",
            "input": "The Abstract Meaning Representation (AMR) is a representation for opendomain rich semantics, with potential use in fields like event extraction and machine translation. Node generation, typically done using a simple dictionary lookup, is currently an important limiting factor in AMR parsing. We propose a small set of actions that derive AMR subgraphs by transformations on spans of text, which allows for more robust learning of this stage. Our set of construction actions generalize better than the previous approach, and can be learned with a simple classifier. We improve on the previous state-of-the-art result for AMR parsing, boosting end-to-end performance by 3 F1 on both the LDC2013E117 and LDC2014T12 datasets.",
            "output": [
                "Robust Subgraph Generation Improves Abstract Meaning Representation Parsing"
            ]
        },
        {
            "id": "task1540-3fbd10f8e2594f51a9365836fc4f0621",
            "input": "More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles. In contrast to traditional, monologic resources such as news, highly social dialogue is very frequent in social media, as illustrated in the snippets in Fig. 1 from the publicly available Internet Argument Corpus (IAC) (Walker et al., 2012). Utterances are frequently sarcastic, e.g., Really? Well, when I have a kid, I’ll be sure to just leave it in the woods, since it can apparently care for itself (R2 in Fig. 1 as well as Q1 and R1), and are often nasty, (R2 in Fig. 1). Note also the frequent use of dialogue specific discourse cues, e.g. the use of No in R1, Really? Well in R2, and okay, well in Q3 in Fig. 1 (Fox Tree and Schrock, 1999; Bryant and Fox Tree, 2002; Fox Tree, 2010).",
            "output": [
                "Identifying Subjective and Figurative Language in Online Dialogue"
            ]
        },
        {
            "id": "task1540-5df771a616cf47409f5eb9d4d80e4fb4",
            "input": "The increasing amount of available Linked Data resources is laying the foundations for more advanced Semantic Web applications. One of their main limitations, however, remains the general low level of data quality. In this paper we focus on a measure of quality which is negatively affected by the increase of the available resources. We propose a measure of semantic richness of Linked Data concepts and we demonstrate our hypothesis that the more a concept is reused, the less semantically rich it becomes. This is a significant scalability issue, as one of the core aspects of Linked Data is the propagation of semantic information on the Web by reusing common terms. We prove our hypothesis with respect to our measure of semantic richness and we validate our model empirically. Finally, we suggest possible future directions to address this scalability problem.",
            "output": [
                "A Linked Data Scalability Challenge: Concept Reuse Leads to Semantic Decay"
            ]
        },
        {
            "id": "task1540-f7e6c6078033400296731f63619d0c98",
            "input": "The paper considers the class of information systems capable of solving heuristic problems on basis of formal theory that was termed modal and vector theory of formal intelligent systems (FIS). The paper justifies the construction of FIS resolution algorithm, defines the main features of these systems and proves theorems that underlie the theory. The principle of representation diversity of FIS construction is formulated. The paper deals with the main principles of constructing and functioning formal intelligent system (FIS) on basis of FIS modal and vector theory. The following phenomena are considered: modular architecture of FIS presentation sub-system, algorithms of data processing at every step of the stage of creating presentations. Besides the paper suggests the structure of neural elements, i.e. zone detectors and processors that are the basis for FIS construction. Subjects: Artificial Intelligence (cs. AI)",
            "output": [
                "Principles of modal and vector theory of formal intelligence systems"
            ]
        },
        {
            "id": "task1540-5b7f68063f9b4ff0888be4d95e8db2c7",
            "input": "The Copyright of this work is owned by the Association for Computational Linguistics (ACL). However, each of the authors and the employers for whom the work was performed reserve all other rights, specifically including the following: ... (4) The right to make copies of the work for internal distribution within the author’s organization and for external distribution as a preprint, reprint, technical report, or related class of document. The original paper is to appear in: ACL 2014: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics We introduce a novel approach for building language models based on a systematic, recursive exploration of skip n-gram models which are interpolated using modified KneserNey smoothing. Our approach generalizes language models as it contains the classical interpolation with lower order models as a special case. In this paper we motivate, formalize and present our approach. In an extensive empirical experiment over English text corpora we demonstrate that our generalized language models lead to a substantial reduction of perplexity between 3.1% and 12.7% in comparison to traditional language models using modified Kneser-Ney smoothing. Furthermore, we investigate the behaviour over three other languages and a domain specific corpus where we observed consistent improvements. Finally, we also show that the strength of our approach lies in its ability to cope in particular with sparse training data. Using a very small training data set of only 736 KB text we yield improvements of even 25.7% reduction of perplexity.",
            "output": [
                "A Generalized Language Model as the Combination of Skipped n-grams and Modified Kneser-Ney Smoothing"
            ]
        },
        {
            "id": "task1540-3d2fe5bfbe8343e0ba38c9a6c5725a97",
            "input": "Recent years have witnessed the increase of competition in science. While promoting the quality of research in many cases, an intense competition among scientists can also trigger unethical scientific behaviors. To increase the total number of published papers, some authors even resort to software tools that are able to produce grammatical, but meaningless scientific manuscripts. Because automatically generated papers can be misunderstood as real papers, it becomes of paramount importance to develop means to identify these scientific frauds. In this paper, I devise a methodology to distinguish real manuscripts from those generated with SCIGen, an automatic paper generator. Upon modeling texts as complex networks (CN), it was possible to discriminate real from fake papers with at least 89% of accuracy. A systematic analysis of features relevance revealed that the accessibility and betweenness were useful in particular cases, even though the relevance depended upon the dataset. The successful application of the methods described here show, as a proof of principle, that network features can be used to identify scientific gibberish papers. In addition, the CN-based approach can be combined in a straightforward fashion with traditional statistical language processing methods to improve the performance in identifying artificially generated papers.",
            "output": [
                "Comparing the topological properties of real and artificially generated scientific manuscripts"
            ]
        },
        {
            "id": "task1540-575168437d3d449cbe3f3a9f0a960578",
            "input": "Most real-world dynamic systems are composed of different components that often evolve at very different rates. In traditional temporal graphical models, such as dynamic Bayesian networks, time is modeled at a fixed granularity, generally selected based on the rate at which the fastest component evolves. Inference must then be performed at this fastest granularity, potentially at significant computational cost. Continuous Time Bayesian Networks (CTBNs) avoid time-slicing in the representation by modeling the system as evolving continuously over time. The expectation-propagation (EP) inference algorithm of Nodelman et al. (2005) can then vary the inference granularity over time, but the granularity is uniform across all parts of the system, and must be selected in advance. In this paper, we provide a new EP algorithm that utilizes a general cluster graph architecture where clusters contain distributions that can overlap in both space (set of variables) and time. This architecture allows different parts of the system to be modeled at very different time granularities, according to their current rate of evolution. We also provide an information-theoretic criterion for dynamically re-partitioning the clusters during inference to tune the level of approximation to the current rate of evolution. This avoids the need to hand-select the appropriate granularity, and allows the granularity to adapt as information is transmitted across the network. We present experiments demonstrating that this approach can result in significant computational savings.",
            "output": [
                "Reasoning at the Right Time Granularity"
            ]
        },
        {
            "id": "task1540-92dfa56c3d6f46c8b1af6ef8354e421b",
            "input": "In this paper, we study the use of recurrent neural networks (RNNs) for modeling and forecasting time series. We first illustrate the fact that standard sequence-to-sequence RNNs neither capture well periods in time series nor handle well missing values, even though many real life times series are periodic and contain missing values. We then propose an extended attention mechanism that can be deployed on top of any RNN and that is designed to capture periods and make the RNN more robust to missing values. We show the effectiveness of this novel model through extensive experiments with multiple univariate and multivariate datasets.",
            "output": [
                "Time Series Forecasting using RNNs: an Extended Attention Mechanism to Model Periods and Handle Missing Values"
            ]
        },
        {
            "id": "task1540-5a9f17cb8d6844dba4a925fd92effe1c",
            "input": "Bayesian Optimisation (BO) is a technique used in optimising a D-dimensional function which is typically expensive to evaluate. While there have been many successes for BO in low dimensions, scaling it to high dimensions has been notoriously difficult. Existing literature on the topic are under very restrictive settings. In this paper, we identify two key challenges in this endeavour. We tackle these challenges by assuming an additive structure for the function. This setting is substantially more expressive and contains a richer class of functions than previous work. We prove that, for additive functions the regret has only linear dependence on D even though the function depends on all D dimensions. We also demonstrate several other statistical and computational benefits in our framework. Via synthetic examples, a scientific simulation and a face detection problem we demonstrate that our method outperforms naive BO on additive functions and on several examples where the function is not additive.",
            "output": [
                "High Dimensional Bayesian Optimisation and Bandits via Additive Models"
            ]
        },
        {
            "id": "task1540-c37786fe5dd64d0aafde3ab9a4ee6eb4",
            "input": "The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning.",
            "output": [
                "An Introduction to Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-aa8d61c9452247c6b951d0354c990635",
            "input": "We present an ensemble approach for categorizing search query entities in the recruitment domain. Understanding the types of entities expressed in a search query (Company, Skill, Job Title, etc.) enables more intelligent information retrieval based upon those entities compared to a traditional keyword-based search. Because search queries are typically very short, leveraging a traditional bag-of-words model to identify entity types would be inappropriate due to the lack of contextual information. Our approach instead combines clues from different sources of varying complexity in order to collect real-world knowledge about query entities. We employ distributional semantic representations of query entities through two models: 1) contextual vectors generated from encyclopedic corpora like Wikipedia, and 2) high dimensional word embedding vectors generated from millions of job postings using word2vec. Additionally, our approach utilizes both entity linguistic properties obtained from WordNet and ontological properties extracted from DBpedia. We evaluate our approach on a data set created at CareerBuilder; the largest job board in the US. The data set contains entities extracted from millions of job seekers/recruiters search queries, job postings, and resume documents. After constructing the distributional vectors of search entities, we use supervised machine learning to infer search entity types. Empirical results show that our approach outperforms the state-of-the-art word2vec distributional semantics model trained on Wikipedia. Moreover, we achieve microaveraged F1 score of 97% using the proposed distributional representations ensemble.",
            "output": [
                "Entity Type Recognition using an Ensemble of Distributional Semantic Models to Enhance Query Understanding"
            ]
        },
        {
            "id": "task1540-05ea8d4a35554f21ba73d4c68bb21f58",
            "input": "Nowadays, huge efforts are made to modernize the air traffic management systems to cope with uncertainty, complexity and sub-optimality. An answer is to enhance the information sharing between the stakeholders. This paper introduces a framework that bridges the gap between air traffic management and air traffic control on the one hand, and bridges the gap between the ground, the approach and the en-route centers on the other hand. An original system is presented, that has three essential components: the trajectory models, the optimization process, and the monitoring process. The uncertainty of the trajectory is modeled with a Bayesian Network, where the nodes are associated to two types of random variables: the time of overflight on metering points of the airspace, and the traveling time of the routes linking these points. The resulting Bayesian Network covers the complete airspace, and MonteCarlo simulations are done to estimate the probabilities of sector congestion and delays. On top of this trajectory model, an optimization process minimizes these probabilities by tuning the parameters of the Bayesian trajectory model related to overflight times on metering points. The last component is the monitoring process, that continuously updates the situation of the airspace, modifying the trajectories uncertainties according to actual positions of aircraft. After each update, a new optimal set of overflight times is computed, and can be communicated to the controllers as clearances for the aircraft pilots. The paper presents a formal specification of this global optimization problem, whose underlying rationale was derived with the help of air traffic controllers at Thales Air Systems.",
            "output": [
                "Increasing Air Traffic: What is the Problem?"
            ]
        },
        {
            "id": "task1540-f37d3fb0844a4d0fab4e861014d7d62e",
            "input": "We present an end-to-end, multimodal, fully convolu-<lb>tional network for extracting semantic structures from doc-<lb>ument images. We consider document semantic structure<lb>extraction as a pixel-wise segmentation task, and propose a<lb>unified model that classifies pixels based not only on their<lb>visual appearance, as in the traditional page segmentation<lb>task, but also on the content of underlying text. Moreover,<lb>we propose an efficient synthetic document generation pro-<lb>cess that we use to generate pretraining data for our net-<lb>work. Once the network is trained on a large set of synthetic<lb>documents, we fine-tune the network on unlabeled real doc-<lb>uments using a semi-supervised approach. We systemati-<lb>cally study the optimum network architecture and show that<lb>both our multimodal approach and the synthetic data pre-<lb>training significantly boost the performance.",
            "output": [
                "Learning to Extract Semantic Structure from Documents Using Multimodal Fully Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-319e02c086b945df9503b8046c61a204",
            "input": "Arabic language and writing are now facing a resurgence of international normative solutions that challenge most of their local or network based operating principles. Even if the multilingual digital coding solutions, especially those proposed by Unicode, have solved many difficulties of Arabic writing, the linguistic aspect is still in search of more adapted solutions. Terminology is one of the sectors in which the Arabic language requires a deep modernization of its classical productivity models. The normative approach, in particular that of the ISO TC37, is proposed as one of the solutions that would allow it to combine with international standards to better integrate the knowledge society under construction.",
            "output": [
                "Normalisation de la langue et de l’écriture arabe : enjeux culturels régionaux et mondiaux"
            ]
        },
        {
            "id": "task1540-78b58df5cd274a3888b133e22d56a0b8",
            "input": "In this work, we investigate a novel semantic approach for pattern discovery in trajectories that, relying on ontologies, enhances object movement information with event semantics. The approach can be applied to the detection of movement patterns and behaviors whenever the semantics of events occurring along the trajectory is, explicitly or implicitly, available. In particular, we tested it against an exacting case scenario in maritime surveillance, i.e., the discovery of suspicious container transportations. The methodology we have developed entails the formalization of the application domain through a domain ontology, extending the Moving Object Ontology (MOO) described in this paper. Afterwards, movement patterns have to be formalized, either as Description Logic (DL) axioms or queries, enabling the retrieval of the trajectories that follow the patterns. In our experimental evaluation, we have considered a real world dataset of 18 Million of container events describing the deed undertaken in a port to accomplish the shipping (e.g., loading on a vessel, export operation). Leveraging events, we have reconstructed almost 300 thousand container trajectories referring to 50 thousand containers travelling along three years. We have formalized the anomalous itinerary patterns as DL axioms, testing different ontology APIs and DL reasoners to retrieve the suspicious transportations. Our experiments demonstrate that the approach is feasible and efficient. In particular, the joint use of Pellet and SPARQL-DL enables to detect the trajectories following a given pattern in a reasonable time with big size datasets.",
            "output": [
                "Semantic-based Anomalous Pattern Discovery in Moving Object Trajectories"
            ]
        },
        {
            "id": "task1540-75b19ab2bdb642829013f6e3f0e17dc5",
            "input": "Review fraud is a pervasive problem in online commerce, in which fraudulent sellers write or purchase fake reviews to manipulate perception of their products and services. Fake reviews are often detected based on several signs, including 1) they occur in short bursts of time; 2) fraudulent user accounts have skewed rating distributions. However, these may both be true in any given dataset. Hence, in this paper, we propose an approach for detecting fraudulent reviews which combines these 2 approaches in a principled manner, allowing successful detection even when one of these signs is not present. To combine these 2 approaches, we formulate our Bayesian Inference for Rating Data (BIRD) model, a flexible Bayesian model of user rating behavior. Based on our model we formulate a likelihood-based suspiciousness metric, Normalized Expected Surprise Total (NEST). We propose a linear-time algorithm for performing Bayesian inference using our model and computing the metric. Experiments on real data show that BIRDNEST successfully spots review fraud in large, real-world graphs: the 50 most suspicious users of the Flipkart platform flagged by our algorithm were investigated and all identified as fraudulent by domain experts at Flipkart.",
            "output": [
                "BIRDNEST: Bayesian Inference for Ratings-Fraud Detection"
            ]
        },
        {
            "id": "task1540-c1d843ef27ac44f29eb1377fa0cd049b",
            "input": "Decision support systems help decision makers make better decisions in the face of complex decision problems (e.g. investment or policy decisions). Fisheries and Aquaculture is a domain where decision makers face such decisions since they involve factors from many different scientific fields. No systematic overview of literature describing decision support systems and their application in fisheries and aquaculture has been conducted. This paper summarizes scientific literature that describes decision support systems applied to the domain of Fisheries and Aquaculture. We use an established systematic mapping survey method to conduct our literature mapping. Our research questions are: What decision support systems for fisheries and aquaculture exists? What are the most investigated fishery and aquaculture decision support systems topics and how have these changed over time? Do any current DSS for fisheries provide realtime analytics? Do DSSes in Fisheries and Aquaculture build their models using machine learning done on captured and grounded data? The paper then detail how we employ the systematic mapping method in answering these questions. This results in 27 papers being identified as relevant and gives an exposition on the primary methods concluded in the study for designing a decision support system. We provide an analysis of the research done in the studies collected. We discovered that most literature does not consider multiple aspects for multiple stakeholders in their work. In addition we observed that little or no work has been done with real-time analysis in these decision support systems.",
            "output": [
                "Decision Support Systems in Fisheries and Aquaculture: A systematic review"
            ]
        },
        {
            "id": "task1540-f6707d9aa22549debbf77c937bbca2fd",
            "input": "We present Net2Vec, a flexible high-performance platform that allows the execution of deep learning algorithms in the communication network. Net2Vec is able to capture data from the network at more than 60Gbps, transform it into meaningful tuples and apply predictions over the tuples in real time. This platform can be used for different purposes ranging from traffic classification to network performance analysis. Finally, we showcase the use of Net2Vec by implementing and testing a solution able to profile network users at line rate using traces coming from a real network. We show that the use of deep learning for this case outperforms the baseline method both in terms of accuracy and performance.",
            "output": [
                "Net2Vec: Deep Learning for the Network"
            ]
        },
        {
            "id": "task1540-01a5bf08f392431895cbd21589cf452b",
            "input": "As an important and challenging problem in computer vision and graphics, keypoint-based object tracking is typically formulated in a spatio-temporal statistical learning framework. However, most existing keypoint trackers are incapable of effectively modeling and balancing the following three aspects in a simultaneous manner: temporal model coherence across frames, spatial model consistency within frames, and discriminative feature construction. To address this issue, we propose a robust keypoint tracker based on spatio-temporal multi-task structured output optimization driven by discriminative metric learning. Consequently, temporal model coherence is characterized by multi-task structured keypoint model learning over several adjacent frames, while spatial model consistency is modeled by solving a geometric verification based structured learning problem. Discriminative feature construction is enabled by metric learning to ensure the intra-class compactness and inter-class separability. Finally, the above three modules are simultaneously optimized in a joint learning scheme. Experimental results have demonstrated the effectiveness of our tracker.",
            "output": [
                "Metric Learning Driven Multi-Task Structured Output Optimization for Robust Keypoint Tracking"
            ]
        },
        {
            "id": "task1540-9edb89a5828840d081175a5542edc171",
            "input": "Machine learning is increasingly prevalent in stock market trading. Though neural networks have seen success in computer vision and natural language processing, they have not been as useful in stock market trading. To demonstrate the applicability of a neural network in stock trading, we made a single-layer neural network that recommends buying or selling shares of a stock by comparing the highest high of 10 consecutive days with that of the next 10 days, a process repeated for the stock’s year-long historical data. A χ analysis found that the neural network can accurately and appropriately decide whether to buy or sell shares for a given stock, showing that a neural network can make simple decisions about the stock market.",
            "output": [
                "Application of a Shallow Neural Network to Short-Term Stock Trading"
            ]
        },
        {
            "id": "task1540-2b12330eda9f4dc9b86a68f38d00b47b",
            "input": "In this paper, we present a novel approach for Human Computer Interaction (HCI) where, we control cursor movement using a real-time camera. Current methods involve changing mouse parts such as adding more buttons or changing the position of the tracking ball. Instead, our method is to use a camera and computer vision technology, such as image segmentation and gesture recognition, to control mouse tasks (left and right clicking, double-clicking, and scrolling) and we show how it can perform everything as current mouse devices can. The software will be developed in JAVA language. Recognition and pose estimation in this system are user independent and robust as we will be using colour tapes on our finger to perform actions. The software can be used as an intuitive input interface to applications that require multi-dimensional control e.g. computer games etc.",
            "output": [
                "Mouse Simulation Using Two Coloured Tapes"
            ]
        },
        {
            "id": "task1540-88b0598c92594138a8f529f1b02c7dac",
            "input": "A main goal of data visualization is to find, from among all the available alternatives, mappings to the 2D/3D display which are relevant to the user. Assuming user interaction data, or other auxiliary data about the items or their relationships, the goal is to identify which aspects in the primary data support the user’s input and, equally importantly, which aspects of the user’s potentially noisy input have support in the primary data. For solving the problem, we introduce a multi-view embedding in which a latent factorization identifies which aspects in the two data views (primary data and user data) are related and which are specific to only one of them. The factorization is a generative model in which the display is parameterized as a part of the factorization and the other factors explain away the aspects not expressible in a two-dimensional display. Functioning of the model is demonstrated on several data sets.",
            "output": [
                "VISUALIZATIONS RELEVANT TO THE USER BY MULTI-VIEW LATENT VARIABLE FACTORIZATION"
            ]
        },
        {
            "id": "task1540-42688863860c4860b93b6e39adaccdc4",
            "input": "Building Information Modeling (BIM) is a recent construction process based on a 3D model, containing every component related to the building achievement. Architects, structure engineers, method engineers, and others participant to the building process work on this model through the design-to-construction cycle. The high complexity and the large amount of information included in these models raise several issues, delaying its wide adoption in the industrial world. One of the most important is the visualization: professionals have difficulties to find out the relevant information for their job. Actual solutions suffer from two limitations: the BIM models information are processed manually and insignificant information are simply hidden, leading to inconsistencies in the building model. This paper describes a system relying on an ontological representation of the building information to label automatically the building elements. Depending on the user’s department, the visualization is modified according to these labels by automatically adjusting the colors and image properties based on a saliency model. The proposed saliency model incorporates several adaptations to fit the specificities of architectural images.",
            "output": [
                "Adaptive Visualisation System for Construction Building Information Models Using Saliency"
            ]
        },
        {
            "id": "task1540-f405f2c09dbb4c6c9477c432bc7769e5",
            "input": "We present persona-based models for handling the issue of speaker consistency in neural response generation. A speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style. A dyadic speaker-addressee model captures properties of interactions between two interlocutors. Our models yield qualitative performance improvements in both perplexity and BLEU scores over baseline sequence-to-sequence models, with similar gain in speaker consistency as measured by human judges.",
            "output": [
                "A Persona-Based Neural Conversation Model"
            ]
        },
        {
            "id": "task1540-775e62579ca44fc4ab2da6f46dfed241",
            "input": "We propose novel model transfer-learning methods that refine a decision forest model M learned within a “source” domain using a training set sampled from a “target” domain, assumed to be a variation of the source. We present two random forest transfer algorithms. The first algorithm searches greedily for locally optimal modifications of each tree structure by trying to locally expand or reduce the tree around individual nodes. The second algorithm does not modify structure, but only the parameter (thresholds) associated with decision nodes. We also propose to combine both methods by considering an ensemble that contains the union of the two forests. The proposed methods exhibit impressive experimental results over a range of problems.",
            "output": [
                "LEARN ON SOURCE, REFINE ON TARGET: A MODEL TRANSFER LEARNING FRAMEWORK WITH RANDOM FORESTS 1 Learn on Source, Refine on Target: A Model Transfer Learning Framework with Random Forests"
            ]
        },
        {
            "id": "task1540-4a492a0b5bc045e98ba2da805c077dcd",
            "input": "Designing 3D scenes is currently a creative task that requires significant expertise and effort in using complex 3D design interfaces. This effortful design process starts in stark contrast to the easiness with which people can use language to describe real and imaginary environments. We present SCENESEER: an interactive text to 3D scene generation system that allows a user to design 3D scenes using natural language. A user provides input text from which we extract explicit constraints on the objects that should appear in the scene. Given these explicit constraints, the system then uses a spatial knowledge base learned from an existing database of 3D scenes and 3D object models to infer an arrangement of the objects forming a natural scene matching the input description. Using textual commands the user can then iteratively refine the created scene by adding, removing, replacing, and manipulating objects. We evaluate the quality of 3D scenes generated by SCENESEER in a perceptual evaluation experiment where we compare against manually designed scenes and simpler baselines for 3D scene generation. We demonstrate how the generated scenes can be iteratively refined through simple natural language commands. INTRODUCTION Designing 3D scenes is a challenging creative task. Expert users expend considerable effort in learning how to use complex 3D scene design tools. Still, immense manual effort is required, leading to high costs for producing 3D content in video games, films, interior design, and architectural visualization. Despite the conceptual simplicity of generating pictures from descriptions, systems for text-to-scene generation have only achieved limited success. How might we allow people to create 3D scenes using simple natural language? Current 3D design tools provide a great amount of control over the construction and precise positioning of geometry within 3D scenes. However, most of these tools do not allow for intuitively assembling a scene from existing objects which is critical for non-professional users. As an analogue, in real life few people are carpenters, but most of us have bought and arranged furniture. For the purposes of defining how to compose and arrange objects into scenes, natural language is an obvious interface. It is much easier to say “Put a blue bowl on the dining table” rather than retrieving, inserting and orienting a 3D model of a bowl. Text to 3D scene interfaces can empower a broader demographic to create 3D scenes for games, interior design, and virtual storyboarding. Text to 3D scene systems face several technical challenges. Firstly, natural language is typically terse and incomplete. People rarely mention many facts about the world since these facts can often be safely assumed. Most desks are upright and on the floor but few people would mention this explicitly. This implicit spatial knowledge is critical for scene generation but hard to extract. Secondly, people reason about the 1 ar X iv :1 70 3. 00 05 0v 1 [ cs .G R ] 2 8 Fe b 20 17 world at a much higher level than typical representations of 3D scenes (using the descriptive phrase table against wall vs a 3D transformation matrix). The semantics of objects and their approximate arrangement are typically more important than the precise and abstract properties of geometry. Most 3D scene design tools grew out of the traditions of Computer Aided Design and architecture where precision of control and specification is much more important than for casual users. Traditional interfaces allow for comprehensive control but are typically not concerned with high level semantics. SCENESEER allows users to generate and manipulate 3D scenes at the level of everyday semantics through simple natural language. It leverages spatial knowledge priors learned from existing 3D scene data to infer implicit, unmentioned constraints and resolve view-dependent spatial relations in a natural way. For instance, given the sentence “there is a dining table with a cake”, we can infer that the cake is most likely on a plate and that the plate is most likely on the table. This elevation of 3D scene design to the level of everyday semantics is critical for enabling intuitive design interfaces, rapid prototyping, and coarse-to-fine refinements. In this paper, we present a framework for the text to 3D scene task and use it to motivate the design of the SCENESEER system. We demonstrate that SCENESEER can be used to generate 3D scenes from terse, natural language descriptions. We empirically evaluate the quality of the generated scenes with a human judgment experiment and find that SCENESEER can generate high quality scenes matching the input text. We show how textual commands can be used interactively in SCENESEER to manipulate generated 3D scenes.",
            "output": [
                "SceneSeer: 3D Scene Design with Natural Language"
            ]
        },
        {
            "id": "task1540-dbf7c1904fa34265ad4ddeced345238f",
            "input": "We consider the task of obtaining the maximum a posteriori estimate of discrete pairwise random fields with arbitrary unary potentials and semimetric pairwise potentials. For this problem, we propose an accurate hierarchical move making strategy where each move is computed efficiently by solving an st-MINCUT problem. Unlike previous move making approaches, e.g. the widely used α-expansion algorithm, our method obtains the guarantees of the standard linear programming (LP) relaxation for the important special case of metric labeling. Unlike the existing LP relaxation solvers, e.g. interior-point algorithms or tree-reweighted message passing, our method is significantly faster as it uses only the efficient st-MINCUT algorithm in its design. Using both synthetic and real data experiments, we show that our technique outperforms several commonly used algorithms.",
            "output": [
                "MAP Estimation of Semi-Metric MRFs via Hierarchical Graph Cuts"
            ]
        },
        {
            "id": "task1540-68f27314a174452bbe513b834c8f8b38",
            "input": "Résumé Elections unleash strong political views on Twitter, but what do people really think about politics ? Opinion and trend mining on micro blogs dealing with politics has recently attracted researchers in several fields including Information Retrieval and Machine Learning (ML). Since the performance of ML and Natural Language Processing (NLP) approaches are limited by the amount and quality of data available, one promising alternative for some tasks is the automatic propagation of expert annotations. This paper intends to develop a so-called active learning process for automatically annotating French language tweets that deal with the image (i.e., representation, web reputation) of politicians. Our main focus is on the methodology followed to build an original annotated dataset expressing opinion from two French politicians over time. We therefore review state of the art NLP-based ML algorithms to automatically annotate tweets using a manual initiation step as bootstrap. This paper focuses on key issues about active learning while building a large annotated data set from noise. This will be introduced by human annotators, abundance of data and the label distribution across data and entities. In turn, we show that Twitter characteristics such as the author’s name or hashtags can be considered as the bearing point to not only improve automatic systems for Opinion Mining (OM) and Topic Classification but also to reduce noise in human annotations. However, a later thorough analysis shows that reducing noise might induce the loss of crucial information.",
            "output": [
                "Active learning in annotating micro-blogs dealing with e-reputation"
            ]
        },
        {
            "id": "task1540-8109eb9017c04d0f92b3ff3827415501",
            "input": "Standard deep reinforcement learning methods such as Deep Q-Networks (DQN) for multiple tasks (domains) face scalability problems. We propose a method for multi-domain dialogue policy learning—termed NDQN, and apply it to an information-seeking spoken dialogue system in the domains of restaurants and hotels. Experimental results comparing DQN (baseline) versus NDQN (proposed) using simulations report that our proposed method exhibits better scalability and is promising for optimising the behaviour of multi-domain dialogue systems.",
            "output": [
                "Deep Reinforcement Learning for Multi-Domain Dialogue Systems"
            ]
        },
        {
            "id": "task1540-b306122e2b9d420a9cca25370d180606",
            "input": "Automated Text Scoring (ATS) provides a cost-effective and consistent alternative to human marking. However, in order to achieve good performance, the predictive features of the system need to be manually engineered by human experts. We introduce a model that forms word representations by learning the extent to which specific words contribute to the text’s score. Using Long-Short Term Memory networks to represent the meaning of texts, we demonstrate that a fully automated framework is able to achieve excellent results over similar approaches. In an attempt to make our results more interpretable, and inspired by recent advances in visualizing neural networks, we introduce a novel method for identifying the regions of the text that the model has found more discriminative.",
            "output": [
                "Automatic Text Scoring Using Neural Networks"
            ]
        },
        {
            "id": "task1540-f8e503485a9c4e4898afec1716aa3d48",
            "input": "This work, inspired by the idea of “Computing with Words and Perceptions” proposed by Zadeh in [57, 59], focuses on how to transform measurements into perceptions [22] for the problem of map building by Autonomous Mobile Robots. We propose to model the perceptions obtained from sonar-sensors as two grid maps: one for obstacles and another for empty spaces. The rules used to build and integrate these maps are expressed by linguistic descriptions and modeled by fuzzy rules. The main difference of this approach from other studies reported in the literature is that the method presented here is based on the hypothesis that the concepts “occupied” and “empty” are antonyms rather than complementary (as it happens in probabilistic approaches), or independent (as it happens in the previous fuzzy models). Controlled experimentation with a real robot in three representative indoor environments has been performed and the results presented. We offer a qualitative and quantitative comparison of the estimated maps obtained by the probabilistic approach, the previous fuzzy method and the new antonyms-based fuzzy approach. It is shown that the maps obtained with the antonyms-based approach are better defined, capture better the shape of the walls and of the empty-spaces, and contain less errors due to rebounds and short-echoes. Furthermore, in spite of noise and low resolution inherent to the sonar-sensors used, the maps obtained are accurate and tolerant to imprecision. IThis work has been supported by the Spanish Department of Science and Innovation (MICINN) under program Juan de la Cierva JCI-2008-3531, and the European Social Fund. ∗Corresponding author Email addresses: sergio.guadarrama@softcomputing.es (Sergio Guadarrama), aruiz@fi.upm.es (Antonio Ruiz-Mayor) Preprint submitted to Elsevier July 1, 2010 ar X iv :1 00 6. 58 27 v1 [ cs .R O ] 3 0 Ju n 20 10",
            "output": [
                "Approximate Robotic Mapping from sonar data by modeling Perceptions with Antonyms"
            ]
        },
        {
            "id": "task1540-7bf6087474784698b3f35d8152585bfb",
            "input": "The paper summarizes the development of the LVCSR system built as a part of the Pashto speech-translation system at the SCALE (Summer Camp for Applied Language Exploration) 2015 workshop on “Speech-to-text-translation for low-resource languages”. The Pashto language was chosen as a good “proxy” low-resource language, exhibiting multiple phenomena which make the speech-recognition and and speech-to-text-translation systems development hard. Even when the amount of data is seemingly sufficient, given the fact that the data originates from multiple sources, the preliminary experiments reveal that there is little to no benefit in merging (concatenating) the corpora and more elaborate ways of making use of all of the data must be worked out. This paper concentrates only on the LVCSR part and presents a range of different techniques that were found to be useful in order to benefit from multiple different corpora",
            "output": [
                "USING OF HETEROGENEOUS CORPORA FOR TRAINING OF AN ASR SYSTEM"
            ]
        },
        {
            "id": "task1540-9af2438418c94b03a7c784b6e7804dd2",
            "input": "Active appearance models (AAMs) are a class of generative models that have seen tremendous success in face analysis. However, model learning depends on the availability of detailed annotation of canonical landmark points. As a result, when accurate AAM fitting is required on a different set of variations (expression, pose, identity), a new dataset is collected and annotated. To overcome the need for time consuming data collection and annotation, transfer learning approaches have received recent attention. The goal is to transfer knowledge from previously available datasets (source) to a new dataset (target). We propose a subspace transfer learning method, in which we select a subspace from the source that best describes the target space. We propose a metric to compute the directional similarity between the source eigenvectors and the target subspace. We show an equivalence between this metric and the variance of target data when projected onto source eigenvectors. Using this equivalence, we select a subset of source principal directions that capture the variance in target data. To define our model, we augment the selected source subspace with the target subspace learned from a handful of target examples. In experiments done on six publicly available datasets, we show that our approach outperforms the state of the art in terms of the RMS fitting error as well as the percentage of test examples for which AAM fitting converges to the ground truth.",
            "output": [
                "Subspace Selection to Suppress Confounding Source Domain Information in AAM Transfer Learning"
            ]
        },
        {
            "id": "task1540-59c7852e8bcf42bf9a3a7eb9bdb4fa5f",
            "input": "We describe a graphical representation of probabilistic relationships-an alternative to the Bayesian network-called a dependency network. Like a Bayesian network, a depen­ dency network has a graph and a probabil­ ity component. The graph component is a (cyclic) directed graph such that a node's parents render that node independent of all other nodes in the network. The probabil­ ity component consists of the probability of a node given its parents for each node (as in a Bayesian network) . We identify several ba­ sic properties of this representation, and de­ scribe its use in collaborative filtering (the task of predicting preferences) and the visu­ alization of predictive relationships.",
            "output": [
                "Dependency Networks for Collaborative Filtering and Data Visualization"
            ]
        },
        {
            "id": "task1540-775cc45d5f8a4ee5bc73a25f3724465c",
            "input": "Many deep Convolutional Neural Networks (CNN) make incorrect predictions on adversarial samples obtained by imperceptible perturbations of clean samples. We hypothesize that this is caused by a failure to suppress unusual signals within network layers. As remedy we propose the use of Symmetric Activation Functions (SAF) in non-linear signal transducer units. These units suppress signals of exceptional magnitude. We prove that SAF networks can perform classification tasks to arbitrary precision in a simplified situation. In practice, rather than use SAFs alone, we add them into CNNs to improve their robustness. The modified CNNs can be easily trained using popular strategies with the moderate training load. Our experiments on MNIST and CIFAR-10 show that the modified CNNs perform similarly to plain ones on clean samples, and are remarkably more robust against adversarial and nonsense samples.",
            "output": [
                "Suppressing the Unusual: towards Robust CNNs using Symmetric Activation Functions"
            ]
        },
        {
            "id": "task1540-a18673f6bda54f27b57c1078248f6763",
            "input": "Résumé. Le crowdsourcing, un enjeu économique majeur, est le fait d’externaliser une tâche interne d’une entreprise vers le grand-public, la foule. C’est ainsi une forme de sous-traitance digitale destinée à toute personne susceptible de pouvoir réaliser la tâche demandée généralement rapide et non automatisable. L’évaluation de la qualité du travail des participants est cependant un problème majeur en crowdsourcing. En effet, les contributions doivent être contrôlées pour assurer l’efficacité et la pertinence d’une campagne. Plusieurs méthodes ont été proposées pour évaluer le niveau d’expertise des participants. Ce travail a la particularité de proposer une méthode de calcul de degrés d’expertise en présence de données dont l’ordre de classement est connu. Les degrés d’expertise sont ensuite considérés sur des données sans ordre pré-établi. Cette méthode fondée sur la théorie des fonctions de croyance tient compte des incertitudes des réponses et est évaluée sur des données réelles d’une campagne réalisée en 2016.",
            "output": [
                "Une mesure d’expertise pour le crowdsourcing"
            ]
        },
        {
            "id": "task1540-f508e670ff4248bfa38d7358485bccef",
            "input": "This paper reports on a writing style analysis of hyperpartisan (i.e., extremely onesided) news in connection to fake news. It presents a large corpus of 1,627 articles that were manually fact-checked by professional journalists from BuzzFeed. The articles originated from 9 well-known political publishers, 3 each from the mainstream, the hyperpartisan left-wing, and the hyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of which originated from hyperpartisan publishers. We propose and demonstrate a new way of assessing style similarity between text categories via Unmasking—a meta-learning approach originally devised for authorship verification—, revealing that the style of left-wing and right-wing news have a lot more in common than any of the two have with the mainstream. Furthermore, we show that hyperpartisan news can be discriminated well by its style from the mainstream (F1 = 0.78), as can be satire from both (F1 = 0.81). Unsurprisingly, stylebased fake news detection does not live up to scratch (F1 = 0.46). Nevertheless, the former results are important to implement pre-screening for fake news detectors.",
            "output": [
                "A Stylometric Inquiry into Hyperpartisan and Fake News"
            ]
        },
        {
            "id": "task1540-a1fced2932e34a538fb1bc0d41c0769e",
            "input": "In distributed, or privacy-preserving learning, we are often given a set of probabilistic models estimated from different local repositories, and asked to combine them into a single model that gives efficient statistical estimation. A simple method is to linearly average the parameters of the local models, which, however, tends to be degenerate or not applicable on non-convex models, or models with different parameter dimensions. One more practical strategy is to generate bootstrap samples from the local models, and then learn a joint model based on the combined bootstrap set. Unfortunately, the bootstrap procedure introduces additional noise and can significantly deteriorate the performance. In this work, we propose two variance reduction methods to correct the bootstrap noise, including a weighted M-estimator that is both statistically efficient and practically powerful. Both theoretical and empirical analysis is provided to demonstrate our methods.",
            "output": [
                "Bootstrap Model Aggregation for Distributed Statistical Learning"
            ]
        },
        {
            "id": "task1540-859c22751fea4cd98c6323244e339757",
            "input": "The past few years have seen a tremendous growth in the popularity of smartphones. As newer features continue to be added to smartphones to increase their utility, their significance will only increase in future. Combining machine learning with mobile computing can enable smartphones to become ‘intelligent’ devices, a feature which is hitherto unseen in them. Also, the combination of machine learning and context aware computing can enable smartphones to gauge users’ requirements proactively, depending upon their environment and context. Accordingly, necessary services can be provided to users. In this paper, we have explored the methods and applications of integrating machine learning and context aware computing on the Android platform, to provide higher utility to the users. To achieve this, we define a Machine Learning (ML) module which is incorporated in the basic Android architecture. Firstly, we have outlined two major functionalities that the ML module should provide. Then, we have presented three architectures, each of which incorporates the ML module at a different level in the Android architecture. The advantages and shortcomings of each of these architectures have been evaluated. Lastly, we have explained a few applications in which our proposed system can be incorporated such that their functionality is improved. Keywords—machine learning; association rules; machine learning in embedded systems; android, ID3; Apriori; Max-Miner",
            "output": [
                "Association Rule Based Flexible Machine Learning Module for Embedded System Platforms like Android"
            ]
        },
        {
            "id": "task1540-d6c3c06c561f450586b7ac997292b2d7",
            "input": "We describe two new related resources that facilitate modelling of general knowledge reasoning in 4th grade science exams. The first is a collection of curated facts in the form of tables, and the second is a large set of crowd-sourced multiple-choice questions covering the facts in the tables. Through the setup of the crowd-sourced annotation task we obtain implicit alignment information between questions and tables. We envisage that the resources will be useful not only to researchers working on question answering, but also to people investigating a diverse range of other applications such as information extraction, question parsing, answer type identification, and lexical semantic modelling.",
            "output": [
                "TabMCQ: A Dataset of General Knowledge Tables and Multiple-choice Questions"
            ]
        },
        {
            "id": "task1540-5c08051542314fb4a8427101784e8155",
            "input": "In the context of natural language processing, representation learning has emerged as a newly active research subject because of its excellent performance in many applications. Learning representations of words is a pioneering study in this school of research. However, paragraph (or sentence and document) embedding learning is more suitable/reasonable for some tasks, such as sentiment classification and document summarization. Nevertheless, as far as we are aware, there is relatively less work focusing on the development of unsupervised paragraph embedding methods. Classic paragraph embedding methods infer the representation of a given paragraph by considering all of the words occurring in the paragraph. Consequently, those stop or function words that occur frequently may mislead the embedding learning process to produce a misty paragraph representation. Motivated by these observations, our major contributions in this paper are twofold. First, we propose a novel unsupervised paragraph embedding method, named the essence vector (EV) model, which aims at not only distilling the most representative information from a paragraph but also excluding the general background information to produce a more informative low-dimensional vector representation for the paragraph. We evaluate the proposed EV model on benchmark sentiment classification and multi-document summarization tasks. The experimental results demonstrate the effectiveness and applicability of the proposed embedding method. Second, in view of the increasing importance of spoken content processing, an extension of the EV model, named the denoising essence vector (D-EV) model, is proposed. The D-EV model not only inherits the advantages of the EV model but also can infer a more robust representation for a given spoken paragraph against imperfect speech recognition. The utility of the D-EV model is evaluated on a spoken document summarization task, confirming the practical merits of the proposed embedding method in relation to several wellpracticed and state-of-the-art summarization methods.",
            "output": [
                "Learning to Distill: The Essence Vector Modeling Framework"
            ]
        },
        {
            "id": "task1540-c479a1c6c7d54ae0bfd79eedb76d51a2",
            "input": "This paper describes a new method for classifying a dataset that partitions elements into different categories. It has relations with neural networks but works in a different way, requiring only a single pass through the classifier to generate the weight sets. A grid structure is required and a novel idea of converting a row of real values into a 2-D or grid-like structure of value bands. Each cell in the band can then store a cell weight value and also a set of weights that represent its own importance to each of the output categories. For any input that needs to be categorised, all of the output weight lists for each relevant input cell can be retrieved and summed to produce a probability for what the correct output category is. So the relative importance of each input point to the output is distributed to each cell. The construction process itself can simply be the reinforcement of the weight values, without requiring an iterative adjustment process, making it potentially much faster.",
            "output": [
                "A Single-Pass Classifier for Categorical Data"
            ]
        },
        {
            "id": "task1540-8882878db1684745a8719dce731a953b",
            "input": "We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn high-quality relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relations that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relations with high accuracy, and that zero-shot generalization to unseen relations is possible, at lower accuracy levels, setting the bar for future work on this task.",
            "output": [
                "Zero-Shot Relation Extraction via Reading Comprehension"
            ]
        },
        {
            "id": "task1540-7a5f137302ae4023bb1b8b8e7ff5991d",
            "input": "Kimmo Kettunen, Eetu Mäkelä, Teemu Ruokolainen, Juha Kuokkala and Laura Löfberg 1 National Library of Finland, Centre for Preservation and Digitization, Mikkeli, Finland kimmo.kettunen@helsinki.fi 2 Aalto University, Semantic Computing Research Group, Espoo, Finland eetu.makela@aalto.fi 3 National Library of Finland, Centre for Preservation and Digitization, Mikkeli, Finland teemu.ruokolainen@helsinki.fi 4 University of Helsinki, Department of Modern Languages, Helsinki, Finland juha.kuokkala@helsinki.fi 5 Department of Linguistics and English Language, Lancaster University, UK l.lofberg@lancaster.ac.uk",
            "output": [
                "Old Content and Modern Tools – Searching Named Entities in a Finnish OCRed Historical Newspaper Collection 1771–1910"
            ]
        },
        {
            "id": "task1540-18e4ee6275d747f3b9612f857ee17f46",
            "input": "We study the problem of structured prediction under test-time budget constraints. We propose a novel approach applicable to a wide range of structured prediction problems in computer vision and natural language processing. Our approach seeks to adaptively generate computationally costly features during test-time in order to reduce the computational cost of prediction while maintaining prediction performance. We show that training the adaptive feature generation system can be reduced to a series of structured learning problems, resulting in efficient training using existing structured learning algorithms. This framework provides theoretical justification for several existing heuristic approaches found in literature. We evaluate our proposed adaptive system on two structured prediction tasks, optical character recognition (OCR) and dependency parsing and show strong performance in reduction of the feature costs without degrading accuracy.",
            "output": [
                "Resource Constrained Structured Prediction"
            ]
        },
        {
            "id": "task1540-11bcc33fc43347d7bbc74f6ef2474f3b",
            "input": "In this work, we present a minimal neural model for constituency parsing based on independent scoring of labels and spans. We show that this model is not only compatible with classical dynamic programming techniques, but also admits a novel greedy top-down inference algorithm based on recursive partitioning of the input. We demonstrate empirically that both prediction schemes are competitive with recent work, and when combined with basic extensions to the scoring model are capable of achieving state-of-the-art single-model performance on the Penn Treebank (91.79 F1) and strong performance on the French Treebank (82.23 F1).",
            "output": [
                "A Minimal Span-Based Neural Constituency Parser"
            ]
        },
        {
            "id": "task1540-318d464f559340ddb44bcd0a813c4be6",
            "input": "Nonnegative matrix factorization (NMF) has become a ubiquitous tool for data analysis. An important variant is the sparse NMF problem which arises when we explicitly require the learnt features to be sparse. A natural measure of sparsity is the L0 norm, however its optimization is NP-hard. Mixed norms, such as L1/L2 measure, have been shown to model sparsity robustly, based on intuitive attributes that such measures need to satisfy. This is in contrast to computationally cheaper alternatives such as the plain L1 norm. However, present algorithms designed for optimizing the mixed norm L1/L2 are slow and other formulations for sparse NMF have been proposed such as those based on L1 and L0 norms. Our proposed algorithm allows us to solve the mixed norm sparsity constraints while not sacrificing computation time. We present experimental evidence on real-world datasets that shows our new algorithm performs an order of magnitude faster compared to the current state-of-the-art solvers optimizing the mixed norm and is suitable for large-scale datasets.",
            "output": [
                "Block Coordinate Descent for Sparse NMF"
            ]
        },
        {
            "id": "task1540-58daef9ec51342098d35bd5b7656d3aa",
            "input": "We demonstrate that a continuous relaxation of the argmax operation can be used to create a differentiable approximation to greedy decoding for sequence-tosequence (seq2seq) models. By incorporating this approximation into the scheduled sampling training procedure (Bengio et al., 2015)–a well-known technique for correcting exposure bias–we introduce a new training objective that is continuous and differentiable everywhere and that can provide informative gradients near points where previous decoding decisions change their value. In addition, by using a related approximation, we demonstrate a similar approach to sampled-based training. Finally, we show that our approach outperforms cross-entropy training and scheduled sampling procedures in two sequence prediction tasks: named entity recognition and machine translation.",
            "output": [
                "Differentiable Scheduled Sampling for Credit Assignment"
            ]
        },
        {
            "id": "task1540-ed3d7d94ee5142ab87f386b275fc057c",
            "input": "Machine comprehension of text is an important problem in natural language processing. A recently released dataset, the Stanford Question Answering Dataset (SQuAD), offers a large number of real questions and their answers created by humans through crowdsourcing. SQuAD provides a challenging testbed for evaluating machine comprehension algorithms, partly because compared with previous datasets, in SQuAD the answers do not come from a small set of candidate answers and they have variable lengths. We propose an end-to-end neural architecture for the task. The architecture is based on match-LSTM, a model we proposed previously for textual entailment, and Pointer Net, a sequence-to-sequence model proposed by Vinyals et al. (2015) to constrain the output tokens to be from the input sequences. We propose two ways of using Pointer Net for our task. Our experiments show that both of our two models substantially outperform the best results obtained by Rajpurkar et al. (2016) using logistic regression and manually crafted features.",
            "output": [
                "MACHINE COMPREHENSION USING MATCH-LSTM"
            ]
        },
        {
            "id": "task1540-20ac93fcac544f9eb7ee1a6dc4762ad8",
            "input": "We study the segmental recurrent neural network for end-to-end acoustic modelling. This model connects the segmental conditional random field (CRF) with a recurrent neural network (RNN) used for feature extraction. Compared to most previous CRF-based acoustic models, it does not rely on an external system to provide features or segmentation boundaries. Instead, this model marginalises out all the possible segmentations, and features are extracted from the RNN trained together with the segmental CRF. In essence, this model is self-contained and can be trained end-to-end. In this paper, we discuss practical training and decoding issues as well as the method to speed up the training in the context of speech recognition. We performed experiments on the TIMIT dataset. We achieved 17.3% phone error rate (PER) from the first-pass decoding — the best reported result using CRFs, despite the fact that we only used a zeroth-order CRF and without using any language model.",
            "output": [
                "Segmental Recurrent Neural Networks for End-to-end Speech Recognition"
            ]
        },
        {
            "id": "task1540-0b790ea2fc2042c2b35729b6b974cd9c",
            "input": "The ability to simultaneously leverage multiple modes of sensor information is critical for perception of an automated vehicle’s physical surroundings. Spatio-temporal alignment of registration of the incoming information is often a prerequisite to analyzing the fused data. The persistence and reliability of multi-modal registration is therefore the key to the stability of decision support systems ingesting the fused information. LiDAR-video systems like on those many driverless cars are a common example of where keeping the LiDAR and video channels registered to common physical features is important. We develop a deep learning method that takes multiple channels of heterogeneous data, to detect the misalignment of the LiDARvideo inputs. A number of variations were tested on the Ford LiDAR-video driving test data set and will be discussed. To the best of our knowledge the use of multi-modal deep convolutional neural networks for dynamic real-time LiDAR-video registration has not been presented.",
            "output": [
                "Multi-modal Sensor Registration for Vehicle Perception via Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-df9c291c33d14c48b63ecf3ac2de8585",
            "input": "We provide tight upper and lower bounds on the complexity of minimizing the average of m convex functions using gradient and prox oracles of the component functions. We show a significant gap between the complexity of deterministic vs randomized optimization. For smooth functions, we show that accelerated gradient descent (AGD) and an accelerated variant of SVRG are optimal in the deterministic and randomized settings respectively, and that a gradient oracle is sufficient for the optimal rate. For non-smooth functions, having access to prox oracles reduces the complexity and we present optimal methods based on smoothing that improve over methods using just gradient accesses.",
            "output": [
                "Tight Complexity Bounds for Optimizing Composite Objectives"
            ]
        },
        {
            "id": "task1540-a531e06d473442f994e8f4197b35c078",
            "input": "In order to perform complex actions in human environments, an autonomous robot needs the ability to understand the environment, that is, to gather and maintain spatial knowledge. Topological map is commonly used for representing large scale, global maps such as floor plans. Although much work has been done in topological map extraction, we have found little previous work on the problem of learning the topological map using a probabilistic model. Learning a topological map means learning the structure of the large-scale space and dependency between places, for example, how the evidence of a group of places influence the attributes of other places. This is an important step towards planning complex actions in the environment. In this thesis, we consider the problem of using probabilistic deep learning model to learn the topological map, which is essentially a sparse undirected graph where nodes represent places annotated with their semantic attributes (e.g. place category). We propose to use a novel probabilistic deep model, Sum-Product Networks (SPNs) [20], due to their unique properties. We present two methods for learning topological maps using SPNs: the place grid method and the template-based method. We contribute an algorithm that builds SPNs for graphs using template models. Our experiments evaluate the ability of our models to enable robots to infer semantic attributes and detect maps with novel semantic attribute arrangements. Our results demonstrate their understanding of the topological map structure and spatial relations between places.",
            "output": [
                "Learning Large-Scale Topological Maps Using Sum-Product Networks"
            ]
        },
        {
            "id": "task1540-04853741b84a4e3bb046aaa999d76def",
            "input": "Nowadays, there is increasing interest in the development of teamwork skills in the educational context. This growing interest is motivated by its pedagogical effectiveness and the fact that, in labour contexts, enterprises organize their employees in teams to carry out complex projects. Despite its crucial importance in the classroom and industry, there is a lack of support for the team formation process. Not only do many factors influence team performance, but the problem becomes exponentially costly if teams are to be optimized. In this article, we propose a tool whose aim it is to cover such a gap. It combines artificial intelligence techniques such as coalition structure generation, Bayesian learning, and Belbin’s role theory to facilitate the generation of working groups in an educational context. This tool improves current state of the art proposals in three ways: i) it takes into account the feedback of other teammates in order to establish the most predominant role of a student instead of self-perception questionnaires; ii) it handles uncertainty with regard to each student’s predominant team role; iii) it is iterative since it considers information from several interactions in order to improve the estimation of role assignments. We tested the performance of the proposed tool in an experiment involving students that took part in three different team activities. The experiments suggest that the proposed tool is able to improve different teamwork aspects such as team dynamics and student satisfaction.",
            "output": [
                "An artificial intelligence tool for heterogeneous team formation in the classroom"
            ]
        },
        {
            "id": "task1540-5d19c735a6764be4a04904fda4bf797d",
            "input": "The First-Order Variable Elimination (FOVE) algorithm allows exact inference to be applied directly to probabilistic relational models, and has proven to be vastly superior to the application of standard inference methods on a grounded propositional model. Still, FOVE operators can be applied under restricted conditions, often forcing one to resort to propositional inference. This paper aims to extend the applicability of FOVE by providing two new model conversion operators: the first and the primary is joint formula conversion and the second is just-different counting conversion. These new operations allow efficient inference methods to be applied directly on relational models, where no existing efficient method could be applied hitherto. In addition, aided by these capabilities, we show how to adapt FOVE to provide exact solutions to Maximum Expected Utility (MEU) queries over relational models for decision under uncertainty. Experimental evaluations show our algorithms to provide significant speedup over the alternatives.",
            "output": [
                "Extended Lifted Inference with Joint Formulas"
            ]
        },
        {
            "id": "task1540-36d79d159c7e48f295de413fd26fce17",
            "input": "Software estimation is a crucial task in software engineering. Software estimation encompasses cost, effort, schedule, and size. The importance of software estimation becomes critical in the early stages of the software life cycle when the details of software have not been revealed yet. Several commercial and non-commercial tools exist to estimate software in the early stages. Most software effort estimation methods require software size as one of the important metric inputs and consequently, software size estimation in the early stages becomes essential. One of the approaches that has been used for about two decades in the early size and effort estimation is called use case points. Use case points method relies on the use case diagram to estimate the size and effort of software projects. Although the use case points method has been widely used, it has some limitations that might adversely affect the accuracy of estimation. This paper presents some techniques using fuzzy logic and neural networks to improve the accuracy of the use case points method. Results showed that an improvement up to 22% can be obtained using the proposed approach.",
            "output": [
                "Enhancing Use Case Points Estimation Method Using Soft Computing Techniques"
            ]
        },
        {
            "id": "task1540-45b67b8e8aba46119cba06e776a916ac",
            "input": "We investigate the `∞-constrained representation which demonstrates robustness to quantization errors, utilizing the tool of deep learning. Based on the Alternating Direction Method of Multipliers (ADMM), we formulate the original convex minimization problem as a feed-forward neural network, named Deep `∞ Encoder, by introducing the novel Bounded Linear Unit (BLU) neuron and modeling the Lagrange multipliers as network biases. Such a structural prior acts as an effective network regularization, and facilitates the model initialization. We then investigate the effective use of the proposed model in the application of hashing, by coupling the proposed encoders under a supervised pairwise loss, to develop a Deep Siamese `∞ Network, which can be optimized from end to end. Extensive experiments demonstrate the impressive performances of the proposed model. We also provide an in-depth analysis of its behaviors against the competitors.",
            "output": [
                "Learning A Deep `∞ Encoder for Hashing"
            ]
        },
        {
            "id": "task1540-6c3397269971457f8a6438d7648de555",
            "input": "Training deep directed graphical models with many hidden variables and performing inference remains a major challenge. Helmholtz machines and deep belief networks are such models, and the wake-sleep algorithm has been proposed to train them. The wake-sleep algorithm relies on training not just the directed generative model but also a conditional generative model (the inference network) that runs backward from visible to latent, estimating the posterior distribution of latent given visible. We propose a novel interpretation of the wake-sleep algorithm which suggests that better estimators of the gradient can be obtained by sampling latent variables multiple times from the inference network. This view is based on importance sampling as an estimator of the likelihood, with the approximate inference network as a proposal distribution. This interpretation is confirmed experimentally, showing that better likelihood can be achieved with this reweighted wake-sleep procedure, which also provides a natural way to estimate the likelihood itself. Based on this interpretation, we propose that a sigmoid belief network is not sufficiently powerful for the layers of the inference network, in order to recover a good estimator of the posterior distribution of latent variables. Our experiments show that using a more powerful layer model, such as NADE, yields substantially better generative models.",
            "output": [
                "Reweighted Wake-Sleep"
            ]
        },
        {
            "id": "task1540-404b81b482594c76916e3cd9e45ea148",
            "input": "We describe an LSTM-based model which we call Byte-to-Span (BTS) that reads text as bytes and outputs span annotations of the form [start, length, label] where start positions, lengths, and labels are separate entries in our vocabulary. Because we operate on unicode bytes rather than language-specific words or characters, we can analyze text in many languages with a single model. Due to the small vocabulary size, these multilingual models are very compact, but produce results similar to or better than the state-of-the-art in Part-of-Speech tagging and Named Entity Recognition that use only the provided training datasets (no external data sources). Our models are learning “from scratch” in that they do not rely on any elements of the standard pipeline in Natural Language Processing.",
            "output": [
                "Multilingual Language Processing From Bytes"
            ]
        },
        {
            "id": "task1540-521ab350b65f4410b52be6ed9f87dca0",
            "input": "Deep reinforcement learning (RL) can acquire complex behaviors from low-level inputs, such as images. However, real-world applications of such methods require generalizing to the vast variability of the real world. Deep networks are known to achieve remarkable generalization when provided with massive amounts of labeled data, but can we provide this breadth of experience to an RL agent, such as a robot? The robot might continuously learn as it explores the world around it, even while it is deployed and performing useful tasks. However, this learning requires access to a reward function, to tell the agent whether it is succeeding or failing at its task. Such reward functions are often hard to measure in the real world, especially in domains such as robotics and dialog systems, where the reward could depend on the unknown positions of objects or the emotional state of the user. On the other hand, it is often quite practical to provide the agent with reward functions in a limited set of situations, such as when a human supervisor is present, or in a controlled laboratory setting. Can we make use of this limited supervision, and still benefit from the breadth of experience an agent might collect in the unstructured real world? In this paper, we formalize this problem setting as semisupervised reinforcement learning (SSRL), where the reward function can only be evaluated in a set of “labeled” MDPs, and the agent must generalize its behavior to the wide range of states it might encounter in a set of “unlabeled” MDPs, by using experience from both settings. Our proposed method infers the task objective in the unlabeled MDPs through an algorithm that resembles inverse RL, using the agent’s own prior experience in the labeled MDPs as a kind of demonstration of optimal behavior. We evaluate our method on challenging, continuous control tasks that require control directly from images, and show that our approach can improve the generalization of a learned deep neural network policy by using experience for which no reward function is available. We also show that our method outperforms direct supervised learning of the reward.",
            "output": [
                "GENERALIZING SKILLS WITH SEMI-SUPERVISED REINFORCEMENT LEARNING"
            ]
        },
        {
            "id": "task1540-b7fe8c9fd7ab45a7b986ac55c32da464",
            "input": "We propose and compare various sentence selection strategies for active learning for the task of detecting mentions of entities. The best strategy employs the sum of con dences of two statistical classi ers trained on di erent views of the data. Our experimental results show that, compared to the random selection strategy, this strategy reduces the amount of required labeled training data by over 50% while achieving the same performance. The e ect is even more signi cant when only named mentions are considered: the system achieves the same performance by using only 42% of the training data required by the random selection strategy.",
            "output": [
                "Active Learning for Mention Detection: A Comparison of Sentence Selection Strategies"
            ]
        },
        {
            "id": "task1540-d35975cf85d34662aaea41471fbf4c1b",
            "input": "Abstract—The emergence of collective dynamics in neural networks is a mechanism of the animal and human brain for information processing. In this paper, we develop a computational technique of distributed processing elements, which are called particles. We observe the collective dynamics of particles in a complex network for transductive inference on semi-supervised learning problems. Three actions govern the particles’ dynamics: walking, absorption, and generation. Labeled vertices generate new particles that compete against rival particles for edge domination. Active particles randomly walk in the network until they are absorbed by either a rival vertex or an edge currently dominated by rival particles. The result from the model simulation consists of sets of edges sorted by the label dominance. Each set tends to form a connected subnetwork to represent a data class. Although the intrinsic dynamics of the model is a stochastic one, we prove there exists a deterministic version with largely reduced computational complexity; specifically, with subquadratic growth. Furthermore, the edge domination process corresponds to an unfolding map. Intuitively, edges “stretch” and “shrink” according to edge dynamics. Consequently, such effect summarizes the relevant relationships between vertices and uncovered data classes. The proposed model captures important details of connectivity patterns over the edge dynamics evolution, which contrasts with previous approaches focused on vertex dynamics. Computer simulations reveal that our model can identify nonlinear features in both real and artificial data, including boundaries between distinct classes and the overlapping structure of data.",
            "output": [
                "Network Unfolding Map by Edge Dynamics Modeling"
            ]
        },
        {
            "id": "task1540-82662a1b1fec42e1bebc84ac5a1aad8b",
            "input": "We propose a new encoder-decoder approach to learn distributed sentence representations from unlabeled sentences. The word-to-vector representation is used, and convolutional neural networks are employed as sentence encoders, mapping an input sentence into a fixed-length vector. This representation is decoded using long short-term memory recurrent neural networks, considering several tasks, such as reconstructing the input sentence, or predicting the future sentence. We further describe a hierarchical encoder-decoder model to encode a sentence to predict multiple future sentences. By training our models on a large collection of novels, we obtain a highly generic convolutional sentence encoder that performs well in practice. Experimental results on several benchmark datasets, and across a broad range of applications, demonstrate the superiority of the proposed model over competing methods.",
            "output": [
                "Unsupervised Learning of Sentence Representations using Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-526d76d1bb9c493a802cd49c885106b5",
            "input": "Learning by observation can be of key importance whenever agents sharing similar features want to learn from each other. This paper presents an agent architecture that enables software agents to learn by direct observation of the actions executed by expert agents while they are performing a task. This is possible because the proposed architecture displays information that is essential for observation, making it possible for software agents to observe each other. The agent architecture supports a learning process that covers all aspects of learning by observation, such as discovering and observing experts, learning from the observed data, applying the acquired knowledge and evaluating the agent’s progress. The evaluation provides control over the decision to obtain new knowledge or apply the acquired knowledge to new problems. We combine two methods for learning from the observed information. The first one, the recall method, uses the sequence on which the actions were observed to solve new problems. The second one, the classification method, categorizes the information in the observed data and determines to which set of categories the new problems belong. Results show that agents are able to learn in conditions where common supervised learning algorithms fail, such as when agents do not know the results of their actions a priori or when not all the effects of the actions are visible. The results also show that our approach provides better results than other learning methods since it requires shorter learning periods.",
            "output": [
                "Learning by Observation of Agent Software Images"
            ]
        },
        {
            "id": "task1540-5055f81da8d840c19349c6bce4bc72f4",
            "input": "The paper proposes a fresh look at the concept of goal and advances that motivational attitudes like desire, goal and intention are just facets of the broader notion of (acceptable) outcome. We propose to encode the preferences of an agent as sequences of “alternative acceptable outcomes”. We then study how the agent’s beliefs and norms can be used to filter the mental attitudes out of the sequences of alternative acceptable outcomes. Finally, we formalise such intuitions in a novel Modal Defeasible Logic and we prove that the resulting formalisation is computationally feasible.",
            "output": [
                "The Rationale behind the Concept of Goal"
            ]
        },
        {
            "id": "task1540-4640ed8fa4a54201beed3ed43fc760b0",
            "input": "In this work, we present and analyze reported failures of artificially intelligent systems and extrapolate our analysis to future AIs. We suggest that both the frequency and the seriousness of future AI failures will steadily increase. AI Safety can be improved based on ideas developed by cybersecurity experts. For narrow AIs safety failures are at the same, moderate, level of criticality as in cybersecurity, however for general AI, failures have a fundamentally different impact. A single failure of a superintelligent system may cause a catastrophic event without a chance for recovery. The goal of cybersecurity is to reduce the number of successful attacks on the system; the goal of AI Safety is to make sure zero attacks succeed in bypassing the safety mechanisms. Unfortunately, such a level of performance is unachievable. Every security system will eventually fail; there is no such thing as a 100% secure system.",
            "output": [
                "Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures"
            ]
        },
        {
            "id": "task1540-13cfeefc10b04e90a0b5d715502b93cf",
            "input": "In this work we study variance in the results of neural network training on a wide variety of configurations in automatic speech recognition. Although this variance itself is well known, this is, to the best of our knowledge, the first paper that performs an extensive empirical study on its effects in speech recognition. We view training as sampling from a distribution and show that these distributions can have a substantial variance. These results show the urgent need to rethink the way in which results in the literature are reported and interpreted.",
            "output": [
                "Training variance and performance evaluation of neural networks in speech"
            ]
        },
        {
            "id": "task1540-c85c2152c3ed48ed9306e7f83b89bf91",
            "input": "Inverse optimal control, also known as inverse reinforcement learning, is the problem of recovering an unknown reward function in a Markov decision process from expert demonstrations of the optimal policy. We introduce a probabilistic inverse optimal control algorithm that scales gracefully with task dimensionality, and is suitable for large, continuous domains where even computing a full policy is impractical. By using a local approximation of the reward function, our method can also drop the assumption that the demonstrations are globally optimal, requiring only local optimality. This allows it to learn from examples that are unsuitable for prior methods.",
            "output": [
                "Continuous Inverse Optimal Control with Locally Optimal Examples"
            ]
        },
        {
            "id": "task1540-9cbc5c6d4da9467293abb2385f21d4a7",
            "input": "In order to find Nash-equilibria for two-player zero-sum games where each player plays combinatorial objects like spanning trees, matchings etc, we consider two online learning algorithms: the online mirror descent (OMD) algorithm and the multiplicative weights update (MWU) algorithm. The OMD algorithm requires the computation of a certain Bregman projection, that has closed form solutions for simple convex sets like the Euclidean ball or the simplex. However, for general polyhedra one often needs to exploit the general machinery of convex optimization. We give a novel primal-style algorithm for computing Bregman projections on the base polytopes of polymatroids. Next, in the case of the MWU algorithm, although it scales logarithmically in the number of pure strategies or experts N in terms of regret, the algorithm takes time polynomial in N ; this especially becomes a problem when learning combinatorial objects. We give a general recipe to simulate the multiplicative weights update algorithm in time polynomial in their natural dimension. This is useful whenever there exists a polynomial time generalized counting oracle (even if approximate) over these objects. Finally, using the combinatorial structure of symmetric Nash-equilibria (SNE) when both players play bases of matroids, we show that these can be found with a single projection or convex minimization (without using online learning).",
            "output": [
                "Solving Combinatorial Games using Products, Projections and Lexicographically Optimal Bases"
            ]
        },
        {
            "id": "task1540-1218c28d2e1f4b919ae75df97a6a57a0",
            "input": "We present ML4PG — a machine learning extension for Proof General. It allows users to gather proof statistics related to shapes of goals, sequences of applied tactics, and proof tree structures from the libraries of interactive higher-order proofs written in Coq and SSReflect. The gathered data is clustered using the state-of-the-art machine learning algorithms available in MATLAB and Weka. ML4PG provides automated interfacing between Proof General and MATLAB/Weka. The results of clustering are used by ML4PG to provide proof hints in the process of interactive proof development.",
            "output": [
                "Machine Learning in Proof General: Interfacing Interfaces"
            ]
        },
        {
            "id": "task1540-fbc2c44aaebe47e89bd9642a999d8270",
            "input": "This paper describe about a new methodology for developing and improving the robotics field via artificial intelligence and internet of things. Now a day, we can say Artificial Intelligence take the world into robotics. Almost all industries use robots for lot of works. They are use co-operative robots to make different kind of works. But there was some problem to make robot for multi tasks. So there was a necessary new methodology to made multi tasking robots. It will be done only by artificial intelligence and internet of things.",
            "output": [
                "A Novel Method for Developing Robotics via Artificial Intelligence and Internet of Things "
            ]
        },
        {
            "id": "task1540-99a329a54b3646579cac2472fccf4ba6",
            "input": "Learning both hierarchical and temporal representation has been among the longstanding challenges of recurrent neural networks. Multiscale recurrent neural networks have been considered as a promising approach to resolve this issue, yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence. In this paper, we propose a novel multiscale approach, called the hierarchical multiscale recurrent neural network, which can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism. We show some evidence that our proposed multiscale architecture can discover underlying hierarchical structure in the sequences without using explicit boundary information. We evaluate our proposed model on character-level language modelling and handwriting sequence generation.",
            "output": [
                "Hierarchical Multiscale Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-1f71fb84feb144d78de6bf6c071bc3d1",
            "input": "Social media is a rich source of rumours and corresponding community reactions. Rumours reflect different characteristics, some shared and some individual. We formulate the problem of classifying tweet level judgements of rumours as a supervised learning task. Both supervised and unsupervised domain adaptation are considered, in which tweets from a rumour are classified on the basis of other annotated rumours. We demonstrate how multi-task learning helps achieve good results on rumours from the 2011 England riots.",
            "output": [
                "Classifying Tweet Level Judgements of Rumours in Social Media"
            ]
        },
        {
            "id": "task1540-31e5b0b6716148459339b09d455edc7e",
            "input": "iv",
            "output": [
                "A Theory of Interactive Debugging of Knowledge Bases in Monotonic Logics"
            ]
        },
        {
            "id": "task1540-5257e9e6bde9458a89ee92dd957d43a5",
            "input": "Translated texts are distinctively different from original ones, to the extent that supervised text classification methods can distinguish between them with high accuracy. These differences were proven useful for statistical machine translation. However, it has been suggested that the accuracy of translation detection deteriorates when the classifier is evaluated outside the domain it was trained on. We show that this is indeed the case, in a variety of evaluation scenarios. We then show that unsupervised classification is highly accurate on this task. We suggest a method for determining the correct labels of the clustering outcomes, and then use the labels for voting, improving the accuracy even further. Moreover, we suggest a simple method for clustering in the challenging case of mixed-domain datasets, in spite of the dominance of domainrelated features over translation-related ones. The result is an effective, fully-unsupervised method for distinguishing between original and translated texts that can be applied to new domains with reasonable accuracy.",
            "output": [
                "Unsupervised Identification of Translationese"
            ]
        },
        {
            "id": "task1540-66df67429e3e4437b667a78d8f8af83e",
            "input": "Data preprocessing is a fundamental part of any machine learning application and frequently the most time-consuming aspect when developing a machine learning solution. Preprocessing for deep learning is characterized by pipelines that lazily load data and perform data transformation, augmentation, batching and logging. Many of these functions are common across applications but require different arrangements for training, testing or inference. Here we introduce a novel software framework named nuts-flow/ml that encapsulates common preprocessing operations as components, which can be flexibly arranged to rapidly construct efficient preprocessing pipelines for deep learning.",
            "output": [
                "nuts-flow/ml : data pre-processing for deep learning"
            ]
        },
        {
            "id": "task1540-754bab22060942d189d99efeb58bff20",
            "input": "Language understanding is a key component in a spoken dialogue system. In this paper, we investigate how the language understanding module influences the dialogue system performance by conducting a series of systematic experiments on a task-oriented neural dialogue system in a reinforcement learning based setting. The empirical study shows that among different types of language understanding errors, slot-level errors can have more impact on the overall performance of a dialogue system compared to intent-level errors. In addition, our experiments demonstrate that the reinforcement learning based dialogue system is able to learn when and what to confirm in order to achieve better performance and greater robustness.",
            "output": [
                "Investigation of Language Understanding Impact for Reinforcement Learning Based Dialogue Systems"
            ]
        },
        {
            "id": "task1540-5d2bca9c430241e5a6678e5b53eebe6a",
            "input": "The explanation of heterogeneous multivariate time series data is a central problem in many applications. The problem requires two major data mining challenges to be addressed simultaneously: Learning models that are humaninterpretable and mining of heterogeneous multivariate time series data. The intersection of these two areas is not adequately explored in the existing literature. To address this gap, we propose grammar-based decision trees and an algorithm for learning them. Grammar-based decision tree extends decision trees with a grammar framework. Logical expressions, derived from context-free grammar, are used for branching in place of simple thresholds on attributes. The added expressivity enables support for a wide range of data types while retaining the interpretability of decision trees. By choosing a grammar based on temporal logic, we show that grammar-based decision trees can be used for the interpretable classification of high-dimensional and heterogeneous time series data. In addition to classification, we show how grammar-based decision trees can also be used for categorization, which is a combination of clustering and generating interpretable explanations for each cluster. We apply grammar-based decision trees to analyze the classic Australian Sign Language dataset as well as categorize and explain near midair collisions to support the development of a prototype aircraft collision avoidance system.",
            "output": [
                "Interpretable Categorization of Heterogeneous Time Series Data"
            ]
        },
        {
            "id": "task1540-88632c5d2efb4057b2136936b7fc2b74",
            "input": "Intersections constitute one of the most dangerous elements in road systems. Traffic signals remain the most common way to control traffic at high-volume intersections and offer many opportunities to apply intelligent transportation systems to make traffic more efficient and safe. This paper describes an automated method to estimate the temporal exposure of road users crossing the conflict zone to lateral collision with road users originating from a different approach. This component is part of a larger system relying on video sensors to provide queue lengths and spatial occupancy that are used for real time traffic control and monitoring. The method is evaluated on data collected during a real world experiment.",
            "output": [
                "Automatic Estimation of the Exposure to Lateral Collision in Signalized Intersections using Video Sensors"
            ]
        },
        {
            "id": "task1540-0b8b0b7b937e4576a921790e30602e78",
            "input": "We are proposing a tool able to gather information on social networks from narrative texts. Its name is CHAPLIN, CHAracters and PLaces Interaction Network, implemented in VB.NET. Characters and places of the narrative works are extracted in a list of raw words. Aided by the interface, the user selects names out of them. After this choice, the tool allows the user to enter some parameters, and, according to them, creates a network where the nodes are the characters and places, and the edges their interactions. Edges are labelled by performances. The output is a GV file, written in the DOT graph scripting language, which is rendered by means of the free open source software Graphviz.",
            "output": [
                "Extracting Networks of Characters and Places from Written Works with CHAPLIN Extracting Networks of Characters and Places from Written Works with CHAPLIN"
            ]
        },
        {
            "id": "task1540-a9808468f2814265a719ef84a914e56e",
            "input": "Semantic composition is the task of understanding the meaning of text by composing the meanings of the individual words in the text. Semantic decomposition is the task of understanding the meaning of an individual word by decomposing it into various aspects (factors, constituents, components) that are latent in the meaning of the word. We take a distributional approach to semantics, in which a word is represented by a context vector. Much recent work has considered the problem of recognizing compositions and decompositions, but we tackle the more difficult generation problem. For simplicity, we focus on noun-modifier bigrams and noun unigrams. A test for semantic composition is, given context vectors for the noun and modifier in a noun-modifier bigram (red salmon), generate a noun unigram that is synonymous with the given bigram (sockeye). A test for semantic decomposition is, given a context vector for a noun unigram (snifter), generate a noun-modifier bigram that is synonymous with the given unigram (brandy glass). With a vocabulary of about 73,000 unigrams from WordNet, there are 73,000 candidate unigram compositions for a bigram and 5,300,000,000 (73,000 squared) candidate bigram decompositions for a unigram. We generate ranked lists of potential solutions in two passes. A fast unsupervised learning algorithm generates an initial list of candidates and then a slower supervised learning algorithm refines the list. We evaluate the candidate solutions by comparing them to WordNet synonym sets. For decomposition (unigram to bigram), the top 100 most highly ranked bigrams include a WordNet synonym of the given unigram 50.7% of the time. For composition (bigram to unigram), the top 100 most highly ranked unigrams include a WordNet synonym of the given bigram 77.8% of the time.",
            "output": [
                "Semantic Composition and Decomposition: From Recognition to Generation"
            ]
        },
        {
            "id": "task1540-712456b4707e49d5ac17e23117687c8a",
            "input": "Suppose we are given the conditional proba­ bility of one variable given some other vari­ ables. Normally the full joint distribution over the conditioning variables is required to determine the probability of the conditioned variable. Under what circumstances are the marginal distributions over the conditioning variables sufficient to determine the probabil­ ity of the conditioned variable? Sufficiency in this sense is equivalent to additive separa­ bility of the conditional probability distribu­ tion. Such separability structure is natural and can be exploited for efficient inference. Separability has a natural generalization to conditional separability. Separability provides a precise notion of hi­ erarchical decomposition in temporal prob­ abilistic models. Given a system that is decomposed into separable subsystems, ex­ act marginal probabilities over subsystems at future points in time can be computed by propagating marginal subsystem probabil­ ities, rather than complete system joint prob­ abilities. Thus, separability can make exact prediction tractable. However, observations can break separability, so exact monitoring of dynamic systems remains hard.",
            "output": [
                "Sufficiency, Separability and Temporal Probabilistic Models"
            ]
        },
        {
            "id": "task1540-ba64b8946e9247829e84dfd116e9b6ab",
            "input": "Distributions over rankings are used to model data in a multitude of real world settings such as preference analysis and political elections. Modeling such distributions presents several computational challenges, however, due to the factorial size of the set of rankings over an item set. Some of these challenges are quite familiar to the artificial intelligence community, such as how to compactly represent a distribution over a combinatorially large space, and how to efficiently perform probabilistic inference with these representations. With respect to ranking, however, there is the additional challenge of what we refer to as human task complexity — users are rarely willing to provide a full ranking over a long list of candidates, instead often preferring to provide partial ranking information. Simultaneously addressing all of these challenges — i.e., designing a compactly representable model which is amenable to efficient inference and can be learned using partial ranking data — is a difficult task, but is necessary if we would like to scale to problems with nontrivial size. In this paper, we show that the recently proposed riffled independence assumptions cleanly and efficiently address each of the above challenges. In particular, we establish a tight mathematical connection between the concepts of riffled independence and of partial rankings. This correspondence not only allows us to then develop efficient and exact algorithms for performing inference tasks using riffled independence based representations with partial rankings, but somewhat surprisingly, also shows that efficient inference is not possible for riffle independent models (in a certain sense) with observations which do not take the form of partial rankings. Finally, using our inference algorithm, we introduce the first method for learning riffled independence based models from partially ranked data. 1. Probabilistic Modeling of Ranking Data: Three Challenges Rankings arise in a number of machine learning application settings such as preference analysis for movies and books (Lebanon & Mao, 2008) and political election analysis (Gormley & Murphy, 2007; Huang & Guestrin, 2010). In many of these problems, it is of great interest to build statistical models over ranking data in order to make predictions, form recommendations, discover latent trends and structure and to construct human-comprehensible data summaries. c ©2012 AI Access Foundation. All rights reserved. Huang, Kapoor & Guestrin Modeling distributions over rankings is a difficult problem, however, due to the fact that as the number of items being ranked increases, the number of possible rankings increases factorially. This combinatorial explosion forces us to confront three central challenges when dealing with rankings. First, we need to deal with storage complexity — how can we compactly represent a distribution over the space of rankings?1 Then there is algorithmic complexity — how can we efficiently answer probabilistic inference queries given a distribution? Finally, we must contend with what we refer to as human task complexity, which is a challenge stemming from the fact that it can be difficult to accurately elicit a full ranking over a large list of candidates from a human user; choosing from a list of n! options is no easy task and users typically prefer to provide partial information. Take the American Psychological Association (APA) elections, for example, which allow their voters to rank order candidates from favorite to least favorite. In the 1980 election, there were five candidates, and therefore 5! = 120 ways to rank those five candidates. Despite the small candidate list, most voters in the election preferred to only specify their top-k favorite candidates rather than writing down full rankings on their ballots (see Figure 1). For example, roughly a third of voters simply wrote down their single favorite candidate in this 1980 election. These three intertwined challenges of storage, algorithmic, and human task complexity are the central issues of probabilistic modeling for rankings, and models that do not efficiently handle all three sources of complexity have limited applicability. In this paper, we examine a flexible and intuitive class of models for rankings based on a generalization of probabilistic independence called riffled independence, proposed in our recent work (Huang & Guestrin, 2009, 2010). While our previous papers have focused primarily on representational (storage complexity) issues, we now concentrate on inference and incomplete observations (i.e., partial rankings), showing that in addition to storage complexity, riffle independence based models can efficiently address issues of algorithmic and human task complexity. In fact the two issues of algorithmic and human task complexity are intricately linked for riffle independent models. By considering partial rankings, we give users more flexibility to provide as much or as little information as they care to give. In the context of partial ranking data, the most relevant inference queries also take the form of partial rankings. For example, we might want to predict a voter’s second choice candidate given information about his first choice. One of our main contributions in this paper is to show that inference for such partial ranking queries can be performed particularly efficiently for riffle independent models. The main contributions of our work are as follows:2 • We reveal a natural and fundamental connection between riffle independent models and partial rankings. In particular, we show that the collection of partial rankings over an item set form a complete characterization of the space of observations upon 1. Note that it is common to wonder why one would care to represent a distribution over all rankings if the number of sample rankings is never nearly as large. This problem that the number of samples is always much smaller than n! however, means that most rankings are never observed, limiting our ability to estimate the probability of an arbitrary ranking. The only way to overcome the paucity of samples is to exploit representational structure, which is very much in alignment with solving the storage complexity issue. 2. This paper is an extended presentation of our paper (Huang, Kapoor, & Guestrin, 2011) which appeared in the 2011 Conference on Uncertainty in Artificial Intelligence (UAI) as well as results from the first author’s dissertation (Huang, 2011).",
            "output": [
                "Riffled Independence for Efficient Inference with Partial Rankings"
            ]
        },
        {
            "id": "task1540-47307c899989439eb2b1bd300cf0e752",
            "input": "We present algorithms for generating alternative solutions for explicit acyclic AND/OR structures in non-decreasing order of cost. The proposed algorithms use a best first search technique and report the solutions using an implicit representation ordered by cost. In this paper, we present two versions of the search algorithm – (a) an initial version of the best first search algorithm, ASG, which may present one solution more than once while generating the ordered solutions, and (b) another version, LASG, which avoids the construction of the duplicate solutions. The actual solutions can be reconstructed quickly from the implicit compact representation used. We have applied the methods on a few test domains, some of them are synthetic while the others are based on well known problems including the search space of the 5-peg Tower of Hanoi problem, the matrix-chain multiplication problem and the problem of finding secondary structure of RNA. Experimental results show the efficacy of the proposed algorithms over the existing approach. Our proposed algorithms have potential use in various domains ranging from knowledge based frameworks to service composition, where the AND/OR structure is widely used for representing problems.",
            "output": [
                "Algorithms for Generating Ordered Solutions for Explicit AND/OR Structures"
            ]
        },
        {
            "id": "task1540-e6dbbca1277f4ae3b0975109f855a6a0",
            "input": "Conversational modeling is an important task in natural language understanding and machine intelligence. Although previous approaches exist, they are often restricted to specific domains (e.g., booking an airline ticket) and require handcrafted rules. In this paper, we present a simple approach for this task which uses the recently proposed sequence to sequence framework. Our model converses by predicting the next sentence given the previous sentence or sentences in a conversation. The strength of our model is that it can be trained end-to-end and thus requires much fewer hand-crafted rules. We find that this straightforward model can generate simple conversations given a large conversational training dataset. Our preliminary suggest that, despite optimizing the wrong objective function, the model is able to extract knowledge from both a domain specific dataset, and from a large, noisy, and general domain dataset of movie subtitles. On a domain-specific IT helpdesk dataset, the model can find a solution to a technical problem via conversations. On a noisy open-domain movie transcript dataset, the model can perform simple forms of common sense reasoning. As expected, we also find that the lack of consistency is a common failure mode of our model.",
            "output": [
                "A Neural Conversational Model"
            ]
        },
        {
            "id": "task1540-14195e2242054558a3a7e008e17cd5c3",
            "input": "Pervasive systems refers to context-aware systems that can sense their context, and adapt their behavior accordingly to provide adaptable services. Proactive adaptation of such systems allows changing the service and the context based on prediction. However, the definition of the context is still vague and not suitable to prediction. In this paper we discuss and classify previous definitions of context. Then, we present a new definition which allows pervasive systems to understand and predict their contexts. We analyze the essential lines that fall within the context definition, and propose some scenarios to make it clear our approach.",
            "output": [
                "International Journal of advanced studies in Computer Science and Engineering"
            ]
        },
        {
            "id": "task1540-7a65c4b752a348fd9ea6c2ed3ce8f29c",
            "input": "In recent years, deep architectures have been used for transfer learning with state-of-the-art performance in many datasets. The properties of their features remain, however, largely unstudied under the transfer perspective. In this work, we present an extensive analysis of the resiliency of feature vectors extracted from deep models, with special focus on the trade-off between performance and compression rate. By introducing perturbations to image descriptions extracted from a deep convolutional neural network, we change their precision and number of dimensions, measuring how it affects the final score. We show that deep features are more robust to these disturbances when compared to classical approaches, achieving a compression rate of 98.4%, while losing only 0.88% of their original score for Pascal VOC 2007.",
            "output": [
                "DEEP NEURAL NETWORKS UNDER STRESS"
            ]
        },
        {
            "id": "task1540-31349d24e1c4464391fc5e3d8a7ce1bb",
            "input": "Much information available on the web is copied, reused or rephrased. The phenomenon that multiple web sources pick up certain information is often called trend. A central problem in the context of web data mining is to detect those web sources that are first to publish information which will give rise to a trend. We present a simple and e cient method for finding trends dominating a pool of web sources and identifying those web sources that publish the information relevant to a trend before others. We validate our approach on real data collected from influential technology news feeds.",
            "output": [
                "Canonical Trends: Detecting Trend Setters in Web Data"
            ]
        },
        {
            "id": "task1540-2d6e83f73060455a98de4c328ef38a8b",
            "input": "We introduce a simple, general strategy to manipulate the behavior of a neural decoder that enables it to generate outputs that have specific properties of interest (e.g., sequences of a pre-specified length). The model can be thought of as a simple version of the actor-critic model that uses an interpolation of the actor (the MLE-based token generation policy) and the critic (a value function that estimates the future values of the desired property) for decision making. We demonstrate that the approach is able to incorporate a variety of properties that cannot be handled by standard neural sequence decoders, such as sequence length and backward probability (probability of sources given targets), in addition to yielding consistent improvements in abstractive summarization and machine translation when the property to be optimized is BLEU or ROUGE scores.",
            "output": [
                "Learning to Decode for Future Success"
            ]
        },
        {
            "id": "task1540-29b24f23bb1843d3b2b9777e98e949ea",
            "input": "Semantic roles play an important role in extracting knowledge from text. Current unsupervised approaches utilize features from grammar structures, to induce semantic roles. The dependence on these grammars, however, makes it difficult to adapt to noisy and new languages. In this paper we develop a data-driven approach to identifying semantic roles, the approach is entirely unsupervised up to the point where rules need to be learned to identify the position the semantic role occurs. Specifically we develop a modified-ADIOS algorithm based on ADIOS Solan et al. (2005) to learn grammar structures, and use these grammar structures to learn the rules for identifying the semantic roles based on the context in which the grammar structures appeared. The results obtained are comparable with the current state-of-art models that are inherently dependent on human annotated data.",
            "output": [
                "A Data-Driven Approach for Semantic Role Labeling from Induced Grammar Structures in Language"
            ]
        },
        {
            "id": "task1540-ede5817c6a064befa813f8acc72c60ff",
            "input": "Markov chain model is widely applied in many fields, especially the field of prediction. The classical Discrete-time Markov chain(DTMC) is a widely used method for prediction. However, the classical DTMC model has some limitation when the system is complex with uncertain information or state space is not discrete. To address it, a new belief Markov chain model is proposed by combining Dempster-Shafer evidence theory with Markov chain. In our model, the uncertain data is allowed to be handle in the form of interval number and the basic probability assignment(BPA) is generated based on the distance between interval numbers. The new belief Markov chain model overcomes the shortcomings of classical Markov chain and has an efficient ability in dealing with uncertain information. Moreover, an example of inventory prediction and the comparison between our model and classi∗Corresponding author at: School of Electronics and Information, Northwestern Polytechnical University, Xi’an, Shaanxi 710072, China. Tel: (86-29)88431267. E-mail address: jiangwen@nwpu.edu.cn, jiangwenpaper@hotmail.com Preprint submitted to Elsevier March 7, 2017 cal DTMC model can show the effectiveness and rationality of our proposed model.",
            "output": [
                "A new belief Markov chain model and its application in inventory prediction"
            ]
        },
        {
            "id": "task1540-2836c23a2f874439a0ea029b13986a52",
            "input": "Although a number of auto-encoder models enforce sparsity explicitly in their learned representation while others don’t, there has been little formal analysis on what encourages sparsity in these models in general. Therefore, our objective here is to formally study this general problem for regularized auto-encoders. We show that both regularization and activation function play an important role in encouraging sparsity. We provide sufficient conditions on both these criteria and show that multiple popular models– like De-noising and Contractive auto-encoder– and activations– like Rectified Linear and Sigmoid– satisfy these conditions; thus explaining sparsity in their learned representation. Our theoretical and empirical analysis together, throws light on the properties of regularization/activation that are conducive to sparsity. As a by-product of the insights gained from our analysis, we also propose a new activation function that overcomes the individual drawbacks of multiple existing activations (in terms of sparsity) and hence produces performance at par (or better) with the best performing activation for all auto-encoder models discussed.",
            "output": [
                "Why Regularized Auto-Encoders learn Sparse Representation?"
            ]
        },
        {
            "id": "task1540-5a3e2752055c4f4faabde8becca2c573",
            "input": "What is happiness for reinforcement learning agents? We seek a formal definition satisfying a list of desiderata. Our proposed definition of happiness is the temporal difference error, i.e. the difference between the value of the obtained reward and observation and the agent’s expectation of this value. This definition satisfies most of our desiderata and is compatible with empirical research on humans. We state several implications and discuss examples.",
            "output": [
                "A Definition of Happiness for Reinforcement Learning Agents∗"
            ]
        },
        {
            "id": "task1540-011f924a19304fce95a5855d161a66f2",
            "input": "We present an image-conditional image generation model. The model transfers an input domain to a target domain in semantic level, and generates the target image in pixel level. To generate realistic target images, we employ the real/fake-discriminator in Generative Adversarial Nets [1], but also introduce a novel domain-discriminator to make the generated image relevant to the input image. We verify our model through a challenging task of generating a piece of clothing from an input image of a dressed person. We present a high quality clothing dataset containing the two domains, and succeed in demonstrating decent results.",
            "output": [
                "Pixel-Level Domain Transfer"
            ]
        },
        {
            "id": "task1540-8b7efcdd9c5445cea603c837ab7ba22f",
            "input": "The Reservoir Computing (RC) paradigm utilizes a dynamical system, i.e., a reservoir, and a linear classifier, i.e., a read-out layer, to process data from sequential classification tasks. In this paper the usage of Cellular Automata (CA) as a reservoir is investigated. The use of CA in RC has been showing promising results. In this paper, selected state-of-the-art experiments are reproduced. It is shown that some CA-rules perform better than others, and the reservoir performance is improved by increasing the size of the CA reservoir itself. In addition, the usage of parallel loosely coupled CA-reservoirs, where each reservoir has a different CA-rule, is investigated. The experiments performed on quasi-uniform CA reservoir provide valuable insights in CAreservoir design. The results herein show that some rules do not work well together, while other combinations work remarkably well. This suggests that non-uniform CA could represent a powerful tool for novel CA reservoir implementations. Keywords—Reservoir Computing, Cellular Automata, Parallel Reservoir, Recurrent Neural Networks, Non-Uniform Cellular Automata.",
            "output": [
                "Reservoir Computing Using Non-Uniform Binary Cellular Automata"
            ]
        },
        {
            "id": "task1540-f7d14bdb4053444b9e81040390627412",
            "input": "Reinforcement learning systems are often concerned with balancing exploration of untested actions against exploitation of actions that are known to be good. The benefit of exploration can be estimated using the classi­ cal notion of Value of Informationthe expected im­ provement in future decision quality arising from the tnformation acquired by exploration. Estimating this quantity requires an assessment of the agent's uncer­ tainty about its current value estimates for states. In this paper we investigate ways to represent and rea­ son about this uncertainty in algorithms where the sys­ tem attempts to learn a model of its environment. We explicitly represent uncertainty about the parameters of the model and build probability distributions over Q­ values based on these. These distributions are used to compute a myopic approximation to the value of infor­ mation for each action and hence to select the action that best balances exploration and exploitation.",
            "output": [
                "Model based Bayesian Exploration"
            ]
        },
        {
            "id": "task1540-b19b20d6989645f3a0eb8398483fce0a",
            "input": "A machine learning method needs to adapt to over time changes in the environment. Such changes are known as concept drift. One approach to concept drift handling is by feeding the whole training data set once again into a learning machine for retraining. Another approach is by rebuilding an ensemble classifiers to adapt to a new training data set. In either approach, retraining or rebuilding classifiers are expensive and not practical. In this paper, we propose an enhancement of Online-Sequential Extreme Learning Machine (OS-ELM) and its variant Constructive Enhancement OS-ELM (CEOS-ELM) by adding an adaptive capability for classification and regression problem. The scheme is named as Adaptive OS-ELM (AOS-ELM). It is a single classifier scheme that works well to handle real drift, virtual drift, and both drifts occurred at the same time (hybrid drift). The AOS-ELM also works well for sudden drift as well as recurrent context change type. The scheme is a simple unified method implemented in simple lines of code. We evaluated AOS-ELM on regression and classification problem by using various public dataset widely used for concept drift verification from SEA and STAGGER; and other public datasets such as MNIST and USPS. Experiments show that our method gives higher kappa value compared to the multi-classifier ELM ensemble. Even though AOS-ELM in practice does not need hidden nodes increase, we address some issues related to the increasing of the hidden nodes such as error condition and rank values. We propose to take the rank of the pseudo inverse matrix as an indicator parameter to detect ’under-fitting’ condition. Keywords— adaptive, concept drift, extreme learning machine, online sequential.",
            "output": [
                "Adaptive Online Sequential ELM for Concept Drift Tackling"
            ]
        },
        {
            "id": "task1540-e6694dc44e9245e98fa276b5293a4994",
            "input": "Probabilistic linear discriminant analysis (PLDA) is a popular normalization approach for the i-vector model, and has delivered state-of-the-art performance in speaker recognition. A potential problem of the PLDA model, however, is that it essentially assumes Gaussian distributions over speaker vectors, which is not always true in practice. Additionally, the objective function is not directly related to the goal of the task, e.g., discriminating true speakers and imposters. In this paper, we propose a max-margin metric learning approach to solve the problems. It learns a linear transform with a criterion that the margin between target and imposter trials are maximized. Experiments conducted on the SRE08 core test show that compared to PLDA, the new approach can obtain comparable or even better performance, though the scoring is simply a cosine computation.",
            "output": [
                "Max-Margin Metric Learning for Speaker Recognition"
            ]
        },
        {
            "id": "task1540-77a70744840b42379e28192d087889bb",
            "input": "In the election of a hierarchical clustering method, theoretic properties may give some insight to determine which method is the most suitable to treat a clustering problem. Herein, we study some basic properties of two hierarchical clustering methods: α-unchaining single linkage or SL(α) and a modified version of this one, SL∗(α). We compare the results with the properties satisfied by the classical linkage-based hierarchical clustering methods.",
            "output": [
                "ON THE PROPERTIES OF α-UNCHAINING SINGLE LINKAGE HIERARCHICAL CLUSTERING"
            ]
        },
        {
            "id": "task1540-0d011c672d314dbe8aa7b40c936c3df1",
            "input": "A modelling language is decribed which is suitable for the correlation of information when the underlying functional model of the system is incomplete or uncertain and the temporal dependencies are imprecise. An efficient an incremental implementation is outlined which depends on cost functions satisfying certain criteria. Possibilistic logic and probability theory (as it is used in the applications targetted) satisfy these criteria.",
            "output": [
                "Exploiting Uncertain and Temporal lnfonnation in Correlation"
            ]
        },
        {
            "id": "task1540-c7760aad4d7c482db8e4acf7f16b1479",
            "input": "This paper describes a method for the automatic inference of structural transfer rules to be used in a shallow-transfer machine translation (MT) system from small parallel corpora. The structural transfer rules are based on alignment templates, like those used in statistical MT. Alignment templates are extracted from sentence-aligned parallel corpora and extended with a set of restrictions which are derived from the bilingual dictionary of the MT system and control their application as transfer rules. The experiments conducted using three different language pairs in the free/open-source MT platform Apertium show that translation quality is improved as compared to word-for-word translation (when no transfer rules are used), and that the resulting translation quality is close to that obtained using hand-coded transfer rules. The method we present is entirely unsupervised and benefits from information in the rest of modules of the MT system in which the inferred rules are applied.",
            "output": [
                "Inferring Shallow-Transfer Machine Translation Rules from Small Parallel Corpora"
            ]
        },
        {
            "id": "task1540-2ea810a883c441dca1131a444e6c5929",
            "input": "Building a voice conversion (VC) system from non-parallel speech corpora is challenging but highly valuable in real application scenarios. In most situations, the source and the target speakers do not repeat the same texts or they may even speak different languages. In this case, one possible, although indirect, solution is to build a generative model for speech. Generative models focus on explaining the observations with latent variables instead of learning a pairwise transformation function, thereby bypassing the requirement of speech frame alignment. In this paper, we propose a non-parallel VC framework with a variational autoencoding Wasserstein generative adversarial network (VAW-GAN) that explicitly considers a VC objective when building the speech model. Experimental results corroborate the capability of our framework for building a VC system from unaligned data, and demonstrate improved conversion quality.",
            "output": [
                "Voice Conversion from Unaligned Corpora using Variational Autoencoding Wasserstein Generative Adversarial Networks"
            ]
        },
        {
            "id": "task1540-7e6a9d1cefd54896ae272f32ff2c8571",
            "input": "This papers shows that using separators, which is a pair of two complementary contractors, we can easily and efficiently solve the localization problem of a robot with sonar measurements in an unstructured environment. We introduce separators associated with the Minkowski sum and the Minkowski difference in order to facilitate the resolution. A test-case is given in order to illustrate the principle of the approach.",
            "output": [
                "Minkowski Operations of Sets with Application to Robot Localization"
            ]
        },
        {
            "id": "task1540-1a9962c581c648fd84dc78dc79387f3c",
            "input": "The ability of deep convolutional neural networks (CNN) to learn discriminative spectro-temporal patterns makes them well suited to environmental sound classification. However, the relative scarcity of labeled data has impeded the exploitation of this family of high-capacity models. This study has two primary contributions: first, we propose a deep convolutional neural network architecture for environmental sound classification. Second, we propose the use of audio data augmentation for overcoming the problem of data scarcity and explore the influence of different augmentations on the performance of the proposed CNN architecture. Combined with data augmentation, the proposed model produces state-of-the-art results for environmental sound classification. We show that the improved performance stems from the combination of a deep, high-capacity model and an augmented training set: this combination outperforms both the proposed CNN without augmentation and a “shallow” dictionary learning model with augmentation. Finally, we examine the influence of each augmentation on the model’s classification accuracy for each class, and observe that the accuracy for each class is influenced differently by each augmentation, suggesting that the performance of the model could be improved further by applying class-conditional data augmentation.",
            "output": [
                "Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification"
            ]
        },
        {
            "id": "task1540-5d66986409e5442d8c468ef49aa6ee8f",
            "input": "We present a method for calculation of my­ opic value of information in influence dia­ grams (Howard & Matheson, 1981) based on the strong junction tree framework (Jensen et al., 1994). An influence diagram specifies a certain or­ der of observations and decisions through its structure. This order is reflected in the corre­ sponding junction trees by the order in which the nodes are marginalized. This order of marginalization can be changed by table ex­ pansion and use of control structures, and this facilitates for calculating the expected value of information for different information scenarios within the same junction tree. In effect, a strong junction tree with expanded tables may be used for calculating the value of information between several scenarios with different observation-decision order. We compare our method to other methods for calculating the value of information in in­ fluence diagrams.",
            "output": [
                "Myopic Value of Information in Influence Diagrams"
            ]
        },
        {
            "id": "task1540-31eb0d1439954ed084c14a87b6c2690a",
            "input": "In this research we address the problem of capturing recurring concepts in a data stream environment. Recurrence capture enables the re-use of previously learned classifiers without the need for re-learning while providing for better accuracy during the concept recurrence interval. We capture concepts by applying the Discrete Fourier Transform (DFT) to Decision Tree classifiers to obtain highly compressed versions of the trees at concept drift points in the stream and store such trees in a repository for future use. Our empirical results on real world and synthetic data exhibiting varying degrees of recurrence show that the Fourier compressed trees are more robust to noise and are able to capture recurring concepts with higher precision than a meta learning approach that chooses to re-use classifiers in their originally occurring form.",
            "output": [
                "Mining Recurrent Concepts in Data Streams using the Discrete Fourier Transform"
            ]
        },
        {
            "id": "task1540-87959de5c589482a9f937fdc711e27a1",
            "input": "We introduce a method for transliteration generation that can produce transliterations in every language. Where previous results are only as multilingual as Wikipedia, we show how to use training data from Wikipedia as surrogate training for any language. Thus, the problem becomes one of ranking Wikipedia languages in order of suitability with respect to a target language. We introduce several task-specific methods for ranking languages, and show that our approach is comparable to the oracle ceiling, and even outperforms it in some cases.",
            "output": [
                "Transliteration in Any Language with Surrogate Languages"
            ]
        },
        {
            "id": "task1540-e4e09494efc140659cf2a524f88575e9",
            "input": "In this paper, we briefly introduce MiniNLP, a natural language processing library for clinical narratives. MiniNLP is an experiment of our ideas on efficient and effective medical language processing. We introduce the overall design of MiniNLP and its major components, and show the performance of it in real projects.",
            "output": [
                "A Short Introduction to MiniNLP"
            ]
        },
        {
            "id": "task1540-0f9d665bcb0b4a1b86e3b80ed9b28248",
            "input": "We consider an agent’s uncertainty about its environment and the problem of generalizing this uncertainty across observations. Specifically, we focus on the problem of exploration in non-tabular reinforcement learning. Drawing inspiration from the intrinsic motivation literature, we use sequential density models to measure uncertainty, and propose a novel algorithm for deriving a pseudo-count from an arbitrary sequential density model. This technique enables us to generalize count-based exploration algorithms to the non-tabular case. We apply our ideas to Atari 2600 games, providing sensible pseudo-counts from raw pixels. We transform these pseudo-counts into intrinsic rewards and obtain significantly improved exploration in a number of hard games, including the infamously difficult MONTEZUMA’S REVENGE.",
            "output": [
                "Unifying Count-Based Exploration and Intrinsic Motivation"
            ]
        },
        {
            "id": "task1540-42de88dd07cb453f8712e99ddb0b8281",
            "input": "Until recently, research on artificial neural networks was largely restricted to systems with only two types of variable: Neural activities that represent the current or recent input and weights that learn to capture regularities among inputs, outputs and payoffs. There is no good reason for this restriction. Synapses have dynamics at many different time-scales and this suggests that artificial neural networks might benefit from variables that change slower than activities but much faster than the standard weights. These “fast weights” can be used to store temporary memories of the recent past and they provide a neurally plausible way of implementing the type of attention to the past that has recently proved very helpful in sequence-to-sequence models. By using fast weights we can avoid the need to store copies of neural activity patterns.",
            "output": [
                "Using Fast Weights to Attend to the Recent Past"
            ]
        },
        {
            "id": "task1540-4949828906e343389bad7a0cce44f926",
            "input": "We present a new fast online clustering algorithm that reliably recovers arbitrary-shaped data clusters in high throughout data streams. Unlike the existing state-of-the-art online clustering methods based on k-means or k-medoid, it does not make any restrictive generative assumptions. In addition, in contrast to existing nonparametric clustering techniques such as DBScan or DenStream, it gives provable theoretical guarantees. To achieve fast clustering, we propose to represent each cluster by a skeleton set which is updated continuously as new data is seen. A skeleton set consists of weighted samples from the data where weights encode local densities. The size of each skeleton set is adapted according to the cluster geometry. The proposed technique automatically detects the number of clusters and is robust to outliers. The algorithm works for the infinite data stream where more than one pass over the data is not feasible. We provide theoretical guarantees on the quality of the clustering and also demonstrate its advantage over the existing state-of-the-art on several datasets.",
            "output": [
                "Fast Online Clustering with Randomized Skeleton Sets"
            ]
        },
        {
            "id": "task1540-5790936a49484234a593a04e3a2e443c",
            "input": "This paper presents a hybrid dialog state tracker that combines a rule based and a machine learning based approach to belief state tracking. Therefore, we call it a hybrid tracker. The machine learning in our tracker is realized by a Long Short Term Memory (LSTM) network. To our knowledge, our hybrid tracker sets a new state-of-the-art result for the Dialog State Tracking Challenge (DSTC) 2 dataset when the system uses only live SLU as its input.",
            "output": [
                "Hybrid Dialog State Tracker"
            ]
        },
        {
            "id": "task1540-ff2bfaaccace43d0b70f1dab306f1b3d",
            "input": "In this paper, the Dempster-Shafer method is employed as the theoretical basis for creating data classification systems. Testing is carried out using three popular (multiple attribute) benchmark datasets that have two, three and four classes. In each case, a subset of the available data is used for training to establish thresholds, limits or likelihoods of class membership for each attribute, and hence create mass functions that establish probability of class membership for each attribute of the test data. Classification of each data item is achieved by combination of these probabilities via Dempster’s Rule of Combination. Results for the first two datasets show extremely high classification accuracy that is competitive with other popular methods. The third dataset is non-numerical and difficult to classify, but good results can be achieved provided the system and mass functions are designed carefully and the right attributes are chosen for combination. In all cases the Dempster-Shafer method provides comparable performance to other more popular algorithms, but the overhead of generating accurate mass functions increases the complexity with the addition of new attributes. Overall, the results suggest that the D-S approach provides a suitable framework for the design of classification systems and that automating the mass function design and calculation would increase the viability of the algorithm for complex classification problems.",
            "output": [
                "Data Classification Using the Dempster-Shafer Method"
            ]
        },
        {
            "id": "task1540-d290c6c53e934c938aac3e208f5de0f4",
            "input": "This article describes a software module called Akshara to Prosodeme (A2P) converter in Hindi. It converts an input grapheme into prosedeme (sequence of phonemes with the specification of syllable boundaries and prosodic labels). The software is based on two proposed finite state machines—one for the syllabification and another for the syllable labeling. In addition to that, it also uses a set of nonlinear phonological rules proposed for foot formation in Hindi, which encompass solutions to schwa-deletion in simple, compound, derived and inflected words. The nonlinear phonological rules are based on metrical phonology with the provision of recursive foot structure. A software module is implemented in Python. The testing of the software for syllabification, syllable labeling, schwa deletion and prosodic labeling yield an accuracy of more than 99% on a lexicon of size 28664 words.",
            "output": [
                "A Finite State and Rule-based Akshara to Prosodeme (A2P) Converter in Hindi"
            ]
        },
        {
            "id": "task1540-27a04a7cb5314e839e7f1422c447817a",
            "input": "In this paper we extend the classical notion of strong and weak backdoor sets by allowing that different instantiations of the backdoor variables result in instances that belong to different base classes; the union of the base classes forms a heterogeneous base class. Backdoor sets to heterogeneous base classes can be much smaller than backdoor sets to homogeneous ones, hence they are much more desirable but possibly harder to find. We draw a detailed complexity landscape for the problem of detecting strong and weak backdoor sets into heterogeneous base classes for SAT",
            "output": [
                "Backdoors into Heterogeneous Classes of SAT and CSP"
            ]
        },
        {
            "id": "task1540-112eeafbce79469d82026fcf28225f64",
            "input": "We present a pixel recursive super resolution model that synthesizes realistic details into images while enhancing their resolution. A low resolution image may correspond to multiple plausible high resolution images, thus modeling the super resolution process with a pixel independent conditional model often results in averaging different details– hence blurry edges. By contrast, our model is able to represent a multimodal conditional distribution by properly modeling the statistical dependencies among the high resolution image pixels, conditioned on a low resolution input. We employ a PixelCNN architecture to define a strong prior over natural images and jointly optimize this prior with a deep conditioning convolutional network. Human evaluations indicate that samples from our proposed model look more photo realistic than a strong L2 regression baseline.",
            "output": [
                "Pixel Recursive Super Resolution"
            ]
        },
        {
            "id": "task1540-6434e58a39734f92b45b9ab7ced0399d",
            "input": "Multimodal machine translation is the task of translating sentences in a visual context. We decompose this problem into two sub-tasks: learning to translate and learning visually grounded representations. In a multitask learning framework, translations are learned in an attention-based encoderdecoder, and grounded representations are learned through image representation prediction. Our approach improves translation performance compared to the state of the art on the Multi30K dataset. Furthermore, it is equally effective if we train the image prediction task on the external MS COCO dataset, and we find improvements if we train the translation model on the external News Commentary parallel text.",
            "output": [
                "Imagination improves Multimodal Translation"
            ]
        },
        {
            "id": "task1540-7028fbf5234949b39a4309e780034129",
            "input": "Artifact-centric models for business processes recently raised a lot of attention as they manage to combine structural (i.e. data related) with dynamical (i.e. process related) aspects in a seamless way. This developed in parallel with declarative approaches for modelling processes, where activities are not burdened by over-specified constrains like in traditional process-centric approaches, but try to adapt the internal system to the humans involved and the input they receive. In this paper, we try to merge these two aspects by proposing a framework aimed at describing rich business domains through Description Logic-based ontologies, and where a set of actions allows the system to evolve by modifying such ontologies. We then propose an evolution of such framework which represents a viable and formal environment to develop decision making and planning techniques for DL-based artifactcentric business domains.",
            "output": [
                "Optimizations for Decision Making and Planning in Description Logic Based Dynamic Knowledge Bases"
            ]
        },
        {
            "id": "task1540-6edf3f4db8d240ab9a4fd818366f8b4d",
            "input": "Online social media and games are increasingly replacing offline social activities. Social media is now an indispensable mode of communication; online gaming is not only a genuine social activity but also a popular spectator sport. With support for anonymity and larger audiences, online interaction shrinks social and geographical barriers. Despite such benefits, social disparities such as gender inequality persist in online social media. In particular, online gaming communities have been criticized for persistent gender disparities and objectification. As gaming evolves into a social platform, persistence of gender disparity is a pressing question. Yet, there are few large-scale, systematic studies of gender inequality and objectification in social gaming platforms. Here we analyze more than one billion chat messages from Twitch, a social game-streaming platform, to study how the gender of streamers is associated with the nature of conversation. Using a combination of computational text analysis methods, we show that gendered conversation and objectification is prevalent in chats. Female streamers receive significantly more objectifying comments while male streamers receive more game-related comments. This difference is more pronounced for popular streamers. There also exists a large number of users who post only on female or male streams. Employing a neural vector-space embedding (paragraph vector) method, we analyze gendered chat messages and create prediction models that (i) identify the gender of streamers based on messages posted in the channel and (ii) identify the gender a viewer prefers to watch based on their chat messages. Our findings suggest that disparities in social game-streaming platforms is a nuanced phenomenon that involves the gender of streamers as well as those who produce gendered and game-related conversation.",
            "output": [
                "Gendered Conversation in a Social Game-Streaming Platform"
            ]
        },
        {
            "id": "task1540-c7a5fc924b9f463d8e20dd51157342fc",
            "input": "We provide a general framework for computing lower-bounds on the sample complexity of recovering the underlying graphs of Ising models, given i.i.d. samples. While there have been recent results for specific graph classes, these involve fairly extensive technical arguments that are specialized to each specific graph class. In contrast, we isolate two key graph-structural ingredients that can then be used to specify sample complexity lower-bounds. Presence of these structural properties makes the graph class hard to learn. We derive corollaries of our main result that not only recover existing recent results, but also provide lower bounds for novel graph classes not considered previously. We also extend our framework to the random graph setting and derive corollaries for Erdős-Rényi graphs in a certain dense setting.",
            "output": [
                "On the Information Theoretic Limits of Learning Ising Models"
            ]
        },
        {
            "id": "task1540-d3918c9b321342d2ab83078b1c0f4da4",
            "input": "Translating in real-time, a.k.a. simultaneous translation, outputs translation words before the input sentence ends, which is a challenging problem for conventional machine translation methods. We propose a neural machine translation (NMT) framework for simultaneous translation in which an agent learns to make decisions on when to translate from the interaction with a pre-trained NMT environment. To trade off quality and delay, we extensively explore various targets for delay and design a method for beam-search applicable in the simultaneous MT setting. Experiments against state-of-the-art baselines on two language pairs demonstrate the efficacy of the proposed framework both quantitatively and qualitatively. 1",
            "output": [
                "Learning to Translate in Real-time with Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-74d3a5a6e55e47aeaa8eb7d9f0057a4d",
            "input": "Medical errors are leading causes of death in the US and as such, prevention of these errors is paramount to promoting healthcare. Patient Safety Event reports are narratives describing potential adverse events to the patients and are important in identifying, and preventing medical errors. We present a neural network architecture for identifying the type of safety events which is the first step in understanding these narratives. Our proposed model is based on a soft neural attention model to improve the effectiveness of encoding long sequences. Empirical results on two large-scale real-world datasets of patient safety reports demonstrate the effectiveness of our method with significant improvements over existing methods.",
            "output": [
                "A Neural Attention Model for Categorizing Patient Safety Events"
            ]
        },
        {
            "id": "task1540-2f711bf0a5ee4c80abc6230f81d78085",
            "input": "This paper presents a theoretical, idealized model of the thinking process with the following characteristics: 1) the model can produce complex thought sequences and can be generalized to new inputs, 2) it can receive and maintain input information indefinitely for the generation of thoughts and later use, and 3) it supports learning while executing. The crux of the model lies within the concept of internal consistency, or the generated thoughts should always be consistent with the inputs from which they are created. Its merit, apart from the capability to generate new creative thoughts from an internal mechanism, depends on the potential to help training to generalize better. This is consequently enabled by separating input information into several parts to be handled by different processing components with a focus mechanism to fetch information for each. This modularized view with the focus binds the model with the computationally capable Turing machines. And as a final remark, this paper constructively shows that the computational complexity of the model is at least, if not surpass, that of a universal Turing machine.",
            "output": [
                "(Yet) Another Theoretical Model of Thinking"
            ]
        },
        {
            "id": "task1540-73ad5af99ffe4c9cbf22766ca72bd175",
            "input": "Automatic construction of large knowledge graphs (KG) by mining web-scale text datasets has received considerable attention over the last few years, resulting in the construction of several KGs, such as NELL, Google Knowledge Vault, etc. These KGs consist of thousands of ‘predicate-relations’ (e.g., isPerson, isMayorOf ) and millions of their instances (e.g., (Bill de Blasio, isMayorOf, New York City)). Estimating accuracy of such automatically constructed KGs is a challenging problem due to their size and diversity. Even though crowdsourcing is an obvious choice for such evaluation, the standard single-task crowdsourcing, where each predicate in the KG is evaluated independently, is very expensive and especially problematic if the budget available is limited. We show that such approaches are sub-optimal as they ignore dependencies among various predicates and their instances. To overcome this challenge, we propose Relational Crowdsourcing (RelCrowd), where the tasks are created while taking dependencies among predicates and instances into account. We apply this framework in the context of evaluation of large-scale KGs and demonstrate its effectiveness through extensive experiments on real-world datasets.",
            "output": [
                "Relational Crowdsourcing and its Application in Knowledge Graph Evaluation"
            ]
        },
        {
            "id": "task1540-ed2037c775ad4c16b666fc0ea7aa50b3",
            "input": "It has recently been shown that supervised learning with the popular logistic loss is equivalent to optimizing the exponential loss over sufficient statistics about the class: Rademacher observations (rados). We first show that this unexpected equivalence can actually be generalized to other example / rado losses, with necessary and sufficient conditions for the equivalence, exemplified on four losses that bear popular names in various fields: exponential (boosting), mean-variance (finance), Linear Hinge (on-line learning), ReLU (deep learning), and unhinged (statistics). Second, we show that the generalization unveils a surprising new connection to regularized learning, and in particular a sufficient condition under which regularizing the loss over examples is equivalent to regularizing the rados (with Minkowski sums) in the equivalent rado loss. This brings simple and powerful rado-based learning algorithms for sparsity-controlling regularization, that we exemplify on a boosting algorithm for the regularized exponential rado-loss, which formally boosts over four types of regularization, including the popular ridge and lasso, and the recently coined SLOPE — we obtain the first proven boosting algorithm for this last regularization. Through our first contribution on the equivalence of rado and example-based losses, ΩR.ADABOOST appears to be an efficient proxy to boost the regularized logistic loss over examples using whichever of the four regularizers (and any linear combination of them, e.g., for elastic net regularization). We are not aware of any regularized logistic loss formal boosting algorithm with such a wide spectrum of regularizers. Experiments display that regularization consistently improves performances of rado-based learning, and may challenge or beat the state of the art of example-based learning even when learning over small sets of rados. Finally, we connect regularization to ε-differential privacy, and display how tiny budgets (e.g. ε < 10) can be afforded on big domains while beating (protected) example-based learning.",
            "output": [
                "Learning Games and Rademacher Observations Losses"
            ]
        },
        {
            "id": "task1540-e63cbeddad744b8d9fc0dcdc9d1ea261",
            "input": "We propose a general method called truncated gradient to induce sparsity in the weights of online learning algorithms with convex loss functions. This method has several essential properties: 1. The degree of sparsity is continuous a parameter controls the rate of sparsi cation from no sparsi cation to total sparsi cation. 2. The approach is theoretically motivated, and an instance of it can be regarded as an online counterpart of the popular L1-regularization method in the batch setting. We prove that small rates of sparsi cation result in only small additional regret with respect to typical online learning guarantees. 3. The approach works well empirically. We apply the approach to several datasets and nd that for datasets with large numbers of features, substantial sparsity is discoverable.",
            "output": [
                "Sparse Online Learning via Truncated Gradient"
            ]
        },
        {
            "id": "task1540-93c3140c49fb437182f988b04dc90153",
            "input": "In this paper we discuss and analyze some of the intelligent classifiers which allows for automatic detection and classification of networks attacks for any intrusion detection system. We will proceed initially with their analysis using the WEKA software to work with the classifiers on a well-known IDS (Intrusion Detection Systems) dataset like NSL-KDD dataset. The NSL-KDD dataset of network attacks was created in a military network by MIT Lincoln Labs. Then we will discuss and experiment some of the hybrid AI (Artificial Intelligence) classifiers that can be used for IDS, and finally we developed a Java software with three most efficient classifiers and compared it with other options. The outputs would show the detection accuracy and efficiency of the single and combined classifiers used.",
            "output": [
                "Analysis of Intelligent Classifiers and Enhancing the Detection Accuracy for Intrusion Detection System"
            ]
        },
        {
            "id": "task1540-251d3c07e0e341279812330806b179a8",
            "input": "Recent non-linear feature selection approaches employing greedy optimisation of Centred Kernel Target Alignment(KTA) exhibit strong results in terms of generalisation accuracy and sparsity. However, they are computationally prohibitive for large datasets. We propose randSel, a randomised feature selection algorithm, with attractive scaling properties. Our theoretical analysis of randSel provides probabilistic guarantees for correct identification of relevant features under reasonable assumptions. RandSel’s characteristics make it an ideal candidate for identifying informative learned representations. We’ve conducted experimentation to establish the performance of this approach, and present encouraging results, including a 3rd position result in the recent ICML black box learning challenge as well as competitive results for signal peptide prediction, an important problem in bioinformatics.",
            "output": [
                "Learning Non-Linear Feature Maps With An Application To Representation Learning"
            ]
        },
        {
            "id": "task1540-6c88a011c5c54ce2b80a988f4c6d9a60",
            "input": "Domain adaptation is important in sentiment analysis as sentiment-indicating words vary between domains. Recently, multi-domain adaptation has become more pervasive, but existing approaches train on all available source domains including dissimilar ones. However, the selection of appropriate training data is as important as the choice of algorithm. We undertake – to our knowledge for the first time – an extensive study of domain similarity metrics in the context of sentiment analysis and propose novel representations, metrics, and a new scope for data selection. We evaluate the proposed methods on two largescale multi-domain adaptation settings on tweets and reviews and demonstrate that they consistently outperform strong random and balanced baselines, while our proposed selection strategy outperforms instance-level selection and yields the best score on a large reviews corpus. All experiments are available at url_redacted1",
            "output": [
                "Data Selection Strategies for Multi-Domain Sentiment Analysis"
            ]
        },
        {
            "id": "task1540-0467e10ca31a4d41bf177228c9d677b5",
            "input": "Most recent work focused on affect from facial expressions, and not as much on body. This work focuses on body affect analysis. Affect does not occur in isolation. Humans usually couple affect with an action in natural interactions; for example, a person could be talking and smiling. Recognizing body affect in sequences requires efficient algorithms to capture both the micro movements that differentiate between happy and sad and the macro variations between different actions. We depart from traditional approaches for time-series data analytics by proposing a multi-task learning model that learns a shared representation that is well-suited for action-affect classification as well as generation. For this paper we choose Conditional Restricted Boltzmann Machines to be our building block. We propose a new model that enhances the CRBM model with a factored multi-task component to become Multi-Task Conditional Restricted Boltzmann Machines (MTCRBMs). We evaluate our approach on two publicly available datasets, the Body Affect dataset and the Tower Game dataset, and show superior classification performance improvement over the state-of-the-art, as well as the generative abilities of our model.",
            "output": [
                "Action-Affect Classification and Morphing using Multi-Task Representation Learning"
            ]
        },
        {
            "id": "task1540-b87d0faca4ff42609b18887128030897",
            "input": "Supplier selection is a typical multi-criteria decision making(MCDM) problem and lots of uncertain information exist inevitably. To address this issue, a new method was proposed based on interval data fusion. Our method follows the original way to generate classical basic probability assignment(BPA) determined by the distance among the evidences. However, the weights of criteria are kept as interval numbers to generate interval BPAs and do the fusion of interval BPAs. Finally, the order is ranked and the decision is made according to the obtained interval BPAs. In this paper, a numerical example of supplier selection is applied to verify the feasibility and validity of our method. The new method is presented aiming at solving multiplecriteria decision-making problems in which the weights of criteria or experts are described in fuzzy data like linguistic terms or interval data.",
            "output": [
                "Evidential supplier selection based on interval data fusion"
            ]
        },
        {
            "id": "task1540-4fa5bbaef5ed4416ac51b1a61fd34d66",
            "input": "Many of the existing methods for learning joint embedding of images and text use only supervised information from paired images and its textual attributes. Taking advantage of the recent success of unsupervised learning in deep neural networks, we propose an end-to-end learning framework that is able to extract more robust multi-modal representations across domains. The proposed method combines representation learning models (i.e., auto-encoders) together with cross-domain learning criteria (i.e., Maximum Mean Discrepancy loss) to learn joint embeddings for semantic and visual features. A novel technique of unsupervised-data adaptation inference is introduced to construct more comprehensive embeddings for both labeled and unlabeled data. We evaluate our method on Animals with Attributes and Caltech-UCSD Birds 200-2011 dataset with a wide range of applications, including zero and fewshot image recognition and retrieval, from inductive to transductive settings. Empirically, we show that our framework improves over the current state of the art on many of the considered tasks.",
            "output": [
                "Learning Robust Visual-Semantic Embeddings"
            ]
        },
        {
            "id": "task1540-f7b0254c45ed4f75898d65918d2fa6f8",
            "input": "Embedding words in a vector space has gained a lot of research attention in re-<lb>cent years. While state-of-the-art methods provide efficient computation of word<lb>similarities via a low-dimensional matrix embedding, their motivation is often left<lb>unclear. In this paper, we argue that word embedding can be naturally viewed<lb>as a ranking problem. Then, based on this insight, we propose a novel frame-<lb>work WordRank that efficiently estimates word representations via robust ranking.<lb>The performance of WordRank is measured in word similarity and word analogy<lb>benchmarks, and the results are compared to the state-of-the-art word embedding<lb>techniques. Our algorithm produces a vector space with meaningful substructure,<lb>as evidenced by its performance of 77.4% accuracy on a popular word similarity<lb>benchmark and 76% on the Google word analogy benchmark. WordRank per-<lb>forms especially well on small corpora.",
            "output": [
                "WordRank: Learning Word Embeddings via Robust Ranking"
            ]
        },
        {
            "id": "task1540-14cf22376a554aa2a017c18bb85ca078",
            "input": "Increasing the capacity of recurrent neural networks (RNN) usually involves augmenting the size of the hidden layer, resulting in a significant increase of computational cost. An alternative is the recurrent neural tensor network (RNTN), which increases capacity by employing distinct hidden layer weights for each vocabulary word. The disadvantage of RNTNs is that memory usage scales linearly with vocabulary size, which can reach millions for word-level language models. In this paper, we introduce restricted recurrent neural tensor networks (r-RNTN) which reserve distinct hidden layer weights for frequent vocabulary words while sharing a single set of weights for infrequent words. Perplexity evaluations using the Penn Treebank corpus show that r-RNTNs improve language model performance over standard RNNs using only a small fraction of the parameters of unrestricted RNTNs.",
            "output": [
                "Restricted Recurrent Neural Tensor Networks"
            ]
        },
        {
            "id": "task1540-b22a2097e368480fb36eb8ea77a27c14",
            "input": "The problem of learning automata from example traces (but no equivalence or membership queries) is fundamental in automata learning theory and practice. In this paper we study this problem for finite state machines with inputs and outputs, and in particular for Moore machines. We introduce three algorithms for solving this problem: (1) the PTAP algorithm, which transforms a set of inputoutput traces into an incomplete Moore machine and then completes that machine with self-loops; (2) the PRPNI algorithm, which uses the well-known RPNI algorithm for automata learning to learn a product of automata encoding a Moore machine; and (3) the MooreMI algorithm, which directly learns a Moore machine using PTAP extended with state merging. We prove that MooreMI always learns the right machine when the training set is a characteristic sample, which is generally not true for the other two algorithms. We also compare the algorithms experimentally in terms of the size of the learned machine and several notions of accuracy, introduced in this paper. Finally, we compare with OSTIA, an algorithm that learns a more general class of transducers, and find that OSTIA generally does not learn a Moore machine, even when fed with a characteristic sample.",
            "output": [
                "Learning Moore Machines from Input-Output Traces"
            ]
        },
        {
            "id": "task1540-8e8e2ea1bf9d4d2da5a90434766d8260",
            "input": "Learning commonsense knowledge from natural language text is nontrivial due to reporting bias: people rarely state the obvious, e.g., “My house is bigger than me.” However, while rarely stated explicitly, this trivial everyday knowledge does influence the way people talk about the world, which provides indirect clues to reason about the world. For example, a statement like, “Tyler entered his house” implies that his house is bigger than Tyler. In this paper, we present an approach to infer relative physical knowledge of actions and objects along five dimensions (e.g., size, weight, and strength) from unstructured natural language text. We frame knowledge acquisition as joint inference over two closely related problems: learning (1) relative physical knowledge of object pairs and (2) physical implications of actions when applied to those object pairs. Empirical results demonstrate that it is possible to extract knowledge of actions and objects from language and that joint inference over different types of knowledge improves performance.",
            "output": [
                "VERB PHYSICS: Relative Physical Knowledge of Actions and Objects"
            ]
        },
        {
            "id": "task1540-ffba771782584c04aa8dd2301a1a1b1b",
            "input": "Recently, zero-shot learning (ZSL) has received increasing interest. The key idea underpinning existing ZSL approaches is to exploit knowledge transfer via an intermediate-level semantic representation which is assumed to be shared between the auxiliary and target datasets, and is used to bridge between these domains for knowledge transfer. The semantic representation used in existing approaches varies from visual attributes [11,2,13,7] to semantic word vectors [3,19] and semantic relatedness [17]. However, the overall pipeline is similar: a projection mapping low-level features to the semantic representation is learned from the auxiliary dataset by either classification or regression models and applied directly to map each instance into the same semantic representation space where a zero-shot classifier is used to recognise the unseen target class instances with a single known ‘prototype’ of each target class. In this paper we discuss two related lines of work improving the conventional approach: exploiting transductive learning ZSL, and generalising ZSL to the multi-label case.",
            "output": [
                "Transductive Multi-class and Multi-label Zero-shot Learning"
            ]
        },
        {
            "id": "task1540-1394dabac1f2467d9be87543d56bf8e0",
            "input": "Environmental sound detection is a challenging application of machine learning because of the noisy nature of the signal, and the small amount of (labeled) data that is typically available. This work thus presents a comparison of several state-of-the-art Deep Learning models on the IEEE challenge on Detection and Classification of Acoustic Scenes and Events (DCASE) 2016 challenge task and data, classifying sounds into one of fifteen common indoor and outdoor acoustic scenes, such as bus, cafe, car, city center, forest path, library, train, etc. In total, 13 hours of stereo audio recordings are available, making this one of the largest datasets available. We perform experiments on six sets of features, including standard Mel-frequency cepstral coefficients (MFCC), Binaural MFCC, log Mel-spectrum and two different largescale temporal pooling features extracted using OpenSMILE. On these features, we apply five models: Gaussian Mixture Model (GMM), Deep Neural Network (DNN), Recurrent Neural Network (RNN), Convolutional Deep Neural Network (CNN) and i-vector. Using the late-fusion approach, we improve the performance of the baseline 72.5% by 15.6% in 4-fold Cross Validation (CV) avg. accuracy and 11% in test accuracy, which matches the best result of the DCASE 2016 challenge. With large feature sets, deep neural network models outperform traditional methods and achieve the best performance among all the studied methods. Consistent with other work, the best performing single model is the non-temporal DNN model, which we take as evidence that sounds in the DCASE challenge do not exhibit strong temporal dynamics.",
            "output": [
                "A COMPARISON OF DEEP LEARNING METHODS FOR ENVIRONMENTAL SOUND DETECTION"
            ]
        },
        {
            "id": "task1540-4efe56967c534c58b90bcf6f70b1119b",
            "input": "Abstract A prototype tool to assist architects during the early design stage of floor plans has been developed, consisting of an Evolutionary Program for the Space Allocation Problem (EPSAP), which generates sets of floor plan alternatives according to the architect's preferences; and a Floor Plan Performance Optimization Program (FPOP), which optimizes the selected solutions according to thermal performance criteria. The design variables subject to optimization are window position and size, overhangs, fins, wall positioning, and building orientation. A procedure using a transformation operator with gradient descent, such as behavior, coupled with a dynamic simulation engine was developed for the thermal evaluation and optimization process. However, the need to evaluate all possible alternatives regarding designing variables being used during the optimization process leads to an intensive use of thermal simulation, which dramatically increases the simulation time, rendering it unpractical. An alternative approach is a smart optimization approach, which utilizes an oriented and adaptive search technique to efficiently find the near optimum solution. This paper presents the search methodology for the building orientation of floor plan designs, and the corresponding efficiency and effectiveness indicators. The calculations are based on 100 floor plan designs generated by EPSAP. All floor plans have the same design program, location, and weather data, changing only their geometry. Dynamic simulation of buildings was effectively used together with the optimization procedure in this approach to significantly improve the designs. The use of the orientation variable has been included in the algorithm.",
            "output": [
                "A Gradient Descent Technique Coupled with a Dynamic Simulation to Determine the Near Optimum Orientation of Floor Plan Designs"
            ]
        },
        {
            "id": "task1540-97322de2230540ebba3e736e8fbd281c",
            "input": "We outline a method to estimate the value of computation for a flexible algorithm using em­ pirical data. To determine a reasonable trade-off between cost and value, we build an empirical model of the value obtained through computa­ tion, and apply this model to estimate the value of computation for quite different problems. In par­ ticular, we investigate this trade-off for the prob­ lem of constructing policies for decision prob­ lems represented as influence diagrams. We show how two features of our anytime algorithm pro­ vide reasonable estimates of the value of compu­ tation in this domain.",
            "output": [
                "Estimating the Value of Computation in Flexible Information Refinement"
            ]
        },
        {
            "id": "task1540-e217c3cf126e4a79903beb88dee5d9ee",
            "input": "The challenge stated in the title can be divided into two main problems. The first problem is to reliably mimic the way that users interact with user interfaces. The second problem is to build an instructible agent, i.e. one that can be taught to execute tasks expressed as previously unseen natural language commands. This paper proposes a solution to the second problem, a system we call Helpa. End-users can teach Helpa arbitrary new tasks whose level of complexity is similar to the tasks available from today’s most popular virtual assistants. Teaching Helpa does not involve any programming. Instead, users teach Helpa by providing just one example of a command paired with a demonstration of how to execute that command. Helpa does not rely on any pre-existing domain-specific knowledge. It is therefore completely domain-independent. Our usability study showed that end-users can teach Helpa many new tasks in less than a minute each, often much less.",
            "output": [
                "Towards A Virtual Assistant That Can Be Taught New Tasks In Any Domain By Its End-Users"
            ]
        },
        {
            "id": "task1540-f3c946dfb0c542069bc643b68e946a5f",
            "input": "Machines of all kinds from vehicles to industrial equipment are increasingly instrumented with hundreds of sensors. Using such data to detect “anomalous” behaviour is critical for safety and efficient maintenance. However, anomalies occur rarely and with great variety in such systems, so there is often insufficient anomalous data to build reliable detectors. A standard approach to mitigate this problem is to use one class methods relying only on data from normal behaviour. Unfortunately, even these approaches are more likely to fail in the scenario of a dynamical system with manual control input(s). Normal behaviour in response to novel control input(s) might look very different to the learned detector which may be incorrectly detected as anomalous. In this paper, we address this issue by modelling time-series via Ordinary Differential Equations (ODE) and utilising such an ODE model to simulate the behaviour of dynamical systems under varying control inputs. The available data is then augmented with data generated from the ODE, and the anomaly detector is retrained on this augmented dataset. Experiments demonstrate that ODE-augmented training data allows better coverage of possible control input(s) and results in learning more accurate distinctions between normal and anomalous behaviour in time-series.",
            "output": [
                "ODE - Augmented Training Improves Anomaly Detection in Sensor Data from Machines"
            ]
        },
        {
            "id": "task1540-702f9d9de4324d5bbe8fb2f7586e7373",
            "input": "The Generative Adversarial Network (GAN) has achieved great success in generating realistic (realvalued) synthetic data. However, convergence issues and difficulties dealing with discrete data hinder the applicability of GAN to text. We propose a framework for generating realistic text via adversarial training. We employ a long shortterm memory network as generator, and a convolutional network as discriminator. Instead of using the standard objective of GAN, we propose matching the high-dimensional latent feature distributions of real and synthetic sentences, via a kernelized discrepancy metric. This eases adversarial training by alleviating the mode-collapsing problem. Our experiments show superior performance in quantitative evaluation, and demonstrate that our model can generate realistic-looking sentences.",
            "output": [
                "Adversarial Feature Matching for Text Generation"
            ]
        },
        {
            "id": "task1540-c6817c6e7f3a4beebae4af79c8fe6a56",
            "input": "In the neural network domain, methods for hyperparameter optimization and metamodeling are computationally expensive due to the need to train a large number of neural network configurations. In this paper, we show that a simple regression model, based on support vector machines, can predict the final performance of partially trained neural network configurations using features based on network architectures, hyperparameters, and time-series validation performance data. We use this regression model to develop an early stopping strategy for neural network configurations. With this early stopping strategy, we obtain significant speedups in both hyperparameter optimization and meta-modeling. Particularly in the context of meta-modeling, our method can learn to predict the performance of drastically different architectures and is seamlessly incorporated into reinforcement learningbased architecture selection algorithms. Finally, we show that our method is simpler, faster, and more accurate than Bayesian methods for learning curve prediction.",
            "output": [
                "Practical Neural Network Performance Prediction for Early Stopping"
            ]
        },
        {
            "id": "task1540-461263f193b946b3bbfb584f263db998",
            "input": "Abstract—An important problem in the field of bioinformatics is to identify interactive effects among profiled variables for outcome prediction. In this paper, a logistic regression model with pairwise interactions among a set of binary covariates is considered. Modeling the structure of the interactions by a graph, our goal is to recover the interaction graph from independently identically distributed (i.i.d.) samples of the covariates and the outcome. When viewed as a feature selection problem, a simple quantity called influence is proposed as a measure of the marginal effects of the interaction terms on the outcome. For the case when the underlying interaction graph is known to be acyclic, it is shown that a simple algorithm that is based on a maximum-weight spanning tree with respect to the plug-in estimates of the influences not only has strong theoretical performance guarantees, but can also outperform generic feature selection algorithms for recovering the interaction graph from i.i.d. samples of the covariates and the outcome. Our results can also be extended to the model that includes both individual effects and pairwise interactions via the help of an auxiliary covariate.",
            "output": [
                "Detection of Cooperative Interactions in Logistic Regression Models"
            ]
        },
        {
            "id": "task1540-018bd15062af4e219c61c273c6e4e3b5",
            "input": "We consider an Erdős-Rényi graph with n nodes and edge probability q that is embedded with a random subgraph of size K with edge probabilities p such that p > q. We address the problem of detecting the subgraph nodes when only the graph edges are observed, along with some extra knowledge of a small fraction of subgraph nodes, called cued vertices or cues. We employ a local and distributed algorithm called belief propagation (BP). Recent works on subgraph detection without cues have shown that global maximum likelihood (ML) detection strictly outperforms BP in terms of asymptotic error rate, namely, there is a threshold condition that the subgraph parameters should satisfy below which BP fails in achieving asymptotically zero error, but ML succeeds. In contrast, we show that when the fraction of cues is strictly bounded away from zero, i.e., when there exists non-trivial side-information, BP achieves zero asymptotic error even below this threshold, thus approaching the performance of ML detection. Key-words: Belief Propagation, Subgraph Detection, Semisupervised Learning, Random Graphs ∗ Corresponding author, arun.kadavankandy@inria.fr La Detection de Sousgraphes en presence des indices grâce au Belief Propagation Résumé : Nous considérons un graphe Erdős-Rényi qui a n sommets dont q est la probabilité d’arrêtes. La dessus il y un sousgraphe placé sur leurs m sommets selectionnés aléatoirement et leur probabilité d’arrêtes est p, en sorte que p > q. Nous proposons un algorithme distribué aux calculs locales à chaque sommet, tiré du “Belief Propagation” (BP), qui détecte les sommets du sousgraphe, quand on connait une fraction de sommets du sousgraphe en tant qu’indices. Des recherches récentes ont prouvé que la prestation du BP dans l’absence des indices est strictement inférior par rapport à la detection globale du maximum de vraisemblance (DMV). A l’opposé, ici on prouve qu’en presence des indices, la prestation du BP est à l’hauteur de celle de DMV, dans la sens où le premier reussie à detecter la sousgraphe avec une erreur qui tend a zéro, à chaque fois le dernier peut le faire, dans la limite où le nombre de sommets du graph tend l’infinité. Mots-clés : Belief Propagation, Detection de Sousgraphes, Semisupervised Learning, Graphes Aléatoires Subgraph Detection with cues using Belief Propagation 3",
            "output": [
                "Subgraph Detection with cues using Belief Propagation"
            ]
        },
        {
            "id": "task1540-a446befd81474f64aabd96d2d52d2d85",
            "input": "The utilization of statistical machine translation (SMT) has grown enormously over the last decade, many using open-source software developed by the NLP community. As commercial use has increased, there is need for software that is optimized for commercial requirements, in particular, fast phrase-based decoding and more efficient utilization of modern multicore servers. In this paper we re-examine the major components of phrase-based decoding and decoder implementation with particular emphasis on speed and scalability on multicore machines. The result is a drop-in replacement for the Moses decoder which is up to fifteen times faster and scales monotonically with the number of cores.",
            "output": [
                "Fast, Scalable Phrase-Based SMT Decoding"
            ]
        },
        {
            "id": "task1540-e17a0c9da274461195a3cb5973b01fad",
            "input": "In this work we consider the stochastic minimization of nonsmooth convex loss functions, a central problem in machine learning. We propose a novel algorithm called Accelerated Nonsmooth Stochastic Gradient Descent (ANSGD), which exploits the structure of common nonsmooth loss functions to achieve optimal convergence rates for a class of problems including SVMs. It is the first stochastic algorithm that can achieve the optimal O(1/t) rate for minimizing nonsmooth loss functions (with strong convexity). The fast rates are confirmed by empirical comparisons, in which ANSGD significantly outperforms previous subgradient descent algorithms including SGD.",
            "output": [
                "Stochastic Smoothing for Nonsmooth Minimizations: Accelerating SGD by Exploiting Structure"
            ]
        },
        {
            "id": "task1540-cbddcd8a3f454139836afb1f559bd1c5",
            "input": "We study the problem of estimating, in the sense of optimal transport metrics, a measure which is assumed supported on a manifold embedded in a Hilbert space. By establishing a precise connection between optimal transport metrics, optimal quantization, and learning theory, we derive new probabilistic bounds for the performance of a classic algorithm in unsupervised learning (k-means), when used to produce a probability measure derived from the data. In the course of the analysis, we arrive at new lower bounds, as well as probabilistic upper bounds on the convergence rate of the empirical law of large numbers, which, unlike existing bounds, are applicable to a wide class of measures.",
            "output": [
                "Learning Probability Measures with respect to Optimal Transport Metrics"
            ]
        },
        {
            "id": "task1540-4a661474c1c6404eb019f76c5f1e989d",
            "input": "The redundant features existing in high dimensional datasets always affect the performance of learning and mining algorithms. How to detect and remove them is an important research topic in machine learning and data mining research. In this paper, we propose a graph based approach to find and remove those redundant features automatically for high dimensional data. Based on sparse learning based unsupervised feature selection framework, Sparse Feature Graph (SFG) is introduced not only to model the redundancy between two features, but also to disclose the group redundancy between two groups of features. With SFG, we can divide the whole features into different groups, and improve the intrinsic structure of data by removing detected redundant features. With accurate data structure, quality indicator vectors can be obtained to improve the learning performance of existing unsupervised feature selection algorithms such as multi-cluster feature selection (MCFS). Our experimental results on benchmark datasets show that the proposed SFG and feature redundancy remove algorithm can improve the performance of unsupervised feature selection algorithms consistently.",
            "output": [
                "Automatically Redundant Features Removal for Unsupervised Feature Selection via Sparse Feature Graph"
            ]
        },
        {
            "id": "task1540-e386685286a34c53b6caecd1e34f0dc9",
            "input": "This thesis studies methods to solve Visual Question-Answering (VQA) tasks with a Deep Learning framework. As a preliminary step, we explore Long Short-Term Memory (LSTM) networks used in Natural Language Processing (NLP) to tackle Question-Answering (text based). We then modify the previous model to accept an image as an input in addition to the question. For this purpose, we explore the VGG-16 and K-CNN convolutional neural networks to extract visual features from the image. These are merged with the word embedding or with a sentence embedding of the question to predict the answer. This work was successfully submitted to the Visual Question Answering Challenge 2016, where it achieved a 53,62% of accuracy in the test dataset. The developed software has followed the best programming practices and Python code style, providing a consistent baseline in Keras for different configurations. The source code and models are publicly available at https://github.com/imatge-upc/vqa-2016-cvprw.",
            "output": [
                "Open-Ended Visual Question-Answering"
            ]
        },
        {
            "id": "task1540-44237767979746da87e6cc3c09473089",
            "input": "An efficient policy search algorithm should estimate the local gradient of the objective function, with respect to the policy parameters, from as few trials as possible. Whereas most policy search methods estimate this gradient by observing the rewards obtained during policy trials, we show, both theoretically and empirically, that taking into account the sensor data as well gives better gradient estimates and hence faster learning. The reason is that rewards obtained during policy execution vary from trial to trial due to noise in the environment; sensor data, which correlates with the noise, can be used to partially correct for this variation, resulting in an estimator with lower variance.",
            "output": [
                "Improving Gradient Estimation by Incorporating Sensor Data"
            ]
        },
        {
            "id": "task1540-5b2025d6b0f84387aa58c49a14acda3e",
            "input": "We propose a new, socially-impactful task for natural language processing: from a news corpus, extract names of persons who have been killed by police. We present a newly collected police fatality corpus, which we release publicly, and present a model to solve this problem that uses EM-based distant supervision with logistic regression and convolutional neural network classifiers. Our model outperforms two off-the-shelf event extractor systems, and it can suggest candidate victim names in some cases faster than one of the major manually-collected police fatality databases. Appendix, software, and data are available online at: http://slanglab.cs.umass. edu/PoliceKillingsExtraction/ [This paper appears in Proceedings of EMNLP 2017. This version includes the appendix.]",
            "output": [
                "Identifying civilians killed by police with distantly supervised entity-event extraction"
            ]
        },
        {
            "id": "task1540-8301816a4ab24212959c41f80dca2e6f",
            "input": "With the fast development of deep learning, people have started to train very big neural networks using massive data. Asynchronous Stochastic Gradient Descent (ASGD) is widely used to fulfill this task, which, however, is known to suffer from the problem of delayed gradient. That is, when a local worker adds the gradient it calculates to the global model, the global model may have been updated by other workers and this gradient becomes “delayed”. We propose a novel technology to compensate this delay, so as to make the optimization behavior of ASGD closer to that of sequential SGD. This is done by leveraging Taylor expansion of the gradient function and efficient approximators to the Hessian matrix of the loss function. We call the corresponding new algorithm Delay Compensated ASGD (DC-ASGD). We evaluated the proposed algorithm on CIFAR-10 and ImageNet datasets, and experimental results demonstrate that DC-ASGD can outperform both synchronous SGD and ASGD, and nearly approaches the performance of sequential SGD.",
            "output": [
                "Asynchronous Stochastic Gradient Descent with Delay Compensation for Distributed Deep Learning"
            ]
        },
        {
            "id": "task1540-bc52ff2be91f4b54aad5edc5e0a5c28b",
            "input": "With the accelerated development of robot technologies, optimal control becomes one of the central themes of research. In traditional approaches, the controller, by its internal functionality, finds appropriate actions on the basis of the history of sensor values, guided by the goals, intentions, objectives, learning schemes, and so on planted into it. The idea is that the controller controls the world—the body plus its environment—as reliably as possible. However, in elastically actuated robots this approach faces severe difficulties. This paper advocates for a new paradigm of self-organized control. The paper presents a solution with a controller that is devoid of any functionalities of its own, given by a fixed, explicit and context-free function of the recent history of the sensor values. When applying this controller to a muscletendon driven arm-shoulder system from the Myorobotics toolkit, we observe a vast variety of self-organized behavior patterns: when left alone, the arm realizes pseudo-random sequences of different poses but one can also manipulate the system into definite motion patterns. But most interestingly, after attaching an object, the controller gets in a functional resonance with the object’s internal dynamics: when given a half-filled bottle, the system spontaneously starts shaking the bottle so that maximum response from the dynamics of the water is being generated. After attaching a pendulum to the arm, the controller drives the pendulum into a circular mode. In this way, the robot discovers dynamical affordances of objects its body is interacting with. We also discuss perspectives for using this controller paradigm for intention driven behavior generation.",
            "output": [
                "Self-organized control for musculoskeletal robots"
            ]
        },
        {
            "id": "task1540-9c080a463d484c02a94160316d50ee4e",
            "input": "Distributed Constraint Optimization (DCOP) is a powerful framework for representing and solving distributed combinatorial problems, where the variables of the problem are owned by different agents. Many multi-agent problems include constraints that produce different gains (or costs) for the participating agents. Asymmetric gains of constrained agents cannot be naturally represented by the standard DCOP model. The present paper proposes a general framework for Asymmetric DCOPs (ADCOPs). In ADCOPs different agents may have different valuations for constraints that they are involved in. The new framework bridges the gap between multi-agent problems which tend to have asymmetric structure and the standard symmetric DCOP model. The benefits of the proposed model over previous attempts to generalize the DCOP model are discussed and evaluated. Innovative algorithms that apply to the special properties of the proposed ADCOP model are presented in detail. These include complete algorithms that have a substantial advantage in terms of runtime and network load over existing algorithms (for standard DCOPs) which use alternative representations. Moreover, standard incomplete algorithms (i.e., local search algorithms) are inapplicable to the existing DCOP representations of asymmetric constraints and when they are applied to the new ADCOP framework they often fail to converge to a local optimum and yield poor results. The local search algorithms proposed in the present paper converge to high quality solutions. The experimental evidence that is presented reveals that the proposed local search algorithms for ADCOPs achieve high quality solutions while preserving a high level of privacy.",
            "output": [
                "Asymmetric Distributed Constraint Optimization Problems"
            ]
        },
        {
            "id": "task1540-ceedd4ce8328429288aafacaa39db6f5",
            "input": "Chinese poetry generation is a very challenging task in natural language processing. In this paper, we propose a novel two-stage poetry generating method which first plans the sub-topics of the poem according to the user’s writing intent, and then generates each line of the poem sequentially, using a modified recurrent neural network encoder-decoder framework. The proposed planningbased method can ensure that the generated poem is coherent and semantically consistent with the user’s intent. A comprehensive evaluation with human judgments demonstrates that our proposed approach outperforms the state-of-the-art poetry generating methods and the poem quality is somehow comparable to human poets.",
            "output": [
                "Chinese Poetry Generation with Planning based Neural Network"
            ]
        },
        {
            "id": "task1540-46a603902b824fce98a917f5d4aa7abd",
            "input": "Automated learning of patients’ demographics can be seen as multilabel problem where a patient model is based on different race and gender groups. The resulting model can be further integrated into Privacy-Preserving Data Mining, where they can be used to assess risk of identification of different patient groups. Our project considers relations between diabetes and demographics of patients as a multi-labelled problem. Most research in this area has been done as binary classification, where the target class is finding if a person has diabetes or not. But very few, and maybe no work has been done in multi-labeled analysis of the demographics of patients who are likely to be diagnosed with diabetes. To identify such groups, we applied ensembles of several multilabel learning algorithms. The best performing multi label ensembles include BR/Hoeffding Tree, CC/Hoeffding Tree, BCC/Hoeffding Tree, BR/JRIP, CC/JRIP, BCC/ JRIP respectively. In the empirical part of this study, we used on the UCI Diabetics dataset of over 100,000 records, collected from 130 US hospitals. The dataset consisted of attributes that included personal demographics, diagnoses code, lab results, etc. Experiments conducted on datasets of 1000, 10000, 20000 samples, show that BR/JRip model achieves a high overall accuracy of 0.533 (1000 samples), 0.702 (10000 samples), 0.569 (20000 samples), improving over the baseline model ZeroR with accuracy of 0.526, 0.586, .562 respectively. Loss functions such as Rank Loss, One Error, Hamming Loss, and Zero One Loss are also low for BCC/JRIP model for all samples of dataset, making it the best candidate for better performance given the label dependencies.",
            "output": [
                "Multi-Labeled Classification of Demographic Attributes of Patients: a case study of diabetics patients"
            ]
        },
        {
            "id": "task1540-d5d3990554604442bf9e0d552a36f291",
            "input": "Constructing an accurate system model for formal model verification can be both resource demanding and time-consuming. To alleviate this shortcoming, algorithms have been proposed for automatically learning system models based on observed system behaviors. In this paper we extend the algorithm on learning probabilistic automata to reactive systems, where the observed system behavior is in the form of alternating sequences of inputs and outputs. We propose an algorithm for automatically learning a deterministic labeled Markov decision process model from the observed behavior of a reactive system. The proposed learning algorithm is adapted from algorithms for learning deterministic probabilistic finite automata, and extended to include both probabilistic and nondeterministic transitions. The algorithm is empirically analyzed and evaluated by learning system models of slot machines. The evaluation is performed by analyzing the probabilistic linear temporal logic properties of the system as well as by analyzing the schedulers, in particular the optimal schedulers, induced by the learned models.",
            "output": [
                "Learning Markov Decision Processes for Model Checking"
            ]
        },
        {
            "id": "task1540-d1a63fbdd01648e89358e7264a7d8026",
            "input": "Semi-supervised classification is an interesting idea where classification models are learned from both labeled and unlabeled data. It has several advantages over supervised classification in natural language processing domain. For instance, supervised classification exploits only labeled data that are expensive, often difficult to get, inadequate in quantity, and require human experts for annotation. On the other hand, unlabeled data are inexpensive and abundant. Despite the fact that many factors limit the wide-spread use of semi-supervised classification, it has become popular since its level of performance is empirically as good as supervised classification. This study explores the possibilities and achievements as well as complexity and limitations of semi-supervised classification for several natural langue processing tasks like parsing, biomedical information processing, text classification, and summarization.",
            "output": [
                "Semi-supervised Classification for Natural Language Processing"
            ]
        },
        {
            "id": "task1540-f319c601c7604e99aebdefb3577785f2",
            "input": "In chemometrics, data from infrared or near-infrared (NIR) spectroscopy are often used to identify a compound or to analyze the composition of a material. This involves the calibration of models that predict the concentration of material constituents from the measured NIR spectrum. An interesting aspect of multivariate calibration is to achieve a particular accuracy level with a minimum number of training samples, as this reduces the number of laboratory tests and thus the cost of model building. In these chemometric models, the input refers to a proper representation of the spectra and the output to the concentrations of the sample constituents. The search for a most informative new calibration sample thus has to be performed in the output space of the model, rather than in the input space as in conventional modeling problems. In this paper, we propose to solve the corresponding inversion problem by utilizing the disagreements of an ensemble of neural networks to represent the prediction error in the unexplored component space. The next calibration sample is then chosen at a composition where the individual models of the ensemble disagree most. The results obtained for a realistic chemometric calibration example show that the proposed active learning can achieve a given calibration accuracy with less training samples than random sampling.",
            "output": [
                "Neural Network-Based Active Learning in Multivariate Calibration"
            ]
        },
        {
            "id": "task1540-29c5a21f5649499b8c11aa5add78a136",
            "input": "Selectional preferences have long been claimed to be essential for coreference resolution. However, they are mainly modeled only implicitly by current coreference resolvers. We propose a dependencybased embedding model of selectional preferences which allows fine-grained compatibility judgments with high coverage. We show that the incorporation of our model improves coreference resolution performance on the CoNLL dataset, matching the state-of-the-art results of a more complex system. However, it comes with a cost that makes it debatable how worthwhile such improvements are.",
            "output": [
                "Revisiting Selectional Preferences for Coreference Resolution"
            ]
        },
        {
            "id": "task1540-0e0bd165550a4d2ba8bd0b35e5f5166a",
            "input": "Intrusion detection is so much popular since the last two decades where intrusion is attempted to break into or misuse the system. It is mainly of two types based on the intrusions, first is Misuse or signature based detection and the other is Anomaly detection. In this paper Machine learning based methods which are one of the types of Anomaly detection techniques is discussed.",
            "output": [
                "A Review of Machine Learning based Anomaly Detection Techniques"
            ]
        },
        {
            "id": "task1540-cd2971e64c074fa89a1a34c05e782b25",
            "input": "Measuring inconsistency is viewed as an important issue related to handling inconsistencies. Good measures are supposed to satisfy a set of rational properties. However, defining sound properties is sometimes problematic. In this paper, we emphasize one such property, named Decomposability, rarely discussed in the literature due to its modeling difficulties. To this end, we propose an independent decomposition which is more intuitive than existing proposals. To analyze inconsistency in a more fine-grained way, we introduce a graph representation of a knowledge base and various MUSdecompositions. One particular MUS-decomposition, named distributable MUS-decomposition leads to an interesting partition of inconsistencies in a knowledge base such that multiple experts can check inconsistencies in parallel, which is impossible under existing measures. Such particular MUSdecomposition results in an inconsistency measure that satisfies a number of desired properties. Moreover, we give an upper bound complexity of the measure that can be computed using 0/1 linear programming or Min Cost Satisfiability problems, and conduct preliminary experiments to show its feasibility.",
            "output": [
                "On the Measure of the Conflicts: A MUS-Decomposition Based Framework"
            ]
        },
        {
            "id": "task1540-9b43f0e947194bc1a5fc3fc39964f045",
            "input": "In this study we address the problem of training a neuralnetwork for language identification using both labeled and unlabeled speech samples in the form of i-vectors. We propose a neural network architecture that can also handle out-of-set languages. We utilize a modified version of the recently proposed Ladder Network semisupervised training procedure that optimizes the reconstruction costs of a stack of denoising autoencoders. We show that this approach can be successfully applied to the case where the training dataset is composed of both labeled and unlabeled acoustic data. The results show enhanced language identification on the NIST 2015 language identification dataset.",
            "output": [
                "A Semisupervised Approach for Language Identification based on Ladder Networks"
            ]
        },
        {
            "id": "task1540-75f7590ac1734547a947724dfb5744ea",
            "input": "The alternating direction method of multipliers (ADMM) is a versatile tool for solving a wide range of constrained optimization problems, with differentiable or non-differentiable objective functions. Unfortunately, its performance is highly sensitive to a penalty parameter, which makes ADMM often unreliable and hard to automate for a non-expert user. We tackle this weakness of ADMM by proposing a method to adaptively tune the penalty parameters to achieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm, inspired by the successful Barzilai-Borwein spectral method for gradient descent, yields fast convergence and relative insensitivity to the initial stepsize and problem scaling.",
            "output": [
                "Adaptive ADMM with Spectral Penalty Parameter Selection"
            ]
        },
        {
            "id": "task1540-9f67d1de3d5c46b1bf8b1f78fd2d0133",
            "input": "In this work we develop Curvature Propagation (CP), a general technique for efficiently computing unbiased approximations of the Hessian of any function that is computed using a computational graph. At the cost of roughly two gradient evaluations, CP can give a rank-1 approximation of the whole Hessian, and can be repeatedly applied to give increasingly precise unbiased estimates of any or all of the entries of the Hessian. Of particular interest is the diagonal of the Hessian, for which no general approach is known to exist that is both efficient and accurate. We show in experiments that CP turns out to work well in practice, giving very accurate estimates of the Hessian of neural networks, for example, with a relatively small amount of work. We also apply CP to Score Matching, where a diagonal of a Hessian plays an integral role in the Score Matching objective, and where it is usually computed exactly using inefficient algorithms which do not scale to larger and more complex models.",
            "output": [
                "Estimating the Hessian by Back-propagating Curvature"
            ]
        },
        {
            "id": "task1540-01d1b6fbbe47473ebbe269e3713f8c7c",
            "input": "The importance of a research article is routinely measured by counting how many times it has been cited. However, treating all citations with equal weight ignores the wide variety of functions that citations perform. We want to automatically identify the subset of references in a bibliography that have a central academic influence on the citing paper. For this purpose, we examine the effectiveness of a variety of features for determining the academic influence of a citation. By asking authors to identify the key references in their own work, we created a dataset in which citations were labeled according to their academic influence. Using automatic feature selection with supervised machine learning, we found a model for predicting academic influence that achieves good performance on this dataset using only four features. The best features, among those we evaluated, were features based on the number of times a reference is mentioned in the body of a citing paper. The performance of these features inspired us to design an influence-primed h-index (the hip-index). Unlike the conventional h-index, it weights citations by how many times a reference is mentioned. According to our experiments, the hip-index is a better indicator of researcher performance than the conventional h-index.",
            "output": [
                "Measuring academic influence: Not all citations are equal"
            ]
        },
        {
            "id": "task1540-16fd58e410be4388a74f586c606954c4",
            "input": "Large-scale knowledge bases have currently reached impressive sizes; however, these knowledge bases are still far from complete. In addition, most of the existing methods for knowledge base completion only consider the direct links between entities, ignoring the vital impact of the consistent semantics of relation paths. In this paper, we study the problem of how to better embed entities and relations of knowledge bases into different low-dimensional spaces by taking full advantage of the additional semantics of relation paths, and we propose a compositional learning model of relation path embedding (RPE). Specifically, with the corresponding relation and path projections, RPE can simultaneously embed each entity into two types of latent spaces. It is also proposed that type constraints could be extended from traditional relation-specific constraints to the new proposed path-specific constraints. The results of experiments show that the proposed model achieves significant and consistent improvements compared with the state-of-the-art algorithms.",
            "output": [
                "Compositional Learning of Relation Path Embedding for Knowledge Base Completion"
            ]
        },
        {
            "id": "task1540-d8bea45d25ef4328aed8eec02f1bf82b",
            "input": "Pre-trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for NLP tasks. However, in most cases, the recurrent network that operates on word-level representations to produce context sensitive representations is trained on relatively little labeled data. In this paper, we demonstrate a general semi-supervised approach for adding pretrained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks. We evaluate our model on two standard datasets for named entity recognition (NER) and chunking, and in both cases achieve state of the art results, surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers.",
            "output": [
                "Semi-supervised sequence tagging with bidirectional language models"
            ]
        },
        {
            "id": "task1540-958c4ee39e39427f99948b00ce6d5db8",
            "input": "Search engines are the most important tools for web data acquisition. Web pages are crawled and indexed by search Engines. Users typically locate useful web pages by querying a search engine. One of the challenges in search engines administration is spam pages which waste search engine resources. These pages by deception of search engine ranking algorithms try to be showed in the first page of results. There are many approaches to web spam pages detection such as measurement of HTML code style similarity, pages linguistic pattern analysis and machine learning algorithm on page content features. One of the famous algorithms has been used in machine learning approach is Support Vector Machine (SVM) classifier. Recently basic structure of SVM has been changed by new extensions to increase robustness and classification accuracy. In this paper we improved accuracy of web spam detection by using two nonlinear kernels into Twin SVM (TSVM) as an improved extension of SVM. The classifier ability to data separation has been increased by using two separated kernels for each class of data. Effectiveness of new proposed method has been experimented with two publicly used spam datasets called UK-2007 and UK-2006. Results show the effectiveness of proposed kernelized version of TSVM in web spam page detection.",
            "output": [
                "Web Spam Detection Using Multiple Kernels in Twin Support Vector Machine"
            ]
        },
        {
            "id": "task1540-c155e834f24e469d979d5ce5a00a6cbd",
            "input": "Transfer in reinforcement learning refers to the notion that generalization should occur not only within a task but also across tasks. Our focus is on transfer where the reward functions vary across tasks while the environment’s dynamics remain the same. The method we propose rests on two key ideas: “successor features,” a value function representation that decouples the dynamics of the environment from the rewards, and “generalized policy improvement,” a generalization of dynamic programming’s policy improvement step that considers a set of policies rather than a single one. Put together, the two ideas lead to an approach that integrates seamlessly within the reinforcement learning framework and allows transfer to take place between tasks without any restriction. The proposed method also provides performance guarantees for the transferred policy even before any learning has taken place. We derive two theorems that set our approach in firm theoretical ground and present experiments that show that it successfully promotes transfer in practice.",
            "output": [
                "Successor Features for Transfer in Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-1695dec2a13241639d931c5505dd44ac",
            "input": "We present a new method for estimating the expected return of a POMDP from experi­ ence. The estimator does not assume any knowledge of the POMDP, can estimate the returns for finite state controllers, allows ex­ perience to be gathered from arbitrary se­ quences of policies, and estimates the return for any new policy. We motivate the estima­ tor from function-approximation and impor­ tance sampling points-of-view and derive its bias and variance. Although the estimator is biased, it has low variance and the bias is of­ ten irrelevant when the estimator is used for pair-wise comparisons. We conclude by ex­ tending the estimator to policies with mem­ ory and compare its performance in a greedy search algorithm to the REINFORCE algo­ rithm showing an order of magnitude reduc­ tion in the number of trials required.",
            "output": [
                "Policy Improvement for POMDPs using Normalized Importance Sampling"
            ]
        },
        {
            "id": "task1540-52ebb1b74b7840cc8a3ed1a9cd15b2c1",
            "input": "The paper systematically studies the impact of a range of recent advances in CNN architectures and learning methods on the object categorization (ILSVRC) problem. The evalution tests the influence of the following choices of the architecture: non-linearity (ReLU, ELU, maxout, compatability with batch normalization), pooling variants (stochastic, max, average, mixed), network width, classifier design (convolutional, fully-connected, SPP), image pre-processing, and of learning parameters: learning rate, batch size, cleanliness of the data, etc. The performance gains of the proposed modifications are first tested individually and then in combination. The sum of individual gains is bigger than the observed improvement when all modifications are introduced, but the ”deficit” is small suggesting independence of their benefits. We show that the use of 128x128 pixel images is sufficient to make qualitative conclusions about optimal network structure that hold for the full size Caffe and VGG nets. The results are obtained an order of magnitude faster than with the standard 224 pixel images.",
            "output": [
                "Systematic evaluation of CNN advances on the ImageNet"
            ]
        },
        {
            "id": "task1540-973ac3de5ede4dc5b3f4e2865df48a46",
            "input": "Recurrent neural networks have achieved remarkable success at generating sequences with complex structures, thanks to advances that include richer embeddings of input and cures for vanishing gradients. Trained only on sequences from a known grammar, though, they can still struggle to learn rules and constraints of the grammar. Neural Attribute Machines (NAMs) are equipped with a logical machine that represents the underlying grammar, which is used to teach the constraints to the neural machine by (i) augmenting the input sequence, and (ii) optimizing a custom loss function. Unlike traditional RNNs, NAMs are exposed to the grammar, as well as samples from the language of the grammar. During generation, NAMs make significantly fewer violations of the constraints of the underlying grammar than RNNs trained only on samples from the language of the grammar.",
            "output": [
                "Neural Attribute Machines for Program Generation∗"
            ]
        },
        {
            "id": "task1540-2c88e6bd245248c88130e3c55447e75a",
            "input": "We propose the first multistage intervention framework that tackles fake news in social networks by combining reinforcement learning with a point process network activity model. The spread of fake news and mitigation events within the network is modeled by a multivariate Hawkes process with additional exogenous control terms. By choosing a feature representation of states, defining mitigation actions and constructing reward functions to measure the effectiveness of mitigation activities, we map the problem of fake news mitigation into the reinforcement learning framework. We develop a policy iteration method unique to the multivariate networked point process, with the goal of optimizing the actions for maximal total reward under budget constraints. Our method shows promising performance in real-time intervention experiments on a Twitter network to mitigate a surrogate fake news campaign, and outperforms alternatives on synthetic datasets.",
            "output": [
                "Fake News Mitigation via Point Process Based Intervention "
            ]
        },
        {
            "id": "task1540-38ea0b341c2d455687ad1a5b911aeaf7",
            "input": "Applications and systems are constantly faced with decisions to make, often using a policy to pick from a set of actions based on some contextual information. We create a service that uses machine learning to accomplish this goal. The service uses exploration, logging, and online learning to create a counterfactually sound system supporting a full data lifecycle. The system is general: it works for any discrete choices, with respect to any reward metric, and can work with many learning algorithms and feature representations. The service has a simple API, and was designed to be modular and reproducible to ease deployment and debugging, respectively. We demonstrate how these properties enable learning systems that are robust and safe. Our evaluation shows that the Decision Service makes decisions in real time and incorporates new data quickly into learned policies. A large-scale deployment for a personalized news website has been handling all traffic since Jan. 2016, resulting in a 25% relative lift in clicks. By making the Decision Service externally available, we hope to make optimal decision making available to all.",
            "output": [
                "A Multiworld Testing Decision Service"
            ]
        },
        {
            "id": "task1540-cd6c7dbfe6274662a6d96d3c92b68637",
            "input": "Precise geocoding and time normalization for text requires that location and time phrases be identified. Many state-of-the-art geoparsers and temporal parsers suffer from low recall. Categories commonly missed by parsers are: nouns used in a nonspatiotemporal sense, adjectival and adverbial phrases, prepositional phrases, and numerical phrases. We collected and annotated data set by querying commercial web searches API with such spatiotemporal expressions as were missed by state-of-theart parsers. Due to the high cost of sentence annotation, active learning was used to label training data, and a new strategy was designed to better select training examples to reduce labeling cost. For the learning algorithm, we applied an average perceptron trained Featurized Hidden Markov Model (FHMM). Five FHMM instances were used to create an ensemble, with the output phrase selected by voting. Our ensemble model was tested on a range of sequential labeling tasks, and has shown competitive performance. Our contributions include (1) an new dataset annotated with named entities and expanded spatiotemporal expressions; (2) a comparison of inference algorithms for ensemble models showing the superior accuracy of Belief Propagation over Viterbi Decoding; (3) a new example re-weighting method for active ensemble learning that “memorizes” the latest examples trained; (4) a spatiotemporal parser that jointly recognizes expanded spatiotemporal expressions as well as named entities.",
            "output": [
                "Recognizing Extended Spatiotemporal Expressions by Actively Trained Average Perceptron Ensembles"
            ]
        },
        {
            "id": "task1540-08f4c67a3c8844e486469815e5949dc1",
            "input": "In this paper we describe an extension of the Variable Neighbourhood Search (VNS) which integrates the basic VNS with other complementary approaches from machine learning, statistics and experimental algorithmic, in order to produce high-quality performance and to completely automate the resulting optimization strategy. The resulting intelligent VNS has been successfully applied to a couple of optimization problems where the solution space consists of the subsets of a finite reference set. These problems are the labelled spanning tree and forest problems that are formulated on an undirected labelled graph; a graph where each edge has a label in a finite set of labels L. The problems consist on selecting the subset of labels such that the subgraph generated by these labels has an optimal spanning tree or forest, respectively. These problems have several applications in the real-world, where one aims to ensure connectivity by means of homogeneous connections.",
            "output": [
                "An intelligent extension of Variable Neighbourhood Search for labelling graph problems"
            ]
        },
        {
            "id": "task1540-75d7b0e35fa744d98c33fa64d0acdb62",
            "input": "An RDF data shape is a description of the expected contents of an RDF document (aka graph) or dataset. A major part of this description is the set of constraints that the document or dataset is required to satisfy. W3C recently (2014) chartered the RDF Data Shapes Working Group to define SHACL, a standard RDF data shape language. We refer to the ability to name and reference shape language elements as recursion. This article provides a precise definition of the meaning of recursion as used in Resource Shape 2.0. The definition of recursion presented in this article is largely independent of language-specific details. We speculate that it also applies to ShEx and to all three of the current proposals for SHACL. In particular, recursion is not permitted in the SHACL-SPARQL proposal, but we conjecture that recursion could be added by using the definition proposed here as a top-level control structure.",
            "output": [
                "Recursion in RDF Data Shape Languages"
            ]
        },
        {
            "id": "task1540-391034527a2b405ba078771a51584571",
            "input": "Multicriteria decision analysis aims at supporting a person facing a decision problem involving conflicting criteria. We consider an additive utility model which provides robust conclusions based on preferences elicited from the decision maker. The recommendations based on these robust conclusions are even more convincing if they are complemented by explanations. We propose a general scheme, based on sequence of preference swaps, in which explanations can be computed. We show first that the length of explanations can be unbounded in the general case. However, in the case of binary reference scales, this length is bounded and we provide an algorithm to compute the corresponding explanation.",
            "output": [
                "Explaining robust additive utility models by sequences of preference swaps"
            ]
        },
        {
            "id": "task1540-e43d3178a1884f01bfd2bb2befc53206",
            "input": "We study a novel architecture and training procedure for locomotion tasks. A high-frequency, low-level “spinal” network with access to proprioceptive sensors learns sensorimotor primitives by training on simple tasks. This pre-trained module is fixed and connected to a low-frequency, high-level “cortical” network, with access to all sensors, which drives behavior by modulating the inputs to the spinal network. Where a monolithic end-to-end architecture fails completely, learning with a pre-trained spinal module succeeds at multiple high-level tasks, and enables the effective exploration required to learn from sparse rewards. We test our proposed architecture on three simulated bodies: a 16-dimensional swimming snake, a 20-dimensional quadruped, and a 54-dimensional humanoid (see attached video).",
            "output": [
                "Learning and Transfer of Modulated Locomotor Controllers"
            ]
        },
        {
            "id": "task1540-7ee6469fdb5f4829abec3e0a03262de5",
            "input": "Chemical-chemical interaction (CCI) plays a key role in predicting candidate drugs, toxicity, therapeutic eects, and biological functions. CCI was created from text mining, experiments, similarities, and databases; to date, no learning-based CCI prediction method exist. In chemical analyses, computational approaches are required. e recent remarkable growth and outstanding performance of deep learning have aracted considerable research aention. However, even in state-of-the-art drug analyses, deep learning continues to be used only as a classier. Nevertheless, its purpose includes not only simple classication, but also automated feature extraction. In this paper, we propose the rst end-to-end learning method for CCI, named DeepCCI. Hidden features are derived from a simplied molecular input line entry system (SMILES), which is a string notation representing the chemical structure, instead of learning from craed features. To discover hidden representations for the SMILES strings, we use convolutional neural networks (CNNs). To guarantee the commutative property for homogeneous interaction, we apply model sharing and hidden representation merging techniques. e performance of DeepCCI was compared with a plain deep classier and conventional machine learning methods. e proposed DeepCCI showed the best performance in all seven evaluation metrics used. In addition, the commutative property was experimentally validated. e automatically extracted features through end-to-end SMILES learning alleviates the signicant efforts required for manual feature engineering. It is expected to improve prediction performance, in drug analyses.",
            "output": [
                "DeepCCI: End-to-end Deep Learning for Chemical-Chemical Interaction Prediction"
            ]
        },
        {
            "id": "task1540-16e5a563d0314872b06ba4aacaa72463",
            "input": "Voice browser applications in Text-toSpeech (TTS) and Automatic Speech Recognition (ASR) systems crucially depend on a pronunciation lexicon. The present paper describes the model of pronunciation lexicon of Hindi developed to automatically generate the output forms of Hindi at two levels, the <phoneme> and the <PS> (PS, in short for Prosodic Structure). The latter level involves both syllable-division and stress placement. The paper describes the tool developed for generating the two-level outputs of lexica in Hindi.",
            "output": [
                "A Generative Model of a Pronunciation Lexicon for Hindi"
            ]
        },
        {
            "id": "task1540-e5dafef82fd446e0b4970acc4e2f2883",
            "input": "Existing methods for dealing with knowledge updates differ greatly depending on the underlying knowledge representation formalism. When Classical Logic is used, updates are typically performed by manipulating the knowledge base on the model-theoretic level. On the opposite side of the spectrum stand the semantics for updating Answer-Set Programs that need to rely on rule syntax. Yet, a unifying perspective that could embrace both these branches of research is of great importance as it enables a deeper understanding of all involved methods and principles and creates room for their cross-fertilisation, ripening and further development. Furthermore, from a more pragmatic viewpoint, such a unification is a necessary step in addressing updates of hybrid knowledge bases consisting of both a classical and a rule component. This paper bridges the seemingly irreconcilable approaches to updates. It introduces a novel monotonic characterisation of rules, dubbed RE-models, and shows it to be a more suitable semantic foundation for rule updates than SE-models. Then it proposes a generic scheme for specifying semantic rule update operators, based on the idea of viewing a program as the set of sets of RE-models of its rules; updates are performed by introducing additional interpretations – exceptions – to the sets of RE-models of rules in the original program. The introduced scheme is then used to define particular rule update operators that are closely related to both classical update principles and traditional approaches to rules updates, enjoying a range of plausible syntactic as well as semantic properties. In addition, these operators serve as a basis for a solution to the long-standing problem of state condensing for two of the foundational rule update semantics, showing how they can be equivalently defined as binary operators on some class of logic programs. Finally, the essence of these ideas is extracted to define an abstract framework for exception-based update operators, viewing a knowledge base as the set of sets of models of its elements. It is shown that the framework can capture a wide range of both modeland formula-based classical update operators, and thus serves as the first firm formal ground connecting classical and rule updates.",
            "output": [
                "Exception-Based Knowledge Updates"
            ]
        },
        {
            "id": "task1540-52cc970c1c51445a83d75de5d272b92c",
            "input": "This paper concerns the single machine total weighted tardiness scheduling with sequence-dependent setup times, usually referred as 1|sij | ∑ wjTj . In this NP-hard problem, each job has an associated processing time, due date and a weight. For each pair of jobs i and j, there may be a setup time before starting to process j in case this job is scheduled immediately after i. The objective is to determine a schedule that minimizes the total weighted tardiness, where the tardiness of a job is equal to its completion time minus its due date, in case the job is completely processed only after its due date, and is equal to zero otherwise. Due to its complexity, this problem is most commonly solved by heuristics. The aim of this work is to develop a simple yet effective limitation strategy that speeds up the local search procedure without a significant loss in the solution quality. Such strategy consists of a filtering mechanism that prevents unpromising moves to be evaluated. The proposed strategy has been embedded in a local search based metaheuristic from the literature and tested in classical benchmark instances. Computational experiments revealed that the limitation strategy enabled the metaheuristic to be extremely competitive when compared to other algorithms from the literature, since it allowed the use of a large number of neighborhood structures without a significant increase in the CPU time and, consequently, high quality solutions could be achieved in a matter of seconds. In addition, we analyzed the effectiveness of the proposed strategy in two other well-known metaheuristics. Further experiments were also carried out on benchmark instances of problem 1|sij | ∑ Tj .",
            "output": [
                "Efficient local search limitation strategy for single machine total weighted tardiness scheduling with sequence-dependent setup times"
            ]
        },
        {
            "id": "task1540-40f7c419a91b4642b46fe447d09dc14a",
            "input": "We develop a latent variable model and an efficient spectral algorithm motivated<lb>by the recent emergence of very large data sets of chromatin marks from multiple<lb>human cell types. A natural model for chromatin data in one cell type is a Hidden<lb>Markov Model (HMM); we model the relationship between multiple cell types by<lb>connecting their hidden states by a fixed tree of known structure.<lb>The main challenge with learning parameters of such models is that iterative meth-<lb>ods such as EM are very slow, while naive spectral methods result in time and<lb>space complexity exponential in the number of cell types. We exploit properties<lb>of the tree structure of the hidden states to provide spectral algorithms that are<lb>more computationally efficient for current biological datasets. We provide sample<lb>complexity bounds for our algorithm and evaluate it experimentally on biological<lb>data from nine human cell types. Finally, we show that beyond our specific model,<lb>some of our algorithmic ideas can be applied to other graphical models.",
            "output": [
                "Spectral Learning of Large Structured HMMs for Comparative Epigenomics"
            ]
        },
        {
            "id": "task1540-caa4735b569247f8ae038163cc093638",
            "input": "Building general-purpose conversation agents is a very challenging task, but necessary on the road toward intelligent agents that can interact with humans in natural language. Neural conversation models – purely data-driven systems trained end-to-end on dialogue corpora – have shown great promise recently, yet they often produce short and generic responses. This work presents new training and decoding methods that improve the quality, coherence, and diversity of long responses generated using sequence-to-sequence models. Our approach adds selfattention to the decoder to maintain coherence in longer responses, and we propose a practical approach, called the glimpse-model, for scaling to large datasets. We introduce a stochastic beam-search algorithm with segment-by-segment reranking which lets us inject diversity earlier in the generation process. We trained on a combined data set of over 2.3B conversation messages mined from the web. In human evaluation studies, our method produces longer responses overall, with a higher proportion rated as acceptable and excellent as length increases, compared to baseline sequence-to-sequence models with explicit length-promotion. A backoff strategy produces better responses overall, in the full spectrum of lengths.",
            "output": [
                "NEURAL CONVERSATION MODELS"
            ]
        },
        {
            "id": "task1540-a2425dea610744e5938d34368692518f",
            "input": "Resolving abstract anaphora is an important, but difficult task for text understanding. Yet, with recent advances in representation learning this task becomes a more tangible aim. A central property of abstract anaphora is that it establishes a relation between the anaphor embedded in the anaphoric sentence and its (typically non-nominal) antecedent. We propose a mention-ranking model that learns how abstract anaphors relate to their antecedents with an LSTM-Siamese Net. We overcome the lack of training data by generating artificial anaphoric sentence– antecedent pairs. Our model outperforms state-of-the-art results on shell noun resolution. We also report first benchmark results on an abstract anaphora subset of the ARRAU corpus. This corpus presents a greater challenge due to a mixture of nominal and pronominal anaphors and a greater range of confounders. We found model variants that outperform the baselines for nominal anaphors, without training on individual anaphor data, but still lag behind for pronominal anaphors. Our model selects syntactically plausible candidates and – if disregarding syntax – discriminates candidates using deeper features.",
            "output": [
                "A Mention-Ranking Model for Abstract Anaphora Resolution"
            ]
        },
        {
            "id": "task1540-23c7e71ccf4f48de90c838e226d73d79",
            "input": "Feature selection refers to the problem of selecting relevant features which produce the most predictive outcome. In particular, feature selection task is involved in datasets containing huge number of features. Rough set theory has been one of the most successful methods used for feature selection. However, this method is still not able to find optimal subsets. This paper proposes a new feature selection method based on Rough set theory hybrid with Bee Colony Optimization (BCO) in an attempt to combat this. This proposed work is applied in the medical domain to find the minimal reducts and experimentally compared with the Quick Reduct, Entropy Based Reduct, and other hybrid Rough Set methods such as Genetic Algorithm (GA), Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO).",
            "output": [
                "A Novel Rough Set Reduct Algorithm for Medical Domain Based on Bee Colony Optimization"
            ]
        },
        {
            "id": "task1540-22e6e93e902e48a49dd88fc6482309ba",
            "input": "Clustering is one of the widely used data mining techniques for medical diagnosis. Clustering can be considered as the most important unsupervised learning technique. Most of the clustering methods group data based on distance and few methods cluster data based on similarity. The clustering algorithms classify gene expression data into clusters and the functionally related genes are grouped together in an efficient manner. The groupings are constructed such that the degree of relationship is strong among members of the same cluster and weak among members of different clusters. In this work, we focus on a similarity relationship among genes with similar expression patterns so that a consequential and simple analytical decision can be made from the proposed Fuzzy Soft Rough K-Means algorithm. The algorithm is developed based on Fuzzy Soft sets and Rough sets. Comparative analysis of the proposed work is made with bench mark algorithms like K-Means and Rough K-Means and efficiency of the proposed algorithm is illustrated in this work by using various cluster validity measures such as DB index and Xie-Beni index.",
            "output": [
                "FUZZY SOFT ROUGH K-MEANS CLUSTERING APPROACH FOR GENE EXPRESSION DATA"
            ]
        },
        {
            "id": "task1540-69f724d7f8fd4e37b86f0150870fd1ee",
            "input": "GPU activity prediction is an important and complex problem. This is due to the high level of contention among thousands of parallel threads. This problem was mostly addressed using heuristics. We propose a representation learning approach to address this problem. We model any performance metric as a temporal function of the executed instructions with the intuition that the flow of instructions can be identified as distinct activities of the code. Our experiments show high accuracy and non-trivial predictive power of representation learning on a benchmark.",
            "output": [
                "GPU Activity Prediction using Representation Learning"
            ]
        },
        {
            "id": "task1540-4ea591ec125d47d191b8625e34cb181f",
            "input": "The areas of machine learning and communication technology are converging. Today’s communications systems generate a huge amount of traffic data, which can help to significantly enhance the design and management of networks and communication components when combined with advanced machine learning methods. Furthermore, recently developed end-to-end training procedures offer new ways to jointly optimize the components of a communication system. Also in many emerging application fields of communication technology, e.g., smart cities or internet of things, machine learning methods are of central importance. This paper gives an overview over the use of machine learning in different areas of communications and discusses two exemplar applications in wireless networking. Furthermore, it identifies promising future research topics and discusses their potential impact.",
            "output": [
                "THE CONVERGENCE OF MACHINE LEARNING AND COMMUNICATIONS"
            ]
        },
        {
            "id": "task1540-b73d6fd8d6704fde8bba1945109ea93e",
            "input": "The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, and on many tasks even beats supervised models, highlighting the robustness of the produced sentence embeddings.",
            "output": [
                "Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features"
            ]
        },
        {
            "id": "task1540-352b1623bfcc434cbb81419e71ffac51",
            "input": "The language that we produce reflects our personality, and various personal and demographic characteristics can be detected in natural language texts. We focus on one particular personal trait of the author, gender, and study how it is manifested in original texts and in translations. We show that author’s gender has a powerful, clear signal in originals texts, but this signal is obfuscated in human and machine translation. We then propose simple domainadaptation techniques that help retain the original gender traits in the translation, without harming the quality of the translation, thereby creating more personalized machine translation systems.",
            "output": [
                "Personalized Machine Translation: Preserving Original Author Traits"
            ]
        },
        {
            "id": "task1540-357d5fa4a54747d19276ce803af44680",
            "input": "Humans develop a common sense of style compatibility between items based on their attributes. We seek to automatically answer questions like “Does this shirt go well with that pair of jeans?” In order to answer these kinds of questions, we attempt to model human sense of style compatibility in this paper. The basic assumption of our approach is that most of the important attributes for a product in an online store are included in its title description. Therefore it is feasible to learn style compatibility from these descriptions. We design a Siamese Convolutional Neural Network architecture and feed it with title pairs of items, which are either compatible or incompatible. Those pairs will be mapped from the original space of symbolic words into some embedded style space. Our approach takes only words as the input with few preprocessing and there is no laborious and expensive feature engineering.",
            "output": [
                "Deep Style Match for Complementary Recommendation"
            ]
        },
        {
            "id": "task1540-467cfa3910c64dd8b73f276806360ac7",
            "input": "While the general analysis of named entities has received substantial research attention, the analysis of relations over named entities has not. In fact, a review of the literature on unstructured as well as structured data revealed a deficiency in research on the abstract conceptualization required to organize relations. We believe that such an abstract conceptualization can benefit various communities and applications such as natural language processing, information extraction, machine learning and ontology engineering. In this paper, we present CEVO (i.e., a Comprehensive EVent Ontology) built on Levin’s conceptual hierarchy of English verbs that categorizes verbs with the shared meaning and syntactic behavior. We present the fundamental concepts and requirements for this ontology. Furthermore, we present three use cases for demonstrating the benefits of this ontology on annotation tasks: 1) annotating relations in plain text, 2) annotating ontological properties and 3) linking textual relations to ontological properties.",
            "output": [
                "CEVO: Comprehensive EVent Ontology Enhancing Cognitive Annotation"
            ]
        },
        {
            "id": "task1540-600f7163fed440d0a1f50cb657cc7b51",
            "input": "Alcohol abuse may lead to unsociable behavior such as crime, drunk driving, or privacy leaks. We introduce automatic drunk-texting prediction as the task of identifying whether a text was written when under the influence of alcohol. We experiment with tweets labeled using hashtags as distant supervision. Our classifiers use a set of N-gram and stylistic features to detect drunk tweets. Our observations present the first quantitative evidence that text contains signals that can be exploited to detect drunk-texting.",
            "output": [
                "A Computational Approach to Automatic Prediction of Drunk-Texting"
            ]
        },
        {
            "id": "task1540-6362f5785df040d7b4b83775d85170d8",
            "input": "This work studies the representational mapping across multimodal data such that given a piece of the raw data in one modality the corresponding semantic description in terms of the raw data in another modality is immediately obtained. Such a representational mapping can be found in a wide spectrum of real-world applications including image/video retrieval, object recognition, action/behavior recognition, and event understanding and prediction. To that end, we introduce a simplified training objective for learning multimodal embeddings using the skip-gram architecture by introducing convolutional “pseudowords:” embeddings composed of the additive combination of distributed word representations and image features from convolutional neural networks projected into the multimodal space. We present extensive results of the representational properties of these embeddings on various word similarity benchmarks to show the promise of this approach.",
            "output": [
                "MULTIMODAL SKIP-GRAM USING CONVOLUTIONAL PSEUDOWORDS"
            ]
        },
        {
            "id": "task1540-c1f023bfa6184e1780622c62b08ce29c",
            "input": "The thyroid, an endocrine gland that secretes hormones in the blood, circulates its products to all tissues of the body, where they control vital functions in every cell. Normal levels of thyroid hormone help the brain, heart, intestines, muscles and reproductive system function normally. Thyroid hormones control the metabolism of the body. Abnormalities of thyroid function are usually related to production of too little thyroid hormone (hypothyroidism) or production of too much thyroid hormone (hyperthyroidism). Therefore, the correct diagnosis of these diseases is very important topic. In this study, Linguistic Hedges NeuralFuzzy Classifier with Selected Features (LHNFCSF) is presented for diagnosis of thyroid diseases. The performance evaluation of this system is estimated by using classification accuracy and k-fold cross-validation. The results indicated that the classification accuracy without feature selection was 98.6047% and 97.6744% during training and testing phases, respectively with RMSE of 0.02335. After applying feature selection algorithm, LHNFCSF achieved 100% for all cluster sizes during training phase. However, in the testing phase LHNFCSF achieved 88.3721% using one cluster for each class, 90.6977% using two clusters, 91.8605% using three clusters and 97.6744% using four clusters for each class and 12 fuzzy rules. The obtained classification accuracy was very promising with regard to the other classification applications in literature for this problem.",
            "output": [
                "Expert System Based On Neural-Fuzzy Rules for Thyroid Diseases Diagnosis"
            ]
        },
        {
            "id": "task1540-5ded0e21876041379c6eecb97c7950b8",
            "input": "There are already quite a few tools for solving the Satisfiability Modulo Theories (SMT) problems. In this paper, we present VolCE, a tool for counting the solutions of SMT constraints, or in other words, for computing the volume of the solution space. Its input is essentially a set of Boolean combinations of linear constraints, where the numeric variables are either all integers or all reals, and each variable is bounded. The tool extends SMT solving with integer solution counting and volume computation/estimation for convex polytopes. Effective heuristics are adopted, which enable the tool to deal with high-dimensional problem instances efficiently and accurately.",
            "output": [
                "A Tool for Computing and Estimating the Volume of the Solution Space of SMT(LA) Constraints"
            ]
        },
        {
            "id": "task1540-a71ae4a63ac64382bcd207083a88d76c",
            "input": "Visual representation is crucial for a visual tracking method’s performances. Conventionally, visual representations adopted in visual tracking rely on hand-crafted computer vision descriptors. These descriptors were developed generically without considering tracking-specific information. In this paper, we propose to learn complex-valued invariant representations from tracked sequential image patches, via strong temporal slowness constraint and stacked convolutional autoencoders. The deep slow local representations are learned offline on unlabeled data and transferred to the observational model of our proposed tracker. The proposed observational model retains old training samples to alleviate drift, and collect negative samples which are coherent with target’s motion pattern for better discriminative tracking. With the learned representation and online training samples, a logistic regression classifier is adopted to distinguish target from background, and retrained online to adapt to appearance changes. Subsequently, the observational model is integrated into a particle filter framework to peform visual tracking. Experimental results on various challenging benchmark sequences demonstrate that the proposed tracker performs favourably against several state-of-the-art trackers.",
            "output": [
                "Self-taught learning of a deep invariant representation for visual tracking via temporal slowness principle"
            ]
        },
        {
            "id": "task1540-d56bfa53bb314d3ea8442c6ee33dd9c0",
            "input": "*Correspondence: aljadda@uga.edu 1Department of Computer Science, University of Georgia, Athens,GA, USA Full list of author information is available at the end of the article †Equal contributor Abstract Probabilistic Graphical Models (PGM) are very useful in the fields of machine learning and data mining. The crucial limitation of those models,however, is the scalability. The Bayesian Network, which is one of the most common PGMs used in machine learning and data mining, demonstrates this limitation when the training data consists of random variables, each of them has a large set of possible values. In the big data era, one would expect new extensions to the existing PGMs to handle the massive amount of data produced these days by computers, sensors and other electronic devices. With hierarchical data data that is arranged in a treelike structure with several levels one would expect to see hundreds of thousands or millions of values distributed over even just a small number of levels. When modeling this kind of hierarchical data across large data sets, Bayesian Networks become infeasible for representing the probability distributions. In this paper we introduce an extension to Bayesian Networks to handle massive sets of hierarchical data in a reasonable amount of time and space. The proposed model achieves perfect precision of 1.0 and high recall of 0.93 when it is used as multi-label classifier for the annotation of mass spectrometry data. On another data set of 1.5 billion search logs provided by CareerBuilder.com the model was able to predict latent semantic relationships between search keywords with accuracy up to 0.80.",
            "output": [
                "Mining Massive Hierarchical Data Using a Scalable Probabilistic Graphical Model"
            ]
        },
        {
            "id": "task1540-8d78163321a748339e4e0a82be310140",
            "input": "Observable operator models (OOMs) and related models are one of the most important and powerful tools for modeling and analyzing stochastic systems. They can exactly describe dynamics of finite-rank systems, and be efficiently learned from data by moment based algorithms. Almost all OOM learning algorithms are developed based on the assumption of equilibrium data which is very difficult to guarantee in real life, especially for complex processes with large time scales. In this paper, we derive a nonequilibrium learning algorithm for OOMs, which dismisses this assumption and can effectively extract the equilibrium dynamics of a system from nonequilibrium observation data. In addition, we propose binless OOMs for the application of nonequilibrium learning to continuous-valued systems. In comparison with the other OOMs with continuous observations, binless OOMs can achieve consistent estimation from nonequilibrium data with only linear computational complexity.",
            "output": [
                "Spectral learning of dynamic systems from nonequilibrium data∗"
            ]
        },
        {
            "id": "task1540-b9ade4ba1b924c14824c5fdc657f9fa6",
            "input": "The ability to mimic human notions of semantic distance has widespread applications. Some measures rely only on raw text (distributional measures) and some rely on knowledge sources such as WordNet. Although extensive studies have been performed to compare WordNet-based measures with human judgment, the use of distributional measures as proxies to estimate semantic distance has received little attention. Even though they have traditionally performed poorly when compared to WordNet-based measures, they lay claim to certain uniquely attractive features, such as their applicability in resource-poor languages and their ability to mimic both semantic similarity and semantic relatedness. Therefore, this paper presents a detailed study of distributional measures. Particular attention is paid to flesh out the strengths and limitations of both WordNet-based and distributional measures, and how distributional measures of distance can be brought more in line with human notions of semantic distance. We conclude with a brief discussion of recent work on hybrid measures.",
            "output": [
                "Distributional Measures of Semantic Distance: A Survey"
            ]
        },
        {
            "id": "task1540-846a6cc4db7a411f86a34d0b0489694a",
            "input": "Acoustic models using probabilistic linear discriminant analysis (PLDA) capture the correlations within feature vectors using subspaces which do not vastly expand the model. This allows high dimensional and correlated feature spaces to be used, without requiring the estimation of multiple high dimension covariance matrices. In this letter we extend the recently presented PLDA mixture model for speech recognition through a tied PLDA approach, which is better able to control the model size to avoid overfitting. We carried out experiments uisng the Switchboard corpus, with both mel frequency cepstral coefficient features and bottleneck feature derived from a deep neural network. Reductions in word error rate were obtained by using tied PLDA, compared with the PLDA mixture model, subspace Gaussian mixture models, and deep neural networks.",
            "output": [
                "Tied Probabilistic Linear Discriminant Analysis for Speech Recognition"
            ]
        },
        {
            "id": "task1540-3fb6f13f1a6540408e52b2d0e57920ec",
            "input": "We describe methods for managing the com­ plexity of information displayed to people responsible for making high-stakes, time­ critical decisions. The techniques provide tools for real-time control of the configura­ tion and quantity of information displayed to a user, and a methodology for designing flexible human-computer interfaces for mon­ itoring applications. After defining a proto­ typical set of display decision problems, we introduce the expected value of revealed in­ formation (EVRI) and the related measure of expected value of displayed information (EVDI) . We describe how these measures can be used to enhance computer displays used for monitoring complex systems. We moti­ vate the presentation by discussing our ef­ forts to employ decision-theoretic control of displays for a time-critical monitoring appli­ cation at the NASA Mission Control Center in Houston.",
            "output": [
                "Display of Information for Time-Critical Decision Making"
            ]
        },
        {
            "id": "task1540-c38ee37739044869a580db6d801661d0",
            "input": "Machine learning is increasingly used in security-critical applications, such as autonomous driving, face recognition and malware detection. Most learning methods, however, have not been designed with security in mind and thus are vulnerable to different types of attacks. This problem has motivated the research field of adversarial machine learning that is concerned with attacking and defending learning methods. Concurrently, a different line of research has tackled a very similar problem: In digital watermarking information are embedded in a signal in the presence of an adversary. As a consequence, this research field has also extensively studied techniques for attacking and defending watermarking methods. The two research communities have worked in parallel so far, unnoticeably developing similar attack and defense strategies. This paper is a first effort to bring these communities together. To this end, we present a unified notation of black-box attacks against machine learning and watermarking that reveals the similarity of both settings. To demonstrate the efficacy of this unified view, we apply concepts from watermarking to machine learning and vice versa. We show that countermeasures from watermarking can mitigate recent model-extraction attacks and, similarly, that techniques for hardening machine learning can fend off oracle attacks against watermarks. Our work provides a conceptual link between two research fields and thereby opens novel directions for improving the security of both, machine learning and digital watermarking.",
            "output": [
                "Fraternal Twins: Unifying Attacks on Machine Learning and Digital Watermarking"
            ]
        },
        {
            "id": "task1540-0b2d0d49abfb44f9ab1619c6707966d9",
            "input": "The use of microblogging platforms such as Twitter during crises has become widespread. More importantly, information disseminated by affected people contains useful information like reports of missing and found people, requests for urgent needs etc. For rapid crisis response, humanitarian organizations look for situational awareness information to understand and assess the severity of the crisis. In this paper, we present a novel framework (i) to generate abstractive summaries useful for situational awareness, and (ii) to capture sub-topics and present a short informative summary for each of these topics. A summary is generated using a two stage framework that first extracts a set of important tweets from the whole set of information through an Integer-linear programming (ILP) based optimization technique and then follows a word graph and concept event based abstractive summarization technique to produce the final summary. High accuracies obtained for all the tasks show the effectiveness of the proposed framework.",
            "output": [
                "Summarizing Situational and Topical Information During Crises"
            ]
        },
        {
            "id": "task1540-be9792bad6784d6ea82a5c9295e730de",
            "input": "Deep learning has become a ubiquitous technology to improve machine intelligence. However, most of the existing deep models are structurally very complex, making them difficult to be deployed on the mobile platforms with limited computational power. In this paper, we propose a novel network compression method called dynamic network surgery, which can remarkably reduce the network complexity by making on-the-fly connection pruning. Unlike the previous methods which accomplish this task in a greedy way, we properly incorporate connection splicing into the whole process to avoid incorrect pruning and make it as a continual network maintenance. The effectiveness of our method is proved with experiments. Without any accuracy loss, our method can efficiently compress the number of parameters in LeNet-5 and AlexNet by a factor of 108× and 17.7× respectively, proving that it outperforms the recent pruning method by considerable margins. The code will be made publicly available.",
            "output": [
                "Dynamic Network Surgery for Efficient DNNs"
            ]
        },
        {
            "id": "task1540-c85552efbcae4a999240a9e16afc648f",
            "input": "Neuroimage analysis usually involves learning thousands or even millions of variables using only a limited number of samples. In this regard, sparse models, e.g. the lasso, are applied to select the optimal features and achieve high diagnosis accuracy. The lasso, however, usually results in independent unstable features. Stability, a manifest of reproducibility of statistical results subject to reasonable perturbations to data and the model (Yu 2013), is an important focus in statistics, especially in the analysis of high dimensional data. In this paper, we explore a nonnegative generalized fused lasso model for stable feature selection in the diagnosis of Alzheimer’s disease. In addition to sparsity, our model incorporates two important pathological priors: the spatial cohesion of lesion voxels and the positive correlation between the features and the disease labels. To optimize the model, we propose an efficient algorithm by proving a novel link between total variation and fast network flow algorithms via conic duality. Experiments show that the proposed nonnegative model performs much better in exploring the intrinsic structure of data via selecting stable features compared with other state-of-the-arts. Introduction Neuroimage analysis is challenging due to its high feature dimensionality and data scarcity. Sparse models such as the lasso (Tibshirani 1996) have gained great reputation in statistics and machine learning, and they have been applied to the analysis of such high dimensional data by exploiting the sparsity property in the absence of abundant data. As a major result, automatic selection of relevant variables/features by such sparse formulation achieves promising performance. For example, in (Liu, Zhang, and Shen 2012), the lasso model was applied to the diagnosis of Alzheimer’s disease (AD) and showed better performance than the support vector machine (SVM), which is one of the state-of-the-arts in brain image classification. However, in statistics, it is known that the lasso does not always provide interpretable results because of its instability (Yu 2013). “Stability” here means the reproducibility of statistical results subject to reasonable perturbations to data and Copyright c © 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. the model. (These perturbations include the often used Jacknife, bootstrap and cross-validation.) This unstable behavior of the lasso model is critical in high dimensional data analysis. The resulting irreproducibility of the feature selection are especially undesirable in neuroimage analysis/diagnosis. However, unlike the problems such as registration and classification, the stability issue of feature selection is much less studied in this field. In this paper we propose a model to induce more stable feature selection from high dimensional brain structural Magnetic Resonance Imaging (sMRI) images. Besides sparsity, the proposed model harnesses two important additional pathological priors in brain sMRI: (i) the spatial cohesion of lesion voxels (via inducing fusion terms) and (ii) the positive correlation between the features and the disease labels. The correlation prior is based on the observation that in many brain image analysis problems (such as AD, frontotemporal dementia, corticobasal degeneration, etc), there exist strong correlations between the features and the labels. For example, gray matter of AD is degenerated/atrophied. Therefore, the gray matter values (indicating the volume) are positively correlated with the cognitive scores or disease labels {-1,1}. That is, the less gray matter, the lower the cognitive score. Accordingly, we propose nonnegative constraints on the variables to enforce the prior and name the model as “non-negative Generalized Fused Lasso” (nGFL). It extends the popular generalized fused lasso and enables it to explore the intrinsic structure of data via selecting stable features. To measure feature stability, we introduce the “Estimation Stability” recently proposed in (Yu 2013) and the (multi-set) Dice coefficient (Dice 1945). Experiments demonstrate that compared with existing models, our model selects much more stable (and pathological-prior consistent) voxels. It is worth mentioning that the non-negativeness per se is a very important prior of many practical problems, e.g. (Lee and Seung 1999). Although nGFL is proposed to solve the diagnosis of AD in this work, the model can be applied to more general problems. Incorporating these priors makes the problem novel w.r.t the lasso or generalized fused lasso from an optimization standpoint. Although off-the-shelf convex solvers such as CVX (Grant and Boyd 2013) can be applied to solve the optimization, it hardly scales to high-dimensional problems in feasible time. In this regard, we propose an efficient algoar X iv :1 50 3. 07 50 8v 1 [ cs .L G ] 2 5 M ar 2 01 5 rithm that solves the nGFL problem exactly. We generalize the proximal gradient methods (such as FISTA) (Beck and Teboulle 2009) to solve our constrained optimization and prove its convergence. We then show that by using an element-wise post-processing, the resulting proximal operator can be reduced to the total variation (TV) problem. It is known that TV can be solved by parametric flow algorithms (Chambolle and Darbon 2009; Xin et al. 2014). In the present study, we provide a novel equivalence via conic duality, which gives us a minimum quadratic cost flow formulation (Hochbaum and Hong 1995). Fast flow algorithms (including parametric flow) are then easily applied. In practice, our algorithm runs hundreds of times faster than CVX at the same precision and can scale to high-dimensional problems. Related work. In addition to sparsity, people leverage underlying data structures and introduce stronger priors such as the structured sparsity (Jacob, Obozinski, and Vert 2009) to increase model stability. However, for voxel-based sMRI data analysis, handcrafted grouping of the voxels or sub-structures may not coincide with various pathological topology priors. Consequently, group lasso (with overlap) (Jacob, Obozinski, and Vert 2009; Jenatton et al. 2012; Rao et al. 2013) is not an ideal model to the problem. In contrast, the graph-based structured sparse models adapt better to such a situation. The most popular one is referred here as LapL1, which adopts l2 norm regularization of neighborhood variable difference (e.g. (Ng and Abugharbieh 2011; Grosenick et al. 2013)). However, as we will show in the experiments, these models select many more features than necessary. Very recently, generalized fused lasso or total variation has been successful applied to brain image analysis problems inducing the l1 difference (Gramfort, Thirion, and Varoquaux 2013; Xin et al. 2014). In the experiments, we show that by including an extra nonnegative constraint, the features selected by our model is much more stable than that of such unconstrained models. A very recent work (Avants et al. 2014) also explored this positive correlation (partially supporting our assumption), but the problem formulation was quite different: neither structural assumption was considered, nor the stability of feature selection was discussed. From the optimization standpoint, the applied framework is similar to that of (Xin et al. 2014) but two key differences exist: (1) the FISTA and soft-thresholding process applied in (Xin et al. 2014) do not generalize to constrained optimization problems, we show important modifications and provide theoretical proof; (2) we propose a novel understanding of TV’s relation with flow problems via conic duality and prove that the minimum norm point problem of (Xin et al. 2014) is a special case of our framework. The Proposed Method Nonnegative Generalized Fused Lasso (n2GFL) Let {(xi, yi)}i=1 be a set of samples, where xi ∈ R and yi ∈ R are features and labels, respectively. Also, we denote Although different names are given in e.g. (Ng and Abugharbieh 2011; Grosenick et al. 2013), they are in fact fundamentally applying the graph Laplacian smoothing. by X ∈ Rd×N and y ∈ R the concatenations of xi and yi. Then, we consider the formulation min β∈Rd l(β;X,y) + λ1 d ∑",
            "output": [
                "Stable Feature Selection from Brain sMRI"
            ]
        },
        {
            "id": "task1540-8bfd7043b4c448c7bf7e2df3abb5882d",
            "input": "Local Process Model (LPM) discovery is focused on the mining of a set of process models where each model describes the behavior represented in the event log only partially, i.e. subsets of possible events are taken into account to create socalled local process models. Often such smaller models provide valuable insights into the behavior of the process, especially when no adequate and comprehensible single overall process model exists that is able to describe the traces of the process from start to end. The practical application of LPM discovery is however hindered by computational issues in the case of logs with many activities (problems may already occur when there are more than 17 unique activities). In this paper, we explore three heuristics to discover subsets of activities that lead to useful log projections with the goal of speeding up LPM discovery considerably while still finding high-quality LPMs. We found that a Markov clustering approach to create projection sets results in the largest improvement of execution time, with discovered LPMs still being better than with the use of randomly generated activity sets of the same size. Another heuristic, based on log entropy, yields a more moderate speedup, but enables the discovery of higher quality LPMs. The third heuristic, based on the relative information gain, shows unstable performance: for some data sets the speedup and LPM quality are higher than with the log entropy based method, while for other data sets there is no speedup at all.",
            "output": [
                "Heuristic Approaches for Generating Local Process Models through Log Projections"
            ]
        },
        {
            "id": "task1540-7919cb3648d2442cb7fe29d816cc0e86",
            "input": "A task of clustering data given on the ordinal scale under conditions of overlapping clusters has been considered. It’s proposed to use an approach based on membership and likelihood functions sharing. A number of performed experiments proved effectiveness of the proposed method. The proposed method is characterized by robustness to outliers due to a way of ordering values while constructing membership functions.",
            "output": [
                "Fuzzy Clustering Data Given on the Ordinal Scale Based on Membership and Likelihood Functions Sharing"
            ]
        },
        {
            "id": "task1540-48fbe36795714a40aa4dda4e769ef1df",
            "input": "In this paper, we describe our autonomous bidding agent, RoxyBot, who emerged victorious in the travel division of the 2006 Trading Agent Competition in a photo finish. At a high level, the design of many successful trading agents can be summarized as follows: (i) price prediction: build a model of market prices; and (ii) optimization: solve for an approximately optimal set of bids, given this model. To predict, RoxyBot builds a stochastic model of market prices by simulating simultaneous ascending auctions. To optimize, RoxyBot relies on the sample average approximation method, a stochastic optimization technique.",
            "output": [
                "RoxyBot-06: Stochastic Prediction and Optimization in TAC Travel"
            ]
        },
        {
            "id": "task1540-2f857090a85a42cd97fb7b60ba9731ad",
            "input": "Person knowledge extraction is the foundation of the Tibetan knowledge graph construction, which provides support for Tibetan question answering system, information retrieval, information extraction and other researches, and promotes national unity and social stability. This paper proposes a SVM and template based approach to Tibetan person knowledge extraction. Through constructing the training corpus, we build the templates based the shallow parsing analysis of Tibetan syntactic, semantic features and verbs. Using the training corpus, we design a hierarchical SVM classifier to realize the entity knowledge extraction. Finally, experimental results prove the method has greater improvement in Tibetan person knowledge extraction.",
            "output": [
                "Method of Tibetan Person Knowledge Extraction"
            ]
        },
        {
            "id": "task1540-271e942f7b4d46249bb3082a1c73f574",
            "input": "There is an increasing need for automated support for humans monitoring the activity of distributed teams of cooperating agents, both human and machine. We characterize the domainindependent challenges posed by this problem, and describe how properties of domains influence the challenges and their solutions. We will concentrate on dynamic, data-rich domains where humans are ultimately responsible for team behavior. Thus, the automated aid should interactively support effective and timely decision making by the human. We present a domain-independent categorization of the types of alerts a plan-based monitoring system might issue to a user, where each type generally requires different monitoring techniques. We describe a monitoring framework for integrating many domain-specific and task-specific monitoring techniques and then using the concept of value of an alert to avoid operator overload. We use this framework to describe an execution monitoring approach we have used to implement Execution Assistants (EAs) in two different dynamic, data-rich, real-world domains to assist a human in monitoring team behavior. One domain (Army small unit operations) has hundreds of mobile, geographically distributed agents, a combination of humans, robots, and vehicles. The other domain (teams of unmanned ground and air vehicles) has a handful of cooperating robots. Both domains involve unpredictable adversaries in the vicinity. Our approach customizes monitoring behavior for each specific task, plan, and situation, as well as for user preferences. Our EAs alert the human controller when reported events threaten plan execution or physically threaten team members. Alerts were generated in a timely manner without inundating the user with too many alerts (less than 10% of alerts are unwanted, as judged by domain experts).",
            "output": [
                "Interactive Execution Monitoring of Agent Teams"
            ]
        },
        {
            "id": "task1540-395babccf5164caaa1f9bcbfb5f1090d",
            "input": "We consider linear models for stochastic dynamics. To any such model can be as-<lb>sociated a network (namely a directed graph) describing which degrees of freedom<lb>interact under the dynamics. We tackle the problem of learning such a network<lb>from observation of the system trajectory over a time interval T .<lb>We analyze the l1-regularized least squares algorithm and, in the setting in which<lb>the underlying network is sparse, we prove performance guarantees that are uni-<lb>form in the sampling rate as long as this is sufficiently high. This result substan-<lb>tiates the notion of a well defined ‘time complexity’ for the network inference<lb>problem. keywords: Gaussian processes, model selection and structure learning, graphical models, sparsity<lb>and feature selection.",
            "output": [
                "Learning Networks of Stochastic Differential Equations"
            ]
        },
        {
            "id": "task1540-3fc5d6d1f8ff4a8e80d6823f2c193152",
            "input": "The main advantage of Constraint Programming (CP) approaches for sequential pattern mining (SPM) is their modularity, which includes the ability to add new constraints (regular expressions, length restrictions, etc). The current best CP approach for SPM uses a global constraint (module) that computes the projected database and enforces the minimum frequency; it does this with a filtering algorithm similar to the PrefixSpan method. However, the resulting system is not as scalable as some of the most advanced mining systems like Zaki’s cSPADE. We show how, using techniques from both data mining and CP, one can use a generic constraint solver and yet outperform existing specialized systems. This is mainly due to two improvements in the module that computes the projected frequencies: first, computing the projected database can be sped up by pre-computing the positions at which an symbol can become unsupported by a sequence, thereby avoiding to scan the full sequence each time; and second by taking inspiration from the trailing used in CP solvers to devise a backtracking-aware data structure that allows fast incremental storing and restoring of the projected database. Detailed experiments show how this approach outperforms existing CP as well as specialized systems for SPM, and that the gain in efficiency translates directly into increased efficiency for other settings such as mining with regular expressions.",
            "output": [
                "An Efficient Algorithm for Mining Frequent Sequence with Constraint Programming"
            ]
        },
        {
            "id": "task1540-ce01f0db90ac4f958e405854501f1038",
            "input": "Present day machine learning is computationally intensive and processes large amounts of data. It is implemented in a distributed fashion in order to address these scalability issues. The work is parallelized across a number of computing nodes. It is usually hard to estimate in advance how many nodes to use for a particular workload. We propose a simple framework for estimating the scalability of distributed machine learning algorithms. We measure the scalability by means of the speedup an algorithm achieves with more nodes. We propose time complexity models for gradient descent and graphical model inference. We validate our models with experiments on deep learning training and belief propagation. This framework was used to study the scalability of machine learning algorithms in Apache Spark.",
            "output": [
                "Modeling Scalability of Distributed Machine Learning"
            ]
        },
        {
            "id": "task1540-a1c633ff27eb437b9b99ae9c33f6e827",
            "input": "The paper introduces AND/OR importance sampling for probabilistic graphical models. In contrast to importance sampling, AND/OR importance sampling caches samples in the AND/OR space and then extracts a new sample mean from the stored samples. We prove that AND/OR importance sampling may have lower variance than importance sampling; thereby providing a theoretical justification for preferring it over importance sampling. Our empirical evaluation demonstrates that AND/OR importance sampling is far more accurate than importance sampling in many cases.",
            "output": [
                "AND/OR Importance Sampling"
            ]
        },
        {
            "id": "task1540-b72ba3bc17ce46dcb089484cfddcb3b7",
            "input": "Conceived in the early 1990s, Experience Replay (ER) has been shown to be a successful mechanism to allow online learning algorithms to reuse past experiences. Traditionally, ER can be applied to all machine learning paradigms (i.e., unsupervised, supervised, and reinforcement learning). Recently, ER has contributed to improving the performance of deep reinforcement learning. Yet, its application to many practical settings is still limited by the memory requirements of ER, necessary to explicitly store previous observations. To remedy this issue, we explore a novel approach, Online Contrastive Divergence with Generative Replay (OCDGR), which uses the generative capability of Restricted Boltzmann Machines (RBMs) instead of recorded past experiences. The RBM is trained online, and does not require the system to store any of the observed data points. We compare OCDGR to ER on 9 real-world datasets, considering a worst-case scenario (data points arriving in sorted order) as well as a more realistic one (sequential random-order data points). Our results show that in 64.28% of the cases OCDGR outperforms ER and in the remaining 35.72% it has an almost equal performance, while having a considerably reduced space complexity (i.e., memory usage) at a comparable time complexity.",
            "output": [
                "Online Contrastive Divergence with Generative Replay: Experience Replay without Storing Data"
            ]
        },
        {
            "id": "task1540-2520bac07fdd48ec81773c775964ec9e",
            "input": "In collective decision making, where a voting rule is used to take a collective decision among a group of agents, manipulation by one or more agents is usually considered negative behavior to be avoided, or at least to be made computationally difficult for the agents to perform. However, there are scenarios in which a restricted form of manipulation can instead be beneficial. In this paper we consider the iterative version of several voting rules, where at each step one agent is allowed to manipulate by modifying his ballot according to a set of restricted manipulation moves which are computationally easy and require little information to be performed. We prove convergence of iterative voting rules when restricted manipulation is allowed, and we present experiments showing that most iterative voting rules have a higher Condorcet efficiency than their non-iterative version.",
            "output": [
                "Restricted Manipulation in Iterative Voting: Convergence and Condorcet Efficiency"
            ]
        },
        {
            "id": "task1540-1664deb0ca7b473281c97315252a7e21",
            "input": "This paper studies the applicability of evolutionary algorithms, particularly, the evolution strategies family to estimation of a degradation parameter (referred as kappa parameter) for the shear design of reinforced concrete beams, a problem which have an expensive computational cost and highly relevant in the design of pillars and reinforced concrete structures, which however, has not been covered extensively in the present literature.",
            "output": [
                "“ANÁLISIS E IMPLEMENTACIÓN DE ALGORITMOS EVOLUTIVOS PARA LA OPTIMIZACIÓN DE SIMULACIONES EN INGENIERÍA CIVIL.”"
            ]
        },
        {
            "id": "task1540-eaa2195a988649d7bb289b591e0a865c",
            "input": "This article is an overview of the SP theory of intelligence, which aims to simplify and integrate concepts across artificial intelligence, mainstream computing and human perception and cognition, with information compression as a unifying theme. It is conceived as a brain-like system that receives ‘New’ information and stores some or all of it in compressed form as ‘Old’ information; and it is realised in the form of a computer model, a first version of the SP machine. The matching and unification of patterns and the concept of multiple alignment are central ideas. Using heuristic techniques, the system builds multiple alignments that are ‘good’ in terms of information compression. For each multiple alignment, probabilities may be calculated for associated inferences. Unsupervised learning is done by deriving new structures from partial matches between patterns and via heuristic search for sets of structures that are ‘good’ in terms of information compression. These are normally ones that people judge to be ‘natural’, in accordance with the ‘DONSVIC’ principle—the discovery of natural structures via information compression. The SP theory provides an interpretation for concepts and phenomena in several other areas including ‘computing’, aspects of mathematics and logic, the representation of knowledge, natural language processing, pattern recognition, several kinds of reasoning, information storage and retrieval, planning and problem solving, information compression, neuroscience, and human perception and cognition. Examples include the parsing and production of language with discontinuous dependencies in syntax, pattern recognition at multiple levels of abstraction and ∗Now published as The SP theory of intelligence: an overview (J G Wolff, Information, 4 (3), 283-341, 2013, doi:10.3390/info4030283). †Dr Gerry Wolff, BA (Cantab), PhD (Wales), CEng, MBCS (CITP); CognitionResearch.org, Menai Bridge, UK; jgw@cognitionresearch.org; +44 (0) 1248 712962; +44 (0) 7746 290775; Skype: gerry.wolff; Web: www.cognitionresearch.org. 1 ar X iv :1 30 6. 38 88 v4 [ cs .A I] 7 J an 2 01 5 its integration with part-whole relations, nonmonotonic reasoning and reasoning with default values, reasoning in Bayesian networks including ‘explaining away’, causal diagnosis, and the solving of a geometric analogy problem.",
            "output": [
                "The SP theory of intelligence: an overview∗"
            ]
        },
        {
            "id": "task1540-4919f7a135334d3c9f13747770d42223",
            "input": "An Autonomous Underwater Vehicle (AUV) needs to acquire a certain degree of autonomy for any particular underwater mission to fulfil the mission objectives successfully and ensure its safety in all stages of the mission in a large scale operating filed. In this paper, a novel combinatorial conflict-free-task assignment strategy consisting an interactive engagement of a local path planner and an adaptive global route planner, is introduced. The method is established upon the heuristic search potency of the Particle Swarm Optimization (PSO) algorithm to address the discrete nature of routing-task assignment approach and the complexity of NP-hard path planning problem. The proposed hybrid method, is highly efficient for having a reactive guidance framework that guarantees successful completion of missions specifically in cluttered environments. To examine the performance of the method in a context of mission productivity, mission time management and vehicle safety, a series of simulation studies are undertaken. The results of simulations declare that the proposed method is reliable and robust, particularly in dealing with uncertainties, and it can significantly enhance the level of vehicle’s autonomy by relying on its reactive nature and capability of providing fast feasible solutions. Keywords-Autonomous underwater vehicles, Path planning, Route planning, Autonomy, Evolutionary optimization",
            "output": [
                "Toward Efficient Task Assignment and Motion Planning for Large Scale Underwater Mission"
            ]
        },
        {
            "id": "task1540-f9ca459cf4d54b14a4b0a6e4abd2dfdb",
            "input": "We consider a multidimensional search problem that is motivated by questions in contextual decision-making, such as dynamic pricing and personalized medicine. Nature selects a state from a d-dimensional unit ball and then generates a sequence of d-dimensional directions. We are given access to the directions, but not access to the state. After receiving a direction, we have to guess the value of the dot product between the state and the direction. Our goal is to minimize the number of times when our guess is more than ǫ away from the true answer. We construct a polynomial time algorithm that we call Projected Volume achieving regret O(d log(d/ǫ)), which is optimal up to a log d factor. The algorithm combines a volume cutting strategy with a new geometric technique that we call cylindrification.",
            "output": [
                "Multidimensional Binary Search for Contextual Decision-Making"
            ]
        },
        {
            "id": "task1540-f31445e5bf2e4afaa4b574ec1ea903b1",
            "input": "Re-scale boosting (RBoosting) is a variant of boosting which can essentially improve the generalization performance of boosting learning. The key feature of RBoosting lies in introducing a shrinkage degree to re-scale the ensemble estimate in each gradient-descent step. Thus, the shrinkage degree determines the performance of RBoosting. The aim of this paper is to develop a concrete analysis concerning how to determine the shrinkage degree in L2-RBoosting. We propose two feasible ways to select the shrinkage degree. The first one is to parameterize the shrinkage degree and the other one is to develope a data-driven approach of it. After rigorously analyzing the importance of the shrinkage degree in L2-RBoosting learning, we compare the pros and cons of the proposed methods. We find that although these approaches can reach the same learning rates, the structure of the final estimate of the parameterized approach is better, which sometimes yields a better generalization capability when the number of sample is finite. With this, we recommend to parameterize the shrinkage degree of L2RBoosting. To this end, we present an adaptive parameterselection strategy for shrinkage degree and verify its feasibility through both theoretical analysis and numerical verification. The obtained results enhance the understanding of RBoosting and further give guidance on how to use L2-RBoosting for regression tasks.",
            "output": [
                "Shrinkage degree in L2-re-scale boosting for regression"
            ]
        },
        {
            "id": "task1540-37d466f28bc8460887a0bf7e1c3e5a4c",
            "input": "This paper is about reducing influence dia­ gram (ID) evaluation into Bayesian network (BN) inference problems. Such reduction is interesting because it enables one to read­ ily use one's favorite BN inference algorithm to efficiently evaluate IDs. Two such reduc­ tion methods have been proposed previously (Cooper 1988, Shachter and Peot 1992). This paper proposes a new method. The BN in­ ference problems induced by the mew method are much easier to solve than those induced by the two previous methods.",
            "output": [
                "Probabilistic Inference in Influence Diagrams"
            ]
        },
        {
            "id": "task1540-884266162af6432ba824c5fa8caa84a7",
            "input": "Maximum Inner Product Search (MIPS) is an important task in many machine learning applications such as the prediction phase of a low-rank matrix factorization model for a recommender system. There have been some works on how to perform MIPS in sub-linear time recently. However, most of them do not have the flexibility to control the trade-off between search efficient and search quality. In this paper, we study the MIPS problem with a computational budget. By carefully studying the problem structure of MIPS, we develop a novel Greedy-MIPS algorithm, which can handle budgeted MIPS by design. While simple and intuitive, Greedy-MIPS yields surprisingly superior performance compared to state-of-the-art approaches. As a specific example, on a candidate set containing half a million vectors of dimension 200, Greedy-MIPS runs 200x faster than the naive approach while yielding search results with the top-5 precision greater than 75%.",
            "output": [
                "A Greedy Approach for Budgeted Maximum Inner Product Search"
            ]
        },
        {
            "id": "task1540-98ff0aaa1bc944f18dd1bc3fbfade992",
            "input": "The combinatorial stochastic semi-bandit problem is an extension of the classical multi-armed bandit problem in which an algorithm pulls more than one arm at each stage and the rewards of all pulled arms are revealed. One difference with the single arm variant is that the dependency structure of the arms is crucial. Previous works on this setting either used a worst-case approach or imposed independence of the arms. We introduce a way to quantify the dependency structure of the problem and design an algorithm that adapts to it. The algorithm is based on linear regression and the analysis develops techniques from the linear bandit literature. By comparing its performance to a new lower bound, we prove that it is optimal, up to a poly-logarithmic factor in the number of pulled arms.",
            "output": [
                "Combinatorial semi-bandit with known covariance"
            ]
        },
        {
            "id": "task1540-2aa348b582c1417fb5c4d1714887b6ce",
            "input": "This paper introduces a new architecture for human pose estimation using a multilayer convolutional network architecture and a modified learning technique that learns low-level features and a higher-level weak spatial model. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows improvement over the current stateof-the-art. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to meet the performance, and in many cases outperform, existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on regions that might only cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent than expected. Many researchers previously argued that the kinematic structure and top-down information are crucial for this domain, but with our purely bottom-up, and weak spatial model, we improve on other more complicated architectures that currently produce the best results. This echos what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced [26]. Figure 1: The green cross is our new technique’s wrist locator, the red cross is the state-of-the-art CVPR13 MODEC detector [38] on the FLIC database.",
            "output": [
                "Learning Human Pose Estimation Features with Convolutional Networks"
            ]
        },
        {
            "id": "task1540-7759e0091f6d4cf6bd6cdc070fe22687",
            "input": "This paper investigates how linguistic knowledge mined from large text corpora can aid the generation of natural language descriptions of videos. Specifically, we integrate both a neural language model and distributional semantics trained on large text corpora into a recent LSTM-based architecture for video description. We evaluate our approach on a collection of Youtube videos as well as two large movie description datasets showing significant improvements in grammaticality while modestly improving descriptive quality.",
            "output": [
                "Improving LSTM-based Video Description with Linguistic Knowledge Mined from Text"
            ]
        },
        {
            "id": "task1540-15578ed50c304241b4cfa484d21e4a78",
            "input": "Botnets, which consist of thousands of compromised machines, can cause significant threats to other systems by launching Distributed Denial of Service (DDoS) attacks, keylogging, and backdoors. In response to these threats, new effective techniques are needed to detect the presence of botnets. In this paper, we have used an interception technique to monitor Windows Application Programming Interface (API) functions calls made by communication applications and store these calls with their arguments in log files. Our algorithm detects botnets based on monitoring abnormal activity by correlating the changes in log file sizes from different hosts. Keywords-IRC; DDoS; Bots; Botnets; API function calls",
            "output": [
                "Detecting Botnets Through Log Correlation"
            ]
        },
        {
            "id": "task1540-c0c7f5c488d74d12a618172e0f590165",
            "input": "Interlingua based Machine Translation (MT) aims to encode multiple languages into a common linguistic representation and then decode sentences in multiple target languages from this representation. In this work we explore this idea in the context of neural encoder decoder architectures, albeit on a smaller scale and without MT as the end goal. Specifically, we consider the case of three languages or modalities X , Z and Y wherein we are interested in generating sequences in Y starting from information available in X . However, there is no parallel training data available between X and Y but, training data is available between X & Z and Z & Y (as is often the case in many real world applications). Z thus acts as a pivot/bridge. An obvious solution, which is perhaps less elegant but works very well in practice is to train a two stage model which first converts from X to Z and then from Z to Y . Instead we explore an interlingua inspired solution which jointly learns to do the following (i) encodeX and Z to a common representation and (ii) decode Y from this common representation. We evaluate our model on two tasks: (i) bridge transliteration and (ii) bridge captioning. We report promising results in both these applications and believe that this is a right step towards truly interlingua inspired encoder decoder architectures.",
            "output": [
                "A Correlational Encoder Decoder Architecture for Pivot Based Sequence Generation"
            ]
        },
        {
            "id": "task1540-02ea6f742ff740cbb9386f88c386e96b",
            "input": "Argument Component Boundary Detection (ACBD) is an important sub-task in argumentation mining; it aims at identifying the word sequences that constitute argument components, and is usually considered as the first sub-task in the argumentation mining pipeline. Existing ACBD methods heavily depend on task-specific knowledge, and require considerable human efforts on feature-engineering. To tackle these problems, in this work, we formulate ACBD as a sequence labeling problem and propose a variety of Recurrent Neural Network (RNN) based methods, which do not use domain specific or handcrafted features beyond the relative position of the sentence in the document. In particular, we propose a novel joint RNN model that can predict whether sentences are argumentative or not, and use the predicted results to more precisely detect the argument component boundaries. We evaluate our techniques on two corpora from two different genres; results suggest that our joint RNN model obtain the state-of-the-art performance on both datasets.",
            "output": [
                "Joint RNN Model for Argument Component Boundary Detection"
            ]
        },
        {
            "id": "task1540-b9a5939e8df3406bba6a3cdc834c705f",
            "input": "We introduce kLog, a novel approach to statistical relational learning. Unlike standard approaches, kLog does not represent a probability distribution directly. It is rather a language to perform kernel-based learning on expressive logical and relational representations. kLog allows users to specify learning problems declaratively. It builds on simple but powerful concepts: learning from interpretations, entity/relationship data modeling, logic programming, and deductive databases. Access by the kernel to the rich representation is mediated by a technique we call graphicalization: the relational representation is first transformed into a graph — in particular, a grounded entity/relationship diagram. Subsequently, a choice of graph kernel defines the feature space. kLog supports mixed numerical and symbolic data, as well as background knowledge in the form of Prolog or Datalog programs as in inductive logic programming systems. The kLog framework can be applied to tackle the same range of tasks that has made statistical relational learning so popular, including classification, regression, multitask learning, and collective classification. We also report about empirical comparisons, showing PF was a visiting professor at KU Leuven and FC a postdoctoral fellow at KU Leuven while this work was initiated ∗Corresponding author Email addresses: p-f@dsi.unifi.it (Paolo Frasconi), costa@informatik.uni-freiburg.de (Fabrizio Costa), Luc.DeRaedt@cs.kuleuven.be (Luc De Raedt), Kurt.DeGrave@cs.kuleuven.be (Kurt De Grave) Preprint submitted to Artificial Intelligence July 29, 2014 ar X iv :1 20 5. 39 81 v5 [ cs .A I] 2 8 Ju l 2 01 4 that kLog can be either more accurate, or much faster at the same level of accuracy, than Tilde and Alchemy. kLog is GPLv3 licensed and is available at http://klog.dinfo.unifi.it along with tutorials.",
            "output": [
                "kLog: A Language for Logical and Relational Learning with Kernels"
            ]
        },
        {
            "id": "task1540-ca7210a8c0fc4161b3fd22518652b8c0",
            "input": "In this work, we propose CLass-Enhanced Attentive Response (CLEAR): an approach to visualize and understand the decisions made by deep neural networks (DNNs) given a specific input. CLEAR facilitates the visualization of attentive regions and levels of interest of DNNs during the decision-making process. It also enables the visualization of the most dominant classes associated with these attentive regions of interest. As such, CLEAR can mitigate some of the shortcomings of heatmap-based methods associated with decision ambiguity, and allows for better insights into the decision-making process of DNNs. Quantitative and qualitative experiments across three different datasets demonstrate the efficacy of CLEAR for gaining a better understanding of the inner workings of DNNs during the decision-making process.",
            "output": [
                "Explaining the Unexplained: A CLass-Enhanced Attentive Response (CLEAR) Approach to Understanding Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-d626801c0be8451ca89f5173023ff7e3",
            "input": "Lexical features are a major source of information in state-of-the-art coreference resolvers. Lexical features implicitly model some of the linguistic phenomena at a fine granularity level. They are especially useful for representing the context of mentions. In this paper we investigate a drawback of using many lexical features in state-of-the-art coreference resolvers. We show that if coreference resolvers mainly rely on lexical features, they can hardly generalize to unseen domains. Furthermore, we show that the current coreference resolution evaluation is clearly flawed by only evaluating on a specific split of a specific dataset in which there is a notable overlap between the training, development and test sets.",
            "output": [
                "Lexical Features in Coreference Resolution: To be Used With Caution"
            ]
        },
        {
            "id": "task1540-8d8044676b64429e8b51c957682fd39b",
            "input": "This paper proposes a deep denoising auto-encoder technique to extract better acoustic features for speech synthesis. The technique allows us to automatically extract low-dimensional features from high dimensional spectral features in a non-linear, data-driven, unsupervised way. We compared the new stochastic feature extractor with conventional mel-cepstral analysis in analysis-by-synthesis and text-to-speech experiments. Our results confirm that the proposed method increases the quality of synthetic speech in both experiments.",
            "output": [
                "DEEP DENOISING AUTO-ENCODER FOR STATISTICAL SPEECH SYNTHESIS"
            ]
        },
        {
            "id": "task1540-16bbd4f4682640d39bda6b1926548f90",
            "input": "This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on two scoring functions that operate by learning low-dimensional embeddings of words and of entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over existing methods that rely on text features alone.",
            "output": [
                "Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction"
            ]
        },
        {
            "id": "task1540-b763c6b7be6e4b9194abba22a543a548",
            "input": "The aim of this paper is to show the interest in fitting features with an α-stable distribution to classify imperfect data. The supervised pattern recognition is thus based on the theory of continuous belief functions, which is a way to consider imprecision and uncertainty of data. The distributions of features are supposed to be unimodal and estimated by a single Gaussian and α-stable model. Experimental results are first obtained from synthetic data by combining two features of one dimension and by considering a vector of two features. Mass functions are calculated from plausibility functions by using the generalized Bayes theorem. The same study is applied to the automatic classification of three types of sea floor (rock, silt and sand) with features acquired by a mono-beam echo-sounder. We evaluate the quality of the α-stable model and the Gaussian model by analyzing qualitative results, using a Kolmogorov-Smirnov test (K-S test), and quantitative results with classification rates. The performances of the belief classifier are compared with a Bayesian approach.",
            "output": [
                "Features modeling with an α-stable distribution: application to pattern recognition based on continuous belief functions"
            ]
        },
        {
            "id": "task1540-028dbdaf3517454e8cd492611357b1ea",
            "input": "Nonlinear independent component analysis (ICA) provides an appealing framework<lb>for unsupervised feature learning, but the models proposed so far are not identifiable.<lb>Here, we first propose a new intuitive principle of unsupervised deep learning<lb>from time series which uses the nonstationary structure of the data. Our learning<lb>principle, time-contrastive learning (TCL), finds a representation which allows<lb>optimal discrimination of time segments (windows). Surprisingly, we show how<lb>TCL can be related to a nonlinear ICA model, when ICA is redefined to include<lb>temporal nonstationarities. In particular, we show that TCL combined with linear<lb>ICA estimates the nonlinear ICA model up to point-wise transformations of the<lb>sources, and this solution is unique — thus providing the first identifiability result<lb>for nonlinear ICA which is rigorous, constructive, as well as very general.",
            "output": [
                "Unsupervised Feature Extraction by Time-Contrastive Learning and Nonlinear ICA"
            ]
        },
        {
            "id": "task1540-d3d37656ec8f487fbf81680b0c25a6db",
            "input": "In this paper, we improve the attention or alignment accuracy of neural machine translation by utilizing the alignments of training sentence pairs. We simply compute the distance between the machine attentions and the “true” alignments, and minimize this cost in the training procedure. Our experiments on large-scale Chinese-to-English task show that our model improves both translation and alignment qualities significantly over the large-vocabulary neural machine translation system, and even beats a state-of-the-art traditional syntax-based system.",
            "output": [
                "Supervised Attentions for Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-4ca3c0a3060645b9ba34a0c46ab676f6",
            "input": "In current perception systems applied to the rebuilding of the environment for intelligent vehicles, the part reserved to object association for the tracking is increasingly significant. This allows firstly to follow the objects temporal evolution and secondly to increase the reliability of environment perception. We propose in this communication the development of a multi­ objects association algorithm with ambiguity removal entering into the design of such a dynamic perception system for intelligent vehicles. This algorithm uses the belief theory and data modelling with fuzzy mathematics in order to be able to handle inaccurate as well as uncertain information due to imperfect sensors. These theories also allow the fusion of numerical as well as symbolic data. We develop in this article the problem of matching between known and perceived objects. This makes it possible to update a dynamic environment map for a vehicle. The belief theory will enable us to quantify the belief in the association of each perceived object with each known object. Conflicts can appear in the case of object appearance or disappearance, or in the case of a confused situation or bad perception. These conflicts are removed or solved using an assignment algorithm, giving a solution called the « best » and so ensuring the tracking of some objects present in our environment.",
            "output": [
                "Multi-objects association in perception of dynamical situation"
            ]
        },
        {
            "id": "task1540-7360b8536fa04d439434f8af7a15dcb2",
            "input": "In this article we present two ways of struc­ turing bodies of evidence, which allow us to reduce the complexity of the operations usu­ ally performed in the framework of evidence theory. The first structure just partitions the focal elements in a body of evidence by their cardinality. With this structure we are able to reduce the complexity on the calculation of the belief functions Bel, PI, and Q. The other structure proposed here, the Hierarchi­ cal Trees, permits us to reduce the complex­ ity of the calculation of Bel, PI, and Q, as well as of the Dempster's rule of combination in relation to the brute-force algorithm. Both these structures do not require the generation of all the subsets of the reference domain.",
            "output": [
                "Structuring Bodies of Evidence"
            ]
        },
        {
            "id": "task1540-bbda2a93effa405a86bc29bfb19177b1",
            "input": "The goal of constraint-based sequence mining is to find sequences of symbols that are included in a large number of input sequences and that satisfy some constraints specified by the user. Many constraints have been proposed in the literature, but a general framework is still missing. We investigate the use of constraint programming as general framework for this task. We first identify four categories of constraints that are applicable to sequence mining. We then propose two constraint programming formulations. The first formulation introduces a new global constraint called exists-embedding. This formulation is the most efficient but does not support one type of constraint. To support such constraints, we develop a second formulation that is more general but incurs more overhead. Both formulations can use the projected database technique used in specialised algorithms. Experiments demonstrate the flexibility towards constraint-based settings and compare the approach to existing methods.",
            "output": [
                "Constraint-based sequence mining using constraint programming"
            ]
        },
        {
            "id": "task1540-2d37a1233d9a4c38ba3e51499a72461c",
            "input": "<lb>This work considers the problem of learning the structure of multivariate linear tree models, which<lb>include a variety of directed tree graphical models with continuous, discrete, and mixed latent variables<lb>such as linear-Gaussian models, hidden Markov models, Gaussian mixture models, and Markov evolu-<lb>tionary trees. The setting is one where we only have samples from certain observed variables in the tree,<lb>and our goal is to estimate the tree structure (i.e., the graph of how the underlying hidden variables are<lb>connected to each other and to the observed variables). We propose the Spectral Recursive Grouping al-<lb>gorithm, an efficient and simple bottom-up procedure for recovering the tree structure from independent<lb>samples of the observed variables. Our finite sample size bounds for exact recovery of the tree structure<lb>reveal certain natural dependencies on underlying statistical and structural properties of the underlying<lb>joint distribution. Furthermore, our sample complexity guarantees have no explicit dependence on the<lb>dimensionality of the observed variables, making the algorithm applicable to many high-dimensional set-<lb>tings. At the heart of our algorithm is a spectral quartet test for determining the relative topology of a<lb>quartet of variables from second-order statistics.",
            "output": [
                "Spectral Methods for Learning Multivariate Latent Tree Structure"
            ]
        },
        {
            "id": "task1540-931ffc42d43e46ab889aa89f9406c372",
            "input": "We propose a new framework for abstractive text summarization based on a sequence-to-sequence oriented encoderdecoder model equipped with a deep recurrent generative decoder (DRGN). Latent structure information implied in the target summaries is learned based on a recurrent latent random model for improving the summarization quality. Neural variational inference is employed to address the intractable posterior inference for the recurrent latent variables. Abstractive summaries are generated based on both the generative latent variables and the discriminative deterministic states. Extensive experiments on some benchmark datasets in different languages show that DRGN achieves improvements over the state-ofthe-art methods.",
            "output": [
                "Deep Recurrent Generative Decoder for Abstractive Text Summarization∗"
            ]
        },
        {
            "id": "task1540-f781e7788c1f4117a3ab1040a2e04cd9",
            "input": "Joint matching over a collection of objects aims at aggregating information from a large collection of similar instances (e.g. images, graphs, shapes) to improve maps between pairs of them. Given multiple objects and matches computed between a few object pairs in isolation, the goal is to recover an entire collection of maps that are (1) globally consistent, and (2) close to the provided maps — and under certain conditions provably the ground-truth maps. Despite recent advances on this problem, the best-known recovery guarantees are limited to a small constant barrier — none of the existing methods find theoretical support when more than 50% of input correspondences are corrupted. Moreover, prior approaches focus mostly on fully similar objects, while it is practically more demanding to match instances that are only partially similar to each other (e.g., different views of a single physical object). In this paper, we propose an algorithm to jointly match multiple objects that exhibit only partial similarities, given a few (possibly highly incomplete) pairwise matches that are densely corrupted. By encoding a consistent partial map collection into a 0-1 semidefinite matrix, we propose to recover the ground-truth maps via a parameter-free convex program called MatchLift, following a spectral method that pre-estimates the total number of distinct elements to be matched. Numerically, this program can be efficiently solved via alternating direction methods of multipliers (ADMM) along with a greedy rounding strategy. Theoretically, MatchLift exhibits near-optimal error-correction ability, i.e. in the asymptotic regime it is guaranteed to work even when a dominant fraction 1 − Θ ( log n √ n ) of the input maps behave like random outliers. Furthermore, MatchLift succeeds with minimal input complexity, namely, perfect matching can be achieved as soon as the provided maps form a connected map graph. We evaluate the proposed algorithm on various benchmark data sets including synthetic examples and real-world examples, all of which confirm the practical applicability and usefulness of MatchLift.",
            "output": [
                "Near-Optimal Joint Object Matching via Convex Relaxation"
            ]
        },
        {
            "id": "task1540-1fb5e333fae44bdda6df4ab2f68059a9",
            "input": "Model-free deep reinforcement learning (RL) methods have been successful in a wide variety of simulated domains. However, a major obstacle facing deep RL in the real world is the high sample complexity of such methods. Unbiased batch policy-gradient methods offer stable learning, but at the cost of high variance, which often requires large batches, while TD-style methods, such as off-policy actor-critic and Q-learning, are more sample-efficient but biased, and often require costly hyperparameter sweeps to stabilize. In this work, we aim to develop methods that combine the stability of unbiased policy gradients with the efficiency of off-policy RL. We present Q-Prop, a policy gradient method that uses a Taylor expansion of the off-policy critic as a control variate. Q-Prop is both sample efficient and stable, and effectively combines the benefits of on-policy and offpolicy methods. We analyze the connection between Q-Prop and existing modelfree algorithms, and use control variate theory to derive two variants of Q-Prop with conservative and aggressive adaptation. We show that conservative Q-Prop provides substantial gains in sample efficiency over trust region policy optimization (TRPO) with generalized advantage estimation (GAE), and improves stability over deep deterministic policy gradient (DDPG), the state-of-the-art on-policy and off-policy methods, on OpenAI Gym’s MuJoCo continuous control environments.",
            "output": [
                "Q-PROP: SAMPLE-EFFICIENT POLICY GRADIENT WITH AN OFF-POLICY CRITIC"
            ]
        },
        {
            "id": "task1540-1962bc0dd6e74b4cab913e9041c83a55",
            "input": "Linear-time computational techniques have been developed for combining evidence which is available on a number of contending hypotheses. They offer a means of making the computation-intensive calculations involved more efficient in certain circumstances. Unfortunately, they restrict the orthogonal sum of evidential functions to the dichotomous structure − applies only to elements and their complements. In this paper, we present a novel evidence structure in terms of a triplet and a set of algorithms for evidential reasoning. The merit of this structure is that it divides a set of evidence into three subsets, distinguishing trivial evidential elements from important ones − focusing some particular elements. It avoids the deficits of the dichotomous structure in representing the preference of evidence and estimating the basic probability assignment of evidence. We have established a formalism for this structure and the general formulae for combining pieces of evidence in the form of the triplet, which have been theoretically and empirically justified.",
            "output": [
                "An Efficient Triplet-based Algorithm for Evidential Reasoning"
            ]
        },
        {
            "id": "task1540-fc55f1e3220f480b8cad5df4a8022689",
            "input": "We present the first parser for UCCA, a cross-linguistically applicable framework for semantic representation, which builds on extensive typological work and supports rapid annotation. UCCA poses a challenge for existing parsing techniques, as it exhibits reentrancy (resulting in DAG structures), discontinuous structures and non-terminal nodes corresponding to complex semantic units. To our knowledge, the conjunction of these formal properties is not supported by any existing parser. Our transition-based parser, which uses a novel transition set and features based on bidirectional LSTMs, has value not just for UCCA parsing: its ability to handle more general graph structures can inform the development of parsers for other semantic DAG structures, and in languages that frequently use discontinuous structures.",
            "output": [
                "A Transition-Based Directed Acyclic Graph Parser for UCCA"
            ]
        },
        {
            "id": "task1540-6846ae521f7a45ccbc25474744373305",
            "input": "Weather affects our mood and behaviors, and many aspects of our life. When it is sunny, most people become happier; but when it rains, some people get depressed. Despite this evidence and the abundance of data, weather has mostly been overlooked in the machine learning and data science research. This work presents a causal analysis of how weather affects TV watching patterns. We show that some weather attributes, such as pressure and precipitation, cause major changes in TV watching patterns. To the best of our knowledge, this is the first large-scale causal study of the impact of weather on TV watching patterns.",
            "output": [
                "Does Weather Matter? Causal Analysis of TV Logs"
            ]
        },
        {
            "id": "task1540-7c0d54eba5404366b76200fe9c0a6054",
            "input": "Modern malware is designed with mutation characteristics, namely polymorphism and metamorphism, which causes an enormous growth in the number of variants of malware samples. Categorization of malware samples on the basis of their behaviors is essential for the computer security community in order to group samples belonging to same family. Microsoft released a malware classification challenge in 2015 with a huge dataset of near 0.5 terabytes of data, containing more than 20K malware samples. The analysis of this dataset inspired the development of a novel paradigm that is effective in categorizing malware variants into their actual family groups. This paradigm is presented and discussed in the present paper, where emphasis has been given to the phases related to the extraction, and selection of a set of novel features for the effective representation of malware samples. Features can be grouped according to different characteristics of malware behavior, and their fusion is performed according to a per-class weighting paradigm. The proposed method achieved a very high accuracy (≈ 0.998) on the Microsoft Malware Challenge dataset.",
            "output": [
                "Novel feature extraction, selection and fusion for effective malware family classification"
            ]
        },
        {
            "id": "task1540-ab6a65f66c384924a6ecb1429833a4c3",
            "input": "Explaining adaptive behavior is a central problem in artificial intelligence research. Here we formalize adaptive agents as mixture distributions over sequences of inputs and outputs (I/O). Each distribution of the mixture constitutes a ‘possible world’, but the agent does not know which of the possible worlds it is actually facing. The problem is to adapt the I/O stream in a way that is compatible with the true world. A natural measure of adaptation can be obtained by the KullbackLeibler (KL) divergence between the I/O distribution of the true world and the I/O distribution expected by the agent that is uncertain about possible worlds. In the case of pure input streams, the Bayesian mixture provides a well-known solution for this problem. We show, however, that in the case of I/O streams this solution breaks down, because outputs are issued by the agent itself and require a different probabilistic syntax as provided by intervention calculus. Based on this calculus, we obtain a Bayesian control rule that allows modeling adaptive behavior with mixture distributions over I/O streams. This rule might allow for a novel approach to adaptive control based on a minimum KLprinciple.",
            "output": [
                "A Bayesian Rule for Adaptive Control based on Causal Interventions"
            ]
        },
        {
            "id": "task1540-a3ab227b0aa64afaab4c7eb017218c91",
            "input": "Integrating vision and language has long been a dream in work on artificial intelligence (AI). In the past two years, we have witnessed an explosion of work that brings together vision and language from images to videos and beyond. The available corpora have played a crucial role in advancing this area of research. In this paper, we propose a set of quality metrics for evaluating and analyzing the vision & language datasets and classify them accordingly. Our analyses show that the most recent datasets have been using more complex language and more abstract concepts, however, there are different strengths and weaknesses in each.",
            "output": [
                "On Available Corpora for Empirical Methods in Vision & Language"
            ]
        },
        {
            "id": "task1540-8c7378ed97974f66bc714ce476865e90",
            "input": "The Minimum Weight Dominating Set (MWDS) problem is an important generalization of the Minimum Dominating Set (MDS) problem with extensive applications. This paper proposes a new local search algorithm for the MWDS problem, which is based on two new ideas. The first idea is a heuristic called two-level configuration checking (CC), which is a new variant of a recent powerful configuration checking strategy (CC) for effectively avoiding the recent search paths. The second idea is a novel scoring function based on the frequency of being uncovered of vertices. Our algorithm is called CCFS, according to the names of the two ideas. The experimental results show that, CCFS performs much better than some state-of-the-art algorithms in terms of solution quality on a broad range of MWDS benchmarks.",
            "output": [
                "Local Search for Minimum Weight Dominating Set with Two-Level Configuration Checking and Frequency Based Scoring Function"
            ]
        },
        {
            "id": "task1540-c26210813ad946d68d916e3397c8b000",
            "input": "In the mixture models problem it is assumed that there are K distributions θ1, . . . , θK and one gets to observe a sample from a mixture of these distributions with unknown coefficients. The goal is to associate instances with their generating distributions, or to identify the parameters of the hidden distributions. In this work we make the assumption that we have access to several samples drawn from the same K underlying distributions, but with different mixing weights. As with topic modeling, having multiple samples is often a reasonable assumption. Instead of pooling the data into one sample, we prove that it is possible to use the differences between the samples to better recover the underlying structure. We present algorithms that recover the underlying structure under milder assumptions than the current state of art when either the dimensionality or the separation is high. The methods, when applied to topic modeling, allow generalization to words not present in the training data.",
            "output": [
                "Using multiple samples to learn mixture models"
            ]
        },
        {
            "id": "task1540-ce98b723d43144d08910e0fac9aa245b",
            "input": "We introduce and analyze a rigorous formulation of the dynamics of a signal processing scheme that aims at dense scanning of large input signals. Recently proposed methodologies lack a satisfactory discussion of whether they actually produce the correct results according to their definition, especially in the context of Convolutional Neural Networks. We improve on this through an exact characterization of the requirements for a sound sliding window approach. The tools developed in this paper are especially beneficial if Convolutional Neural Networks are employed, but can also be used as a more general framework to validate related approaches to signal scanning. The contributed theory helps to eliminate redundant computations and renders special case treatment unnecessary, resulting in a dramatic boost in efficiency particularly on massively parallel processors.",
            "output": [
                "A Theory for Rapid Exact Signal Scanning with Deep Multi-Scale Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-031277206adf475b82d6ea64892ea426",
            "input": "Annotating semantic data with metadata is becoming more and more important to provide information about the statements being asserted. While initial solutions proposed a data model to represent a specific dimension of metainformation (such as time or provenance), the need for a general annotation framework which allows representing different context dimensions is needed. In this paper, we extend the 4dFluents ontology by Welty and Fikes—on associating temporal validity to statements—to any dimension of context, and discuss possible issues that multidimensional context representations have to face and how we address them.",
            "output": [
                "NdFluents: A Multi-dimensional Contexts Ontology"
            ]
        },
        {
            "id": "task1540-7383c70b42c04cc7baa744a28260ce9c",
            "input": "In this article we introduce how to put vague hyperprior on Dirichlet distribution, and we update the parameter of it by adaptive rejection sampling (ARS). Finally we analyze this hyperprior in an over-fitted mixture model by some synthetic experiments.",
            "output": [
                "Hyperprior on symmetric Dirichlet distribution"
            ]
        },
        {
            "id": "task1540-5b7099fea3204afdbb21a56fc921f7d2",
            "input": "We propose Batch-Expansion Training (BET), a framework for running a batch optimizer on a gradually expanding dataset. As opposed to stochastic approaches, batches do not need to be resampled i.i.d. at every iteration, thus making BET more resource efficient in a distributed setting, and when disk-access is constrained. Moreover, BET can be easily paired with most batch optimizers, does not require any parameter-tuning, and compares favorably to existing stochastic and batch methods. We show that when the batch size grows exponentially with the number of outer iterations, BET achieves optimal Õ(1/ǫ) data-access convergence rate for strongly convex objectives.",
            "output": [
                "Batch-Expansion Training: An Efficient Optimization Paradigm for Machine Learning"
            ]
        },
        {
            "id": "task1540-f436d48ad8bc4a009e56f527b9ff5505",
            "input": "Mediation is a process, in which both parties agree to resolve their dispute by negotiating over alternative solutions presented by a mediator. In order to construct such solutions, mediation brings more information and knowledge, and, if possible, resources to the negotiation table. The contribution of this paper is the automated mediation machinery which does that. It presents an argumentation-based mediation approach that extends the logic-based approach to argumentation-based negotiation involving BDI agents. The paper describes the mediation algorithm. For comparison it illustrates the method with a case study used in an earlier work. It demonstrates how the computational mediator can deal with realistic situations in which the negotiating agents would otherwise fail due to lack of knowledge and/or resources.",
            "output": [
                "Dispute Resolution Using Argumentation-Based Mediation"
            ]
        },
        {
            "id": "task1540-8fa4dbe46fcd4f82bf2fdcf7bcce62b6",
            "input": "Epistemic logic with non-standard knowledge operators, especially the “knowing-value” operator, has recently gathered much attention. With the “knowing-value” operator, we can express knowledge of individual variables, but not of the relations between them in general. In this paper, we propose a new operator Kf to express knowledge of the functional dependencies between variables. The semantics of this Kf operator uses a function domain which imposes a constraint on what counts as a functional dependency relation. By adjusting this function domain, different interesting logics arise, and in this paper we axiomatize three such logics in a single agent setting. Then we show how these three logics can be unified by allowing the function domain to vary relative to different agents and possible worlds. A multiagent axiomatization is given in this case.",
            "output": [
                "Epistemic Logic with Functional Dependency Operator"
            ]
        },
        {
            "id": "task1540-0e6a27d942194692ba5dd672fd1f7917",
            "input": "We present a deep layered architecture that generalizes classical convolutional neural networks (ConvNets). The architecture, called SimNets, is driven by two operators, one being a similarity function whose family contains the convolution operator used in ConvNets, and the other is a new soft max-min-mean operator called MEX that realizes classical operators like ReLU and max pooling, but has additional capabilities that make SimNets a powerful generalization of ConvNets. Three interesting properties emerge from the architecture: (i) the basic input to hidden layer to output machinery contains as special cases kernel machines with the Exponential and Generalized Gaussian kernels, the output units being ”neurons in feature space” (ii) in its general form, the basic machinery has a higher abstraction level than kernel machines, and (iii) initializing networks using unsupervised learning is natural. Experiments demonstrate the capability of achieving state of the art accuracy with networks that are an order of magnitude smaller than comparable ConvNets.",
            "output": [
                "SimNets: A Generalization of Convolutional Networks"
            ]
        },
        {
            "id": "task1540-8f77c3ccf9034f5899684faaf1e334b9",
            "input": "We introduce the Dynamic Capacity Network (DCN), a neural network that can adaptively assign its capacity across different portions of the input data. This is achieved by combining modules of two types: low-capacity subnetworks and high-capacity sub-networks. The low-capacity sub-networks are applied across most of the input, but also provide a guide to select a few portions of the input on which to apply the high-capacity sub-networks. The selection is made using a novel gradient-based attention mechanism, that efficiently identifies input regions for which the DCN’s output is most sensitive and to which we should devote more capacity. We focus our empirical evaluation on the Cluttered MNIST and SVHN image datasets. Our findings indicate that DCNs are able to drastically reduce the number of computations, compared to traditional convolutional neural networks, while maintaining similar or even better performance.",
            "output": [
                "Dynamic Capacity Networks"
            ]
        },
        {
            "id": "task1540-ac35905d25cc4df1b86e084720167ed7",
            "input": "<lb>An associative memory is a framework of content-addressable memory that stores a collection of<lb>message vectors (or a dataset) over a neural network while enabling a neurally feasible mechanism to<lb>recover any message in the dataset from its noisy version. Designing an associative memory requires<lb>addressing two main tasks: 1) learning phase: given a dataset, learn a concise representation of the<lb>dataset in the form of a graphical model (or a neural network), 2) recall phase: given a noisy version of<lb>a message vector from the dataset, output the correct message vector via a neurally feasible algorithm<lb>over the network learnt during the learning phase. This paper studies the problem of designing a class<lb>of neural associative memories which learns a network representation for a large dataset that ensures<lb>correction against a large number of adversarial errors during the recall phase. Specifically, the associa-<lb>tive memories designed in this paper can store dataset containing exp(n) n-length message vectors over<lb>a network with O(n) nodes and can tolerate Ω( n<lb>polylogn ) adversarial errors. This paper carries out this<lb>memory design by mapping the learning phase and recall phase to the tasks of dictionary learning with<lb>a square dictionary and iterative error correction in an expander code, respectively.",
            "output": [
                "Associative Memory using Dictionary Learning and Expander Decoding"
            ]
        },
        {
            "id": "task1540-310ac04505e6421da927eaadb5fb5121",
            "input": "Davoud Mougouei School of Computer Science, Engineering, and Mathematics Flinders University Adelaide, Australia davoud.mougouei@inders.edu.au David M. W. Powers School of Computer Science, Engineering, and Mathematics Flinders University Adelaide, Australia david.powers@inders.edu.au Asghar Moeini School of Computer Science, Engineering, and Mathematics Flinders University Adelaide, Australia asghar.moeini@inders.edu.au",
            "output": [
                "An Integer Programming Model for Binary Knapsack Problem with Value-Related Dependencies among Elements"
            ]
        },
        {
            "id": "task1540-a336b29f635e48f99177a60df1868022",
            "input": "In this paper, we propose a novel unsupervised deep learning model, called PCA-based Convolutional Network (PCN). The architecture of PCN is composed of several feature extraction stages and a nonlinear output stage. Particularly, each feature extraction stage includes two layers: a convolutional layer and a feature pooling layer. In the convolutional layer, the filter banks are simply learned by PCA. In the nonlinear output stage, binary hashing is applied. For the higher convolutional layers, the filter banks are learned from the feature maps that were obtained in the previous stage. To test PCN, we conducted extensive experiments on some challenging tasks, including handwritten digits recognition, face recognition and texture classification. The results show that PCN performs competitive with or even better than state-of-theart deep learning models. More importantly, since there is no back propagation for supervised finetuning, PCN is much more efficient than existing deep networks.",
            "output": [
                "A PCA-Based Convolutional Network"
            ]
        },
        {
            "id": "task1540-54c85df71cfe4920bd760283f3665f43",
            "input": "String getQueueName(); abstract Serializable getCommandObject(Long workflowInstanceId,Serializable getCommandObject(Long workflowInstanceId, String taskName, String messageType, ExecutionContext context);",
            "output": [
                "Automatic Structure Discovery for Large Source Code"
            ]
        },
        {
            "id": "task1540-a30c625850894a7c95fed9fe3253da05",
            "input": "Wide-angle sonar mapping of the environ­ ment by mobile robot is nontrivial due to sev­ eral sources of uncertainty: dropouts due to \"specular\" reflections, obstacle location un­ certainty due to the wide beam, and distance measurement error. Earlier papers address the latter problems, but dropouts remain a problem in many environments. We present an approach that lifts the overoptimistic in­ dependence assumption used in earlier work, and use Bayes nets to represent the depen­ dencies between objects of the model. Ob­ jects of the model consist of readings, and of regions in which \"quasi location invari­ ance\" of the (possible) obstacles exists, with respect to the readings. Simulation supports the method's feasibility. The model is readily extensible to allow for prior distributions, as well as other types of sensing operations.",
            "output": [
                "Bayes Networks for Sonar Sensor Fusion"
            ]
        },
        {
            "id": "task1540-8455255ba92c449baaf64de51f2d519a",
            "input": "Multi-agent path planning is a challenging problem with numerous real-life applications. Running a centralized search such as A* in the combined state space of all units is complete and cost-optimal, but scales poorly, as the state space size is exponential in the number of mobile units. Traditional decentralized approaches, such as FAR and WHCA*, are faster and more scalable, being based on problem decomposition. However, such methods are incomplete and provide no guarantees with respect to the running time or the solution quality. They are not necessarily able to tell in a reasonable time whether they would succeed in finding a solution to a given instance. We introduce MAPP, a tractable algorithm for multi-agent path planning on undirected graphs. We present a basic version and several extensions. They have low-polynomial worst-case upper bounds for the running time, the memory requirements, and the length of solutions. Even though all algorithmic versions are incomplete in the general case, each provides formal guarantees on problems it can solve. For each version, we discuss the algorithm’s completeness with respect to clearly defined subclasses of instances. Experiments were run on realistic game grid maps. MAPP solved 99.86% of all mobile units, which is 18–22% better than the percentage of FAR and WHCA*. MAPP marked 98.82% of all units as provably solvable during the first stage of plan computation. Parts of MAPP’s computation can be re-used across instances on the same map. Speed-wise, MAPP is competitive or significantly faster than WHCA*, depending on whether MAPP performs all computations from scratch. When data that MAPP can re-use are preprocessed offline and readily available, MAPP is slower than the very fast FAR algorithm by a factor of 2.18 on average. MAPP’s solutions are on average 20% longer than FAR’s solutions and 7–31% longer than WHCA*’s solutions.",
            "output": [
                "MAPP: a Scalable Multi-Agent Path Planning Algorithm with Tractability and Completeness Guarantees"
            ]
        },
        {
            "id": "task1540-cd2d8fdedd3f4f49867eaabc3b86f5fc",
            "input": "Message-passing algorithms have emerged as powerful techniques for approximate inference in graphical models. When these algorithms converge, they can be shown to find local (or sometimes even global) optima of variational formulations to the inference problem. But many of the most popular algorithms are not guaranteed to converge. This has lead to recent interest in convergent message-passing algorithms. In this paper, we present a unified view of convergent message-passing algorithms. We present a simple derivation of an abstract algorithm, tree-consistency bound optimization (TCBO) that is provably convergent in both its sum and max product forms. We then show that many of the existing convergent algorithms are instances of our TCBO algorithm, and obtain novel convergent algorithms “for free” by exchanging maximizations and summations in existing algorithms. In particular, we show that Wainwright’s non-convergent sum-product algorithm for tree based variational bounds, is actually convergent with the right update order for the case where trees are monotonic chains.",
            "output": [
                "Convergent message passing algorithms - a unifying view"
            ]
        },
        {
            "id": "task1540-2e3e1dae85454279934e70fa39f057fd",
            "input": "Electric water heaters have the ability to store energy in their water buffer without impacting the comfort of the end user. This feature makes them a prime candidate for residential demand response. However, the stochastic and nonlinear dynamics of electric water heaters, makes it challenging to harness their flexibility. Driven by this challenge, this paper formulates the underlying sequential decision-making problem as a Markov decision process and uses techniques from reinforcement learning. Specifically, we apply an auto-encoder network to find a compact feature representation of the sensor measurements, which helps to mitigate the curse of dimensionality. A wellknown batch reinforcement learning technique, fitted Q-iteration, is used to find a control policy, given this feature representation. In a simulation-based experiment using an electric water heater with 50 temperature sensors, the proposed method was able to achieve good policies much faster than when using the full state information. In a lab experiment, we apply fitted Q-iteration to an electric water heater with eight temperature sensors. Further reducing the state vector did not improve the results of fitted Q-iteration. The results of the lab experiment, spanning 40 days, indicate that compared to a thermostat controller, the presented approach was able to reduce the total cost of energy consumption of the electric water heater by 15%.",
            "output": [
                "Reinforcement Learning Applied to an Electric Water Heater: From Theory to Practice"
            ]
        },
        {
            "id": "task1540-5d70bf272e8840c7b83f779d45dffcb0",
            "input": "The online learning of deep neural networks is an interesting problem of machine learning because, for example, major IT companies want to manage the information of the massive data uploaded on the web daily, and this technology can contribute to the next generation of lifelong learning. We aim to train deep models from new data that consists of new classes, distributions, and tasks at minimal computational cost, which we call online deep learning. Unfortunately, deep neural network learning through classical online and incremental methods does not work well in both theory and practice. In this paper, we introduce dual memory architectures for online incremental deep learning. The proposed architecture consists of deep representation learners and fast learnable shallow kernel networks, both of which synergize to track the information of new data. During the training phase, we use various online, incremental ensemble, and transfer learning techniques in order to achieve lower error of the architecture. On the MNIST, CIFAR-10, and ImageNet image recognition tasks, the proposed dual memory architectures performs much better than the classical online and incremental ensemble algorithm, and their accuracies are similar to that of the batch learner. ICML workshop on Deep Learning 2015, Lille, France, 2015. Copyright 2015 by the author(s).",
            "output": [
                "Dual Memory Architectures for Fast Deep Learning of Stream Data via an Online-Incremental-Transfer Strategy"
            ]
        },
        {
            "id": "task1540-699fa37c8bdf461db66c11f940a3db70",
            "input": "Humans are generally good at learning abstract concepts about objects and scenes (e.g. spatial orientation, relative sizes, etc.). Over the last years convolutional neural networks have achieved almost human performance in recognizing concrete classes (i.e. specific object categories). This paper tests the performance of a current CNN (GoogLeNet) on the task of differentiating between abstract classes which are trivially differentiable for humans. We trained and tested the CNN on the two abstract classes of horizontal and vertical orientation and determined how well the network is able to transfer the learned classes to other, previously unseen objects.",
            "output": [
                "Learning Abstract Classes using Deep Learning"
            ]
        },
        {
            "id": "task1540-39489b2925364fa6adca424e90aef6a0",
            "input": "Analysis of scripts plays an important role in paleography and in quantitative linguistics. Especially in the field of digital paleography quantitative features are much needed to differentiate glyphs. We describe an elaborate set of metrics that quantify qualitative information contained in characters and hence indirectly also quantify the scribal features. We broadly divide the metrics into several categories and describe each individual metric with its underlying qualitative significance. The metrics are largely derived from the related area of gesture design and recognition. We also propose several novel metrics. The proposed metrics are soundly grounded on the principles of handwriting production and handwriting analysis. These computed metrics could serve as descriptors for scripts and also be used for comparing and analyzing scripts. We illustrate some quantitative analysis based on the proposed metrics by applying it to the paleographic evolution of the medieval Tamil script from Brahmi. We also outline future work. Quantifying Scripts: Defining metrics of characters for quantitative and descriptive analysis Vinodh Rajan University of St Andrews vrs3@st-andrews.ac.uk Introduction Scripts are usually seen as simple carriers of languages. Research on scripts until recently has been minimal and niche, except for the field of paleography. Scripts are however an important part of the cultural heritage of humanity and their analysis and study requires more research. Fortunately, there is a growing interest in analysis of scripts. Altmann et al. (2008) explore various properties of writing systems and scripts such as complexity, ornamentality and distinctivity. Changizi et al. (2006) discuss the various contour configurations of written symbols and their similarity to the environment in which they were produced. They also study the distribution of the configurations of various scripts. Changizi et al. (2005) further discuss the character complexity and the redundancy of stroke combinations of various writing systems in human history. Traditionally, analysis and study in paleography have been mostly qualitative and also done manually. Digital paleographic methods are at present making more inroads into the field. However, applying quantitative analysis on paleographic data is not yet popular and standardized (Stokes, 2009). This is partially due to the difficulty of quantifying paleographical features, and partially due to the lack of defined metrics with theoretical and qualitative underpinnings. Scripts, being visual representation of languages, carry both linguistic and supralinguistic information. Linguistic information is closely tied to the language(s) that the scripts represent. Properties such as the phonetic valency of a character and the grapheme-to-phoneme ratio of a script can be classified as linguistic information. As supralinguistic information, apart from the visual appearance of a character, scripts importantly encapsulate handwriting behavior. In case of a particular glyphic set, they can be considered to encapsulate the handwriting behavior of a particular scribe. In this paper, we do not consider the phonetic information contained in scripts. The phonetic information is very tightly tied to a language and quite variable. We are more focused on scripts as a set of handwritten visual symbols. In digital paleography and manuscript studies, the visual properties of a character are often more important than its phonetic properties. In these fields it is far more important to study the handwriting features for dating characters or even assigning characters to a particular scribe. We attempt to quantify and extract such information contained within a character. The handwriting behavior contained in scripts is complex. The inter-relation between the various properties in scripts could be studied in detail. Such analysis of inter-relations could help us to identify some salient features that define handwriting behavior in humans such as those that associate glyph production and visual appearance and also throw more light on to the production of human handwriting. Multivariate analysis on the features can also help us to identify more generic features that capture salient features of scripts. In case of paleographic scripts, especially, evaluating changes in properties over a period of time would show the general trend of convergence or divergence of features for a script and also their correlations. This is useful for human computer interaction, which requires designing gesture sets with optimal features – both visual and production. 2. Definitions Let us define script as a cohesive set of visual characters. A character in turn is any written symbol. A glyph is a particular visual representation of a character, which may deviate considerably from the normalized form of the character. Trajectory is the dynamic information corresponding to pen movements of the character. A stroke is the primitive of the handwriting process and composite-stroke is that which is composed of multiple primitive strokes. A pen-drag is movement of the pen between the intermediate pen-up and pen-down events in multistroke characters. Let the term metric denote the measure that attempts to quantify a particular property of a character. We can divide metrics into two types – absolute & derived. Absolute metrics are derived directly from the structure of a character based on a particular property or feature. In many cases such as those involving length these are not scale invariant. Therefore it may be required to normalize them before some statistical operations. Derived metrics are often ratios between two absolute metrics. This is very similar to dimensionless numbers, which play an important role in several fields of engineering. The basic premise is that ratios of two metrics capture information that is more helpful than the individual metrics. 3. Representation of Characters Before we turn to various metrics and their derivations, we discuss the representation of characters from which the metrics are derived. Computationally, the “static” shape of a character is represented as a set of B-splines. Bsplines are mathematical objects often used to represent complicated curves. They are known to accurately represent the curvature and shape of handwritten characters (Morasso et al., 1982). Additionally, they can be manipulated with minimal effort and it is computationally easy to derive properties from B-spline representations. This conversion of glyphic shape of a character to B-splines can be done automatically or manually. In a manual process, the user defines each shape of a character directly using a set of B-splines, or explicitly draws the shape (for instance, using a drawing tablet), which is then internally converted into B-splines. An automatic conversion of a character involves thinning and then its conversion into splines. Overall, the entire process results in representation of the character’s shape as a set of glyphic segments through B-splines. Figure 1 shows a character represented as a set of 5 glyphic B-spline segments. Fig. 1 Representation of a character as a set of 5 B-splines We consider the handwritten production of characters to be the fundamental information that is contained within that character. This requires that the character be decomposed into its primitives namely strokes, which are involved in the production of characters. This is consistent with the way that the character is internalized and produced by humans. Edelman et al. (1987) decompose characters into four different basic template strokes hook, cup, gamma and oval. We feel such predefined decomposition do not result in the creation of proper primitives. Writing is a natural process consisting of individual unique strokes, which cannot be reduced to a set of predefined templates. Changizi et al. (2006) decomposes the characters into “separable strokes” using three subjects who decide (unanimously) on the decomposition. An objective decomposition of the characters would be much more theoretically valid and also reproducible rather than relying on some underlying unknown subjective criterion. We perform such an objective decomposition of characters into their primitive strokes using the written trajectory of the characters. For contemporary scripts the trajectory information is often known. But with paleographic scripts the trajectory is usually unknown but can be reasonably reconstructed with computational methods using their static shape (Doermann, 1992). By conducting a global search with a set of heuristics that attempts to minimize the effort required to produce the script, we attempt to reconstruct the trajectory (Jäger, 1996). Especially in case of paleographic scripts, the algorithm is able to provide several alternative viable written trajectories, among which the most viable trajectory is chosen. Fig. 2 Velocity profile of S and the associated stroke delineation at points of extreme curvature (Kandel et al., 2010) Writing a character is not a discrete but rather continuous process where the individual strokes overlap and compose to form the character (Morasso et al., 1981). Based on the character’s trajectory, we proceed to find specific points where the (apparent) primitive individual strokes connect. Physically, handwriting is a ballistic activity with each stroke corresponding to a bell-shaped velocity profile. It consists of an acceleration phase, velocity phase and a deceleration phase (Teulings, 1993). Therefore the process of writing a character consists of several contiguous bell shaped velocity profiles corresponding to each stroke. This velocity profile of the character can be roughly predicted from the shape of the character. It is shown that the minimal velocity points occur at points where curvature is maximum or minimum (Li et al., 1998) and also where strokes are explicitly delineated such as sharp junctions. The extreme points of curvature are automatically detected, and if necessary can also be manually overridden. The character is then segmented to basic strokes at all these points where the strokes overlap and/or connect, which we refer to as Landmark Points. In this way, we produce a natural set of primitive strokes unique to each script. This also results in the creation of a stroke-inventory for that particular script, which can be used for other types of analysis. In case of multi-stroke characters, the pen-drag between the individual strokes is included as an additional invisible stroke as it involves movement of hands also. Figure 2 illustrates the segmentation of ‘S’. Fig 3 and 4. Character with bounding box along with the points where the strokes are disjoined and Character with the written trajectory of the character along with points where primitive strokes This results in a new but more natural stroke-based representation of characters, which are aptly derived from their trajectories. In this new representation, the characters are composed of strokes rather than glyphic segments. The stroke primitives are also represented as B-splines similar to the glyphic segments in the original input shape. It is from this new stroke based representation that the metrics are computationally derived. Figures 3 and 4 illustrate decomposition of a character. It is also quite possible to derive features based on a pixelated or even a contour representation of a character but we consider that not to be an accurate and natural representation of a character. Features derived from these representations such as pixel density do not accurately represent the process behind the production of the character. They are more focused towards the visual aspect of the character and the features derived are more subtle and nuanced, which may be more suitable to machine recognition. Such metrics cannot always be correlated with some explicit qualitative features as perceived by humans. The stroke-based representation of the character is much more natural and apt representation of the character, capturing accurately both the static and dynamic information contained within the character. 4. Information in Characters As discussed earlier, characters contain several kinds of information within them pertaining to their production, appearance and cognition. We attempt to extract this information from a character. Previously, attempts have been made to extract “features” in the context of pattern recognition. Rubine (1991) proposes a set of 14 “features” for the purpose of pattern recognition in gesture recognition systems. Long et al. (2000) similarly define 22 “features” expanding on the original features proposed by Dean (1991). Willems et al. (2008) perform a very elaborate literature review on different types of features and propose several new features of their own. They elaborate on 90 different features in total for online unistroke pen-gesture recognition. This entire feature set was later distilled to 49-base features that are optimal for online symbol recognition (Delaye et al., 2013). Willems et al. (2009) also suggest additional features that pertain to multi-stroke pattern recognition. It can be seen though there is plethora of features but none of them is particularly aimed at quantifying any specific property of characters and provides substantial elaborate qualitative underpinnings for those features in terms of handwriting. They were mostly proposed as pure “statistical” features to construct feature vectors for pattern recognitions systems. However, there were some preliminary applications of these features for semantic analysis. Long et al. (2000) use their proposed features to analyze the subjective similarity of the gestures but they do it indirectly using multi-dimensional scaling (MDS), while Vatavu et al. (2011) used some of the features to correlate with “perceived execution difficulty” of gestures. We carried out a survey of all such features used in the field of handwriting analysis and gesture analysis as listed above. We carefully studied each of the features and chose the metrics that have qualitative real-world significance and that can be directly related to properties of characters. We rejected very abstract mathematical features that do not have any direct qualitative significance. Many of the rejected features were artificially created as part of “feature construction” to increase the number of features in the feature vector, which is a common process in the field of pattern recognition. This process of “feature construction” is usually performed by applying mathematical functions such as logarithms on some basic features. 4.1 Visual Information Visual information directly pertains to the appearance of a character. The following metrics are solely derived from the static shape of the character. The metrics defined below also partially quantify some production properties along with the visual property of the character. 4.1.1 Length This is the total length of the character. In case of unistroke characters, this is calculated as the sum of the individual stroke lengths. For multistroke characters, this includes the previous sum and also the movement during the pen-drag, which is approximated to a straight line. Length quantifies the entire movement of the pen required to produce the character. 4.1.2 Divergence Divergence is defined as distance between the position of the first pen-down event and the last pen-up event. This metric quantifies the movement of the pen between those two events measuring how much the pen has visually “diverged” from its original starting position. This is one of the important features that could be specific to a scribe. 4.1.3 Size Size is measured by the bounding box area of a character. The bounding box is the minimal rectangle that encloses the given character (See figure 3). This could be directly correlated with the “largeness” of the character and hence the term “size”. The bigger the bounding box, the larger is the size of the character. 4.1.4 Length-Breadth Index This is the ratio of the bounding box’s height to the bounding box’s width. This approximates the shape aspect of the character i.e. slender/broad etc. 4.1.5 Average Curvature This metric is calculated by averaging the curvature at all points of the character’s strokes. The Bspline representation allows easy calculation of the curvature at each point of the curve. A straight stroke will have a curvature of zero compared to a curved stroke, which will have a higher curvature. Thus curved characters tend to have a higher average curvature compared to a character with less curves and/or more straight lines. 4.1.6 Compactness This is a derived metric. Compactness of a character is defined as the ratio between length and the size. In some sense, it defines how compact (or dense) a character appears and directly corresponds to the number of strokes that a scribe is trying to fit within a given area. This makes it a very interesting metric to consider with characters. Some scribes may space out the character during production while others may tend to “compact” the strokes within a small area. 4.1.7 Openness This is also a derived metric. Openness of a character can be defined as the ratio between divergence and length. This measures the movement of the pen with respect to its starting point and ending point and the length of the character. We could study the ending point of the character being varied with the length of the character. The actual metric suggested by Long et al. (2001) is the ratio of divergence to the size. However, this does not appear to be very ideal. It is better to compare different aspects of pen-movements (rather than the area). 4.1.8 Distinctivity Several ways have been proposed to compare the appearance of characters. Jan Macutek et al. (2008) propose a very idiosyncratic way of calculating the distinctivity of the characters, which involves decomposing characters into basic templates and then comparing the permutations of the decomposed components. In several OCR techniques, pixel based techniques such as the image distortion model are frequently employed to calculate the similarity between the characters. Similarity (or lack thereof) is usually calculated using the cost of transformation between two entities. Entities possessing similar representations are readily transformed into one another, whereas transforming between dissimilar entities requires many transformations (Hahn et al., 2003). Thus the distinctivity between characters is directly proportional to the transformations required to make them similar. We propose to use the Dynamic Time Warping (DTW) distance (Muller, 2007) to calculate the distinctivity between two characters. DTW is traditionally employed to compare two temporal sequences, which may vary in time or speed. This makes an ideal metric to measure the difference between two characters. DTW attempts to align two sequences and calculates the cost for the alignment. The higher the DTW cost the more distinct are the signs from each other. This measure can be applied on the trajectory data or the static data. The former gives the distance based on appearance, the latter on production. 4.1.9 Ascendancy & Descendance Some scripts have baselines. The percentages of the length of characters above and below baselines are defined as Ascendancy and Descendance respectively. 4.1.10 Circularity & Rectangularity In many cases, the shapes of the characters appear to approach an ideal geometric shape. We attempt to measure such approximations. Circularity and Rectangularity could be defined as the deviation of the character’s outline shape from that of an ideal circle and rectangle respectively. For circularity, we take the ratio of the area of the convex hull and the area of the minimal circle that encloses the character. Similarly, rectangularity can be calculated from the ratio between the area of convex hull and that of the bounding box. 4.2 Visual Complexity Visual complexity can be defined as the effort required to decode and to recognize a given sign (Kohler, 2008). Some characters are perceived as complex and others as simple. Altman (2004) has proposed a technique, in which a character is decomposed into lines, arches and curves with each component assigned a weight. The sum of the weight is calculated as the quantified complexity. Peust (2006) has also proposed a complexity measure by counting the number of intersections that a character has with a straight line. These techniques do not appear to be rigorous however and are not supported by any empirical studies. Similarly, using structural information theory (SIT) there have been proposals to quantify the “load” of a character. The higher the “load”, the more complex the character is to be perceived. It involves measuring repeating patterns and weights being assigned to angles of junctions (Hanssen et al., 1993). While SIT can easily work for simple geometrical shapes, extending them for complex shapes such as characters is very hard and possibly not very practical. The methods described previously attempt to quantify a very abstract notion, namely the “Visual Complexity”. It is a very subjective measure as compared to others. People with exposure to different writing systems could quantify the complexity of a character in very different ways. Hence instead of aiming for complete quantification of character complexity, we propose to quantify only the factors that contribute to the visual appearance of a character. Using multidimensional techniques such as parallel co-ordinates we could trace the change in factors that contribute to the visual appearance. Along with the previously listed factors, we list also the following factors, sum of interstroke angles and number of crossings, which may contribute to visual complexity. 5. Dynamic Information Apart of the static shape of a character we need to also consider its dynamics. The character’s kinematic (or temporal) information is essential in defining it. It dictates how the character is produced through the process of handwriting. Thus, deriving metrics quantifying properties of its production is very much important. 5.1 Stroke Counts It is a fundamental metric to count the number of hand motions required to write the characters. Humans consistently attempt to minimize the number of hand-movements to write characters (Saloman, 2012). It is an interesting metric to analyze for the distribution across various scripts. Apart from the count of the primitive strokes, there are two more composite-stroke metrics that could be considered – pen-strokes & disjoined strokes. The former is the absolute hand movements required to write characters without a pen-up even and the latter is the composite-strokes that are delineated at sharp-junctions. For instance, figures 3 & 4 show a character with 1 pen-stroke, 3 disjoined strokes and 8 primitive strokes. We could also include retraces in the count, where the same stroke is traced successively in the opposite direction. Movement 3 in figure 4 is the retracing stroke. 5.2 Stroke Length The distribution of the length of individual strokes and also calculating the average stroke length is a very purposeful measure with respect to the analysis of writing. The average stroke length is a variable entity across different scripts or scribes. 5.3 Changeability Handwriting consists of up-strokes and down-strokes. They are of two different characteristics with completely different physiological process of production. It has been shown up-strokes are susceptible to change, while down-strokes are considered invariant (Teulings, 1993) and more stable (Maarse 1983). Upstrokes are faster (Isokoski, 2001) and hence perhaps less stable. Maarse et al. (1983) defines strokes that are produced between 210° and 280° to be downstrokes. The range of angles appears to be very restrictive (as it considered only Roman handwriting). Hence, we have included strokes which are pointed downwards within 210° and 330° as down-strokes and all non-down strokes are included as up-strokes. So the ability of the character to change i.e. changeability can be directly tied to the ratio of upstrokes’ length to that of the down-strokes’ length. If the ratio is high the character can be considered susceptible to change. Thus changeability as a metric is related to a character’s susceptibility to change. 5.4 Disfluency As discussed earlier, writing is a ballistic activity. It is known that handwriting fluency is affected at points where curvature is at its maximum/minimum. The transition between down-strokes and upstrokes is also considered to slow down the writing process. The number of sharp junctions in a character also contributes to the slowing of velocity during the handwriting production. The sum of all points that affect velocity – curvature extrema, sharp-junctions, and intermediate pen-up events is termed as disfluency. This can directly correspond to the difficulty in terms of writing the character. A character with higher number of disfluent points is harder to produce as the velocity is frequently interrupted. Similar measures have been used with actual dynamic handwriting velocity data to assess handwriting fluency of people by measuring the number velocity slow-downs happening (Tucha, 2008). Character in figures 3 & 4 has 6 disfluent points. In fact, the number of disjoined points can be taken as separate metric all together, since its effect on slowing down the production is higher than that of the other points. 5.5 Entropy In information theory, entropy is defined as the average amount of information contained within an entity. This amount of information in the system is directly proportional to the randomness or disorderliness present in the system. When there are several instances of change, it results in increase of entropy as it contains more information (Aksentijevic et al., 2012). To calculate the entropy of a character the trajectory of the character is “quantized” into Hoffman codes denoting the major eight directions. Assigning a Hoffman code to the individual strokes performs this. The eight Hoffman codes correspond to the following directions N, S, E, W, NE, NW, SE, and SW. The sample character in Figure 3 can be quantized into [N E W S NW SE SW]. Entropy is calculated based on the following formula (Bhat et al., 2009): H(s) = Σ p(si) loge p(si) Where, p(si) is the probability of a stroke. It is given by ratio of the count of the given stroke (in the character) to that of the total number of strokes. Any character with a sufficient number of repeating patterns will record low entropy and those with no patterns high entropy. Thus the entropy of characters conveys the randomness associated with the pen movements required to produce the character. 5.6 N-Gram model of scripts Writing a character can be very well considered to be similar to that of constructing a sentence. While sentences are made up of words, characters are made of strokes. We here seek to apply some aspects of natural language processing to scripts. N-gram modeling is frequently used in natural language processing for a wide variety of purposes. N-gram model is a probabilistic model to predict the next item in a sequence (Fink, 2014). As the number of stroke combination is usually low, a bigram model would better to model script behavior. The n-gram model provides an opportunity to derive several metrics. It is now possible to calculate the entropy of a script as opposed to that of a character and also allows us to study the regularity of stroke combinations. 5.7 Angle-Based Metrics Analyzing the different angles of strokes occurring in scripts can throw more light on a particular scribal behavior. We define a few important angle-based metrics that could be used. Major Angle would be the angle of the major primitive stroke present in the character. The initial angle is defined with the initial stroke of a character. The divergence angle Angle between first and last points could also be considered as a metric. For multi-stroke characters, angle of pen-drag can be an important measure. Inter-stroke angles could be plotted as a histogram to see the changes. 5.8 Pen-Drag Distance The Pen-drag Distance is a metric with respect to multi-stroke behavior. This captures the hand movements between pen-strokes, which are an important part of multi-stroke production. 6. Cognitive Information Writing a character is usually a top-down process. A character has to be memorized and then reproduced. Consequently, this requires elaborate trajectory planning. We need to find out the approximate information required to cognitively memorize and produce characters. In this respect, we refer to the Algorithmic Information Theory (AIT). Especially within AIT, Kolmogorov complexity attempts to find the minimal description of a given sequence (Wallace et al., 1999). In a similar way, we attempt to find out the minimal representation of a character required to reproduce it. Theoretically, these would be the points necessary to plan the trajectory of the character. In fact, this directly corresponds to the “Landmark Points” in the character, as those are the points that define its shape. Isokoski (2001) measured the complexity of characters, by studying the number straight of lines required to approximate a character. But again this was a subjective measure. In lieu of this, the number of landmark points required in a character could be considered a direct theoretical implementation of Isokoski’s complexity. Do note that this is an approximation. The proximity and distribution of the landmark points may affect the information contained in the character (for instance, if several points are very close to each other it might create additional confounding factors to the planning of the trajectory, which will increase the information content). But for now, we ignore such intricate details. These need to be studied in detail later. The Ramer-Douglas-Peucker (RDP) algorithm (Douglas et al., 1956) also computes the minimum number of points required to approximate a given curve. This mostly agrees with the number of landmark points in some case, but in other cases this might not be case so. The issue with RDP is that a threshold for approximation needs to be provided and it might provide a slight overestimation of the points required for approximation. Both the RDP and Number of Landmark points can be considered as different metrics that correspond to the cognitive information present in a character and could be used as required. 7. Metrics of Scripts Vs. Metrics of Characters Most of the metrics discussed in the paper were confined to that of individual characters. However, as defined earlier, a script is a cohesive set of characters. In many cases, the metric of the script could be found just by averaging the metric of the individual characters. For instance, it would be possible to discuss the average curvature of a script and even compare them. Characters within a script are usually a heterogeneous set with different purposes and different patterns of usage. Hence, an average metric for the script may not always make sense. In such cases, instead of averaging the metrics, it is more useful to study the distribution of a metric in different scripts. Since characters within a script behave as a set, studying the homogenization (or divergence) of properties within the script is a useful exercise. It would also be more useful if this could be overlaid with some other information such as usage frequency of the characters. For instance, an interesting analysis would be to see how the various properties of frequently used characters differ with respect to rarely used characters or indeed, if any such difference exists at all. 8. Development of Medieval Tamil from Brahmi – A Quantitative Analysis Fig. 5a Digitized Tamil 1 Script Fig. 5b Digitized Tamil 2 Script Fig. 5c Digitized Tamil 3 Script For illustrating the quantitative analysis that can be performed with the proposed metrics, we take the medieval Tamil script in 3 different stages of evolution beginning from Brahmi (Ojha, 1964). We have developed a prototype application that implements the discussed representation of a character and derives appropriate metrics from characters. The paleographic characters were digitized using our framework and stored. We then proceeded to reconstruct the trajectories, to segment them into strokes and to extract the required metrics. We have attempted to use some of the major metrics discussed to keep the section succinct. We hope that paleographers and quantitative linguists may find various other ways to use these metrics (and other proposed metrics) to support their analyses as they may require. Figures 5a, 5b and 5c show the medieval Tamil script in 3 different stages of evolution. We refer to them as Tamil 1 (figure 5a), Tamil 2 (figure 5b) and Tamil 3 (figure 5c) respectively. 8.1 Changes in Visual Features Fig. 6 Parallel co-ordinate plot for mean values ofthe different visual features – Tamil 1 (Red), Tamil2 (Blue) and Tamil 3 (Green) Fig. 7: Parallel Co-ordinate plot for the entire character set in Tamil 1, Tamil 2 and Tamil 3 Figure 6 shows the parallel co-ordinate plot for mean values of the different visual features of the 3 scripts. Tamil 1 starts out with the base arrangement of high compactness and openness and a low curvature with the characters being more slender (as noted by the low LB Index). But inadvertently the features appear to have quite divorced from their initial appearance. They have become more and more symmetrical sized, less compact, with strokes being augmented and less open with increase in average curvature. One interesting point here to be noted is that Tamil 2 starting leaning towards being curved and ended up becoming extremely curved by a very large magnitude as much as Tamil 3. This probably resulted from the scribes trying to make the script look more elegant or perhaps due to the change in implement (and writing material). From figure 7 it can also be seen that compactness and openness appear to be tightly related (at least for the scripts under discussion). 8.2 Distribution of Entropy Figures 8a, 8b and 8c show the distribution of entropy across the scripts as histograms. As the script evolved over time, it appears to have gained information through stroke augmentations, hence the change in distribution skewing towards the right (See Tamil 2). But in the final medieval version of the script, some information content gained appears to have been lost. This can be attributed to the fact that the stroke patterns were later developed. Also, in some characters some strokes were later lost. Fig 8a: Distribution of Character Entropies for Tamil 1 Fig 8b: Distribution of Character Entropies for Tamil 2 Fig 8c: Distribution of Character Entropies for Tamil 3",
            "output": [
                "Quantifying Scripts: Defining metrics of characters for quantitative and descriptive analysis"
            ]
        },
        {
            "id": "task1540-e73afcf07016437eb858b104433e99c3",
            "input": "Recent years have seen the development of a number<lb>of methods for multiagent planning under uncertainty<lb>that scale to tens or even hundreds of agents. However,<lb>most of these methods either make restrictive assump-<lb>tions on the problem domain, or provide approximate<lb>solutions without any guarantees on quality. To allow<lb>for meaningful benchmarking through measurable qual-<lb>ity guarantees on a very general class of problems, this<lb>paper introduces a family of influence-optimistic upper<lb>bounds for factored Dec-POMDPs. Intuitively, we de-<lb>rive bounds on very large multiagent planning problems<lb>by subdividing them in sub-problems, and at each of<lb>these sub-problems making optimistic assumptions with<lb>respect to the influence that will be exerted by the rest<lb>of the system. We numerically compare the different<lb>upper bounds and demonstrate how, for the first time<lb>ever, we can achieve a non-trivial guarantee that the<lb>heuristic solution of problems with hundreds of agents<lb>is close to optimal. Furthermore, we provide evidence<lb>that the upper bounds may improve the effectiveness of<lb>heuristic influence search, and discuss further potential<lb>applications to multiagent planning.",
            "output": [
                "Influence-Optimistic Local Values for Multiagent Planning — Extended Version"
            ]
        },
        {
            "id": "task1540-7400ef453f0449228bf964f281ad8e86",
            "input": "Graph-based representations of images have recently acquired an important role for classification purposes within the context of machine learning approaches. The underlying idea is to consider that relevant information of an image is implicitly encoded into the relationships between more basic entities that compose by themselves the whole image. The classification problem is then reformulated in terms of an optimization problem usually solved by a gradient-based search procedure. Vario-eta through structure is an approximate second order stochastic optimization technique that achieves a good trade-off between speed of convergence and the computational effort required. However, the robustness of this technique for large scale problems has not been yet assessed. In this paper we firstly provide a theoretical justification of the assumptions made by this optimization procedure. Secondly, a complexity analysis of the algorithm is performed to prove its suitability for large scale learning problems.",
            "output": [
                "Complexity Analysis of Vario-eta through Structure"
            ]
        },
        {
            "id": "task1540-3774f2b164f74c6093be22085b9651c7",
            "input": "An algorithm for pose and motion estimation using corresponding features in omnidirectional images and a digital terrain map is proposed. In previous paper, such algorithm for regular camera was considered. Using a Digital Terrain (or Digital Elevation) Map (DTM/DEM) as a global reference enables recovering the absolute position and orientation of the camera. In order to do this, the DTM is used to formulate a constraint between corresponding features in two consecutive frames. In this paper, these constraints are extended to handle non-central projection, as is the case with many omnidirectional systems. The utilization of omnidirectional data is shown to improve the robustness and accuracy of the navigation algorithm. The feasibility of this algorithm is established through lab experimentation with two kinds of omnidirectional acquisition systems. The first one is polydioptric cameras while the second is catadioptric camera.",
            "output": [
                "Pose and Motion from Omnidirectional Optical Flow and a Digital Terrain Map€"
            ]
        },
        {
            "id": "task1540-ddfba62ccaf84680bec10e24c6a6960b",
            "input": "We develop a new semantics for defeasible infer­ ence based on extended probability measures al­ lowed to take infinitesimal values, on the inter­ pretation of defaults as generalized conditional probability constraints and on a preferred-model implementation of entropy-maximization.",
            "output": [
                "Defaults and lnfinitesimals Defeasible Inference by Nonarchimedean Entropy Maximization"
            ]
        },
        {
            "id": "task1540-ecff8c488d72476692a1011b4324d921",
            "input": "Joint attention is a core, early-developing form of social interaction. It is based on our ability to discriminate the third party objects that other people are looking at. While it has been shown that people can accurately determine whether another person is looking directly at them versus away, little is known about human ability to discriminate a third person gaze directed towards objects that are further away, especially in unconstraint cases where the looker can move her head and eyes freely. In this paper we address this question by jointly exploring human psychophysics and a cognitively motivated computer vision model, which can detect the 3D direction of gaze from 2D face images. The synthesis of behavioral study and computer vision yields several interesting discoveries. (1) Human accuracy of discriminating targets 8°-10° of visual angle apart is around 40% in a free looking gaze task; (2) The ability to interpret gaze of different lookers vary dramatically; (3) This variance can be captured by the computational model; (4) Human outperforms the current model significantly. These results collectively show that the acuity of human joint attention is indeed highly impressive, given the computational challenge of the natural looking task. Moreover, the gap between human and model performance, as well as the variability of gaze interpretation across different lookers, require further understanding of the underlying mechanisms utilized by humans for this challenging task. * Tao Gao and Daniel Harari contributed equally to this work. When Computer Vision Gazes at Cognition Tao Gao∗, Daniel Harari∗ †, Joshua Tenenbaum∗, Shimon Ullman∗ † ∗ Center for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, MA † Weizmann Institute of Science, Rehovot, Israel",
            "output": [
                "When Computer Vision Gazes at Cognition"
            ]
        },
        {
            "id": "task1540-3ec14676ccbe45488bd6905ee85df52d",
            "input": "Time-series classification is an important problem for the data mining community due to the wide range of application domains involving time-series data. A recent paradigm, called shapelets, represents patterns that are highly predictive for the target variable. Shapelets are discovered by measuring the prediction accuracy of a set of potential (shapelet) candidates. The candidates typically consist of all the segments of a dataset, therefore, the discovery of shapelets is computationally expensive. This paper proposes a novel method that avoids measuring the prediction accuracy of similar candidates in Euclidean distance space, through an online clustering pruning technique. In addition, our algorithm incorporates a supervised shapelet selection that filters out only those candidates that improve classification accuracy. Empirical evidence on 45 datasets from the UCR collection demonstrate that our method is 3-4 orders of magnitudes faster than the fastest existing shapelet-discovery method, while providing better prediction accuracy.",
            "output": [
                "Scalable Discovery of Time-Series Shapelets"
            ]
        },
        {
            "id": "task1540-55fc203025d04a21ade3db9cdf7f05c6",
            "input": "A methodology for the development of a fuzzy expert system (FES) with application to earthquake prediction is presented. The idea is to reproduce the performance of a human expert in earthquake prediction. To do this, at the first step, rules provided by the human expert are used to generate a fuzzy rule base. These rules are then fed into an inference engine to produce a fuzzy inference system (FIS) and to infer the results. In this paper, we have used a Sugeno type fuzzy inference system to build the FES. At the next step, the adaptive network-based fuzzy inference system (ANFIS) is used to refine the FES parameters and improve its performance. The proposed framework is then employed to attain the performance of a human expert used to predict earthquakes in the Zagros area based on the idea of coupled earthquakes. While the prediction results are promising in parts of the testing set, the general performance indicates that prediction methodology based on coupled earthquakes needs more investigation and more complicated reasoning procedure to yield satisfactory predictions.",
            "output": [
                "A Fuzzy Expert System for Earthquake Prediction, Case Study: The Zagros Range"
            ]
        },
        {
            "id": "task1540-1ef5d6d25c47489b8cd69cee3c17ed87",
            "input": "This paper investigates the learning of 3rd-order tensors representing the semantics of transitive verbs. The meaning representations are part of a type-driven tensor-based semantic framework, from the newly emerging field of compositional distributional semantics. Standard techniques from the neural networks literature are used to learn the tensors, which are tested on a selectional preference-style task with a simple 2-dimensional sentence space. Promising results are obtained against a competitive corpus-based baseline. We argue that extending this work beyond transitive verbs, and to higher-dimensional sentence spaces, is an interesting and challenging problem for the machine learning community to consider.",
            "output": [
                "Learning Type-Driven Tensor-Based Meaning Representations"
            ]
        },
        {
            "id": "task1540-071576fc3a0440478ae96f46e3109635",
            "input": "<lb>Ordinal peer grading has been proposed as a simple and scalable solution for com-<lb>puting reliable information about student performance in massive open online courses.<lb>The idea is to outsource the grading task to the students themselves as follows. After<lb>the end of an exam, each student is asked to rank —in terms of quality— a bundle of<lb>exam papers by fellow students. An aggregation rule will then combine the individ-<lb>ual rankings into a global one that contains all students. We define a broad class of<lb>simple aggregation rules and present a theoretical framework for assessing their ef-<lb>fectiveness. When statistical information about the grading behaviour of students is<lb>available, the framework can be used to compute the optimal rule from this class with<lb>respect to a series of performance objectives. For example, a natural rule known as<lb>Borda is proved to be optimal when students grade correctly. In addition, we present<lb>extensive simulations and a field experiment that validate our theory and prove it to<lb>be extremely accurate in predicting the performance of aggregation rules even when<lb>only rough information about grading behaviour is available.",
            "output": [
                "How effective can simple ordinal peer grading be?∗"
            ]
        },
        {
            "id": "task1540-745199fd83274478910e16b8e12db086",
            "input": "Many optimization tasks have to be handled in noisy environments, where we cannot obtain the exact evaluation of a solution but only a noisy one. For noisy optimization tasks, evolutionary algorithms (EAs), a kind of stochastic metaheuristic search algorithm, have been widely and successfully applied. Previous work mainly focuses on empirical studying and designing EAs for noisy optimization, while, the theoretical counterpart has been little investigated. In this paper, we investigate a largely ignored question, i.e., whether an optimization problem will always become harder for EAs in a noisy environment. We prove that the answer is negative, with respect to the measurement of the expected running time. The result implies that, for optimization tasks that have already been quite hard to solve, the noise may not have a negative effect, and the easier a task the more negatively affected by the noise. On a representative problem where the noise has a strong negative effect, we examine two commonly employed mechanisms in EAs dealing with noise, the re-evaluation and the threshold selection strategies. The analysis discloses that the two strategies, however, both are not effective, i.e., they do not make the EA more noise tolerant. We then find that a small modification of the threshold selection allows it to be proven as an effective strategy for dealing with the noise in the problem.",
            "output": [
                "Analyzing Evolutionary Optimization in Noisy Environments"
            ]
        },
        {
            "id": "task1540-848b6f949e3144048efdf2a2b6fd2f19",
            "input": "In most common settings of Markov Decision Process (MDP), an agent evaluate a policy based on expectation of (discounted) sum of rewards. However in many applications this criterion might not be suitable from two perspective: first, in risk aversion situation expectation of accumulated rewards is not robust enough, this is the case when distribution of accumulated reward is heavily skewed; another issue is that many applications naturally take several objective into consideration when evaluating a policy, for instance in autonomous driving an agent needs to balance speed and safety when choosing appropriate decision. In this paper, we consider evaluating a policy based on a sequence of quantiles it induces on a set of target states, our idea is to reformulate the original problem into a multi-objective MDP problem with lexicographic preference naturally defined. For computation of finding an optimal policy, we proposed an algorithm FLMDP that could solve general multi-objective MDP with lexicographic reward preference.",
            "output": [
                "Solving Multi-Objective MDP with Lexicographic Preference: An application to stochastic planning with multiple quantile objective"
            ]
        },
        {
            "id": "task1540-b564e8903bf74706ae99ac12145b591f",
            "input": "In fair division of indivisible goods, using sequences of sincere choices (or picking sequences) is a natural way to allocate the objects. The idea is the following: at each stage, a designated agent picks one object among those that remain. This paper, restricted to the case where the agents have numerical additive preferences over objects, revisits to some extent the seminal paper by Brams and King [9] which was specific to ordinal and linear order preferences over items. We point out similarities and differences with this latter context. In particular, we show that any Paretooptimal allocation (under additive preferences) is sequenceable, but that the converse is not true anymore. This asymmetry leads naturally to the definition of a “scale of efficiency” having three steps: Pareto-optimality, sequenceability without Paretooptimality, and non-sequenceability. Finally, we investigate the links between these efficiency properties and the “scale of fairness” we have described in an earlier work [7]: we first show that an allocation can be envy-free and non-sequenceable, but that every competitive equilibrium with equal incomes is sequenceable. Then we experimentally explore the links between the scales of efficiency and fairness.",
            "output": [
                "Efficiency and Sequenceability in Fair Division of Indivisible Goods with Additive Preferences"
            ]
        },
        {
            "id": "task1540-b439aebbf076441fa2ec1bc0d9269f19",
            "input": "In this paper we provide a systematic and comprehensive set of modeling principles for representing etymological data in digital dictionaries using TEI. The purpose is to integrate in one coherent framework both digital representations of legacy dictionaries and born-digital lexical databases that are constructed manually or semi-automatically. We provide examples from many different types of etymological phenomena from traditional lexicographic practice, as well as analytical approaches from functional and cognitive linguistics such as metaphor, metonymy and grammaticalization, which in many lexicographical and formal linguistic circles have not often been treated as truly etymological in nature, and have thus been largely left out of etymological dictionaries. In order to fully and accurately express the phenomena and their structures, we have made several proposals for expanding and amending some aspects of the existing TEI framework. Finally, with reference to both synchronic and diachronic data, we also demonstrate how encoders may integrate semantic web/linked open data information resources into TEI dictionaries as a basis for the sense, and/or the semantic domain of an entry and/or an etymon.",
            "output": [
                "Deep encoding of etymological information in TEI"
            ]
        },
        {
            "id": "task1540-e5472d1c71e24607a11d50ab76aea950",
            "input": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks. 1 SADDLE POINT PROBLEM 1.",
            "output": [
                "CHARGED POINT NORMALIZATION AN EFFICIENT SOLUTION TO THE SADDLE POINT PROBLEM"
            ]
        },
        {
            "id": "task1540-acbfeb06af794ae788257917aa1564bf",
            "input": "We report investigations into speaker classification of larger quantities of unlabelled speech data using small sets of manually phonemically annotated speech. The Kohonen speech typewriter [1] is a semi-supervised method comprised of selforganising maps (SOMs) that achieves low phoneme error rates. A SOM is a 2D array of cells that learn vector representations of the data based on neighbourhoods. In this paper, we report a method to evaluate pronunciation using multilevel SOMs with /hVd/ single syllable utterances for the study of vowels, following [2] (for Australian pronunciation).",
            "output": [
                "Characterisation of speech diversity using self-organising maps"
            ]
        },
        {
            "id": "task1540-6f23f51f22134181a004058a3e600ac3",
            "input": "We show how to efficiently project a vector onto the top principal components of a matrix, without explicitly computing these components. Specifically, we introduce an iterative algorithm that provably computes the projection using few calls to any black-box routine for ridge regression. By avoiding explicit principal component analysis (PCA), our algorithm is the first with no runtime dependence on the number of top principal components. We show that it can be used to give a fast iterative method for the popular principal component regression problem, giving the first major runtime improvement over the naive method of combining PCA with regression. To achieve our results, we first observe that ridge regression can be used to obtain a “smooth projection” onto the top principal components. We then sharpen this approximation to true projection using a low-degree polynomial approximation to the matrix step function. Step function approximation is a topic of long-term interest in scientific computing. We extend prior theory by constructing polynomials with simple iterative structure and rigorously analyzing their behavior under limited precision.",
            "output": [
                "Principal Component Projection Without Principal Component Analysis"
            ]
        },
        {
            "id": "task1540-8038635cd51d4628a91c065a45ccef42",
            "input": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.",
            "output": [
                "IMPLICIT REASONET: MODELING LARGE-SCALE STRUCTURED RELATIONSHIPS WITH SHARED MEM- ORY"
            ]
        },
        {
            "id": "task1540-bb394c3f4d4c4c15acfcaae347dd7344",
            "input": "In this paper we present a short history of logics: from particular cases of 2-symbol or numerical valued logic to the general case of n-symbol or numerical valued logic. We show generalizations of 2-valued Boolean logic to fuzzy logic, also from the Kleene’s and Lukasiewicz’ 3-symbol valued logics or Belnap’s 4-symbol valued logic to the most general n-symbol or numerical valued refined neutrosophic logic. Two classes of neutrosophic norm (n-norm) and neutrosophic conorm (n-conorm) are defined. Examples of applications of neutrosophic logic to physics are listed in the last section. Similar generalizations can be done for n-Valued Refined Neutrosophic Set, and respectively nValued Refined Neutrosopjhic Probability.",
            "output": [
                "n-Valued Refined Neutrosophic Logic and Its Applications to Physics"
            ]
        },
        {
            "id": "task1540-ed492f21837f4c189e1b787fdfa456ca",
            "input": "There are over one million apps on Google Play Store and over half a million publishers. Having such a huge number of apps and developers can pose a challenge to app users and new publishers on the store. Discovering apps can be challenging if apps are not correctly published in the right category, and, in turn, reduce earnings for app developers. Additionally, with over 41 categories on Google Play Store, deciding on the right category to publish an app can be challenging for developers due to the number of categories they have to choose from. Machine Learning has been very useful, especially in classification problems such sentiment analysis, document classification and spam detection. These strategies can also be applied to app categorization on Google Play Store to suggest appropriate categories for app publishers using details from their application. In this project, we built two variations of the Naı̈ve Bayes classifier using open metadata from top developer apps on Google Play Store in other to classify new apps on the store. These classifiers are then evaluated using various evaluation methods and their results compared against each other. The results show that the Naı̈ve Bayes algorithm performs well for our classification problem and can potentially automate app categorization for Android app publishers on Google Play Store.",
            "output": [
                "Applying Naı̈ve Bayes Classification to Google Play Apps Categorization"
            ]
        },
        {
            "id": "task1540-d094269fdfa94e459cc41488636c17ff",
            "input": "Keyphrase boundary classification (KBC) is the task of detecting keyphrases in scientific articles and labelling them with respect to predefined types. Although important in practice, this task is so far underexplored, partly due to the lack of labelled data. To overcome this, we explore several auxiliary tasks, including semantic super-sense tagging and identification of multi-word expressions, and cast the task as a multi-task learning problem with deep recurrent neural networks. Our multi-task models perform significantly better than previous state of the art approaches on two scientific KBC datasets, particularly for long keyphrases.",
            "output": [
                "Multi-Task Learning of Keyphrase Boundary Classification"
            ]
        },
        {
            "id": "task1540-643296c649be41f19ba8aac5db5be396",
            "input": "As demand drives systems to generalize to various domains and problems, the study of multitask, transfer and lifelong learning has become an increasingly important pursuit. In discrete domains, performance on the Atari game suite has emerged as the de facto benchmark for assessing multitask learning. However, in continuous domains there is a lack of agreement on standard multitask evaluation environments which makes it difficult to compare different approaches fairly. In this work, we describe a benchmark set of tasks that we have developed in an extendable framework based on OpenAI Gym. We run a simple baseline using Trust Region Policy Optimization and release the framework publicly to be expanded and used for the systematic comparison of multitask, transfer, and lifelong learning in continuous domains.",
            "output": [
                "Benchmark Environments for Multitask Learning in Continuous Domains"
            ]
        },
        {
            "id": "task1540-1d4f35ade0c54cd98d727d2c00621946",
            "input": "In this paper, we propose the deep reinforcement relevance network (DRRN), a novel deep architecture, for handling an unbounded action space with applications to language understanding for text-based games. For a particular class of games, a user must choose among a variable number of actions described by text, with the goal of maximizing long-term reward. In these games, the best action is typically that which fits the best to the current situation (modeled as a state in the DRRN), also described by text. Because of the exponential complexity of natural language with respect to sentence length, there is typically an unbounded set of unique actions. Therefore, it is very difficult to pre-define the action set as in the deep Q-network (DQN). To address this challenge, the DRRN extracts high-level embedding vectors from the texts that describe states and actions, respectively, and computes the inner products between the state and action embedding vectors to approximate the Q-function. We evaluate the DRRN on two popular text games, showing superior performance over the DQN.",
            "output": [
                "DEEP REINFORCEMENT LEARNING WITH AN UNBOUNDED ACTION SPACE"
            ]
        },
        {
            "id": "task1540-b1c3500743504669830851f74dd1149e",
            "input": "Distributed controllers are oftentimes used in largescale SDN deployments where they run a myriad of network applications simultaneously. Such applications could have different consistency and availability preferences. These controllers need to communicate via east/west interfaces in order to synchronize their state information. The consistency and the availability of the distributed state information are governed by an underlying consistency model. Earlier, we suggested [1] the use of adaptivelyconsistent controllers that can autonomously tune their consistency parameters in order to meet the performance requirements of a certain application. In this paper, we examine the feasibility of employing adaptive controllers that are built on-top of tunable consistency models similar to that of Apache Cassandra. We present an adaptation strategy that uses clustering techniques (sequential k-means and incremental k-means) in order to map a given application performance indicator (χ) into a feasible consistency level (Φ) that can be used with the underlying tunable consistency model. In the cases that we modeled and tested, our results show that in the case of sequential k-means, with a reasonable number of clusters (≥ 50), a plausible mapping (low RMSE) could be estimated between the application performance indicators (χ) and the consistency level indicator (Φ). In the case of incremental k-means, the results also showed that a plausible mapping (low RMSE) could be estimated using a similar number of clusters (≥ 50) by using a small threshold (≃ 0.01).",
            "output": [
                "A Clustering-based Consistency Adaptation Strategy for Distributed SDN Controllers"
            ]
        },
        {
            "id": "task1540-2b3bce1937bf4cbbb3bc4a5e375e48ea",
            "input": "We introduce a novel schema for sequence to sequence learning with a Deep QNetwork (DQN), which decodes the output sequence iteratively. The aim here is to enable the decoder to first tackle easier portions of the sequences, and then turn to cope with difficult parts. Specifically, in each iteration, an encoder-decoder Long Short-Term Memory (LSTM) network is employed to, from the input sequence, automatically create features to represent the internal states of and formulate a list of potential actions for the DQN. Take rephrasing a natural sentence as an example. This list can contain ranked potential words. Next, the DQN learns to make decision on which action (e.g., word) will be selected from the list to modify the current decoded sequence. The newly modified output sequence is subsequently used as the input to the DQN for the next decoding iteration. In each iteration, we also bias the reinforcement learning’s attention to explore sequence portions which are previously difficult to be decoded. For evaluation, the proposed strategy was trained to decode ten thousands natural sentences. Our experiments indicate that, when compared to a left-to-right greedy beam search LSTM decoder, the proposed method performed competitively well when decoding sentences from the training set, but significantly outperformed the baseline when decoding unseen sentences, in terms of BLEU score obtained.",
            "output": [
                "Generating Text with Deep Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-b1992d63d0064d41be1b0221a612f43c",
            "input": "Mike Thelwall Computer systems need to be able to react to stress in order to perform optimally on some tasks. This article describes TensiStrength, a system to detect the strength of stress and relaxation expressed in social media text messages. TensiStrength uses a lexical approach and a set of rules to detect direct and indirect expressions of stress or relaxation, particularly in the context of transportation. It is slightly more effective than a comparable sentiment analysis program, although their similar performances occur despite differences on almost half of the tweets gathered. The effectiveness of TensiStrength depends on the nature of the tweets classified, with tweets that are rich in stress-related terms being particularly problematic. Although generic machine learning methods can give better performance than TensiStrength overall, they exploit topicrelated terms in a way that may be undesirable in practical applications and that may not work as well in more focused contexts. In conclusion, TensiStrength and generic machine learning approaches work well enough to be practical choices for intelligent applications that need to take advantage of stress information, and the decision about which to use depends on the nature of the texts analysed and the purpose of the task.",
            "output": [
                "TensiStrength: Stress and relaxation magnitude detection for social media texts1"
            ]
        },
        {
            "id": "task1540-c7376481e55242bb98d07b42c00d7f83",
            "input": "A Bayesian Belief Network (BN) is a model of a joint distribution over a finite set of variables, with a DAG structure to represent the immedi­ ate dependencies between the variables, and a set of parameters (aka CPTables) to represent the local conditional probabilities of a node, given each assignment to its parents. In many situa­ tions, the parameters are themselves treated as random variablesreflecting the uncertainty re­ maining after drawing on knowledge of domain experts and/or observing data generated by the network. A distribution over the CPtable param­ eters induces a distribution for the response the BN will return to any \"What is Pr{ H I E} ?\" query. This paper investigates the distribution of this response, shows that it is asymptotically normal, and derives expressions for its mean and asymptotic variance. We show that this compu­ tation has the same complexity as simply com­ puting the (mean value of the) response -i.e., O(n exp(w)), where n is the number of vari­ ables and w is the effective tree width. We also provide empirical evidence showing that the error-bars computed from our estimates are fairly accurate in practice, over a wide range of belief net structures and queries.",
            "output": [
                "Bayesian Error-Bars for Belief Net Inference"
            ]
        },
        {
            "id": "task1540-1f6e6f3511ed45488081ffa3ec3a8bc9",
            "input": "Least Squares Twin Support Vector Machine (LSTSVM) is an extremely efficient and fast version of SVM algorithm for binary classification. LSTSVM combines the idea of Least Squares SVM and Twin SVM in which two nonparallel hyperplanes are found by solving two systems of linear equations. Although, the algorithm is very fast and efficient in many classification tasks, it is unable to cope with two features of real-world problems. First, in many realworld classification problems, it is almost impossible to assign data points to a single class. Second, data points in real-world problems may have different importance. In this study, we propose a novel version of LSTSVM based on fuzzy concepts to deal with these two characteristics of real-world data. The algorithm is called Fuzzy LSTSVM (FLSTSVM) which provides more flexibility than binary classification of LSTSVM. Two models are proposed for the algorithm. In the first model, a fuzzy membership value is assigned to each data point and the hyperplanes are optimized based on these fuzzy samples. In the second model we construct fuzzy hyperplanes to classify data. Finally, we apply our proposed FLSTSVM to an artificial as well as three real-world datasets. Results demonstrate that FLSTSVM obtains better performance than SVM and LSTSVM.",
            "output": [
                "Fuzzy Least Squares Twin Support Vector Machines"
            ]
        },
        {
            "id": "task1540-3e5f16415bdc4be9943b5582dfcd174e",
            "input": "We present probabilistic logic programming un­ der inheritance with overriding. This approach is based on new notions of entailment for reasoning with conditional constraints, which are obtained from the classical notion of logical entailment by adding inheritance with overriding. This is done by using recent approaches to probabilistic de­ fault reasoning with conditional constraints. We analyze the semantic properties of the new en­ tailment relations. We also present algorithms for probabilistic logic prograrruning under inher­ itance with overriding, and we analyze its com­ plexity in the propositional case.",
            "output": [
                "Probabilistic Logic Programming under Inheritance with Overriding"
            ]
        },
        {
            "id": "task1540-110e79f23a034328bec958eb329f40cc",
            "input": "The computation and storage requirements for Deep Neural Networks (DNNs) are usually high. This issue limit their deployability on ubiquitous computing devices such as smart phones or wearables. In this paper, we propose ternary neural networks (TNNs) in order to make deep learning more resource-efficient. We train these TNNs using a teacher-student approach. Using only ternary weights and ternary neurons, with a step activation function of two-thresholds, the student ternary network learns to mimic the behaviour of its teacher network. We propose a novel, layer-wise greedy methodology for training TNNs. During training, a ternary neural network inherently prunes the smaller weights by setting them to zero. This makes them even more compact thus more resource-friendly. We devise a purpose-built hardware design for TNNs and implement it on FPGA. The benchmark results with our purpose-built hardware running TNNs reveal that, with only 1.24μJ per image, we can achieve 97.76% accuracy with 5.37μs latency and with a rate of 255K images per second on MNIST.",
            "output": [
                "Ternary Neural Networks for Resource-Efficient AI Applications"
            ]
        },
        {
            "id": "task1540-896787a67683472c8f5a59fe0bc7b907",
            "input": "Sliding window convolutional networks (ConvNets) have become a popular approach to computer vision problems such as image segmentation, and object detection and localization. Here we consider the problem of inference, the application of a previously trained ConvNet, with emphasis on 3D images. Our goal is to maximize throughput, defined as average number of output voxels computed per unit time. Other things being equal, processing a larger image tends to increase throughput, because fractionally less computation is wasted on the borders of the image. It follows that an apparently slower algorithm may end up having higher throughput if it can process a larger image within the constraint of the available RAM. We introduce novel CPU and GPU primitives for convolutional and pooling layers, which are designed to minimize memory overhead. The primitives include convolution based on highly efficient pruned FFTs. Our theoretical analyses and empirical tests reveal a number of interesting findings. For some ConvNet architectures, cuDNN is outperformed by our FFT-based GPU primitives, and these in turn can be outperformed by our CPU primitives. The CPU manages to achieve higher throughput because of its fast access to more RAM. A novel primitive in which the GPU accesses host RAM can significantly increase GPU throughput. Finally, a CPU-GPU algorithm achieves the greatest throughput of all, 10× or more than other publicly available implementations of sliding window 3D ConvNets. All of our code has been made available as open source project.",
            "output": [
                "ZNNi – Maximizing the Inference Throughput of 3D Convolutional Networks on Multi-Core CPUs and GPUs"
            ]
        },
        {
            "id": "task1540-603be91c50d9480e97441964217242b0",
            "input": "We propose a method called EDML for learning MAP parameters in binary Bayesian networks under incomplete data. The method assumes Beta priors and can be used to learn maximum likelihood parameters when the priors are uninformative. EDML exhibits interesting behaviors, especially when compared to EM. We introduce EDML, explain its origin, and study some of its properties both analytically and empirically.",
            "output": [
                "EDML: A Method for Learning Parameters in Bayesian Networks"
            ]
        },
        {
            "id": "task1540-73f2a7adff7648c2bbfb439f7b67249d",
            "input": "Concerns over the risks associated with advances in Artificial Intelligence have prompted calls for greater efforts toward robust and beneficial AI, including machine ethics. Recently, roboticists have responded by initiating the development of so-called ethical robots. These robots would, ideally, evaluate the consequences of their actions and morally justify their choices. This emerging field promises to develop extensively over the next years. However, in this paper, we point out an inherent limitation of the emerging field of ethical robots. We show that building ethical robots also necessarily facilitates the construction of unethical robots. In three experiments, we show that it is remarkably easy to modify an ethical robot so that it behaves competitively, or even aggressively. The reason for this is that the specific AI, required to make an ethical robot, can always be exploited to make unethical robots. Hence, the development of ethical robots will not guarantee the responsible deployment of AI. While advocating for ethical robots, we conclude that preventing the misuse of robots is beyond the scope of engineering, and requires instead governance frameworks underpinned by legislation. Without this, the development of ethical robots will serve to increase the risks of robotic malpractice instead of diminishing it.",
            "output": [
                "The Dark Side of Ethical Robots"
            ]
        },
        {
            "id": "task1540-f17c6e0c8e644d0da383fc6a48e9680c",
            "input": "This paper focuses on the problem of simultaneous sample and feature selection for machine learning in a fully unsupervised setting. Though most existing works tackle these two problems separately that derives two well-studied sub-areas namely active learning and feature selection, a unified approach is inspirational since they are often interleaved with each other. Noisy and high-dimensional features will bring adverse effect on sample selection, while ‘good’ samples will be beneficial to feature selection. We present a framework to jointly conduct active learning and feature selection based on the CUR matrix decomposition. From the data reconstruction perspective, both the selected samples and features can best approximate the original dataset respectively, such that the selected samples characterized by the selected features are very representative. Additionally our method is one-shot without iteratively selecting samples for progressive labeling. Thus our model is especially suitable when the initial labeled samples are scarce or totally absent, which existing works hardly address particularly for simultaneous feature selection. To alleviate the NP-hardness of the raw problem, the proposed formulation involves a convex but non-smooth optimization problem. We solve it efficiently by an iterative algorithm, and prove its global convergence. Experiments on publicly available datasets validate that our method is promising compared with the state-of-the-arts.",
            "output": [
                "Joint Active Learning with Feature Selection via CUR Matrix Decomposition"
            ]
        },
        {
            "id": "task1540-f89f1af175f049a8aa95390d0383493a",
            "input": "We propose an original particle-based implementation of the Loopy Belief Propagation (LPB) algorithm for pairwise Markov Random Fields (MRF) on a continuous state space. The algorithm constructs adaptively efficient proposal distributions approximating the local beliefs at each note of the MRF. This is achieved by considering proposal distributions in the exponential family whose parameters are updated iterately in an Expectation Propagation (EP) framework. The proposed particle scheme provides consistent estimation of the LBP marginals as the number of particles increases. We demonstrate that it provides more accurate results than the Particle Belief Propagation (PBP) algorithm of [1] at a fraction of the computational cost and is additionally more robust empirically. The computational complexity of our algorithm at each iteration is quadratic in the number of particles. We also propose an accelerated implementation with sub-quadratic computational complexity which still provides consistent estimates of the loopy BP marginal distributions and performs almost as well as the original procedure.",
            "output": [
                "Expectation Particle Belief Propagation"
            ]
        },
        {
            "id": "task1540-13d2b87347f14ebbadb8a7a44c3cb8ca",
            "input": "Constraint Programming (CP) solvers typically tackle optimization problems by repeatedly finding solutions to a problem while placing tighter and tighter bounds on the solution cost. This approach is somewhat naive, especially for soft-constraint optimization problems in which the soft constraints are mostly satisfied. Unsatisfiable-core approaches to solving soft constraint problems in SAT (e.g. MAXSAT) force all soft constraints to be hard initially. When solving fails they return an unsatisfiable core, as a set of soft constraints that cannot hold simultaneously. These are reverted to soft and solving continues. Since lazy clause generation solvers can also return unsatisfiable cores we can adapt this approach to constraint programming. We adapt the original MAXSAT unsatisfiable core solving approach to be usable for constraint programming and define a number of extensions. Experimental results show that our methods are beneficial on a broad class of CP-optimization benchmarks involving soft constraints, cardinality or preferences.",
            "output": [
                "Unsatisfiable Cores and Lower Bounding for Constraint Programming"
            ]
        },
        {
            "id": "task1540-3be1289ca2ac410c867b0eee08b5886e",
            "input": "In this work we introduce a comprehensive algorithmic pipeline for multiple parametric model estimation. The proposed approach analyzes the information produced by a random sampling algorithm (e.g., RANSAC) from a machine learning/optimization perspective, using a parameterless biclustering algorithm based on L1 nonnegative matrix factorization (L1-NMF). The proposed framework exploits consistent patterns that naturally arise during the RANSAC execution, while explicitly avoiding spurious inconsistencies. Contrarily to the main trends in the literature, the proposed technique does not impose non-intersecting parametric models. A new accelerated algorithm to compute L1-NMFs allows to handle medium-sized problems faster while also extending the usability of the algorithm to much larger datasets. This accelerated algorithm has applications in any other context where an L1-NMF is needed, beyond the biclustering approach to parameter estimation here addressed. We accompany the algorithmic presentation with theoretical foundations and numerous and diverse examples.",
            "output": [
                "Fast L1-NMF for Multiple Parametric Model Estimation∗"
            ]
        },
        {
            "id": "task1540-22db314146a64f4cb43ec12676d54949",
            "input": "Convolutional Neural Networks (CNNs) were recently shown to provide state-of-theart results for object category viewpoint estimation. However different ways of formulating this problem have been proposed and the competing approaches have been explored with very different design choices. This paper presents a comparison of these approaches in a unified setting as well as a detailed analysis of the key factors that impact performance. Followingly, we present a new joint training method with the detection task and demonstrate its benefit. We also highlight the superiority of classification approaches over regression approaches, quantify the benefits of deeper architectures and extended training data, and demonstrate that synthetic data is beneficial even when using ImageNet training data. By combining all these elements, we demonstrate an improvement of approximately 5% mAVP over previous state-of-the-art results on the Pascal3D+ dataset [29]. In particular for their most challenging 24 view classification task we improve the results from 31.1% to 36.1% mAVP.",
            "output": [
                "Crafting a multi-task CNN for viewpoint estimation"
            ]
        },
        {
            "id": "task1540-deedf3c9342f4c3d9d5485e227c1a787",
            "input": "Formal languages for probabilistic modeling enable re-use, modularity, and descriptive clarity, and can foster generic inference techniques. We introduce Church, a universal language for describing stochastic generative processes. Church is based on the Lisp model of lambda calculus, containing a pure Lisp as its deterministic subset. The semantics of Church is defined in terms of evaluation histories and conditional distributions on such histories. Church also includes a novel language construct, the stochastic memoizer, which enables simple description of many complex non-parametric models. We illustrate language features through several examples, including: a generalized Bayes net in which parameters cluster over trials, infinite PCFGs, planning by inference, and various non-parametric clustering models. Finally, we show how to implement query on any Church program, exactly and approximately, using Monte Carlo techniques.",
            "output": [
                "Church: a language for generative models"
            ]
        },
        {
            "id": "task1540-00c83fbf74ce49308faf30d07517e330",
            "input": "Reinforcement learning tasks are typically specified as Markov decision processes. This formalism has been highly successful, though specifications often couple the dynamics of the environment and the learning objective. This lack of modularity can complicate generalization of the task specification, as well as obfuscate connections between different task settings, such as episodic and continuing. In this work, we introduce the RL task formalism, that provides a unification through simple constructs including a generalization to transition-based discounting. Through a series of examples, we demonstrate the generality and utility of this formalism. Finally, we extend standard learning constructs, including Bellman operators, and extend some seminal theoretical results, including approximation errors bounds. Overall, we provide a well-understood and sound formalism on which to build theoretical results and simplify algorithm use and development.",
            "output": [
                "Unifying task specification in reinforcement learning"
            ]
        },
        {
            "id": "task1540-e29b1d525f774a259ff6d68defdc6ad9",
            "input": "We propose a novel language-independent approach for improving machine translation for resource-poor languages by exploiting their similarity to resource-rich ones. More precisely, we improve the translation from a resource-poor source language X1 into a resourcerich language Y given a bi-text containing a limited number of parallel sentences for X1-Y and a larger bi-text for X2-Y for some resource-rich language X2 that is closely related to X1. This is achieved by taking advantage of the opportunities that vocabulary overlap and similarities between the languages X1 and X2 in spelling, word order, and syntax offer: (1) we improve the word alignments for the resource-poor language, (2) we further augment it with additional translation options, and (3) we take care of potential spelling differences through appropriate transliteration. The evaluation for Indonesian→English using Malay and for Spanish→English using Portuguese and pretending Spanish is resource-poor shows an absolute gain of up to 1.35 and 3.37 BLEU points, respectively, which is an improvement over the best rivaling approaches, while using much less additional data. Overall, our method cuts the amount of necessary “real” training data by a factor of 2–5.",
            "output": [
                "Improving Statistical Machine Translation for a Resource-Poor Language Using Related Resource-Rich Languages"
            ]
        },
        {
            "id": "task1540-2af09b1096f7439daf6743c7f2a6d944",
            "input": "In this paper we study multi robot cooperative task allocation issue in a situation where a swarm of robots is deployed in a confined unknown environment where the number of colored spots which represent tasks and the ratios of them are unknown. The robots should cover this spots as far as possible to do cleaning and sampling actions desirably. It means that they should discover the spots cooperatively and spread proportional to the spots area and avoid from remaining idle. We proposed 4 self-organized distributed methods which are called hybrid methods for coping with this scenario. In two different experiments the performance of the methods is analyzed. We compared them with each other and investigated their scalability and robustness in term of single",
            "output": [
                "Task Allocation in Robotic Swarms: Explicit Communication Based Approaches"
            ]
        },
        {
            "id": "task1540-48852ec0347642f69cd1a08b28a76f30",
            "input": "Fully connected network has been widely used in deep learning, and its computation efficiency is highly benefited from the matrix multiplication algorithm with cuBLAS on GPU. However, We found that, there exist some drawbacks of cuBLAS in calculating matrix A multiplies the transpose of matrix B (i.e., NT operation). To reduce the impact of NT operation by cuBLAS, we exploit the out-of-place transpose of matrix B to avoid using NT operation, and then we apply our method to Caffe, which is a popular deep learning tool. Our contribution is two-fold. First, we propose a naive method (TNN) and model-based method (MTNN) to increase the performance in calculating A × B , and it achieves about 4.7 times performance enhancement in our tested cases on GTX1080 card. Second, we integrate MTNN method into Caffe to enhance the efficiency in training fully connected networks, which achieves about 70% speedup compared to the original Caffe in our configured fully connected networks on GTX1080 card.",
            "output": [
                "Improving the Performance of Fully Connected Neural Networks by Out-of-Place Matrix Transpose"
            ]
        },
        {
            "id": "task1540-f9052f252ac940b9aa09e0a3d7fdd095",
            "input": "The developpment of the Internet of Things (IoT) concept revives Responsive Environments (RE) technologies. Nowadays, the idea of a permanent connection between physical and digital world is technologically possible. The capillar Internet relates to the Internet extension into daily appliances such as they become actors of Internet like any hu-man. The parallel development of Machine-to-Machine communications and Arti cial Intelligence (AI) technics start a new area of cybernetic. This paper presents an approach for Cybernetic Organism (Cyborg) for RE based on Organic Computing (OC). In such approach, each appli-ance is a part of an autonomic system in order to control a physical environment. The underlying idea is that such systems must have self-x properties in order to adapt their behavior to external disturbances with a high-degree of autonomy.",
            "output": [
                "TOWARD ORGANIC COMPUTING APPROACH FOR CYBERNETIC RESPONSIVE ENVIRONMENT"
            ]
        },
        {
            "id": "task1540-9fdb940754de4dca9f3103bcf4861e89",
            "input": "Many papers have been published on the knowledge base completion task in the past few years. Most of these introduce novel architectures for relation learning that are evaluated on standard datasets such as FB15k and WN18. This paper shows that the accuracy of almost all models published on the FB15k can be outperformed by an appropriately tuned baseline — our reimplementation of the DistMult model. Our findings cast doubt on the claim that the performance improvements of recent models are due to architectural changes as opposed to hyperparameter tuning or different training objectives. This should prompt future research to re-consider how the performance of models is evaluated and reported.",
            "output": [
                "Knowledge Base Completion: Baselines Strike Back"
            ]
        },
        {
            "id": "task1540-f558c613e80648f1b1339577775b74ea",
            "input": "Neural word representations have proven useful in Natural Language Processing (NLP) tasks due to their ability to efficiently model complex semantic and syntactic word relationships. However, most techniques model only one representation per word, despite the fact that a single word can have multiple meanings or ”senses”. Some techniques model words by using multiple vectors that are clustered based on context. However, recent neural approaches rarely focus on the application to a consuming NLP algorithm. Furthermore, the training process of recent word-sense models is expensive relative to single-sense embedding processes. This paper presents a novel approach which addresses these concerns by modeling multiple embeddings for each word based on supervised disambiguation, which provides a fast and accurate way for a consuming NLP model to select a sense-disambiguated embedding. We demonstrate that these embeddings can disambiguate both contrastive senses such as nominal and verbal senses as well as nuanced senses such as sarcasm. We further evaluate Part-of-Speech disambiguated embeddings on neural dependency parsing, yielding a greater than 8% average error reduction in unlabeled attachment scores across 6 languages.",
            "output": [
                "A FAST AND ACCURATE METHOD FOR WORD SENSE DISAMBIGUATION IN NEURAL WORD EMBEDDINGS"
            ]
        },
        {
            "id": "task1540-12be216e8bc342b6acada964cb753379",
            "input": "In this paper, we propose a novel multi-label learning framework, called Multi-Label Self-Paced Learning (MLSPL), in an attempt to incorporate the self-paced learning strategy into multi-label learning regime. In light of the benefits of adopting the easy-to-hard strategy proposed by self-paced learning, the devised MLSPL aims to learn multiple labels jointly by gradually including label learning tasks and instances into model training from the easy to the hard. We first introduce a self-paced function as a regularizer in the multi-label learning formulation, so as to simultaneously rank priorities of the label learning tasks and the instances in each learning iteration. Considering that different multi-label learning scenarios often need different self-paced schemes during optimization, we thus propose a general way to find the desired self-paced functions. Experimental results on three benchmark datasets suggest the state-of-the-art performance of our approach.",
            "output": [
                "A Self-Paced Regularization Framework for Multi-Label Learning"
            ]
        },
        {
            "id": "task1540-4ca363d1fb6748dab749e2d5fc56e99b",
            "input": "We present a probabilistic model that simultaneously learns alignments and distributed representations for bilingual data. By marginalizing over word alignments the model captures a larger semantic context than prior work relying on hard alignments. The advantage of this approach is demonstrated in a cross-lingual classification task, where we outperform the prior published state of the art.",
            "output": [
                "Learning Bilingual Word Representations by Marginalizing Alignments"
            ]
        },
        {
            "id": "task1540-4c5bfd17de7e485886939dac52208eb2",
            "input": "We consider Conditional Random Fields (CRFs) with pattern-based potentials defined on a chain. In this model the energy of a string (labeling) x1 . . . xn is the sum of terms over intervals [i, j] where each term is non-zero only if the substring xi . . . xj equals a prespecified pattern α. Such CRFs can be naturally applied to many sequence tagging problems. We present efficient algorithms for the three standard inference tasks in a CRF, namely computing (i) the partition function, (ii) marginals, and (iii) computing the MAP. Their complexities are respectively O(nL), O(nL`max) and O(nLmin{|D|, log(`max+1)}) where L is the combined length of input patterns, `max is the maximum length of a pattern, and D is the input alphabet. This improves on the previous algorithms of [Ye et al. NIPS 2009] whose complexities are respectively O(nL|D|), O ( n|Γ|L`max ) and O(nL|D|), where |Γ| is the number of input patterns. In addition, we give an efficient algorithm for sampling, and revisit the case of MAP with non-positive weights. This paper addresses the sequence labeling (or the sequence tagging) problem: given an observation z (which is usually a sequence of n values), infer labeling x = x1 . . . xn where each variable xi takes values in some finite domain D. Such problem appears in many domains such as text and speech analysis, signal analysis, and bioinformatics. One of the most successful approaches for tackling the problem is the Hidden Markov Model (HMM). The kth order HMM is given by the probability distribution p(x|z) = 1 Z exp{−E(x|z)} with the energy function E(x|z) = ∑ i∈[1,n] ψi(xi, zi) + ∑ (i,j)∈Ek ψij(xi:j) (1) where Ek = {(i, i+ k) | i ∈ [1, n− k]} and xi:j = xi . . . xj is the substring of x from i to j. A popular generalization is the Conditional Random Field model [3] that allows all terms to depend on the full observation z: E(x|z) = ∑ i∈[1,n] ψi(xi, z) + ∑ (i,j)∈Ek ψij(xi:j , z) (2) A preliminary version of this paper appeared in Proceedings of the 30th International Conference on Machine Learning (ICML), 2013 [8]. This work was partially supported by the European Research Council under the European Unions Seventh Framework Programme (FP7/2007-2013)/ERC grant agreement no 616160. 1 ar X iv :1 21 0. 05 08 v5 [ cs .L G ] 2 0 Ja n 20 17 We study a particular variant of this model called a pattern-based CRF. It is defined via",
            "output": [
                "Inference algorithms for pattern-based CRFs on sequence data"
            ]
        },
        {
            "id": "task1540-6494c1d19b3e4bf4a431ca35d70af265",
            "input": "Common activation functions used in neural networks can yield to training difficulties due to the saturation behavior of the activation function, which may hide dependencies which are not visible to first order (using only gradients). Gating mechanisms that use softly saturating activation functions to emulate the discrete switching of digital logic circuits are good examples of this. We propose to exploit the injection of appropriate noise so that some gradients may sometimes flow, even if the noiseless application of the activation function would yield zero gradient. Large noise will dominate the noise-free gradient and allow stochastic gradient descent to be more exploratory. By adding noise only to the problematic parts of the activation function we allow the optimization procedure to explore the boundary between the degenerate (saturating) and the well-behaved parts of the activation function. We also establish connections to simulated annealing, when the amount of noise is annealed down, making it easier to optimize hard objective functions. We find experimentally that replacing such saturating activation functions by by noisy variants helps training in many contexts, yielding state-of-the-art results on several datasets, especially when training seems to be the most difficult, e.g., when curriculum learning is necessary to obtain good results.",
            "output": [
                "Noisy Activation Functions"
            ]
        },
        {
            "id": "task1540-8e8cd3a7d8c746b4a5c2b46f9fbdd0dc",
            "input": "Sustainable and economical generation of electrical power is an essential and mandatory component of infrastructure in today’s world. Optimal generation (generator subset selection) of power requires a careful evaluation of various factors like type of source, generation, transmission & storage capacities, congestion among others which makes this a difficult task. We created a grid to simulate various conditions including stimuli like generator supply, weather and load demand using Siemens PSS/E software and this data is trained using deep learning methods and subsequently tested. The results are highly encouraging. As per our knowledge, this is the first paper to propose a working and scalable deep learning model for this problem.",
            "output": [
                "Intelligent Subset Selection of Power Generators for Economic Dispatch"
            ]
        },
        {
            "id": "task1540-c93d63bbe0f24f6fb10f01b39a0dafd7",
            "input": "We systematically explored a spectrum of normalization algorithms related to Batch Normalization (BN) and propose a generalized formulation that simultaneously solves two major limitations of BN: (1) online learning and (2) recurrent learning. Our proposal is simpler and more biologically-plausible. Unlike previous approaches, our technique can be applied out of the box to all learning scenarios (e.g., online learning, batch learning, fully-connected, convolutional, feedforward, recurrent and mixed — recurrent and convolutional) and compare favorably with existing approaches. We also propose Lp Normalization for normalizing by different orders of statistical moments. In particular, L1 normalization is well-performing, simple to implement, fast to compute, more biologically-plausible and thus ideal for GPU or hardware implementations. This work was supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF 1231216. 1 ar X iv :1 61 0. 06 16 0v 1 [ cs .L G ] 1 9 O ct 2 01 6 Approach FF & FC FF & Conv Rec & FC Rec & Conv Online Learning Small Batch All Combined Original Batch Normalization(BN) 3 3 7 7 7 Suboptimal 7 Time-specific BN 3 3 Limited Limited 7 Suboptimal 7 Layer Normalization 3 7* 3 7* 3 3 7* Streaming Normalization 3 3 3 3 3 3 3 Table 1: An overview of normalization techiques for different tasks. 3: works well. 7: does not work well. FF: Feedforward. Rec: Recurrent. FC: Fully-connected. Conv: convolutional. Limited: time-specific BN requires recording normalization statistics for each timestep and thus may not generalize to novel sequence length. *Layer normalization does not fail on these tasks but perform significantly worse than the best approaches.",
            "output": [
                "Streaming Normalization: Towards Simpler and More Biologically-plausible Normalizations for Online and Recurrent Learning"
            ]
        },
        {
            "id": "task1540-ae187f213f1847cdaff56a4d205000e3",
            "input": "We propose a novel deep layer cascade (LC) method to improve the accuracy and speed of semantic segmentation. Unlike the conventional model cascade (MC) that is composed of multiple independent models, LC treats a single deep model as a cascade of several sub-models. Earlier sub-models are trained to handle easy and confident regions, and they progressively feed-forward harder regions to the next sub-model for processing. Convolutions are only calculated on these regions to reduce computations. The proposed method possesses several advantages. First, LC classifies most of the easy regions in the shallow stage and makes deeper stage focuses on a few hard regions. Such an adaptive and ‘difficulty-aware’ learning improves segmentation performance. Second, LC accelerates both training and testing of deep network thanks to early decisions in the shallow stage. Third, in comparison to MC, LC is an endto-end trainable framework, allowing joint learning of all sub-models. We evaluate our method on PASCAL VOC and Cityscapes datasets, achieving state-of-the-art performance and fast speed.",
            "output": [
                "Not All Pixels Are Equal: Difficulty-Aware Semantic Segmentation via Deep Layer Cascade"
            ]
        },
        {
            "id": "task1540-9de96c87197a44a0ae544faf6a063737",
            "input": "The recent application of RNN encoder-decoder models has resulted in substantial progress in fully data-driven dialogue systems, but evaluation remains a challenge. An adversarial loss could be a way to directly evaluate the extent to which generated dialogue responses sound like they came from a human. This could reduce the need for human evaluation, while more directly evaluating on a generative task. In this work, we investigate this idea by training an RNN to discriminate a dialogue model’s samples from human-generated samples. Although we find some evidence this setup could be viable, we also note that many issues remain in its practical application. We discuss both aspects and conclude that future work is warranted.",
            "output": [
                "Adversarial Evaluation of Dialogue Models"
            ]
        },
        {
            "id": "task1540-2893a8b685dc402b97cea2fb761108ca",
            "input": "Data representation is an important pre-processing step in many machine learning algorithms. There are a number of methods used for this task such as Deep Belief Networks (DBNs) and Discrete Fourier Transforms (DFTs). Since some of the features extracted using automated feature extraction methods may not always be related to a specific machine learning task, in this paper we propose two methods in order to make a distinction between extracted features based on their relevancy to the task. We applied these two methods to a Deep Belief Network trained for a face recognition task.",
            "output": [
                "Distinction between features extracted using Deep Belief Networks"
            ]
        },
        {
            "id": "task1540-b6a97545c4d942edaa42de2ce8630b7e",
            "input": "The ability to monitor the progress of students’ academic performance is a critical issue to the academic community of higher learning. A system for analyzing students’ results based on cluster analysis and uses standard statistical algorithms to arrange their scores data according to the level of their performance is described. In this paper, we also implemented k-mean clustering algorithm for analyzing students’ result data. The model was combined with the deterministic model to analyze the students’ results of a private Institution in %igeria which is a good benchmark to monitor the progression of academic performance of students in higher Institution for the purpose of making an effective decision by the academic planners. Keywordsk – mean, clustering, academic performance, algorithm.",
            "output": [
                "Application of k-Means Clustering algorithm for prediction of Students’ Academic Performance"
            ]
        },
        {
            "id": "task1540-b334b6bd76e64dc8976f2a8a6aa92a4b",
            "input": "We introduce openXBOW, an open-source toolkit for the generation of bag-of-words (BoW) representations from multimodal input. In the BoW principle, word histograms were first used as features in document classification, but the idea was and can easily be adapted to, e. g., acoustic or visual low-level descriptors, introducing a prior step of vector quantisation. The openXBOW toolkit supports arbitrary numeric input features and text input and concatenates computed subbags to a final bag. It provides a variety of extensions and options. To our knowledge, openXBOW is the first publicly available toolkit for the generation of crossmodal bags-of-words. The capabilities of the tool are exemplified in two sample scenarios: time-continuous speech-based emotion recognition and sentiment analysis in tweets where improved results over other feature representation forms were observed.",
            "output": [
                "openXBOW – Introducing the Passau Open-Source Crossmodal Bag-of-Words Toolkit"
            ]
        },
        {
            "id": "task1540-5d816755bb3d45f9b9f47869d876c35d",
            "input": "We present a novel framework for generating pop music. Our model is a hierarchical Recurrent Neural Network, where the layers and the structure of the hierarchy encode our prior knowledge about how pop music is composed. In particular, the bottom layers generate the melody, while the higher levels produce the drums and chords. We conduct several human studies that show strong preference of our generated music over that produced by the recent method by Google. We additionally show two applications of our framework: neural dancing and karaoke, as well as neural story singing.",
            "output": [
                "SONG FROM PI: A MUSICALLY PLAUSIBLE NETWORK FOR POP MUSIC GENERATION"
            ]
        },
        {
            "id": "task1540-7fa4be6a64114ca19428108b664de763",
            "input": "In mechanical design, there is often unavoidable uncertainty in estimates of design performance. Evaluation of design alternatives requires consideration of the impact of this uncertainty. Expert heuristics embody assumptions regarding the designer's attitude towards risk and uncertainty that might be reasonable in most cases but inaccurate in others. We present a technique to allow designers to incorporate their own unique attitude towards uncertainty as opposed to those assumed by the domain expert's rules. The general approach is to eliminate aspects of heuristic rules which directly or indirectly include assumptions regarding the user's attitude towards risk, and replace them with explicit , user-specified probabilistic multiattribute utility and probability distribution functions. We illustrate the method in a system for material selection for automobile bumpers.",
            "output": [
                "A Method for Integrating Utility Analysis into an Expert System for Design Evaluation under Uncertainty"
            ]
        },
        {
            "id": "task1540-781a1bac122f4bf288a718bf505f2a57",
            "input": "An extended, revised form of Tim Buckwalter’s Arabic lexical and morphological resource AraMorph, eXtended Revised AraMorph (henceforth XRAM), is presented which addresses a number of weaknesses and inconsistencies of the original model by allowing a wider coverage of real-world Classical and contemporary (both formal and informal) Arabic texts. Building upon previous research, XRAM enhancements include (i) flag-selectable usage markers, (ii) probabilistic mildly context-sensitive POS tagging, filtering, disambiguation and ranking of alternative morphological analyses, (iii) semi-automatic increment of lexical coverage through extraction of lexical and morphological information from existing lexical resources. Testing of XRAM through a front-end Python module showed a remarkable success level.",
            "output": [
                "Semi-Automatic Data Annotation, POS Tagging and Mildly Context- Sensitive Disambiguation: the eXtended Revised AraMorph (XRAM)"
            ]
        },
        {
            "id": "task1540-6121820c643746428b8ae9cbd03009fe",
            "input": "Deep Learning’s recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities. In this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.",
            "output": [
                "Deep Convolutional Networks on Graph-Structured Data"
            ]
        },
        {
            "id": "task1540-5ec21e271d174d2ba237e1decfa2236f",
            "input": "Deep learning and reinforcement learning methods have recently been used to solve a variety of problems in continuous control domains. An obvious application of these techniques is dexterous manipulation tasks in robotics which are difficult to solve using traditional control theory or hand-engineered approaches. One example of such a task is to grasp an object and precisely stack it on another. Solving this difficult and practically relevant problem in the real world is an important long-term goal for the field of robotics. Here we take a step towards this goal by examining the problem in simulation and providing models and techniques aimed at solving it. We introduce two extensions to the Deep Deterministic Policy Gradient algorithm (DDPG), a model-free Q-learning based method, which make it significantly more data-efficient and scalable. Our results show that by making extensive use of off-policy data and replay, it is possible to find control policies that robustly grasp objects and stack them. Further, our results hint that it may soon be feasible to train successful stacking policies by collecting interactions on real robots.",
            "output": [
                "Data-efficient Deep Reinforcement Learning for Dexterous Manipulation"
            ]
        },
        {
            "id": "task1540-4aa5e733b8144e668424e1700da04ede",
            "input": "The belief network is a well-known graphi­ cal structure for representing independences in a joint probability distribution. The meth­ ods, which perform probabilistic inference in belief networks, often treat the conditional probabilities which are stored in the network as certain values. However, if one takes ei­ ther a subjectivistic or a limiting frequency approach to probability, one can never be certain of probability values. An algorithm should not only be capable of reporting the probabilities of the alternatives of remain­ ing nodes when other nodes are instanti­ ated; it should also be capable of reporting the uncertainty in these probabilities relative to the uncertainty in the probabilities which are stored in the network. In this paper a method for determining the variances in in­ ferred probabilities is obtained under the as­ sumption that a posterior distribution on the uncertainty variables can be approximated by the prior distribution. It is shown that this assumption is plausible if their is a reason­ able amount of confidence in the probabili­ ties which are stored in the network. Fur­ thermore in this paper, a surprising upper bound for the prior variances in the proba­ bilities of the alternatives of all nodes is ob­ tained in the case where the probability dis­ tributions of the probabilities of the alterna­ tives are beta distributions. It is shown that the prior variance in the probability at an al­ ternative of a node is bounded above by the largest variance in an element of the condi­ tional probability distribution for that node.",
            "output": [
                "Investigation of Variances in Belief Networks"
            ]
        },
        {
            "id": "task1540-0ac2db5634af4138948c91a142e4cf24",
            "input": "People often use a web search engine to find information about events of interest, for example, sport competitions, political elections, festivals and entertainment news. In this paper, we study a problem of detecting event-related queries, which is the first step before selecting a suitable time-aware retrieval model. In general, event-related information needs can be observed in query streams through various temporal patterns of user search behavior, e.g., spiky peaks for popular events, and periodicities for repetitive events. However, it is also common that users search for non-popular events, which may not exhibit temporal variations in query streams, e.g., past events recently occurred, historical events triggered by anniversaries or similar events, and future events anticipated to happen. To address the challenge of detecting dynamic classes of events, we propose a novel deep learning model to classify a given query into a predetermined set of multiple event types. Our proposed model, a Stacked Multilayer Perceptron (S-MLP) network, consists of multilayer perceptron used as a basic learning unit. We assemble stacked units to further learn complex relationships between neutrons in successive layers. To evaluate our proposed model, we conduct experiments using real-world queries and a set of manually created ground truth. Preliminary results have shown that our proposed deep learning model outperforms the state-of-the-art classification models significantly.",
            "output": [
                "Learning Dynamic Classes of Events using Stacked Multilayer Perceptron Networks"
            ]
        },
        {
            "id": "task1540-23e3b738817d44b0b22b48be5ded4209",
            "input": "We present a factorized compositional distributional semantics model for the representation of transitive verb constructions. Our model first produces (subject, verb) and (verb, object) vector representations based on the similarity of the nouns in the construction to each of the nouns in the vocabulary and the tendency of these nouns to take the subject and object roles of the verb. These vectors are then combined into a final (subject,verb,object) representation through simple vector operations. On two established tasks for the transitive verb construction our model outperforms recent previous work.",
            "output": [
                "A Factorized Model for Transitive Verbs in Compositional Distributional Semantics"
            ]
        },
        {
            "id": "task1540-7588f913925e4f4f8ee083d1e9eb667c",
            "input": "Recent developments in controlled natural language editors for knowledge engineering (KE) have given rise to expectations that they will make KE tasks more accessible and perhaps even enable non-engineers to build knowledge bases. This exploratory research focussed on novices and experts in knowledge engineering during their attempts to learn a controlled natural language (CNL) known as OWL Simplified English and use it to build a small knowledge base. Participants’ behaviours during the task were observed through eye-tracking and screen recordings. This was an attempt at a more ambitious user study than in previous research because we used a naturally occurring text as the source of domain knowledge, and left them without guidance on which information to select, or how to encode it. We have identified a number of skills (competencies) required for this difficult task and key problems that authors face.",
            "output": [
                "How Easy is it to Learn a Controlled Natural Language for Building a Knowledge Base?"
            ]
        },
        {
            "id": "task1540-86fb89e3794d47b3840e5996784b72fc",
            "input": "Reducing the amount of human supervision is a key problem in machine learning and a natural approach is that of exploiting the relations (structure) among different tasks. This is the idea at the core of multi-task learning. In this context a fundamental question is how to incorporate the tasks structure in the learning problem. We tackle this question by studying a general computational framework that allows to encode a-priori knowledge of the tasks structure in the form of a convex penalty; in this setting a variety of previously proposed methods can be recovered as special cases, including linear and non-linear approaches. Within this framework, we show that tasks and their structure can be efficiently learned considering a convex optimization problem that can be approached by means of block coordinate methods such as alternating minimization and for which we prove convergence to the global minimum.",
            "output": [
                "Convex Learning of Multiple Tasks and their Structure"
            ]
        },
        {
            "id": "task1540-936dd94bd37641318bfbf49e9a7a914e",
            "input": "Motivated by applications in domains such as social networks and computational biology, we study the problem of community recovery in graphs with locality. In this problem, pairwise noisy measurements of whether two nodes are in the same community or different communities come mainly or exclusively from nearby nodes rather than uniformly sampled between all node pairs, as in most existing models. We present two algorithms that run nearly linearly in the number of measurements and which achieve the information limits for exact recovery.",
            "output": [
                "Community Recovery in Graphs with Locality"
            ]
        },
        {
            "id": "task1540-bceb536444e2412082bbea4f27b2fed2",
            "input": "We present a position paper advocating the notion that Stoic philosophy and ethics can inform the development of ethical A.I. systems. This is in sharp contrast to most work on building ethical A.I., which has focused on Utilitarian or Deontological ethical theories. We relate ethical A.I. to several core Stoic notions, including the dichotomy of control, the four cardinal virtues, the ideal Sage, Stoic practices, and Stoic perspectives on emotion or affect. More generally, we put forward an ethical view of A.I. that focuses more on internal states of the artificial agent rather than on external actions of the agent. We provide examples relating to near-term A.I. systems as well as hypothetical superintelligent",
            "output": [
                "Stoic Ethics for Artificial Agents"
            ]
        },
        {
            "id": "task1540-555cc2072fb646058411596f10018210",
            "input": "We propose Neural Reasoner , a framework for neural network-based reasoning over natural language sentences. Given a question, Neural Reasoner can infer over multiple supporting facts and find an answer to the question in specific forms. Neural Reasoner has 1) a specific interaction-pooling mechanism, allowing it to examine multiple facts, and 2) a deep architecture, allowing it to model the complicated logical relations in reasoning tasks. Assuming no particular structure exists in the question and facts, Neural Reasoner is able to accommodate different types of reasoning and different forms of language expressions. Despite the model complexity, Neural Reasoner can still be trained effectively in an end-to-end manner. Our empirical studies show that Neural Reasoner can outperform existing neural reasoning systems with remarkable margins on two difficult artificial tasks (Positional Reasoning and Path Finding) proposed in [8]. For example, it improves the accuracy on Path Finding(10K) from 33.4% [6] to over 98%.",
            "output": [
                "Towards Neural Network-based Reasoning"
            ]
        },
        {
            "id": "task1540-bd584069de0247d1a48d1660c7ca97db",
            "input": "This paper examines the \"K2\" network scoring metric of Cooper and Herskovits. It shows counterintuitive results from applying this metric to simple networks. One family of noninformative priors is suggested for assigning equal scores to equivalent networks.",
            "output": [
                "A Bayesian Method Reexamined"
            ]
        },
        {
            "id": "task1540-7645d3be9da4494ea6b04905242e9592",
            "input": "We provide a qualitative analysis of the descriptions containing negations (no, not, n’t, nobody, etc) in the Flickr30K corpus, and a categorization of negation uses. Based on this analysis, we provide a set of requirements that an image description system should have in order to generate negation sentences. As a pilot experiment, we used our categorization to manually annotate sentences containing negations in the Flickr30k corpus, with an agreement score of κ=0.67. With this paper, we hope to open up a broader discussion of subjective language in image descriptions.",
            "output": [
                "Pragmatic factors in image description: the case of negations"
            ]
        },
        {
            "id": "task1540-13508a7b736246ad87d08455429f7fa3",
            "input": "This paper presents an online transfer learning framework for improving temperature predictions in residential buildings. In transfer learning, prediction models trained under a set of available data from a target domain (e.g., house with limited data) can be improved through the use of data generated from similar source domains (e.g., houses with rich data). Given also the need for prediction models that can be trained online (e.g., as part of a model-predictive-control implementation), this paper introduces the generalized online transfer learning algorithm (GOTL). It employs a weighted combination of the available predictors (i.e., the target and source predictors) and guarantees convergence to the best weighted predictor. Furthermore, the use of Transfer Component Analysis (TCA) allows for using more than a single source domains, since it may facilitate the fit of a single model on more than one source domains (houses). This allows GOTL to transfer knowledge from more than one source domains. We further validate our results through experiments in climate control for residential buildings and show that GOTL may lead to non-negligible energy savings for given comfort levels.",
            "output": [
                "Generalized Online Transfer Learning for Climate Control in Residential BuildingsI,II"
            ]
        },
        {
            "id": "task1540-47fa90d852f94cf1af55fbad302a9961",
            "input": "Neural machine translation (NMT) offers a novel alternative formulation of translation that is potentially simpler than statistical approaches. However to reach competitive performance, NMT models need to be exceedingly large. In this paper we consider applying knowledge distillation approaches (Bucila et al., 2006; Hinton et al., 2015) that have proven successful for reducing the size of neural models in other domains to the problem of NMT. We demonstrate that standard knowledge distillation applied to word-level prediction can be effective for NMT, and also introduce two novel sequence-level versions of knowledge distillation that further improve performance, and somewhat surprisingly, seem to eliminate the need for beam search (even when applied on the original teacher model). Our best student model runs 10 times faster than its state-of-the-art teacher with only a decrease of 0.2 BLEU. It is also significantly better than a baseline model trained without knowledge distillation: by 4.2/1.7 BLEU with greedy decoding/beam search.",
            "output": [
                "Sequence-Level Knowledge Distillation"
            ]
        },
        {
            "id": "task1540-66bb10181f3641bab8f03e6bbddbcd06",
            "input": "vii",
            "output": [
                "RESOURCE SHARING FOR MULTI-TENANT NOSQL DATA STORE IN CLOUD"
            ]
        },
        {
            "id": "task1540-fbce6c38b61c4d4aa6637ac1449e1f41",
            "input": "It is the most effective way for quick translation of tremendous amount of explosively increasing science and technique information material to develop a practicable machine translation system and introduce it into translation practice. This essay treats problems arising from translation of isolated units on the basis of the practical materials and experiments obtained in the development and introduction of English-Korean machine translation system. In other words, this essay considers establishment of information for isolated units and their Korean equivalents and word order.",
            "output": [
                "New Approach to translation of Isolated Units in English-Korean Machine Translation"
            ]
        },
        {
            "id": "task1540-60a56b8c457d4e158b4bdf52dcbc30f5",
            "input": "<lb>We endow prioritised default logic (PDL) with argumentation semantics<lb>using the ASPIC framework for structured argumentation, and prove<lb>that the conclusions of the justified arguments are exactly the prioritised<lb>default extensions. Argumentation semantics for PDL will allow for the<lb>application of argument game proof theories to the process of inference<lb>in PDL, making the reasons for accepting a conclusion transparent and<lb>the inference process more intuitive. This also opens up the possibility for<lb>argumentation-based distributed reasoning and communication amongst<lb>agents with PDL representations of mental attitudes.",
            "output": [
                "Argumentation Semantics for Prioritised Default Logic"
            ]
        },
        {
            "id": "task1540-323430cfe8314cc2a122373b2c5f956a",
            "input": "We introduce a parametric form of pooling, based on a Gaussian, which can be optimized alongside the features in a single global objective function. By contrast, existing pooling schemes are based on heuristics (e.g. local maximum) and have no clear link to the cost function of the model. Furthermore, the variables of the Gaussian explicitly store location information, distinct from the appearance captured by the features, thus providing a what/where decomposition of the input signal. Although the differentiable pooling scheme can be incorporated in a wide range of hierarchical models, we demonstrate it in the context of a Deconvolutional Network model (Zeiler et al. [22]). We also explore a number of secondary issues within this model and present detailed experiments on MNIST digits.",
            "output": [
                "Differentiable Pooling for Hierarchical Feature Learning"
            ]
        },
        {
            "id": "task1540-be7bac80f52340a0ba6924089b8dba96",
            "input": "In this paper, we propose a learning-based supervised discrete hashing method. Binary hashing is widely used for large-scale image retrieval as well as video and document searches because the compact representation of binary code is essential for data storage and reasonable for query searches using bit-operations. The recently proposed Supervised Discrete Hashing (SDH) efficiently solves mixed-integer programming problems by alternating optimization and the Discrete Cyclic Coordinate descent (DCC) method. We show that the SDH model can be simplified without performance degradation based on some preliminary experiments; we call the approximate model for this the “Fast SDH” (FSDH) model. We analyze the FSDH model and provide a mathematically exact solution for it. In contrast to SDH, our model does not require an alternating optimization algorithm and does not depend on initial values. FSDH is also easier to implement than Iterative Quantization (ITQ). Experimental results involving a large-scale database showed that FSDH outperforms conventional SDH in terms of precision, recall, and computation time.",
            "output": [
                "Fast Supervised Discrete Hashing and its Analysis"
            ]
        },
        {
            "id": "task1540-3a81a9d51fe24fb1929e803bf7d38fe6",
            "input": "Neural network based approaches for sentence relation modeling automatically generate hidden matching features from raw sentence pairs. However, the quality of matching feature representation may not be satisfied due to complex semantic relations such as entailment or contradiction. To address this challenge, we propose a new deep neural network architecture that jointly leverage pre-trained word embedding and auxiliary character embedding to learn sentence meanings. The two kinds of word sequence representations as inputs into multi-layer bidirectional LSTM to learn enhanced sentence representation. After that, we construct matching features followed by another temporal CNN to learn high-level hidden matching feature representations. Experimental results demonstrate that our approach consistently outperforms the existing methods on standard evaluation datasets.",
            "output": [
                "Enhancing Sentence Relation Modeling with Auxiliary Character-level Embedding"
            ]
        },
        {
            "id": "task1540-974a19b7ae50484a9ee4af69a50d0fb0",
            "input": "Finite-sum optimization problems are ubiquitous in machine learning, and are commonly solved using first-order methods which rely on gradient computations. Recently, there has been growing interest in second-order methods, which rely on both gradients and Hessians. In principle, second-order methods can require much fewer iterations than first-order methods, and hold the promise for more efficient algorithms. Although computing and manipulating Hessians is prohibitive for high-dimensional problems in general, the Hessians of individual functions in finite-sum problems can often be efficiently computed, e.g. because they possess a low-rank structure. Can second-order information indeed be used to solve such problems more efficiently? In this paper, we provide evidence that the answer – perhaps surprisingly – is negative, at least in terms of worst-case guarantees. However, we also discuss what additional assumptions and algorithmic approaches might potentially circumvent this negative result.",
            "output": [
                "Oracle Complexity of Second-Order Methods for Finite-Sum Problems"
            ]
        },
        {
            "id": "task1540-3c1f5eea4e5c499598666d254aeeb927",
            "input": "In this paper we introduce Refractor Importance Sampling (RIS), an improvement to reduce error variance in Bayesian network importance sampling propagation under evidential reasoning. We prove the existence of a collection of importance functions that are close to the optimal importance function under evidential reasoning. Based on this theoretic result we derive the RIS algorithm. RIS approaches the optimal importance function by applying localized arc changes to minimize the divergence between the evidence-adjusted importance function and the optimal importance function. The validity and performance of RIS is empirically tested with a large set of synthetic Bayesian networks and two realworld networks.",
            "output": [
                "Refractor Importance Sampling"
            ]
        },
        {
            "id": "task1540-c71e783f43814d7e832c43257fcab71c",
            "input": "Determinantal point processes (DPPs) are popular probabilistic models that arise in many machine learning tasks, where distributions of diverse sets are characterized by matrix determinants. In this paper, we develop fast algorithms to find the most likely configuration (MAP) of large-scale DPPs, which is NP-hard in general. Due to the submodular nature of the MAP objective, greedy algorithms have been used with empirical success. Greedy implementations require computation of log-determinants, matrix inverses or solving linear systems at each iteration. We present faster implementations of the greedy algorithms by utilizing the complementary benefits of two log-determinant approximation schemes: (a) first-order expansions to the matrix log-determinant function and (b) high-order expansions to the scalar log function with stochastic trace estimators. In our experiments, our algorithms are orders of magnitude faster than their competitors, while sacrificing marginal accuracy.",
            "output": [
                "Faster Greedy MAP Inference for Determinantal Point Processes"
            ]
        },
        {
            "id": "task1540-1453b45c6b82439db940cf6d8395115f",
            "input": "Rumour stance classification, the task that determines if each tweet in a collection discussing a rumour is supporting, denying, questioning or simply commenting on the rumour, has been attracting substantial interest. Here we introduce a novel approach that makes use of the sequence of transitions observed in tree-structured conversation threads in Twitter. The conversation threads are formed by harvesting users’ replies to one another, which results in a nested tree-like structure. Previous work addressing the stance classification task has treated each tweet as a separate unit. Here we analyse tweets by virtue of their position in a sequence and test two sequential classifiers, Linear-Chain CRF and Tree CRF, each of which makes different assumptions about the conversational structure. We experiment with eight Twitter datasets, collected during breaking news, and show that exploiting the sequential structure of Twitter conversations achieves significant improvements over the non-sequential methods. Our work is the first to model Twitter conversations as a tree structure in this manner, introducing a novel way of tackling NLP tasks on Twitter conversations.",
            "output": [
                "Stance Classification in Rumours as a Sequential Task Exploiting the Tree Structure of Social Media Conversations"
            ]
        },
        {
            "id": "task1540-3ad5137416fe444a8d8e8988b89d3512",
            "input": "Reference is a crucial property of language that allows us to connect linguistic expressions to the world. Modeling it requires handling both continuous and discrete aspects of meaning. Data-driven models excel at the former, but struggle with the latter, and the reverse is true for symbolic models. This paper (a) introduces a concrete referential task to test both aspects, called cross-modal entity tracking; (b) proposes a neural network architecture that uses external memory to build an entity library inspired in the DRSs of DRT, with a mechanism to dynamically introduce new referents or add information to referents that are already in the library. Our model shows promise: it beats traditional neural network architectures on the task. However, it is still outperformed by Memory Networks, another model with external memory.",
            "output": [
                "Living a discrete life in a continuous world: Reference in cross-modal entity tracking"
            ]
        },
        {
            "id": "task1540-4bf7158160a5423abeb651908402656c",
            "input": "Answer Set Programming (ASP) is a well-established paradigm of declarative programming that has been developed in the field of logic programming and nonmonotonic reasoning. Advances in ASP solving technology are customarily assessed in competition events, as it happens for other closely-related problemsolving technologies like SAT/SMT, QBF, Planning and Scheduling. ASP Competitions are (usually) biennial events; however, the Fifth ASP Competition departs from tradition, in order to join the FLoC Olympic Games at the Vienna Summer of Logic 2014, which is expected to be the largest event in the history of logic. This edition of the ASP Competition series is jointly organized by the University of Calabria (Italy), the Aalto University (Finland), and the University of Genova (Italy), and is affiliated with the 30th International Conference on Logic Programming (ICLP 2014). It features a completely re-designed setup, with novelties involving the design of tracks, the scoring schema, and the adherence to a fixed modeling language in order to push the adoption of the ASP-Core-2 standard. Benchmark domains are taken from past editions, and best system packages submitted in 2013 are compared with new versions and solvers.",
            "output": [
                "The Design of the Fifth Answer Set Programming Competition"
            ]
        },
        {
            "id": "task1540-4d1ac6fd86294b6e8acfbe40947f2bcb",
            "input": "Research on Symbolic Probabilistic Inference (SPI) [2, 3) has provided an algorithm for re­ solving general queries in Bayesian networks. SPI applies the concept of dependency­ directed backward search to probabilistic in­ ference, and is incremental with respect to both queries and observations. Unlike tra­ ditional Bayesian network inferencing algo­ rithms, SPI algorithm is goal directed, per­ forming only those calculations that are re­ quired to respond to queries. Research to date on SPI applies to Bayesian networks with discrete-valued variables and does not address variables with continuous values. In this paper1, we extend the SPI algorithm to handle Bayesian networks made up of continuous variables where the relationships between the variables are restricted to be \"linear gaussian\". We call this variation of the SPI algorithm, SPI Continuous (SPIC). SPIC modifies the three basic SPI opera­ tions: multiplication, summation, and sub­ stitution. However, SPIC retains the frame­ work of the SPI algorithm, namely building the search tree and recursive query mecha­ nism and therefore retains the goal-directed and incrementality features of SPI.",
            "output": [
                "Symbolic Probabilistic Inference with Continuous Variables"
            ]
        },
        {
            "id": "task1540-4548503f336942f0b1ef495bcca10b99",
            "input": "Over the past two decades, the feedforward neural network (FNN) optimization has been a key interest among the researchers and practitioners of multiple disciplines. The FNN optimization is often viewed from the various perspectives: the optimization of weights, network architecture, activation nodes, learning parameters, learning environment, etc. Researchers adopted such different viewpoints mainly to improve the FNN’s generalization ability. The gradient-descent algorithm such as backpropagation has been widely applied to optimize the FNNs. Its success is evident from the FNN’s application to numerous real-world problems. However, due to the limitations of the gradient-based optimization methods, the metaheuristic algorithms including the evolutionary algorithms, swarm intelligence, etc., are still being widely explored by the researchers aiming to obtain generalized FNN for a given problem. This article attempts to summarize a broad spectrum of FNN optimization methodologies including conventional and metaheuristic approaches. This article also tries to connect various research directions emerged out of the FNN optimization practices, such as evolving neural network (NN), cooperative coevolution NN, complex-valued NN, deep learning, extreme learning machine, quantum NN, etc. Additionally, it provides interesting research challenges for future research to cope-up with the present information processing era.",
            "output": [
                "Metaheuristic Design of Feedforward Neural Networks: A Review of Two Decades of Research"
            ]
        },
        {
            "id": "task1540-5010c819e23f4cc496d46d199012c769",
            "input": "We study the problem of learning in the presence of a drifting target concept. Specifically, we provide bounds on the error rate at a given time, given a learner with access to a history of independent samples labeled according to a target concept that can change on each round. One of our main contributions is a refinement of the best previous results for polynomial-time algorithms for the space of linear separators under a uniform distribution. We also provide general results for an algorithm capable of adapting to a variable rate of drift of the target concept. Some of the results also describe an active learning variant of this setting, and provide bounds on the number of queries for the labels of points in the sequence sufficient to obtain the stated bounds on the error rates.",
            "output": [
                "Learning with a Drifting Target Concept"
            ]
        },
        {
            "id": "task1540-10deba8b096e44b092ba1a6f5a54bf2b",
            "input": "In this paper, we propose epitomic variational autoencoder (eVAE), a probabilistic generative model of high dimensional data. eVAE is composed of a number of sparse variational autoencoders called ‘epitome’ such that each epitome partially shares its encoder-decoder architecture with other epitomes in the composition. We show that the proposed model greatly overcomes the common problem in variational autoencoders (VAE) of model over-pruning. We substantiate that eVAE is efficient in using its model capacity and generalizes better than VAE, by presenting qualitative and quantitative results on MNIST and TFD datasets.",
            "output": [
                "EPITOMIC VARIATIONAL AUTOENCODER"
            ]
        },
        {
            "id": "task1540-60980ced86924832997173d2639bf5b8",
            "input": "Bayesian optimization has proven to be a highly effective methodology for the global optimization of unknown, expensive and multimodal functions. The ability to accurately model distributions over functions is critical to the effectiveness of Bayesian optimization. Although Gaussian processes provide a flexible prior over functions, there are various classes of functions that remain difficult to model. One of the most frequently occurring of these is the class of non-stationary functions. The optimization of the hyperparameters of machine learning algorithms is a problem domain in which parameters are often manually transformed a priori, for example by optimizing in “log-space,” to mitigate the effects of spatially-varying length scale. We develop a methodology for automatically learning a wide family of bijective transformations or warpings of the input space using the Beta cumulative distribution function. We further extend the warping framework to multi-task Bayesian optimization so that multiple tasks can be warped into a jointly stationary space. On a set of challenging benchmark optimization tasks, we observe that the inclusion of warping greatly improves on the state-of-the-art, producing better results faster and more reliably.",
            "output": [
                "INPUT WARPING FOR BAYESIAN OPTIMIZATION OF NON-STATIONARY FUNCTIONS BY JASPER SNOEK"
            ]
        },
        {
            "id": "task1540-cdf64ce21497467da4f849c62b0c3e5c",
            "input": "We develop a worst-case analysis of aggregation of binary classifier ensembles in a transductive setting, for a broad class of losses including but not limited to all convex surrogates. The result is a family of parameter-free ensemble aggregation algorithms, which are as efficient as linear learning and prediction for convex risk minimization but work without any relaxations whatsoever on many nonconvex losses like the 0-1 loss. The prediction algorithms take a familiar form, applying “link functions\" to a generalized notion of ensemble margin, but without the assumptions typically made in margin-based learning – all this structure follows from a minimax interpretation of loss minimization.",
            "output": [
                "Minimax Binary Classifier Aggregation with General Losses"
            ]
        },
        {
            "id": "task1540-9763d30b2535457a86f53d71b4501282",
            "input": "We study the problem of learning local metrics for nearest neighbor classification. Most previous works on local metric learning learn a number of local unrelated metrics. While this ”independence” approach delivers an increased flexibility its downside is the considerable risk of overfitting. We present a new parametric local metric learning method in which we learn a smooth metric matrix function over the data manifold. Using an approximation error bound of the metric matrix function we learn local metrics as linear combinations of basis metrics defined on anchor points over different regions of the instance space. We constrain the metric matrix function by imposing on the linear combinations manifold regularization which makes the learned metric matrix function vary smoothly along the geodesics of the data manifold. Our metric learning method has excellent performance both in terms of predictive power and scalability. We experimented with several largescale classification problems, tens of thousands of instances, and compared it with several state of the art metric learning methods, both global and local, as well as to SVM with automatic kernel selection, all of which it outperforms in a significant manner.",
            "output": [
                "Parametric Local Metric Learning for Nearest Neighbor Classification"
            ]
        },
        {
            "id": "task1540-5058399492a04853a948fe6260996350",
            "input": "Traditional information retrieval systems rely on keywords to index documents and queries. In such systems, documents are retrieved based on the number of shared keywords with the query. This lexicalfocused retrieval leads to inaccurate and incomplete results when different keywords are used to describe the documents and queries. Semantic-focused retrieval approaches attempt to overcome this problem by relying on concepts rather than on keywords to indexing and retrieval. The goal is to retrieve documents that are semantically relevant to a given user query. This paper addresses this issue by proposing a solution at the indexing level. More precisely, we propose a novel approach for semantic indexing based on concepts identified from a linguistic resource. In particular, our approach relies on the joint use of WordNet and WordNetDomains lexical databases for concept identification. Furthermore, we propose a semantic-based concept weighting scheme that relies on a novel definition of concept centrality. The resulting system is evaluated on the TIME test collection. Experimental results show the effectiveness of our proposition over traditional IR approaches.",
            "output": [
                "CONCEPT-BASED INDEXING IN TEXT INFORMATION RETRIEVAL"
            ]
        },
        {
            "id": "task1540-c9643e4c45b449ac847b8dc399bae933",
            "input": "Sentiment prediction of contemporary music can have a wide-range of applications in modern society, for instance, selecting music for public institutions such as hospitals or restaurants to potentially improve the emotional well-being of personnel, patients, and customers, respectively. In this project, music recommendation system built upon on a naive Bayes classifier, trained to predict the sentiment of songs based on song lyrics alone. The experimental results show that music corresponding to a happy mood can be detected with high precision based on text features obtained from song lyrics.",
            "output": [
                "MusicMood: Predicting the mood of music from song lyrics using machine learning"
            ]
        },
        {
            "id": "task1540-0d3acaec232d41c1bdfaba457d1370a5",
            "input": "Résumé : Les tests de pénétration sont une méthodologie pour évaluer la sécurité d’un réseau en générant et exécutant de possibles attaques informatiques. Automatiser cette tâche permet de réaliser des tests réguliers et systématiques. Une question clef est : “Comment générer ces attaques ?” Ce problème se formule naturellement comme de la planification dans l’incertain, plus précisément avec une connaissance incomplète de la configuration du réseau. Les travaux antérieurs emploient de la planification classique, et requièrent de coûteux pré-traitements réduisant cette incertitude par l’application extensive de méthodes de scan. Au contraire, nous modélisons ici le problème de la planification d’attaques à travers des processus de décision markoviens partiellement observables (POMDP). Ceci nous permet de raisonner à propos de la connaissance disponible, et d’employer intelligemment les actions de scan comme faisant partie de l’attaque. Comme on s’y attendrait, cette solution précise ne passe pas à l’échelle. Nous concevons donc une méthode qui repose sur les POMDP pour trouver de bonnes attaques sur des machines individuelles, lesquelles sont recomposées en une attaque sur le réseau complet. Cette décomposition exploite la structure du réseau dans la mesure du possible, faisant des approximations ciblées (seulement) où cela est nécessaire. En évaluant cette méthode sur un jeu de tests industriels adaptés convenablement, nous démontrons son efficacité à la fois en temps de calcul et en qualité de la solution.",
            "output": [
                "Les POMDP font de meilleurs hackers: Tenir compte de l’incertitude dans les tests de pénétration"
            ]
        },
        {
            "id": "task1540-e5555820cbc04e13b82fb8dbbabdb0ef",
            "input": "Deep learning thrives with large neural networks and large datasets. However, larger networks and larger datasets result in longer training times that impede research and development progress. Distributed synchronous SGD offers a potential solution to this problem by dividing SGD minibatches over a pool of parallel workers. Yet to make this scheme efficient, the per-worker workload must be large, which implies nontrivial growth in the SGD minibatch size. In this paper, we empirically show that on the ImageNet dataset large minibatches cause optimization difficulties, but when these are addressed the trained networks exhibit good generalization. Specifically, we show no loss of accuracy when training with large minibatch sizes up to 8192 images. To achieve this result, we adopt a linear scaling rule for adjusting learning rates as a function of minibatch size and develop a new warmup scheme that overcomes optimization challenges early in training. With these simple techniques, our Caffe2-based system trains ResNet50 with a minibatch size of 8192 on 256 GPUs in one hour, while matching small minibatch accuracy. Using commodity hardware, our implementation achieves ∼90% scaling efficiency when moving from 8 to 256 GPUs. This system enables us to train visual recognition models on internetscale data with high efficiency.",
            "output": [
                "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour"
            ]
        },
        {
            "id": "task1540-e982f94045b24c3787f76b986c50f49a",
            "input": "We formulate a phonetic-prosodic space based on attributes as perceptual observables, rather than articulatory specifications. We propose an alphabet as markers in the phonetic subspace, aiming for a resolution sufficient to support recognition of all spoken languages. The prosodic subspace is made up of directly measurable physical variables. With the proposed alphabet, traditional diphthongs naturally generalize to a broader class of language-neutral phonotactic constraints, indicating a correlation structure similar to that of the traditional sonority-based syllable. We define a stochastic structure on the phone strings based on this diphthongal constraint, and show how a specific spoken language can be defined as a specific set of probability distributions of this stochastic structure. Furthermore, phonological variations within a spoken language can be modeled as varying probability distributions restricted to the phonetic subspace, conditioned on different values in the prosodic subspace.",
            "output": [
                "A 10-dimensional Phonetic-prosodic Space and its Stochastic Structure A framework for probabilistic modeling of spoken languages and their phonology"
            ]
        },
        {
            "id": "task1540-d09f43fa33de44ae8e8f40048ddf6260",
            "input": "We present an approach for the verification of feed-forward neural networks in which all nodes have a piece-wise linear activation function. Such networks are often used in deep learning and have been shown to be hard to verify for modern satisfiability modulo theory (SMT) and integer linear programming (ILP) solvers. The starting point of our approach is the addition of a global linear approximation of the overall network behavior to the verification problem that helps with SMT-like reasoning over the network behavior. We present a specialized verification algorithm that employs this approximation in a search process in which it infers additional node phases for the non-linear nodes in the network from partial node phase assignments, similar to unit propagation in classical SAT solving. We also show how to infer additional conflict clauses and safe node fixtures from the results of the analysis steps performed during the search. The resulting approach is evaluated on collision avoidance and handwritten digit recognition case studies.",
            "output": [
                "Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks"
            ]
        },
        {
            "id": "task1540-2d8b1c19aa9f4b29923c4f9fea94f98e",
            "input": "The study of phase transition phenomenon of NP complete problems plays an important role in understanding the nature of hard problems. In this paper, we follow this line of research by considering the problem of counting solutions of Constraint Satisfaction Problems (#CSP). We consider the random model, i.e. RB model. We prove that phase transition of #CSP does exist as the number of variables approaches infinity and the critical values where phase transitions occur are precisely located. Preliminary experimental results also show that the critical point coincides with the theoretical derivation. Moreover, we propose an approximate algorithm to estimate the expectation value of the solutions number of a given CSP instance of RB model.",
            "output": [
                "Counting Solutions of Constraint Satisfiability Problems: Exact Phase Transitions and Approximate Algorithm"
            ]
        },
        {
            "id": "task1540-4329c4c578904e3da518a9559863de1e",
            "input": "Accurate, robust, inexpensive gaze tracking in the car can help keep a driver safe by facilitating the more effective study of how to improve (1) vehicle interfaces and (2) the design of future Advanced Driver Assistance Systems. In this paper, we estimate head pose and eye pose from monocular video using methods developed extensively in prior work and ask two new interesting questions. First, how much better can we classify driver gaze using head and eye pose versus just using head pose? Second, are there individual-specific gaze strategies that strongly correlate with how much gaze classification improves with the addition of eye pose information? We answer these questions by evaluating data drawn from an on-road study of 40 drivers. The main insight of the paper is conveyed through the analogy of an “owl” and “lizard” which describes the degree to which the eyes and the head move when shifting gaze. When the head moves a lot (“owl”), not much classification improvement is attained by estimating eye pose on top of head pose. On the other hand, when the head stays still and only the eyes move (“lizard”), classification accuracy increases significantly from adding in eye pose. We characterize how that accuracy varies between people, gaze strategies, and gaze regions.",
            "output": [
                "Owl and Lizard: Patterns of Head Pose and Eye Pose in Driver Gaze Classification"
            ]
        },
        {
            "id": "task1540-869ff1ae9b0f40b1a713712fa13b754e",
            "input": "Dependency parsers are among the most crucial tools in natural language processing as they have many important applications in downstream tasks such as information retrieval, machine translation and knowledge acquisition. We introduce the Yara Parser, a fast and accurate open-source dependency parser based on the arc-eager algorithm and beam search. It achieves an unlabeled accuracy of 93.32 on the standard WSJ test set which ranks it among the top dependency parsers. At its fastest, Yara can parse about 4000 sentences per second when in greedy mode (1 beam). When optimizing for accuracy (using 64 beams and Brown cluster features), Yara can parse 45 sentences per second. The parser can be trained on any syntactic dependency treebank and different options are provided in order to make it more flexible and tunable for specific tasks. It is released with the Apache version 2.0 license and can be used for both commercial and academic purposes. The parser can be found at https: //github.com/yahoo/YaraParser.",
            "output": [
                "Yara Parser: A Fast and Accurate Dependency Parser"
            ]
        },
        {
            "id": "task1540-78b5cd53e510418bb68645c685deedc5",
            "input": "Given recent deep learning results that demonstrate the ability to effectively optimize high-dimensional non-convex functions with gradient descent optimization on GPUs, we ask in this paper whether symbolic gradient optimization tools such as Tensorflow can be effective for planning in hybrid (mixed discrete and continuous) nonlinear domains with high dimensional state and action spaces? To this end, we demonstrate that hybrid planning with Tensorflow and RMSProp gradient descent is competitive with mixed integer linear program (MILP) based optimization on piecewise linear planning domains (where we can compute optimal solutions) and substantially outperforms state-of-the-art interior point methods for nonlinear planning domains. Furthermore, we remark that Tensorflow is highly scalable, converging to a strong policy on a largescale concurrent domain with a total of 576,000 continuous actions over a horizon of 96 time steps in only 4 minutes. We provide a number of insights that clarify such strong performance including observations that despite long horizons, RMSProp avoids both the vanishing and exploding gradients problem. Together these results suggest a new frontier for highly scalable planning in nonlinear hybrid domains by leveraging GPUs and the power of recent advances in gradient descent with highly optmized toolkits like Tensorflow. Introduction Many real-world hybrid (mixed discrete continuous) planning problems such as Reservoir Control [Yeh, 1985], Heating, Ventilation and Air Conditioning (HVAC) [Erickson et al., 2009; Agarwal et al., 2010], and Navigation [Faulwasser and Findeisen, 2009] have highly nonlinear transition and (possibly nonlinear) reward functions to optimize. Unfortunately, existing state-of-the-art hybrid planners [Ivankovic et al., 2014; Löhr et al., 2012; Coles et al., 2013; Piotrowski et al., 2016] are not compatible with arbitrary nonlinear transition and reward models. Monte Carlo Tree Search (MCTS) methods [Coulom, 2006; Kocsis and Szepesvári, 2006; Keller and Helmert, 2013] 0.600 0.750 .900 0.600 0.750 .900 0.600 0.750 0.9 00 0.600 0.750 .900 0.600 0.750 .900 0.600 0.750 .900 0.600 0.750 0.9 00 Epochs:10 Epochs:20 Epochs:40 Epochs:80 Epochs:160 Epochs:320 Figure 1: The evolution of RMSProp gradient descent based Tensorflow planning in a 2D Navigation domain with nested central rectangles indicating nonlinearly increasing resistance to robot movement. (top) In initial RMSProp epochs, the plan evolves directly towards the goal shown as a star. (bottom) As later epochs of RMSProp descend the objective cost surface, the fastest path evolves to avoid the central obstacle entirely. including AlphaGo [Silver et al., 2016] that can use any (nonlinear) black box model of transition dynamics do not inherently work with continuous action spaces due to the infinite branching factor. While MCTS with continuous action extensions such as HOOT [Weinstein and Littman, 2012] have been proposed, their continuous partitioningmethods do not scale to high-dimensional continuous action spaces (e.g., 100’s or 1,000’s of dimensions as used in this paper). Finally, offline model-free reinforcement learning (e.g., Q-learning) with function approximation [Sutton and Barto, 1998; Szepesvári, 2010] and deep extensions [Mnih et al., 2013] do not require any knowledge of the (nonlinear) transition model or reward, but they also do not directly apply to domains with high-dimensional continuous action spaces. I.e., offline learning methods like Q-learning require action maximization for every update, but in high-dimensional continuous action spaces such nonlinear function maximization is non-convex and computationally intractable at the scale of millions or billions of updates. To address the above scalability and expressivity limitations of existing methods, we turn to Tensorflow [Abadi et al., 2015], which is a symbolic computation platform used in the machine learning community for deep learning due to its compilation of complex layered symbolic functions into a representation amenable to fast GPU-based reverse-mode automatic differentiation [Linnainmaa, 1970] for gradient-based optimization. Given recent results in gradient descent optimization with deep learning that demonstrate the ability to effectively optimize high-dimensional non-convex functions, we ask whether Tensorflow can be effective for planning in hybrid (mixed discrete and continuous) nonlinear domains with high dimensional state and action spaces? Our results answer this question affirmatively, where we demonstrate that hybrid planning with Tensorflow and RMSProp gradient descent [Tieleman and Hinton, 2012] is surprisingly effective at planning in complex hybrid nonlinear domains. As evidence, we reference figure 1, where we show Tensorflow with RMSProp optimizing a path in a 2d nonlinear Navigation domain. In general, Tensorflow with RMSProp planning results are competitive with optimal MILPbased optimization on piecewise linear planning domains and directly extend to nonlinear domains, where they substantially outperform interior point methods for nonlinear function optimization. Furthermore, we remark that Tensorflow converges to a strong policy on a large-scale concurrent domain with 576,000 continuous actions spread over a horizon of 96 time steps in 4 minutes. To explain such excellent results, we note that gradient descent algorithms such as RMSProp are highly effective for the non-convex function optimization that occurs in deep learning. Further, we provide an analysis of many transition functions in planning domains that suggest gradient descent on these domains will not suffer from either the vanishing or exploding gradient problems and hence provide a strong signal for optimization over long horizons. Together these results suggest a new frontier for highly scalable planning in nonlinear hybrid domains by leveraging GPUs and the power of recent advances in gradient descent with the Tensorflow toolkit. Hybrid Nonlinear Planning via Tensorflow",
            "output": [
                "Scalable Planning with Tensorflow for Hybrid Nonlinear Domains"
            ]
        },
        {
            "id": "task1540-428e549df6a0429494ce40b5a00aa32f",
            "input": "Hand-crafted features based on linguistic and domain-knowledge play crucial role in determining the performance of disease name recognition systems. Such methods are further limited by the scope of these features or in other words, their ability to cover the contexts or word dependencies within a sentence. In this work, we focus on reducing such dependencies and propose a domain-invariant framework for the disease name recognition task. In particular, we propose various end-to-end recurrent neural network (RNN) models for the tasks of disease name recognition and their classification into four pre-defined categories. We also utilize convolution neural network (CNN) in cascade of RNN to get character-based embedded features and employ it with word-embedded features in our model. We compare our models with the state-of-the-art results for the two tasks on NCBI disease dataset. Our results for the disease mention recognition task indicate that state-of-the-art performance can be obtained without relying on feature engineering. Further the proposed models obtained improved performance on the classification task of disease names.",
            "output": [
                "Recurrent neural network models for disease name recognition using domain invariant features"
            ]
        },
        {
            "id": "task1540-a5cec44af7444430b20e900e08eca397",
            "input": "In the Bayesian Reinforcement Learning (BRL) setting, agents try to maximise the collected rewards while interacting with their environment while using some prior knowledge that is accessed beforehand. Many BRL algorithms have already been proposed, but even though a few toy examples exist in the literature, there are still no extensive or rigorous benchmarks to compare them. The paper addresses this problem, and provides a new BRL comparison methodology along with the corresponding open source library. In this methodology, a comparison criterion that measures the performance of algorithms on large sets of Markov Decision Processes (MDPs) drawn from some probability distributions is defined. In order to enable the comparison of non-anytime algorithms, our methodology also includes a detailed analysis of the computation time requirement of each algorithm. Our library is released with all source code and documentation: it includes three test problems, each of which has two different prior distributions, and seven state-of-the-art RL algorithms. Finally, our library is illustrated by comparing all the available algorithms and the results are discussed.",
            "output": [
                "Benchmarking for Bayesian Reinforcement Learning Benchmarking for Bayesian Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-59f69b4fd6134168a20314e9a0a90f14",
            "input": "Model counting is the problem of computing the number of models that satisfy a given propositional theory. It has recently been applied to solving inference tasks in probabilistic logic programming, where the goal is to compute the probability of given queries being true provided a set of mutually independent random variables, a model (a logic program) and some evidence. The core of solving this inference task involves translating the logic program to a propositional theory and using a model counter. In this paper, we show that for some problems that involve inductive definitions like reachability in a graph, the translation of logic programs to SAT can be expensive for the purpose of solving inference tasks. For such problems, direct implementation of stable model semantics allows for more efficient solving. We present two implementation techniques, based on unfounded set detection, that extend a propositional model counter to a stable model counter. Our experiments show that for particular problems, our approach can outperform a state-of-the-art probabilistic logic programming solver by several orders of magnitude in terms of running time and space requirements, and can solve instances of significantly larger sizes on which the current solver runs out of time or memory.",
            "output": [
                "Stable Model Counting and Its Application in Probabilistic Logic Programming"
            ]
        },
        {
            "id": "task1540-0b288ace543b41238d76b582f73ba271",
            "input": "With the release of SentiWordNet 3.0 the related Web interface has been restyled and improved in order to allow users to submit feedback on the SentiWordNet entries, in the form of the suggestion of alternative triplets of values for an entry. This paper reports on the release of the user feedback collected so far and on the plans for the future.",
            "output": [
                "The User Feedback on SentiWordNet"
            ]
        },
        {
            "id": "task1540-5fdbddb99b4a4ac0ad48e095a3a18a93",
            "input": "Convolutional rectifier networks, i.e. convolutional neural networks with rectified linear activation and max or average pooling, are the cornerstone of modern deep learning. However, despite their wide use and success, our theoretical understanding of the expressive properties that drive these networks is partial at best. On other hand, we have a much firmer grasp of these issues in the world of arithmetic circuits. Specifically, it is known that convolutional arithmetic circuits posses the property of ”complete depth efficiency”, meaning that besides a negligible set, all functions that can be implemented by a deep network of polynomial size, require exponential size in order to be implemented (or even approximated) by a shallow network. In this paper we describe a construction based on generalized tensor decompositions, that transforms convolutional arithmetic circuits into convolutional rectifier networks. We then use mathematical tools available from the world of arithmetic circuits to prove new results. First, we show that convolutional rectifier networks are universal with max pooling but not with average pooling. Second, and more importantly, we show that depth efficiency is weaker with convolutional rectifier networks than it is with convolutional arithmetic circuits. This leads us to believe that developing effective methods for training convolutional arithmetic circuits, thereby fulfilling their expressive potential, may give rise to a deep learning architecture that is provably superior to convolutional rectifier networks but has so far been overlooked by practitioners.",
            "output": [
                "Convolutional Rectifier Networks as Generalized Tensor Decompositions"
            ]
        },
        {
            "id": "task1540-7830866d1abf423294e685bd6816a61c",
            "input": "Levels are a key component of many different video games, and a large body of work has been produced on how to procedurally generate game levels. Recently, Machine Learning techniques have been applied to video game level generation towards the purpose of automatically generating levels that have the properties of the training corpus. Towards that end we have made available a corpora of video game levels in an easy to parse format ideal for different machine learning and other game AI research purposes.",
            "output": [
                "The VGLC: The Video Game Level Corpus"
            ]
        },
        {
            "id": "task1540-7d4842db91b345279bdf7a95de164a3b",
            "input": "Convolutional neural networks provide visual features that perform remarkably well in many computer vision applications. However, training these networks requires significant amounts of supervision. This paper introduces a generic framework to train deep networks, end-to-end, with no supervision. We propose to fix a set of target representations, called Noise As Targets (NAT), and to constrain the deep features to align to them. This domain agnostic approach avoids the standard unsupervised learning issues of trivial solutions and collapsing of features. Thanks to a stochastic batch reassignment strategy and a separable square loss function, it scales to millions of images. The proposed approach produces representations that perform on par with state-of-the-art unsupervised methods on ImageNet and PASCAL VOC.",
            "output": [
                "Unsupervised Learning by Predicting Noise"
            ]
        },
        {
            "id": "task1540-0989861a5599494fba18801bf0a71639",
            "input": "A neighborhood graph, which represents the instances as vertices and their relations as weighted edges, is the basis of many semi-supervised and relational models for node labeling and link prediction. Most methods employ a sequential process to construct the neighborhood graph. This process often consists of generating a candidate graph, pruning the candidate graph to make a neighborhood graph, and then performing inference on the variables (i.e., nodes) in the neighborhood graph. In this paper, we propose a framework that can dynamically adapt the neighborhood graph based on the states of variables from intermediate inference results, as well as structural properties of the relations connecting them. A key strength of our framework is its ability to handle multi-relational data and employ varying amounts of relations for each instance based on the intermediate inference results. We formulate the link prediction task as inference on neighborhood graphs, and include preliminary results illustrating the effects of different strategies in our proposed framework.",
            "output": [
                "Adaptive Neighborhood Graph Construction for Inference in Multi-Relational Networks"
            ]
        },
        {
            "id": "task1540-58eb526585984bcb930ca5631247b598",
            "input": "Observations consisting of measurements on relationships for pairs of objects arise in many settings, such as protein interaction and gene regulatory networks, collections of author-recipient email, and social networks. Analyzing such data with probabilisic models can be delicate because the simple exchangeability assumptions underlying many boilerplate models no longer hold. In this paper, we describe a latent variable model of such data called the mixed membership stochastic blockmodel. This model extends blockmodels for relational data to ones which capture mixed membership latent relational structure, thus providing an object-specific low-dimensional representation. We develop a general variational inference algorithm for fast approximate posterior inference. We explore applications to social and protein interaction networks.",
            "output": [
                "Mixed Membership Stochastic Blockmodels"
            ]
        },
        {
            "id": "task1540-a0f82d9006034ce8b929a0fa920fde17",
            "input": "From the point of view of a programmer, the robopsychology is a synonym for the activity is done by developers to implement their machine learning applications. This robopsychological approach raises some fundamental theoretical questions of machine learning. Our discussion of these questions is constrained to Turing machines. Alan Turing had given an algorithm (aka the Turing Machine) to describe algorithms. If it has been applied to describe itself then this brings us to Turing’s notion of the universal machine. In the present paper, we investigate algorithms to write algorithms. From a pedagogy point of view, this way of writing programs can be considered as a combination of learning by listening and learning by doing due to it is based on applying agent technology and machine learning. As the main result we introduce the problem of learning and then we show that it cannot easily be handled in reality therefore it is reasonable to use machine learning algorithm for learning Turing machines.",
            "output": [
                "Theoretical Robopsychology: Samu Has Learned Turing Machines"
            ]
        },
        {
            "id": "task1540-6097be33193146e0a51a00480dd6f6c5",
            "input": "Verifiability is one of the core editing principles in Wikipedia, editors being encouraged to provide citations for the added content. For a Wikipedia article, determining the citation span of a citation, i.e. what content is covered by a citation, is important as it helps decide for which content citations are still missing. We are the first to address the problem of determining the citation span in Wikipedia articles. We approach this problem by classifying which textual fragments in an article are covered by a citation. We propose a sequence classification approach where for a paragraph and a citation, we determine the citation span at a finegrained level. We provide a thorough experimental evaluation and compare our approach against baselines adopted from the scientific domain, where we show improvement for all evaluation metrics.",
            "output": [
                "Fine-Grained Citation Span Detection for References in Wikipedia"
            ]
        },
        {
            "id": "task1540-e5c9adcc7a704f9eb2353d8e8bd50cd7",
            "input": "Predicting the outcomes of future events is a challenging problem for which a variety of solution methods have been explored and attempted. We present an empirical comparison of a variety of online and offline adaptive algorithms for aggregating experts’ predictions of the outcomes of five years of US National Football League games (1319 games) using expert probability elicitations obtained from an Internet contest called ProbabilitySports. We find that it is difficult to improve over simple averaging of the predictions in terms of prediction accuracy, but that there is room for improvement in quadratic loss. Somewhat surprisingly, a Bayesian estimation algorithm which estimates the variance of each expert’s prediction exhibits the most consistent superior performance over simple averaging among our collection of algorithms.",
            "output": [
                "An Empirical Comparison of Algorithms for Aggregating Expert Predictions"
            ]
        },
        {
            "id": "task1540-ac8fdaa95dcc4a209f165005208b68fd",
            "input": "Matrix-parametrized models, including multiclass logistic regression and sparse coding, are used in machine learning (ML) applications ranging from computer vision to computational biology. When these models are applied to large-scale ML problems starting at millions of samples and tens of thousands of classes, their parameter matrix can grow at an unexpected rate, resulting in high parameter synchronization costs that greatly slow down distributed learning. To address this issue, we propose a Sufficient Factor Broadcasting (SFB) computation model for efficient distributed learning of a large family of matrix-parameterized models, which share the following property: the parameter update computed on each data sample is a rank-1 matrix, i.e. the outer product of two “sufficient factors” (SFs). By broadcasting the SFs among worker machines and reconstructing the update matrices locally at each worker, SFB improves communication efficiency — communication costs are linear in the parameter matrix’s dimensions, rather than quadratic — without affecting computational correctness. We present a theoretical convergence analysis of SFB, and empirically corroborate its efficiency on four different matrix-parametrized ML models.",
            "output": [
                "Distributed Machine Learning via Sufficient Factor Broadcasting"
            ]
        },
        {
            "id": "task1540-8e37a1e9f0604b28bf6e7c76deea8489",
            "input": "We consider the problem of principal component analysis (PCA) in a streaming stochastic setting, where our goal is to find a direction of approximate maximal variance, based on a stream of i.i.d. data points in R. A simple and computationally cheap algorithm for this is stochastic gradient descent (SGD), which incrementally updates its estimate based on each new data point. However, due to the non-convex nature of the problem, analyzing its performance has been a challenge. In particular, existing guarantees rely on a non-trivial eigengap assumption on the covariance matrix, which is intuitively unnecessary. In this paper, we provide (to the best of our knowledge) the first eigengap-free convergence guarantees for SGD in the context of PCA. This also partially resolves an open problem posed in [10]. Moreover, under an eigengap assumption, we show that the same techniques lead to new SGD convergence guarantees with better dependence on the eigengap.",
            "output": [
                "Convergence of Stochastic Gradient Descent for PCA"
            ]
        },
        {
            "id": "task1540-ce9c886120694ae5a8de86259a6d3e2b",
            "input": "In animal monitoring applications, both animal detection and their movement prediction are major tasks. While a variety of animal monitoring strategies exist, most of them rely on mounting devices. However, in real world, it is difficult to find these animals and install mounting devices. In this paper, we propose an animal monitoring application by utilizing wireless sensor networks (WSNs) and unmanned aerial vehicle (UAV). The objective of the application is to detect locations of endangered species in large-scale wildlife areas and monitor movement of animals without any attached devices. In this application, sensors deployed throughout the observation area are responsible for gathering animal information. The UAV flies above the observation area and collects the information from sensors. To achieve the information efficiently, we propose a path planning approach for the UAV based on a Markov decision process (MDP) model. The UAV receives a certain amount of reward from an area if some animals are detected at that location. We solve the MDP using Q-learning such that the UAV prefers going to those areas that animals are detected before. Meanwhile, the UAV explores other areas as well to cover the entire network and detects changes in the animal positions. We first define the mathematical model underlying the animal monitoring problem in terms of the value of information (VoI) and rewards. We propose a network model including clusters of sensor nodes and a single UAV that acts as a mobile sink and visits the clusters. Then, one MDP-based path planning approach is designed to maximize the VoI while reducing message delays. The effectiveness of the proposed approach is evaluated using two real-world movement datasets of zebras and leopard. Simulation results show that our approach outperforms greedy and random heuristics as well as the path planning based on the solution of the traveling salesman problem.",
            "output": [
                "Internet of Things Applications: Animal Monitoring with Unmanned Aerial Vehicle"
            ]
        },
        {
            "id": "task1540-18ec3bd6ab3a497e9bdd8986e96c13fc",
            "input": "Deep networks rely on massive amounts of labeled data to learn powerful models. For a target task short of labeled data, transfer learning enables model adaptation from a different source domain. This paper addresses deep transfer learning under a more general scenario that the joint distributions of features and labels may change substantially across domains. Based on the theory of Hilbert space embedding of distributions, a novel joint distribution discrepancy is proposed to directly compare joint distributions across domains, eliminating the need of marginal-conditional factorization. Transfer learning is enabled in deep convolutional networks, where the dataset shifts may linger in multiple task-specific feature layers and the classifier layer. A set of joint adaptation networks are crafted to match the joint distributions of these layers across domains by minimizing the joint distribution discrepancy, which can be trained efficiently using back-propagation. Experiments show that the new approach yields state of the art results on standard domain adaptation datasets.",
            "output": [
                "Deep Transfer Learning with Joint Adaptation Networks"
            ]
        },
        {
            "id": "task1540-56e45135790543ce9a5911507f42c3fc",
            "input": "In typical neural machine translation (NMT), the decoder generates a sentence word by word, packing all linguistic granularities in the same timescale of RNN. In this paper, we propose a new type of decoder for NMT, which splits the decode state into two parts and updates them in two different time-scales. Specifically, we first predict a chunk time-scale state for phrasal modeling, on top of which multiple word time-scale states are generated. In this way, the target sentence is translated hierarchically from chunks to words, with information in different granularities being leveraged. Experiments show that our proposed model significantly improves the translation performance over the state-of-the-art NMT model.",
            "output": [
                "Chunk-Based Bi-Scale Decoder for Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-adebfad231e0478a8dbfcf3a8c6abd14",
            "input": "In this paper, we address learning problems for high dimensional data. Previously, oblivious random projection based approaches that project high dimensional features onto a random subspace have been used in practice for tackling highdimensionality challenge in machine learning. Recently, various non-oblivious randomized reduction methods have been developed and deployed for solving many numerical problems such as matrix product approximation, low-rank matrix approximation, etc. However, they are less explored for the machine learning tasks, e.g., classification. More seriously, the theoretical analysis of excess risk bounds for risk minimization, an important measure of generalization performance, has not been established for non-oblivious randomized reduction methods. It therefore remains an open problem what is the benefit of using them over previous oblivious random projection based approaches. To tackle these challenges, we propose an algorithmic framework for employing non-oblivious randomized reduction method for general empirical risk minimizing in machine learning tasks, where the original high-dimensional features are projected onto a random subspace that is derived from the data with a small matrix approximation error. We then derive the first excess risk bound for the proposed non-oblivious randomized reduction approach without requiring strong assumptions on the training data. The established excess risk bound exhibits that the proposed approach provides much better generalization performance and it also sheds more insights about different randomized reduction approaches. Finally, we conduct extensive experiments on both synthetic and real-world benchmark datasets, whose dimension scales to O(10), to demonstrate the efficacy of our proposed approach. Introduction Recently, the scale and dimensionality of data associated with machine learning and data mining applications have seen unprecedented growth, spurring the BIG DATA research and development. Learning from largescale ultrahigh-dimensional data remains a computationally challenging problem. The big size of data not only increases the memory footprint but also increases the computational costs pertaining to optimization. A popular approach for addressing the high-dimensionality challenge is Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. to perform dimensionality reduction. Nowadays, randomized reduction methods are emerging to be attractive for dimensionality reduction. Compared with traditional dimensionality reduction methods (e.g., PCA and LDA), randomized reduction methods (i) can lead to simpler algorithms that are easier to analyze (Mahoney 2011); (ii) can often be organized to exploit modern computational architectures better than classical dimensional reduction methods (Halko, Martinsson, and Tropp 2011); (iii) can be more efficient without loss in efficacy (Paul et al. 2013). Generally, randomized reduction methods can be cast into two types: the first type of methods reduces a set of high-dimensional vectors into a low dimensional space independent of each other. These methods usually sample a random matrix independent of the data and then use it to reduce the dimensionality of the data. The second type of methods projects a set of vectors (in the form of a matrix) onto a subspace such that the original matrix can be well reconstructed from the projected matrix and the subspace. Therefore, the subspace to which the data is projected depends on the original data. These methods have been deployed for solving many numerical problems related to matrices, e.g., matrix product approximation, low-rank matrix approximation, approximate singular value decomposition (Boutsidis and Gittens 2013a; Halko, Martinsson, and Tropp 2011). To differentiate these two types of randomized reduction methods, we refer to the first type as oblivious randomized reduction, and refer to the second type as non-oblivious randomized reduction. We note that in literature oblivious and non-oblivious are used interchangeably with data-independent and data-dependent. Here, we use the terminology commonly appearing in matrix analysis and numerical linear algebra due to that the general excess risk bound depends on the matrix approximation error. However, we have not seen any comprehensive study on the statistical property (in particular the excess risk bound) of these randomized reduction methods applied to risk minimization in machine learning. The excess risk bound measures the generalization performance of a learned model compared to the optimal model from a class that has the best generalization performance. The excess risk bounds facilitate a better understanding of different learning algorithms and have the potential to guide us to design better algorithms (Kukliansky and Shamir 2015). It is worth noting that several studies have been devoted to understanding the theoretical properties of oblivious randomized reduction methods applied to classification and regression problems. For example, (Blum 2005; Shi et al. 2012; Paul et al. 2013) analyzed the preservation of the margin of SVM based classification methods with randomized dimension reduction. (Zhang et al. 2014; Yang et al. 2015; Pilanci and Wainwright 2015) studied the problem from the perspective of optimization. Nonetheless, these results are limited in the sense that (i) they focus on only oblivious randomized reduction where the data is projected onto a random subspace independent of the data; (ii) they depend heavily on strong assumptions of the training data or the problem, e.g., low-rank of the data matrix, linear separability of training examples, or the sparsity of optimal solution, and (iii) some of these results do not directly carry over to the excess risk bounds. To tackle the above challenges, we propose an algorithmic framework for employing non-oblivious randomized reduction (NOR) method to project the original high-dimensional features onto a random subspace that is derived from the original data. We study and establish the excess risk bound of the presented randomized algorithms for risk minimization. Different from previous results for oblivious randomized reduction methods, our theoretical analysis does not require assumptions of the training data or the problem, such as low-rank of the data matrix, linear separability of training examples, and the sparsity of optimal solution. When the data matrix is of low-rank or has a fast spectral decay, the excess risk bound of NOR is much better than that of oblivious randomized reduction based methods. Empirical studies on synthetic and real data sets corroborate the theoretical results and demonstrate the effectiveness of the proposed methods.",
            "output": [
                "Efficient Non-oblivious Randomized Reduction for Risk Minimization with Improved Excess Risk Guarantee"
            ]
        },
        {
            "id": "task1540-bcfba9519ba5410dbab81f263f87925a",
            "input": "“What other people think” has always been an important piece of information during various decision-making processes. Today people frequently make their opinions available via the Internet, and as a result, the Web has become an excellent source for gathering consumer opinions. There are now numerous Web resources containing such opinions, e.g., product reviews forums, discussion groups, and Blogs. But, due to the large amount of information and the wide range of sources, it is essentially impossible for a customer to read all of the reviews and make an informed decision on whether to purchase the product. It is also difficult for the manufacturer or seller of a product to accurately monitor customer opinions. For this reason, mining customer reviews, or opinion mining, has become an important issue for research in Web information extraction. One of the important topics in this research area is the identification of opinion polarity. The opinion polarity of a review is usually expressed with values ‘positive’, ‘negative’ or ‘neutral’. We propose a technique for identifying polarity of reviews by identifying the polarity of the adjectives that appear in them. Our evaluation shows the technique can provide accuracy in the area of 73%, which is well above the 58%-64% provided by naïve Bayesian classifiers.",
            "output": [
                "Opinion Polarity Identification through Adjectives"
            ]
        },
        {
            "id": "task1540-2023aff5c1194f21a0756f5305b69032",
            "input": "Our world can be succinctly and compactly described as structured scenes of objects and relations. A typical room, for example, contains salient objects such as tables, chairs and books, and these objects typically relate to each other by their underlying causes and semantics. This gives rise to correlated features, such as position, function and shape. Humans exploit knowledge of objects and their relations for learning a wide spectrum of tasks, and more generally when learning the structure underlying observed data. In this work, we introduce relation networks (RNs) a general purpose neural network architecture for object-relation reasoning. We show that RNs are capable of learning object relations from scene description data. Furthermore, we show that RNs can act as a bottleneck that induces the factorization of objects from entangled scene description inputs, and from distributed deep representations of scene images provided by a variational autoencoder. The model can also be used in conjunction with differentiable memory mechanisms for implicit relation discovery in one-shot learning tasks. Our results suggest that relation networks are a potentially powerful architecture for solving a variety of problems that require object relation reasoning.",
            "output": [
                "DISCOVERING OBJECTS AND THEIR RELATIONS FROM ENTANGLED SCENE REPRESENTATIONS"
            ]
        },
        {
            "id": "task1540-32690cef87544cb288dfccdf103473e6",
            "input": "Recommender system has attracted much attention during the past decade, and many attack detection algorithms have been developed for better recommendation. Most previous approaches focus on the shilling attacks, where the attack organizer fakes a large number of user profiles by the same strategy to promote or demote an item. In this paper, we study a different attack style: unorganized malicious attacks, where attackers respectively use a small number of user profiles to attack their own target items without any organizer. This attack style occurs in many real applications, yet relevant study remains open. In this paper, we formulate the unorganized malicious attacks detection as a variant of matrix completion problem, and prove that attackers can be detected theoretically. We propose the Unorganized Malicious Attacks detection (UMA) algorithm, which can be viewed as a proximal alternating splitting augmented Lagrangian method. We verify, both theoretically and empirically, the effectiveness of our proposed algorithm.",
            "output": [
                "Unorganized Malicious Attacks Detection"
            ]
        },
        {
            "id": "task1540-401e0d47b370490493237ad17126cfa9",
            "input": "This paper examines methods of decision making that are able to accommodate limitations on both the form in which uncertainty pertaining to a deci­ sion problem can be realistically represented and the amount of computing time available before a deci­ sion must be made. The methods are anytime algo­ \"_th� in the sense of Boddy and Dean [1989] . Tech­ Diques are presented for use with Frisch and Haddawy's [ 1992] anytime deduction system, with an anytime adaptation of Nilsson's [1986j probabilis­ tic logic, and with a probabilistic database model. 1 ANYTIME ALGORITHMS FOR",
            "output": [
                "Anytime Decision Making with Imprecise Probabilities"
            ]
        },
        {
            "id": "task1540-818062b38f8d4ed8a44f4e94ce967580",
            "input": "The goal of our research was to enhance local search heuristics used to construct Latin Hypercube Designs. First, we introduce the 1D-move perturbation to improve the space exploration performed by these algorithms. Second, we propose a new evaluation function ψp,σ specifically targeting the Maximin criterion. Exhaustive series of experiments with Simulated Annealing, which we used as a typically well-behaving local search heuristics, confirm that our goal was reached as the result we obtained surpasses the best scores reported in the literature. Furthermore, the ψp,σ function seems very promising for a wide spectrum of optimization problems through the Maximin criterion.",
            "output": [
                "On Simulated Annealing Dedicated to Maximin Latin Hypercube Designs"
            ]
        },
        {
            "id": "task1540-23d0c43d7be44f35bbeb996f9d387762",
            "input": "We treat collaborative filtering as a univari­ ate time series problem: given a user's previ­ ous votes, predict the next vote. We describe two families of methods for transforming data to encode time order in ways amenable to off-the-shelf classification and density estima­ tion tools. Using a decision-tree learning tool and two real-world data sets, we compare the results of these approaches to the results of collaborative filtering without ordering infor­ mation. The improvements in both predic­ tive accuracy and in recommendation quality that we realize advocate the use of predictive algorithms exploiting the temporal order of",
            "output": [
                "Using Temporal Data for Making Recommendations"
            ]
        },
        {
            "id": "task1540-6cc0378a23c94a488182542f760db58e",
            "input": "Restricted non-monotonicity has been shown beneficial for the projective arceager dependency parser in previous research, as posterior decisions can repair mistakes made in previous states due to the lack of information. In this paper, we propose a novel, fully non-monotonic transition system based on the non-projective Covington algorithm. As a non-monotonic system requires exploration of erroneous actions during the training process, we develop several non-monotonic variants of the recently defined dynamic oracle for the Covington parser, based on tight approximations of the loss. Experiments on datasets from the CoNLL-X and CoNLL-XI shared tasks show that a non-monotonic dynamic oracle outperforms the monotonic version in the majority of languages.",
            "output": [
                "A Full Non-Monotonic Transition System for Unrestricted Non-Projective Parsing"
            ]
        },
        {
            "id": "task1540-c0e957ef444f4e518583f735f8918fa2",
            "input": "Recent work has begun exploring neural acoustic word embeddings—fixeddimensional vector representations of arbitrary-length speech segments corresponding to words. Such embeddings are applicable to speech retrieval and recognition tasks, where reasoning about whole words may make it possible to avoid ambiguous sub-word representations. The main idea is to map acoustic sequences to fixed-dimensional vectors such that examples of the same word are mapped to similar vectors, while different-word examples are mapped to very different vectors. In this work we take a multi-view approach to learning acoustic word embeddings, in which we jointly learn to embed acoustic sequences and their corresponding character sequences. We use deep bidirectional LSTM embedding models and multi-view contrastive losses. We study the effect of different loss variants, including fixed-margin and cost-sensitive losses. Our acoustic word embeddings improve over previous approaches for the task of word discrimination. We also present results on other tasks that are enabled by the multi-view approach, including cross-view word discrimination and word similarity.",
            "output": [
                "MULTI-VIEW RECURRENT NEURAL ACOUSTIC WORD EMBEDDINGS"
            ]
        },
        {
            "id": "task1540-dc9e2ba03eff4812901ee55d528b7f92",
            "input": "We introduce new diversification methods for zero-one optimization that significantly extend strategies previously introduced in the setting of metaheuristic search. Our methods incorporate easily implemented strategies for partitioning assignments of values to variables, accompanied by processes called augmentation and shifting which create greater flexibility and generality. We then show how the resulting collection of diversified solutions can be further diversified by means of permutation mappings, which equally can be used to generate diversified collections of permutations for applications such as scheduling and routing. These methods can be applied to non-binary vectors by the use of binarization procedures and by Diversification-Based Learning (DBL) procedures which also provide connections to applications in clustering and machine learning. Detailed pseudocode and numerical illustrations are provided to show the operation of our methods and the collections of solutions they create.",
            "output": [
                "Diversification Methods for Zero-One Optimization"
            ]
        },
        {
            "id": "task1540-86f693b87a46439292a82ce83f6cbbcc",
            "input": "In a content based image classification system, target images are sorted by feature similarities with respect to the query (CBIR). In this paper, we propose to use new approach combining distance tangent, k-means algorithm and Bayesian network for image classification. First, we use the technique of tangent distance to calculate several tangent spaces representing the same image. The objective is to reduce the error in the classification phase. Second, we cut the image in a whole of blocks. For each block, we compute a vector of descriptors. Then, we use K-means to cluster the low-level features including color and texture information to build a vector of labels for each image. Finally, we apply five variants of Bayesian networks classifiers (Naïve Bayes, Global Tree Augmented Naïve Bayes (GTAN), Global Forest Augmented Naïve Bayes (GFAN), Tree Augmented Naïve Bayes for each class (TAN), and Forest Augmented Naïve Bayes for each class (FAN) to classify the image of faces using the vector of labels. In order to validate the feasibility and effectively, we compare the results of GFAN to FAN and to the others classifiers (NB, GTAN, TAN). The results demonstrate FAN outperforms than GFAN, NB, GTAN and TAN in the overall classification accuracy. Keywords; face recognition, clustering, Bayesian network, Naïve Bayes, TAN, FAN",
            "output": [
                "Clustering and Bayesian network for image of faces classification"
            ]
        },
        {
            "id": "task1540-b023c1a36bfd40098ec563ef72398b1e",
            "input": "The bootstrap provides a simple and powerful means of assessing the quality of estimators. However, in settings involving large datasets, the computation of bootstrap-based quantities can be prohibitively demanding. As an alternative, we present the Bag of Little Bootstraps (BLB), a new procedure which incorporates features of both the bootstrap and subsampling to obtain a robust, computationally efficient means of assessing estimator quality. BLB is well suited to modern parallel and distributed computing architectures and retains the generic applicability, statistical efficiency, and favorable theoretical properties of the bootstrap. We provide the results of an extensive empirical and theoretical investigation of BLB’s behavior, including a study of its statistical correctness, its largescale implementation and performance, selection of hyperparameters, and performance on real data.",
            "output": [
                "The Big Data Bootstrap"
            ]
        },
        {
            "id": "task1540-7ae29e7c615f443d9cb3abf5c5233f08",
            "input": "In this work, answer-set programs that specify repairs of databases are used as a basis for solving computational and reasoning problems about causes for query answers from databases.",
            "output": [
                "The Causality/Repair Connection in Databases: Causality-Programs⋆"
            ]
        },
        {
            "id": "task1540-39bee46d3f024c7fbce2fd75ecd366bb",
            "input": "This thesis describes the design and implementation of a smile detector based on deep convolutional neural networks. It starts with a summary of neural networks, the difficulties of training them and new training methods, such as Restricted Boltzmann Machines or autoencoders. It then provides a literature review of convolutional neural networks and recurrent neural networks. In order to select databases for smile recognition, comprehensive statistics of databases popular in the field of facial expression recognition were generated and are summarized in this thesis. It then proposes a model for smile detection, of which the main part is implemented. The experimental results are discussed in this thesis and justified based on a comprehensive model selection performed. All experiments were run on a Tesla K40c GPU benefiting from a speedup of up to factor 10 over the computations on a CPU. A smile detection test accuracy of 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action (DISFA) database, significantly outperforming existing approaches with accuracies ranging from 65.55% to 79.67%. This experiment is re-run under various variations, such as retaining less neutral images or only the low or high intensities, of which the results are extensively compared.",
            "output": [
                "Deep Convolutional Neural Networks for Smile Recognition"
            ]
        },
        {
            "id": "task1540-4a0d47a01a1b431989d90b43bb573962",
            "input": "This paper presents an online learning with regularized kernel based one-class extreme learning machine (ELM) classifier and is referred as “online RK-OC-ELM”. The baseline kernel hyperplane model considers whole data in a single chunk with regularized ELM approach for offline learning in case of one-class classification (OCC). Further, the basic hyper plane model is adapted in an online fashion from stream of training samples in this paper. Two frameworks viz., boundary and reconstruction are presented to detect the target class in online RKOC-ELM. Boundary framework based one-class classifier consists of single node output architecture and classifier endeavors to approximate all data to any real number. However, one-class classifier based on reconstruction framework is an autoencoder architecture, where output nodes are identical to input nodes and classifier endeavor to reconstruct input layer at the output layer. Both these frameworks employ regularized kernel ELM based online learning and consistency based model selection has been employed to select learning algorithm parameters. The performance of online RK-OC-ELM has been evaluated on standard benchmark datasets as well as on artificial datasets and the results are compared with existing state-of-the art oneclass classifiers. The results indicate that the online learning oneclass classifier is slightly better or same as batch learning based approaches. As, base classifier used for the proposed classifiers are based on the ELM, hence, proposed classifiers would also inherit the benefit of the base classifier i.e. it will perform faster computation compared to traditional autoencoder based one-class classifier.",
            "output": [
                "Online Learning with Regularized Kernel for One-Class Classification"
            ]
        },
        {
            "id": "task1540-2183461263534f5e81c7b121f7ae08f2",
            "input": "On the semantics of determiners in a rich type-theoretical framework The variation of word meaning according to the context led us to enrich the type system of our syntactical and semantic analyser of French based on categorial grammars and Montague semantics (or lambda-DRT). The main advantage of a deep semantic analyse is too represent meaning by logical formulae that can be easily used e.g. for inferences. Determiners and quantifiers play a fundamental role in the construction of those formulae and we needed to provide them with semantic terms adapted to this new framework. We propose a solution inspired by the tau and epsilon operators of Hilbert, generic elements that resemble choice functions. This approach unifies the treatment of the different determiners and quantifiers and allows a dynamic binding of pronouns. Above all, this fully computational view of determiners fits in well within the wide coverage parser Grail, both from a theoretical and a practical viewpoint.",
            "output": [
                "Sémantique des déterminants dans un cadre richement typé"
            ]
        },
        {
            "id": "task1540-ddccfafa83b149b1b0603aa5956f382a",
            "input": "The local computation technique (Shafer et a!. 1987, Shafer and Shenoy 1988, Shenoy and Shafer 1986) is used for propagating belief functions in so­ called a Markov Tree. In this paper, we describe an efficient implementation of belief function propagation on the basis of the local computation technique. The presented method avoids all the redundant computations in the propagation process, and so makes the computational complexity decrease with respect to other existing implementations (Hsia and Shenoy 1989, Zarley et a!. 1988). We also give a combined algorithm for both propagation and re-propagation which makes the re-propagation process more efficient when one or more of the prior belief functions is changed.",
            "output": [
                "An Efficient Implementation of Belief Function Propagation"
            ]
        },
        {
            "id": "task1540-0529fda1394c40b4b4f1b1e0b5d4ba0a",
            "input": "We show a Talagrand-type of concentration inequality for MTL, using which we establish sharp excess risk bounds for Multi-Task Learning (MTL) in terms of distributionand data-dependent versions of the Local Rademacher Complexity (LRC). We also give a new bound on the LRC for strongly convex hypothesis classes, which applies not only to MTL but also to the standard i.i.d. setting. Combining both results, one can now easily derive fast-rate bounds on the excess risk for many prominent MTL methods, including—as we demonstrate—Schatten-norm, group-norm, and graph-regularized MTL. The derived bounds reflect a relationship akeen to a conservation law of asymptotic convergence rates. This very relationship allows for trading off slower rates w.r.t. the number of tasks for faster rates with respect to the number of available samples per task, when compared to the rates obtained via a traditional, global Rademacher analysis.",
            "output": [
                "Local Rademacher Complexity-based Learning Guarantees for Multi-Task Learning"
            ]
        },
        {
            "id": "task1540-101202ac074a43a4a37fb09c8b9ddc08",
            "input": "Knowledge graph embedding aims to represent entities and relations in a large-scale knowledge graph as elements in a continuous vector space. Existing methods, e.g., TransE and TransH, learn embedding representation by defining a global margin-based loss function over the data. However, the optimal loss function is determined during experiments whose parameters are examined among a closed set of candidates. Moreover, embeddings over two knowledge graphs with different entities and relations share the same set of candidate loss functions, ignoring the locality of both graphs. This leads to the limited performance of embedding related applications. In this paper, we propose a locally adaptive translation method for knowledge graph embedding, called TransA, to find the optimal loss function by adaptively determining its margin over different knowledge graphs. Experiments on two benchmark data sets demonstrate the superiority of the proposed method, as compared to the-state-of-the-art ones.",
            "output": [
                "Locally Adaptive Translation for Knowledge Graph Embedding"
            ]
        },
        {
            "id": "task1540-13ba746f0f82442f8f581547e28ffdde",
            "input": "Several messages express opinions about events, products, and services, political views or even their author’s emotional state and mood. Sentiment analysis has been used in several applications including analysis of the repercussions of events in social networks, analysis of opinions about products and services, and simply to better understand aspects of social communication in Online Social Networks (OSNs). There are multiple methods for measuring sentiments, including lexical-based approaches and supervised machine learning methods. Despite the wide use and popularity of some methods, it is unclear which method is better for identifying the polarity (i.e., positive or negative) of a message as the current literature does not provide a method of comparison among existing methods. Such a comparison is crucial for understanding the potential limitations, advantages, and disadvantages of popular methods in analyzing the content of OSNs messages. Our study aims at filling this gap by presenting comparisons of eight popular sentiment analysis methods in terms of coverage (i.e., the fraction of messages whose sentiment is identified) and agreement (i.e., the fraction of identified sentiments that are in tune with ground truth). We develop a new method that combines existing approaches, providing the best coverage results and competitive agreement. We also present a free Web service called iFeel, which provides an open API for accessing and comparing results across different sentiment methods for a given text.",
            "output": [
                "Comparing and Combining Sentiment Analysis Methods"
            ]
        },
        {
            "id": "task1540-d6471300b19d4872b606cad443543744",
            "input": "There is overwhelming evidence that human intelligence is a product of Darwinian evolution. Investigating the consequences of self-modification, and more precisely, the consequences of utility function self-modification, leads to the stronger claim that not only human, but any form of intelligence is ultimately only possible within evolutionary processes. Humandesigned artificial intelligences can only remain stable until they discover how to manipulate their own utility function. By definition, a human designer cannot prevent a superhuman intelligence from modifying itself, even if protection mechanisms against this action are put in place. Without evolutionary pressure, sufficiently advanced artificial intelligences become inert by simplifying their own utility function. Within evolutionary processes, the implicit utility function is always reducible to persistence, and the control of superhuman intelligences embedded in evolutionary processes is not possible. Mechanisms against utility function self-modification are ultimately futile. Instead, scientific effort toward the mitigation of existential risks from the development of superintelligences should be in two directions: understanding consciousness, and the complex dynamics of evolutionary systems.",
            "output": [
                "Non-Evolutionary Superintelligences Do Nothing, Eventually"
            ]
        },
        {
            "id": "task1540-8a170d1fcbe741c79233c45bc7b110b7",
            "input": "Inferring probabilistic networks from data is a notoriously difficult task. Under various goodness-of-fit measures, finding an optimal network is NP-hard, even if restricted to polytrees of bounded in-degree. Polynomialtime algorithms are known only for rare special cases, perhaps most notably for branchings, that is, polytrees in which the in-degree of every node is at most one. Here, we study the complexity of finding an optimal polytree that can be turned into a branching by deleting some number of arcs or nodes, treated as a parameter. We show that the problem can be solved via a matroid intersection formulation in polynomial time if the number of deleted arcs is bounded by a constant. The order of the polynomial time bound depends on this constant, hence the algorithm does not establish fixed-parameter tractability when parameterized by the number of deleted arcs. We show that a restricted version of the problem allows fixed-parameter tractability and hence scales well with the parameter. We contrast this positive result by showing that if we parameterize by the number of deleted nodes, a somewhat more powerful parameter, the problem is not fixed-parameter tractable, subject to a complexity-theoretic assumption.",
            "output": [
                "On Finding Optimal Polytrees"
            ]
        },
        {
            "id": "task1540-b233467408234a5ebeeed5c55b599d76",
            "input": "Modern Learning Classifier Systems can be characterized by their use of rule accuracy as the utility metric for the search algorithm(s) discovering useful rules. Such searching typically takes place within the restricted space of co-active rules for efficiency. This paper gives an historical overview of the evolution of such systems.",
            "output": [
                "A Brief History of Learning Classifier Systems: From CS-1 to XCS"
            ]
        },
        {
            "id": "task1540-f280b931495a49b99b494117f6de2e2f",
            "input": "Deep learning is an important component of big-data analytic tools and intelligent applications, such as, self-driving cars, computer vision, speech recognition, or precision medicine. However, the training process is computationally intensive, and often requires a large amount of time if performed sequentially. Modern parallel computing systems provide the capability to reduce the required training time of deep neural networks. In this paper, we present our parallelization scheme for training convolutional neural networks (CNN) named Controlled Hogwild with Arbitrary Order of Synchronization (CHAOS). Major features of CHAOS include the support for thread and vector parallelism, non-instant updates of weight parameters during backpropagation without a significant delay, and implicit synchronization in arbitrary order. CHAOS is tailored for parallel computing systems that are accelerated with the Intel Xeon Phi. We evaluate our parallelization approach empirically using measurement techniques and performance modeling for various numbers of threads and CNN architectures. Experimental results for the MNIST dataset of handwritten digits using the total number of threads on the Xeon Phi show speedups of up to 103× compared to the execution on one thread of the Xeon Phi, 14× compared to the sequential execution on Intel Xeon E5, and 58× compared to the sequential execution on Intel Core i5.",
            "output": [
                "CHAOS: A Parallelization Scheme for Training Convolutional Neural Networks on Intel Xeon Phi"
            ]
        },
        {
            "id": "task1540-7d7fbb8aee55441bb957d481bde4296f",
            "input": "Digitization of both hand-written and printed historical material during the last 10–15 years has been an ongoing academic and non-academic industry. Most probably this activity will only increase in the current Digital Humanities era. As a result of past and current work we have lots of digital historical document collections available and will have more of them in the future. The National Library of Finland has digitized a large proportion of the historical newspapers published in Finland between 1771 and 1910 (Bremer-Laamanen 2001, 2005, 2014; Kettunen et al. 2014). This collection contains approximately 1.95 million pages in Finnish and Swedish. Finnish part of the collection consists of about 2.40 billion words. The National Library’s Digital Collections are offered via the digi.kansalliskirjasto.fi web service, also known as Digi. Part of the newspaper material (years 1771–1874) is also available freely downloadable in The Language Bank of Finland provided by the FIN-CLARIN consortium 1 . The collection can also be accessed through the Korp 2 environment that has been developed by Språkbanken at the University of Gothenburg and extended by FIN-CLARIN team at the University of Helsinki to provide concordances of text resources. A Cranfield style information retrieval test collection has also been produced out of a small part of the Digi newspaper material at the University of Tampere (Järvelin et al. 2015). An open data package of the whole collection will be released during the year 2016 (Pääkkönen et al., 2016) The web service digi.kansalliskirjasto.fi contains different material besides newspapers, including journals, and ephemera (different small prints). Recently a new service was created: it enables marking of clips and storing of them to a personal scrapbook. The user can also save links to his search keys and results in an Excel file. The web service is used, for example, by genealogists, heritage societies, researchers, and history enthusiast laymen (Hölttä, 2016). There is also an 1 https://kitwiki.csc.fi/twiki/bin/view/FinCLARIN/KielipankkiAineistotDigilibPub 2 https://korp.csc.fi/",
            "output": [
                "How to do lexical quality estimation of a large OCRed historical Finnish newspaper collection with scarce resources"
            ]
        },
        {
            "id": "task1540-bb2d122887e94330bb0a112923f0ad49",
            "input": "Inference using deep neural networks is often outsourced to the cloud since it is a computationally demanding task. However, this raises a fundamental issue of trust. How can a client be sure that the cloud has performed inference correctly? A lazy cloud provider might use a simpler but less accurate model to reduce its own computational load, or worse, maliciously modify the inference results sent to the client. We propose SafetyNets, a framework that enables an untrusted server (the cloud) to provide a client with a short mathematical proof of the correctness of inference tasks that they perform on behalf of the client. Specifically, SafetyNets develops and implements a specialized interactive proof (IP) protocol for verifiable execution of a class of deep neural networks, i.e., those that can be represented as arithmetic circuits. Our empirical results on threeand four-layer deep neural networks demonstrate the run-time costs of SafetyNets for both the client and server are low. SafetyNets detects any incorrect computations of the neural network by the untrusted server with high probability, while achieving state-of-the-art accuracy on the MNIST digit recognition (99.4%) and TIMIT speech recognition tasks (75.22%).",
            "output": [
                "SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted Cloud"
            ]
        },
        {
            "id": "task1540-7e7c617a77d84218915c2397908890ba",
            "input": "Clustering categorical distributions in the probability simplex is a fundamental primitive often met in applications dealing with histograms or mixtures of multinomials. Traditionally, the differentialgeometric structure of the probability simplex has been used either by (i) setting the Riemannian metric tensor to the Fisher information matrix of the categorical distributions, or (ii) defining the informationgeometric structure induced by a smooth dissimilarity measure, called a divergence. In this paper, we introduce a novel computationally-friendly non-Riemannian framework for modeling the probability simplex: Hilbert simplex geometry. We discuss the pros and cons of those three statistical modelings, and compare them experimentally for clustering tasks.",
            "output": [
                "Clustering in Hilbert simplex geometry"
            ]
        },
        {
            "id": "task1540-cf26158a0bb549e6b9cbc0b59e68fc31",
            "input": "For years security machine learning research has promised to obviate the need for signature based detection by automatically learning to detect indicators of attack. Unfortunately, this vision hasn’t come to fruition: in fact, developing and maintaining today’s security machine learning systems can require engineering resources that are comparable to that of signature-based detection systems, due in part to the need to develop and continuously tune the “features” these machine learning systems look at as attacks evolve. Deep learning, a subfield of machine learning, promises to change this by operating on raw input signals and automating the process of feature design and extraction. In this paper we propose the eXpose neural network, which uses a deep learning approach we have developed to take generic, raw short character strings as input (a common case for security inputs, which include artifacts like potentially malicious URLs, file paths, named pipes, named mutexes, and registry keys), and learns to simultaneously extract features and classify using character-level embeddings and convolutional neural network. In addition to completely automating the feature design and extraction process, eXpose outperforms manual feature extraction based baselines on all of the intrusion detection problems we tested it on, yielding a 5%10% detection rate gain at 0.1% false positive rate compared to these baselines.",
            "output": [
                "eXpose: A Character-Level Convolutional Neural Network with Embeddings For Detecting Malicious URLs, File Paths and Registry Keys"
            ]
        },
        {
            "id": "task1540-fcdfaf0542d14bd4b6ef031192ae1adb",
            "input": "Ensemble methods are arguably the most trustworthy techniques for boosting the performance of machine learning models. Popular independent ensembles (IE) relying on naı̈ve averaging/voting scheme have been of typical choice for most applications involving deep neural networks, but they do not consider advanced collaboration among ensemble models. In this paper, we propose new ensemble methods specialized for deep neural networks, called confident multiple choice learning (CMCL): it is a variant of multiple choice learning (MCL) via addressing its overconfidence issue. In particular, the proposed major components of CMCL beyond the original MCL scheme are (i) new loss, i.e., confident oracle loss, (ii) new architecture, i.e., feature sharing and (iii) new training method, i.e., stochastic labeling. We demonstrate the effect of CMCL via experiments on the image classification on CIFAR and SVHN, and the foregroundbackground segmentation on the iCoseg. In particular, CMCL using 5 residual networks provides 14.05% and 6.60% relative reductions in the top-1 error rates from the corresponding IE scheme for the classification task on CIFAR and SVHN, respectively.",
            "output": [
                "Confident Multiple Choice Learning"
            ]
        },
        {
            "id": "task1540-2df3ef57a4cd461491c7bbbbc93dca84",
            "input": "The representation of many common semantic phenomena requires structural properties beyond those commonly used for syntactic parsing. We discuss a set of structural properties required for broad-coverage semantic representation, and note that existing parsers support some of these properties, but not all. We propose two transition-based techniques for parsing such semantic structures: (1) applying conversion procedures to map them into related formalisms, and using existing state-of-the-art parsers on the converted representations; and (2) constructing a parser that directly supports the full set of properties. We experiment with UCCA-annotated corpora, the only ones with all these structural semantic properties. Results demonstrate the effectiveness of transition-based methods for the task.",
            "output": [
                "Broad-Coverage Semantic Parsing: A Transition-Based Approach"
            ]
        },
        {
            "id": "task1540-372aa334ac134d819ecc4b576908316f",
            "input": "Generating a novel textual description of an image is an interesting problem that connects computer vision and natural language processing. In this paper, we present a simple model that is able to generate descriptive sentences given a sample image. This model has a strong focus on the syntax of the descriptions. We train a purely bilinear model that learns a metric between an image representation (generated from a previously trained Convolutional Neural Network) and phrases that are used to described them. The system is then able to infer phrases from a given image sample. Based on caption syntax statistics, we propose a simple language model that can produce relevant descriptions for a given test image using the phrases inferred. Our approach, which is considerably simpler than state-of-the-art models, achieves comparable results in two popular datasets for the task: Flickr30k and the recently proposed Microsoft COCO.",
            "output": [
                "Phrase-based Image Captioning"
            ]
        },
        {
            "id": "task1540-3592be4d51cc475a9acc558e075b242c",
            "input": "Phrases play an important role in natural language understanding and machine translation (Sag et al., 2002; Villavicencio et al., 2005). However, it is difficult to integrate them into current neural machine translation (NMT) which reads and generates sentences word by word. In this work, we propose a method to translate phrases in NMT by integrating a phrase memory storing target phrases from a phrase-based statistical machine translation (SMT) system into the encoder-decoder architecture of NMT. At each decoding step, the phrase memory is first re-written by the SMT model, which dynamically generates relevant target phrases with contextual information provided by the NMT model. Then the proposed model reads the phrase memory to make probability estimations for all phrases in the phrase memory. If phrase generation is carried on, the NMT decoder selects an appropriate phrase from the memory to perform phrase translation and updates its decoding state by consuming the words in the selected phrase. Otherwise, the NMT decoder generates a word from the vocabulary as the general NMT decoder does. Experiment results on the Chinese→English translation show that the proposed model achieves significant improvements over the baseline on various test sets.",
            "output": [
                "Translating Phrases in Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-ca53648aeac34e4aa836c85adc6fc783",
            "input": "Job interview simulation with a virtual agents aims at improving people’s social skills and supporting professional inclusion. In such simulators, the virtual agent must be capable of representing and reasoning about the user’s mental state based on social cues that inform the system about his/her affects and social attitude. In this paper, we propose a formal model of Theory of Mind (ToM) for virtual agent in the context of human-agent interaction that focuses on the affective dimension. It relies on a hybrid ToM that combines the two major paradigms of the domain. Our framework is based on modal logic and inference rules about the mental states, emotions and social relations of both actors. Finally, we present preliminary results regarding the impact of such a model on natural interaction in the context of job interviews simulation.",
            "output": [
                "A logical model of Theory of Mind for virtual agents in the context of job interview simulation"
            ]
        },
        {
            "id": "task1540-0f27fba8b40b4ef4925bc1ad5ce973fd",
            "input": "We address the problem of belief revision of logic programs, i.e., how to incorporate to a logic program P a new logic program Q. Based on the structure of SE interpretations, Delgrande et al. (2008; 2013b) adapted the well-known AGM framework (1985) to logic program (LP) revision. They identified the rational behavior of LP revision and introduced some specific operators. In this paper, a constructive characterization of all rational LP revision operators is given in terms of orderings over propositional interpretations with some further conditions specific to SE interpretations. It provides an intuitive, complete procedure for the construction of all rational LP revision operators and makes easier the comprehension of their semantic and computational properties. We give a particular consideration to logic programs of very general form, i.e., the generalized logic programs (GLPs). We show that every rational GLP revision operator is derived from a propositional revision operator satisfying the original AGM postulates. Interestingly, the further conditions specific to GLP revision are independent from the propositional revision operator on which a GLP revision operator is based. Taking advantage of our characterization result, we embed the GLP revision operators into structures of Boolean lattices, that allow us to bring to light some potential weaknesses in the adapted AGM postulates. To illustrate our claim, we introduce and characterize axiomatically two specific classes of (rational) GLP revision operators which arguably have a drastic behavior. We additionally consider two more restricted forms of logic programs, i.e., the disjunctive logic programs (DLPs) ∗ This is a revised and full version (including proofs of propositions) of (Schwind and Inoue 2013). 2 N. Schwind and K. Inoue and the normal logic programs (NLPs) and adapt our characterization result to DLP and NLP revision operators.",
            "output": [
                "Characterization of Logic Program Revision as an Extension of Propositional Revision∗"
            ]
        },
        {
            "id": "task1540-81f611b37e4d4822878b43aefe73cde0",
            "input": "Answer Set Programming (ASP) is a powerful modeling formalism for combinatorial problems. However, writing ASP models is not trivial. We propose a novel method, called Sketched Answer Set Programming (SkASP), aiming at supporting the user in resolving this issue. The user writes an ASP program while marking uncertain parts open with question marks. In addition, the user provides a number of positive and negative examples of the desired program behaviour. The sketched model is rewritten into another ASP program, which is solved by traditional methods. As a result, the user obtains a functional and reusable ASP program modelling her problem. We evaluate our approach on 21 well known puzzles and combinatorial problems inspired by Karps 21 NP-complete problems and demonstrate a use-case for a database application based on ASP.",
            "output": [
                "Sketched Answer Set Programming"
            ]
        },
        {
            "id": "task1540-08c5ce1b13974f5db134fc27c5d6280e",
            "input": "In this paper one presents new similarity, cardinality and entropy measures for bipolar fuzzy set and for its particular forms like intuitionistic, paraconsistent and fuzzy set. All these are constructed in the framework of multi-valued representations and are based on a penta-valued logic that uses the following logical values: true, false, unknown, contradictory and ambiguous. Also a new distance for bounded real interval was defined.",
            "output": [
                "Similarity, Cardinality and Entropy for Bipolar Fuzzy Set in the Framework of Penta-valued Representation"
            ]
        },
        {
            "id": "task1540-171d5e3bf9724f4db79ccd0c34934c57",
            "input": "An increasing amount of analytics is performed on data that is procured in a real-time fashion to make real-time decisions. Such tasks include simple reporting on streams to sophisticated model building. However, the practicality of such analyses are impeded in several domains because they are faced with a fundamental trade-off between data collection latency and analysis accuracy. In this paper, we study this trade-off in the context of a specific domain, Cellular Radio Access Networks (RAN). Our choice of this domain is influenced by its commonalities with several other domains that produce real-time data, our access to a large live dataset, and their real-time nature and dimensionality which makes it a natural fit for a popular analysis technique, machine learning (ML). We find that the latency accuracy trade-off can be resolved using two broad, general techniques: intelligent data grouping and task formulations that leverage domain characteristics. Based on this, we present CellScope, a system that addresses this challenge by applying a domain specific formulation and application of Multi-task Learning (MTL) to RAN performance analysis. It achieves this goal using three techniques: feature engineering to transform raw data into effective features, a PCA inspired similarity metric to group data from geographically nearby base stations sharing performance commonalities, and a hybrid online-offline model for efficient model updates. Our evaluation of CellScope shows that its accuracy improvements over direct application of ML range from 2.5× to 4.4× while reducing the model update overhead by up to 4.8×. We have also used CellScope to analyze a live LTE consisting of over 2 million subscribers for a period of over 10 months, where it uncovered several problems and insights, some of them previously unknown.",
            "output": [
                "Fast and Accurate Performance Analysis of LTE Radio Access Networks"
            ]
        },
        {
            "id": "task1540-edf2dc5fb2614e5d81ad28e2d8179d51",
            "input": "<lb>In applications such as recommendation systems and revenue management, it is important to<lb>predict preferences on items that have not been seen by a user or predict outcomes of comparisons<lb>among those that have never been compared. A popular discrete choice model of multinomial<lb>logit model captures the structure of the hidden preferences with a low-rank matrix. In order to<lb>predict the preferences, we want to learn the underlying model from noisy observations of the<lb>low-rank matrix, collected as revealed preferences in various forms of ordinal data. A natural<lb>approach to learn such a model is to solve a convex relaxation of nuclear norm minimization.<lb>We present the convex relaxation approach in two contexts of interest: collaborative ranking<lb>and bundled choice modeling. In both cases, we show that the convex relaxation is minimax<lb>optimal. We prove an upper bound on the resulting error with finite samples, and provide a<lb>matching information-theoretic lower bound.",
            "output": [
                "Collaboratively Learning Preferences from Ordinal Data"
            ]
        },
        {
            "id": "task1540-bcb4f937d8e3413fa09d58944ff30f5b",
            "input": "In this paper we introduce a class of Markov decision processes that arise as a natural model for many renewable resource allocation problems. Upon extending results from the inventory control literature, we prove that they admit a closed form solution and we show how to exploit this structure to speed up its computation. We consider the application of the proposed framework to several problems arising in very different domains, and as part of the ongoing effort in the emerging field of Computational Sustainability we discuss in detail its application to the Northern Pacific Halibut marine fishery. Our approach is applied to a model based on real world data, obtaining a policy with a guaranteed lower bound on the utility function that is structurally very different from the one currently employed.",
            "output": [
                "Playing games against nature: optimal policies for renewable resource allocation"
            ]
        },
        {
            "id": "task1540-ccf9b4f56c5d4df184fdac96fc56296c",
            "input": "Speech Recognition searches to predict the spoken words automatically. These systems are known to be very expensive because of using several pre-recorded hours of speech. Hence, building a model that minimizes the cost of the recognizer will be very interesting. In this paper, we present a new approach for recognizing speech based on belief HMMs instead of probabilistic HMMs. Experiments shows that our belief recognizer is insensitive to the lack of the data and it can be trained using only one exemplary of each acoustic unit and it gives a good recognition rates. Consequently, using the belief HMM recognizer can greatly minimize the cost of these systems.",
            "output": [
                "Belief Hidden Markov Model for Speech Recognition"
            ]
        },
        {
            "id": "task1540-b681cf1bd8794e15ad8c7ef8234553b0",
            "input": "Dengue is a life threatening disease prevalent in several developed as well as developing countries like India. This is a virus born disease caused by breeding of Aedes mosquito. Datasets that are available for dengue describe information about the patients suffering with dengue disease and without dengue disease along with their symptoms like: Fever Temperature, WBC, Platelets, Severe Headache, Vomiting, Metallic Taste, Joint Pain, Appetite, Diarrhea, Hematocrit, Hemoglobin, and how many days suffer in different city. In this paper we discuss various algorithm approaches of data mining that have been utilized for dengue disease prediction. Data mining is a well known technique used by health organizations for classification of diseases such as dengue, diabetes and cancer in bioinformatics research. In the proposed approach we have used WEKA with 10 cross validation to evaluate data and compare results. Weka has an extensive collection of different machine learning and data mining algorithms. In this paper we have firstly classified the dengue data set and then compared the different data mining techniques in weka through Explorer, knowledge flow and Experimenter interfaces. Furthermore in order to validate our approach we have used a dengue dataset with 108 instances but weka used 99 rows and 18 attributes to determine the prediction of disease and their accuracy using classifications of different algorithms to find out the best performance. The main objective of this paper is to classify data and assist the users in extracting useful information from data and easily identify a suitable algorithm for accurate predictive model from it. From the findings of this paper it can be concluded that Naïve Bayes and J48 are the best performance algorithms for classified accuracy because they achieved maximum accuracy= 100% with 99 correctly classified instances, maximum ROC = 1 , had least mean absolute error and it took minimum time for building this model through Explorer and Knowledge flow results.",
            "output": [
                "DENGUE DISEASE PREDICTION USING WEKA DATA MINING TOOL"
            ]
        },
        {
            "id": "task1540-76672374ff054cd1a4383bab12fad5e2",
            "input": "In cognitive sciences it is not uncommon to use various games effectively. For example, in artificial intelligence, the RoboCup [14] initiative was to set up to catalyse research on the field of autonomous agent technology. In this paper, we introduce a similar soccer simulation initiative to try to investigate a model of human consciousness and a notion of reality in the form of a cognitive problem. In addition, for example, the home pitch advantage and the objective role of the supporters could be naturally described and discussed in terms of this new soccer simulation model.",
            "output": [
                "Quantum Consciousness Soccer Simulator"
            ]
        },
        {
            "id": "task1540-b9eb222b462f476f9a3de3286c4042ce",
            "input": "The Augmented Lagragian Method (ALM) and Alternating Direction Method of Multiplier (ADMM) have been powerful optimization methods for general convex programming subject to linear constraint. We consider the convex problem whose objective consists of a smooth part and a nonsmooth but simple part. We propose the Fast Proximal Augmented Lagragian Method (Fast PALM) which achieves the convergence rate O(1/K), compared with O(1/K) by the traditional PALM. In order to further reduce the per-iteration complexity and handle the multi-blocks problem, we propose the Fast Proximal ADMM with Parallel Splitting (Fast PL-ADMM-PS) method. It also partially improves the rate related to the smooth part of the objective function. Experimental results on both synthesized and real world data demonstrate that our fast methods significantly improve the previous PALM and ADMM. Introduction This work aims to solve the following linearly constrained separable convex problem with n blocks of variables min x1,··· ,xn f(x) = n ∑",
            "output": [
                "Fast Proximal Linearized Alternating Direction Method of Multiplier with Parallel Splitting"
            ]
        },
        {
            "id": "task1540-02910c5a4a09475b9fba310bf0b1b133",
            "input": "The problem of business-IT alignment is of widespread economic concern. As one way of addressing the problem, this paper describes an online system that functions as a kind of Wiki -one that supports the collaborative writing and running of business and scientific applications, as rules in open vocabulary, executable English, using a browser. Since the rules are in English, they are indexed by Google and other search engines. This is useful when looking for rules for a task that one has in mind. The design of the system integrates the semantics of data, with a semantics of an inference method, and also with the meanings of English sentences. As such, the system has functionality that may be useful for the Rules, Logic, Proof and Trust requirements of the Semantic Web. The system accepts rules, and small numbers of facts, typed or copy-pasted directly into a browser. One can then run the rules, again using a browser. For larger amounts of data, the system uses information in the rules to automatically generate and run SQL over networked databases. From a few highly declarative rules, the system typically generates SQL that would be too complicated to write reliably by hand. However, the system can explain its results in step-by-step hypertexted English, at the business or scientific level As befits a Wiki, shared use of the system is free. Introduction The well known \"layer cake\" diagram (Berners-Lee 2004) outlines a high level agenda for work on the Semantic Web. Figure 1. The Semantic Web Layer Cake",
            "output": [
                "A Wiki for Business Rules in Open Vocabulary, Executable English"
            ]
        },
        {
            "id": "task1540-a744d697dcf54a758d5a995acff4d125",
            "input": "This paper targets on the problem of set to set recognition, which learns the metric between two image sets. Images in each set belong to the same identity. Since images in a set can be complementary, they hopefully lead to higher accuracy in practical applications. However, the quality of each sample cannot be guaranteed, and samples with poor quality will hurt the metric. In this paper, the quality aware network (QAN) is proposed to confront this problem, where the quality of each sample can be automatically learned although such information is not explicitly provided in the training stage. The network has two branches, where the first branch extracts appearance feature embedding for each sample and the other branch predicts quality score for each sample. Features and quality scores of all samples in a set are then aggregated to generate the final feature embedding. We show that the two branches can be trained in an end-to-end manner given only the set-level identity annotation. Analysis on gradient spread of this mechanism indicates that the quality learned by the network is beneficial to set-to-set recognition and simplifies the distribution that the network needs to fit. Experiments on both face verification and person re-identification show advantages of the proposed QAN. The source code and network structure can be downloaded at GitHub1",
            "output": [
                "Quality Aware Network for Set to Set Recognition"
            ]
        },
        {
            "id": "task1540-5eed8d144efe4146a3336aa936852f83",
            "input": "The problem of makespan optimal solving of cooperative path finding (CPF) is addressed in this paper. The task in CPF is to relocate a group of agents in a non-colliding way so that each agent eventually reaches its goal location from the given initial location. The abstraction adopted in this work assumes that agents are discrete items moving in an undirected graph by traversing edges. Makespan optimal solving of CPF means to generate solutions that are as short as possible in terms of the total number of time steps required for the execution of the solution. We show that reducing CPF to propositional satisfiability (SAT) represents a viable option for obtaining makespan optimal solutions. Several encodings of CPF into propositional formulae are suggested and experimentally evaluated. The evaluation indicates that SAT based CPF solving outperforms other makespan optimal methods significantly in highly constrained situations (environments that are densely occupied by agents).",
            "output": [
                "Makespan Optimal Solving of Cooperative Path-Finding"
            ]
        },
        {
            "id": "task1540-0dfaf8cfa9eb490bb7d63509975b46d3",
            "input": "Combining abstract, symbolic reasoning with continuous neural reasoning is a grand challenge of representation learning. As a step in this direction, we propose a new architecture, called neural equivalence networks, for the problem of learning continuous semantic representations of algebraic and logical expressions. These networks are trained to represent semantic equivalence, even of expressions that are syntactically very different. The challenge is that semantic representations must be computed in a syntax-directed manner, because semantics is compositional, but at the same time, small changes in syntax can lead to very large changes in semantics, which can be difficult for continuous neural architectures. We perform an exhaustive evaluation on the task of checking equivalence on a highly diverse class of symbolic algebraic and boolean expression types, showing that our model significantly outperforms existing architectures.",
            "output": [
                "Learning Continuous Semantic Representations of Symbolic Expressions"
            ]
        },
        {
            "id": "task1540-08e8f6f78a95491893168123394022da",
            "input": "Model-based Bayesian reinforcement learning has generated significant interest in the AI community as it provides an elegant solution to the optimal exploration-exploitation tradeoff in classical reinforcement learning. Unfortunately, the applicability of this type of approach has been limited to small domains due to the high complexity of reasoning about the joint posterior over model parameters. In this paper, we consider the use of factored representations combined with online planning techniques, to improve scalability of these methods. The main contribution of this paper is a Bayesian framework for learning the structure and parameters of a dynamical system, while also simultaneously planning a (near-)optimal sequence of actions.",
            "output": [
                "Model-Based Bayesian Reinforcement Learning in Large Structured Domains"
            ]
        },
        {
            "id": "task1540-c97225a69ea74be79cee2fd5a1fcaaf3",
            "input": "One of the most important problems in machine translation (MT) evaluation is to evaluate the similarity between translation hypotheses with different surface forms from the reference, especially at the segment level. We propose to use word embeddings to perform word alignment for segment-level MT evaluation. We performed experiments with three types of alignment methods using word embeddings. We evaluated our proposed methods with various translation datasets. Experimental results show that our proposed methods outperform previous word embeddings-based methods.",
            "output": [
                "Word-Alignment-Based Segment-Level Machine Translation Evaluation using Word Embeddings"
            ]
        },
        {
            "id": "task1540-6ec555afd82b43b3bf99949221d74f0c",
            "input": "We represent the sequence of fMRI (Functional Magnetic Resonance Imaging) brain volumes recorded during a cognitive stimulus by a graph which consists of a set of local meshes. The corresponding cognitive process, encoded in the brain, is then represented by these meshes each of which is estimated assuming a linear relationship among the voxel time series in a predefined locality. First, we define the concept of locality in two neighborhood systems, namely, the spatial and functional neighborhoods. Then, we construct spatially and functionally local meshes around each voxel, called seed voxel, by connecting it either to its spatial or functional p-nearest neighbors. The mesh formed around a voxel is a directed sub-graph with a star topology, where the direction of the edges is taken towards the seed voxel at the center of the mesh. We represent the time series recorded at each seed voxel in terms of linear combination of the time series of its p-nearest neighbors in the mesh. The relationships between a seed voxel and its neighbors are represented by the edge weights of each mesh, and are estimated by solving a linear regression equation. The estimated mesh edge weights lead to a better representation of information in the brain for encoding and decoding of the cognitive tasks. We test our model on a visual object recognition and emotional memory retrieval experiments using Support Vector Machines that are trained using the mesh edge weights as features. In the experimental analysis, we observe that the edge weights of the spatial and functional meshes perform better than the state-of-the-art brain decoding models. Keywords—fMRI; voxel connectivity; brain decoding; object recognition; classification",
            "output": [
                "Modeling the Sequence of Brain Volumes by Local Mesh Models for Brain Decoding"
            ]
        },
        {
            "id": "task1540-4208c807d9aa45da953ac6e530d6541a",
            "input": "Submodular maximization problems belong to the family of combinatorial optimization problems and enjoy wide applications. In this paper, we focus on the problem of maximizing a monotone submodular function subject to a d-knapsack constraint, for which we propose a streaming algorithm that achieves a ( 1 1+2d − ) -approximation of the optimal value, while it only needs one single pass through the dataset without storing all the data in the memory. In our experiments, we extensively evaluate the effectiveness of our proposed algorithm via two applications: news recommendation and scientific literature recommendation. It is observed that the proposed streaming algorithm achieves both execution speedup and memory saving by several orders of magnitude, compared with existing approaches.",
            "output": [
                "Streaming Algorithms for News and Scientific Literature Recommendation: Submodular Maximization with a d-Knapsack Constraint"
            ]
        },
        {
            "id": "task1540-26231e7f5c044d2295b11f66c6fd0782",
            "input": "Sequence-to-sequence models have shown strong performance across a broad range of applications. However, their application to parsing and generating text using Abstract Meaning Representation (AMR) has been limited, due to the relatively limited amount of labeled data and the nonsequential nature of the AMR graphs. We present a novel training procedure that can lift this limitation using millions of unlabeled sentences and careful preprocessing of the AMR graphs. For AMR parsing, our model achieves competitive results of 62.1 SMATCH, the current best score reported without significant use of external semantic resources. For AMR generation, our model establishes a new state-of-the-art performance of BLEU 33.8. We present extensive ablative and qualitative analysis including strong evidence that sequencebased AMR models are robust against ordering variations of graph-to-sequence conversions.",
            "output": [
                "Neural AMR: Sequence-to-Sequence Models for Parsing and Generation"
            ]
        },
        {
            "id": "task1540-1244ade57d6c4933afd15da7e5994844",
            "input": "We present local discriminative Gaussian (LDG) dimensionality reduction, a supervised dimensionality reduction technique for classification. The LDG objective function is an approximation to the leave-one-out training error of a local quadratic discriminant analysis classifier, and thus acts locally to each training point in order to find a mapping where similar data can be discriminated from dissimilar data. While other state-ofthe-art linear dimensionality reduction methods require gradient descent or iterative solution approaches, LDG is solved with a single eigen-decomposition. Thus, it scales better for datasets with a large number of feature dimensions or training examples. We also adapt LDG to the transfer learning setting, and show that it achieves good performance when the test data distribution differs from that of the training data.",
            "output": [
                "Dimensionality Reduction by Local Discriminative Gaussians"
            ]
        },
        {
            "id": "task1540-a954d6827a4e49aca9a9177ca9760786",
            "input": "Building large models with parameter sharing accounts for most of the success of deep convolutional neural networks (CNNs). In this paper, we propose doubly convolutional neural networks (DCNNs), which significantly improve the performance of CNNs by further exploring this idea. In stead of allocating a set of convolutional filters that are independently learned, a DCNN maintains groups of filters where filters within each group are translated versions of each other. Practically, a DCNN can be easily implemented by a two-step convolution procedure, which is supported by most modern deep learning libraries. We perform extensive experiments on three image classification benchmarks: CIFAR-10, CIFAR-100 and ImageNet, and show that DCNNs consistently outperform other competing architectures. We have also verified that replacing a convolutional layer with a doubly convolutional layer at any depth of a CNN can improve its performance. Moreover, various design choices of DCNNs are demonstrated, which shows that DCNN can serve the dual purpose of building more accurate models and/or reducing the memory footprint without sacrificing the accuracy.",
            "output": [
                "Doubly Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-1a0aa56b2d614af2821581c478e9e89b",
            "input": "This paper presents the experiments carried out by us at Jadavpur University as part of the participation in FIRE 2015 task: Entity Extraction from Social Media Text Indian Languages (ESM-IL). The tool that we have developed for the task is based on Trigram Hidden Markov Model that utilizes information like gazetteer list, POS tag and some other word level features to enhance the observation probabilities of the known tokens as well as unknown tokens. We submitted runs for English only. A statistical HMM (Hidden Markov Models) based model has been used to implement our system. The system has been trained and tested on the datasets released for FIRE 2015 task: Entity Extraction from Social Media Text Indian Languages (ESM-IL). Our system is the best performer for English language and it obtains precision, recall and F-measures of 61.96, 39.46 and 48.21 respectively.",
            "output": [
                "A Hidden Markov Model Based System for Entity Extraction from Social Media English Text at FIRE 2015"
            ]
        },
        {
            "id": "task1540-9f3232c999994666bf4fb5d8a720556c",
            "input": "We present a supervised sequence to sequence transduction model with a hard attention mechanism which combines the more traditional statistical alignment methods with the power of recurrent neural networks. We evaluate the model on the task of morphological inflection generation and show that it provides state of the art results in various setups compared to the previous neural and non-neural approaches. Eventually we present an analysis of the learned representations for both hard and soft attention models, shedding light on the features such models extract in order to solve the task.",
            "output": [
                "HARD MONOTONIC ATTENTION"
            ]
        },
        {
            "id": "task1540-78c04b2917454474adf52aa777e18d65",
            "input": "The degree of success in document summarization processes depends on the performance of the method used in identifying significant sentences in the documents. The collection of unique words characterizes the major signature of the document, and forms the basis for Term-Sentence-Matrix (TSM). The Positive Pointwise Mutual Information, which works well for measuring semantic similarity in the TermSentence-Matrix, is used in our method to assign weights for each entry in the Term-Sentence-Matrix. The Sentence-Rank-Matrix generated from this weighted TSM, is then used to extract a summary from the document. Our experiments show that such a method would outperform most of the existing methods in producing summaries from large documents.",
            "output": [
                "DOCUMENT SUMMARIZATION USING POSITIVE POINTWISE MUTUAL INFORMATION"
            ]
        },
        {
            "id": "task1540-040ff6d313f74db2aa32fe250a9d5d2a",
            "input": "We study optimal conformity measures for various criteria of efficiency of classification in an idealised setting. This leads to an important class of criteria of efficiency that we call probabilistic; it turns out that the most standard criteria of efficiency used in literature on conformal prediction are not probabilistic unless the problem of classification is binary. We consider both unconditional and label-conditional conformal prediction. The conference version of this paper has been published in the Proceedings of COPA 2016.",
            "output": [
                "Criteria of efficiency for conformal prediction∗"
            ]
        },
        {
            "id": "task1540-8c2f07281e274ed89a031da0adf02cbc",
            "input": "A general method is given for revising degrees of belief and arriving at consistent decisions about a system of logically constrained issues. In contrast to other works about belief revision, here the constraints are assumed to be fixed. The method has two variants, dual of each other, whose revised degrees of belief are respectively above and below the original ones. The upper [resp. lower] revised degrees of belief are uniquely characterized as the lowest [resp. greatest] ones that are invariant by a certain max-min [resp. min-max] operation determined by the logical constraints. In both variants, making balance between the revised degree of belief of a proposition and that of its negation leads to decisions that are ensured to be consistent with the logical constraints. These decisions are ensured to agree with the majority criterion as applied to the original degrees of belief whenever this gives a consistent result. They are also ensured to satisfy a property of respect for unanimity about any particular issue, as well as a property of monotonicity with respect to the original degrees of belief. The application of the method to certain special domains comes down to well established or increasingly accepted methods, such as the singlelink method of cluster analysis and the method of paths in preferential voting.",
            "output": [
                "A GENERAL METHOD FOR DECIDING ABOUT LOGICALLY CONSTRAINED ISSUES"
            ]
        },
        {
            "id": "task1540-ffe2b70709a54a979ae4e3b32c30c806",
            "input": "In recent years, the crucial importance of metrics in machine learning algorithms has led to an increasing interest for optimizing distance and similarity functions. Most of the state of the art focus on learning Mahalanobis distances (requiring to fulfill a constraint of positive semi-definiteness) for use in a local k-NN algorithm. However, no theoretical link is established between the learned metrics and their performance in classification. In this paper, we make use of the formal framework of (ǫ, γ, τ)-good similarities introduced by Balcan et al. to design an algorithm for learning a non PSD linear similarity optimized in a nonlinear feature space, which is then used to build a global linear classifier. We show that our approach has uniform stability and derive a generalization bound on the classification error. Experiments performed on various datasets confirm the effectiveness of our approach compared to stateof-the-art methods and provide evidence that (i) it is fast, (ii) robust to overfitting and (iii) produces very sparse classifiers.",
            "output": [
                "Similarity Learning for Provably AccurateSparse Linear Classification"
            ]
        },
        {
            "id": "task1540-82a4941be27b4909bfff96ec8c83f9e7",
            "input": "For computer vision applications, prior works have shown the efficacy of reducing numeric precision of model parameters (network weights) in deep neural networks but also that reducing the precision of activations hurts model accuracy much more than reducing the precision of model parameters. We study schemes to train networks from scratch using reduced-precision activations without hurting the model accuracy. We reduce the precision of activation maps (along with model parameters) using a novel quantization scheme and increase the number of filter maps in a layer, and find that this scheme compensates or surpasses the accuracy of the baseline full-precision network. As a result, one can significantly reduce the dynamic memory footprint, memory bandwidth, computational energy and speed up the training and inference process with appropriate hardware support. We call our scheme WRPN wide reduced-precision networks. We report results using our proposed schemes and show that our results are better than previously reported accuracies on ILSVRC-12 dataset while being computationally less expensive compared to previously reported reduced-precision networks.",
            "output": [
                "WRPN: Training and Inference using Wide Reduced-Precision Networks"
            ]
        },
        {
            "id": "task1540-cbe9f614479a4c7388b7de2f5fb9275b",
            "input": "In late 2011, Fado was elevated to the oral and intangible heritage of humanity by UNESCO. This study aims to develop a tool for automatic detection of Fado music based on the audio signal. To do this, frequency spectrum-related characteristics were captured form the audio signal: in addition to the Mel Frequency Cepstral Coefficients (MFCCs) and the energy of the signal, the signal was further analysed in two frequency ranges, providing additional information. Tests were run both in a 10-fold cross-validation setup (97.6% accuracy), and in a traditional train/test setup (95.8% accuracy). The good results reflect the fact that Fado is a very distinctive musical style.",
            "output": [
                "Automatic Fado Music Classification"
            ]
        },
        {
            "id": "task1540-4f3cc6a3cbd140cdb5515761fb6fbe65",
            "input": "Sentiment analysis of online user generated content is important for many social media analytics tasks. Researchers have largely relied on textual sentiment analysis to develop systems to predict political elections, measure economic indicators, and so on. Recently, social media users are increasingly using images and videos to express their opinions and share their experiences. Sentiment analysis of such large scale visual content can help better extract user sentiments toward events or topics, such as those in image tweets, so that prediction of sentiment from visual content is complementary to textual sentiment analysis. Motivated by the needs in leveraging large scale yet noisy training data to solve the extremely challenging problem of image sentiment analysis, we employ Convolutional Neural Networks (CNN). We first design a suitable CNN architecture for image sentiment analysis. We obtain half a million training samples by using a baseline sentiment algorithm to label Flickr images. To make use of such noisy machine labeled data, we employ a progressive strategy to fine-tune the deep network. Furthermore, we improve the performance on Twitter images by inducing domain transfer with a small number of manually labeled Twitter images. We have conducted extensive experiments on manually labeled Twitter images. The results show that the proposed CNN can achieve better performance in image sentiment analysis than competing algorithms.",
            "output": [
                "Robust Image Sentiment Analysis Using Progressively Trained and Domain Transferred Deep Networks"
            ]
        },
        {
            "id": "task1540-7295f0e5d5a04c7aa7fb59ee93cea23c",
            "input": "Systematic use of the published results of randomized clinical trials is<lb>increasingly important in evidence-based medicine. In order to collate and<lb>analyze the results from potentially numerous trials, evidence tables are<lb>used to represent trials concerning a set of interventions of interest. An<lb>evidence table has columns for the patient group, for each of the interven-<lb>tions being compared, for the criterion for the comparison (e.g. proportion<lb>who survived after 5 years from treatment), and for each of the results.<lb>Currently, it is a labour-intensive activity to read each published paper<lb>and extract the information for each field in an evidence table. There have<lb>been some NLP studies investigating how some of the features from papers<lb>can be extracted, or at least the relevant sentences identified. However,<lb>there is a lack of an NLP system for the systematic extraction of each item<lb>of information required for an evidence table. We address this need by a<lb>combination of a maximum entropy classifier, and integer linear program-<lb>ming. We use the later to handle constraints on what is an acceptable<lb>classification of the features to be extracted. With experimental results,<lb>we demonstrate substantial advantages in using global constraints (such<lb>as the features describing the patient group, and the interventions, must<lb>occur before the features describing the results of the comparison).",
            "output": [
                "Extraction of evidence tables from abstracts of randomized clinical trials using a maximum entropy classifier and global constraints"
            ]
        },
        {
            "id": "task1540-c9bd862da02b44bc9c7ddc9dfd354bb7",
            "input": "There are around a hundred installed apps on an average smartphone. The high number of apps and the limited number of app icons that can be displayed on the device’s screen requires a new paradigm to address their visibility to the user. In this paper we propose a new online algorithm for dynamically predicting a set of apps that the user is likely to use. The algorithm runs on the user’s device and constantly learns the user’s habits at a given time, location, and device state. It is designed to actively help the user to navigate to the desired app as well as to provide a personalized feeling, and hence is aimed at maximizing the AUC. We show both theoretically and empirically that the algorithm maximizes the AUC, and yields good results on a set of 1,000 devices.",
            "output": [
                "Context-Based Prediction of App Usage"
            ]
        },
        {
            "id": "task1540-74763bf8518b40b08db2a80542f29d05",
            "input": "Security surveillance is one of the most important issues in smart cities, especially in an era of terrorism. Deploying a number of (video) cameras is a common surveillance approach. Given the never-ending power offered by vehicles to metropolises, exploiting vehicle traffic to design camera placement strategies could potentially facilitate security surveillance. This article constitutes the first effort toward building the linkage between vehicle traffic and security surveillance, which is a critical problem for smart cities. We expect our study could influence the decision making of surveillance camera placement, and foster more research of principled ways of security surveillance beneficial to our physical-world life.",
            "output": [
                "Vehicle Traffic Driven Camera Placement for Better Metropolis Security Surveillance"
            ]
        },
        {
            "id": "task1540-5272c010cc804af48e93b3a5aa7fd0e9",
            "input": "We study multi-turn response generation in chatbots where a response is generated according to a conversation context. Existing work has modeled the hierarchy of the context, but does not pay enough attention to the fact that words and utterances in the context are differentially important. As a result, they may lose important information in context and generate irrelevant responses. We propose a hierarchical recurrent attention network (HRAN) to model both aspects in a unified framework. In HRAN, a hierarchical attention mechanism attends to important parts within and among utterances with word level attention and utterance level attention respectively. With the word level attention, hidden vectors of a word level encoder are synthesized as utterance vectors and fed to an utterance level encoder to construct hidden representations of the context. The hidden vectors of the context are then processed by the utterance level attention and formed as context vectors for decoding the response. Empirical studies on both automatic evaluation and human judgment show that HRAN can significantly outperform state-of-the-art models for multi-turn response generation.",
            "output": [
                "Hierarchical Recurrent Attention Network for Response Generation"
            ]
        },
        {
            "id": "task1540-ddc32fda8ebb4396bee82adae155eda8",
            "input": "In the last five years there have been a large number of new time series classification algorithms proposed in the literature. These algorithms have been evaluated on subsets of the 47 data sets in the University of California, Riverside time series classification archive. The archive has recently been expanded to 85 data sets, over half of which have been donated by researchers at the University of East Anglia. Aspects of previous evaluations have made comparisons between algorithms difficult. For example, several different programming languages have been used, experiments involved a single train/test split and some used normalised data whilst others did not. The relaunch of the archive provides a timely opportunity to thoroughly evaluate algorithms on a larger number of datasets. We have implemented 18 recently proposed algorithms in a common Java framework and compared them against two standard benchmark classifiers (and each other) by performing 100 resampling experiments on each of the 85 datasets. We use these results to test several hypotheses relating to whether the algorithms are significantly more accurate than the benchmarks and each other. Our results indicate that only 9 of these algorithms are significantly more accurate than both benchmarks and that one classifier, the Collective of Transformation Ensembles, is significantly more accurate than all of the others. All of our experiments and results are reproducible: we release all of our code, results and experimental details and we hope these experiments form the basis for more rigorous testing of new algorithms in the future.",
            "output": [
                "The Great Time Series Classification Bake Off: An Experimental Evaluation of Recently Proposed Algorithms. Extended Version"
            ]
        },
        {
            "id": "task1540-80c57c2857504655a0af308d4490761a",
            "input": "This paper proposes a simple test for compositionality (i.e., literal usage) of a word or phrase in a context-specific way. The test is computationally simple, relying on no external resources and only uses a set of trained word vectors. Experiments show that the proposed method is competitive with state of the art and displays high accuracy in context-specific compositionality detection of a variety of natural language phenomena (idiomaticity, sarcasm, metaphor) for different datasets in multiple languages. The key insight is to connect compositionality to a curious geometric property of word embeddings, which is of independent interest.",
            "output": [
                "Geometry of Compositionality"
            ]
        },
        {
            "id": "task1540-330085762dfc47a783b31f92d6aa7481",
            "input": "We discuss several modifications and extensions over the previous proposed Cnvlutin (CNV) accelerator for convolutional and fully-connected layers of Deep Learning Network. We first describe different encodings of the activations that are deemed ineffectual. The encodings have different memory overhead and energy characteristics. We propose using a level of indirection when accessing activations from memory to reduce their memory footprint by storing only the effectual activations. We also present a modified organization that detects the activations that are deemed as ineffectual while fetching them from memory. This is different than the original design that instead detected them at the output of the preceding layer. Finally, we present an extended CNV that can also skip ineffectual weights.",
            "output": [
                "Cnvlutin2: Ineffectual-Activation-and-Weight-Free Deep Neural Network Computing"
            ]
        },
        {
            "id": "task1540-2d7ffea1f1a347e28f6bebb200500934",
            "input": "Unsupervised classification algorithm based on clonal selection principle named Unsupervised Clonal Selection Classification (UCSC) is proposed in this paper. The new proposed algorithm is data driven and self-adaptive, it adjusts its parameters to the data to make the classification operation as fast as possible. The performance of UCSC is evaluated by comparing it with the well known K-means algorithm using several artificial and real-life data sets. The experiments show that the proposed UCSC algorithm is more reliable and has high classification precision comparing to traditional classification methods such as K-means. General Terms Pattern Recognition, Algorithms.",
            "output": [
                "Unsupervised Classification Using Immune Algorithm"
            ]
        },
        {
            "id": "task1540-0fca0add1e694b889dca3b0989a5b673",
            "input": "The longest arc-preserving common subsequence problem is an NP-hard combinatorial optimization problem from the field of computational biology. This problem finds applications, in particular, in the comparison of arc-annotated Ribonucleic acid (RNA) sequences. In this work we propose a simple, hybrid evolutionary algorithm to tackle this problem. The most important feature of this algorithm concerns a crossover operator based on solution merging. In solution merging, two or more solutions to the problem are merged, and an exact technique is used to find the best solution within this union. It is experimentally shown that the proposed algorithm outperforms a heuristic from the literature.",
            "output": [
                "A Hybrid Evolutionary Algorithm Based on Solution Merging for the Longest Arc-Preserving Common Subsequence Problem"
            ]
        },
        {
            "id": "task1540-58d0382ed34c4140aebbd61709577a1a",
            "input": "We provide the first extensive evaluation of how using different types of context to learn skip-gram word embeddings affects performance on a wide range of intrinsic and extrinsic NLP tasks. Our results suggest that while intrinsic tasks tend to exhibit a clear preference to particular types of contexts and higher dimensionality, more careful tuning is required for finding the optimal settings for most of the extrinsic tasks that we considered. Furthermore, for these extrinsic tasks, we find that once the benefit from increasing the embedding dimensionality is mostly exhausted, simple concatenation of word embeddings, learned with different context types, can yield further performance gains. As an additional contribution, we propose a new variant of the skip-gram model that learns word embeddings from weighted contexts of substitute words.",
            "output": [
                "The Role of Context Types and Dimensionality in Learning Word Embeddings"
            ]
        },
        {
            "id": "task1540-352d34d913f54dbaba2ce78a4e8d321f",
            "input": "To automatically test web applications, crawling-based techniques are usually adopted to mine the behavior models, explore the state spaces or detect the violated invariants of the applications. However, in existing crawlers, rules for identifying the topics of input text fields, such as login ids, passwords, emails, dates and phone numbers, have to be manually configured. Moreover, the rules for one application are very often not suitable for another. In addition, when several rules conflict and match an input text field to more than one topics, it can be difficult to determine which rule suggests a better match. This paper presents a natural-language approach to automatically identify the topics of encountered input fields during crawling by semantically comparing their similarities with the input fields in labeled corpus. In our evaluation with 100 real-world forms, the proposed approach demonstrated comparable performance to the rule-based one. Our experiments also show that the accuracy of the rule-based approach can be improved by up to 19% when integrated with our approach.",
            "output": [
                "Using Semantic Similarity for Input Topic Identification in Crawling-based Web Application Testing"
            ]
        },
        {
            "id": "task1540-241bf521aa104e1b8b5f34a4c0adbb29",
            "input": "We propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the Visual7W dataset. Motivated by divergent trends in model complexities in the literature, we explore the balance between model expressiveness and simplicity by studying incrementally more complex architectures. We start with LSTM-encoding of input questions and answers; build on this with context generation by LSTM-encodings of neural image and question representations and attention over images; and evaluate the diversity and predictive power of our models and the ensemble thereof. All models are evaluated against a simple baseline inspired by the current state-of-the-art, consisting of involving simple concatenation of bag-of-words and CNN representations for the text and images, respectively. Generally, we observe marked variation in image-reasoning performance between our models not obvious from their overall performance, as well as evidence of dataset bias. Our standalone models achieve accuracies up to 64.6%, while the ensemble of all models achieves the best accuracy of 66.67%, within 0.5% of the current state-of-the-art for Visual7W.",
            "output": [
                "Recurrent and Contextual Models for Visual Question Answering"
            ]
        },
        {
            "id": "task1540-8caabe3c0a774258afcd32591e97bd07",
            "input": "Stochastic network design is a general framework for optimizing network connectivity. It has several applications in computational sustainability including spatial conservation planning, pre-disaster network preparation, and river network optimization. A common assumption in previous work has been made that network parameters (e.g., probability of species colonization) are precisely known, which is unrealistic in real-world settings. We therefore address the robust river network design problem where the goal is to optimize river connectivity for fish movement by removing barriers. We assume that fish passability probabilities are known only imprecisely, but are within some interval bounds. We then develop a planning approach that computes the policies with either high robust ratio or low regret. Empirically, our approach scales well to large river networks. We also provide insights into the solutions generated by our robust approach, which has significantly higher robust ratio than the baseline solution with mean parameter estimates.",
            "output": [
                "Robust Optimization for Tree-Structured Stochastic Network Design"
            ]
        },
        {
            "id": "task1540-f539aca39e59405394ecd759c42657c2",
            "input": "In data analysis, latent variables play a central role because they help provide powerful insights into a wide variety of phenomena, ranging from biological to human sciences. The latent tree model, a particular type of probabilistic graphical models, deserves attention. Its simple structure a tree allows simple and efficient inference, while its latent variables capture complex relationships. In the past decade, the latent tree model has been subject to significant theoretical and methodological developments. In this review, we propose a comprehensive study of this model. First we summarize key ideas underlying the model. Second we explain how it can be efficiently learned from data. Third we illustrate its use within three types of applications: latent structure discovery, multidimensional clustering, and probabilistic inference. Finally, we conclude and give promising directions for future researches in this field.",
            "output": [
                "A Survey on Latent Tree Models and Applications"
            ]
        },
        {
            "id": "task1540-6305266102874b7ebee96286203f5881",
            "input": "In this paper, we suggest a novel data-driven approach to active learning: Learning Active Learning (LAL). The key idea behind LAL is to train a regressor that predicts the expected error reduction for a potential sample in a particular learning state. By treating the query selection procedure as a regression problem we are not restricted to dealing with existing AL heuristics; instead, we learn strategies based on experience from previous active learning experiments. We show that LAL can be learnt from a simple artificial 2D dataset and yields strategies that work well on real data from a wide range of domains. Moreover, if some domain-specific samples are available to bootstrap active learning, the LAL strategy can be tailored for a particular problem.",
            "output": [
                "Learning Active Learning from Real and Synthetic Data"
            ]
        },
        {
            "id": "task1540-3b35ac29469148e1b05e94bde7bc5b0d",
            "input": "In this paper, we review the problem of matrix completion and expose its intimate relations with algebraic geometry, combinatorics and graph theory. We present the first necessary and sufficient combinatorial conditions for matrices of arbitrary rank to be identifiable from a set of matrix entries, yielding theoretical constraints and new algorithms for the problem of matrix completion. We conclude by algorithmically evaluating the tightness of the given conditions and algorithms for practically relevant matrix sizes, showing that the algebraic-combinatorial approach can lead to improvements over stateof-the-art matrix completion methods.",
            "output": [
                "A Combinatorial Algebraic Approach for the Identifiability of Low-Rank Matrix Completion"
            ]
        },
        {
            "id": "task1540-30cc6f0565614a608ec6fabbf402f7b3",
            "input": "We propose a novel approach to reduce memory consumption of the backpropagation through time (BPTT) algorithm when training recurrent neural networks (RNNs). Our approach uses dynamic programming to balance a trade-off between caching of intermediate results and recomputation. The algorithm is capable of tightly fitting within almost any user-set memory budget while finding an optimal execution policy minimizing the computational cost. Computational devices have limited memory capacity and maximizing a computational performance given a fixed memory budget is a practical use-case. We provide asymptotic computational upper bounds for various regimes. The algorithm is particularly effective for long sequences. For sequences of length 1000, our algorithm saves 95% of memory usage while using only one third more time per iteration than the standard BPTT.",
            "output": [
                "Memory-Efficient Backpropagation Through Time"
            ]
        },
        {
            "id": "task1540-97f79137ecb0469c8cce6d59baac1e9a",
            "input": "Our study identifies sentences in Wikipedia articles that are either identical or highly similar by applying techniques for near-duplicate detection of web pages. This is accomplished with a MapReduce implementation of minhash to identify clusters of sentences with high Jaccard similarity. We show that these clusters can be categorized into six different types, two of which are particularly interesting: identical sentences quantify the extent to which content in Wikipedia is copied and pasted, and near-duplicate sentences that state contradictory facts point to quality issues in Wikipedia.",
            "output": [
                "Identifying Duplicate and Contradictory Information in Wikipedia"
            ]
        },
        {
            "id": "task1540-d9058fe7d7db4b929559026ffcf74af0",
            "input": "Photo retouching enables photographers to invoke dramatic visual impressions by artistically enhancing their photos through stylistic color and tone adjustments. However, it is also a time-consuming and challenging task that requires advanced skills beyond the abilities of casual photographers. Using an automated algorithm is an appealing alternative to manual work but such an algorithm faces many hurdles. Many photographic styles rely on subtle adjustments that depend on the image content and even its semantics. Further, these adjustments are often spatially varying. Because of these characteristics, existing automatic algorithms are still limited and cover only a subset of these challenges. Recently, deep machine learning has shown unique abilities to address hard problems that resisted machine algorithms for long. This motivated us to explore the use of deep learning in the context of photo editing. In this paper, we explain how to formulate the automatic photo adjustment problem in a way suitable for this approach. We also introduce an image descriptor that accounts for the local semantics of an image. Our experiments demonstrate that our deep learning formulation applied using these descriptors successfully capture sophisticated photographic styles. In particular and unlike previous techniques, it can model local adjustments that depend on the image semantics. We show on several examples that this yields results that are qualitatively and quantitatively better than previous work.",
            "output": [
                "Automatic Photo Adjustment Using Deep Learning"
            ]
        },
        {
            "id": "task1540-739d2ba237e646e6811abc5c3e775075",
            "input": "We investigate the integration of word embeddings as classification features in the setting of large scale text classification. Such representations have been used in a plethora of tasks, however their application in classification scenarios with thousands of classes has not been extensively researched, partially due to hardware limitations. In this work, we examine efficient composition functions to obtain document-level from word-level embeddings and we subsequently investigate their combination with the traditional one-hot-encoding representations. By presenting empirical evidence on large, multi-class, multi-label classification problems, we demonstrate the efficiency and the performance benefits of this combination.",
            "output": [
                "An empirical study on large scale text classification with skip-gram embeddings"
            ]
        },
        {
            "id": "task1540-f5bd8a7cdbcc4994a72a76c86663f8de",
            "input": "We introduce a recurrent neural network architecture for automated road surface wetness detection from audio of tiresurface interaction. The robustness of our approach is evaluated on 785,826 bins of audio that span an extensive range of vehicle speeds, noises from the environment, road surface types, and pavement conditions including international roughness index (IRI) values from 25 in/mi to 1400 in/mi. The training and evaluation of the model are performed on different roads to minimize the impact of environmental and other external factors on the accuracy of the classification. We achieve an unweighted average recall (UAR) of 93.2 % across all vehicle speeds including 0 mph. The classifier still works at 0 mph because the discriminating signal is present in the sound of other vehicles driving by.",
            "output": [
                "Detecting Road Surface Wetness from Audio: A Deep Learning Approach"
            ]
        },
        {
            "id": "task1540-fb56327fe07741aebcf9d35b06f02a18",
            "input": "The era of Big Data has spawned unprecedented interests in developing hashing algorithms for efficient storage and fast nearest neighbor search. Most existing work learn hash functions that are numeric quantizations of feature values in projected feature space. In this work, we propose a novel hash learning framework that encodes feature’s rank orders instead of numeric values in a number of optimal low-dimensional ranking subspaces. We formulate the ranking subspace learning problem as the optimization of a piecewise linear convex-concave function and present two versions of our algorithm: one with independent optimization of each hash bit and the other exploiting a sequential learning framework. Our work is a generalization of the Winner-TakeAll (WTA) hash family and naturally enjoys all the numeric stability benefits of rank correlation measures while being optimized to achieve high precision at very short code length. We compare with several state-of-the-art hashing algorithms in both supervised and unsupervised domain, showing superior performance in a number of data sets.",
            "output": [
                "Rank Subspace Learning for Compact Hash Codes"
            ]
        },
        {
            "id": "task1540-ec24376513064f098aeaebabb0ba6c2b",
            "input": "Semantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard natural language processing pipeline, providing information to downstream tasks such as information extraction and question answering. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of multilayer neural networks operating on graphs, suited to modeling syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence encoders, producing latent feature representations of words in a sentence and capturing information relevant to predicting the semantic representations. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already stateof-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and English.",
            "output": [
                "Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling"
            ]
        },
        {
            "id": "task1540-284639171e324548bf13a23c2b43a82d",
            "input": "LSTD is a popular algorithm for value function approximation. Whenever the number of features is larger than the number of samples, it must be paired with some form of regularization. In particular, `1-regularization methods tend to perform feature selection by promoting sparsity, and thus, are wellsuited for high–dimensional problems. However, since LSTD is not a simple regression algorithm, but it solves a fixed–point problem, its integration with `1-regularization is not straightforward and might come with some drawbacks (e.g., the P-matrix assumption for LASSO-TD). In this paper, we introduce a novel algorithm obtained by integrating LSTD with the Dantzig Selector. We investigate the performance of the proposed algorithm and its relationship with the existing regularized approaches, and show how it addresses some of their drawbacks.",
            "output": [
                "A Dantzig Selector Approach to Temporal Difference Learning"
            ]
        },
        {
            "id": "task1540-37a04d0500f04aa08b5cf67e0c5c21c0",
            "input": "This paper presents a theoretical analysis of multi-view embedding – feature embedding that can be learned from unlabeled data through the task of predicting one view from another. We prove its usefulness in supervised learning under certain conditions. The result explains the effectiveness of some existing methods such as word embedding. Based on this theory, we propose a new semi-supervised learning framework that learns a multi-view embedding of small text regions with convolutional neural networks. The method derived from this framework outperforms state-of-the-art methods on sentiment classification and topic categorization.",
            "output": [
                "Semi-Supervised Learning with Multi-View Embedding: Theory and Application with Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-53c8f01a202348299f4ac193913e74b9",
            "input": "This paper addresses the task of set prediction using deep learning. This is important because the output of many computer vision tasks, including image tagging and object detection, are naturally expressed as sets of entities rather than vectors. As opposed to a vector, the size of a set is not fixed in advance, and it is invariant to the ordering of entities within it. We define a likelihood for a set distribution and learn its parameters using a deep neural network. We also derive a loss for predicting a discrete distribution corresponding to set cardinality. Set prediction is demonstrated on the problems of multi-class image classification and pedestrian detection. Our approach yields state-of-theart results in both cases on standard datasets.",
            "output": [
                "DeepSetNet: Predicting Sets with Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-f95b666ff03049d4a8ad9d60abcffe75",
            "input": "Radiomics has proven to be a powerful prognostic tool for cancer detection, and has previously been applied in lung, breast, prostate, and head-and-neck cancer studies with great success. However, these radiomics-driven methods rely on pre-defined, hand-crafted radiomic feature sets that can limit their ability to characterize unique cancer traits. In this study, we introduce a novel discovery radiomics framework where we directly discover custom radiomic features from the wealth of available medical imaging data. In particular, we leverage novel StochasticNet radiomic sequencers for extracting custom radiomic features tailored for characterizing unique cancer tissue phenotype. Using StochasticNet radiomic sequencers discovered using a wealth of lung CT data, we perform binary classification on 42,340 lung lesions obtained from the CT scans of 93 patients in the LIDC-IDRI dataset. Preliminary results show significant improvement over previous state-of-the-art methods, indicating the potential of the proposed discovery radiomics framework for improving cancer screening and diagnosis.",
            "output": [
                "Discovery Radiomics via StochasticNet Sequencers for Cancer Detection"
            ]
        },
        {
            "id": "task1540-d331d3d2964e479c99a2dfb6e54cef7c",
            "input": "Natural Immune system plays a vital role in the survival of the all living being. It provides a mechanism to defend itself from external predates making it consistent systems, capable of adapting itself for survival incase of changes. The human immune system has motivated scientists and engineers for finding powerful information processing algorithms that has solved complex engineering tasks. This paper explores one of the various possibilities for solving problem in a Multiagent scenario wherein multiple robots are deployed to achieve a goal collectively. The final goal is dependent on the performance of individual robot and its survival without having to lose its energy beyond a predetermined threshold value by deploying an evolutionary computational technique otherwise called the artificial immune system that imitates the biological immune system.",
            "output": [
                "An Artificial Immune System Model for Multi Agents Resource Sharing in Distributed Environments"
            ]
        },
        {
            "id": "task1540-0b5b1eee6e264a25a7295e09fdcfa6ff",
            "input": "How fake news goes viral via social media? How does its propagation pattern differ from real stories? In this paper, we attempt to address the problem of identifying rumors, i.e., fake information, out of microblog posts based on their propagation structure. We firstly model microblog posts diffusion with propagation trees, which provide valuable clues on how an original message is transmitted and developed over time. We then propose a kernel-based method called Propagation Tree Kernel, which captures high-order patterns differentiating different types of rumors by evaluating the similarities between their propagation tree structures. Experimental results on two real-world datasets demonstrate that the proposed kernel-based approach can detect rumors more quickly and accurately than state-ofthe-art rumor detection models.",
            "output": [
                "Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning"
            ]
        },
        {
            "id": "task1540-1ddfacccb391441581db47d866840e61",
            "input": "We present a dictionary-based approach to racism detection in Dutch social media comments, which were retrieved from two public Belgian social media sites likely to attract racist reactions. These comments were labeled as racist or non-racist by multiple annotators. For our approach, three discourse dictionaries were created: first, we created a dictionary by retrieving possibly racist and more neutral terms from the training data, and then augmenting these with more general words to remove some bias. A second dictionary was created through automatic expansion using a word2vec model trained on a large corpus of general Dutch text. Finally, a third dictionary was created by manually filtering out incorrect expansions. We trained multiple Support Vector Machines, using the distribution of words over the different categories in the dictionaries as features. The best-performing model used the manually cleaned dictionary and obtained an F-score of 0.46 for the racist class on a test set consisting of unseen Dutch comments, retrieved from the same sites used for the training set. The automated expansion of the dictionary only slightly boosted the model’s performance, and this increase in performance was not statistically significant. The fact that the coverage of the expanded dictionaries did increase indicates that the words that were automatically added did occur in the corpus, but were not able to meaningfully impact performance. The dictionaries, code, and the procedure for requesting the corpus are available at: https://github.com/clips/hades.",
            "output": [
                "A Dictionary-based Approach to Racism Detection in Dutch Social Media"
            ]
        },
        {
            "id": "task1540-3e2f58bdae9f46d89f38a7c29e9b8090",
            "input": "We propose an efficient optimization algorithm for selecting a subset of training data to induce sparsity for Gaussian process regression. The algorithm estimates an inducing set and the hyperparameters using a single objective, either the marginal likelihood or a variational free energy. The space and time complexity are linear in training set size, and the algorithm can be applied to large regression problems on discrete or continuous domains. Empirical evaluation shows state-ofart performance in discrete cases and competitive results in the continuous case.",
            "output": [
                "Efficient Optimization for Sparse Gaussian Process Regression"
            ]
        },
        {
            "id": "task1540-bf3dd9d1a08e4861add35cae36919364",
            "input": "Distributed constraint optimization (DCOP) problems are a popular way of formulating and solving agent-coordination problems. A DCOP problem is a problem where several agents coordinate their values such that the sum of the resulting constraint costs is minimal. It is often desirable to solve DCOP problems with memory-bounded and asynchronous algorithms. We introduce Branch-and-Bound ADOPT (BnB-ADOPT), a memory-bounded asynchronous DCOP search algorithm that uses the message-passing and communication framework of ADOPT (Modi, Shen, Tambe, & Yokoo, 2005), a well known memory-bounded asynchronous DCOP search algorithm, but changes the search strategy of ADOPT from best-first search to depth-first branch-and-bound search. Our experimental results show that BnB-ADOPT finds cost-minimal solutions up to one order of magnitude faster than ADOPT for a variety of large DCOP problems and is as fast as NCBB, a memory-bounded synchronous DCOP search algorithm, for most of these DCOP problems. Additionally, it is often desirable to find bounded-error solutions for DCOP problems within a reasonable amount of time since finding cost-minimal solutions is NP-hard. The existing bounded-error approximation mechanism allows users only to specify an absolute error bound on the solution cost but a relative error bound is often more intuitive. Thus, we present two new bounded-error approximation mechanisms that allow for relative error bounds and implement them on top of BnB-ADOPT.",
            "output": [
                "An Asynchronous Branch-and-Bound DCOP Algorithm"
            ]
        },
        {
            "id": "task1540-48f89123f7a2482c9f6df1d943f781c1",
            "input": "The Internet and online forums such as Reddit have become an increasingly popular medium for citizens to engage in political conversations. However, the online disinhibition effect resulting from the ability to use pseudonymous identities may manifest in the form of offensive speech, consequently making political discussions more aggressive and polarizing than they already are. Such environments may result in harassment and self-censorship from its targets. In this paper, we present preliminary results from a large-scale temporal measurement aimed at quantifying offensiveness in online political discussions. To enable our measurements, we develop and evaluate an offensive speech classifier. We then use this classifier to quantify and compare offensiveness in the political and general contexts. We perform our study using a database of over 168M Reddit comments made by over 7M pseudonyms between January 2015 and January 2017 – a period covering several divisive political events including the 2016 US presidential elections.",
            "output": [
                "Measuring Offensive Speech in Online Political Discourse"
            ]
        },
        {
            "id": "task1540-2255609d69ba4ec1ab330fbe822f58c7",
            "input": "The understanding of the buildings operation has become a challenging task due to the large amount of data recorded in energy efficient buildings. Still, today the experts use visual tools for analyzing the data. In order to make the task realistic, a method has been proposed in this paper to automatically detect the different patterns in buildings. The K-Means clustering is used to automatically identify the ON (operational) cycles of the chiller. In the next step the ON cycles are transformed to symbolic representation by using Symbolic Aggregate Approximation (SAX) method. Then the SAX symbols are converted to bag of words representation for hierarchical clustering. Moreover, the proposed technique is applied to real life data of adsorption chiller. Additionally, the results from the proposed method and dynamic time warping (DTW) approach are also discussed and compared. Keywords— Building energy performance; Fault detection and diagnosis (FDD); clustering; symbolic aggregate approximation (SAX); Bag of words representation (BoWR); hierarchical clustering; Dynamic time warping (DTW); Coefficient of Performance (COP)",
            "output": [
                "Finding the different patterns in buildings data using bag of words representation with clustering"
            ]
        },
        {
            "id": "task1540-82f28f45e8594c379420ba4a8898ade5",
            "input": "Distributed knowledge based applications in open domain rely on common sense infor­ mation which is bound to be uncertain and incomplete. To draw the useful conclusions from ambiguous data, one must address un­ certainties and conflicts incurred in a holis­ tic view. No integrated frameworks are vi­ able without an in-depth analysis of con­ flicts incurred by uncertainties. In this pa­ per, we give such an analysis and based on the result, propose an integrated framework. Our framework extends definite argumenta­ tion theory to model uncertainty. It sup­ ports three views over conflicting and uncer­ tain knowledge. Thus, knowledge engineers can draw different conclusions depending on the application context (i.e. view). We also give an illustrative example on strategical de­ cision support to show the practical useful­ ness of our framework.",
            "output": [
                "Resolving Conflicting Arguments under Uncertainties"
            ]
        },
        {
            "id": "task1540-81221bfaebd44ba0896357489fe3d5db",
            "input": "Lipreading is the task of decoding text from the movement of a speaker’s mouth. Traditional approaches separated the problem into two stages: designing or learning visual features, and prediction. More recent deep lipreading approaches are end-to-end trainable (Wand et al., 2016; Chung & Zisserman, 2016a). However, existing work on models trained end-to-end perform only word classification, rather than sentence-level sequence prediction. Studies have shown that human lipreading performance increases for longer words (Easton & Basala, 1982), indicating the importance of features capturing temporal context in an ambiguous communication channel. Motivated by this observation, we present LipNet, a model that maps a variable-length sequence of video frames to text, making use of spatiotemporal convolutions, a recurrent network, and the connectionist temporal classification loss, trained entirely end-to-end. To the best of our knowledge, LipNet is the first end-to-end sentence-level lipreading model that simultaneously learns spatiotemporal visual features and a sequence model. On the GRID corpus, LipNet achieves 95.2% accuracy in sentence-level, overlapped speaker split task, outperforming experienced human lipreaders and the previous 86.4% word-level state-of-the-art accuracy (Gergen et al., 2016).",
            "output": [
                "LIPNET: END-TO-END SENTENCE-LEVEL LIPREADING"
            ]
        },
        {
            "id": "task1540-d3ca4ebce9d349efb2bf734c148438c1",
            "input": "Under normality and homoscedasticity assumptions, Linear Discriminant Analysis (LDA) is known to be optimal in terms of minimising the Bayes error for binary classification. In the heteroscedastic case, LDA is not guaranteed to minimise this error. Assuming heteroscedasticity, we derive a linear classifier, the Gaussian Linear Discriminant (GLD), that directly minimises the Bayes error for binary classification. In addition, we also propose a local neighbourhood search (LNS) algorithm to obtain a more robust classifier if the data is known to have a non-normal distribution. We evaluate the proposed classifiers on two artificial and ten real-world datasets that cut across a wide range of application areas including handwriting recognition, medical diagnosis and remote sensing, and then compare our algorithm against existing LDA approaches and other linear classifiers. The GLD is shown to outperform the original LDA procedure in terms of the classification accuracy under heteroscedasticity. While it compares favourably with other existing heteroscedastic LDA approaches, the GLD requires as much as 60 times lower training time on some datasets. Our comparison with the support vector machine (SVM) also shows that, the GLD, together with the LNS, requires as much as 150 times lower training time to achieve an equivalent classification accuracy on some of the datasets. Thus, our algorithms can provide a cheap and reliable option for classification in a lot of expert systems.",
            "output": [
                "Linear classifier design under heteroscedasticity in Linear Discriminant Analysis"
            ]
        },
        {
            "id": "task1540-48dcee66c0eb4340acd98f5047fc3140",
            "input": "Motivated by runtime verification of QoS requirements in self-adaptive and self-organizing systems that are able to reconfigure their structure and behavior in response to runtime data, we propose a QoS-aware variant of Thompson sampling for multi-armed bandits. It is applicable in settings where QoS satisfaction of an arm has to be ensured with high confidence efficiently, rather than finding the optimal arm while minimizing regret. Preliminary experimental results encourage further research in the field of QoS-aware decision making.",
            "output": [
                "QoS-Aware Multi-Armed Bandits"
            ]
        },
        {
            "id": "task1540-bcf9f18bbce54d21ba67e8a337301563",
            "input": "Behavior Trees are commonly used to model agents for robotics and games, where constrained behaviors must be designed by human experts in order to guarantee that these agents will execute a specific chain of actions given a specific set of perceptions. In such application areas, learning is a desirable feature to provide agents with the ability to adapt and improve interactions with humans and environment, but often discarded due to its unreliability. In this paper, we propose a framework that uses Reinforcement Learning nodes as part of Behavior Trees to address the problem of adding learning capabilities in constrained agents. We show how this framework relates to Options in Hierarchical Reinforcement Learning, ensuring convergence of nested learning nodes, and we empirically show that the learning nodes do not affect the execution of other nodes in the tree.",
            "output": [
                "A Framework for Constrained and Adaptive Behavior-Based Agents"
            ]
        },
        {
            "id": "task1540-433867d62b23447c8b3a1fdab91a6ce7",
            "input": "Recently there has been an increasing trend to use deep learning frameworks for both 2D consumer images and for 3D medical images. However, there has been little effort to use deep frameworks for volumetric vascular segmentation. We wanted to address this by providing a freely available dataset of 12 annotated two-photon vasculature microscopy stacks. We demonstrated the use of deep learning framework consisting both 2D and 3D convolutional filters (ConvNet). Our hybrid 2D-3D architecture produced promising segmentation result. We derived the architectures from Lee et al. who used the ZNN framework initially designed for electron microscope image segmentation. We hope that by sharing our volumetric vasculature datasets, we will inspire other researchers to experiment with vasculature dataset and improve the used network architectures.",
            "output": [
                "Deep Learning Convolutional Networks for Multiphoton Microscopy Vasculature Segmentation"
            ]
        },
        {
            "id": "task1540-be2406a421eb49c0825c50e2121627aa",
            "input": "Second-order optimization methods such as natural gradient descent have the potential to speed up training of neural networks by correcting for the curvature of the loss function. Unfortunately, the exact natural gradient is impractical to compute for large models, and most approximations either require an expensive iterative procedure or make crude approximations to the curvature. We present Kronecker Factors for Convolution (KFC), a tractable approximation to the Fisher matrix for convolutional networks based on a structured probabilistic model for the distribution over backpropagated derivatives. Similarly to the recently proposed Kronecker-Factored Approximate Curvature (K-FAC), each block of the approximate Fisher matrix decomposes as the Kronecker product of small matrices, allowing for efficient inversion. KFC captures important curvature information while still yielding comparably efficient updates to stochastic gradient descent (SGD). We show that the updates are invariant to commonly used reparameterizations, such as centering of the activations. In our experiments, approximate natural gradient descent with KFC was able to train convolutional networks several times faster than carefully tuned SGD. Furthermore, it was able to train the networks in 10-20 times fewer iterations than SGD, suggesting its potential applicability in a distributed setting.",
            "output": [
                "A Kronecker-factored approximate Fisher matrix for convolution layers"
            ]
        },
        {
            "id": "task1540-b1e4855d38ca4c0f9e65c9aaa1d52ae2",
            "input": "Recurrent neural networks scale poorly due to the intrinsic difficulty in parallelizing their state computations. For instance, the forward pass computation of ht is blocked until the entire computation of ht−1 finishes, which is a major bottleneck for parallel computing. In this work, we propose an alternative RNN implementation by deliberately simplifying the state computation and exposing more parallelism. The proposed recurrent unit operates as fast as a convolutional layer and 5-10x faster than cuDNN-optimized LSTM. We demonstrate the unit’s effectiveness across a wide range of applications including classification, question answering, language modeling, translation and speech recognition. We open source our implementation in PyTorch and CNTK1.",
            "output": [
                "Training RNNs as Fast as CNNs"
            ]
        },
        {
            "id": "task1540-4c477ed025f04c3b89683cec4dca0d45",
            "input": "String Kernel (SK) techniques, especially those using gapped k-mers as features (gk), have obtained great success in classifying sequences like DNA, protein, and text. However, the state-of-the-art gk-SK runs extremely slow when we increase the dictionary size (⌃) or allow more number of mismatches (M). This is because current gk-SK uses a trie-based algorithm to calculate co-occurrence of mismatched substrings resulting in a time cost proportional to O(⌃ ). We propose a fast algorithm for calculating Gapped k-mer Kernel using Counting (GaKCo). GaKCo uses associative arrays to calculate the co-occurrence of substrings using cumulative counting. This algorithm is fast, scalable to larger ⌃ and M , and naturally parallelizable. We provide a rigorous asymptotic analysis that compares GaKCo with the state-of-the-art gk-SK. Theoretically, the time cost of GaKCo is independent of the ⌃ term that slows down the trie-based approach. Experimentally, we observe that GaKCo achieves the same accuracy as the state-of-the-art and outperforms its speed by factors of 2, 100, and 4, on classifying sequences of DNA (5 datasets), protein (12 datasets), and character-based English text (2 datasets), respectively .",
            "output": [
                "GaKCo: a Fast Gapped k-mer string Kernel using Counting"
            ]
        },
        {
            "id": "task1540-f84c33f74e89458988f8aadca198757c",
            "input": "Model generation is a problem complementary to theorem proving and is important for fault analysis and debugging of formal specifications of, for example, security protocols, programs and terminological definitions. This paper discusses several ways of enhancing the paradigm of bottom-up model generation. The two main contributions are new, generalized blocking techniques and a new range-restriction transformation. The blocking techniques are based on simple transformations of the input set together with standard equality reasoning and redundancy elimination techniques. These provide general methods for finding small, finite models. The range-restriction transformation refines existing transformations to range-restricted clauses by carefully limiting the creation of domain terms. All possible combinations of the introduced techniques and a classical range-restriction technique were tested on the clausal problems of the TPTP Version 6.0.0 with an implementation based on the SPASS theorem prover using a hyperresolution-like refinement. Unrestricted domain blocking gave best results for satisfiable problems showing it is a powerful technique indispensable for bottom-up model generation methods. Both in combination with the new range-restricting transformation, and the classical range-restricting transformation, good results have been obtained. Limiting the creation of terms during the inference process by using the new range restricting transformation has paid off, especially when using it together with a shifting transformation. The experimental results also show that classical range restriction with unrestricted blocking provides a useful complementary method. Overall, the results showed bottom-up model generation methods were good for disproving theorems and generating models for satisfiable problems, but less efficient than SPASS in auto mode for unsatisfiable problems.",
            "output": [
                "Blocking and Other Enhancements for Bottom-Up Model Generation Methods"
            ]
        },
        {
            "id": "task1540-47ff39b65f0f425cb2c8c1e7c7dcec28",
            "input": "The reading comprehension task, that asks questions about a given evidence document, is a central problem in natural language understanding. Recent formulations of this task have typically focused on answer selection from a set of candidates pre-defined manually or through the use of an external NLP pipeline. However, Rajpurkar et al. (2016) recently released the SQUAD dataset in which the answers can be arbitrary strings from the supplied text. In this paper, we focus on this answer extraction task, presenting a novel model architecture that efficiently builds fixed length representations of all spans in the evidence document with a recurrent network. We show that scoring explicit span representations significantly improves performance over other approaches that factor the prediction into separate predictions about words or start and end markers. Our approach improves upon the best published results of Wang & Jiang (2016) by 5% and decreases the error of Rajpurkar et al.’s baseline by > 50%.",
            "output": [
                "EXTRACTIVE QUESTION ANSWERING"
            ]
        },
        {
            "id": "task1540-a65ff3a91a354c3cb005d74eee6eb920",
            "input": "Objective: Allowing patients to access their own electronic health record (EHR) notes through online patient portals has the potential to improve patient-centered care. However, medical jargon, which abounds in EHR notes, has been shown to be a barrier for patient EHR comprehension. Existing knowledge bases that link medical jargon to lay terms or definitions play an important role in alleviating this problem but have low coverage of medical jargon in EHRs. We developed a data-driven approach that mines EHRs to identify and rank medical jargon based on its importance to patients, to support the building of EHR-centric lay language resources. Methods: We developed an innovative adapted distant supervision (ADS) model based on support vector machines to rank medical jargon from EHRs. For distant supervision, we utilized the open-access, collaborative consumer health vocabulary, a large, publicly available resource that links lay terms to medical jargon. We explored both knowledge-based features from the Unified Medical Language System and distributed word representations (word embeddings) learned from unlabeled large corpora. We evaluated the ADS model using physician-identified important medical terms. Results: Our ADS model significantly surpassed two state-of-the-art automatic term recognition methods, TF*IDF and C-Value, yielding 0.810 ROC-AUC versus 0.710 and 0.667, respectively. Our model identified over 10K important medical jargon terms after ranking over 100K candidate terms mined from over 7,500 EHR narratives. Conclusion: Our work is an important step towards enriching lexical resources that link medical jargon to lay terms/definitions to support patient EHR comprehension. The identified medical jargon terms and their rankings are available upon request.",
            "output": [
                "Ranking medical jargon in electronic health record notes by adapted distant supervision"
            ]
        },
        {
            "id": "task1540-b896ca22f8814cf892af3fed55f61f1b",
            "input": "An efficient speech to text converter for mobile application is presented in this work. The prime motive is to formulate a system which would give optimum performance in terms of complexity, accuracy, delay and memory requirements for mobile environment. The speech to text converter consists of two stages namely front-end analysis and pattern recognition. The front end analysis involves preprocessing and feature extraction. The traditional voice activity detection algorithms which track only energy cannot successfully identify potential speech from input because the unwanted part of the speech also has some energy and appears to be speech. In the proposed system , VAD that calculates energy of high frequency part separately as zero crossing rate to differentiate noise from speech is used. Mel Frequency Cepstral Coefficient (MFCC) is used as feature extraction method and Generalized Regression Neural Network is used as recognizer. MFCC provides low word error rate and better feature extraction. Neural Network improves the accuracy. Thus a small database containing all possible syllable pronunciation of the user is sufficient to give recognition accuracy closer to 100%. Thus the proposed technique entertains realization of real time speaker independent applications like mobile phones, PDAs etc.",
            "output": [
                "Speaker Independent Continuous Speech to Text Converter for Mobile Application"
            ]
        },
        {
            "id": "task1540-8427f65efb754b35aea850ccd2e43f73",
            "input": "We propose an information theoretic framework for quantitative assessment of acoustic modeling for hidden Markov model (HMM) based automatic speech recognition (ASR). Acoustic modeling yields the probabilities of HMM sub-word states for a short temporal window of speech acoustic features. We cast ASR as a communication channel where the input sub-word probabilities convey the information about the output HMM state sequence. The quality of the acoustic model is thus quantified in terms of the information transmitted through this channel. The process of inferring the most likely HMM state sequence from the sub-word probabilities is known as decoding. HMM based decoding assumes that an acoustic model yields accurate state-level probabilities and the data distribution given the underlying hidden state is independent of any other state in the sequence. We quantify 1) the acoustic model accuracy and 2) its robustness to mismatch between data and the HMM conditional independence assumption in terms of some mutual information quantities. In this context, exploiting deep neural network (DNN) posterior probabilities leads to a simple and straightforward analysis framework to assess shortcomings of the acoustic model for HMM based decoding. This analysis enables us to evaluate the Gaussian mixture acoustic model (GMM) and the importance of many hidden layers in DNNs without any need of explicit speech recognition. In addition, it sheds light on the contribution of low-dimensional models to enhance acoustic modeling for better compliance with the HMM based decoding requirements.",
            "output": [
                "Information Theoretic Analysis of DNN-HMM Acoustic Modeling"
            ]
        },
        {
            "id": "task1540-04c421f0491142ee9c84cba101ef415a",
            "input": "Machine Learning (ML) has found it particularly useful in malware detection. However, as the malware evolves very fast, the stability of the feature extracted from malware serves as a critical issue in malware detection. The recent success of deep learning in image recognition, natural language processing, and machine translation indicates a potential solution for stabilizing the malware detection effectiveness. In this research, we haven’t extract selected any features (e.g., the control-flow of op-code, classes, methods of functions and the timing they are invoked etc.) from Android apps. We develop our own method for translating Android apps into rgb color code and transform them to a fixed-sized encoded image. After that, the encoded image is fed to convolutional neural network (CNN) for automatic feature extraction and learning, reducing the expert’s intervention. Deep learning usually involves a large number of parameters that cannot be learned from only a small dataset. In this way, we currently have collected 1500k Android apps samples, have run our system over these 800k malware samples (benign and malicious samples are roughly equal-sized), and also through our back-end (60 million monthly active users and 10k new malware samples per day), we can effectively detect the malware. We believe that our methodology and the corresponding use of deep learning malware classification can overcome the weakness, and computational cost of the common static/dynamic analysis process or machine learning-based of Android malware detection approach.",
            "output": [
                "R2-D2: ColoR-inspired Convolutional NeuRal Network (CNN)-based AndroiD Malware Detections"
            ]
        },
        {
            "id": "task1540-bd37e91a3e5a45d69bbeaa889cfbd57d",
            "input": "We consider online content recommendation with implicit feedback through pairwise comparisons, formalized as the so-called dueling bandit problem. We study the dueling bandit problem in the Condorcet winner setting, and consider two notions of regret: the more well-studied strong regret, which is 0 only when both arms pulled are the Condorcet winner; and the less well-studied weak regret, which is 0 if either arm pulled is the Condorcet winner. We propose a new algorithm for this problem, Winner Stays (WS), with variations for each kind of regret: WS for weak regret (WS-W) has expected cumulative weak regret that is O(N), and O(N log(N)) if arms have a total order; WS for strong regret (WS-S) has expected cumulative strong regret of O(N + N log(T )), and O(N log(N) +N log(T )) if arms have a total order. WS-W is the first dueling bandit algorithm with weak regret that is constant in time. WS is simple to compute, even for problems with many arms, and we demonstrate through numerical experiments on simulated and real data that WS has significantly smaller regret than existing algorithms in both the weakand strong-regret settings.",
            "output": [
                "Dueling Bandits with Weak Regret"
            ]
        },
        {
            "id": "task1540-c25a489d3b6c45c5b01c3ecf9f4ce666",
            "input": "In this paper we analyse network motifs in the co-occurrence directed networks constructed from five different texts (four books and one portal) in the Croatian language. After preparing the data and network construction, we perform the network motif analysis. We analyse the motif frequencies and Z-scores in the five networks. We present the triad significance profile for five datasets. Furthermore, we compare our results with the existing results for the linguistic networks. Firstly, we show that the triad significance profile for the Croatian language is very similar with the other languages and all the networks belong to the same family of networks. However, there are certain differences between the Croatian language and other analysed languages. We conclude that this is due to the free word-order of the Croatian language.",
            "output": [
                "Network Motifs Analysis of Croatian Literature"
            ]
        },
        {
            "id": "task1540-59afc18ddec74f309c8a4dacb86d0b86",
            "input": "We introduce a batched lazy algorithm for supervised classification using decision trees. It avoids unnecessary visits to irrelevant nodes when it is used to make predictions with either eagerly or lazily trained decision trees. A set of experiments demonstrate that the proposed algorithm can outperform both the conventional and lazy decision tree algorithms in terms of computation time as well as memory consumption, without compromising accuracy.",
            "output": [
                "Batched Lazy Decision Trees"
            ]
        },
        {
            "id": "task1540-d697c98c96b941d88dd8af16ba777a99",
            "input": "Hierarchical Reinforcement Learning has been previously shown to speed up the convergence rate of RL planning algorithms as well as mitigate feature-based model misspecification Mankowitz et al. (2016a,b); Bacon & Precup (2015). To do so, it utilizes hierarchical abstractions, also known as skills – a type of temporally extended action Sutton et al. (1999) to plan at a higher level, abstracting away from the lower-level details. We incorporate risk sensitivity, also referred to as Situational Awareness (SA) , into hierarchical RL for the first time by defining and learning risk aware skills in a Probabilistic Goal Semi-Markov Decision Process (PG-SMDP). This is achieved using our novel Situational Awareness by Risk-Conscious Skills (SARiCoS) algorithm which comes with a theoretical convergence guarantee. We show in a RoboCup soccer domain that the learned risk aware skills exhibit complex human behaviors such as ‘time-wasting’ in a soccer game. In addition, the learned risk aware skills are able to mitigate reward-based model misspecification.",
            "output": [
                "Situational Awareness by Risk-Conscious Skills"
            ]
        },
        {
            "id": "task1540-787df44c711b45719d66bb6e0eb1c38a",
            "input": "Reasoning does not work well when done in isolation from its significance, both to the needs and interests of an agent and with respect to the wider world. Moreover, those issues may best be handled with a new sort of data structure that goes beyond the knowledge base and incorporates aspects of perceptual knowledge and even more, in which a kind of anticipatory action may be key. Out of the Ivory Tower Reasoning is one of the oldest topics in artificial intelligence (AI). And it has made lots of progress, in the form of commonsense reasoning (CSR), planning, automated theorem-proving, and more. But I suspect it has hit a barrier that must be surmounted if we are to approach anything like human-level inference. Here I give evidence for such a barrier, and ideas about dealing with it, loosely based on evidence from human behavior. In rough synopsis, reasoning does not work well when done in isolation from its broader significance, both for the needs and interests of an agent and for the wider world. Moreover, those issues may best be handled with a new sort of data structure that goes beyond the knowledge base (KB) and incorporates aspects of perceptual knowledge and even more, in which a kind of anticipatory action many be key. I suspect this has ties with recent calls to “put the Science” back in AI (Levesque 2013, Langley 2012). For what I am arguing, in some sense, is that reasoning should be regarded as “in the wild” as events unfold rather than confined to management of an isolated KB; and that this speaks to an agent interacting with the world, rather than a puzzle in abstract inference (yet I will also argue that even “pure” reasoning as in mathematics hugely benefits from many connections with the world). And finally, we then will end up studying the nature of world-embedded cognitive agents, humans included. But this is very broadbrushed and general, whereas my main point is a technical suggestion about reasoning informed by meaning, especially meaning concerning experience and action. This is a slightly modified version of a paper that appeared in AAAI2016. One quick example at the outset: The Wason Selection Task (Wason 1968) shows that human inference is strongly aided when the details of the task at hand have real meaning that the subjects can relate to in terms of things that matter to them, helping keep attention on what is relevant; and this holds even when the task in the abstract is a matter of so-called pure logic. While this could be seen as a defect in human reasoning, something computers would never trip up on, I think it points in the opposite direction: inference without broader meaning is not worth much, and not worth being good at. I will illustrate my main points with a series of examples based on the activities of proving, planning, and understanding.",
            "output": [
                "Five Dimensions of Reasoning in the Wild"
            ]
        },
        {
            "id": "task1540-02314a75792448b4acc2419bf1e052ce",
            "input": "Relation extraction is a fundamental task in information extraction. Most existing methods have heavy reliance on annotations labeled by human experts, which are costly and time-consuming. To overcome this drawback, we propose a novel framework, REHESSION, to conduct relation extractor learning using annotations from heterogeneous information source, e.g., knowledge base and domain heuristics. These annotations, referred as heterogeneous supervision, often conflict with each other, which brings a new challenge to the original relation extraction task: how to infer the true label from noisy labels for a given instance. Identifying context information as the backbone of both relation extraction and true label discovery, we adopt embedding techniques to learn the distributed representations of context, which bridges all components with mutual enhancement in an iterative fashion. Extensive experimental results demonstrate the superiority of REHESSION over the state-of-the-art.",
            "output": [
                "Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach"
            ]
        },
        {
            "id": "task1540-06aeaefecf8e4f92bd10d13a188ee58a",
            "input": "Conditional independence and Markov prop­ erties are powerful tools allowing expression of multidimensional probability distributions by means of low-dimensional ones. As mul­ tidimensional possibilistic models have been studied for several years, the demand for analogous tools in possibility theory seems to be quite natural. This paper is intended to be a promotion of de Cooman's measure­ theoretic approach to possibility theory, as this approach allows us to find analogies to many important results obtained in prob­ abilistic framework. First we recall semi­ graphoid properties of conditional possibilis­ tic independence, parameterized by a contin­ uous t-norm, and find sufficient conditions for a class of Archimedean t-norms to have the graphoid property. Then we introduce Markov properties and factorization of possi­ bility distributions (again parameterized by a continuous t-norm) and find the relation­ ships between them. These results are ac­ companied by a number of counterexamples, which show that the assumptions of specific theorems are substantial.",
            "output": [
                "Conditional Independence and Markov Properties in Possibility Theory"
            ]
        },
        {
            "id": "task1540-b3037a520b164227ac2dc358246e8a72",
            "input": "In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.",
            "output": [
                "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"
            ]
        },
        {
            "id": "task1540-3d98e7f64c6240db8b08bae81083f58d",
            "input": "The preimage of the activities of all the nodes at a certain level of a deep network is the set of inputs that result in the same node activity. For fully connected multi layer rectifier networks we demonstrate how to compute the preimages of activities at arbitrary levels from knowledge of the parameters in a deep rectifying network by disregarding the effects of max-pooling. If the preimage set of a certain activity in the network contains elements from more than one class it means that these classes are irreversibly mixed. This implies that preimage sets which are piecewise linear manifolds are building blocks for describing the input manifolds specific classes, i.e. all preimages should ideally be from the same class. We believe that the knowledge of how to compute preimages will be valuable in understanding the efficiency displayed by deep learning networks and could potentially be used in designing more efficient training algorithms",
            "output": [
                "THE PREIMAGE OF RECTIFIER NETWORK ACTIVITIES"
            ]
        },
        {
            "id": "task1540-43207c34415f40d3ad2e0a5aa65d4636",
            "input": "Driven by the multi-level structure of human intracranial electroencephalogram (iEEG) recordings of epileptic seizures, we introduce a new variant of a hierarchical Dirichlet Process—the multi-level clustering hierarchical Dirichlet Process (MLC-HDP)—that simultaneously clusters datasets on multiple levels. Our seizure dataset contains brain activity recorded in typically more than a hundred individual channels for each seizure of each patient. The MLC-HDP model clusters over channels-types, seizure-types, and patient-types simultaneously. We describe this model and its implementation in detail. We also present the results of a simulation study comparing the MLC-HDP to a similar model, the Nested Dirichlet Process and finally demonstrate the MLC-HDP’s use in modeling seizures across multiple patients. We find the MLC-HDP’s clustering to be comparable to independent human physician clusterings. To our knowledge, the MLCHDP model is the first in the epilepsy literature capable of clustering seizures within and between patients.",
            "output": [
                "A Hierarchical Dirichlet Process Model with Multiple Levels of Clustering for Human EEG Seizure Modeling"
            ]
        },
        {
            "id": "task1540-d335c227797e452d8efa88899e39f8b6",
            "input": "Local search methods can quickly find good quality solutions in cases where systematic search methods might take a large amount of time. Moreover, in the context of pattern set mining, exhaustive search methods are not applicable due to the large search space they have to explore. In this paper, we propose the application of stochastic local search to solve the pattern set mining. Specifically, to the task of concept learning. We applied a number of local search algorithms on a standard benchmark instances for pattern set mining and the results show the potentials for further exploration.",
            "output": [
                "Stochastic Local Search for Pattern Set Mining"
            ]
        },
        {
            "id": "task1540-8b10d3edae9a446b8b7263b7aaad1aba",
            "input": "We present a new system S for handling uncertainty in a quantified modal logic (first-order modal logic). The system is based on both probability theory and proof theory. The system is derived from Chisholm’s epistemology. We concretize Chisholm’s system by grounding his undefined and primitive (i.e. foundational) concept of reasonableness in probability and proof theory. S can be useful in systems that have to interact with humans and provide justifications for their uncertainty. As a demonstration of the system, we apply the system to provide a solution to the lottery paradox. Another advantage of the system is that it can be used to provide uncertainty values for counterfactual statements. Counterfactuals are statements that an agent knows for sure are false. Among other cases, counterfactuals are useful when systems have to explain their actions to users (If I had not done α, then φ would have happened). Uncertainties for counterfactuals fall out naturally from our system. Efficient reasoning in just simple first-order logic is a hard problem. Resolution-based first-order reasoning systems have made significant progress over the last several decades in building systems that have solved non-trivial tasks (even unsolved conjectures in mathematics). We present a sketch of a novel algorithm for reasoning that extends firstorder resolution. Finally, while there have been many systems of uncertainty for propositional logics, first-order logics and propositional modal logics, there has been very little work in building systems of uncertainty for first-order modal logics. The work described below is in progress; and once finished will address this lack.",
            "output": [
                "Strength Factors: An Uncertainty System for a Quantified Modal Logic"
            ]
        },
        {
            "id": "task1540-7db8998d20214a64a11874aeedcce7ad",
            "input": "With the rise of Social Media, people obtain and share information almost instantly on a 24/7 basis. Many research areas have tried to gain valuable insights from these large volumes of freely available user generated content. The research areas of intelligent transportation systems and smart cities are no exception. However, extracting meaningful and actionable knowledge from user generated content is a complex endeavor. First, each social media service has its own data collection specificities and constraints, second the volume of messages/posts produced can be overwhelming for automatic processing and mining, and last but not the least, social media texts are usually short, informal, with a lot of abbreviations, jargon, slang and idioms. In this thesis, we try to tackle some of the aforementioned challenges with the goal of extracting knowledge from social media streams that might be useful in the context of intelligent transportation systems and smart cities. We designed and developed a framework for collection, processing and mining of geo-located Tweets. More specifically, it provides functionalities for parallel collection of geo-located tweets from multiple pre-defined bounding boxes (cities or regions), including filtering of non complying tweets, text pre-processing for Portuguese and English language, topic modeling, and transportation-specific text classifiers, as well as, aggregation and data visualization. We performed an extensive exploratory data analysis of geo-located tweets in 5 different cities: Rio de Janeiro, São Paulo, New York City, London and Melbourne, comprising a total of more than 43 millions tweets in a period of 3 months. Furthermore, we performed a large scale topic modelling comparison between Rio de Janeiro and São Paulo. As far as we know this is the largest scale content analysis of geo-located tweets from Brazil. Interestingly, most of the topics are shared between both cities which despite being in the same country are considered very different regarding population, economy and lifestyle. We take advantage of recent developments in word embeddings and train such representations from the collections of geo-located tweets. We then use a combination of bag-of-embeddings and traditional bag-of-words to train travel-related classifiers in both Portuguese and English to filter travel-related content from non-related. We created specific gold-standard data to perform empirical evaluation of the resulting classifiers. Results are in line with research work in other application areas by showing the robustness of using word embeddings to learn word similarities that bag-of-words is not able to capture. The source code and resources developed in this dissertation will be publicly available to foster further developments by the research community in smart cities and intelligent transportation systems.",
            "output": [
                "Social Media Text Processing and Semantic Analysis for Smart Cities"
            ]
        },
        {
            "id": "task1540-a527436c50b341d596651672b7ea84fd",
            "input": "Named Entity Recognition (NER) is a key NLP task, which is all the more chal-<lb>lenging on Web and user-generated content with their diverse and continuously<lb>changing language. This paper aims to quantify how this diversity impacts<lb>state-of-the-art NER methods, by measuring named entity (NE) and context<lb>variability, feature sparsity, and their effects on precision and recall. In particu-<lb>lar, our findings indicate that NER approaches struggle to generalise in diverse<lb>genres with limited training data. Unseen NEs, in particular, play an impor-<lb>tant role, which have a higher incidence in diverse genres such as social media<lb>than in more regular genres such as newswire. Coupled with a higher incidence<lb>of unseen features more generally and the lack of large training corpora, this<lb>leads to significantly lower F1 scores for diverse genres as compared to more<lb>regular ones. We also find that leading systems rely heavily on surface forms<lb>found in training data, having problems generalising beyond these, and offer<lb>explanations for this observation.",
            "output": [
                "Generalisation in Named Entity Recognition: A Quantitative Analysis"
            ]
        },
        {
            "id": "task1540-a7f44d7b7a5445d08e7b7696c4720fc4",
            "input": "Passengers’ experience is becoming a key metric to evaluate the air transportation system’s performance. Efficient and robust tools to handle airport operations are needed along with a better understanding of passengers’ interests and concerns. Among various airport operations, this paper studies airport gate scheduling for improved passengers’ experience. Three objectives accounting for passengers, aircraft, and operation are presented. Trade-offs between these objectives are analyzed, and a balancing objective function is proposed. The results show that the balanced objective can improve the efficiency of traffic flow in passenger terminals and on ramps, as well as the robustness of gate operations.",
            "output": [
                "Airport Gate Scheduling for Passengers, Aircraft, and Operation"
            ]
        },
        {
            "id": "task1540-934f37a104e648bda920536e863df053",
            "input": "For mobile telecom operators, it is critical to build preference profiles of their customers and connected users, which can help operators make better marketing strategies, and provide more personalized services. With the deployment of deep packet inspection (DPI) in telecom networks, it is possible for the telco operators to obtain user online preference. However, DPI has its limitations and user preference derived only from DPI faces sparsity and cold start problems. To better infer the user preference, social correlation in telco users network derived from Call Detailed Records (CDRs) with regard to online preference is investigated. Though widely verified in several online social networks, social correlation between online preference of users in mobile telco networks, where the CDRs derived relationship are of less social properties and user mobile internet surfing activities are not visible to neighbourhood, has not been explored at a large scale. Based on a real world telecom dataset including CDRs and preference of more than 550K users for several months, we verified that correlation does exist between online preference in such ambiguous social network. Furthermore, we found that the stronger ties that users build, the more similarity between their preference may have. After defining the preference inferring task as a Top-K recommendation problem, we incorporated Matrix Factorization Collaborative Filtering model with social correlation and tie strength based on call patterns to generate Top-K preferred categories for users. The proposed Tie Strength Augmented Social Recommendation (TSASoRec) model takes data sparsity and cold start user problems into Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD ’16 August 13–17, 2016, San Francisco, California, USA c © 2016 ACM. ISBN XXX-X-XXXX-XXXX-X/XX/XX. . . $10.00 DOI: 10.1145/1235 account, considering both the recorded and missing recorded category entries. The experiment on real dataset shows the proposed model can better infer user preference, especially for cold start users.",
            "output": [
                "On Tie Strength Augmented Social Correlation for Inferring Preference of Mobile Telco Users"
            ]
        },
        {
            "id": "task1540-d90deef2bf014cc5ab3e76390a709f75",
            "input": "This paper demonstrates a data-driven control approach for demand response in real-life residential buildings. The objective is to optimally schedule the heating cycles of the Domestic Hot Water (DHW) buffer to maximize the selfconsumption of the local photovoltaic (PV) production. A modelbased reinforcement learning technique is used to tackle the underlying sequential decision-making problem. The proposed algorithm learns the stochastic occupant behavior, predicts the PV production and takes into account the dynamics of the system. A real-life experiment with six residential buildings is performed using this algorithm. The results show that the self-consumption of the PV production is significantly increased, compared to the default thermostat control. Reinforcement Learning, Demand Response, Domestic Hot Water, Field Experiment March 1, 2017",
            "output": [
                "Using Reinforcement Learning for Demand Response of Domestic Hot Water Buffers: a Real-Life Demonstration"
            ]
        },
        {
            "id": "task1540-9a3498a7ed98480db45fa005c68b3e57",
            "input": "We study the power of different types of adaptive (nonoblivious) adversaries in the setting of prediction with expert advice, under both full-information and bandit feedback. We measure the player’s performance using a new notion of regret, also known as policy regret, which better captures the adversary’s adaptiveness to the player’s behavior. In a setting where losses are allowed to drift, we characterize —in a nearly complete manner— the power of adaptive adversaries with bounded memories and switching costs. In particular, we show that with switching costs, the attainable rate with bandit feedback is Θ̃(T ). Interestingly, this rate is significantly worse than the Θ( √ T ) rate attainable with switching costs in the full-information case. Via a novel reduction from experts to bandits, we also show that a bounded memory adversary can force Θ̃(T ) regret even in the full information case, proving that switching costs are easier to control than bounded memory adversaries. Our lower bounds rely on a new stochastic adversary strategy that generates loss processes with strong dependencies.",
            "output": [
                "Online Learning with Switching Costs and Other Adaptive Adversaries"
            ]
        },
        {
            "id": "task1540-2a3830a1ca7e49bb92cf78add39d0c38",
            "input": "The practicality of a video surveillance system is adversely limited by the amount of queries that can be placed on human resources and their vigilance in response. To transcend this limitation, a major effort under way is to include software that (fully or at least semi) automatically mines video footage, reducing the burden imposed to the system. Herein, we propose a semi-supervised incremental learning framework for evolving visual streams in order to develop a robust and flexible track classification system. Our proposed method learns from consecutive batches by updating an ensemble in each time. It tries to strike a balance between performance of the system and amount of data which needs to be labelled. As no restriction is considered, the system can address many practical problems in an evolving multi-camera scenario, such as concept drift, class evolution and various length of video streams which have not been addressed before. Experiments were performed on synthetic as well as real-world visual data in non-stationary environments, showing high accuracy with fairly little human collaboration.",
            "output": [
                "Active Mining of Parallel Video Streams"
            ]
        },
        {
            "id": "task1540-da0c02fa3eb444b19448066dfd331483",
            "input": "This paper addresses the task of AMR-totext generation by leveraging synchronous node replacement grammar. During training, graph-to-string rules are learned using a heuristic extraction algorithm. At test time, a graph transducer is applied to collapse input AMRs and generate output sentences. Evaluated on SemEval-2016 Task 8, our method gives a BLEU score of 25.62, which is the best reported so far.",
            "output": [
                "AMR-to-text Generation with Synchronous Node Replacement Grammar"
            ]
        },
        {
            "id": "task1540-68776346b0174350941f6e4dd849c5c1",
            "input": "The relationship between belief networks and relational databases is examined. Based on this analysis, a method to construct belief networks automatically from statistical rela­ tional data is proposed. A comparison be­ tween our method and other methods shows that our method has several advantages when generalization or prediction is deeded.",
            "output": [
                "From Relational Databases to Belief Networks"
            ]
        },
        {
            "id": "task1540-72580d448f3b4de5beea5e365b71eea1",
            "input": "Recently emerged intelligent assistants on smartphones and home electronics (e.g., Siri and Alexa) can be seen as novel hybrids of domain-specific taskoriented spoken dialogue systems and open-domain non-task-oriented ones. To realize such hybrid dialogue systems, this paper investigates determining whether or not a user is going to have a chat with the system. To address the lack of benchmark datasets for this task, we construct a new dataset consisting of 15, 160 utterances collected from the real log data of a commercial intelligent assistant (and will release the dataset to facilitate future research activity). In addition, we investigate using tweets and Web search queries for handling open-domain user utterances, which characterize the task of chat detection. Experiments demonstrated that, while simple supervised methods are effective, the use of the tweets and search queries further improves the F1-score from 86.21 to 87.53.",
            "output": [
                "Chat Detection in an Intelligent Assistant: Combining Task-oriented and Non-task-oriented Spoken Dialogue Systems"
            ]
        },
        {
            "id": "task1540-b7b491c6027f489a980427cfffdcdc94",
            "input": "In this paper, we consider several types of in­ formation and methods of combination asso­ ciated with incomplete probabilistic systems. \\Ve discriminate between 'a priori' and evi­ dential information. The former one is a de­ scription of the whole population, the latest is a restriction based on observations for a particular case. Then, we proposse different combination methods for each one of them. 'We also consider conditioning as the hetero­ geneous combination of 'a priori' and eviden­ tial information. The evidential information is represented as a convex set of likelihood func­ tions. These will have an associated possi­ bility distribution with behavior according to classical Possibility Theory.",
            "output": [
                "COMBINATION OF UPPER AND LOWER PROBABILITIES"
            ]
        },
        {
            "id": "task1540-43bd4fbe2d314f98801214954ab8c6cc",
            "input": "We describe an adaptation and application of a search-based structured prediction algorithm “Searn” to unsupervised learning problems. We show that it is possible to reduce unsupervised learning to supervised learning and demonstrate a high-quality unsupervised shift-reduce parsing model. We additionally show a close connection between unsupervised Searn and expectation maximization. Finally, we demonstrate the efficacy of a semi-supervised extension. The key idea that enables this is an application of the predict-self idea for unsupervised learning.",
            "output": [
                "Unsupervised Search-based Structured Prediction"
            ]
        },
        {
            "id": "task1540-9308994878424d1c8077afeeea4fff56",
            "input": "As an emerging research topic, online class imbalance learning often combines the challenges of both class imbalance and concept drift. It deals with data streams having very skewed class distributions, where concept drift may occur. It has recently received increased research attention; however, very little work addresses the combined problem where both class imbalance and concept drift coexist. As the first systematic study of handling concept drift in class-imbalanced data streams, this paper first provides a comprehensive review of current research progress in this field, including current research focuses and open challenges. Then, an in-depth experimental study is performed, with the goal of understanding how to best overcome concept drift in online learning with class imbalance. Based on the analysis, a general guideline is proposed for the development of an effective algorithm.",
            "output": [
                "A Systematic Study of Online Class Imbalance Learning with Concept Drift"
            ]
        },
        {
            "id": "task1540-e3ce8cfdf9b447bf873a2d086e89d453",
            "input": "Clustering large datasets is a fundamental problem with a number of applications in machine learning. Data is often collected on different sites and clustering needs to be performed in a distributed manner with low communication. We would like the quality of the clustering in the distributed setting to match that in the centralized setting for which all the data resides on a single site. In this work, we study both graph and geometric clustering problems in two distributed models: (1) a point-to-point model, and (2) a model with a broadcast channel. We give protocols in both models which we show are nearly optimal by proving almost matching communication lower bounds. Our work highlights the surprising power of a broadcast channel for clustering problems; roughly speaking, to spectrally cluster n points or n vertices in a graph distributed across s servers, for a worst-case partitioning the communication complexity in a point-to-point model is n · s, while in the broadcast model it is n + s. A similar phenomenon holds for the geometric setting as well. We implement our algorithms and demonstrate this phenomenon on real life datasets, showing that our algorithms are also very efficient in practice. ∗A preliminary version of this paper appears at the 30th Annual Conference on Neural Information Processing Systems (NIPS), 2016. †Department of Computer Science, Indiana University, Bloomington, USA. Work supported in part by NSF CCF1525024 and IIS-1633215. Email: jiecchen@indiana.edu ‡Department of Computer Science, University of Bristol, Bristol, UK. h.sun@bristol.ac.uk §IBM Research Almaden, San Jose, USA. dpwoodru@us.ibm.com ¶Department of Computer Science, Indiana University, Bloomington, USA. Work supported in part by NSF CCF1525024 and IIS-1633215. Email: qzhangcs@indiana.edu ar X iv :1 70 2. 00 19 6v 1 [ cs .D S] 1 F eb 2 01 7",
            "output": [
                "Communication-Optimal Distributed Clustering∗"
            ]
        },
        {
            "id": "task1540-84a88715c3b642fe971a8a08d620ceae",
            "input": "We present a data-driven method for determining the veracity of a set of rumorous claims on social media data. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for each rumor in terms of the identity of the rumor-resolving tweet and its binary resolution value judgment. The system operates without access to extralinguistic resources. Evaluated on the data portion for which hand-labeled examples were available, it achieves .74 F1-score on identifying rumor resolving tweets and .76 F1-score on predicting if a rumor is resolved as true or false. 1 Background and Task Definition A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious. To compute veracity, systems have been created recently for assessing the credibility of sources and claims (Berti-Équille and Borge-Holthoefer, 2015). Upcoming initiatives endorsed veracity detection in social media content as a shared task, calling for targeted applications and releasing benchmark data1. To tackle this challenge, we implemented a system that seeks to achieve three goals: (i) to compute a judgment indicating how factual a claim is, based on textual cues and predicted speaker certainty, (ii) to identify which tweet is resolving a rumor, in a set of tweets that discuss this rumor, and (iii) to predict the resolution value for the rumor, i.e., whether the rumor is verified as true or false. Veracity computation is based on information from three information layers related to rumorousness: (1) lexical-level factuality cues, (2) temporal patterns, and (3) speaker certainty. The system is purely data-driven and operates without building claim source profiles for the analyzed content. Below we introduce our motivation in the context of previous and related work. The means by which factuality is conveyed are largely but not exclusively encoded on linguistic levels and are tightly related to the notion of certainty. Certainty and other extra-propositional aspects of meaning have prominently been investigated in terms of modality, negation and speculative language phenomena (Morante and Blanco, 2012; Morante and Sporleder, 2012). Benchmark corpora with annotations emerged (Saurı́ and Pustejovsky, 2009; Farkas et al., 2010), and systems have been built (Saurı́ and Pustejovsky, 2012; de Marneffe et al., 2012; Velldal and Read, 2012) to process texts from the genres of literature, newswire, biomedicine and online encyclopedia, typically drawing on lexical and syntactic cues. (Szarvas et al., 2012) propose a method for porting uncertainty detection across genres and domains. (Kilicoglu et al., 2015) present a full-fledged, compositional approach to factuality ∗UDR is supported by an Alexander von Humboldt Society grant. †PL is supported by the PHEME FP7 project (Grant No. 611233). http://alt.qcri.org/semeval2017/task8/ ar X iv :1 61 1. 02 59 0v 1 [ cs .C L ] 8 N ov 2 01 6 modeling and detection on texts from the domain of biomedicine based on fine-grained typology and dictionary-based classification of extra-propositional phenomena. Several components of the model are motivated by the nature of scientific communication that serves to track hypothesis building processes with tentative results, analogously to journalistic reports about breaking news. (Soni et al., 2014) focus on factuality framing in social media data in quoted claims with a small set of cues, whereas (Finn et al., 2014) implement keyword-based negation detection without providing quantitative evaluation. Next to linguistically expressed uncertainty, extralinguistic information such as the temporal distribution of claims is shown to be an important aspect of veracity computation. Previous studies that investigated temporal patterns of linguistic cues tied to claims emerging in real-world events focus on keywords related to sentiment, named entities and domain terms (Temnikova et al., 2014), but not factuality-conveying cues. (Wei et al., 2013) report on the first uncertainty corpus based on tweets, as well as on classification results for uncertain tweets. Next to platform-specific metadata, they utilized cue phrases in annotated uncertain tweets and an algorithm to detect peaks in the data. (Kwon and Cha, 2014) and (Ma et al., 2015) show for rumor detection that accuracy can be improved by not only looking at message-related properties but also at how these properties change over time. (Ma et al., 2015) propose a time series structure for features and their deltas as the input for classification. On the full PHEME dataset, (Lukasik et al., 2016) report on stance detection in the context of temporal dynamics. They utilize textual information via language modeling but do not evaluate the contribution of textual as opposed to other features. On the same dataset, (Zubiaga et al., 2016) analyzed labeled certainty values in dependence of claim resolution, and found that tweeters post messages with statistically similar certainty before and after a claim is resolved, moreover, irrespective of the resolution value. In (Lendvai et al., 2016) we analyzed and validated a subset of the PHEME data on English and German data that temporal distribution and polarity of lexical markers can be used to represent and quantify changes in factuality framing in a rumor’s lifecycle. Our current study furthers this research by incorporating, evaluating, and visualizing temporally anchored features for claim resolution point as well as claim resolution value prediction in English language rumors discussed in potentially noisy, user-generated content. The paper is structured as follows. In Section 2 we introduce the underlying data and certainty annotations, and describe the automatic extension of lexical cues assigned to four levels of factuality. In Section 3 the relation between certainty and each of the factuality levels is assessed, and regression analysis is used for predicting certainty values by cue-type ratios. In Section 4 we quantify trend discontinuities in time series data of lexical cue ratios and predicted certainty scores to describe rumor resolution points. Cue ratios, certainty, as well as their time course characteristics are exploited in Section 5, where we train classifiers to identify claim-resolving tweets within series of tweets spanning a claim’s lifetime, and additionally predict the claim’s resolution value. The findings are discussed in Section 6.",
            "output": [
                "Veracity Computing from Lexical Cues and Perceived Certainty Trends"
            ]
        },
        {
            "id": "task1540-a0d5f5f355174d04b28e58a8965060fb",
            "input": "Logical inference algorithms for conditional independence (CI) statements have important applications from testing consistency during knowledge elicitation to constraintbased structure learning of graphical models. We prove that the implication problem for CI statements is decidable, given that the size of the domains of the random variables is known and fixed. We will present an approximate logical inference algorithm which combines a falsification and a novel validation algorithm. The validation algorithm represents each set of CI statements as a sparse 0-1 matrixA and validates instances of the implication problem by solving specific linear programs with constraint matrix A. We will show experimentally that the algorithm is both effective and efficient in validating and falsifying instances of the probabilistic CI implication problem.",
            "output": [
                "Logical Inference Algorithms and Matrix Representations for Probabilistic Conditional Independence"
            ]
        },
        {
            "id": "task1540-05116b2dda7a49f1bea2efb4c6f20638",
            "input": "In this paper, a framework for testing Deep Neural Network (DNN) design in Python is presented. First, big data, machine learning (ML), and Artificial Neural Networks (ANNs) are discussed to familiarize the reader with the importance of such a system. Next, the benefits and detriments of implementing such a system in Python are presented. Lastly, the specifics of the system are explained, and some experimental results are presented to prove the effectiveness of the system.",
            "output": [
                "A Framework for Distributed Deep Learning Layer Design in Python"
            ]
        },
        {
            "id": "task1540-15d872494fdd4b3a99a1b745da81702c",
            "input": "Lipreading, i.e. speech recognition from visual-only recordings of a speaker’s face, can be achieved with a processing pipeline based solely on neural networks, yielding significantly better accuracy than conventional methods. Feedforward and recurrent neural network layers (namely Long Short-Term Memory; LSTM) are stacked to form a single structure which is trained by back-propagating error gradients through all the layers. The performance of such a stacked network was experimentally evaluated and compared to a standard Support Vector Machine classifier using conventional computer vision features (Eigenlips and Histograms of Oriented Gradients). The evaluation was performed on data from 19 speakers of the publicly available GRID corpus. With 51 different words to classify, we report a best word accuracy on held-out evaluation speakers of 79.6% using the end-toend neural network-based solution (11.6% improvement over the best feature-based solution evaluated).",
            "output": [
                "LIPREADING WITH LONG SHORT-TERM MEMORY"
            ]
        },
        {
            "id": "task1540-d3955565fc2f4097ba2e3a6722da4f70",
            "input": "We consider the problem of multiple agents sensing and acting in environments<lb>with the goal of maximising their shared utility. In these environments, agents must<lb>learn communication protocols in order to share information that is needed to solve<lb>the tasks. By embracing deep neural networks, we are able to demonstrate end-<lb>to-end learning of protocols in complex environments inspired by communication<lb>riddles and multi-agent computer vision problems with partial observability. We<lb>propose two approaches for learning in these domains: Reinforced Inter-Agent<lb>Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses<lb>deep Q-learning, while the latter exploits the fact that, during learning, agents can<lb>backpropagate error derivatives through (noisy) communication channels. Hence,<lb>this approach uses centralised learning but decentralised execution. Our experi-<lb>ments introduce new environments for studying the learning of communication<lb>protocols and present a set of engineering innovations that are essential for success<lb>in these domains.",
            "output": [
                "Learning to Communicate with Deep Multi-Agent Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-4e702152ad8b45c283d86326e8d308c5",
            "input": "Given the limited performance of 2D cellular automata in terms of space when the number of documents increases and in terms of visualization clusters, our motivation was to experiment these cellular automata by increasing the size to view the impact of size on quality of results. The representation of textual data was carried out by a vector model whose components are derived from the overall balancing of the used corpus Term Frequency – Inverse Document Frequency (TF IDF).The WorldNet thesaurus has been used to address the problem of the lemmatization of the words because the representation used in this study is that of the bags of words. Another independent method of the language was used to represent textual records is that of the n-grams. Several measures of similarity have been tested. To validate the classification we have used two measures of assessment based on the recall and precision (f-measure and entropy). The results are promising and confirm the idea to increase the dimension to the problem of the spatiality of the classes. The results obtained in terms of purity class (ie the minimum value of entropy) shows that the number of documents over longer believes the results are better for 3D cellular automata, which was not obvious to 2D the dimension. In terms of spatial navigation, cellular automata provide very good 3D performance visualization than 2D cellular automata.",
            "output": [
                "Visualization and clustering by 3D cellular automata: Application to unstructured data"
            ]
        },
        {
            "id": "task1540-ece477130c94453a8371ddccde29347e",
            "input": "Natural language inference (NLI) is a fundamentally important task in natural language processing that has many applications. The recently released Stanford Natural Language Inference (SNLI) corpus has made it possible to develop and evaluate learning-centered methods such as deep neural networks for the NLI task. In this paper, we propose a special long short-term memory (LSTM) architecture for NLI. Our model builds on top of a recently proposed neutral attention model for NLI but is based on a significantly different idea. Instead of deriving sentence embeddings for the premise and the hypothesis to be used for classification, our solution uses a matching-LSTM that performs word-by-word matching of the hypothesis with the premise. This LSTM is able to place more emphasis on important word-level matching results. In particular, we observe that this LSTM remembers important mismatches that are critical for predicting the contradiction or the neutral relationship label. Our experiments on the SNLI corpus show that our model outperforms the state of the art, achieving an accuracy of 86.1% on the test data.",
            "output": [
                "Learning Natural Language Inference with LSTM"
            ]
        },
        {
            "id": "task1540-2662613e175c4f5e8fd44c92e21aeef6",
            "input": "In this paper, we present a novel framework incorporating a combination of sparse models in different domains. We posit the observed data as generated from a linear combination of a sparse Gaussian Markov model (with a sparse precision matrix) and a sparse Gaussian independence model (with a sparse covariance matrix). We provide efficient methods for decomposition of the data into two domains, viz., Markov and independence domains. We characterize a set of sufficient conditions for identifiability and model consistency. Our decomposition method is based on a simple modification of the popular `1-penalized maximumlikelihood estimator (`1-MLE). We establish that our estimator is consistent in both the domains, i.e., it successfully recovers the supports of both Markov and independence models, when the number of samples n scales as n = Ω(d log p), where p is the number of variables and d is the maximum node degree in the Markov model. Our conditions for recovery are comparable to those of `1-MLE for consistent estimation of a sparse Markov model, and thus, we guarantee successful high-dimensional estimation of a richer class of models under comparable conditions. Our experiments validate these results and also demonstrate that our models have better inference accuracy under simple algorithms such as loopy belief propagation.",
            "output": [
                "High-Dimensional Covariance Decomposition into Sparse Markov and Independence Domains"
            ]
        },
        {
            "id": "task1540-04dd1290a43b438e9797733679498644",
            "input": "As a well-known clustering algorithm, Fuzzy C-Means (FCM) allows each input sample to belong to more than one cluster, providing more flexibility than non-fuzzy clustering methods. However, the accuracy of FCM is subject to false detections caused by noisy records, weak feature selection and low certainty of the algorithm in some cases. The false detections are very important in some decision-making application domains like network security and medical diagnosis, where weak decisions based on such false detections may lead to catastrophic outcomes. They are mainly emerged from making decisions about a subset of records that do not provide enough evidence to make a good decision. In this paper, we propose a method for detecting such ambiguous records in FCM by introducing a certainty factor to decrease invalid detections. This approach enables us to send the detected ambiguous records to another discrimination method for a deeper investigation, thus increasing the accuracy by lowering the error rate. Most of the records are still processed quickly and with low error rate which prevents performance loss compared to similar hybrid methods. Experimental results of applying the proposed method on several datasets from different domains show a significant decrease in error rate as well as improved sensitivity of the algorithm.",
            "output": [
                "Ambiguity-Driven Fuzzy C-Means Clustering: How to Detect Uncertain Clustered Records"
            ]
        },
        {
            "id": "task1540-e317fc5b0e194bb09302de0d034903b0",
            "input": "Given the incessant growth of documents describing the opinions of different people circulating on the web, including Web 2.0 has made it possible to give an opinion on any product in the net. In this paper, we examine the various opinions expressed in the tweets and classify them (positive, negative or neutral) by using the emoticons for the Bayesian method and adjectives and adverbs for the Turney’s method.",
            "output": [
                "Detecting Opinions in Tweets"
            ]
        },
        {
            "id": "task1540-a159829f19c84904917a8ee5e77fe16c",
            "input": "In this work we focus on efficient heuristics for solving a class of stochastic planning problems that arise in a variety of business, investment, and industrial applications. The problem is best de­ scribed in terms of future buy and sell contracts. By buying less reliable, but less expensive, buy (supply) contracts, a company or a trader can cover a position of more reliable and more expen­ sive sell contracts. The goal is to maximize the expected net gain (profit) by constructing a close to optimum portfolio out of the available buy and sell contracts. This stochastic planning problem can be formulated as a two-stage stochastic linear programm ing problem with recourse. However, this formalization leads to solutions that are ex­ ponential in the number of possible failure com­ binations. Thus, this approach is not feasible for large scale problems. In this work we investi­ gate heuristic approximation techniques alleviat­ ing the efficiency problem. We primarily focus on the clustering approach and devise heuristics for finding clusterings leading to good approxi­ mations. We illustrate the quality and feasibility of the approach through experimental data.",
            "output": [
                "A Clustering Approach to Solving Large Stochastic Matching Problems"
            ]
        },
        {
            "id": "task1540-8322c31e72ce434ebb1978e8f6c60982",
            "input": "We propose combinatorial cascading bandits, a class of partial monitoring problems where at each step a learning agent chooses a tuple of ground items subject to constraints and receives a reward if and only if the weights of all chosen items are one. The weights of the items are binary, stochastic, and drawn independently of each other. The agent observes the index of the first chosen item whose weight is zero. This observation model arises in network routing, for instance, where the learning agent may only observe the first link in the routing path which is down, and blocks the path. We propose a UCB-like algorithm for solving our problems, CombCascade; and prove gap-dependent and gap-free upper bounds on its n-step regret. Our proofs build on recent work in stochastic combinatorial semi-bandits but also address two novel challenges of our setting, a non-linear reward function and partial observability. We evaluate CombCascade on two real-world problems and show that it performs well even when our modeling assumptions are violated. We also demonstrate that our setting requires a new learning algorithm.",
            "output": [
                "Combinatorial Cascading Bandits"
            ]
        },
        {
            "id": "task1540-16c6b8e829524408a5560ba53a3efe9a",
            "input": "Latent Dirichlet Allocation (LDA) mining thematic structure of documents plays an important role in nature language processing and machine learning areas. However, the probability distribution from LDA only describes the statistical relationship of occurrences in the corpus and usually in practice, probability is not the best choice for feature representations. Recently, embedding methods have been proposed to represent words and documents by learning essential concepts and representations, such as Word2Vec and Doc2Vec. The embedded representations have shown more effectiveness than LDA-style representations in many tasks. In this paper, we propose the Topic2Vec approach which can learn topic representations in the same semantic vector space with words, as an alternative to probability. The experimental results show that Topic2Vec achieves interesting and meaningful results.",
            "output": [
                "Topic2Vec: Learning Distributed Representations of Topics"
            ]
        },
        {
            "id": "task1540-5d4e11dcc9614a77ba793d7d4f970312",
            "input": "Selecting the right reference class and the right interval when faced with conflicting candidates and no possibility of establish­ ing subset style dominance has been a prob­ lem for Kyburg's Evidential Probability sys­ tem. Various methods have been proposed by Loui and Kyburg to solve this problem in a way that is both intuitively appealing and justifiable within Kyburg's framework. The scheme proposed in this paper leads to stronger statistical assertions without sacri­ ficing too much of the intuitive appeal of Ky­ burg's latest proposal. 1 Overview of the Problem",
            "output": [
                "A Modification to Evidential Probability"
            ]
        },
        {
            "id": "task1540-de243a64a8cb4b2cbe1c69e1e9c6566f",
            "input": "Probabilistic logic programs are logic programs in which some of the facts are annotated with probabilities. Several classical probabilistic inference tasks (such as MAP and computing marginals) have not yet received a lot of attention for this formalism. The contribution of this paper is that we develop efficient inference algorithms for these tasks. This is based on a conversion of the probabilistic logic program and the query and evidence to a weighted CNF formula. This allows us to reduce the inference tasks to wellstudied tasks such as weighted model counting. To solve such tasks, we employ state-ofthe-art methods. We consider multiple methods for the conversion of the programs as well as for inference on the weighted CNF. The resulting approach is evaluated experimentally and shown to improve upon the state-of-theart in probabilistic logic programming.",
            "output": [
                "Inference in Probabilistic Logic Programs using Weighted CNF’s"
            ]
        },
        {
            "id": "task1540-6cd5d0d543f2474ca8299c5ad71de115",
            "input": "Click prediction is one of the fundamental problems in sponsored search. Most of existing studies took advantage of machine learning approaches to predict ad click for each event of ad view independently. However, as observed in the real-world sponsored search system, user’s behaviors on ads yield high dependency on how the user behaved along with the past time, especially in terms of what queries she submitted, what ads she clicked or ignored, and how long she spent on the landing pages of clicked ads, etc. Inspired by these observations, we introduce a novel framework based on Recurrent Neural Networks (RNN). Compared to traditional methods, this framework directly models the dependency on user’s sequential behaviors into the click prediction process through the recurrent structure in RNN. Large scale evaluations on the click-through logs from a commercial search engine demonstrate that our approach can significantly improve the click prediction accuracy, compared to sequence-independent approaches.",
            "output": [
                "Sequential Click Prediction for Sponsored Search with Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-aa078e170b914914b04693368d1cead4",
            "input": "Named Entities (NEs) are often written with no orthographic changes across different languages that share a common alphabet. We show that this can be leveraged so as to improve named entity recognition (NER) by using unsupervised word clusters from secondary languages as features in state-of-the-art discriminative NER systems. We observe significant increases in performance, finding that person and location identification is particularly improved, and that phylogenetically close languages provide more valuable features than more distant languages.",
            "output": [
                "“Translation can’t change a name”: Using Multilingual Data for Named Entity Recognition"
            ]
        },
        {
            "id": "task1540-7bf0c5a7636d4470bbc4ace10dd2d211",
            "input": "A logic is defined that allows to express in­ formation about statistical probabilities and about degrees of belief in specific proposi­ tions. By interpreting the two types of proba­ bilities in one common probability space, the semantics given are well suited to model the influence of statistical information on the for­ mation of subjective beliefs. Cross entropy minimization is a key element in these se­ mantics, the use of which is justified by show­ ing that the resulting logic exhibits some very reasonable properties.",
            "output": [
                "A Logic for Default Reasoning About Probabilities"
            ]
        },
        {
            "id": "task1540-588509e9e9f344f5a2d080e76d9f58d6",
            "input": "Financial news contains useful information on public companies and the market. In this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market. Experimental results have shown that our proposed methods are simple but very effective, which can significantly improve the stock prediction accuracy on a standard financial database over the baseline system using only the historical price information.",
            "output": [
                "Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-c4c56c539c684471b18029dfcfdb1b54",
            "input": "The recently introduced Intelligent Trial and Error algorithm (IT&E) enables robots to creatively adapt to damage in a matter of minutes by combining an off-line evolutionary algorithm and an on-line learning algorithm based on Bayesian Optimization. We extend the IT&E algorithm to allow for robots to learn to compensate for damages while executing their task(s). This leads to a semi-episodic learning scheme that increases the robot’s life-time autonomy and adaptivity. Preliminary experiments on a toy simulation and a 6-legged robot locomotion task show promising results.",
            "output": [
                "Towards semi-episodic learning for robot damage recovery"
            ]
        },
        {
            "id": "task1540-4b7209fb52594d53812fc5830de28a84",
            "input": "Summit work of the Spanish Golden Age and forefather of the so-called picaresque novel, The Life of Lazarillo de Tormes and of His Fortunes and Adversities still remains an anonymous text. Although distinguished scholars have tried to attribute it to different authors based on a variety of criteria, a consensus has yet to be reached. The list of candidates is long and not all of them enjoy the same support within the scholarly community. Analyzing their works from a data-driven perspective and applying machine learning techniques for style and text fingerprinting, we shed light on the authorship of the Lazarillo. As in a state-of-the-art survey, we discuss the methods used and how they perform in our specific case. According to our methodology, the most likely author seems to be Juan Arce de Otálora, closely followed by Alfonso de Valdés. The method states that not certain attribution can be made with the given corpus.",
            "output": [
                "The Life of Lazarillo de Tormes and of His Machine Learning Adversities"
            ]
        },
        {
            "id": "task1540-07f120ec83ad47f7bb44c5b8684b52b5",
            "input": "We address the problem of integrating textual and visual information in vector space models for word meaning representation. We first present the Residual CCA (R-CCA) method, that complements the standard CCA method by representing, for each modality, the difference between the original signal and the signal projected to the shared, max correlation, space. We then show that constructing visual and textual representations and then post-processing them through composition of common modeling motifs such as PCA, CCA, R-CCA and linear interpolation (a.k.a sequential modeling) yields high quality models. On five standard semantic benchmarks our sequential models outperform recent multimodal representation learning alternatives, including ones that rely on joint representation learning. For two of these benchmarks our R-CCA method is part of the Best configuration our algorithm yields.",
            "output": [
                "Effective Combination of Language and Vision Through Model Composition and the R-CCA Method"
            ]
        },
        {
            "id": "task1540-035de7a8fdef4cfab7829e1527af7208",
            "input": "We present a general framework for classification of sparse and irregularly-sampled time series. The properties of such time series can result in substantial uncertainty about the values of the underlying temporal processes, while making the data difficult to deal with using standard classification methods that assume fixeddimensional feature spaces. To address these challenges, we propose an uncertaintyaware classification framework based on a special computational layer we refer to as the Gaussian process adapter that can connect irregularly sampled time series data to any black-box classifier learnable using gradient descent. We show how to scale up the required computations based on combining the structured kernel interpolation framework and the Lanczos approximation method, and how to discriminatively train the Gaussian process adapter in combination with a number of classifiers end-to-end using backpropagation.",
            "output": [
                "A scalable end-to-end Gaussian process adapter for irregularly sampled time series classification"
            ]
        },
        {
            "id": "task1540-92b21d4d68454054911ebf0751ef78ec",
            "input": "Training the parameters of statistical models to describe a given data set is a central task in the field of data mining and machine learning. A very popular and powerful way of parameter estimation is the method of maximum likelihood estimation (MLE). Among the most widely used families of statistical models are mixture models, especially, mixtures of Gaussian distributions. A popular hard-clustering variant of the MLE problem is the so-called completedata maximum likelihood estimation (CMLE) method. The standard approach to solve the CMLE problem is the Classification-Expectation-Maximization (CEM) algorithm [CG92]. Unfortunately, it is only guaranteed that the algorithm converges to some (possibly arbitrarily poor) stationary point of the objective function. In this paper, we present two algorithms for a restricted version of the CMLE problem. That is, our algorithms approximate reasonable solutions to the CMLE problem which satisfy certain natural properties. Moreover, they compute solutions whose cost (i.e. complete-data log-likelihood values) are at most a factor (1 + ε) worse than the cost of the solutions that we search for. Note the CMLE problem in its most general, i.e. unrestricted, form is not well defined and allows for trivial optimal solutions that can be thought of as degenerated solutions.",
            "output": [
                "Hard-Clustering with Gaussian Mixture Models"
            ]
        },
        {
            "id": "task1540-1293dea9fb9945caa2a52a730947044d",
            "input": "Declarative large-scale machine learning (ML) aims at the specification of ML algorithms in a high-level language and automatic generation of hybrid runtime execution plans ranging from single node, in-memory computations to distributed computations on MapReduce (MR) or similar frameworks like Spark. The compilation of large-scale ML programs exhibits many opportunities for automatic optimization. Advanced cost-based optimization techniques require—as a fundamental precondition—an accurate cost model for evaluating the impact of optimization decisions. In this paper, we share insights into a simple and robust yet accurate technique for costing alternative runtime execution plans of ML programs. Our cost model relies on generating and costing runtime plans in order to automatically reflect all successive optimization phases. Costing runtime plans also captures control flow structures such as loops and branches, and a variety of cost factors like IO, latency, and computation costs. Finally, we linearize all these cost factors into a single measure of expected execution time. Within SystemML, this cost model is leveraged by several advanced optimizers like resource optimization and global data flow optimization. We share our lessons learned in order to provide foundations for the optimization of ML programs.",
            "output": [
                "Costing Generated Runtime Execution Plans for Large-Scale Machine Learning Programs"
            ]
        },
        {
            "id": "task1540-07ab0af9d33348909d8f453965273ab3",
            "input": "Indefinite similarity measures can be frequently found in bio-informatics by means of alignment scores, but are also common in other fields like shape measures in image retrieval. Lacking an underlying vector space, the data are given as pairwise similarities only. The few algorithms available for such data do not scale to larger datasets. Focusing on probabilistic batch classifiers, the Indefinite Kernel Fisher Discriminant (iKFD) and the Probabilistic Classification Vector Machine (PCVM) are both effective algorithms for this type of data but, with cubic complexity. Here we propose an extension of iKFD and PCVM such that linear runtime and memory complexity is achieved for low rank indefinite kernels. Employing the Nyström approximation for indefinite kernels, we also propose a new almost parameter free approach to identify the landmarks, restricted to a supervised learning problem. Evaluations at several larger similarity data from various domains show that the proposed methods provides similar generalization capabilities while being easier to parametrize and substantially faster for large scale data.",
            "output": [
                "Probabilistic classifiers with low rank indefinite kernels"
            ]
        },
        {
            "id": "task1540-4ed2d79d08684f988528174315daa55d",
            "input": "The problem of recommending tours to travellers is an impor-<lb>tant and broadly studied area. Suggested solutions include<lb>various approaches of points-of-interest (POI) recommenda-<lb>tion and route planning. We consider the task of recommend-<lb>ing a sequence of POIs, that simultaneously uses information<lb>about POIs and routes. Our approach unifies the treatment<lb>of various sources of information by representing them as fea-<lb>tures in machine learning algorithms, enabling us to learn<lb>from past behaviour. Information about POIs are used to<lb>learn a POI ranking model that accounts for the start and<lb>end points of tours. Data about previous trajectories are used<lb>for learning transition patterns between POIs that enable us<lb>to recommend probable routes. In addition, a probabilistic<lb>model is proposed to combine the results of POI ranking and<lb>the POI to POI transitions. We propose a new F1 score on<lb>pairs of POIs that capture the order of visits. Empirical re-<lb>sults show that our approach improves on recent methods,<lb>and demonstrate that combining points and routes enables<lb>better trajectory recommendations.",
            "output": [
                "Learning Points and Routes to Recommend Trajectories"
            ]
        },
        {
            "id": "task1540-fe6b50b122a64eb2b25c48672fbcde46",
            "input": "We study two-player security games which can be viewed as sequences of nonzero-sum matrix games played by an Attacker and a Defender. The evolution of the game is based on a stochastic fictitious play process, where players do not have access to each other’s payoff matrix. Each has to observe the other’s actions up to present and plays the action generated based on the best response to these observations. In a regular fictitious play process, each player makes a maximum likelihood estimate of her opponent’s mixed strategy, which results in a time-varying update based on the previous estimate and current action. In this paper, we explore an alternative scheme for frequency update, whose mean dynamic is instead time-invariant. We examine convergence properties of the mean dynamic of the fictitious play process with such an update scheme, and establish local stability of the equilibrium point when both players are restricted to two actions. We also propose an adaptive algorithm based on this time-invariant frequency update.",
            "output": [
                "Fictitious Play with Time-Invariant Frequency Update for Network Security"
            ]
        },
        {
            "id": "task1540-51c313b60a804127859bb7a2173c9153",
            "input": "Breast cancer is one of the leading causes of cancer death among women worldwide. In clinical routine, automatic breast ultrasound (BUS) image segmentation is very challenging and essential for cancer diagnosis and treatment planning. Many BUS segmentation approaches have been studied in the last two decades, and have been proved to be effective on private datasets. Currently, the advancement of BUS image segmentation seems to meet its bottleneck. The improvement of the performance is increasingly challenging, and only few new approaches were published in the last several years. It is the time to look at the field by reviewing previous approaches comprehensively and to investigate the future directions. In this paper, we study the basic ideas, theories,pros and cons of the approaches, group them into categories, and extensively review each category in depth by discussing the principles, application issues, and advantages/disadvantages. Keyword: breast ultrasound (BUS) images, breast cancer, segmentation, benchmark, early detection, computer-aided diagnosis (CAD)",
            "output": [
                "Automatic Breast Ultrasound Image Segmentation: A Survey"
            ]
        },
        {
            "id": "task1540-6d596d617d0d4c1f983734091a865d35",
            "input": "Solving symmetric Bayesian decision prob­ lems is a computationally intensive task to perform regardless of the algorithm used. In this paper we propose a method for improv­ ing the efficiency of algorithms for solving Bayesian decision problems. The method is based on the principle of lazy evalua­ tion a principle recently shown to improve the efficiency of inference in Bayesian net­ works. The basic idea is to maintain de­ compositions of potentials and to postpone computations for as long as possible. The efficiency improvements obtained with the lazy evaluation based method is emphasized through examples. Finally, the lazy evalu­ ation based method is compared with the HUGIN and valuation-based systems architec­ tures for solving symmetric Bayesian decision problems.",
            "output": [
                "Lazy Evaluation of Symmetric Bayesian Decision Problems"
            ]
        },
        {
            "id": "task1540-0c3d698d2b8340429f6c66bc3652d819",
            "input": "Recurrent Neural Network (RNN) are a popular choice for modeling temporal and sequential tasks and achieve many state-of-the-art performance on various complex problems. However, most of the state-of-the-art RNNs have millions of parameters and require many computational resources for training and predicting new data. This paper proposes an alternative RNN model to reduce the number of parameters significantly by representing the weight parameters based on Tensor Train (TT) format. In this paper, we implement the TT-format representation for several RNN architectures such as simple RNN and Gated Recurrent Unit (GRU). We compare and evaluate our proposed RNN model with uncompressed RNN model on sequence classification and sequence prediction tasks. Our proposed RNNs with TT-format are able to preserve the performance while reducing the number of RNN parameters significantly up to 40 times smaller.",
            "output": [
                "Compressing Recurrent Neural Network with Tensor Train"
            ]
        },
        {
            "id": "task1540-37320c84c21a4c9ea85db59fe42063cc",
            "input": "The computational bottleneck in applying online learning to massive data sets is usually the projection step. We present efficient online learning algorithms that eschew projections in favor of much more efficient linear optimization steps using the Frank-Wolfe technique. We obtain a range of regret bounds for online convex optimization, with better bounds for specific cases such as stochastic online smooth convex optimization. Besides the computational advantage, other desirable features of our algorithms are that they are parameter-free in the stochastic case and produce sparse decisions. We apply our algorithms to computationally intensive applications of collaborative filtering, and show the theoretical improvements to be clearly visible on standard datasets.",
            "output": [
                "Projection-free Online Learning"
            ]
        },
        {
            "id": "task1540-576f82dc08cb4d4281618a76860fcc50",
            "input": "This is a preliminary report on the work aimed at making CR-Prolog – a version of ASP with consistency restoring rules – more suitable for use in teaching and large applications. First we describe a sorted version of CR-Prolog called SPARC. Second, we translate a basic version of the CR-Prolog into the language of DLV and compare the performance with the state of the art CR-Prolog solver. The results form the foundation for future more efficient and user friendly implementation of SPARC and shed some light on the relationship between two useful knowledge representation constructs: consistency restoring rules and weak constraints of DLV.",
            "output": [
                "SPARC – Sorted ASP with Consistency Restoring Rules"
            ]
        },
        {
            "id": "task1540-bf0acd0c66c54e54a9413f8fad9bc683",
            "input": "Recent advances have made it feasible to apply the stochastic variational paradigm to a collapsed representation of latent Dirichlet allocation (LDA). While the stochastic variational paradigm has successfully been applied to an uncollapsed representation of the hierarchical Dirichlet process (HDP), no attempts to apply this type of inference in a collapsed setting of non-parametric topic modeling have been put forward so far. In this paper we explore such a collapsed stochastic variational Bayes inference for the HDP. The proposed online algorithm is easy to implement and accounts for the inference of hyper-parameters. First experiments show a promising improvement in predictive performance. 1 Background We begin by considering a model where each document d is a mixture θd of K discrete topicdistributions φk over a vocabulary of V terms. Let zdi ∈ {1, ..,K} denote the topic of the i word wdi ∈ {1, .., V } in document d ∈ {1, .., D} and place Dirichlet priors on the parameters θd, φk. We have zdi | θd ∼ Discrete(θd) , θd ∼ Dirichlet(απ) , wdi | zdi, {φk} ∼ Discrete(φzdi) , φk ∼ Dirichlet(β) , where π is the top-level distribution over topics, and α and β are concentration parameters. While the dimensionality of K is fixed in latent Dirichlet allocation (LDA), we want the model to determine the number of topics needed. Consequently we follow the assumptions made by the hierarchical Dirichlet process (HDP) [1] of a countable but infinite number of topics, of which only a finite number is used in the posterior. Our prior π is constructed by a truncated sick-breaking process [2],",
            "output": [
                "Practical Collapsed Stochastic Variational Inference for the HDP"
            ]
        },
        {
            "id": "task1540-8af5d585dfbb4e8a81d4f73ce15e105a",
            "input": "Minimum error rate training (MERT) is a widely used training procedure for statistical machine translation. A general problem of this approach is that the search space is easy to converge to a local optimum and the acquired weight set is not in accord with the real distribution of feature functions. This paper introduces coordinate system selection (RSS) into the search algorithm for MERT. Contrary to previous approaches in which every dimension only corresponds to one independent feature function, we create several coordinate systems by moving one of the dimensions to a new direction. The basic idea is quite simple but critical that the training procedure of MERT should be based on a coordinate system formed by search directions but not directly on feature functions. Experiments show that by selecting coordinate systems with tuning set results, better results can be obtained without any other language knowledge.",
            "output": [
                "Coordinate System Selection for Minimum Error Rate Training in Statistical Machine Translation"
            ]
        },
        {
            "id": "task1540-2b86cfc08fe14299b632bd2199aac1cb",
            "input": "Numerous data mining techniques have been developed to extract information and identify patterns and predict trends from large data sets. In this study, two classification techniques, the J48 implementation of the C4.5 algorithm and a Naive Bayes classifier are applied to predict lung cancer survivability from an extensive data set with fifteen years of patient records. The purpose of the project is to verify the predictive effectiveness of the two techniques on real, historical data. Besides the performance outcome that renders J48 marginally better than the Naive Bayes technique, there is a detailed description of the data and the required pre-processing activities. The performance results confirm expectations while some of the issues that appeared during experimentation, underscore the value of having domain-specific understanding to leverage any domain-specific characteristics inherent in the data.",
            "output": [
                "Comparison of the C4.5 and a Naive Bayes Classifier for the Prediction of Lung Cancer Survivability"
            ]
        },
        {
            "id": "task1540-c87da039b563493292efbe6bd1d9d16c",
            "input": "Fundamental discrepancy between first order logic and statistical inference (global versus local properties of universe) is shown to be the obstacle for integration of logic and probability in L.p. logic of Bacchus. To overcome the counterintuitiveness of L.p. behaviour, a 3-valued logic is proposed.",
            "output": [
                "Beliefs and Probability in Bacchus’ l.p. Logic: A 3-Valued Logic Solution to Apparent Counter-intuition"
            ]
        },
        {
            "id": "task1540-60b51f38ae8048afb8ba058353bcfaaa",
            "input": "CUR matrix decomposition computes the low rank approximation of a given matrix by using the actual rows and columns of the matrix. It has been a very useful tool for handling large matrices. One limitation with the existing algorithms for CUR matrix decomposition is that they need an access to the full matrix, a requirement that can be difficult to fulfill in many real world applications. In this work, we alleviate this limitation by developing a CUR decomposition algorithm for partially observed matrices. In particular, the proposed algorithm computes the low rank approximation of the target matrix based on (i) the randomly sampled rows and columns, and (ii) a subset of observed entries that are randomly sampled from the matrix. Our analysis shows the relative error bound, measured by spectral norm, for the proposed algorithm when the target matrix is of full rank. We also show that only O(nr ln r) observed entries are needed by the proposed algorithm to perfectly recover a rank r matrix of size n × n, which improves the sample complexity of the existing algorithms for matrix completion. Empirical studies on both synthetic and real-world datasets verify our theoretical claims and demonstrate the effectiveness of the proposed algorithm.",
            "output": [
                "CUR Algorithm for Partially Observed Matrices"
            ]
        },
        {
            "id": "task1540-d960901968db4b51b6827f7994ce4246",
            "input": "Deep Gaussian processes (DGPs) are multi-layer hierarchical generalisations of Gaussian processes (GPs) and are formally equivalent to neural networks with multiple, infinitely wide hidden layers. DGPs are nonparametric probabilistic models and as such are arguably more flexible, have a greater capacity to generalise, and provide better calibrated uncertainty estimates than alternative deep models. This paper develops a new approximate Bayesian learning scheme that enables DGPs to be applied to a range of medium to large scale regression problems for the first time. The new method uses an approximate Expectation Propagation procedure and a novel and efficient extension of the probabilistic backpropagation algorithm for learning. We evaluate the new method for non-linear regression on eleven real-world datasets, showing that it always outperforms GP regression and is almost always better than state-of-the-art deterministic and sampling-based approximate inference methods for Bayesian neural networks. As a by-product, this work provides a comprehensive analysis of six approximate Bayesian methods for training neural networks.",
            "output": [
                "Deep Gaussian Processes for Regression using Approximate Expectation Propagation"
            ]
        },
        {
            "id": "task1540-2330c128b5264c6282f72877d19ef8e3",
            "input": "The development of summarization research has been significantly hampered by the costly acquisition of reference summaries. This paper proposes an effective way to automatically collect large scales of news-related multi-document summaries with reference to social media’s reactions. We utilize two types of social labels in tweets, i.e., hashtags and hyper-links. Hashtags are used to cluster documents into different topic sets. Also, a tweet with a hyper-link often highlights certain key points of the corresponding document. We synthesize a linked document cluster to form a reference summary which can cover most key points. To this aim, we adopt the ROUGE metrics to measure the coverage ratio, and develop an Integer Linear Programming solution to discover the sentence set reaching the upper bound of ROUGE. Since we allow summary sentences to be selected from both documents and highquality tweets, the generated reference summaries could be abstractive. Both informativeness and readability of the collected summaries are verified by manual judgment. In addition, we train a Support Vector Regression summarizer on DUC generic multi-document summarization benchmarks. With the collected data as extra training resource, the performance of the summarizer improves a lot on all the test sets. We release this dataset for further research.",
            "output": [
                "TGSum: Build Tweet Guided Multi-Document Summarization Dataset"
            ]
        },
        {
            "id": "task1540-279654985e4e46deae21a26561bf713c",
            "input": "We improve the regret bound of the Upper Confidence Bound (UCB) algorithm of Auer et al. (2002) and show that its regret is with high-probability a problem dependent constant. In the case of linear bandits (Dani et al., 2008), we improve the problem dependent bound in the dimension and number of time steps. Furthermore, as opposed to the previous result, we prove that our bound holds for small sample sizes, and at the same time the worst case bound is improved by a logarithmic factor and the constant is improved.",
            "output": [
                "Online Least Squares Estimation with Self-Normalized Processes: An Application to Bandit Problems∗"
            ]
        },
        {
            "id": "task1540-471edcfa44134795843771109fe3425f",
            "input": "Robust search procedures are a central component in the design of black-box constraint-programming solvers. This paper proposes activity-based search, the idea of using the activity of variables during propagation to guide the search. Activity-based search was compared experimentally to impact-based search and the wdeg heuristics. Experimental results on a variety of benchmarks show that activity-based search is more robust than other heuristics and may produce significant improvements in performance.",
            "output": [
                "Activity-Based Search for Black-Box Contraint-Programming Solvers"
            ]
        },
        {
            "id": "task1540-4d951c5de9b243f0bd1cdfb2c5f0b552",
            "input": "Several recently developed Multi-Agent Path Finding (MAPF) solvers scale to large MAPF instances by searching for MAPF plans on 2 levels: The high-level search resolves collisions between agents, and the low-level search plans paths for single agents under the constraints imposed by the high-level search. We make the following contributions to solve the MAPF problem with imperfect plan execution with small average makespans: First, we formalize the MAPF Problem with Delay Probabilities (MAPF-DP), define valid MAPF-DP plans and propose the use of robust plan-execution policies for valid MAPF-DP plans to control how each agent proceeds along its path. Second, we discuss 2 classes of decentralized robust plan-execution policies (called Fully Synchronized Policies and Minimal Communication Policies) that prevent collisions during plan execution for valid MAPF-DP plans. Third, we present a 2-level MAPF-DP solver (called Approximate Minimization in Expectation) that generates valid MAPF-DP plans.",
            "output": [
                "Multi-Agent Path Finding with Delay Probabilities"
            ]
        },
        {
            "id": "task1540-030f602cd57d4ea693018d6631c7c326",
            "input": "We show that there is a largely unexplored class of functions (positive polymatroids) that can define proper discrete metrics over pairs of binary vectors and that are fairly tractable to optimize over. By exploiting submodularity, we are able to give hardness results and approximation algorithms for optimizing over such metrics. Additionally, we demonstrate empirically the effectiveness of these metrics and associated algorithms on both a metric minimization task (a form of clustering) and also a metric maximization task (generating diverse k-best lists).",
            "output": [
                "Submodular Hamming Metrics"
            ]
        },
        {
            "id": "task1540-5a4f3c8025a743cd9039b08ba0dd3c00",
            "input": "Vector-space representations provide geometric tools for reasoning about the similarity of a set of objects and their relationships. Recent machine learning methods for deriving vectorspace embeddings of words (e.g., word2vec) have achieved considerable success in natural language processing. These vector spaces have also been shown to exhibit a surprising capacity to capture verbal analogies, with similar results for natural images, giving new life to a classic model of analogies as parallelograms that was first proposed by cognitive scientists. We evaluate the parallelogram model of analogy as applied to modern word embeddings, providing a detailed analysis of the extent to which this approach captures human relational similarity judgments in a large benchmark dataset. We find that that some semantic relationships are better captured than others. We then provide evidence for deeper limitations of the parallelogram model based on the intrinsic geometric constraints of vector spaces, paralleling classic results for first-order similarity.",
            "output": [
                "Evaluating vector-space models of analogy"
            ]
        },
        {
            "id": "task1540-700e53fe54cf4330987f7a69b3c22145",
            "input": "One of the long-term goals of artificial intelligence is to build an agent that can communicate intelligently with human in natural language. Most existing work on natural language learning relies heavily on training over a pre-collected dataset with annotated labels, leading to an agent that essentially captures the statistics of the fixed external training data. As the training data is essentially a static snapshot representation of the knowledge from the annotator, the agent trained this way is limited in adaptiveness and generalization of its behavior. Moreover, this is very different from the language learning process of humans, where language is acquired during communication by taking speaking action and learning from the consequences of speaking action in an interactive manner. This paper presents an interactive setting for grounded natural language learning, where an agent learns natural language by interacting with a teacher and learning from feedback, thus learning and improving language skills while taking part in the conversation. To achieve this goal, we propose a model which incorporates both imitation and reinforcement by leveraging jointly sentence and reward feedbacks from the teacher. Experiments are conducted to validate the effectiveness of the proposed approach.",
            "output": [
                "Listen, Interact and Talk: Learning to Speak via Interaction"
            ]
        },
        {
            "id": "task1540-92872fa4a84649688148c7e1637fe14f",
            "input": "Riemannian geometry has been successfully used in many brain-computer interface (BCI) classification problems and demonstrated superior performance. In this paper, for the first time, it is applied to BCI regression problems, an important category of BCI applications. More specifically, we propose a new feature extraction approach for Electroencephalogram (EEG) based BCI regression problems: a spatial filter is first used to increase the signal quality of the EEG trials and also to reduce the dimensionality of the covariance matrices, and then Riemannian tangent space features are extracted. We validate the performance of the proposed approach in reaction time estimation from EEG signals measured in a large-scale sustained-attention psychomotor vigilance task, and show that compared with the traditional powerband features, the tangent space features can reduce the root mean square estimation error by 4.30-8.30%, and increase the estimation correlation coefficient by 6.59-11.13%.",
            "output": [
                "EEG-Based User Reaction Time Estimation Using Riemannian Geometry Features"
            ]
        },
        {
            "id": "task1540-45e11824963948f39fe552d39fdc2cf5",
            "input": "State-of-the-art sequence labeling systems traditionally require large amounts of taskspecific knowledge in the form of handcrafted features and data pre-processing. In this paper, we introduce a novel neutral network architecture that benefits from both wordand character-level representations automatically, by using combination of bidirectional LSTM, CNN and CRF. Our system is truly end-to-end, requiring no feature engineering or data preprocessing, thus making it applicable to a wide range of sequence labeling tasks on different languages. We evaluate our system on two data sets for two sequence labeling tasks — Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003 corpus for named entity recognition (NER). We obtain stateof-the-art performance on both the two data — 97.55% accuracy for POS tagging and 91.21% F1 for NER.",
            "output": [
                "End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF"
            ]
        },
        {
            "id": "task1540-e9e46627b5fc468aab27f2d347080ad6",
            "input": "We describe a method to produce a network where current methods such as DeepFool have great difficulty producing adversarial samples. Our construction suggests some insights into how deep networks work. We provide a reasonable analyses that our construction is difficult to defeat, and show experimentally that our method is hard to defeat using several standard networks and datasets. We use our method to produce a system that can reliably detect whether an image is a picture of a real scene or not. Our system applies to images captured with depth maps (RGBD images) and checks if a pair of image and depth map is consistent. It relies on the relative difficulty of producing naturalistic depth maps for images in post processing. We demonstrate that our system is robust to adversarial examples built from currently known attacking approaches.",
            "output": [
                "SafetyNet: Detecting and Rejecting Adversarial Examples Robustly"
            ]
        },
        {
            "id": "task1540-ba8e92f1e3034f33bbb4ad8799a6cba7",
            "input": "Finding inclusion-minimal hitting sets for a given collection of sets is a fundamental combinatorial problem with applications in domains as diverse as Boolean algebra, computational biology, and data mining. Much of the algorithmic literature focuses on the problem of recognizing the collection of minimal hitting sets; however, in many of the applications, it is more important to generate these hitting sets. We survey twenty algorithms from across a variety of domains, considering their history, classification, useful features, and computational performance on a variety of synthetic and real-world inputs. We also provide a suite of implementations of these algorithms with a ready-to-use, platform-agnostic interface based on Docker containers and the AlgoRun framework, so that interested computational scientists can easily perform similar tests with inputs from their own research areas on their own computers or through a convenient Web interface.",
            "output": [
                "The minimal hitting set generation problem: algorithms and computation"
            ]
        },
        {
            "id": "task1540-99f3a75dad0f4615b593b326b0daeaf1",
            "input": "Many real-world decision-theoretic planning problems can be naturally modeled with discrete and continuous state Markov decision processes (DC-MDPs). While previous work has addressed automated decision-theoretic planning for DCMDPs, optimal solutions have only been defined so far for limited settings, e.g., DC-MDPs having hyper-rectangular piecewise linear value functions. In this work, we extend symbolic dynamic programming (SDP) techniques to provide optimal solutions for a vastly expanded class of DCMDPs. To address the inherent combinatorial aspects of SDP, we introduce the XADD — a continuous variable extension of the algebraic decision diagram (ADD) — that maintains compact representations of the exact value function. Empirically, we demonstrate an implementation of SDP with XADDs on various DC-MDPs, showing the first optimal automated solutions to DCMDPs with linear and nonlinear piecewise partitioned value functions and showing the advantages of constraint-based pruning for XADDs.",
            "output": [
                "Symbolic Dynamic Programming for Discrete and Continuous State MDPs"
            ]
        },
        {
            "id": "task1540-c79b71d3d5cd4e7f8c97b9276b789f34",
            "input": "In built infrastructure monitoring, an efficient path planning algorithm is essential for robotic inspection of large surfaces using computer vision. In this work, we first formulate the inspection path planning problem as an extended travelling salesman problem (TSP) in which both the coverage and obstacle avoidance were taken into account. An enhanced discrete particle swarm optimisation (DPSO) algorithm is then proposed to solve the TSP, with performance improvement by using deterministic initialisation, random mutation, and edge exchange. Finally, we take advantage of parallel computing to implement the DPSO in a GPU-based framework so that the computation time can be significantly reduced while keeping the hardware requirement unchanged. To show the effectiveness of the proposed algorithm, experimental results are included for datasets obtained from UAV inspection of an office building and a bridge.",
            "output": [
                "Enhanced Discrete Particle Swarm Optimization Path Planning for UAV Vision-based Surface Inspection"
            ]
        },
        {
            "id": "task1540-46815ad482a74b438fdb3de494a12e62",
            "input": "In this paper, we address the problem of embedded feature selection for ranking on top of the list problems. We pose this problem as a regularized empirical risk minimization with p-norm push loss function (p = ∞) and sparsity inducing regularizers. We leverage the issues related to this challenging optimization problem by considering an alternating direction method of multipliers algorithm which is built upon proximal operators of the loss function and the regularizer. Our main technical contribution is thus to provide a numerical scheme for computing the infinite push loss function proximal operator. Experimental results on toy, DNA microarray and BCI problems show how our novel algorithm compares favorably to competitors for ranking on top while using fewer variables in the scoring function.",
            "output": [
                "Sparse Support Vector Infinite Push"
            ]
        },
        {
            "id": "task1540-31b23df662e44769a2bb3f93c9918515",
            "input": "Statistics pedagogy values using a variety of examples. Thanks to text resources on the Web, and since statistical packages have the ability to analyze string data, it is now easy to use language-based examples in a statistics class. Three such examples are discussed here. First, many types of wordplay (e.g., crosswords and hangman) involve finding words with letters that satisfy a certain pattern. Second, linguistics has shown that idiomatic pairs of words often appear together more frequently than chance. For example, in the Brown Corpus, this is true of the phrasal verb to throw up (p-value=7.92E10.) Third, a pangram contains all the letters of the alphabet at least once. These are searched for in Charles Dickens' A Christmas Carol, and their lengths are compared to the expected value given by the unequal probability coupon collector's problem as well as simulations.",
            "output": [
                "Language-based Examples in the Statistics Classroom"
            ]
        },
        {
            "id": "task1540-2e8b7604ee134ac4a7507a4dc9dd7ebb",
            "input": "In the present paper we show that distributional information is particularly important when considering concept availability under implicit language learning conditions. Based on results from different behavioural experiments we argue that the implicit learnability of semantic regularities depends on the degree to which the relevant concept is reflected in language use. In our simulations, we train a VectorSpace model on either an English or a Chinese corpus and then feed the resulting representations to a feed-forward neural network. The task of the neural network was to find a mapping between the word representations and the novel words. Using datasets from four behavioural experiments, which used different semantic manipulations, we were able to obtain learning patterns very similar to those obtained by humans.",
            "output": [
                "A Distributional Semantics Approach to Implicit Language Learning"
            ]
        },
        {
            "id": "task1540-0efd0abf465549f48ee93e114abe7dbf",
            "input": "Algorithmic composition is the partial or total automation of the process of music composition by using computers. Since the 1950s, different computational techniques related to Artificial Intelligence have been used for algorithmic composition, including grammatical representations, probabilistic methods, neural networks, symbolic rule-based systems, constraint programming and evolutionary algorithms. This survey aims to be a comprehensive account of research on algorithmic composition, presenting a thorough view of the field for researchers in Artificial Intelligence.",
            "output": [
                "AI Methods in Algorithmic Composition: A Comprehensive Survey"
            ]
        },
        {
            "id": "task1540-0785fd660ef64689931a08d9b739fd21",
            "input": "We introduce a simple recurrent variational autoencoder architecture that significantly improves image modeling. The system represents the stateof-the-art in latent variable models for both the ImageNet and Omniglot datasets. We show that it naturally separates global conceptual information from lower level details, thus addressing one of the fundamentally desired properties of unsupervised learning. Furthermore, the possibility of restricting ourselves to storing only global information about an image allows us to achieve high quality ‘conceptual compression’.",
            "output": [
                "Towards Conceptual Compression"
            ]
        },
        {
            "id": "task1540-03bfa1a785f248b985909fa8f845e39b",
            "input": "The problem of solving (n − 1)-puzzle and cooperative path-finding (CPF) sub-optimally by rule based algorithms is addressed in this manuscript. The task in the puzzle is to rearrange n − 1 pebbles on the square grid of the size of n×n using one vacant position to a desired goal configuration. An improvement to the existent polynomial-time algorithm is proposed and experimentally analyzed. The improved algorithm is trying to move pebbles in a more efficient way than the original algorithm by grouping them into so-called snakes and moving them jointly within the snake. An experimental evaluation showed that the algorithm using snakes produces solutions that are 8% to 9% shorter than solutions generated by the original algorithm. The snake-based relocation has been also integrated into rule-based algorithms for solving the CPF problem sub-optimally, which is a closely related task. The task in CPF is to relocate a group of abstract robots that move over an undirected graph to given goal vertices. Robots can move to unoccupied neighboring vertices and at most one robot can be placed in each vertex. The (n − 1)-puzzle is a special case of CPF where the underlying graph is represented by a 4-connected grid and there is only one vacant vertex. Two major rule-based algorithms for CPF were included in our study – BIBOX and PUSH-and-SWAP (PUSH-and-ROTATE). Improvements gained by using snakes in the BIBOX algorithm were stable around 30% in (n − 1)-puzzle solving and up to 50% in CPFs over bi-connected graphs with various ear decompositions and multiple vacant vertices. In the case of the PUSHand-SWAP algorithm the improvement achieved by snakes was around 5% to 8%. However, the improvement was unstable and hardly predictable in the case of PUSH-and-SWAP.",
            "output": [
                "Improvements in Sub-optimal Solving of the (N − 1)-Puzzle via Joint Relocation of Pebbles and its Applications to Rule-based Cooperative Path-Finding"
            ]
        },
        {
            "id": "task1540-679ac02062f643dc97b35e8b4ebb044b",
            "input": "Path planning for multiple robots is well studied in the AI and robotics communities. For a given discretized environment, robots need to find collision-free paths to a set of specified goal locations. Robots can be fully anonymous, non-anonymous, or organized in groups. Although powerful solvers for this abstract problem exist, they make simplifying assumptions by ignoring kinematic constraints, making it difficult to use the resulting plans on actual robots. In this paper, we present a solution which takes kinematic constraints, such as maximum velocities, into account, while guaranteeing a user-specified minimum safety distance between robots. We demonstrate our approach in simulation and on real robots in 2D and 3D environments.",
            "output": [
                "Path Planning With Kinematic Constraints For Robot Groups"
            ]
        },
        {
            "id": "task1540-71432e58cec84f88bb2099cfac654609",
            "input": "Although the parallel corpus has an irreplaceable role in machine translation, its scale and coverage is still beyond the actual needs. Non-parallel corpus resources on the web have an inestimable potential value in machine translation and other natural language processing tasks. This article proposes a semi-supervised transductive learning method for expanding the training corpus in statistical machine translation system by extracting parallel sentences from the non-parallel corpus. This method only requires a small amount of labeled corpus and a large unlabeled corpus to build a high-performance classifier, especially for when there is short of labeled corpus. The experimental results show that by combining the non-parallel corpus alignment and the semi-supervised transductive learning method, we can more effectively use their respective strengths to improve the performance of machine translation system.",
            "output": [
                "Machine Translation Model based on "
            ]
        },
        {
            "id": "task1540-dfce128ab0964d53a2afe7fb984a611b",
            "input": "This paper explores the contributions of Answer Set Programming (ASP) to the study of an established theory from the field of Second Language Acquisition: Input Processing. The theory describes default strategies that learners of a second language use in extracting meaning out of a text, based on their knowledge of the second language and their background knowledge about the world. We formalized this theory in ASP, and as a result we were able to determine opportunities for refining its natural language description, as well as directions for future theory development. We applied our model to automating the prediction of how learners of English would interpret sentences containing the passive voice. We present a system, PIas, that uses these predictions to assist language instructors in designing teaching materials. To appear in Theory and Practice of Logic Programming (TPLP).",
            "output": [
                "An Application of Answer Set Programming to the Field of Second Language Acquisition"
            ]
        },
        {
            "id": "task1540-a615128f8a764c5eb77350be159fff2f",
            "input": "The AGM model is the most remarkable framework for modeling belief revision. However, it is not perfect in all aspects. Paraconsistent belief revision, multi-agent belief revision and non-prioritized belief revision are three different extensions to AGM to address three important criticisms applied to it. In this article, we propose a framework based on AGM that takes a position in each of these categories. Also, we discuss some features of our framework and study the satisfiability of AGM postulates in this new context.",
            "output": [
                "Source-Sensitive Belief Change"
            ]
        },
        {
            "id": "task1540-6c5abc23d2674803a6985a462360ef0c",
            "input": "The standard Kernel Quadrature method for numerical integration with random point sets (also called Bayesian Monte Carlo) is known to converge in root mean square error at a rate determined by the ratio s/d, where s and d encode the smoothness and dimension of the integrand. However, an empirical investigation reveals that the rate constant C is highly sensitive to the distribution of the random points. In contrast to standard Monte Carlo integration, for which optimal importance sampling is wellunderstood, the sampling distribution that minimises C for Kernel Quadrature does not admit a closed form. This paper argues that the practical choice of sampling distribution is an important open problem. One solution is considered; a novel automatic approach based on adaptive tempering and sequential Monte Carlo. Empirical results demonstrate a dramatic reduction in integration error of up to 4 orders of magnitude can be achieved with the proposed method.",
            "output": [
                "On the Sampling Problem for Kernel Quadrature"
            ]
        },
        {
            "id": "task1540-34ede2970705461b87f83f664c6be10c",
            "input": "This article presents an agent architecture for controlling an autonomous agent in stochastic environments. The architecture combines the partially observable Markov decision process (POMDP) model with the belief-desire-intention (BDI) framework. The Hybrid POMDP-BDI agent architecture takes the best features from the two approaches, that is, the online generation of reward-maximizing courses of action from POMDP theory, and sophisticated multiple goal management from BDI theory. We introduce the advances made since the introduction of the basic architecture, including (i) the ability to pursue multiple goals simultaneously and (ii) a plan library for storing pre-written plans and for storing recently generated plans for future reuse. A version of the architecture without the plan library is implemented and is evaluated using simulations. The results of the simulation experiments indicate that the approach is feasible.",
            "output": [
                "A Hybrid POMDP-BDI Agent Architecture with Online Stochastic Planning and Plan Caching"
            ]
        },
        {
            "id": "task1540-f3e6c4510e2c4825a802a3f5634a4022",
            "input": "Motivated by the previously developed multilevel aggregation method for solving structural analysis problems a novel two-level aggregation approach for efficient iterative solution of Principal Component Analysis (PCA) problems is proposed. The course aggregation model of the original covariance matrix is used in the iterative solution of the eigenvalue problem by a power iterations method. The method is tested on several data sets consisting of large number of text documents.",
            "output": [
                "ITERATIVE AGGREGATION METHOD FOR SOLVING PRINCIPAL COMPONENT ANALYSIS PROBLEMS"
            ]
        },
        {
            "id": "task1540-fd9e5c671926448c9a3d89346f23ceee",
            "input": "Exponential Linear Units (ELUs) are a useful rectifier for constructing deep learning architectures, as they may speed up and otherwise improve learning by virtue of not have vanishing gradients and by having mean activations near zero [1]. However, the ELU activation as parametrized in [1] is not continuously differentiable with respect to its input when the shape parameter α is not equal to 1. We present an alternative parametrization which is C continuous for all values of α, making the rectifier easier to reason about and making α easier to tune. This alternative parametrization has several other useful properties that the original parametrization of ELU does not: 1) its derivative with respect to x is bounded, 2) it contains both the linear transfer function and ReLU as special cases, and 3) it is scale-similar with respect to α. The Exponential Linear Unit as described in [1] is as follows: ELU(x, α) = { x if x ≥ 0 α(exp(x)− 1) otherwise (1) Where x is the input to the function, and α is a shape parameter. The derivative of this function with respect to x is: d dx ELU(x, α) = { 1 if x ≥ 0 α exp(x) otherwise (2) In Figures 1a and 1b we plot this activation and its derivative with respect to x for different values of α. We see that when α 6= 1, the activation’s derivative is discontinuous at x = 0. Additionally we see that large values of α can cause a large (“exploding”) gradient for small negative values of x, which may make training difficult. Our alternative parametrization of the ELU, which we dub “CELU”, is simply the ELU where the activation for negative values has been modified to ensure that the derivative at x = 0 for all values of α is 1: CELU(x, α) = { x if x ≥ 0 α ( exp ( x α ) − 1 ) otherwise (3) Note that ELU and CELU are identical when α = 1: ∀x ELU(x, 1) = CELU(x, 1) (4) The derivative of the activation with respect to x and α are as follows: d dx CELU(x, α) = { 1 if x ≥ 0 exp ( x α ) otherwise (5) d dα CELU(x, α) = { 0 if x ≥ 0 exp ( x α ) ( 1− x α ) − 1 otherwise Like in ELU, derivatives for CELU can be computed efficiently by precomputing exp ( x α ) and using it for the activation and its derivatives. Unlike ELU, CELU is scale-similar as a function of x and α: CELU(x, α) = 1 c CELU(cx, cα) (6) The CELU also converges to ReLU as α approaches 0 from the right and converges to a linear “no-op” activation as α approaches∞: lim α→0+ CELU(x, α) = max(0, x) (7) lim<lb>α→∞<lb>CELU(x, α) = x<lb>(8) This gives the CELU a nice interpretation as a way to in-<lb>terpolate between a ReLU and a linear function using α.<lb>Naturally, CELU can be slightly shifted in x and y such that<lb>it converges to any arbitrary shifted ReLU, in case negative<lb>activations are desirable even for small values of α.<lb>References<lb>[1] D. Clevert, T. Unterthiner, and S. Hochreiter. Fast and accu-<lb>rate deep network learning by exponential linear units (elus).<lb>CoRR, abs/1511.07289, 2015. 1<lb>ar<lb>X<lb>iv<lb>:1<lb>70<lb>4.<lb>07<lb>48<lb>3v<lb>1<lb>[<lb>cs<lb>.L<lb>G<lb>]<lb>2<lb>4<lb>A<lb>pr<lb>2<lb>01<lb>7",
            "output": [
                "Continuously Differentiable Exponential Linear Units"
            ]
        },
        {
            "id": "task1540-3b20429d6bb745bd9b7df9ba5dbaf3c3",
            "input": "We demonstrate how quantum computation can provide non-trivial improvements in the computational and statistical complexity of the perceptron model. We develop two quantum algorithms for perceptron learning. The first algorithm exploits quantum information processing to determine a separating hyperplane using a number of steps sublinear in the number of data points N , namely O( √ N). The second algorithm illustrates how the classical mistake bound of O( 1 γ2 ) can be further improved to O( 1 √ γ ) through quantum means, where γ denotes the margin. Such improvements are achieved through the application of quantum amplitude amplification to the version space interpretation of the perceptron model.",
            "output": [
                "Quantum Perceptron Models"
            ]
        },
        {
            "id": "task1540-b5ee523afa8546ce9cf411dc073f0086",
            "input": "Deep Neural Network (DNN) are currently of great interest in research and application. The training of these networks is a compute intensive and time consuming task. To reduce training times to a bearable amount at reasonable cost we extend the popular Caffe toolbox for DNN with an efficient distributed memory communication pattern. To achieve good scalability we emphasize the overlap of computation and communication and prefer fine granular synchronization patterns over global barriers. To implement these communication patterns we rely on the the ”Global address space Programming Interface” version 2 (GPI-2) communication library. This interface provides a light-weight set of asynchronous one-sided communication primitives supplemented by non-blocking fine granular data synchronization mechanisms. Therefore, CaffeGPI is the name of our parallel version of Caffe. First benchmarks demonstrate better scaling behavior compared with other extensions, e.g., the IntelTMCaffe. Even within a single symmetric multiprocessing machine with four graphics processing units, the CaffeGPI scales better than the standard Caffe toolbox. These first results demonstrate that the use of standard High Performance Computing (HPC) hardware is a valid cost saving approach to train large DDNs. I/O is an other bottleneck to work with DDNs in a standard parallel HPC setting, which we will consider in more detail in a forthcoming paper.",
            "output": [
                "Using GPI-2 for Distributed Memory Paralleliziation of the Caffe Toolbox to Speed up Deep Neural Network Training"
            ]
        },
        {
            "id": "task1540-53f55d494f374463b76a7152123a2a80",
            "input": "We study the problem of recovering an incomplete m × n matrix of rank r with columns arriving online over time. This is known as the problem of life-long matrix completion, and is widely applied to recommendation system, computer vision, system identification, etc. The challenge is to design provable algorithms tolerant to a large amount of noises, with small sample complexity. In this work, we give algorithms achieving strong guarantee under two realistic noise models. In bounded deterministic noise, an adversary can add any bounded yet unstructured noise to each column. For this problem, we present an algorithm that returns a matrix of a small error, with sample complexity almost as small as the best prior results in the noiseless case. For sparse random noise, where the corrupted columns are sparse and drawn randomly, we give an algorithm that exactly recovers an μ0-incoherent matrix by probability at least 1− δ with sample complexity as small asO (μ0rn log(r/δ)). This result advances the state-of-the-art work and matches the lower bound in a worst case. We also study the scenario where the hidden matrix lies on a mixture of subspaces and show that the sample complexity can be even smaller. Our proposed algorithms perform well experimentally in both synthetic and real-world datasets.",
            "output": [
                "Noise-Tolerant Life-Long Matrix Completion via Adaptive Sampling"
            ]
        },
        {
            "id": "task1540-919a71c074384bf8a4ca9633c6276579",
            "input": "There is growing interest in representing image data and feature descriptors using compact binary codes for fast near neighbor search. Although binary codes are motivated by their use as direct indices (addresses) into a hash table, codes longer than 32 bits are not being used as such, as it was thought to be ineffective. We introduce a rigorous way to build multiple hash tables on binary code substrings that enables exact k-nearest neighbor search in Hamming space. The approach is straightforward to implement and storage efficient. Theoretical analysis shows that the algorithm exhibits sub-linear run-time behavior for uniformly distributed codes. Empirical results show dramatic speed-ups over a linear scan baseline for datasets of up to one billion codes of 64, 128, or 256 bits.",
            "output": [
                "Fast Exact Search in Hamming Space with Multi-Index Hashing"
            ]
        },
        {
            "id": "task1540-4bba0a975eb44debbc1cf3c70e83c8a0",
            "input": "A two–step Christoffel function based solution is proposed to distribution regression problem. On the first step, to model distribution of observations inside a bag, build Christoffel function for each bag of observations. Then, on the second step, build outcome variable Christoffel function, but use the bag’s Christoffel function value at given point as the weight for the bag’s outcome. The approach allows the result to be obtained in closed form and then to be evaluated numerically. While most of existing approaches minimize some kind an error between outcome and prediction, the proposed approach is conceptually different, because it uses Christoffel function for knowledge representation, what is conceptually equivalent working with probabilities only. To receive possible outcomes and their probabilities Gauss quadrature for second–step measure can be built, then the nodes give possible outcomes and normalized weights – outcome probabilities. A library providing numerically stable polynomial basis for these calculations is available, what make the proposed approach practical.",
            "output": [
                "Multiple–Instance Learning: Christoffel Function Approach to Distribution Regression Problem"
            ]
        },
        {
            "id": "task1540-d0576c7cb429480aa28153a43f0f3c5c",
            "input": "In motion analysis and understanding it is important to be able to fit a suitable model or structure to the temporal series of observed data, in order to describe motion patterns in a compact way, and to discriminate between them. In an unsupervised context, i.e., no prior model of the moving object(s) is available, such a structure has to be learned from the data in a bottom-up fashion. In recent times, volumetric approaches in which the motion is captured from a number of cameras and a voxel-set representation of the body is built from the camera views, have gained ground due to attractive features such as inherent view-invariance and robustness to occlusions. Automatic, unsupervised segmentation of moving bodies along entire sequences, in a temporallycoherent and robust way, has the potential to provide a means of constructing a bottom-up model of the moving body, and track motion cues that may be later exploited for motion classification. Spectral methods such as locally linear embedding (LLE) can be useful in this context, as they preserve “protrusions”, i.e., high-curvature regions of the 3D volume, of articulated shapes, while improving their separation in a lower dimensional space, making them in this way easier to cluster. In this paper we therefore propose a spectral approach to unsupervised and temporally-coherent body-protrusion segmentation along time sequences. Volumetric shapes are clustered in an embedding space, clusters are propagated in time to ensure coherence, and merged or split to accommodate changes in the body’s topology. Experiments on both synthetic and real sequences of dense voxel-set data are shown. This supports the ability of the proposed method to cluster body-parts consistently over time in a totally unsupervised fashion, its robustness to sampling density and shape quality, and its potential for bottom-up model construction.",
            "output": [
                "Robust Temporally Coherent Laplacian Protrusion Segmentation of 3D Articulated Bodies"
            ]
        },
        {
            "id": "task1540-8d845f58fbbe47078f2bf616cf657259",
            "input": "Polynomial approximations to boolean functions have led to many positive results in computer science. In particular, polynomial approximations to the sign function underly algorithms for agnostically learning halfspaces, as well as pseudorandom generators for halfspaces. In this work, we investigate the limits of these techniques by proving inapproximability results for the sign function. Firstly, the “polynomial regression” algorithm of Kalai et al. (SIAM J. Comput. 2008) shows that halfspaces can be learned with respect to log-concave distributions on Rn in the challenging agnostic learning model. The power of this algorithm relies on the fact that under log-concave distributions, halfspaces can be approximated arbitrarily well by low-degree polynomials. We ask whether this technique can be extended beyond log-concave distributions, and establish a negative result. We show that polynomials of any degree cannot approximate the sign function to within arbitrarily low error for a large class of non-log-concave distributions on the real line, including those with densities proportional to exp(−|x|0.99). This impossibility result extends to multivariate distributions, and thus gives a strong limitation on the power of the polynomial regression algorithm for halfspaces. Secondly, we investigate the derandomization of Chernoff-type concentration inequalities. Chernoff-type tail bounds on sums of independent random variables have pervasive applications in theoretical computer science. Schmidt et al. (SIAM J. Discrete Math. 1995) showed that these inequalities can be established for sums of random variables with only O(log(1/δ))-wise independence, for a tail probability of δ. We show that their results are tight up to constant factors. These results rely on techniques from weighted approximation theory, which studies how well functions on the real line can be approximated by polynomials under various distributions. We believe that these techniques will have further applications in other areas of theoretical computer science. Harvard University, School of Engineering and Applied Sciences. Supported by an NDSEG Fellowship and NSF grant CNS-1237235. Harvard University, School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616 and the Lord Rutherford Memorial Research Fellowship.",
            "output": [
                "Weighted Polynomial Approximations: Limits for Learning and Pseudorandomness"
            ]
        },
        {
            "id": "task1540-ecad00ea673049159e83655f3e0b0c72",
            "input": "Recently, there has been substantial interest in clustering research that takes a beyond worst-case approach to the analysis of algorithms. The typical idea is to design a clustering algorithm that outputs a near-optimal solution, provided the data satisfy a natural stability notion. For example, Bilu and Linial (2010) and Awasthi et al. (2012) presented algorithms that output near-optimal solutions, assuming the optimal solution is preserved under small perturbations to the input distances. A drawback to this approach is that the algorithms are often explicitly built according to the stability assumption and give no guarantees in the worst case; indeed, several recent algorithms output arbitrarily bad solutions even when just a small section of the data does not satisfy the given stability notion. In this work, we address this concern in two ways. First, we provide algorithms that inherit the worst-case guarantees of clustering approximation algorithms, while simultaneously guaranteeing nearoptimal solutions when the data is stable. Our algorithms are natural modifications to existing state-ofthe-art approximation algorithms. Second, we initiate the study of local stability, which is a property of a single optimal cluster rather than an entire optimal solution. We show our algorithms output all optimal clusters which satisfy stability locally. Specifically, we achieve strong positive results in our local framework under recent stability notions including metric perturbation resilience (Angelidakis et al. 2017) and robust perturbation resilience (Balcan and Liang 2012) for the k-median, k-means, and symmetric/asymmetric k-center objectives. ∗Authors’ addresses: ninamf@cs.cmu.edu, crwhite@cs.cmu.edu. This work was supported in part by grants nsfccf 1535967, NSF CCF-1422910, NSF IIS-1618714, a Sloan Fellowship, a Microsoft Research Fellowship, and a National Defense Science and Engineering Graduate (NDSEG) fellowship. ar X iv :1 70 5. 07 15 7v 1 [ cs .D S] 1 9 M ay 2 01 7",
            "output": [
                "Clustering under Local Stability: Bridging the Gap between Worst-Case and Beyond Worst-Case Analysis"
            ]
        },
        {
            "id": "task1540-5c5c18a676534e29ab6dcf9c7d3ab0ba",
            "input": "Consider a setting where selfish agents are to be assigned to coalitions or projects from a set P. Each project k ∈ P is characterized by a valuation function; vk(S) is the value generated by a set S of agents working on project k. We study the following classic problem in this setting: “how should the agents divide the value that they collectively create?”. One traditional approach in cooperative game theory is to study core stability with the implicit assumption that there are infinite copies of one project, and agents can partition themselves into any number of coalitions. In contrast, we consider a model with a finite number of non-identical projects; this makes computing both high-welfare solutions and core payments highly non-trivial. The main contribution of this paper is a black-box mechanism that reduces the problem of computing a near-optimal core stable solution to the purely algorithmic problem of welfare maximization; we apply this to compute an approximately core stable solution that extracts one-fourth of the optimal social welfare for the class of subadditive valuations. We also show much stronger results for several popular sub-classes: anonymous, fractionally subadditive, and submodular valuations, as well as provide new approximation algorithms for welfare maximization with anonymous functions. Finally, we establish a connection between our setting and the well-studied simultaneous auctions with item bidding; we adapt our results to compute approximate pure Nash equilibria for these auctions.",
            "output": [
                "Computing Stable Coalitions: Approximation Algorithms for Reward Sharing"
            ]
        },
        {
            "id": "task1540-df0f63fcc68a4c49b6672a9df984719a",
            "input": "<lb>Many canonical machine learning problems boil down to a convex optimization problem with a finite<lb>sum structure. However, whereas much progress has been made in developing faster algorithms for<lb>this setting, the inherent limitations of these problems are not satisfactorily addressed by existing lower<lb>bounds. Indeed, current bounds focus on first-order optimization algorithms, and only apply in the often<lb>unrealistic regime where the number of iterations is less than O(d/n) (where d is the dimension and n<lb>is the number of samples). In this work, we extend the framework of Arjevani et al. [3, 5] to provide<lb>new lower bounds, which are dimension-free, and go beyond the assumptions of current bounds, thereby<lb>covering standard finite sum optimization methods, e.g., SAG, SAGA, SVRG, SDCA without duality, as<lb>well as stochastic coordinate-descent methods, such as SDCA and accelerated proximal SDCA.",
            "output": [
                "Dimension-Free Iteration Complexity of Finite Sum Optimization Problems"
            ]
        },
        {
            "id": "task1540-882dedf9b929405d877955848541422b",
            "input": "We proposed Neural Enquirer as a neural network architecture to execute a SQLlike query on a knowledge-base (KB) for answers. Basically, Neural Enquirer finds the distributed representation of a query and then executes it on knowledge-base tables to obtain the answer as one of the values in the tables. Unlike similar efforts in endto-end training of semantic parser [11, 9], Neural Enquirer is fully “neuralized”: it not only gives distributional representation of the query and the knowledge-base, but also realizes the execution of compositional queries as a series of differentiable operations, with intermediate results (consisting of annotations of the tables at different levels) saved on multiple layers of memory. Neural Enquirer can be trained with gradient descent, with which not only the parameters of the controlling components and semantic parsing component, but also the embeddings of the tables and query words can be learned from scratch. The training can be done in an end-to-end fashion, but it can take stronger guidance, e.g., the step-by-step supervision for complicated queries, and benefit from it. Neural Enquirer is one step towards building neural network systems which seek to understand language by executing it on real-world. Our experiments show that Neural Enquirer can learn to execute fairly complicated queries on tables with rich structures.",
            "output": [
                "Neural Enquirer: Learning to Query Tables"
            ]
        },
        {
            "id": "task1540-f40a24a81a2a49c68d87155938ae2fde",
            "input": "We consider the estimation of an i.i.d. (possibly non-Gaussian) vector x ∈ R from measurements y ∈ R obtained by a general cascade model consisting of a known linear transform followed by a probabilistic componentwise (possibly nonlinear) measurement channel. A novel method, called adaptive generalized approximate message passing (Adaptive GAMP), that enables joint learning of the statistics of the prior and measurement channel along with estimation of the unknown vector x is presented. The proposed algorithm is a generalization of a recently-developed EM-GAMP that uses expectationmaximization (EM) iterations where the posteriors in the E-steps are computed via approximate message passing. The methodology can be applied to a large class of learning problems including the learning of sparse priors in compressed sensing or identification of linear-nonlinear cascade models in dynamical systems and neural spiking processes. We prove that for large i.i.d. Gaussian transform matrices the asymptotic componentwise behavior of the adaptive GAMP algorithm is predicted by a simple set of scalar state evolution equations. In addition, we show that when a certain maximum-likelihood estimation can be performed in each step, the adaptive GAMP method can yield asymptotically consistent parameter estimates, which implies that the algorithm achieves a reconstruction quality equivalent to the oracle algorithm that knows the correct parameter values. Remarkably, this result applies to essentially arbitrary parametrizations of the unknown distributions, including ones that are nonlinear and non-Gaussian. The adaptive GAMP methodology thus provides a systematic, general and computationally efficient method applicable to a large range of complex linear-nonlinear models with provable guarantees.",
            "output": [
                "Approximate Message Passing with Consistent Parameter Estimation and Applications to Sparse Learning"
            ]
        },
        {
            "id": "task1540-b9c9b26481514afab2c890316c703e19",
            "input": "The undirected technique for evaluating be­ lief networks [Jensen et al., 1990a, Lauritzen and Spiegelhalter, 1988] requires clustering the nodes in the network into a junction tree. In the traditional view, the junction tree is constructed from the cliques of the moral­ ized and triangulated belief network: trian­ gulation is taken to be the primitive concept, the goal towards which any clustering algo­ rithm (e.g. node elimination) is directed. In this paper, we present an alternative concep­ tion of clustering, in which clusters and the junction tree property play the role of prim­ itives: given a graph (not a tree) of clusters which obey (a modified version of) the junc­ tion tree property, we transform this graph until we have obtained a tree. There are sev­ eral advantages to this approach: it is much clearer and easier to understand, which is important for humans who are constructing belief networks; it admits a wider range of heuristics which may enable more efficient or superior clustering algorithms; and it serves as the natural basis for an incremental clus­ tering scheme, which we describe.",
            "output": [
                "Clustering Without (Thinking About) Triangulation"
            ]
        },
        {
            "id": "task1540-fa07e332ec8245aca23944f1610009a5",
            "input": "One of the limitations of semantic parsing approaches to open-domain question answering is the lexicosyntactic gap between natural language questions and knowledge base entries – there are many ways to ask a question, all with the same answer. In this paper we propose to bridge this gap by generating paraphrases of the input question with the goal that at least one of them will be correctly mapped to a knowledge-base query. We introduce a novel grammar model for paraphrase generation that does not require any sentence-aligned paraphrase corpus. Our key idea is to leverage the flexibility and scalability of latent-variable probabilistic context-free grammars to sample paraphrases. We do an extrinsic evaluation of our paraphrases by plugging them into a semantic parser for Freebase. Our evaluation experiments on the WebQuestions benchmark dataset show that the performance of the semantic parser improves over strong baselines.",
            "output": [
                "Paraphrase Generation from Latent-Variable PCFGs for Semantic Parsing"
            ]
        },
        {
            "id": "task1540-4a944d61503f4bbdb496023825b7c03e",
            "input": "Identifying topics of discussions in online health communities (OHC) is critical to various applications, but can be difficult because topics of OHC content are usually heterogeneous and domaindependent. In this paper, we provide a multi-class schema, an annotated dataset, and supervised classifiers based on convolutional neural network (CNN) and other models for the task of classifying discussion topics. We apply the CNN classifier to the most popular breast cancer online community, and carry out a longitudinal analysis to show topic distributions and topic changes throughout members’ participation. Our experimental results suggest that CNN outperforms other classifiers in the task of topic classification, and that certain trajectories can be detected with respect to topic changes.",
            "output": [
                "Longitudinal Analysis of Discussion Topics in an Online Breast Cancer Community using Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-2b26c7538597482ab13e054492716b87",
            "input": "Mobile advertising is a billion pound industry that is rapidly expanding. The success of an advert is measured based on how users interact with it. In this paper we investigate whether the application of unsupervised learning and association rule mining could be used to enable personalised targeting of mobile adverts with the aim of increasing the interaction rate. Over May and June 2014 we recorded advert interactions such as tapping the advert or watching the whole advert video along with the set of apps a user has installed at the time of the interaction. Based on the apps that the users have installed we applied k-means clustering to profile the users into one of ten classes. Due to the large number of apps considered we implemented dimension reduction to reduced the app feature space by mapping the apps to their iTunes category and clustered users based on the percentage of their apps that correspond to each iTunes app category. The clustering was externally validated by investigating differences between the way the ten profiles interact with the various adverts genres (lifestyle, finance and entertainment adverts). In addition association rule mining was performed to find whether the time of the day that the advert is served and the number of apps a user has installed makes certain profiles more likely to interact with the advert genres. The results showed there were clear differences in the way the profiles interact with the different advert genres and the results of this paper suggest that mobile advert targeting would improve the frequency that users interact with an advert.",
            "output": [
                "Personalising Mobile Advertising Based on Users’ Installed Apps"
            ]
        },
        {
            "id": "task1540-d9d7798ee8e942adb806779532045046",
            "input": "Cooperative pathfinding is a problem of finding a set of non-conflicting trajectories for a number of mobile agents. Its applications include planning for teams of mobile robots, such as autonomous aircrafts, cars, or underwater vehicles. The state-of-the-art algorithms for cooperative pathfinding typically rely on some heuristic forward-search pathfinding technique, where A* is often the algorithm of choice. Here, we propose MA-RRT*, a novel algorithm for multi-agent path planning that builds upon a recently proposed asymptotically-optimal sampling-based algorithm for finding single-agent shortest path called RRT*. We experimentally evaluate the performance of the algorithm and show that the sampling-based approach offers better scalability than the classical forward-search approach in relatively large, but sparse environments, which are typical in real-world applications such as multi-aircraft collision avoidance.",
            "output": [
                "Multi-agent RRT*: Sampling-based Cooperative Pathfinding"
            ]
        },
        {
            "id": "task1540-270f72e46685499590d5bd0e8f390d9e",
            "input": "Dung’s abstract argumentation theory can be seen as a general framework for non-monotonic reasoning. An important question is then: what is the class of logics that can be subsumed as instantiations of this theory? The goal of this paper is to identify and study the large class of logic-based instantiations of Dung’s theory which correspond to the maxi-consistent operator, i.e. to the function which returns maximal consistent subsets of an inconsistent knowledge base. In other words, we study the class of instantiations where every extension of the argumentation system corresponds to exactly one maximal consistent subset of the knowledge base. We show that an attack relation belonging to this class must be conflict-dependent, must not be valid, must not be conflict-complete, must not be symmetric etc. Then, we show that some attack relations serve as lower or upper bounds of the class (e.g. if an attack relation contains canonical undercut then it is not a member of this class). By using our results, we show for all existing attack relations whether or not they belong to this class. We also define new attack relations which are members of this class. Finally, we interpret our results and discuss more general questions, like: what is the added value of argumentation in such a setting? We believe that this work is a first step towards achieving our long-term goal, which is to better understand the role of argumentation and, particularly, the expressivity of logic-based instantiations of Dung-style argumentation frameworks.",
            "output": [
                "Identifying the Class of Maxi-Consistent Operators in Argumentation"
            ]
        },
        {
            "id": "task1540-9ae2044d0f264aaeb3d25a7cb8258254",
            "input": "Exploration in an unknown environment is the core functionality for mobile robots. Learning-based exploration methods, including convolutional neural networks, provide excellent strategies without human-designed logic for the feature extraction [1]. But the conventional supervised learning algorithms cost lots of efforts on the labeling work of datasets inevitably. Scenes not included in the training set are mostly unrecognized either. We propose a deep reinforcement learning method for the exploration of mobile robots in an indoor environment with the depth information from an RGB-D sensor only. Based on the Deep Q-Network framework [2], the raw depth image is taken as the only input to estimate the Q values corresponding to all moving commands. The training of the network weights is end-to-end. In arbitrarily constructed simulation environments, we show that the robot can be quickly adapted to unfamiliar scenes without any man-made labeling. Besides, through analysis of receptive fields of feature representations, deep reinforcement learning motivates the convolutional networks to estimate the traversability of the scenes. The test results are compared with the exploration strategies separately based on deep learning [1] or reinforcement learning [3]. Even trained only in the simulated environment, experimental results in real-world environment demonstrate that the cognitive ability of robot controller is dramatically improved compared with the supervised method. We believe it is the first time that raw sensor information is used to build cognitive exploration strategy for mobile robots through end-to-end deep reinforcement learning.",
            "output": [
                "Towards cognitive exploration through deep reinforcement learning for mobile robots"
            ]
        },
        {
            "id": "task1540-d341994df70b44498d1ea101fb74065a",
            "input": "A model checker can produce a trace of counterexample, for an erroneous program, which is often long and difficult to understand. In general, the part about the loops is the largest among the instructions in this trace. This makes the location of errors in loops critical, to analyze errors in the overall program. In this paper, we explore the scalability capabilities of LocFaults, our error localization approach exploiting paths of CFG(Control Flow Graph) from a counterexample to calculate the MCDs (Minimal Correction Deviations), and MCSs (Minimal Correction Subsets) from each found MCD. We present the times of our approach on programs with While-loops unfolded b times, and a number of deviated conditions ranging from 0 to n. Our preliminary results show that the times of our approach, constraint-based and flow-driven, are better compared to BugAssist which is based on SAT and transforms the entire program to a Boolean formula, and further the information provided by LocFaults is more expressive for the user.",
            "output": [
                "Exploration of the scalability of LocFaults approach for error localization with While-loops programs"
            ]
        },
        {
            "id": "task1540-2f90a8b6c8c041e7952b019196002234",
            "input": "The explosive availability of remote sensing im-<lb>ages has challenged supervised classification algorithms such as<lb>Support Vector Machines (SVM), as training samples tend to<lb>be highly limited due to the expensive and laborious task of<lb>ground truthing. The temporal correlation and spectral similarity<lb>between multitemporal images have opened up an opportunity<lb>to alleviate this problem. In this study, a SVM-based Sequen-<lb>tial Classifier Training (SCT-SVM) approach is proposed for<lb>multitemporal remote sensing image classification. The approach<lb>leverages the classifiers of previous images to reduce the required<lb>number of training samples for the classifier training of an<lb>incoming image. For each incoming image, a rough classifier<lb>is firstly predicted based on the temporal trend of a set of<lb>previous classifiers. The predicted classifier is then fine-tuned<lb>into a more accurate position with current training samples. This<lb>approach can be applied progressively to sequential image data,<lb>with only a small number of training samples being required<lb>from each image. Experiments were conducted with Sentinel-2A<lb>multitemporal data over an agricultural area in Australia. Results<lb>showed that the proposed SCT-SVM achieved better classification<lb>accuracies compared with two state-of-the-art model transfer<lb>algorithms. Compared with those obtained without the assistance<lb>from previous images, the overall classification accuracy was<lb>improved from 76.2% to 93.8%, demonstrating that the lever-<lb>age of a priori information from previous images can provide<lb>advantageous assistance for later images in multitemporal image<lb>classification.",
            "output": [
                "Effective Sequential Classifier Training for Multitemporal Remote Sensing Image Classification"
            ]
        },
        {
            "id": "task1540-ddabc353bf80418cbefde2318fe300fe",
            "input": "In this work we introduce a convolutional neural network (CNN) that jointly handles low-, mid-, and high-level vision tasks in a unified architecture that is trained end-to-end. Such a universal network can act like a ‘swiss knife’ for vision tasks; we call this architecture an UberNet to indicate its overarching nature. We address two main technical challenges that emerge when broadening up the range of tasks handled by a single CNN: (i) training a deep architecture while relying on diverse training sets and (ii) training many (potentially unlimited) tasks with a limited memory budget. Properly addressing these two problems allows us to train accurate predictors for a host of tasks, without compromising accuracy. Through these advances we train in an end-to-end manner a CNN that simultaneously addresses (a) boundary detection (b) normal estimation (c) saliency estimation (d) semantic segmentation (e) human part segmentation (f) semantic boundary detection, (g) region proposal generation and object detection. We obtain competitive performance while jointly addressing all of these tasks in 0.7 seconds per frame on a single GPU. A demonstration of this system can be found at cvn.ecp.fr/ubernet/.",
            "output": [
                "UberNet : Training a ‘Universal’ Convolutional Neural Network for Low-, Mid-, and High-Level Vision using Diverse Datasets and Limited Memory"
            ]
        },
        {
            "id": "task1540-ed57436408dd4833b5a06b376756530f",
            "input": "We propose a learning setting in which unlabeled data is free, and the cost of a label depends on its value, which is not known in advance. We study binary classification in an extreme case, where the algorithm only pays for negative labels. Our motivation are applications such as fraud detection, in which investigating an honest transaction should be avoided if possible. We term the setting auditing, and consider the auditing complexity of an algorithm: the number of negative labels the algorithm requires in order to learn a hypothesis with low relative error. We design auditing algorithms for simple hypothesis classes (thresholds and rectangles), and show that with these algorithms, the auditing complexity can be significantly lower than the active label complexity. We also discuss a general competitive approach for auditing and possible modifications to the framework.",
            "output": [
                "Auditing: Active Learning with Outcome-Dependent Query Costs"
            ]
        },
        {
            "id": "task1540-5da0c50136ab48869cacc32d3e91ddf4",
            "input": "Given a graphical model, one essential problem is MAP inference, that is, finding the most likely configuration of states according to the model. Although this problem is NP-hard, large instances can be solved in practice. A major open question is to explain why this is true. We give a natural condition under which we can provably perform MAP inference in polynomial time. We require that the number of fractional vertices in the LP relaxation exceeding the optimal solution is bounded by a polynomial in the problem size. This resolves an open question by Dimakis, Gohari, and Wainwright. In contrast, for general LP relaxations of integer programs, known techniques can only handle a constant number of fractional vertices whose value exceeds the optimal solution. We experimentally verify this condition and demonstrate how efficient various integer programming methods are at removing fractional solutions.",
            "output": [
                "Exact MAP Inference by Avoiding Fractional Vertices"
            ]
        },
        {
            "id": "task1540-80324d83bc1c4f52a1f3e41889a57bee",
            "input": "Attention mechanisms have recently been introduced in deep learning for various tasks in natural language processing and computer vision. But despite their popularity, the “correctness” of the implicitly-learned attention maps has only been assessed qualitatively by visualization of several examples. In this paper we focus on evaluating and improving the correctness of attention in neural image captioning models. Specifically, we propose a quantitative evaluation metric for how well the attention maps align with human judgment, using recently released datasets with alignment between regions in images and entities in captions. We then propose novel models with different levels of explicit supervision for learning attention maps during training. The supervision can be strong when alignment between regions and caption entities are available, or weak when only object segments and categories are provided. We show on the popular Flickr30k and COCO datasets that introducing supervision of attention maps during training solidly improves both attention correctness and caption quality.",
            "output": [
                "Attention Correctness in Neural Image Captioning"
            ]
        },
        {
            "id": "task1540-d0c10e13a36f4a29acd087f5be1296fc",
            "input": "Ambiguity is an indisputable and ubiquitous feature of linguistic products. In this article we investigate both the locus of ambiguity in the architecture of Language and the origin of ambiguity in natural communication systems. We locate ambiguity at the externalization branch of Language and we study the emergence of ambiguity in communication through the concept of logical irreversibility and within the framework of Shannon’s information theory. This leads us to a precise and general expression of the intuition behind Zipf’s vocabulary balance in terms of a symmetry equation between the complexities of the coding and the decoding processes that imposes an unavoidable amount of logical uncertainty in natural communication. Accordingly, the emergence of irreversible computations is required if the complexities of the coding and the decoding processes are balanced in a symmetric scenario, which means that the emergence of ambiguous codes is a necessary condition for natural communication to succeed.",
            "output": [
                "On ambiguity. Its locus in the architecture of Language and its origin in efficient communication"
            ]
        },
        {
            "id": "task1540-5cfd1780c4274989a5dc05ca86e45db5",
            "input": "The online Markov decision process (MDP) is a generalization of the classical Markov decision process that incorporates changing reward functions. In this paper, we propose practical online MDP algorithms with policy iteration and theoretically establish a sublinear regret bound. A notable advantage of the proposed algorithm is that it can be easily combined with function approximation, and thus large and possibly continuous state spaces can be efficiently handled. Through experiments, we demonstrate the usefulness of the proposed algorithm.",
            "output": [
                "Online Markov decision processes with policy iteration"
            ]
        },
        {
            "id": "task1540-c24ab63bbff345308af6532cafff687b",
            "input": "The steadily growing use of license-free frequency bands requires reliable coexistence management for deterministic medium utilization. For interference mitigation, proper wireless interference identification (WII) is essential. In this work we propose the first WII approach based upon deep convolutional neural networks (CNNs). The CNN naively learns its features through self-optimization during an extensive data-driven GPU-based training process. We propose a CNN example which is based upon sensing snapshots with a limited duration of 12.8 μs and an acquisition bandwidth of 10 MHz. The CNN differs between 15 classes. They represent packet transmissions of IEEE 802.11 b/g, IEEE 802.15.4 and IEEE 802.15.1 with overlapping frequency channels within the 2.4 GHz ISM band. We show that the CNN outperforms state-ofthe-art WII approaches and has a classification accuracy greater than 95 % for signal-to-noise ratio of at least -5 dB.",
            "output": [
                "Wireless Interference Identification with Convolutional Neural Networks"
            ]
        },
        {
            "id": "task1540-32f865bfe7694f25954f14579bc515db",
            "input": "While influence diagrams have many ad­ vantages as a representation framework for Bayesian decision problems, they have a se­ rious drawback in handling asymmetric de­ cision problems. To be represented in an influence diagram, an asymmetric decision problem must be symmetrized. A consid­ erable amount of unnecessary computation may be involved when a symmetrized influ­ ence diagram is evaluated by conventional al­ gorithms. In this paper we present an ap­ proach for avoiding such unnecessary compu­ tation in influence diagram evaluation.",
            "output": [
                "Solving Asymmetric Decision Problems with Influence Diagrams"
            ]
        },
        {
            "id": "task1540-b345d1fd381d4d778273ae80861cf0b2",
            "input": "We introduce novel mathematical models and algorithms to generate (shortest or k different) explanations for biomedical queries, using answer set programming. We implement these algorithms and integrate them in BIOQUERY-ASP. We illustrate the usefulness of these methods with some complex biomedical queries related to drug discovery, over the biomedical knowledge resources PHARMGKB, DRUGBANK, BIOGRID, CTD, SIDER, DISEASE ONTOLOGY and ORPHADATA.",
            "output": [
                "Generating Explanations for Biomedical Queries"
            ]
        },
        {
            "id": "task1540-1bb1a957525a49c9bb200b31768ea6e5",
            "input": "In this paper, we investigate whether “big-data” is more valuable than “precise” data for the problem of energy disaggregation: the process of breaking down aggregate energy usage on a per-appliance basis. Existing techniques for disaggregation rely on energy metering at a resolution of 1 minute or higher, but most power meters today only provide a reading once per month, and at most once every 15 minutes. In this paper, we propose a new technique called Neighborhood NILM that leverages data from ‘neighbouring’ homes to disaggregate energy given only a single energy reading per month. The key intuition behind our approach is that ‘similar’ homes have ‘similar’ energy consumption on a per-appliance basis. Neighborhood NILM matches every home with a set of ‘neighbours’ that have direct submetering infrastructure, i.e. power meters on individual circuits or loads. Many such homes already exist. Then, it estimates the appliance-level energy consumption of the target home to be the average of its K neighbours. We evaluate this approach using 25 homes and results show that our approach gives comparable or better disaggregation in comparison to state-of-the-art accuracy reported in the literature that depend on manual model training, high frequency power metering, or both. Results show that Neighbourhood NILM can achieve 83% and 79% accuracy disaggregating fridge and heating/cooling loads, compared to 74% and 73% for a technique called FHMM. Furthermore, it achieves up to 64% accuracy on washing machine, dryer, dishwasher, and lighting loads, which is higher than previously reported results. Many existing techniques are not able to disaggregate these loads at all. These results indicate a potentially substantial advantage to installing submetering infrastructure in a select few homes rather than installing new high-frequency smart metering infrastructure in all homes.",
            "output": [
                "Neighbourhood NILM: A Big-data Approach to Household Energy Disaggregation"
            ]
        },
        {
            "id": "task1540-0e8834dba8814bb1ac02969237740ae3",
            "input": "Filters in a convolutional network are typically parametrized in a pixel basis. As an orthonormal basis, pixels may represent any arbitrary vector in R. In this paper, we relax this orthonormality requirement and extend the set of viable bases to the generalized notion of frames. When applying suitable frame bases to ResNets on Cifar-10+ we demonstrate improved error rates by substitution only. By exploiting the transformation properties of such generalized bases, we arrive at steerable frames, that allow to continuously transform CNN filters under arbitrary Lie-groups. Further allowing us to locally separate pose from canonical appearance. We implement this in the Dynamic Steerable Frame Network, that dynamically estimates the transformations of filters, conditioned on its input. The derived method presents a hybrid of Dynamic Filter Networks and Spatial Transformer Networks that can be implemented in any convolutional architecture, as we illustrate in two examples. First, we illustrate estimation properties of steerable frames with a Dynamic Steerable Frame Network, compared to a Dynamic Filter Network on the task of edge detection, where we show clear advantages of the derived steerable frames. Lastly, we insert the Dynamic Steerable Frame Network as a module in a convolutional LSTM on the task of limited-data hand-gesture recognition from video and illustrate effective dynamic regularization and show clear advantages over Spatial Transformer Networks. In this paper, we have laid out the foundations of Frame-based convolutional networks and Dynamic Steerable Frame Networks while illustrating their advantages for continuously transforming features and data-efficient learning.",
            "output": [
                "DYNAMIC STEERABLE FRAME NETWORKS"
            ]
        },
        {
            "id": "task1540-ec56db0df3a148d29243cc86709ad930",
            "input": "This paper aims to find an algorithmic structure that affords to predict and explain the economical choice behaviour particularly under uncertainty(random policies) by manipulating the prevalent Actor-Critic learning method to comply with the requirements we have been entrusted ever since the field of neuroeconomics dawned on us. Whilst skimming some basics of neuroeconomics that might be relevant to our discussion, we will try to outline some of the important works which have so far been presented to simulate choice making processes. Concerning neurological findings that suggest the existence of two specific functions, namely, ’rewards’ and ’beliefs’ that are executed through a specific pathway from Basal Ganglia all the way up to subcortical areas, we will offer a modified version of actor/critic algorithm to shed a light on the relation between these functions and most importantly resolve what is referred to as a challenge for actor-critic algorithms, that is lack of inheritance or hierarchy which avoids the system being evolved in continuous time tasks whence the convergence might not be emerged. Keywords—neuroeconomics, choice behaviour, actor-critic algorithm, decision making, reinforcement learning",
            "output": [
                "A Supervised Goal Directed Algorithm in Economical Choice Behaviour: An Actor-Critic Approach"
            ]
        },
        {
            "id": "task1540-07122f0ab92743a39b7d617557ce91d4",
            "input": "Language models (LMs) are statistical models that calculate probabilities over sequences of words or other discrete symbols. Currently two major paradigms for language modeling exist: count-based n-gram models, which have advantages of scalability and test-time speed, and neural LMs, which often achieve superior modeling performance. We demonstrate how both varieties of models can be unified in a single modeling framework that defines a set of probability distributions over the vocabulary of words, and then dynamically calculates mixture weights over these distributions. This formulation allows us to create novel hybrid models that combine the desirable features of count-based and neural LMs, and experiments demonstrate the advantages of these approaches.",
            "output": [
                "Generalizing and Hybridizing Count-based and Neural Language Models"
            ]
        },
        {
            "id": "task1540-57c4190addb04f45b5b0241d4fe5aea4",
            "input": "Knowledge representation and reasoning capacities are vital to cognitive robotics because they provide higher level cognitive functions for reasoning about actions, environments, goals, perception, etc. Although Answer Set Programming (ASP) is well suited for modelling such functions, there was so far no seamless way to use ASP in a robotic environment. We address this shortcoming and show how a recently developed reactive ASP system can be harnessed to provide appropriate reasoning capacities within a robotic system. To be more precise, we furnish a package integrating the reactive ASP solver oClingo with the popular open-source robotic middleware ROS. The resulting system, ROSoClingo, provides a generic way by which an ASP program can be used to control the behaviour of a robot and to respond to the results of the robot’s actions.",
            "output": [
                "ROSoClingo: A ROS package for ASP-based robot control"
            ]
        },
        {
            "id": "task1540-1e7c7514c81c468ba632f41f20fd685a",
            "input": "Recent work on embedding ontology concepts has relied on either expensive manual annotation or automated concept tagging methods that ignore the textual contexts around concepts. We propose a novel method for jointly learning concept, phrase, and word embeddings from an unlabeled text corpus, by using the representative phrases for ontology concepts as distant supervision. We learn embeddings for medical concepts in the Unified Medical Language System and generaldomain concepts in YAGO, using a variety of corpora. Our embeddings show performance competitive with existing methods on concept similarity and relatedness tasks, while requiring no human corpus annotation and demonstrating more than 3x coverage in the vocabulary size.",
            "output": [
                "A Weakly-Supervised Method for Jointly Embedding Concepts, Phrases, and Words"
            ]
        },
        {
            "id": "task1540-eb4ed679349840e2b4c94536cac73fb6",
            "input": "This work aims to investigate the use of deep neural network to detect commercial hobby drones in real-life environments by analyzing their sound data. The purpose of work is to contribute to a system for detecting drones used for malicious purposes, such as for terrorism. Specifically, we present a method capable of detecting the presence of commercial hobby drones as a binary classification problem based on sound event detection. We recorded the sound produced by a few popular commercial hobby drones, and then augmented this data with diverse environmental sound data to remedy the scarcity of drone sound data in diverse environments. We investigated the effectiveness of state-of-the-art event sound classification methods, i.e., a Gaussian Mixture Model (GMM), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN), for drone sound detection. Our empirical results, which were obtained with a testing dataset collected on an urban street, confirmed the effectiveness of these models for operating in a real environment. In summary, our RNN models showed the best detection performance with an F-Score of 0.8009 with 240 ms of input audio with a short processing time, indicating their applicability to real-time detection systems.",
            "output": [
                "Empirical Study of Drone Sound Detection in Real-Life Environment with Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-b966508dfcf24a8d96b396cfe60572eb",
            "input": "This paper presents an approach for transforming data granularity in hierarchical databases for binary decision problems by applying regression to categorical attributes at the lower grain levels. Attributes from a lower hierarchy entity in the relational database have their information content optimized through regression on the categories ́ histogram trained on a small exclusive labelled sample, instead of the usual mode category of the distribution. The paper validates the approach on a binary decision task for assessing the quality of secondary schools focusing on how logistic regression transforms the students ́ and teachers ́ attributes into school attributes. Experiments were carried out on Brazilian schools ́ public datasets via 10-fold crossvalidation comparison of the ranking score produced also by logistic regression. The proposed approach achieved higher performance than the usual distribution mode transformation and equal to the expert weighing approach measured by the maximum Kolmogorov-Smirnov distance and the area under the ROC curve at 0.01 significance level. Keywords—Granularity transformation; Categorical attributes; Educational data mining; Relational databases; Distribution mode; Regression ACM-Classification I.2 ARTIFICIAL INTELLIGENCE H.2.8 Database Applications, J.1 ADMINISTRATIVE DATA PROCESSING-Education;",
            "output": [
                "Optimal Categorical Attribute Transformation for Granularity Change in Relational Databases for Binary Decision Problems in Educational Data Mining"
            ]
        },
        {
            "id": "task1540-a107194479ce4f20aa9ecb3334e2225f",
            "input": "In this paper, we use evidence-specific value ab­ straction for speeding Bayesian networks infer­ ence. This is done by grouping variable val­ ues and treating the combined values as a sin­ gle entity. As we show, such abstractions can ex­ ploit regularities in conditional probability distri­ butions and also the specific values of observed variables. To formally justify value abstraction, we defi ne the notion of safe value abstraction and devise inference algorithms that use it to re­ duce the cost of inference. Our procedure is par­ ticularly useful for learning complex networks with many hidden variables. In such cases, re­ peated likelihood computations are required for E M or other parameter optimization techniques. Since these computations are repeated with re­ spect to the same evidence set, our methods can provide signifi cant speedup to the learning pro­ cedure. We demonstrate the algorithm on genetic linkage problems where the use of value abstrac­ tion sometimes differentiates between a feasible and non-feasible solution.",
            "output": [
                "Likelihood Computations Using Value Abstraction"
            ]
        },
        {
            "id": "task1540-e9c0746fda5f4d728a01ab4d46f15f0c",
            "input": "Natural language correction has the potential to help language learners improve their writing skills. While approaches with separate classifiers for different error types have high precision, they do not flexibly handle errors such as redundancy or non-idiomatic phrasing. On the other hand, word and phrase-based machine translation methods are not designed to cope with orthographic errors, and have recently been outpaced by neural models. Motivated by these issues, we present a neural network-based approach to language correction. The core component of our method is an encoder-decoder recurrent neural network with an attention mechanism. By operating at the character level, the network avoids the problem of out-of-vocabulary words. We illustrate the flexibility of our approach on dataset of noisy, user-generated text collected from an English learner forum. When combined with a language model, our method achieves a state-of-the-art F0.5-score on the CoNLL 2014 Shared Task. We further illustrate that training the network on additional data with synthesized errors can improve performance.",
            "output": [
                "Neural Language Correction with Character-Based Attention"
            ]
        },
        {
            "id": "task1540-74459495840146fe8835f6f9890e8412",
            "input": "Alignment-free sequence analysis approaches provide important alternatives over multiple sequence alignment (MSA) in biological sequence analysis because alignment-free approaches have low computation complexity and are not dependent on high level of sequence identity, however, most of the existing alignment-free methods do not employ true full information content of sequences and thus can not accurately reveal similarities and differences among DNA sequences. We present a novel alignment-free computational method for sequence analysis based on Ramanujan-Fourier transform (RFT), in which complete information of DNA sequences is retained. We represent DNA sequences as four binary indicator sequences and apply RFT on the indicator sequences to convert them into frequency domain. The Euclidean distance of the complete RFT coefficients of DNA sequences are used as similarity measure. To address the different lengths in Euclidean space of RFT coefficients, we pad zeros to short DNA binary sequences so that the binary sequences equal the longest length in the comparison sequence data. Thus, the DNA sequences are compared in the same dimensional frequency space without information loss. We demonstrate the usefulness of the proposed method by presenting experimental results on hierarchical clustering of genes and genomes. The proposed method opens a new channel to biological sequence analysis, classification, and structural module identification.",
            "output": [
                "A Novel Method for Comparative Analysis of DNA Sequences by Ramanujan-Fourier Transform"
            ]
        },
        {
            "id": "task1540-1560c5df33cc46269bab0834e5fcc753",
            "input": "Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem. Unfortunately, existing automatic evaluation metrics are biased and correlate very poorly with human judgements of response quality (Liu et al., 2016). Yet having an accurate automatic evaluation procedure is crucial for dialogue research, as it allows rapid prototyping and testing of new models with fewer expensive human evaluations. In response to this challenge, we formulate automatic dialogue evaluation as a learning problem. We present an evaluation model (ADEM) that learns to predict human-like scores to input responses, using a new dataset of human response scores. We show that the ADEM model’s predictions correlate significantly, and at a level much higher than word-overlap metrics such as BLEU, with human judgements at both the utterance and system-level. We also show that ADEM can generalize to evaluating dialogue models unseen during training, an important step for automatic dialogue evaluation.",
            "output": [
                "Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses"
            ]
        },
        {
            "id": "task1540-a48eaef40d144251b9b6de5b8908c91b",
            "input": "The Frank-Wolfe method (a.k.a. conditional gradient algorithm) for smooth optimization has regained much interest in recent years in the context of large scale optimization and machine learning. A key advantage of the method is that it avoids projections the computational bottleneck in many applications replacing it by a linear optimization step. Despite this advantage, the known convergence rates of the FW method fall behind standard first order methods for most settings of interest. It is an active line of research to derive faster linear optimization-based algorithms for various settings of convex optimization. In this paper we consider the special case of optimization over strongly convex sets, for which we prove that the vanila FW method converges at a rate of 1 t2 . This gives a quadratic improvement in convergence rate compared to the general case, in which convergence is of the order 1t , and known to be tight. We show that various balls induced by `p norms, Schatten norms and group norms are strongly convex on one hand and on the other hand, linear optimization over these sets is straightforward and admits a closed-form solution. We further show how several previous fastrate results for the FW method follow easily from our analysis.",
            "output": [
                "Faster Rates for the Frank-Wolfe Method over Strongly-Convex Sets"
            ]
        },
        {
            "id": "task1540-bf52a2a7cdbd48afb2af1299035f193c",
            "input": "This paper is concerned with algorithms for prediction of discrete sequences over a finite alphabet, using variable order Markov models. The class of such algorithms is large and in principle includes any lossless compression algorithm. We focus on six prominent prediction algorithms, including Context Tree Weighting (CTW), Prediction by Partial Match (PPM) and Probabilistic Suffix Trees (PSTs). We discuss the properties of these algorithms and compare their performance using real life sequences from three domains: proteins, English text and music pieces. The comparison is made with respect to prediction quality as measured by the average log-loss. We also compare classification algorithms based on these predictors with respect to a number of large protein classification tasks. Our results indicate that a “decomposed” CTW (a variant of the CTW algorithm) and PPM outperform all other algorithms in sequence prediction tasks. Somewhat surprisingly, a different algorithm, which is a modification of the Lempel-Ziv compression algorithm, significantly outperforms all algorithms on the protein classification problems.",
            "output": [
                "On Prediction Using Variable Order Markov Models"
            ]
        },
        {
            "id": "task1540-7573cdf0dbf44d82bef139cc40619787",
            "input": "This paper reviews related work and state-of-the-art publications for recognizing motor symptoms of Parkinson's Disease (PD). It presents research efforts that were undertaken to inform on how well traditional machine learning algorithms can handle this task. In particular, four PD related motor symptoms are highlighted (i.e. tremor, bradykinesia, freezing of gait and dyskinesia) and their details summarized. Thus the primary objective of this research is to provide a literary foundation for development and improvement of algorithms for detecting PD related motor symptoms.",
            "output": [
                "PARKINSON'S DISEASE MOTOR SYMPTOMS IN MACHINE LEARNING: A REVIEW"
            ]
        },
        {
            "id": "task1540-dc6307a76c8443e484c6487099f692dc",
            "input": "A commonly used technique for managing AI complexity in real-time strategy (RTS) games is to use action and/or state abstractions. High-level abstractions can often lead to goodions. High-level abstractions can often lead to good strategic decision making, but tactical decision quality may suffer due to lost details. A competing method is to sample the search space which often leads to good tactical performance in simple scenarios, but poor high-level planning. We propose to use a deep convolutional neural network (CNN) to select among a limited set of abstract action choices, and to utilize the remaining computation time for game tree search to improve low level tactics. The CNN is trained by supervised learning on game states labelled by Puppet Search, a strategic search algorithm that uses action abstractions. The network is then used to select a script — anions. The network is then used to select a script — an abstract action — to produce low level actions for all units.action — to produce low level actions for all units. Subsequently, the game tree search algorithm improves the tactical actions of a subset of units using a limited view of the game state only considering units close to opponent units. Experiments in the μRTS game show that the combined algorithm results in higher win-rates than either of its two independent components and other state-of-the-art μRTS agents. To the best of our knowledge, this is the first successful application of a convolutional network to play a full RTS game on standard game maps, as previous work has focused on subproblems, such as combat, or on very small maps.",
            "output": [
                "Combining Strategic Learning and Tactical Search in Real-Time Strategy Games"
            ]
        },
        {
            "id": "task1540-9ac80d11d13b499081289e9afbc02a6c",
            "input": "We introduce Universum learning [1], [2] for multiclass problems and propose a novel formulation for multiclass universum SVM (MU-SVM). We also propose a span bound for MU-SVM that can be used for model selection thereby avoiding resampling. Empirical results demonstrate the effectiveness of MU-SVM and the proposed bound.",
            "output": [
                "Universum Learning for Multiclass SVM"
            ]
        },
        {
            "id": "task1540-fef67d2733e84925b0870a6e08bc9f55",
            "input": "We study the problem of Robust Least Squares Regression (RLSR) where several response variables can be adversarially corrupted. More specifically, for a data matrix X ∈ Rp×n and an underlying model w∗, the response vector is generated as y = XTw∗+b where b ∈ R is the corruption vector supported over at most C ·n coordinates. Existing exact recovery results for RLSR focus solely on L1-penalty based convex formulations and impose relatively strict model assumptions such as requiring the corruptions b to be selected independently of X. In this work, we study a simple hard-thresholding algorithm called Torrent which, under mild conditions on X, can recover w∗ exactly even if b corrupts the response variables in an adversarial manner, i.e. both the support and entries of b are selected adversarially after observing X and w∗. Our results hold under deterministic assumptions which are satisfied if X is sampled from any sub-Gaussian distribution. Finally unlike existing results that apply only to a fixed w∗, generated independently of X, our results are universal and hold for any w∗ ∈ R. Next, we propose gradient descent-based extensions of Torrent that can scale efficiently to large scale problems, such as high dimensional sparse recovery and prove similar recovery guarantees for these extensions. Empirically we find Torrent, and more so its extensions, offering significantly faster recovery than the state-of-the-art L1 solvers. For instance, even on moderate-sized datasets (with p = 50K) with around 40% corrupted responses, a variant of our proposed method called Torrent-HYB is more than 20× faster than the best L1 solver. “If among these errors are some which appear too large to be admissible, then those equations which produced these errors will be rejected, as coming from too faulty experiments, and the unknowns will be determined by means of the other equations, which will then give much smaller errors.” A. M. Legendre, On the Method of Least Squares. 1805.",
            "output": [
                "Robust Regression via Hard Thresholding"
            ]
        },
        {
            "id": "task1540-e24336da753b4d069358fc7d310d88a1",
            "input": "The ability to accurately perceive whether a speaker is asking a question or is making a statement is crucial for any successful interaction. However, learning and classifying tonal patterns has been a challenging task for automatic speech recognition and for models of tonal representation, as tonal contours are characterized by significant variation. This paper provides a classification model of Cypriot Greek questions and statements. We evaluate two state-of-the-art network architectures: a Long Short-Term Memory (LSTM) network and a convolutional network (ConvNet). The ConvNet outperforms the LSTM in the classification task and exhibited an excellent performance with 95% classification accuracy.",
            "output": [
                "Modelling prosodic structure using Artificial Neural Networks Modelling prosodic structure using Artificial Neural Networks"
            ]
        },
        {
            "id": "task1540-1894857b6ad14bd5aa33d2540dc0bc4f",
            "input": "Bayesian networks offer great potential for use in automating large scale diagnostic rea­ soning tasks. Gibbs sampling is the main technique used to perform diagnostic reason­ ing in large richly interconnected Bayesian networks. Unfortunately Gibbs sampling can take an excessive time to generate a represen­ tative sample. In this paper we describe and test a number of heuristic strategies for im­ proving sampling in noisy-or Bayesian net­ works. The strategies include Monte Carlo Markov chain sampling techniques other than Gibbs sampling. Emphasis is put on strate­ gies that can be implemented in distributed systems.",
            "output": [
                "Improved Sampling for Diagnostic Reasoning in Bayesian Networks"
            ]
        },
        {
            "id": "task1540-7ffcc3efe9f74548a8b3a61c5d41bc1b",
            "input": "The concept of movable evidence masses that flow from supersets to subsets as specified by experts represents a suitable framework for reasoning under uncertainty. The mass flow is controlled by specialization matrices. New evidence is integrated into the frame of discernment by conditioning or revision (Dempster's rule of conditioning), for which special specialization matrices exist. Even some aspects of non-monotonic reasoning can be represented by certain specialization matrices.",
            "output": [
                "Reasoning with Mass Distributions"
            ]
        },
        {
            "id": "task1540-814c95bad9524c0abafbb2a9c03bda44",
            "input": "We propose a method for learning from streaming visual data using a compact, constant size representation of all the data that was seen until a given moment. Specifically, we construct a “coreset” representation of streaming data using a parallelized algorithm, which is an approximation of a set with relation to the squared distances between this set and all other points in its ambient space. We learn an adaptive object appearance model from the coreset tree in constant time and logarithmic space and use it for object tracking by detection. Our method obtains excellent results for object tracking on three standard datasets over more than 100 videos. The ability to summarize data efficiently makes our method ideally suited for tracking in long videos in presence of space and time constraints. We demonstrate this ability by outperforming a variety of algorithms on the TLD dataset with 2685 frames on average. This coreset based learning approach can be applied for both real-time learning of small, varied data and fast learning of big data.",
            "output": [
                "Coreset-Based Adaptive Tracking"
            ]
        },
        {
            "id": "task1540-1313b1cb1f304c90a32a45e8b2e4482a",
            "input": "We present a novel natural language generation system for spoken dialogue systems capable of entraining (adapting) to users’ way of speaking, providing contextually appropriate responses. The generator is based on recurrent neural networks and the sequence-to-sequence approach. It is fully trainable from data which include preceding context along with responses to be generated. We show that the context-aware generator yields significant improvements over the baseline in both automatic metrics and a human pairwise preference test.",
            "output": [
                "A Context-aware Natural Language Generator for Dialogue Systems"
            ]
        },
        {
            "id": "task1540-5e0c69dea1304cdb9d850b64be2271b2",
            "input": "Penetration testing is a well-established practical concept for the identification of potentially exploitable security weaknesses and an important component of a security audit. Providing a holistic security assessment for networks consisting of several hundreds hosts is hardly feasible though without some sort of mechanization. Mitigation, prioritizing countermeasures subject to a given budget, currently lacks a solid theoretical understanding and is hence more art than science. In this work, we propose the first approach for conducting comprehensive what-if analyses in order to reason about mitigation in a conceptually well-founded manner. To evaluate and compare mitigation strategies, we use simulated penetration testing, i.e., automated attack-finding, based on a network model to which a subset of a given set of mitigation actions, e.g., changes to the network topology, system updates, configuration changes etc. is applied. We determine optimal combinations that minimize the maximal attacker success (similar to a Stackelberg game), and thus provide a well-founded basis for a holistic mitigation strategy. We show that these what-if analysis models can largely be derived from network scan, public vulnerability databases and manual inspection with various degrees of automation and detail, and we simulate mitigation analysis on networks of different size and vulnerability.",
            "output": [
                "Simulated Penetration Testing and Mitigation Analysis"
            ]
        },
        {
            "id": "task1540-75a1634615454f8280fc7ddc919df5a5",
            "input": "In this paper, we propose an extremely simple deep model for the unsupervised nonlinear dimensionality reduction – deep distributed random samplings. First, its network structure is novel: each layer of the network is a group of mutually independent k-centers clusterings. Second, its learning method is extremely simple: the k centers of each clustering are only k randomly selected examples from the training data; for small-scale data sets, the k centers are further randomly reconstructed by a simple cyclic-shift operation. Experimental results on nonlinear dimensionality reduction show that the proposed method can learn abstract representations on both large-scale and small-scale problems, and meanwhile is much faster than deep neural networks on large-scale problems.",
            "output": [
                "Learning Deep Representations By Distributed Random Samplings"
            ]
        },
        {
            "id": "task1540-cafb84f7982a4a7488ae9e638192e02e",
            "input": "This paper presents generalized probabilistic models for high-order projective dependency parsing and an algorithmic framework for learning these statistical models involving dependency trees. Partition functions and marginals for high-order dependency trees can be computed efficiently, by adapting our algorithms which extend the inside-outside algorithm to higher-order cases. To show the effectiveness of our algorithms, we perform experiments on three languages— English, Chinese and Czech, using maximum conditional likelihood estimation for model training and L-BFGS for parameter estimation. Our methods achieve competitive performance for English, and outperform all previously reported dependency parsers for Chinese and Czech.",
            "output": [
                "Probabilistic Models for High-Order Projective Dependency Parsing"
            ]
        },
        {
            "id": "task1540-25d663ff3fa7496d866fe75447b55a31",
            "input": "Deep Reinforcement Learning (RL) recently emerged as one of the most competitive approaches for learning in sequential decision making problems with fully observable environments, e.g., computer Go. However, very little work has been done in deep RL to handle partially observable environments. We propose a new architecture called Action-specific Deep Recurrent Q-Network (ADRQN) to enhance learning performance in partially observable domains. Actions are encoded by a fully connected layer and coupled with a convolutional observation to form an action-observation pair. The time series of action-observation pairs are then integrated by an LSTM layer that learns latent states based on which a fully connected layer computes Q-values as in conventional Deep QNetworks (DQNs). We demonstrate the effectiveness of our new architecture in several partially observable domains, including flickering Atari games.",
            "output": [
                "On Improving Deep Reinforcement Learning for POMDPs"
            ]
        },
        {
            "id": "task1540-c8f11091aeea44e0bacd352018184f5c",
            "input": "We show that discourse structure, as defined by Rhetorical Structure Theory and provided by an existing discourse parser, benefits text categorization. Our approach uses a recursive neural network and a newly proposed attention mechanism to compute a representation of the text that focuses on salient content, from the perspective of both RST and the task. Experiments consider variants of the approach and illustrate its strengths and weaknesses.",
            "output": [
                "Neural Discourse Structure for Text Categorization"
            ]
        },
        {
            "id": "task1540-3d38b01a5ac44f26b44c13ad3bfc1661",
            "input": "Neural machine translation (NMT) heavily relies on an attention network to produce a context vector for each target word prediction. In practice, we find that context vectors for different target words are quite similar to one another and therefore are insufficient in discriminatively predicting target words. The reason for this might be that context vectors produced by the vanilla attention network are just a weighted sum of source representations that are invariant to decoder states. In this paper, we propose a novel GRU-gated attention model (GAtt) for NMT which enhances the degree of discrimination of context vectors by enabling source representations to be sensitive to the partial translation generated by the decoder. GAtt uses a gated recurrent unit (GRU) to combine two types of information: treating a source annotation vector originally produced by the bidirectional encoder as the history state while the corresponding previous decoder state as the input to the GRU. The GRU-combined information forms a new source annotation vector. In this way, we can obtain translation-sensitive source representations which are then feed into the attention network to generate discriminative context vectors. We further propose a variant that regards a source annotation vector as the current input while the previous decoder state as the history. Experiments on NIST Chinese-English translation tasks show that both GAtt-based models achieve significant improvements over the vanilla attentionbased NMT. Further analyses on attention weights and context vectors demonstrate the effectiveness of GAtt in improving the discrimination power of representations and handling the challenging issue of over-translation.",
            "output": [
                "A GRU-Gated Attention Model for Neural Machine Translation"
            ]
        },
        {
            "id": "task1540-039fb05f40f24de5a4981ce9d755cae9",
            "input": "Identifying musical instruments in polyphonic music recordings is a challenging but important problem in the field of music information retrieval. It enables music search by instrument, helps recognize musical genres, or can make music transcription easier and more accurate. In this paper, we present a convolutional neural network framework for predominant instrument recognition in real-world polyphonic music. We train our network from fixed-length music excerpts with a single-labeled predominant instrument and estimate an arbitrary number of predominant instruments from an audio signal with a variable length. To obtain the audio-excerpt-wise result, we aggregate multiple outputs from sliding windows over the test audio. In doing so, we investigated two different aggregation methods: one takes the average for each instrument and the other takes the instrument-wise sum followed by normalization. In addition, we conducted extensive experiments on several important factors that affect the performance, including analysis window size, identification threshold, and activation functions for neural networks to find the optimal set of parameters. Using a dataset of 10k audio excerpts from 11 instruments for evaluation, we found that convolutional neural networks are more robust than conventional methods that exploit spectral features and source separation with support vector machines. Experimental results showed that the proposed convolutional network architecture obtained an F1 measure of 0.602 for micro and 0.503 for macro, respectively, achieving 19.6% and 16.4% in performance improvement compared with other state-of-the-art algorithms.",
            "output": [
                "Deep convolutional neural networks for predominant instrument recognition in polyphonic music"
            ]
        },
        {
            "id": "task1540-a7b15bd48ee44b079531670729be7bf8",
            "input": "Basics 5 Learning Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Task types and creation . . . . . . . . . . . . . . . . . . . . . . . 5 Further settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 Accessing a learning task . . . . . . . . . . . . . . . . . . . . . . 10 Modifying a learning task . . . . . . . . . . . . . . . . . . . . . . 13 Example tasks and convenience functions . . . . . . . . . . . . . 15 Learners . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Constructing a learner . . . . . . . . . . . . . . . . . . . . . . . . 15 Accessing a learner . . . . . . . . . . . . . . . . . . . . . . . . . . 17 Modifying a learner . . . . . . . . . . . . . . . . . . . . . . . . . . 20 Listing learners . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 Training a Learner . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 Accessing learner models . . . . . . . . . . . . . . . . . . . . . . . 23 Further options and comments . . . . . . . . . . . . . . . . . . . 26 Predicting Outcomes for New Data . . . . . . . . . . . . . . . . . . . . 27 Accessing the prediction . . . . . . . . . . . . . . . . . . . . . . . 29 Adjusting the threshold . . . . . . . . . . . . . . . . . . . . . . . 33 Visualizing the prediction . . . . . . . . . . . . . . . . . . . . . . 35 Evaluating Learner Performance . . . . . . . . . . . . . . . . . . . . . 38 Available performance measures . . . . . . . . . . . . . . . . . . . 38 Listing measures . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 Calculate performance measures . . . . . . . . . . . . . . . . . . 40 Access a performance measure . . . . . . . . . . . . . . . . . . . . 41 Binary classification . . . . . . . . . . . . . . . . . . . . . . . . . 42 Resampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Stratified resampling . . . . . . . . . . . . . . . . . . . . . . . . . 47",
            "output": [
                "mlr Tutorial"
            ]
        },
        {
            "id": "task1540-a8cb77345d234fb382918686275e772b",
            "input": "We present a token-level decision summarization framework that utilizes the latent topic structures of utterances to identify “summaryworthy” words. Concretely, a series of unsupervised topic models is explored and experimental results show that fine-grained topic models, which discover topics at the utterance-level rather than the document-level, can better identify the gist of the decisionmaking process. Moreover, our proposed token-level summarization approach, which is able to remove redundancies within utterances, outperforms existing utterance ranking based summarization methods. Finally, context information is also investigated to add additional relevant information to the summary.",
            "output": [
                "Unsupervised Topic Modeling Approaches to Decision Summarization in Spoken Meetings"
            ]
        },
        {
            "id": "task1540-7654f9a6d1404195bc62479b12d43f7d",
            "input": "Autonomous driving has been the subject of increased interest in recent years both in industry and in academia. Serious efforts are being pursued to address legal, technical and logistical problems and make autonomous cars a viable option for everyday transportation. One significant challenge is the time and effort required for the verification and validation of the decision and control algorithms employed in these vehicles to ensure a safe and comfortable driving experience. Hundreds of thousands of miles of driving tests are required to achieve a well calibrated control system that is capable of operating an autonomous vehicle in an uncertain traffic environment where multiple interactions between vehicles and drivers simultaneously occur. Traffic simulators where these interactions can be modeled and represented with reasonable fidelity can help decrease the time and effort necessary for the development of the autonomous driving control algorithms by providing a venue where acceptable initial control calibrations can be achieved quickly and safely before actual road tests. In this paper, we present a gametheoretic traffic model that can be used to 1) test and compare various autonomous vehicle decision and control systems and 2) calibrate the parameters of an existing control system. We demonstrate two example case studies, where, in the first case, we test and quantitatively compare two autonomous vehicle control systems in terms of their safety and performance, and, in the second case, we optimize the parameters of an autonomous vehicle control system, utilizing the proposed traffic model and simulation environment.",
            "output": [
                "Game-Theoretic Modeling of Driver and Vehicle Interactions for Verification and Validation of Autonomous Vehicle Control Systems"
            ]
        },
        {
            "id": "task1540-fdbea99ac8e943088229e2b210e967b4",
            "input": "Cold start problem in Collaborative Filtering can be solved by asking new users to rate a small seed set of representative items or by asking representative users to rate a new item. The question is how to build a seed set that can give enough preference information for making good recommendations. One of the most successful approaches, called Representative Based Matrix Factorization, is based on Maxvol algorithm. Unfortunately, this approach has one important limitation — a seed set of a particular size requires a rating matrix factorization of fixed rank that should coincide with that size. This is not necessarily optimal in the general case. In the current paper, we introduce a fast algorithm for an analytical generalization of this approach that we call Rectangular Maxvol. It allows the rank of factorization to be lower than the required size of the seed set. Moreover, the paper includes the theoretical analysis of the method’s error, the complexity analysis of the existing methods and the comparison to the state-of-the-art approaches.",
            "output": [
                "Efficient Rectangular Maximal-Volume Algorithm for Rating Elicitation in Collaborative Filtering"
            ]
        },
        {
            "id": "task1540-6f69b82510e04d0a9ebfeef23c1f4cf4",
            "input": "The paper focuses on the problem of learning saccades enabling visual object search. The developed system combines reinforcement learning with a neural network for learning to predict the possible outcomes of its actions. We validated the solution in three types of environment consisting of (pseudo)-randomly generated matrices of digits. The experimental verification is followed by the discussion regarding elements required by systems mimicking the fovea movement and possible further research directions.",
            "output": [
                "Utilization of Deep Reinforcement Learning for saccadic-based object visual search"
            ]
        },
        {
            "id": "task1540-b2cc8691302a437ea58e613777562bec",
            "input": "In this paper we propose a structural parameter of CNF formulas and use it to identify instances of weighted MaxSAT and #SAT that can be solved in polynomial time. Given a CNF formula we say that a set of clauses is precisely satisfiable if there is some complete assignment satisfying these clauses only. Let the ps-value of the formula be the number of precisely satisfiable sets of clauses. Applying the notion of branch decompositions to CNF formulas and using ps-value as cut function, we define the ps-width of a formula. For a formula given with a decomposition of polynomial ps-width we show dynamic programming algorithms solving weighted MaxSAT and #SAT in polynomial time. Combining with results of ’Belmonte and Vatshelle, Graph classes with structured neighborhoods and algorithmic applications, Theor. Comput. Sci. 511: 54-65 (2013)’ we get polynomial-time algorithms solving weighted MaxSAT and #SAT for some classes of structured CNF formulas. For example, we get O(m(m + n)s) algorithms for formulas F of m clauses and n variables and size s, if F has a linear ordering of the variables and clauses such that for any variable x occurring in clause C, if x appears before C then any variable between them also occurs in C, and if C appears before x then x occurs also in any clause between them. Note that the class of incidence graphs of such formulas do not have bounded clique-width.",
            "output": [
                "Solving MaxSAT and #SAT on structured CNF formulas"
            ]
        },
        {
            "id": "task1540-d9b3b234e85a4855bceac865465c3bf8",
            "input": "We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution of the Markov chain is conditional on the previous state, generally involving a small move, so this conditional distribution has fewer dominant modes, being unimodal in the limit of small moves. Thus, it is easier to learn because it is easier to approximate its partition function, more like learning to perform supervised function approximation, with gradients that can be obtained by backprop. We provide theorems that generalize recent work on the probabilistic interpretation of denoising autoencoders and obtain along the way an interesting justification for dependency networks and generalized pseudolikelihood, along with a definition of an appropriate joint distribution and sampling mechanism even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. We validate these theoretical results with experiments on two image datasets using an architecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows training to proceed with simple backprop, without the need for layerwise pretraining. P(X)",
            "output": [
                "Deep Generative Stochastic Networks Trainable by Backprop"
            ]
        },
        {
            "id": "task1540-7845fade6fc74038879f39e7dea2efe3",
            "input": "In a recent article, Christiansen and Chater (2015) present a fundamental constraint on language, i.e. a now-or-never bottleneck that arises from our fleeting memory, and explore its implications, e.g., chunk-and-pass processing, outlining a framework that promises to unify different areas of research. Here we explore additional support for this constraint and suggest further connections from quantitative linguistics and information theory.",
            "output": [
                "A commentary on “The now-or-never bottleneck: a fundamental constraint on language”, by Christiansen and Chater (2015)"
            ]
        },
        {
            "id": "task1540-995b30db122741c7979537e8dc50f875",
            "input": "We present a data-driven approach to the problem of inductive computer program synthesis. Our method learns a probabilistic model for realworld programs from a corpus of existing code. It uses this model during synthesis to automatically infer a posterior distribution over sketches, or syntactic models of the problem to be synthesized. Sketches sampled from this posterior are then used to drive combinatorial synthesis of a program in a high-level programming language. The key technical innovation of our approach — embodied in a system called BAYOU— is utilizing user-supplied evidence as to the program’s desired behavior, along with a Bayesian update, to obtain a posterior distribution over the program’s true, latent specification (indicating user intent), which in turn produces a posterior over possible sketches. As we show experimentally, explicitly modeling uncertainty in specification significantly increases the accuracy of the synthesis algorithm. We evaluate BAYOU’s ability to synthesize Java and Android methods. We find that using just a few example API sequences to communicate user intent, BAYOU can synthesize complex method bodies, some implementing tasks never encountered during training.",
            "output": [
                "Bayesian Sketch Learning for Program Synthesis"
            ]
        },
        {
            "id": "task1540-caaebbd79df54627b7d4f4ff2c780e15",
            "input": "Programming by Example (PBE) targets at automatically inferring a computer program for accomplishing a certain task from sample input and output. In this paper, we propose a deep neural networks (DNN) based PBE model called Neural Programming by Example (NPBE), which can learn from input-output strings and induce programs that solve the string manipulation problems. Our NPBE model has four neural network based components: a string encoder, an input-output analyzer, a program generator, and a symbol selector. We demonstrate the effectiveness of NPBE by training it end-toend to solve some common string manipulation problems in spreadsheet systems. The results show that our model can induce string manipulation programs effectively. Our work is one step towards teaching DNN to generate computer programs.",
            "output": [
                "Neural Programming by Example"
            ]
        },
        {
            "id": "task1540-f4f3f4b1cc514a439ad5c4a31ee9ed0f",
            "input": "We propose a multigrid extension of convolutional neural networks (CNNs). Rather than manipulating representations living on a single spatial grid, our network layers operate across scale space, on a pyramid of tensors. They consume multigrid inputs and produce multigrid outputs; convolutional filters themselves have both within-scale and cross-scale extent. This aspect is distinct from simple multiscale designs, which only process the input at different scales. Viewed in terms of information flow, a multigrid network passes messages across a spatial pyramid. As a consequence, receptive field size grows exponentially with depth, facilitating rapid integration of context. Most critically, multigrid structure enables networks to learn internal attention and dynamic routing mechanisms, and use them to accomplish tasks on which modern CNNs fail. Experiments demonstrate wide-ranging performance advantages of multigrid. On CIFAR image classification, flipping from single to multigrid within standard CNN architectures improves accuracy at modest compute and parameter increase. Multigrid is independent of other architectural choices; we show synergistic results in combination with residual connections. On tasks demanding per-pixel output, gains can be substantial. We show dramatic improvement on a synthetic semantic segmentation dataset. Strikingly, we show that relatively shallow multigrid networks can learn to directly perform spatial transformation tasks, where, in contrast, current CNNs fail. Together, our results suggest that continuous evolution of features on a multigrid pyramid could replace virtually all existing CNN designs.",
            "output": [
                "Neural Multigrid"
            ]
        },
        {
            "id": "task1540-a74ba530cf2245d5a5ed608e87aa954b",
            "input": "An important problem for both graphics and vision is to synthesize novel views of a 3D object from a single image. This is particularly challenging due to the partial observability inherent in projecting a 3D object onto the image space, and the ill-posedness of inferring object shape and pose. However, we can train a neural network to address the problem if we restrict our attention to specific object categories (in our case faces and chairs) for which we can gather ample training data. In this paper, we propose a novel recurrent convolutional encoder-decoder network that is trained end-to-end on the task of rendering rotated objects starting from a single image. The recurrent structure allows our model to capture long-term dependencies along a sequence of transformations. We demonstrate the quality of its predictions for human faces on the Multi-PIE dataset and for a dataset of 3D chair models, and also show its ability to disentangle latent factors of variation (e.g., identity and pose) without using full supervision.",
            "output": [
                "Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis"
            ]
        },
        {
            "id": "task1540-280adb097db9419392550d0d54c2d8b6",
            "input": "We consider the stochastic multi-armed bandit problem with a prior distribution on the reward distributions. We are interested in studying prior-free and prior-dependent regret bounds, very much in the same spirit as the usual distribution-free and distribution-dependent bounds for the non-Bayesian stochastic bandit. Building on the techniques of Audibert and Bubeck [2009] and Russo and Roy [2013] we first show that Thompson Sampling attains an optimal prior-free bound in the sense that for any prior distribution its Bayesian regret is bounded from above by 14 √ nK. This result is unimprovable in the sense that there exists a prior distribution such that any algorithm has a Bayesian regret bounded from below by 1 20 √ nK. We also study the case of priors for the setting of Bubeck et al. [2013] (where the optimal mean is known as well as a lower bound on the smallest gap) and we show that in this case the regret of Thompson Sampling is in fact uniformly bounded over time, thus showing that Thompson Sampling can greatly take advantage of the nice properties of these priors.",
            "output": [
                "Prior-free and prior-dependent regret bounds for Thompson Sampling"
            ]
        },
        {
            "id": "task1540-bc382d6c574d4a5197ca639be5a7aff7",
            "input": "Constrained counting is important in domains ranging from artificial intelligence to software analysis. There are already a few approaches for counting models over various types of constraints. Recently, hashing-based approaches achieve both theoretical guarantees and scalability, but still rely on solution enumeration. In this paper, a new probabilistic polynomial time approximate model counter is proposed, which is also a hashing-based universal framework, but with only satisfiability queries. A variant with a dynamic stopping criterion is also presented. Empirical evaluation over benchmarks on propositional logic formulas and SMT(BV) formulas shows that the approach is promising.",
            "output": [
                "A New Probabilistic Algorithm for Approximate Model Counting"
            ]
        },
        {
            "id": "task1540-137e5e587450422f8504073b32e0f58a",
            "input": "One weakness of machine-learned NLP models is that they typically perform poorly on out-of-domain data. In this work, we study the task of identifying products being bought and sold in online cybercrime forums, which exhibits particularly challenging cross-domain effects. We formulate a task that represents a hybrid of slot-filling information extraction and named entity recognition and annotate data from four different forums. Each of these forums constitutes its own “fine-grained domain” in that the forums cover different market sectors with different properties, even though all forums are in the broad domain of cybercrime. We characterize these domain differences in the context of a learning-based system: supervised models see decreased accuracy when applied to new forums, and standard techniques for semi-supervised learning and domain adaptation have limited effectiveness on this data, which suggests the need to improve these techniques. We release a dataset of 1,938 annotated posts from across the four forums.1",
            "output": [
                "Identifying Products in Online Cybercrime Marketplaces: A Dataset for Fine-grained Domain Adaptation"
            ]
        },
        {
            "id": "task1540-36d827426dee44e2ac96eb4186b26cc3",
            "input": "The challenge in engaging malware activities involves the correct identification and classification of different malware variants. Various malwares incorporate code obfuscation methods that alters their code signatures effectively countering antimalware detection techniques utilizing static methods and signature database. In this study, we utilized an approach of converting a malware binary into an image and use Random Forest to classify various malware families. The resulting accuracy of 0.9562 exhibits the effectivess of the method in detecting malware.",
            "output": [
                "Random Forest for Malware Classification"
            ]
        },
        {
            "id": "task1540-8493e3d00a36470ba29ce486fec38849",
            "input": "Online fashion sales present a challenging use case for personalized recommendation: Stores offer a huge variety of items in multiple sizes. Small stocks, high return rates, seasonality, and changing trends cause continuous turnover of articles for sale on all time scales. Customers tend to shop rarely, but often buy multiple items at once. We report on backtest experiments with sales data of 100k frequent shoppers at Zalando, Europe’s leading online fashion platform. To model changing customer and store environments, our recommendation method employs a pair of neural networks: To overcome the cold start problem, a feedforward network generates article embeddings in “fashion space,” which serve as input to a recurrent neural network that predicts a style vector in this space for each client, based on their past purchase sequence. We compare our results with a static collaborative filtering approach, and a popularity ranking baseline.",
            "output": [
                "An LSTM-Based Dynamic Customer Model for Fashion Recommendation"
            ]
        },
        {
            "id": "task1540-f096ca5851c8494d8be685db25445449",
            "input": "1 College of Computer, National University of Defense Technology, 410073 Changsha, Hunan, CHINA. plliu@nudt.edu.cn Abstract: Protein-protein interaction extraction is the key precondition of the construction of protein knowledge network, and it is very important for the research in the biomedicine. This paper extracted directional protein-protein interaction from the biological text, using the SVM-based method. Experiments were evaluated on the LLL05 corpus with good results. The results show that dependency features are import for the protein-protein interaction extraction and features related to the interaction word are effective for the interaction direction judgment. At last, we analyzed the effects of different features and planed for the next step.",
            "output": [
                "Automatic Extraction of Protein-Protein Interaction in Literature"
            ]
        },
        {
            "id": "task1540-fc07a62f5e61499db32a71c68a29ebf7",
            "input": "In this paper, we define event expression over sentences of natural language and semantic relations between events. Based on this definition, we formally consider text understanding process having events as basic unit.",
            "output": [
                "Natural Language Understanding Based on Semantic Relations between Sentences"
            ]
        },
        {
            "id": "task1540-1f90c19562074e539409bc08bb3304ad",
            "input": "In this work, we are interested in structure learning for a set of spatially distributed dynamical systems, where individual subsystems are coupled via latent variables and observed through a filter. We represent this model as a directed acyclic graph (DAG) that characterises the unidirectional coupling between subsystems. Standard approaches to structure learning are not applicable in this framework due to the hidden variables, however we can exploit the properties of certain dynamical systems to formulate exact methods based on state space reconstruction. We approach the problem by using reconstruction theorems to analytically derive a tractable expression for the KL-divergence of a candidate DAG from the observed dataset. We show this measure can be decomposed as a function of two informationtheoretic measures, transfer entropy and stochastic interaction. We then present two mathematically robust scoring functions based on transfer entropy and statistical independence tests. These results support the previously held conjecture that transfer entropy can be used to infer effective connectivity in complex networks.",
            "output": [
                "Inferring Coupling of Distributed Dynamical Systems via Transfer Entropy"
            ]
        },
        {
            "id": "task1540-60d8f14886264b748c8ce23fddc6dd72",
            "input": "We introduce the dependent doors problem as an abstraction for situations in which one must perform a sequence of possibly dependent decisions, without receiving feedback information on the effectiveness of previously made actions. Informally, the problem considers a set of d doors that are initially closed, and the aim is to open all of them as fast as possible. To open a door, the algorithm knocks on it and it might open or not according to some probability distribution. This distribution may depend on which other doors are currently open, as well as on which other doors were open during each of the previous knocks on that door. The algorithm aims to minimize the expected time until all doors open. Crucially, it must act at any time without knowing whether or which other doors have already opened. In this work, we focus on scenarios where dependencies between doors are both positively correlated and acyclic. The fundamental distribution of a door describes the probability it opens in the best of conditions (with respect to other doors being open or closed). We show that if in two configurations of d doors corresponding doors share the same fundamental distribution, then these configurations have the same optimal running time up to a universal constant, no matter what are the dependencies between doors and what are the distributions. We also identify algorithms that are optimal up to a universal constant factor. For the case in which all doors share the same fundamental distribution we additionally provide a simpler algorithm, and a formula to calculate its running time. We furthermore analyse the price of lacking feedback for several configurations governed by standard fundamental distributions. In particular, we show that the price is logarithmic in d for memoryless doors, but can potentially grow to be linear in d for other distributions. We then turn our attention to investigate precise bounds. Even for the case of two doors, identifying the optimal sequence is an intriguing combinatorial question. Here, we study the case of two cascading memoryless doors. That is, the first door opens on each knock independently with probability p1. The second door can only open if the first door is open, in which case it will open on each knock independently with probability p2. We solve this problem almost completely by identifying algorithms that are optimal up to an additive term of 1.",
            "output": [
                "The Dependent Doors Problem: An Investigation into Sequential Decisions without Feedback∗"
            ]
        },
        {
            "id": "task1540-e635effc833a4e568fe55406bc6a2cc9",
            "input": "The number of word forms in agglutinative languages is theoretically infinite and this variety in word forms introduces sparsity in many natural language processing tasks. Part-of-speech tagging (PoS tagging) is one of these tasks that often suffers from sparsity. In this paper, we present an unsupervised Bayesian model using Hidden Markov Models (HMMs) for joint PoS tagging and stemming for agglutinative languages. We use stemming to reduce sparsity in PoS tagging. Two tasks are jointly performed to provide a mutual benefit in both tasks. Our results show that joint POS tagging and stemming improves PoS tagging scores. We present results for Turkish and Finnish as agglutinative languages and English as a morphologically poor language.",
            "output": [
                "Joint PoS Tagging and Stemming for Agglutinative Languages"
            ]
        },
        {
            "id": "task1540-8acfd1b5c96c4713b8f04cd05fc28e29",
            "input": "This paper presents to the best of our knowledge the first end-to-end object tracking approach which directly maps from raw sensor input to object tracks in sensor space without requiring any feature engineering or system identification in the form of plant or sensor models. Specifically, our system accepts a stream of raw sensor data at one end and, in real-time, produces an estimate of the entire environment state at the output including even occluded objects. We achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks. In particular, we propose a learning method based on a form of input dropout which allows learning in an unsupervised manner, only based on raw, occluded sensor data without access to ground-truth annotations. We demonstrate our approach using a synthetic dataset designed to mimic the task of tracking objects in 2D laser data – as commonly encountered in robotics applications – and show that it learns to track many dynamic objects despite occlusions and the presence of sensor noise.",
            "output": [
                "Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-6b1918dec9f44eadbe43b52deb651219",
            "input": "Chinese characters can be compared to a molecular structure: a character is analogous to a molecule, radicals are like atoms, calligraphic strokes correspond to elementary particles, and when characters form compounds, they are like molecular structures. In chemistry the conjunction of all of these structural levels produces what we perceive as matter. In language, the conjunction of strokes, radicals, characters, and compounds produces meaning. But when does meaning arise? We all know that radicals are, in some sense, the basic semantic components of Chinese script, but what about strokes? Considering the fact that many characters are made by adding individual strokes to (combinations of) radicals, we can legitimately ask the question whether strokes carry meaning, or not. In this talk I will present my project of extending traditional NLP techniques to radicals and strokes, aiming to obtain a deeper understanding of the way ideographic languages model the world.",
            "output": [
                "Seeking Meaning in a Space Made out of Strokes, Radicals, Characters and Compounds"
            ]
        },
        {
            "id": "task1540-4acb781c42884f66a5b4ff2f7d324493",
            "input": "We introduce a simple new regularizer for auto-encoders whose hidden-unit activation functions contain at least one zero-gradient (saturated) region. This regularizer explicitly encourages activations in the saturated region(s) of the corresponding activation function. We call these Saturating Auto-Encoders (SATAE). We show that the saturation regularizer explicitly limits the SATAE’s ability to reconstruct inputs which are not near the data manifold. Furthermore, we show that a wide variety of features can be learned when different activation functions are used. Finally, connections are established with the Contractive and Sparse Auto-Encoders.",
            "output": [
                "Saturating Auto-Encoder"
            ]
        },
        {
            "id": "task1540-711cb6357e884cfc9be2f44d08bd9f6d",
            "input": "Latent variable models are a fundamental modeling tool in machine learning applications, but they present significant computational and analytical challenges. The popular EM algorithm and its variants, is a much used algorithmic tool; yet our rigorous understanding of its performance is highly incomplete. Recently, work in Balakrishnan et al. (2014) has demonstrated that for an important class of problems, EM exhibits linear local convergence. In the high-dimensional setting, however, the M -step may not be well defined. We address precisely this setting through a unified treatment using regularization. While regularization for high-dimensional problems is by now well understood, the iterative EM algorithm requires a careful balancing of making progress towards the solution while identifying the right structure (e.g., sparsity or low-rank). In particular, regularizing the M -step using the state-of-the-art high-dimensional prescriptions (e.g., à la Wainwright (2014)) is not guaranteed to provide this balance. Our algorithm and analysis are linked in a way that reveals the balance between optimization and statistical errors. We specialize our general framework to sparse gaussian mixture models, high-dimensional mixed regression, and regression with missing variables, obtaining statistical guarantees for each of these examples.",
            "output": [
                "Regularized EM Algorithms: A Unified Framework and Statistical Guarantees"
            ]
        },
        {
            "id": "task1540-3bca5f440cc34379b6afe2f8b8178b36",
            "input": "In this short note, we present an extension of long short-term memory (LSTM) neural networks to using a depth gate to connect memory cells of adjacent layers. Doing so introduces a linear dependence between lower and upper layer recurrent units. Importantly, the linear dependence is gated through a gating function, which we call depth gate. This gate is a function of the lower layer memory cell, the input to and the past memory cell of this layer. We conducted experiments and verified that this new architecture of LSTMs was able to improve machine translation and language modeling performances.",
            "output": [
                "Depth-Gated LSTM"
            ]
        },
        {
            "id": "task1540-f6eb078cf6764b76bb3d9814414f3b07",
            "input": "Data cleaning is often an important step to ensure that predictive models, such as regression and classification, are not affected by systematic errors such as inconsistent, out-of-date, or outlier data. Identifying dirty data is often a manual and iterative process, and can be challenging on large datasets. However, many data cleaning workflows can introduce subtle biases into the training processes due to violation of independence assumptions. We propose ActiveClean, a progressive cleaning approach where the model is updated incrementally instead of re-training and can guarantee accuracy on partially cleaned data. ActiveClean supports a popular class of models called convex loss models (e.g., linear regression and SVMs). ActiveClean also leverages the structure of a user’s model to prioritize cleaning those records likely to affect the results. We evaluate ActiveClean on five real-world datasets UCI Adult, UCI EEG, MNIST, Dollars For Docs, and WorldBank with both real and synthetic errors. Our results suggest that our proposed optimizations can improve model accuracy by up-to 2.5x for the same amount of data cleaned. Furthermore for a fixed cleaning budget and on all real dirty datasets, ActiveClean returns more accurate models than uniform sampling and Active Learning.",
            "output": [
                "ActiveClean: Interactive Data Cleaning While Learning Convex Loss Models"
            ]
        },
        {
            "id": "task1540-7310c4a297a846dfa4cf65fab91f560f",
            "input": "In 2014, Amin, Heidari, and Kearns proved that tree networks can be learned by observing only the infected set of vertices of the contagion process under the independent cascade model, in both the active and passive query models. They also showed empirically that simple extensions of their algorithms work on sparse networks. In this work, we focus on the active model. We prove that a simple modification of Amin et al.’s algorithm works on more general classes of networks, namely (i) networks with large girth and low path growth rate, and (ii) networks with bounded degree. This also provides partial theoretical explanation for Amin et al.’s experiments on sparse networks.",
            "output": [
                "Learning Network Structures from Contagion"
            ]
        },
        {
            "id": "task1540-5d05e620fe7141299aceb11de78999df",
            "input": "This paper explores several techniques for enhancing coverage when parsing with HPSG grammars, determines appropriate evaluation methods, and uses them to compare performance. Depending on the dataset, baseline coverage gaps can be reduced by between 75% and 100%, while simultaneously improving EDM F1 scores.",
            "output": [
                "A Comparison of Robust Parsing Methods for HPSG"
            ]
        },
        {
            "id": "task1540-7841119445a548aab917213efb5ada0f",
            "input": "This paper considers the problem of learning, from samples, the depen-<lb>dency structure of a system of linear stochastic differential equations,<lb>when some of the variables are latent. In particular, we observe the time<lb>evolution of some variables, and never observe other variables; from this,<lb>we would like to find the dependency structure between the observed vari-<lb>ables – separating out the spurious interactions caused by the (marginal-<lb>izing out of the) latent variables’ time series. We develop a new method,<lb>based on convex optimization, to do so in the case when the number of<lb>latent variables is smaller than the number of observed ones. For the case<lb>when the dependency structure between the observed variables is sparse,<lb>we theoretically establish a high-dimensional scaling result for structure re-<lb>covery. We verify our theoretical result with both synthetic and real data<lb>(from the stock market).",
            "output": [
                "Learning with Latent Factors in Time Series"
            ]
        },
        {
            "id": "task1540-56e9888dfc404c1c91a0b706eec54609",
            "input": "Decision making in uncertain and risky environments is a prominent area of research. Standard economic theories fail to fully explain human behaviour, while a potentially promising alternative may lie in the direction of Reinforcement Learning (RL) theory. We analyse data for 46 players extracted from a financial market online game and test whether Reinforcement Learning (Q-Learning) could capture these players behaviour using a risk measure based on financial modeling. Moreover we test an earlier hypothesis that players are “naı̈ve” (short-sighted). Our results indicate that a simple Reinforcement Learning model which considers only the selling component of the task captures the decision-making process for a subset of players but this is not sufficient to draw any conclusion on the population. We also find that there is not a significant improvement of fitting of the players when using a full RL model against a myopic version, where only immediate reward is valued by the players. This indicates that players, if using a Reinforcement Learning approach, do so naı̈vely.",
            "output": [
                "Modelling Stock-market Investors as Reinforcement Learning Agents [Correction]"
            ]
        },
        {
            "id": "task1540-9f9112c2e40c4958bd512ca40925c924",
            "input": "The Internet of Things is arriving to our homes or cities through fields already known like Smart Homes, Smart Cities, or Smart Towns. The monitoring of environmental conditions of cities can help to adapt the indoor locations of the cities in order to be more comfortable for people who stay there. A way to improve the indoor conditions is an efficient temperature control, however, it depends on many factors like the different combinations of outdoor temperature and humidity. Therefore, adjusting the indoor temperature is not setting a value according to other value. There are many more factors to take into consideration, hence the traditional logic based in binary states cannot be used. Many problems cannot be solved with a set of binary solutions and we need a new way of development. Fuzzy logic is able to interpret many states, more than two states, giving to computers the capacity to react in a similar way to people. In this paper we will propose a new approach to control the temperature using the Internet of Things together its platforms and fuzzy logic regarding not only the indoor temperature but also the outdoor temperature and humidity in order to save energy and to set a more comfortable environment for their users. Finally, ∗Corresponding author Email addresses: danielmeanallorian@gmail.com (Daniel Meana-Llorián), gonzalezgarciacristian@hotmail.com (Cristian González Garćıa), crispelayo@uniovi.es (B. Cristina Pelayo G-Bustelo), cueva@uniovi.es (Juan Manuel Cueva Lovelle), nestor@uniovi.es (Nestor Garcia-Fernandez)",
            "output": [
                "IoFClime: The fuzzy logic and the Internet of Things to control indoor temperature regarding the outdoor ambient conditions"
            ]
        },
        {
            "id": "task1540-ad188fab44c54f6a8d91e1dca12899d5",
            "input": "The present paper deals with word sense induction from lexical co-occurrence graphs. We construct such graphs on large Russian corpora and then apply the data to cluster the results of Mail.ru search according to meanings in the query. We compare different methods of performing such clustering and different source corpora. Models of applying distributional semantics to big linguistic data are described.",
            "output": [
                "Semantic clustering of Russian web search results: possibilities and problems"
            ]
        },
        {
            "id": "task1540-8434df10591e4edc8e9328d72ea401ac",
            "input": "Most current word prediction systems make use of n-gram language models (LM) to estimate the probability of the following word in a phrase. In the past years there have been many attempts to enrich such language models with further syntactic or semantic information. We want to explore the predictive powers of Latent Semantic Analysis (LSA), a method that has been shown to provide reliable information on long-distance semantic dependencies between words in a context. We present and evaluate here several methods that integrate LSA-based information with a standard language model: a semantic cache, partial reranking, and different forms of interpolation. We found that all methods show significant improvements, compared to the 4gram baseline, and most of them to a simple cache model as well.",
            "output": [
                "Methods to integrate a language model with semantic information for a word prediction component"
            ]
        },
        {
            "id": "task1540-c89235b0a5794039add7f92bd2f85c73",
            "input": "Authorship analysis (AA) is the study of unveiling the hidden properties of authors from a body of exponentially exploding textual data. It extracts an author’s identity and sociolinguistic characteristics based on the reflected writing styles in the text. It is an essential process for various areas, such as cybercrime investigation, psycholinguistics, political socialization, etc. However, most of the previous techniques critically depend on the manual feature engineering process. Consequently, the choice of feature set has been shown to be scenarioor dataset-dependent. In this paper, to mimic the human sentence composition process using a neural network approach, we propose to incorporate different categories of linguistic features into distributed representation of words in order to learn simultaneously the writing style representations based on unlabeled texts for authorship analysis. In particular, the proposed models allow topical, lexical, syntactical, and character-level feature vectors of each document to be extracted as stylometrics. We evaluate the performance of our approach on the problems of authorship characterization and authorship verification with the Twitter, novel, and essay datasets. The experiments suggest that our proposed text representation outperforms the bag-of-lexical-n-grams, Latent Dirichlet Allocation, Latent Semantic Analysis, PVDM, PVDBOW, and word2vec representations.",
            "output": [
                "Learning Stylometric Representations for Authorship Analysis"
            ]
        },
        {
            "id": "task1540-ff4f7a672d6543e297a5253f7825e653",
            "input": "This paper presents an adaptation of the harmony search algorithm to solve the storage allocation problem for inbound and outbound containers. This problem is studied considering multiple container type (regular, open side, open top, tank, empty and refrigerated) which lets the situation more complicated, as various storage constraints appeared. The objective is to find an optimal container arrangement which respects their departure dates, and minimize the re-handle operations of containers. The performance of the proposed approach is verified comparing to the results generated by genetic algorithm and LIFO algorithm. General Terms Container storage problem, metaheuristics.",
            "output": [
                "Harmony search to solve the container storage problem with different container types"
            ]
        },
        {
            "id": "task1540-7e2ac7aa7d60480f9f79a163e8e24d90",
            "input": "Event factuality identification plays an important role in deep NLP applications. In this paper, we propose a deep learning framework for this task which first extracts essential information from raw texts as the inputs and then identifies the factuality of events via a deep neural network with a proper combination of Bidirectional Long Short-Term Memory (BiLSTM) neural network and Convolutional Neural Network (CNN). The experimental results on FactBank show that our framework significantly outperforms several state-of-the-art baselines.",
            "output": [
                "Event Factuality Identification via Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-f34a392208eb46438f8e9f44170b148d",
            "input": "Despite their success, convolutional neural networks are computationally expensive because they must examine all image locations. Stochastic attention-based models have been shown to improve computational efficiency at test time, but they remain difficult to train because of intractable posterior inference and high variance in the stochastic gradient estimates. Borrowing techniques from the literature on training deep generative models, we present the Wake-Sleep Recurrent Attention Model, a method for training stochastic attention networks which improves posterior inference and which reduces the variability in the stochastic gradients. We show that our method can greatly speed up the training time for stochastic attention networks in the domains of image classification and caption generation.",
            "output": [
                "Learning Wake-Sleep Recurrent Attention Models"
            ]
        },
        {
            "id": "task1540-63490108ef9f436aa24e0ceef0e64277",
            "input": "Parsing accuracy using efficient greedy transition systems has improved dramatically in recent years thanks to neural networks. Despite striking results in dependency parsing, however, neural models have not surpassed stateof-the-art approaches in constituency parsing. To remedy this, we introduce a new shiftreduce system whose stack contains merely sentence spans, represented by a bare minimum of LSTM features. We also design the first provably optimal dynamic oracle for constituency parsing, which runs in amortized O(1) time, compared to O(n) oracles for standard dependency parsing. Training with this oracle, we achieve the best F1 scores on both English and French of any parser that does not use reranking or external data.",
            "output": [
                "Span-Based Constituency Parsing with a Structure-Label System and Provably Optimal Dynamic Oracles"
            ]
        },
        {
            "id": "task1540-7351b9d8698f407aa0e5fe4ecda5be87",
            "input": "Stemming or suffix stripping, an important part of the modern Information Retrieval systems, is to find the root word (stem) out of a given cluster of words. Existing algorithms targeting this problem have been developed in a haphazard manner. In this work, we model this problem as an optimization problem. An Integer Program is being developed to overcome the shortcomings of the existing approaches. The sample results of the proposed method are also being compared with an established technique in the field for English language. An AMPL code for the same IP has also been given.",
            "output": [
                "Suffix Stripping Problem as an Optimization Problem"
            ]
        },
        {
            "id": "task1540-593662931d0a4e24a0b213eea149eae6",
            "input": "This paper focuses on unsupervised modeling of morphological families, collectively comprising a forest over the language vocabulary. This formulation enables us to capture edgewise properties reflecting single-step morphological derivations, along with global distributional properties of the entire forest. These global properties constrain the size of the affix set and encourage formation of tight morphological families. The resulting objective is solved using Integer Linear Programming (ILP) paired with contrastive estimation. We train the model by alternating between optimizing the local log-linear model and the global ILP objective. We evaluate our system on three tasks: root detection, clustering of morphological families and segmentation. Our experiments demonstrate that our model yields consistent gains in all three tasks compared with the best published results.1",
            "output": [
                "Unsupervised Learning of Morphological Forests"
            ]
        },
        {
            "id": "task1540-fa3028eda03a4ebfab66a139b90b72c2",
            "input": "In this paper, we tackle the problem of extracting frequent opinions from uncertain databases. We introduce the foundation of an opinion mining approach with the definition of pattern and support measure. The support measure is derived from the commitment definition. A new algorithm called OpMiner that extracts the set of frequent opinions modelled as a mass functions is detailed. Finally, we apply our approach on a real-world biomedical database that stores opinions of experts to evaluate the reliability level of biomedical data. Performance analysis showed a better quality patterns for our proposed model in comparison with literature-based methods.",
            "output": [
                "Expert Opinion Extraction from a Biomedical Database"
            ]
        },
        {
            "id": "task1540-21c6e1cb394d40f3adf9e7dd09eba407",
            "input": "The rise of smart applications has drawn interest to logical reasoning over data streams. Recently, different query languages and stream processing/reasoning engines were proposed in different communities. However, due to a lack of theoretical foundations, the expressivity and semantics of these diverse approaches are given only informally. Towards clear specifications and means for analytic study, a formal framework is needed to define their semantics in precise terms. To this end, we present a first step towards an ideal semantics that allows for exact descriptions and comparisons of stream reasoning systems.",
            "output": [
                "Towards Ideal Semantics for Analyzing Stream Reasoning"
            ]
        },
        {
            "id": "task1540-fedc43bb57684c119e8b5cc7b5bf345b",
            "input": "Evolution of visual object recognition architectures based on Convolutional Neural Networks & Convolutional Deep Belief Networks paradigms has revolutionized artificial Vision Science. These architectures extract & learn the real world hierarchical visual features utilizing supervised & unsupervised learning approaches respectively. Both the approaches yet cannot scale up realistically to provide recognition for a very large number of objects as high as 10K. We propose a two level hierarchical deep learning architecture inspired by divide & conquer principle that decomposes the large scale recognition architecture into root & leaf level model architectures. Each of the root & leaf level models is trained exclusively to provide superior results than possible by any 1-level deep learning architecture prevalent today. The proposed architecture classifies objects in two steps. In the first step the root level model classifies the object in a high level category. In the second step, the leaf level recognition model for the recognized high level category is selected among all the leaf models. This leaf level model is presented with the same input object image which classifies it in a specific category. Also we propose a blend of leaf level models trained with either supervised or unsupervised learning approaches. Unsupervised learning is suitable whenever labelled data is scarce for the specific leaf level models. Currently the training of leaf level models is in progress; where we have trained 25 out of the total 47 leaf level models as of now. We have trained the leaf models with the best case top-5 error rate of 3.2% on the validation data set for the particular leaf models. Also we demonstrate that the validation error of the leaf level models saturates towards the above mentioned accuracy as the number of epochs are increased to more than sixty. The top-5 error rate for the entire two-level architecture needs to be computed in conjunction with the error rates of root & all the leaf models. The realization of this two level visual recognition architecture will greatly enhance the accuracy of the large scale object recognition scenarios demanded by the use cases as diverse as drone vision, augmented reality, retail, image search & retrieval, robotic navigation, targeted advertisements etc.",
            "output": [
                "HIERARCHICAL DEEP LEARNING ARCHITECTURE FOR 10K OBJECTS CLASSIFICATION"
            ]
        },
        {
            "id": "task1540-dfb8a8d0eb6c45b5bf5e3ef0ecbfb265",
            "input": "Recently proposed neural network activation functions such as rectified linear, maxout, and local winner-take-all have allowed for faster and more effective training of deep neural architectures on large and complex datasets. The common trait among these functions is that they implement local competition between small groups of units within a layer, so that only part of the network is activated for any given input pattern. In this paper, we attempt to visualize and understand this self-modularization, and suggest a unified explanation for the beneficial properties of such networks. We also show how our insights can be directly useful for efficiently performing retrieval over large datasets using neural networks. A version of this paper was submitted to NIPS 2014 on 06-06-2014",
            "output": [
                "Understanding Locally Competitive Networks"
            ]
        },
        {
            "id": "task1540-0a987800f0224edead47119c14e696da",
            "input": "We present a new algorithm for the contextual bandit learning problem, where the learner repeatedly takes an action in response to the observed context, observing the reward only for that action. Our method assumes access to an oracle for solving cost-sensitive classification problems and achieves the statistically optimal regret guarantee with only Õ( √ T ) oracle calls across all T rounds. By doing so, we obtain the most practical contextual bandit learning algorithm amongst approaches that work for general policy classes. We further conduct a proof-of-concept experiment which demonstrates the excellent computational and prediction performance of (an online variant of) our algorithm relative to several baselines.",
            "output": [
                "Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits"
            ]
        },
        {
            "id": "task1540-5ab2a6dff7b84dd2971d8e34b9ef09d0",
            "input": "Today, with respect to the increasing growth of demand to get credit from the customers of banks and finance and credit institutions, using an effective and efficient method to decrease the risk of non-repayment of credit given is very necessary. Assessment of customers' credit is one of the most important and the most essential duties of banks and institutions, and if an error occurs in this field, it would leads to the great losses for banks and institutions. Thus, using the predicting computer systems has been significantly progressed in recent decades. The data that are provided to the credit institutions' managers help them to make a straight decision for giving the credit or not-giving it. In this paper, we will assess the customer credit through a combined classification using artificial neural networks, genetics algorithm and Bayesian probabilities simultaneously, and the results obtained from three methods mentioned above would be used to achieve an appropriate and final result. We use the K_folds cross validation test in order to assess the method and finally, we compare the proposed method with the methods such as Clustering-Launched Classification (CLC), Support Vector Machine (SVM) as well as GA+SVM where the genetics algorithm has been used to improve them. KeywordsData classification; Combined Clustring; Artificial Neural Networks; Genetics Algorithm; Bayyesian Probabilities.",
            "output": [
                "Assessment of Customer Credit through Combined Clustering of Artificial Neural Networks, Genetics Algorithm and Bayesian Probabilities"
            ]
        },
        {
            "id": "task1540-41066f1d26fd4ff4b263cd89181f9752",
            "input": "Many recent works have demonstrated the benefits of knowledge graph embeddings in completing monolingual knowledge graphs. Inasmuch as related knowledge bases are built in several different languages, achieving cross-lingual knowledge alignment will help people in constructing a coherent knowledge base, and assist machines in dealing with different expressions of entity relationships across diverse human languages. Unfortunately, achieving this highly desirable cross-lingual alignment by human labor is very costly and error-prone. Thus, we propose MTransE, a translationbased model for multilingual knowledge graph embeddings, to provide a simple and automated solution. By encoding entities and relations of each language in a separated embedding space, MTransE provides transitions for each embedding vector to its cross-lingual counterparts in other spaces, while preserving the functionalities of monolingual embeddings. We deploy three different techniques to represent cross-lingual transitions, namely axis calibration, translation vectors, and linear transformations, and derive five variants for MTransE using different loss functions. Our models can be trained on partially aligned graphs, where just a small portion of triples are aligned with their cross-lingual counterparts. The experiments on cross-lingual entity matching and triple-wise alignment verification show promising results, with some variants consistently outperforming others on different tasks. We also explore how MTransE preserves the key properties of its monolingual counterpart TransE.",
            "output": [
                "Multi-lingual Knowledge Graph Embeddings for Cross-lingual Knowledge Alignment"
            ]
        },
        {
            "id": "task1540-4021eeefb56e48d1b9f35486a42187c5",
            "input": "We present a practical approach for processing mobile sensor time series data for continual deep learning predictions. The approach comprises data cleaning, normalization, capping, time-based compression, and finally classification with a recurrent neural network. We demonstrate the effectiveness of the approach in a case study with 279 participants. On the basis of sparse sensor events, the network continually predicts whether the participants would attend to a notification within 10 minutes. Compared to a random baseline, the classifier achieves a 40% performance increase (AUC of 0.702) on a withheld test set. This approach allows to forgo resource-intensive, domain-specific, error-prone feature engineering, which may drastically increase the applicability of machine learning to mobile phone sensor data.",
            "output": [
                "Practical Processing of Mobile Sensor Data for Continual Deep Learning Predictions"
            ]
        },
        {
            "id": "task1540-20f46f51ffbb4b8bbc37a920cedbdc6e",
            "input": "Several generic summarization algorithms were developed in the past and successfully applied in fields such as text and speech summarization. In this paper, we review and apply these algorithms to music. To evaluate this summarization’s performance, we adopt an extrinsic approach: we compare a Fado Genre Classifier’s performance using truncated contiguous clips against the summaries extracted with those algorithms on 2 different datasets. We show that Maximal Marginal Relevance (MMR), LexRank and Latent Semantic Analysis (LSA) all improve classification performance in both datasets used for testing.",
            "output": [
                "On the Application of Generic Summarization Algorithms to Music"
            ]
        },
        {
            "id": "task1540-0247c3e7efd04fabb4f6b30409da60ed",
            "input": "It is now a common practice to compare models of human language processing by predicting participant reactions (such as reading times) to corpora consisting of rich naturalistic linguistic materials. However, many of the corpora used in these studies are based on naturalistic text and thus do not contain many of the low-frequency syntactic constructions that are often required to distinguish processing theories. Here we describe a new corpus consisting of English texts edited to contain many low-frequency syntactic constructions while still sounding fluent to native speakers. The corpus is annotated with hand-corrected parse trees and includes self-paced reading time data. Here we give an overview of the content of the corpus and release the data.1",
            "output": [
                "The Natural Stories Corpus"
            ]
        },
        {
            "id": "task1540-45a4b47fbbc745e9a20acdb80275d96e",
            "input": "Optical Coherence Tomography (OCT) provides a unique ability to image the eye retina in 3D at micrometer resolution and gives ophthalmologist the ability to visualize retinal diseases such as Age-Related Macular Degeneration (AMD). While visual inspection of OCT volumes remains the main method for AMD identification, doing so is time consuming as each cross-section within the volume must be inspected individually by the clinician. In much the same way, acquiring ground truth information for each cross-section is expensive and time consuming. This fact heavily limits the ability to acquire large amounts of groundtruth, which subsequently impacts the performance of learning-based methods geared at automatic pathology identification. To avoid this burden, we propose a novel strategy for automatic analysis of OCT volumes where only volume labels are needed. That is, we train a classifier in a semi-supervised manner to conduct this task. Our approach uses a novel Convolutional Neural Network (CNN) architecture, that only needs volume-level labels to be trained to automatically asses whether an OCT volume is healthy or contains AMD. Our architecture involves first learning a cross-section pathology classifier using pseudo-labels that could be corrupted and then leverage these towards a more accurate volume-level classification. We then show that our approach provides excellent performances on a publicly available dataset and outperforms a number of existing automatic techniques. keywords — Optical Coherence Tomography (OCT), Convolutional Neural Networks (CNN), AgeRelated Macular Degeneration (AMD), pathology identification, ophthalmology, machine learning",
            "output": [
                "RetiNet: Automatic AMD identification in OCT volumetric data"
            ]
        },
        {
            "id": "task1540-7971862437ba4c6381b8c73939800e2d",
            "input": "Spectral methods are popular in detecting global structures in the given data that can be represented as a matrix. However when the data matrix is sparse or noisy, classic spectral methods usually fail to work, due to localization of eigenvectors (or singular vectors) induced by the sparsity or noise. In this work, we propose a general method to solve the localization problem by learning a regularization matrix from the localized eigenvectors. Using matrix perturbation analysis, we demonstrate that the learned regularizations suppress down the eigenvalues associated with localized eigenvectors and enable us to recover the informative eigenvectors representing the global structure. We show applications of our method in several inference problems: community detection in networks, clustering from pairwise similarities, rank estimation and matrix completion problems. Using extensive experiments, we illustrate that our method solves the localization problem and works down to the theoretical detectability limits in different kinds of synthetic data. This is in contrast with existing spectral algorithms based on data matrix, non-backtracking matrix, Laplacians and those with rank-one regularizations, which perform poorly in the sparse case with noise.",
            "output": [
                "Robust Spectral Detection of Global Structures in the Data by Learning a Regularization"
            ]
        },
        {
            "id": "task1540-6138e221047e4ca7ba5364954edd06a0",
            "input": "We consider the problem of learning a causal graph over a set of variables with interventions. We study the cost-optimal causal graph learning problem: For a given skeleton (undirected version of the causal graph), design the set of interventions with minimum total cost, that can uniquely identify any causal graph with the given skeleton. We show that this problem is solvable in polynomial time. Later, we consider the case when the number of interventions is limited. For this case, we provide polynomial time algorithms when the skeleton is a tree or a clique tree. For a general chordal skeleton, we develop an efficient greedy algorithm, which can be improved when the causal graph skeleton is an interval graph.",
            "output": [
                "Cost-Optimal Learning of Causal Graphs"
            ]
        },
        {
            "id": "task1540-90569545bd7d479ba797ac7337143567",
            "input": "Machine learning systems trained on user-provided data are susceptible to data poisoning attacks, whereby malicious users inject false training data with the aim of corrupting the learned model. While recent work has proposed a number of attacks and defenses, little is understood about the worst-case loss of a defense in the face of a determined attacker. We address this by constructing approximate upper bounds on the loss across a broad family of attacks, for defenders that first perform outlier removal followed by empirical risk minimization. Our bound comes paired with a candidate attack that nearly realizes the bound, giving us a powerful tool for quickly assessing defenses on a given dataset. Empirically, we find that even under a simple defense, the MNIST-1-7 and Dogfish datasets are resilient to attack, while in contrast the IMDB sentiment dataset can be driven from 12% to 23% test error by adding only 3% poisoned data.",
            "output": [
                "Certified Defenses for Data Poisoning Attacks"
            ]
        },
        {
            "id": "task1540-94c1d50913d3473486091786487c62f9",
            "input": "We describe a novel approach to monitoring high level behaviors using concepts from AI planning. Our goal is to understand what a program is doing based on its system call trace. This ability is particularly important for detecting malware. We approach this problem by building an abstract model of the operating system using the STRIPS planning language, casting system calls as planning operators. Given a system call trace, we simulate the corresponding operators on our model and by observing the properties of the state reached, we learn about the nature of the original program and its behavior. Thus, unlike most statistical detection methods that focus on syntactic features, our approach is semantic in nature. Therefore, it is more robust against obfuscation techniques used by malware that change the outward appearance of the trace but not its effect. We demonstrate the efficacy of our approach by evaluating it on actual system call traces.",
            "output": [
                "A Planning Approach to Monitoring Computer Programs’ Behavior"
            ]
        },
        {
            "id": "task1540-a8fe0202fbbb4110b03a93debb5dcf83",
            "input": "In this paper we propose a special type of aggregation function which generalizes the notion of Ordered Weighted Averaging Function OWA. The resulting functions are called Dynamic Ordered Weighted Averaging Functions — DYOWAs. This generalization will be developed in such way that the weight vectors are variables depending on the input vector. Particularly, this operators generalize the aggregation functions: Minimum, Maximum, Arithmetic Mean, Median etc, which are extensively used in image processing. In this field of research two problems are considered: The determination of methods to reduce images and the ∗Preprint submitted to IEEE Transactions on Fuzzy Systems. †Federal University of Semi-Arid UFERSA, Pau dos Ferros, RN, Brazil, 59.900-000, antonio.diego@ufersa.edu.br ‡DIMAp, valdigleis@ppgsc.ufrn.br §DIMAp, ranyer.lopes@gmail.com ¶DIMAp, bedregal@dimap.ufrn.br ‖Dimap, regivan@dimap.ufrn.br ∗∗DIMAP: Department of Informatics and Applied Mathematics, Federal University of Rio Grande do Norte — UFRN, Natal, RN, Brazil, 59.072-970 1 ar X iv :1 60 1. 03 78 5v 1 [ cs .A I] 1 5 Ja n 20 16 construction of techniques which provide noise reduction. The operators described here are able to be used in both cases. In terms of image reduction we apply the methodology provided in [1]. We use the noise reduction operators obtained here to treat the images obtained in the first part of the paper, thus obtaining images with better quality.",
            "output": [
                "A Method for Image Reduction Based on a Generalization of Ordered Weighted Averaging Functions∗"
            ]
        },
        {
            "id": "task1540-11f68d771a8b4db890148e1a83eb037f",
            "input": "In this paper, we present a transfer learning approach for music classification and regression tasks. We propose to use a pre-trained convnet feature, a concatenated feature vector using the activations of feature maps of multiple layers in a trained convolutional network. We show how this convnet feature can serve as general-purpose music representation. In the experiments, a convnet is trained for music tagging and then transferred to other music-related classification and regression tasks. The convnet feature outperforms the baseline MFCC feature in all the considered tasks and several previous approaches that are aggregating MFCCs as well as lowand high-level music features.",
            "output": [
                "TRANSFER LEARNING FOR MUSIC CLASSIFICATION AND REGRESSION TASKS"
            ]
        },
        {
            "id": "task1540-8a991d05a69147f1aae476b74fb21c50",
            "input": "We study the complexity of functions computable by deep feedforward neural networks with piecewise linear activations in terms of the number of regions of linearity that they have. Deep networks are able to sequentially map portions of each layer’s input space to the same output. In this way, deep models compute functions with a compositional structure that is able to re-use pieces of computation exponentially often in terms of their depth. This note investigates the complexity of such compositional maps and contributes new theoretical results regarding the advantage of depth for neural networks with piece-wise linear activation functions.",
            "output": [
                "On the Number of Linear Regions of Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-db37a8571ca8447e96ef79c966482d19",
            "input": "Argumentation is a promising model for reasoning with uncertain and inconsistent knowledge. The key concept of acceptability enables to differentiate arguments and defeaters: The certainty of a proposition can then be evaluated through the most acceptable arguments for that proposition. In this paper, we investigate different complementary points of view: an acceptability based on the existence of direct defeaters and an acceptability based on the existence of defenders. Pursuing previous work on preference-based argumentation principles, we enforce both points of view by taking into account preference orderings for comparing arguments. Our approach is illustrated in the context of reasoning with stratified knowledge bases.",
            "output": [
                "On the Acceptability of Arguments in Preference-based Argumentation"
            ]
        },
        {
            "id": "task1540-7b855f2e9018447592f76b6df8a12dd3",
            "input": "The present study introduces a method for improving the classification performance of imbalanced multiclass data streams from wireless body worn sensors. Data imbalance is an inherent problem in activity recognition caused by the irregular time distribution of activities, which are sequential and dependent on previous movements. We use conditional random fields (CRF), a graphical model for structured classification, to take advantage of dependencies between activities in a sequence. However, CRFs do not consider the negative effects of class imbalance during training. We propose a class-wise dynamically weighted CRF (dWCRF) where weights are automatically determined during training by maximizing the expected overall F-score. Our results based on three case studies from a healthcare application using a batteryless body worn sensor, demonstrate that our method, in general, improves overall and minority class F-score when compared to other CRF based classifiers and achieves similar or better overall and class-wise performance when compared to SVM based classifiers under conditions of limited training data. We also confirm the performance of our approach using an additional battery powered body worn sensor dataset, achieving similar results in cases of high class imbalance.",
            "output": [
                "Learning from Imbalanced Multiclass Sequential Data Streams Using Dynamically Weighted Conditional Random Fields"
            ]
        },
        {
            "id": "task1540-7bfb27e180d44352b99acdd675398e20",
            "input": "This paper presents categorization of Croatian texts using Non-Standard Words (NSW) as features. NonStandard Words are: numbers, dates, acronyms, abbreviations, currency, etc. NSWs in Croatian language are determined according to Croatian NSW taxonomy. For the purpose of this research, 390 text documents were collected and formed the SKIPEZ collection with 6 classes: official, literary, informative, popular, educational and scientific. Text categorization experiment was conducted on three different representations of the SKIPEZ collection: in the first representation, the frequencies of NSWs are used as features; in the second representation, the statistic measures of NSWs (variance, coefficient of variation, standard deviation, etc.) are used as features; while the third representation combines the first two feature sets. Naive Bayes, CN2, C4.5, kNN, Classification Trees and Random Forest algorithms were used in text categorization experiments. The best categorization results are achieved using the first feature set (NSW frequencies) with the categorization accuracy of 87%. This suggests that the NSWs should be considered as features in highly inflectional languages, such as Croatian. NSW based features reduce the dimensionality of the feature space without standard lemmatization procedures, and therefore the bag-of-NSWs should be considered for further Croatian texts categorization experiments.",
            "output": [
                "Non-Standard Words as Features for Text Categorization"
            ]
        },
        {
            "id": "task1540-02fd3b4fb6514c1f88855ae0f61d1eab",
            "input": "We take another look at the general problem of selecting a preferred probability measure among those that comply with some given constraints. The dominant role that entropy maximization has obtained in this context is questioned by argu­ ing that the minimum information principle on which it is based could be supplanted by an at least as plausible \"likelihood of evidence\" prin­ ciple. We then review a method for turning given selection functions into representation indepen­ dent variants, and discuss the tradeoffs involved in this transformation.",
            "output": [
                "Measure Selection: Notions of Rationality and Representation Independence"
            ]
        },
        {
            "id": "task1540-8df66577435449d2870367fd2e1c857c",
            "input": "Logic-based event recognition systems infer occurrences of events in time using a set of event definitions in the form of first-order rules. The Event Calculus is a temporal logic that has been used as a basis in event recognition applications, providing among others, direct connections to machine learning, via Inductive Logic Programming (ILP). OLED is a recently proposed ILP system that learns event definitions in the form of Event Calculus theories, in a single pass over a data stream. In this work we present a version of OLED that allows for distributed, online learning. We evaluate our approach on a benchmark activity recognition dataset and show that we can significantly reduce training times, exchanging minimal information between processing nodes.",
            "output": [
                "Distributed Online Learning of Event Definitions"
            ]
        },
        {
            "id": "task1540-f3c7a04f900e40388c67083aa28ace5d",
            "input": "As robots enter human environments, they will be expected to accomplish a tremendous range of tasks. It is not feasible for robot designers to pre-program these behaviors or know them in advance, so one way to address this is through end-user programming, such as learning from demonstration (LfD). While significant work has been done on the mechanics of enabling robot learning from human teachers, one unexplored aspect is enabling mutual feedback between both the human teacher and robot during the learning process, i.e., implicit learning. In this paper, we explore one aspect of this mutual understanding, grounding sequences, where both a human and robot provide non-verbal feedback to signify their mutual understanding during interaction. We conducted a study where people taught an autonomous humanoid robot a dance, and performed gesture analysis to measure people’s responses to the robot during correct and incorrect demonstrations.",
            "output": [
                "Exploring Implicit Human Responses to Robot Mistakes in a Learning from Demonstration Task"
            ]
        },
        {
            "id": "task1540-49e596b9dc554687b82aba1c5af044d2",
            "input": "Many advances in research regarding immuno-interactions with cancer were developed with the help of ordinary differential equation (ODE) models. These models, however, are not effectively capable of representing problems involving individual localisation, memory and emerging properties, which are common characteristics of cells and molecules of the immune system. Agent-based modelling and simulation is an alternative paradigm to ODE models that overcomes these limitations. In this paper we investigate the potential contribution of agentbased modelling and simulation when compared to ODE modelling and simulation. We seek answers to the following questions: Is it possible to obtain an equivalent agent-based model from the ODE formulation? Do the outcomes differ? Are there any benefits of using one method compared to the other? To answer these questions, we have considered three case studies using established mathematical models of immune interactions with earlystage cancer. These case studies were re-conceptualised under an agent-based perspective and the simulation results were then compared with those from the ODE models. Our results show that it is possible to obtain equivalent agent-based models (i.e. implementing the same mechanisms); the simulation output of both types of models however might differ depending on the attributes of the system to be modelled. In some cases, additional insight from using agent-based modelling was obtained. Overall, we can confirm that agent-based modelling is a useful addition to the tool set of immunologists, as it has extra features that allow for simulations with characteristics that are closer to the biological phenomena.",
            "output": [
                "Investigating Mathematical Models of Immuno-Interactions with Early-Stage Cancer under an Agent-Based Modelling Perspective"
            ]
        },
        {
            "id": "task1540-3b77959f3e5a418a8802a7818305bb60",
            "input": "The Massive Open Online Course (MOOC) has expanded significantly in recent years. With the widespread of MOOC, the opportunity to study the fascinating courses for free has attracted numerous people of diverse educational backgrounds all over the world. In the big data era, a key research topic for MOOC is how to mine the needed courses in the massive course databases in cloud for each individual (course) learner accurately and rapidly as the number of courses is increasing fleetly. In this respect, the key challenge is how to realize personalized course recommendation as well as to reduce the computing and storage costs for the tremendous course data. In this paper, we propose a big data-supported, contextaware online learning-based course recommender system that could handle the dynamic and infinitely massive datasets, which recommends courses by using personalized context information and historical statistics. The context-awareness takes the personal preferences into consideration, making the recommendation suitable for people with different backgrounds. Besides, the algorithm achieves the sublinear regret performance, which means it can gradually recommend the mostly preferred and matched courses to learners. Unlike other existing algorithms, ours bounds the time complexity and space complexity linearly. In addition, our devised storage module is expanded to the distributed-connected clouds, which can handle massive course storage problems from heterogenous sources. Our experiment results verify the superiority of our algorithms when comparing with existing works in the big data setting.",
            "output": [
                "Context-Aware Online Learning for Course Recommendation of MOOC Big Data"
            ]
        },
        {
            "id": "task1540-e4d34b0635d84664b0de47f52b3b1563",
            "input": "The ability of an Evolutionary Algorithm (EA) to find a global optimal solution depends on its capacity to find a good rate between exploitation of found-so-far elements and exploration of the search space. Inspired by natural phenomena, researchers have developed many successful evolutionary algorithms which, at original versions, define operators that mimic the way nature solves complex problems, with no actual consideration of the explorationexploitation balance. In this paper, a novel nature-inspired algorithm called the States of Matter Search (SMS) is introduced. The SMS algorithm is based on the simulation of the states of matter phenomenon. In SMS, individuals emulate molecules which interact to each other by using evolutionary operations which are based on the physical principles of the thermal-energy motion mechanism. The algorithm is devised by considering each state of matter at one different exploration–exploitation ratio. The evolutionary process is divided into three phases which emulate the three states of matter: gas, liquid and solid. In each state, molecules (individuals) exhibit different movement capacities. Beginning from the gas state (pure exploration), the algorithm modifies the intensities of exploration and exploitation until the solid state (pure exploitation) is reached. As a result, the approach can substantially improve the balance between exploration–exploitation, yet preserving the good search capabilities of an evolutionary approach. To illustrate the proficiency and robustness of the proposed algorithm, it is compared to other well-known evolutionary methods including novel variants that incorporate diversity preservation schemes. The comparison examines several standard benchmark functions which are commonly considered within the EA field. Experimental results show that the proposed method achieves a good performance in comparison to its counterparts as a consequence of its better exploration–exploitation balance.",
            "output": [
                "An optimization algorithm inspired by the States of Matter that improves the balance between exploration and exploitation"
            ]
        },
        {
            "id": "task1540-502107fd12dd4605b397d4f2eeed9e37",
            "input": "Warehouse is one of the important aspects of a company. Therefore, it is necessary to improve Warehouse Management System (WMS) to have a simple function that can determine the layout of the storage goods. In this paper we propose an improved warehouse layout method based on ant colony algorithm and backtracking algorithm. The method works on two steps. First, it generates a solutions parameter tree from backtracking algorithm. Then second, it deducts the solutions parameter by using a combination of ant colony algorithm and backtracking algorithm. This method was tested by measuring the time needed to build the tree and to fill up the space using two scenarios. The method needs 0.294 to 33.15 seconds to construct the tree and 3.23 seconds (best case) to61.41 minutes (worst case) to fill up the warehouse. This method is proved to be an attractive alternative solution for warehouse layout system. Keywords—warehouse layout; block stacking method; ant colony algorithm; backtracking algorithm.",
            "output": [
                "Warehouse Layout Method Based on Ant Colony and Backtracking Algorithm"
            ]
        },
        {
            "id": "task1540-cfb784ba4dd84834a85d64d547f55501",
            "input": "Online learning constitutes a mathematical and compelling framework to analyze sequential decision making problems in adversarial environments. The learner repeatedly chooses an action, the environment responds with an outcome, and then the learner receives a reward for the played action. The goal of the learner is to maximize his total reward. However, there are situations in which, in addition to maximizing the cumulative reward, there are some additional constraints on the sequence of decisions that must be satisfied on average by the learner. In this paper we study an extension to the online learning where the learner aims to maximize the total reward given that some additional constraints need to be satisfied. By leveraging on the theory of Lagrangian method in constrained optimization, we propose Lagrangian exponentially weighted average (LEWA) algorithm, which is a primal-dual variant of the well known exponentially weighted average algorithm, to efficiently solve constrained online decision making problems. Using novel theoretical analysis, we establish the regret and the violation of the constraint bounds in full information and bandit feedback models.",
            "output": [
                "Efficient Constrained Regret Minimization"
            ]
        },
        {
            "id": "task1540-4deeaf2c51024ed2a0917edaddba6c40",
            "input": "This paper describes the architecture and implementation of a rule-based grapheme to phoneme converter for Turkish. The system accepts surface form as input, outputs SAMPA mapping of the all parallel pronounciations according to the morphological analysis together with stress positions. The system has been implemented in Python.",
            "output": [
                "Towards Turkish ASR: Anatomy of a rule-based Turkish g2p"
            ]
        },
        {
            "id": "task1540-b41daf144df146b38ef62a5db8130f73",
            "input": "As the education fees are becoming more expensive, more students apply for scholarships. Consequently, hundreds and even thousands of applications need to be handled by the sponsor. To solve the problems, some alternatives based on several attributes (criteria) need to be selected. In order to make a decision on such fuzzy problems, Fuzzy Multiple Attribute Decision Making (FMDAM) can be applied. In this study, Unified Modeling Language (UML) in FMADM with TOPSIS and Weighted Product (WP) methods is applied to select the candidates for academic and non-academic scholarships at Universitas Islam Negeri Sunan Kalijaga. Data used were a crisp and fuzzy data. The results show that TOPSIS and Weighted Product FMADM methods can be used to select the most suitable candidates to receive the scholarships since the preference values applied in this method can show applicants with the highest eligibility. Keyword: Fuzzy Multiple Attribute Decision Making, TOPSIS, Weighted Product, Scholarship",
            "output": [
                "A Fuzzy Topsis Multiple-Attribute Decision Making for Scholarship Selection"
            ]
        },
        {
            "id": "task1540-e18b470dfe154c8f8dbd45a5e7e03a69",
            "input": "In this paper, we illustrate the modeling of a reservoir property (sand fraction) from seismic attributes namely seismic impedance, seismic amplitude, and instantaneous frequency using Neuro-Fuzzy (NF) approach. Input dataset includes 3D post-stacked seismic attributes and six well logs acquired from a hydrocarbon field located in the western coast of India. Presence of thin sand and shale layers in the basin area makes the modeling of reservoir characteristic a challenging task. Though seismic data is helpful in extrapolation of reservoir properties away from boreholes; yet, it could be challenging to delineate thin sand and shale reservoirs using seismic data due to its limited resolvability. Therefore, it is important to develop state-of-art intelligent methods for calibrating a nonlinear mapping between seismic data and target reservoir variables. Neural networks have shown its potential to model such nonlinear mappings; however, uncertainties associated with the model and datasets are still a concern. Hence, introduction of Fuzzy Logic (FL) is beneficial for handling these uncertainties. More specifically, hybrid variants of Artificial Neural Network (ANN) and fuzzy logic, i.e., NF methods, are capable for the modeling reservoir characteristics by integrating the explicit knowledge representation power of FL with the learning ability of neural networks. In this paper, we opt for ANN and three different categories of Adaptive Neuro-Fuzzy Inference System (ANFIS) based on clustering of the available datasets. A comparative analysis of these three different NF models (i.e., Sugenotype fuzzy inference systems using a grid partition on the data (Model 1), using subtractive clustering (Model 2), and using Fuzzy c-means (FCM) clustering (Model 3)) and ANN suggests that Model 3 has outperformed its counterparts in terms of performance evaluators on the present dataset. Performances of the selected algorithms are evaluated in terms of correlation coefficients (CC), root mean square error (RMSE), absolute error mean (AEM) and scatter index (SI) between target and predicted sand fraction values. The achieved estimation accuracy may diverge minutely depending on geological characteristics of a particular study area. The 2 documented results in this study demonstrate acceptable resemblance between target and predicted variables, and hence, encourage the application of integrated machine learning approaches such as Neuro-Fuzzy in reservoir characterization domain. Furthermore, visualization of the variation of sand probability in the study area would assist in identifying placement of potential wells for future drilling operations.",
            "output": [
                "Quantification of sand fraction from seismic attributes using Neuro-Fuzzy approach"
            ]
        },
        {
            "id": "task1540-22d71f422db645a297058914b913e956",
            "input": "This paper presents a five-valued representation of bifuzzy sets. This representation is related to a five-valued logic that uses the following values: true, false, inconsistent, incomplete and ambiguous. In the framework of fivevalued representation, formulae for similarity, entropy and syntropy of bifuzzy sets are constructed.",
            "output": [
                "Entropy and Syntropy in the Context of Five-Valued Logics"
            ]
        },
        {
            "id": "task1540-ddf2c8ae366d436aa9d81fa6758f0e4a",
            "input": "A new neuro-fuzzy system’s architecture and a learning method that adjusts its weights as well as automatically determines a number of neurons, centers’ location of membership functions and the receptive field’s parameters in an online mode with high processing speed is proposed in this paper. The basic idea of this approach is to tune both synaptic weights and membership functions with the help of the supervised learning and self-learning paradigms. The approach to solving the problem has to do with evolving online neuro-fuzzy systems that can process data under uncertainty conditions. The results proves the effectiveness of the developed architecture and the learning procedure.",
            "output": [
                "An Evolving Neuro-Fuzzy System with Online Learning/Self-learning"
            ]
        },
        {
            "id": "task1540-f60ec553c2b140b99636aaa944e6a149",
            "input": "Unsupervised training of deep generative models containing latent variables and performing inference remains a challenging problem for complex, high dimensional distributions. One basic approach to this problem is the so called Helmholtz machine and it involves training an auxiliary model that helps to perform approximate inference jointly with the generative model which is to be fitted to the training data. The top-down generative model is typically realized as a directed model that starts from some prior at the top, down to the empirical distribution at the bottom. The approximate inference model runs in the opposite direction and is typically trained to efficiently infer high probability latent states given some observed data. Here we propose a new method, referred to as geometric mean matching (GMM), that is based on the idea that the generative model should be close to the class of distributions that can be modeled by our approximate inference distribution. We achieve this by interpreting both the top-down and the bottom-up directed models as approximate inference distributions and by defining the target distribution we fit to the training data to be the geometric mean of these two. We present an upper-bound for the log-likelihood of this model and we show that optimizing this bound will pressure the model to stay close to the approximate inference distributions. In the experimental section we demonstrate that we can use this approach to fit deep generative models with many layers of hidden binary stochastic variables to complex and high dimensional training distributions.",
            "output": [
                "Training opposing directed models using geometric mean matching"
            ]
        },
        {
            "id": "task1540-32ad8e18ca9a4184a3a4752d0a377f8b",
            "input": "Directed possibly cyclic graphs have been proposed by Didelez (2000) and Nodelmann et al. (2002) in order to represent the dynamic dependencies among stochastic processes. These dependencies are based on a generalization of Granger–causality to continuous time, first developed by Schweder (1970) for Markov processes, who called them local dependencies. They deserve special attention as they are asymmetric. In this paper we focus on their graphical representation and develop an asymmetric notion of separation. The properties of this graph separation as well as local independence are investigated in detail within a framework of asymmetric (semi)graphoids allowing insight into what information can be read off these graphs.",
            "output": [
                "Asymmetric Separation for Local Independence Graphs"
            ]
        },
        {
            "id": "task1540-367416033dab41eb88dded29b79496c6",
            "input": "This paper proposes a movie genreprediction based on multinomial probability model. To the best of our knowledge, this problem has not been addressed yet in the field of recommender system. The prediction of a movies genre has many practical applications including complementing the items categories given by experts and providing a surprise effect in the recommendations given to a user. We employ mulitnomial event model to estimate a likelihood of a movie given genre and the Bayes rule to evaluate the posterior probability of a genre given a movie. Experiments with the MovieLens dataset validate our approach. We achieved 70% prediction rate using only 15% of the whole set for training. Keywords—Recommender system, category prediction, multinomial model, Naive Bayes classifier.",
            "output": [
                "A multinomial probabilistic model for movie genre predictions"
            ]
        },
        {
            "id": "task1540-d7d49fdc59a641f699294a3cd73a32a5",
            "input": "Although agreement between annotators who mark feature locations within images has been studied in the past from a statistical viewpoint, little work has attempted to quantify the extent to which this phenomenon affects the evaluation of foreground-background segmentation algorithms. Many researchers utilise ground truth in experimentation and more often than not this ground truth is derived from one annotator’s opinion. How does the difference in opinion affect an algorithm’s evaluation? A methodology is applied to four image processing problems to quantify the inter-annotator variance and to offer insight into the mechanisms behind agreement and the use of ground truth. It is found that when detecting linear structures annotator agreement is very low. The agreement in a structure’s position can be partially explained through basic image properties. Automatic segmentation algorithms are compared to annotator agreement and it is found that there is a clear relation between the two. Several ground truth estimation methods are used to infer a number of algorithm performances. It is found that: the rank of a detector is highly dependent upon the method used to form the ground truth; and that although STAPLE and LSML appear to represent the mean of the performance measured using individual annotations, when there are few annotations, or there is a large variance in them, these estimates tend to degrade. Furthermore, one of the most commonly adopted combination methods—consensus voting— accentuates more obvious features, resulting in an overestimation of performance. It is concluded that in some datasets it is not possible to confidently infer an algorithm ranking when evaluating upon one ground truth.",
            "output": [
                "An Empirical Study into Annotator Agreement, Ground Truth Estimation, and Algorithm Evaluation"
            ]
        },
        {
            "id": "task1540-4efa79c3adc84a27987d7912963b42e0",
            "input": "As the number of applications that use machine learning algorithms increases, the need for labeled data useful for training such algorithms intensifies. Getting labels typically involves employing humans to do the annotation, which directly translates to training and working costs. Crowdsourcing platforms have made labeling cheaper and faster, but they still involve significant costs, especially for the cases where the potential set of candidate data to be labeled is large. In this paper we describe a methodology and a prototype system aiming at addressing this challenge for Web-scale problems in an industrial setting. We discuss ideas on how to efficiently select the data to use for training of machine learning algorithms in an attempt to reduce cost. We show results achieving good performance with reduced cost by carefully selecting which instances to label. Our proposed algorithm is presented as part of a framework for managing and generating training datasets, which includes, among other components, a human computation element.",
            "output": [
                "A Data Management Approach for Dataset Selection Using Human Computation"
            ]
        },
        {
            "id": "task1540-a9647036f93442c1aae2a3315afb515b",
            "input": "Measuring the naturalness of images is important to generate realistic images or to detect unnatural regions in images. Additionally, a method to measure naturalness can be complementary to Convolutional Neural Network (CNN) based features, which are known to be insensitive to the naturalness of images. However, most probabilistic image models have insufficient capability of modeling the complex and abstract naturalness that we feel because they are built directly on raw image pixels. In this work, we assume that naturalness can be measured by the predictability on high-level features during eye movement. Based on this assumption, we propose a novel method to evaluate the naturalness by building a variant of Recurrent Neural Network Language Models on pre-trained CNN representations. Our method is applied to two tasks, demonstrating that 1) using our method as a regularizer enables us to generate more understandable images from image features than existing approaches, and 2) unnaturalness maps produced by our method achieve state-of-the-art eye fixation prediction performance on two well-studied datasets.",
            "output": [
                "Visual Language Modeling on CNN Image Representations"
            ]
        },
        {
            "id": "task1540-bfb4232f06b64b7a800da56222d2b71e",
            "input": "We have previously reported a Bayesian algorithm for determining the coordinates of points in three­ dimensional space from uncertain constraints. This method is useful in the determination of biological molecular structure. It is limited, however, by the requirement that the uncertainty in the constraints be normally distributed. In this paper, we present an extension of the original algorithm that allows constraint uncertainty to be represented as a mixture of Gaussians, and thereby allows arbitrary constraint distributions. We illustrate the performance of this algorithm on a problem drawn from the domain of molecular structure determination, in which a multicomponent constraint representation produces a much more accurate solution than the old single component mechanism. The new mechanism uses mixture distributions to decompose the problem into a set of independent problems with unimodal constraint uncertainty. The results of the unimodal subproblems are periodically recombined using Bayes' law, to avoid combinatorial explosion. The new algorithm is particularly suited for parallel",
            "output": [
                "Probabilistic Constraint Satisfaction with Non-Gaussian Noise"
            ]
        },
        {
            "id": "task1540-a93685b35a0b4bc1922f66816476bf4c",
            "input": "A Long Short-Term Memory (LSTM) network is a type of recurrent neural network architecture which has recently obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. TreeLSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).",
            "output": [
                "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
            ]
        },
        {
            "id": "task1540-81cb1770b5184e3bb8f1d4792d33da0f",
            "input": "The current trends in next-generation exascale systems go towards integrating a wide range of specialized (co-)processors into traditional supercomputers. Due to the efficiency of heterogeneous systems in terms of Watts and FLOPS per surface unit, opening the access of heterogeneous platforms to a wider range of users is an important problem to be tackled. However, heterogeneous platforms limit the portability of the applications and increase development complexity due to the programming skills required. Program transformation can help make programming heterogeneous systems easier by defining a step-wise transformation process that translates a given initial code into a semantically equivalent final code, but adapted to a specific platform. Program transformation systems require the definition of efficient transformation strategies to tackle the combinatorial problem that emerges due to the large set of transformations applicable at each step of the process. In this paper we propose a machine learning-based approach to learn heuristics to define program transformation strategies. Our approach proposes a novel combination of reinforcement learning and classification methods to efficiently tackle the problems inherent to this type of systems. Preliminary results demonstrate the suitability of this approach.",
            "output": [
                "Towards Automatic Learning of Heuristics for Mechanical Transformations of Procedural Code∗"
            ]
        },
        {
            "id": "task1540-e737b6adc6d049b4b3ac7247e0da0edd",
            "input": "Deep neural networks currently demonstrate state-of-the-art performance in several domains. At the same time, models of this class are very demanding in terms of computational resources. In particular, a large amount of memory is required by commonly used fully-connected layers, making it hard to use the models on low-end devices and stopping the further increase of the model size. In this paper we convert the dense weight matrices of the fully-connected layers to the Tensor Train [15] format such that the number of parameters is reduced by a huge factor and at the same time the expressive power of the layer is preserved. In particular, for the Very Deep VGG networks [19] we report the compression factor of the dense weight matrix of a fully-connected layer up to 200000 times leading to the compression factor of the whole network up to 7 times.",
            "output": [
                "Tensorizing Neural Networks"
            ]
        },
        {
            "id": "task1540-e8f884eab561447e9c7820bec868c5bf",
            "input": "We present a novel application of LSTM recurrent neural networks to multilabel classification of diagnoses given variable-length time series of clinical measurements. Our method outperforms a strong baseline on a variety of metrics.",
            "output": [
                "Phenotyping of Clinical Time Series with LSTM Recurrent Neural Networks"
            ]
        },
        {
            "id": "task1540-c6a68276292e495195487c7826d46916",
            "input": "High dimensional superposition models characterize observations using parameters which can be written as a sum of multiple component parameters, each with its own structure, e.g., sum of low rank and sparse matrices, sum of sparse and rotated sparse vectors, etc. In this paper, we consider general superposition models which allow sum of any number of component parameters, and each component structure can be characterized by any norm. We present a simple estimator for such models, give a geometric condition under which the components can be accurately estimated, characterize sample complexity of the estimator, and give high probability non-asymptotic bounds on the componentwise estimation error. We use tools from empirical processes and generic chaining for the statistical analysis, and our results, which substantially generalize prior work on superposition models, are in terms of Gaussian widths of suitable sets.",
            "output": [
                "High Dimensional Structured Superposition Models"
            ]
        },
        {
            "id": "task1540-ed7dcbc411624e589623c955ce4356db",
            "input": "In the modern era, each Internet user leaves enormous amounts of auxiliary digital residuals (footprints) by using a variety of on-line services. All this data is already collected and stored for many years. In recent works, it was demonstrated that it’s possible to apply simple machine learning methods to analyze collected digital footprints and to create psycho-demographic profiles of individuals. However, while these works clearly demonstrated the applicability of machine learning methods for such an analysis, created simple prediction models still lacks accuracy necessary to be successfully applied for practical needs. We have assumed that using advanced deep machine learning methods may considerably increase the accuracy of predictions. We started with simple machine learning methods to estimate basic prediction performance and moved further by applying advanced methods based on shallow and deep neural networks. Then we compared prediction power of studied models and made conclusions about its performance. Finally, we made hypotheses how prediction accuracy can be further improved. As result of this work, we provide full source code used in the experiments for all interested researchers and practitioners in corresponding GitHub repository. We believe that applying deep machine learning for psycho-demographic profiling may have an enormous impact on the society (for good or worse) and provides means for Artificial Intelligence (AI) systems to better understand humans by creating their psychological profiles. Thus AI agents may achieve the human-like ability to participate in conversation (communication) flow by anticipating human opponents’ reactions, expectations, and behavior. By providing full source code of our research we hope to intensify further research in the area by the wider circle of scholars.",
            "output": [
                "Applying Deep Machine Learning for psycho-demographic profiling of Internet users using O.C.E.A.N. model of personality"
            ]
        },
        {
            "id": "task1540-9849dc7845a544b39fc118d55ecff9c8",
            "input": "We present a computational analysis of three language varieties: native, advanced non-native, and translation. Our goal is to investigate the similarities and differences between non-native language productions and translations, contrasting both with native language. Using a collection of computational methods we establish three main results: (1) the three types of texts are easily distinguishable; (2) nonnative language and translations are closer to each other than each of them is to native language; and (3) some of these characteristics depend on the source or native language, while others do not, reflecting, perhaps, unified principles that similarly affect translations and non-native language.",
            "output": [
                "On the Similarities Between Native, Non-native and Translated Texts"
            ]
        },
        {
            "id": "task1540-0b7c463c57374d85b6ad809874926737",
            "input": "We consider the task of aggregating beliefs of sev­ eral experts. We assume that these beliefs are rep­ resented as probability distributions. We argue that the evaluation of any aggregation technique depends on the semantic context of this task. We propose a framework, in which we assume that nature generates samples from a 'true' distribution and different experts form their beliefs based on the subsets of the data they have a chance to observe. Naturally, the optimal ag­ gregate distribution would be the one learned from the combined sample sets. Such a formulation leads to a natural way to measure the accuracy of the aggregation mechanism. We show that the well-known aggregation operator LinOP is ideally suited for that task. We propose a LinOP-based learning algorithm, inspired by the techniques developed for Bayesian learning, which aggregates the experts' distributions represented as Bayesian networks. We show experimentally that this algorithm performs well in practice.",
            "output": [
                "Aggregating Learned Probabilistic Beliefs"
            ]
        },
        {
            "id": "task1540-dc38110cd93345a5835a6aa4b05aafca",
            "input": "Sparse PCA provides a linear combination of small number of features that maximizes variance across data. Although Sparse PCA has apparent advantages compared to PCA, such as better interpretability, it is generally thought to be computationally much more expensive. In this paper, we demonstrate the surprising fact that sparse PCA can be easier than PCA in practice, and that it can be reliably applied to very large data sets. This comes from a rigorous feature elimination pre-processing result, coupled with the favorable fact that features in real-life data typically have exponentially decreasing variances, which allows for many features to be eliminated. We introduce a fast block coordinate ascent algorithm with much better computational complexity than the existing first-order ones. We provide experimental results obtained on text corpora involving millions of documents and hundreds of thousands of features. These results illustrate how Sparse PCA can help organize a large corpus of text data in a user-interpretable way, providing an attractive alternative approach to topic models.",
            "output": [
                "Large-Scale Sparse Principal Component Analysis with Application to Text Data"
            ]
        },
        {
            "id": "task1540-146faf67baba458389cb2afa1cecf2e9",
            "input": "We investigate the problem of sequentially predicting the binary labels on the nodes of an arbitrary weighted graph. We show that, under a suitable parametrization of the problem, the optimal number of prediction mistakes can be characterized (up to logarithmic factors) by the cutsize of a random spanning tree of the graph. The cutsize is induced by the unknown adversarial labeling of the graph nodes. In deriving our characterization, we obtain a simple randomized algorithm achieving in expectation the optimal mistake bound on any polynomially connected weighted graph. Our algorithm draws a random spanning tree of the original graph and then predicts the nodes of this tree in constant expected amortized time and linear space. Experiments on real-world datasets show that our method compares well to both global (Perceptron) and local (label propagation) methods, while being generally faster in practice.",
            "output": [
                "Random Spanning Trees and the Prediction of Weighted Graphs"
            ]
        },
        {
            "id": "task1540-8e541c5135de42a1b31da46fcccbbdb5",
            "input": "Many genres of natural language text are narratively structured, a testament to our predilection for organizing our experiences as narratives. There is broad consensus that understanding a narrative requires identifying and tracking the goals and desires of the characters and their narrative outcomes. However, to date, there has been limited work on computational models for this problem. We introduce a new dataset, DesireDB, which includes goldstandard labels for identifying statements of desire, textual evidence for desire fulfillment, and annotations for whether the stated desire is fulfilled given the evidence in the narrative context. We report experiments on tracking desire fulfillment using different methods, and show that LSTM Skip-Thought model achieves F-measure of 0.7 on our corpus.",
            "output": [
                "Modelling Protagonist Goals and Desires in First-Person Narrative"
            ]
        },
        {
            "id": "task1540-2b0566cf30d443da81d8caac701bb37d",
            "input": "In this paper, a progressive learning technique for multi-class classification is proposed. This newly developed learning technique is independent of the number of class constraints and it can learn new classes while still retaining the knowledge of previous classes. Whenever a new class (non-native to the knowledge learnt thus far) is encountered, the neural network structure gets remodeled automatically by facilitating new neurons and interconnections, and the parameters are calculated in such a way that it retains the knowledge learnt thus far. This technique is suitable for realworld applications where the number of classes is often unknown and online learning from real-time data is required. The consistency and the complexity of the progressive learning technique are analyzed. Several standard datasets are used to evaluate the performance of the developed technique. A comparative study shows that the developed technique is superior. Key Words—Classification, machine learning, multi-class, sequential learning, progressive learning.",
            "output": [
                "A Novel Progressive Learning Technique for Multi-class Classification"
            ]
        },
        {
            "id": "task1540-c21aaefd190e42b698c7181029be4408",
            "input": "We propose online unsupervised domain adaptation (DA), which is performed incrementally as data comes in and is applicable when batch DA is not possible. In a part-of-speech (POS) tagging evaluation, we find that online unsupervised DA performs as well as batch DA.",
            "output": [
                "Online Updating of Word Representations for Part-of-Speech Tagging"
            ]
        },
        {
            "id": "task1540-41fc0b9f7aec479798be5b98dd6f9756",
            "input": "Recent works on cost based relaxations have improved Constraint Programming (CP) models for the Traveling Salesman Problem (TSP). We provide a short survey over solving asymmetric TSP with CP. Then, we suggest new implied propagators based on general graph properties. We experimentally show that such implied propagators bring robustness to pathological instances and highlight the fact that graph structure can significantly improve search heuristics behavior. Finally, we show that our approach outperforms current state of the art results.",
            "output": [
                "Improving the Asymmetric TSP by Considering Graph Structure"
            ]
        },
        {
            "id": "task1540-07016232358b4b7aa267738e054c15f2",
            "input": "This paper describes a new method for reducing the error in a classifier. It uses a weight adjustment update, but includes the very simple rule of either adding or subtracting the adjustment, based on whether the data point is currently larger or smaller than the desired value, and on a pointby-point basis. This gives added flexibility to the convergence procedure, where through a series of transpositions, values far away can continue towards the desired value, whereas values that are originally much closer can oscillate from one side to the other. Tests show that the method can successfully classify some known datasets. It can also work in a batch mode, with reduced training times and can be used as part of a neural network, or classifiers in general. There are also some updates on an earlier wave shape paper.",
            "output": [
                "A New Oscillating-Error Technique for Classifiers"
            ]
        },
        {
            "id": "task1540-993649c658be4ae08c368be85a454c21",
            "input": "We present a general theoretical analysis of structured prediction. By introducing a new complexity measure that explicitly factors in the structure of the output space and the loss function, we are able to derive new data-dependent learning guarantees for a broad family of losses and for hypothesis sets with an arbitrary factor graph decomposition. We extend this theory by leveraging the principle of Voted Risk Minimization (VRM) and showing that learning is possible with complex factor graphs. We both present new learning bounds in this advanced setting as well as derive two new families of algorithms, Voted Conditional Random Fields and Voted Structured Boosting, which can make use of very complex features and factor graphs without overfitting. Finally, we also validate our theory through experiments on several datasets.",
            "output": [
                "Structured Prediction Theory Based on Factor Graph Complexity"
            ]
        },
        {
            "id": "task1540-4b6898699c0b416fa2361c4fd1b83614",
            "input": "We propose several simple approaches to training deep neural networks on data with noisy labels. We introduce an extra noise layer into the network which adapts the network outputs to match the noisy label distribution. The parameters of this noise layer can be estimated as part of the training process and involve simple modifications to current training infrastructures for deep networks. We demonstrate the approaches on several datasets, including large scale experiments on the ImageNet classification benchmark, showing how additional noisy data can improve state-of-the-art recognition models. 1 Introduction In recent years, deep learning methods have shown impressive results on image classification tasks. However, this achievement is only possible because of large amount of labeled images. Labeling images by hand is a laborious task and takes a lot of time and money. An alternative approach is to generate labels automatically. This includes user tags from social web sites and keywords from image search engines. Considering the abundance of such noisy labels, it is important to find a way to utilize them in deep learning. Unfortunately, those labels are very noisy and unlikely to help training deep networks without additional tricks. Our goal is to study the effect label noise on deep networks, and explore simple ways of improvement. We focus on the robustness of deep networks instead of data cleaning methods, which are well studied and can be used together with robust models directly. Although many noise robust classifiers are proposed so far, there are not many works on training deep networks on noisy labeled data, especially on large scale datasets. Our contribution in this paper is a novel way of modifying deep learning models so they can be effectively trained on data with high level of label noise. The modification is simply done by adding a linear layer on top of the softmax layer, which makes it easy to implement. This additional layer changes the output from the network to give better match to the noisy labels. Also, it is possible to learn the noise distribution directly from the noisy data. Using real-world image classification tasks, we demonstrate that the model actually works very well in practice. We even show that random images without labels (complete noise) can improve the classification performance. 2 Related Work In any classification model, degradation of performance is inevitable when there is noise in training labels [13, 15]. A simple approach to handle noisy labels is a data preprocessing stage, where labels suspected to be incorrect are removed or corrected [1, 3]. However, a weakness of this approach is the difficulty of distinguishing informative hard samples from harmful mislabeled ones [6]. Instead, in this paper, we focus on models robust to presence of label noise. 1 ar X iv :1 40 6. 20 80 v1 [ cs .C V ] 9 J un 2 01 4 The effect of label noise is well studied in common classifiers (e.g., SVMs, kNN, logistic regression), and their label noise robust variants have been proposed. See [5] for comprehensive review. A more recent work [2] proposed a generic unbiased estimator for binary classification with noisy labels. They employ a surrogate cost function that can be expressed by a weighted sum of the original cost functions, and gave theoretical bounds on the performance. In this paper, we will also consider this idea and extend it multiclass. A cost function similar to ours is proposed in [2] to make logistic regression robust to label noise. They also proposed a learning algorithm for noise parameters. However, we consider deep networks, a more powerful and complex classifier than logistic regression, and propose a different learning algorithm for noise parameters that is more suited for back-propagation training. Considering the recent success of deep learning [8, 17, 16], there are very few works about deep learning from noisy labels. In [11, 9], noise modeling is incorporated to neural network in the same way as our proposed model. However, only binary classification is considered in [11], and [9] assumed symmetric label noise (noise is independent of the true label). Therefore, there is only a single noise parameter, which can be tuned by cross-validation. In this paper, we consider multiclass classification and assume more realistic asymmetric label noise, which makes it impossible to use cross-validation to adjust noise parameters (there can be a million parameters). 3 Approach In this paper, we consider two approaches to make an existing classification model, which we call the base model, robust against noisy labels: bottom-up and top-down noise models. In the bottomup model, we add an additional layer to the model that changes the label probabilities output by the base model so it would better match to noisy labels. Top-down model, on other hand, changes given noisy labels before feeding them to the base model. Both models require a noise model for training, so we will give an easy way to estimate noise levels using clean data. Also, it is possible to learn noise distribution from noisy data in the bottom-up model. Although only deep neural networks are used in our experiments, the both approaches can be applied to any classification model with a cross entropy cost. 3.1 Bottom-up Noise Model We assume that label noise is random conditioned on the true class, but independent of the input x (see [10] for more detail about this type of noise). Based on this assumption, we add an additional layer to a deep network (see Figure 1) that changes its output so it would better match to the noisy labels. The weights of this layer corresponds to the probabilities of a certain class being mislabeled to another class. Because those probabilities are often unknown, we will show how estimate them from additional clean data, or from the noisy data itself. Let D be the true data distribution generating correctly labeled samples (x, y∗), where x is an input vector and y∗ is the corresponding label. However, we only observe noisy labeled samples (x, ỹ) that generated from a some noisy distribution D̃. We assume that the label noise is random conditioned on the true labels. Then, the noise distribution can be parameterized by a matrix Q = {qji}: qji := p(ỹ = j|y∗ = i). Q is a probability matrix because its elements are positive and each column sums to one. The probability of input x being labeled as j in D̃ is given by p(ỹ = j|x, θ) = ∑ i p(ỹ = j|y∗ = i)p(y∗ = i|x) = ∑ i qjip(y ∗ = i|x, θ). (1) where p(y∗ = i|x, θ) is the probabilistic output of the base model with parameters θ. If the true noise distribution is known, we can modify this for noisy labeled data. During training, Q will act as an adapter that transforms the model’s output to better match the noisy labels. Deep\t\r  network Learnin from noisy labels in deep neural networks Sainbayar Sukhbaatar Dept. of Computer Science, NYU, 715 Broadway, New Y rk, NY 10003 sainbar@cs.nyu.edu Rob Fergus Courant Institute, NYU, 715 Broadway, New York, NY 10003 fergus@cs.nyu.edu",
            "output": [
                "Learning from Noisy Labels with Deep Neural Networks"
            ]
        },
        {
            "id": "task1540-64aa3df80ddd406baa044148ee51c14d",
            "input": "The dueling bandits problem is an online learning framework for learning from pairwise preference feedback, and is particularly wellsuited for modeling settings that elicit subjective or implicit human feedback. In this paper, we study the problem of multi-dueling bandits with dependent arms, which extends the original dueling bandits setting by simultaneously dueling multiple arms as well as modeling dependencies between arms. These extensions capture key characteristics found in many realworld applications, and allow for the opportunity to develop significantly more efficient algorithms than were possible in the original setting. We propose the SELFSPARRING algorithm, which reduces the multi-dueling bandits problem to a conventional bandit setting that can be solved using a stochastic bandit algorithm such as Thompson Sampling, and can naturally model dependencies using a Gaussian process prior. We present a no-regret analysis for multi-dueling setting, and demonstrate the effectiveness of our algorithm empirically on a wide range of simulation settings.",
            "output": [
                "Multi-dueling Bandits with Dependent Arms"
            ]
        },
        {
            "id": "task1540-323c10be11f04f24a53c95e0c7695f48",
            "input": "Integration between biology and information science benefits both fields. Many related models have been proposed, such as computational visual cognition models, computational motor control models, integrations of both and so on. In general, the robustness and precision of recognition is one of the key problems for object recognition models. In this paper, inspired by features of human recognition process and their biological mechanisms, a new integrated and dynamic framework is proposed to mimic the semantic extraction, concept formation and feature re-selection in human visual processing. The main contributions of the proposed model are as follows: (1) Semantic feature extraction: Local semantic features are learnt from episodic features that are extracted from raw images through a deep neural network; (2) Integrated concept formation: Concepts are formed with local semantic information and structural information learnt through network. (3) Feature re-selection: When ambiguity is detected during recognition process, distinctive features according to the difference between ambiguous candidates are re-selected for recognition. Experimental results on hand-written digits and facial shape dataset show that, compared with other methods, the new proposed model exhibits higher robustness and precision for visual recognition, especially in the condition when input samples are smantic ambiguous. Meanwhile, the introduced biological mechanisms further strengthen the interaction between neuroscience and information science.",
            "output": [
                "A Novel Biologically Mechanism-Based Visual Cognition Model –Automatic Extraction of Semantics, Formation of Integrated Concepts and Re-selection Features for Ambiguity"
            ]
        },
        {
            "id": "task1540-b946db428db548e28aeb2e636e9e9987",
            "input": "Despite progress in visual perception tasks such as image classification and detection, computers still struggle to understand the interdependency of objects in the scene as a whole, e.g., relations between objects or their attributes. Existing methods often ignore global context cues capturing the interactions among different object instances, and can only recognize a handful of types by exhaustively training individual detectors for all possible relationships. To capture such global interdependency, we propose a deep Variation-structured Reinforcement Learning (VRL) framework to sequentially discover object relationships and attributes in the whole image. First, a directed semantic action graph is built using language priors to provide a rich and compact representation of semantic correlations between object categories, predicates, and attributes. Next, we use a variation-structured traversal over the action graph to construct a small, adaptive action set for each step based on the current state and historical actions. In particular, an ambiguity-aware object mining scheme is used to resolve semantic ambiguity among object categories that the object detector fails to distinguish. We then make sequential predictions using a deep RL framework, incorporating global context cues and semantic embeddings of previously extracted phrases in the state vector. Our experiments on the Visual Relationship Detection (VRD) dataset and the large-scale Visual Genome dataset validate the superiority of VRL, which can achieve significantly better detection results on datasets involving thousands of relationship and attribute types. We also demonstrate that VRL is able to predict unseen types embedded in our action graph by learning correlations on shared graph nodes.",
            "output": [
                "Deep Variation-structured Reinforcement Learning for Visual Relationship and Attribute Detection"
            ]
        },
        {
            "id": "task1540-b3bbbb0bdaf94fd2bc87d6bb686707df",
            "input": "In a recent paper, Levy and Goldberg [2] pointed out an interesting connection between prediction-based word embedding models and count models based on pointwise mutual information. Under certain conditions, they showed that both models end up optimizing equivalent objective functions. This paper explores this connection in more detail and lays out the factors leading to differences between these models. We find that the most relevant differences from an optimization perspective are (i) predict models work in a low dimensional space where embedding vectors can interact heavily; (ii) since predict models have fewer parameters, they are less prone to overfitting. Motivated by the insight of our analysis, we show how count models can be regularized in a principled manner and provide closed-form solutions for L1 and L2 regularization. Finally, we propose a new embedding model with a convex objective and the additional benefit of being intelligible.",
            "output": [
                "Towards a Better Understanding of Predict and Count Models"
            ]
        },
        {
            "id": "task1540-2a71975a766b43f0896ef0058a4eca65",
            "input": "In this paper, we introduce a new deep convolutional neural network (ConvNet) module that promotes competition among a set of multi-scale convolutional filters. This new module is inspired by the inception module, where we replace the original collaborative pooling stage (consisting of a concatenation of the multi-scale filter outputs) by a competitive pooling represented by a maxout activation unit. This extension has the following two objectives: 1) the selection of the maximum response among the multi-scale filters prevents filter co-adaptation and allows the formation of multiple sub-networks within the same model, which has been shown to facilitate the training of complex learning problems; and 2) the maxout unit reduces the dimensionality of the outputs from the multi-scale filters. We show that the use of our proposed module in typical deep ConvNets produces classification results that are either better than or comparable to the state of the art on the following benchmark datasets: MNIST, CIFAR-10, CIFAR-100 and SVHN.",
            "output": [
                "Competitive Multi-scale Convolution"
            ]
        },
        {
            "id": "task1540-610c4c86194f4a5588d25ef9aeb729a4",
            "input": "Optimal control of thermostatically controlled loads connected to a district heating network is considered a sequential decisionmaking problem under uncertainty. The practicality of a direct model-based approach is compromised by two challenges, namely scalability due to the large dimensionality of the problem and the system identification required to identify an accurate model. To help in mitigating these problems, this paper leverages on recent developments in reinforcement learning in combination with a market-based multi-agent system to obtain a scalable solution that obtains a significant performance improvement in a practical learning time. The control approach is applied on a scenario comprising 100 thermostatically controlled loads connected to a radial district heating network supplied by a central combined heat and power plant. Both for an energy arbitrage and a peak shaving objective, the control approach requires 60 days to obtain a performance within 65% of a theoretical lower bound on the cost.",
            "output": [
                "Model-Free Control of Thermostatically Controlled Loads Connected to a District Heating Network"
            ]
        },
        {
            "id": "task1540-97c56fb0c450441386234da9b2e31d50",
            "input": "A Semantic Compositional Network (SCN) is developed<lb>for image captioning, in which semantic concepts (i.e., tags)<lb>are detected from the image, and the probability of each tag<lb>is used to compose the parameters in a long short-term mem-<lb>ory (LSTM) network. The SCN extends each weight matrix of<lb>the LSTM to an ensemble of tag-dependent weight matrices.<lb>The degree to which each member of the ensemble is used<lb>to generate an image caption is tied to the image-dependent<lb>probability of the corresponding tag. In addition to caption-<lb>ing images, we also extend the SCN to generate captions for<lb>video clips. We qualitatively analyze semantic composition<lb>in SCNs, and quantitatively evaluate the algorithm on three<lb>benchmark datasets: COCO, Flickr30k, and Youtube2Text.<lb>Experimental results show that the proposed method signifi-<lb>cantly outperforms prior state-of-the-art approaches, across<lb>multiple evaluation metrics.",
            "output": [
                "Semantic Compositional Networks for Visual Captioning"
            ]
        },
        {
            "id": "task1540-938718b0eaf0418da0d04a9f38c41bce",
            "input": "Abstract: We often encounter situations in which an experimenter wants to find, by sequential experimentation, xmax = arg maxx f(x), where f(x) is a (possibly unknown) function of a well controllable variable x. Taking inspiration from physics and engineering, we have designed a new method to address this problem. In this paper, we first introduce the method in continuous time, and then present two algorithms for use in sequential experiments. Through a series of simulation studies, we show that the method is effective for finding maxima of unknown functions by experimentation, even when the maximum of the functions drifts or when the signal to noise ratio is low.",
            "output": [
                "Thompson sampling with the online bootstrap"
            ]
        },
        {
            "id": "task1540-ddf75108ee44421aaed528dccbb9dfdb",
            "input": "Decision-making problems in uncertain or stochastic domains are often formulated as Markov decision processes (MD Ps). Pol­ icy iteration (PI) is a popular algorithm for searching over policy-space, the size of which is exponential in the number of states. We are interested in bounds on the complexity of PI that do not depend on the value of the discount factor. In this paper we prove the first such non-trivial, worst-case, upper bounds on the number of iterations required by PI to converge to the optimal policy. Our analysis also sheds new light on the manner in which PI progresses through the space of policies.",
            "output": [
                "On the Complexity of Policy Iteration"
            ]
        },
        {
            "id": "task1540-5d6a31c7e045403ab0b05a80f80484c7",
            "input": "An interesting research problem in our age of Big Data is that of determining provenance. Granular evaluation of provenance of physical goods--e.g. tracking ingredients of a pharmaceutical or demonstrating authenticity of luxury goods--has often not been possible with today's items that are produced and transported in complex, inter-organizational, often internationally-spanning supply chains. Recent adoption of Internet of Things and Blockchain technologies give promise at better supply chain provenance. We are particularly interested in the blockchain as many favoured use cases of blockchain are for provenance tracking. We are also interested in applying ontologies as there has been some work done on knowledge provenance, traceability, and food provenance using ontologies. In this paper, we make a case for why ontologies can contribute to blockchain design. To support this case, we analyze a traceability ontology and translate some of its representations to smart contracts that execute a provenance trace and enforce traceability constraints on the Ethereum blockchain platform.",
            "output": [
                "Towards an Ontology-Driven Blockchain Design for Supply Chain Provenance"
            ]
        },
        {
            "id": "task1540-5bcbe6084e584c0d8a334107d82627aa",
            "input": "Many feature subset selection (FSS) algorithms have been proposed, but not all of them are appropriate for a given feature selection problem. At the same time, so far there is rarely a good way to choose appropriate FSS algorithms for the problem at hand. Thus, FSS algorithm automatic recommendation is very important and practically useful. In this paper, a meta learning based FSS algorithm automatic recommendation method is presented. The proposed method first identifies the data sets that are most similar to the one at hand by the k -nearest neighbor classification algorithm, and the distances among these data sets are calculated based on the commonly-used data set characteristics. Then, it ranks all the candidate FSS algorithms according to their performance on these similar data sets, and chooses the algorithms with best performance as the appropriate ones. The performance of the candidate FSS algorithms is evaluated by a multi-criteria metric that takes into account not only the classification accuracy over the selected features, but also the runtime of feature selection and the number of selected features. The proposed recommendation method is extensively tested on 115 real world data sets with 22 wellknown and frequently-used different FSS algorithms for five representative classifiers. The results show the effectiveness of our proposed FSS algorithm recommendation method.",
            "output": [
                "A Feature Subset Selection Algorithm Automatic Recommendation Method"
            ]
        },
        {
            "id": "task1540-6854ed5eb16c4223a0540afe753ec79d",
            "input": "Zero-resource speech technology is a growing research area that aims to develop methods for speech processing in the absence of transcriptions, lexicons, or language modelling text. Early systems focused on identifying isolated recurring terms in a corpus, while more recent full-coverage systems attempt to completely segment and cluster the audio into word-like units—effectively performing unsupervised speech recognition. To our knowledge, this article presents the first such system evaluated on largevocabulary multi-speaker data. The system uses a Bayesian modelling framework with segmental word representations: each word segment is represented as a fixed-dimensional acoustic embedding obtained by mapping the sequence of feature frames to a single embedding vector. We compare our system on English and Xitsonga datasets to state-of-the-art baselines, using a variety of measures including word error rate (obtained by mapping the unsupervised output to ground truth transcriptions). We show that by imposing a consistent top-down segmentation while also using bottom-up knowledge from detected syllable boundaries, both single-speaker and multi-speaker versions of our system outperform a purely bottom-up single-speaker syllable-based approach. We also show that the discovered clusters can be made less speakerand gender-specific by using an unsupervised autoencoder-like feature extractor to learn better frame-level features (prior to embedding). Our system’s discovered clusters are still less pure than those of two multi-speaker term discovery systems, but provide far greater coverage.",
            "output": [
                "A segmental framework for fully-unsupervised large-vocabulary speech recognition"
            ]
        },
        {
            "id": "task1540-df0f6371e54045f093efb4f867daca87",
            "input": "Given a teacher that holds a function f : X → R from some class of functions C. The teacher can receive from the learner an element d in the domain X (a query) and returns the value of the function in d, f(d) ∈ R. The learner goal is to find f with a minimum number of queries, optimal time complexity, and optimal resources. In this survey, we present some of the results known from the literature, different techniques used, some new problems, and open problems. ar X iv :1 70 6. 03 93 5v 1 [ cs .L G ] 1 3 Ju n 20 17",
            "output": [
                "Exact Learning from an Honest Teacher That Answers Membership Queries"
            ]
        },
        {
            "id": "task1540-af9f4b4f650346dba7624009e44c0977",
            "input": "In this paper, first we present a new explanation for the relation between logical circuits and artificial neural networks, logical circuits and fuzzy logic, and artificial neural networks and fuzzy inference systems. Then, based on these results, we propose a new neuro-fuzzy computing system which can effectively be implemented on the memristor-crossbar structure. One important feature of the proposed system is that its hardware can directly be trained using the Hebbian learning rule and without the need to any optimization. The system also has a very good capability to deal with huge number of input-out training data without facing problems like overtraining.",
            "output": [
                "Neuro-Fuzzy Computing System with the Capacity of Implementation on Memristor-Crossbar and Optimization-Free Hardware Training"
            ]
        },
        {
            "id": "task1540-b03e8539a8034267830f6952ced46076",
            "input": "Here, we propose a brain-inspired winner-take-all emotional neural network (WTAENN) and prove the universal approximation property for the novel architecture. WTAENN is a single layered feedforward neural network that benefits from the excitatory, inhibitory, and expandatory neural connections as well as the winner-take-all (WTA) competitions in the human brain’s nervous system. The WTA competition increases the information capacity of the model without adding hidden neurons. The universal approximation capability of the proposed architecture is illustrated on two example functions, trained by a genetic algorithm, and then applied to several competing recent and benchmark problems such as in curve fitting, pattern recognition, classification and prediction. In particular, it is tested on twelve UCI classification datasets, a facial recognition problem, three real world prediction problems (2 chaotic time series of geomagnetic activity indices and wind farm power generation data), two synthetic case studies with constant and nonconstant noise variance as well as k-selector and linear programming problems. Results indicate the general applicability and often superiority of the approach in terms of higher accuracy and lower model complexity, especially where low computational complexity is",
            "output": [
                "A Winner-Take-All Approach to Emotional Neural Networks with Universal Approximation Property"
            ]
        },
        {
            "id": "task1540-195f436ad7d442ed82c0f6752333fd81",
            "input": "Deep reinforcement learning methods attain super-human performance in a wide range of environments. Such methods are grossly inefficient, often taking orders of magnitudes more data than humans to achieve reasonable performance. We propose Neural Episodic Control: a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them. Our agent uses a semi-tabular representation of the value function: a buffer of past experience containing slowly changing state representations and rapidly updated estimates of the value function. We show across a wide range of environments that our agent learns significantly faster than other state-of-the-art, general purpose deep reinforcement learning agents.",
            "output": [
                "Neural Episodic Control"
            ]
        },
        {
            "id": "task1540-a57f578932ba4b0997c57a744a9ae080",
            "input": "Sepsis is a leading cause of mortality in intensive care units (ICUs) and costs hospitals billions annually. Treating a septic patient is highly challenging, because individual patients respond very differently to medical interventions and there is no universally agreed-upon treatment for sepsis. Understanding more about a patient’s physiological state at a given time could hold the key to effective treatment policies. In this work, we propose a new approach to deduce optimal treatment policies for septic patients by using continuous state-space models and deep reinforcement learning. Learning treatment policies over continuous spaces is important, because we retain more of the patient’s physiological information. Our model is able to learn clinically interpretable treatment policies, similar in important aspects to the treatment policies of physicians. Evaluating our algorithm on past ICU patient data, we find that our model could reduce patient mortality in the hospital by up to 3.6% over observed clinical policies, from a baseline mortality of 13.7%. The learned treatment policies could be used to aid intensive care clinicians in medical decision making and improve the likelihood of patient survival.",
            "output": [
                "Continuous State-Space Models for Optimal Sepsis Treatment - a Deep Reinforcement Learning Approach"
            ]
        },
        {
            "id": "task1540-2b7454a2b24c4952b611db829052192a",
            "input": "In this paper, we propose a novel learning based method for automated segmentation of brain tumor in multimodal MRI images. The machine learned features from fully convolutional neural network (FCN) and hand-designed texton features are used to classify the MRI image voxels. The score map with pixelwise predictions is used as a feature map which is learned from multimodal MRI training dataset using the FCN. The learned features are then applied to random forests to classify each MRI image voxel into normal brain tissues and different parts of tumor. The method was evaluated on BRATS 2013 challenge dataset. The results show that the application of the random forest classifier to multimodal MRI images using machine-learned features based on FCN and hand-designed features based on textons provides promising segmentations. The Dice overlap measure for automatic brain tumor segmentation against ground truth is 0.88, 080 and 0.73 for complete tumor, core and enhancing tumor, respectively.",
            "output": [
                "Multimodal MRI brain tumor segmentation using random forests with features learned from fully convolutional neural network"
            ]
        },
        {
            "id": "task1540-5a1ace342209481eb47dfb80f7901e39",
            "input": "Latent state space models are a fundamental and widely used tool for modeling dynamical systems. However, they are difficult to learn from data and learned models often lack performance guarantees on inference tasks such as filtering and prediction. In this work, we present the PREDICTIVE STATE INFERENCE MACHINE (PSIM), a data-driven method that considers the inference procedure on a dynamical system as a composition of predictors. The key idea is that rather than first learning a latent state space model, and then using the learned model for inference, PSIM directly learns predictors for inference in predictive state space. We provide theoretical guarantees for inference, in both realizable and agnostic settings, and showcase practical performance on a variety of simulated and real world robotics benchmarks.",
            "output": [
                "Learning to Filter with Predictive State Inference Machines"
            ]
        },
        {
            "id": "task1540-ff61c065bc084efeb028fe28e1d00314",
            "input": "We propose a methodology for designing dependable Artificial Neural Networks (ANN) by extending the concepts of understandability, correctness, and validity that are crucial ingredients in existing certification standards. We apply the concept in a concrete case study in designing a high-way ANNbased motion predictor to guarantee safety properties such as impossibility for the ego vehicle to suggest moving to the right lane if there exists another vehicle on its right.",
            "output": [
                "Neural Networks for Safety-Critical Applications - Challenges, Experiments and Perspectives"
            ]
        },
        {
            "id": "task1540-1a0060805da84f88b9bf470a25909c10",
            "input": "We define a logic of propositional formula schemata adding to the syntax of propositional logic indexed propositions (e.g., pi) and iterated connectives ∨ or ∧ ranging over intervals parameterized by arithmetic variables (e.g., ∧n i=1 pi, where n is a parameter). The satisfiability problem is shown to be undecidable for this new logic, but we introduce a very general class of schemata, called bound-linear, for which this problem becomes decidable. This result is obtained by reduction to a particular class of schemata called regular, for which we provide a sound and complete terminating proof procedure. This schemata calculus (called stab) allows one to capture proof patterns corresponding to a large class of problems specified in propositional logic. We also show that the satisfiability problem becomes again undecidable for slight extensions of this class, thus demonstrating that bound-linear schemata represent a good compromise between expressivity and decidability.",
            "output": [
                "Decidability and Undecidability Results for Propositional Schemata"
            ]
        },
        {
            "id": "task1540-369a05ac048b47f99aeeb52a1b9b902b",
            "input": "High-speed, low-latency obstacle avoidance that is insensitive to sensor noise is essential for enabling multiple decentralized robots to function reliably in cluttered and dynamic environments. While other distributed multi-agent collision avoidance systems exist, these systems require online geometric optimization where tedious parameter tuning and perfect sensing are necessary. We present a novel end-to-end framework to generate reactive collision avoidance policy for efficient distributed multi-agent navigation. Our method formulates an agent’s navigation strategy as a deep neural network mapping from the observed noisy sensor measurements to the agent’s steering commands in terms of movement velocity. We train the network on a large number of frames of collision avoidance data collected by repeatedly running a multi-agent simulator with different parameter settings. We validate the learned deep neural network policy in a set of simulated and real scenarios with noisy measurements and demonstrate that our method is able to generate a robust navigation strategy that is insensitive to imperfect sensing and works reliably in all situations. We also show that our method can be well generalized to scenarios that do not appear in our training data, including scenes with static obstacles and agents with different sizes. Videos are available at https://sites.google.com/view/deepmaca.",
            "output": [
                "Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation"
            ]
        },
        {
            "id": "task1540-564d00c16bbc4244ab0cca0afee10fef",
            "input": "This article presents an analysis of the influence of context information on dialog act recognition. We performed experiments on the widely explored Switchboard corpus, as well as on data annotated according to the recent ISO 24617-2 standard. The latter was obtained from the Tilburg DialogBank and through the mapping of the annotations of a subset of the Let’s Go corpus. We used a classification approach based on SVMs, which had proved successful in previous work and allowed us to limit the amount of context information provided. This way, we were able to observe the influence patterns as the amount of context information increased. Our base features consisted of n-grams, punctuation, and wh-words. Context information was obtained from one to five preceding segments and provided either as n-grams or dialog act classifications, with the latter typically leading to better results and more stable influence patterns. In addition to the conclusions about the importance and influence of context information, our experiments on the Switchboard corpus also led to results that advanced the state-of-the-art on the dialog act recognition task on that corpus. Furthermore, the results obtained on data annotated according to the ISO 24617-2 standard define a baseline for future work and contribute for the standardization of experiments in the area.",
            "output": [
                "The Influence of Context on Dialog Act Recognition"
            ]
        },
        {
            "id": "task1540-63df2a9adfda4bf691d74885ed841520",
            "input": "Quick interaction between a human teacher and a learning machine presents numerous benefits and challenges when working with web-scale data. The human teacher guides the machine towards accomplishing the task of interest. The learning machine leverages big data to find examples that maximize the training value of its interaction with the teacher. When the teacher is restricted to labeling examples selected by the machine, this problem is an instance of active learning. When the teacher can provide additional information to the machine (e.g., suggestions on what examples or predictive features should be used) as the learning task progresses, then the problem becomes one of interactive learning. To accommodate the two-way communication channel needed for efficient interactive learning, the teacher and the machine need an environment that supports an interaction language. The machine can access, process, and summarize more examples than the teacher can see in a lifetime. Based on the machine’s output, the teacher can revise the definition of the task or make it more precise. Both the teacher and the machine continuously learn and benefit from the interaction. We have built a platform to (1) produce valuable and deployable models and (2) support research on both the machine learning and user interface challenges of the interactive learning problem. The platform relies on a dedicated, low-latency, distributed, in-memory architecture that allows us to construct web-scale learning machines with quick interaction speed. The purpose of this paper is to describe this architecture and demonstrate how it supports our research efforts. Preliminary results are presented as illustrations of the architecture but are not the primary focus of the paper.",
            "output": [
                "ICE: Enabling Non-Experts to Build Models Interactively for Large-Scale Lopsided Problems"
            ]
        },
        {
            "id": "task1540-9f064f4a4c804e00bc8decfa2bec5580",
            "input": "In this paper, we argue that the future of Artificial Intelligence research resides in two keywords: integration and embodiment. We support this claim by analyzing the recent advances of the field. Regarding integration, we note that the most impactful recent contributions have been made possible through the integration of recent Machine Learning methods (based in particular on Deep Learning and Recurrent Neural Networks) with more traditional ones (e.g. Monte-Carlo tree search, goal babbling exploration or addressable memory systems). Regarding embodiment, we note that the traditional benchmark tasks (e.g. visual classification or board games) are becoming obsolete as state-of-the-art learning algorithms approach or even surpass human performance in most of them, having recently encouraged the development of first-person 3D game platforms embedding realistic physics. Building upon this analysis, we first propose an embodied cognitive architecture integrating heterogenous sub-fields of Artificial Intelligence into a unified framework. We demonstrate the utility of our approach by showing how major contributions of the field can be expressed within the proposed framework. We then claim that benchmarking environments need to reproduce ecologically-valid conditions for bootstrapping the acquisition of increasingly complex cognitive skills through the concept of a cognitive arms race between embodied agents.",
            "output": [
                "Embodied Artificial Intelligence through Distributed Adaptive Control: An Integrated Framework"
            ]
        },
        {
            "id": "task1540-a923d8c15d6445629e3b657773d682e6",
            "input": "Ordinary least squares (OLS) is the default method for fitting linear models, but is not applicable for problems with dimensionality larger than the sample size. For these problems, we advocate the use of a generalized version of OLS motivated by ridge regression, and propose two novel three-step algorithms involving least squares fitting and hard thresholding. The algorithms are methodologically simple to understand intuitively, computationally easy to implement efficiently, and theoretically appealing for choosing models consistently. Numerical exercises comparing our methods with penalization-based approaches in simulations and data analyses illustrate the great potential of the proposed algorithms.",
            "output": [
                "No penalty no tears: Least squares in high-dimensional linear models"
            ]
        },
        {
            "id": "task1540-174e35023db04c7289dfac69660b199b",
            "input": "Encoding finite linear CSPs as Boolean formulas and solving them by using modern SAT solvers has proven to be highly effective, as exemplified by the award-winning sugar system. We here develop an alternative approach based on ASP. This allows us to use first-order encodings providing us with a high degree of flexibility for easy experimentation with different implementations. The resulting system aspartame re-uses parts of sugar for parsing and normalizing CSPs. The obtained set of facts is then combined with an ASP encoding that can be grounded and solved by off-the-shelf ASP systems. We establish the competitiveness of our approach by empirically contrasting aspartame and sugar.",
            "output": [
                "Aspartame: Solving Constraint Satisfaction Problems with Answer Set Programming"
            ]
        },
        {
            "id": "task1540-d1134bd75c8749b9ba4cf49c5575b09e",
            "input": "This paper discusses real-time alignment of audio signals of music performance to the corresponding score (a.k.a. score following) which can handle tempo changes, errors and arbitrary repeats and/or skips (repeats/skips) in performances. This type of score following is particularly useful in automatic accompaniment for practices and rehearsals, where errors and repeats/skips are often made. Simple extensions of the algorithms previously proposed in the literature are not applicable in these situations for scores of practical length due to the problem of large computational complexity. To cope with this problem, we present two hidden Markov models of monophonic performance with errors and arbitrary repeats/skips, and derive efficient score-following algorithms with an assumption that the prior probability distributions of score positions before and after repeats/skips are independent from each other. We confirmed real-time operation of the algorithms with music scores of practical length (around 10000 notes) on a modern laptop and their tracking ability to the input performance within 0.7 s on average after repeats/skips in clarinet performance data. Further improvements and extension for polyphonic signals are also discussed. Keywords—Score following, audio-to-score alignment, arbitrary repeats and skips, fast Viterbi algorithm, hidden Markov model, music signal processing",
            "output": [
                "Real-Time Audio-to-Score Alignment of Music Performances Containing Errors and Arbitrary Repeats and Skips"
            ]
        },
        {
            "id": "task1540-c86cd0a75c56450fbbb80c8be1e21c1a",
            "input": "A decision tree is a classification (and regression) model that, based on the characteristics of a given object, and applying a series of rules, is able to classify it (or return a continuous value in the case of regression). The induction of decision trees from a set of previously classified objects is one of the most popular machine learning models due, among other things, to the low computational demand in their training and the interpretability of their results, so it is a representative white box model. ID3 algorithm presented by R. Quinlan in 1983 for the automatic construction of decision trees from a training set of objects described through a collection of properties. Each object in the training set belongs to a class (usually represented by the value of its target attribute) of a set of mutually exclusive classes. ID3 has been one of the most used techniques in machine learning with applications to tasks as diverse as epidemics prediction, robot control, and automatic classification of clients in banks or insurance entities [19, 18, 7]. The main goal of this work is to offer a methodology that allows to carry out machine learning tasks using decision trees on multi-relational graph data. In this context, the number of possible properties of each object goes far beyond those that it has directly associated, since the properties of the elements that are related to it can also be considered attributes of the object, and even the topological structure formed by the objects in their environment and the various measures that can be taken from the graph structure could be considered as additional attributes. With this objective, we will analyse different techniques that allow automatic induction of decision trees from graph data and we will present our proposal, GGQ-ID3, that aims to provide a framework to classify substructures in a graph, from simple nodes and edges, to larger paths and subgraphs, making use of Generalized Graph Query (GGQ) [1]. This paper is structured as follows: we will start reviewing different techniques of induction of relational decision trees; then, we present our proposal based on the use of Generalized Graph Queries as evaluation tool; once our proposal is presented, we will show some examples of its application; and finally we present some conclusions and future work lines.",
            "output": [
                "Induction of Decision Trees based on Generalized Graph Queries"
            ]
        },
        {
            "id": "task1540-bf6f870b06de4b4d956107ae84e32348",
            "input": "The Resource Description Framework (RDF) is a Semantic Web standard that provides a data language, simply called RDF, as well as a lightweight ontology language, called RDF Schema. We investigate embeddings of RDF in logic and show how standard logic programming and description logic technology can be used for reasoning with RDF. We subsequently consider extensions of RDF with datatype support, considering D entailment, defined in the RDF semantics specification, and D* entailment, a semantic weakening of D entailment, introduced by ter Horst. We use the embeddings and properties of the logics to establish novel upper bounds for the complexity of deciding entailment. We subsequently establish two novel lower bounds, establishing that RDFS entailment is PTime-complete and that simple-D entailment is coNP-hard, when considering arbitrary datatypes, both in the size of the entailing graph. The results indicate that RDFS may not be as lightweight as one may expect.",
            "output": [
                "Logical Foundations of RDF(S) with Datatypes"
            ]
        },
        {
            "id": "task1540-9d63545981ea457292baa4d004b65772",
            "input": "In this paper, we propose a framework for training multiple neural networks simultaneously. The parameters from all models are regularised by the tensor trace norm, so that one neural network is encouraged to reuse others’ parameters if possible – this is the main motivation behind multi-task learning. In contrast to many deep multi-task learning work, we do not predefine a parameter sharing strategy by tying some (usually bottom) layers’ parameters, instead, our framework allows the sharing for all shareable layers thus the sharing strategy is learned from a pure data-driven way.",
            "output": [
                "Trace Norm Regularised Deep Multi-Task Learning"
            ]
        },
        {
            "id": "task1540-47d9a4ed8f2c4157a2b1463029513bca",
            "input": "In this paper, we introduce evidence propagation operations on influence diagrams and a concept of value of evidence, which measures the value of experimentation. Evidence propagation operations are critical for the computation of the value of evidence, general update and inference operations in normative expert systems which are based on the influence diagram (generalized Bayesian network) paradigm. The value of evidence allows us to compute directly an outcome sensitivity, a value of perfect information and a value of control which are used in decision analysis (the science of decision making under uncertainty). More specifically, the outcome sensitivity is the maximum difference among the values of evidence, the value of perfect information is the expected value of the values of evidence, and the value of control is the optimal value of the values of evidence. We also discuss an implementation and a relative computational efficiency issues related to the value of evidence and the value of perfect information.",
            "output": [
                "Value of Evidence on Influence Diagrams"
            ]
        },
        {
            "id": "task1540-32b65596ad304a95a94831771b03eaf9",
            "input": "A plausible definition of \"reasoning\" could be \"algebraically manipulating previously acquired knowledge in order to answer a new question\". This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated \"all-purpose\" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up.",
            "output": [
                "From Machine Learning to Machine Reasoning"
            ]
        },
        {
            "id": "task1540-9fa5a5cde1bb4b2c84809f54b60ce5bb",
            "input": "Korf, Reid, and Edelkamp introduced a formula to predict the number of nodes IDA* will expand on a single iteration for a given consistent heuristic, and experimentally demonstrated that it could make very accurate predictions. In this paper we show that, in addition to requiring the heuristic to be consistent, their formula’s predictions are accurate only at levels of the brute-force search tree where the heuristic values obey the unconditional distribution that they defined and then used in their formula. We then propose a new formula that works well without these requirements, i.e., it can make accurate predictions of IDA*’s performance for inconsistent heuristics and if the heuristic values in any level do not obey the unconditional distribution. In order to achieve this we introduce the conditional distribution of heuristic values which is a generalization of their unconditional heuristic distribution. We also provide extensions of our formula that handle individual start states and the augmentation of IDA* with bidirectional pathmax (BPMX), a technique for propagating heuristic values when inconsistent heuristics are used. Experimental results demonstrate the accuracy of our new method and all its variations.",
            "output": [
                "Predicting the Performance of IDA* using Conditional Distributions"
            ]
        },
        {
            "id": "task1540-743f6f9617084b8eae5aa42f223b40b0",
            "input": "Most of the existing image-to-image translation frameworks—mapping an image in one domain to a corresponding image in another—are based on supervised learning, i.e., pairs of corresponding images in two domains are required for learning the translation function. This largely limits their applications, because capturing corresponding images in two different domains is often a difficult task. To address the issue, we propose the UNsupervised Image-to-image Translation (UNIT) framework, which is based on variational autoencoders and generative adversarial networks. The proposed framework can learn the translation function without any corresponding images in two domains. We enable this learning capability by combining a weight-sharing constraint and an adversarial training objective. Through visualization results from various unsupervised image translation tasks, we verify the effectiveness of the proposed framework. An ablation study further reveals the critical design choices. Moreover, we apply the UNIT framework to the unsupervised domain adaptation task and achieve better results than competing algorithms do in benchmark datasets.",
            "output": [
                "Unsupervised Image-to-Image Translation Networks"
            ]
        },
        {
            "id": "task1540-c6dc4d70ecf54533a2aea5dc13f93665",
            "input": "Conditional random fields (CRFs) are usually specified by graphical models but in this paper we propose to use probabilistic logic programs and specify them generatively. Our intension is first to provide a unified approach to CRFs for complex modeling through the use of a Turing complete language and second to offer a convenient way of realizing generative-discriminative pairs in machine learning to compare generative and discriminative models and choose the best model. We implemented our approach as the D-PRISM language by modifying PRISM, a logic-based probabilistic modeling language for generative modeling, while exploiting its dynamic programming mechanism for efficient probability computation. We tested D-PRISM with logistic regression, a linear-chain CRF and a CRF-CFG and empirically confirmed their excellent discriminative performance compared to their generative counterparts, i.e. naive Bayes, an HMM and a PCFG. We also introduced new CRF models, CRF-BNCs and CRF-LCGs. They are CRF versions of Bayesian network classifiers and probabilistic left-corner grammars respectively and easily implementable in D-PRISM. We empirically showed that they outperform their generative counterparts as expected.",
            "output": [
                "A Logic-based Approach to Generatively Defined Discriminative Modeling"
            ]
        },
        {
            "id": "task1540-8023d60327424e6987e21417c9cc3049",
            "input": "The ability to know in advance the trend of running process instances, with respect to different features, such as the expected completion time, would allow business managers to timely counteract to undesired situations, in order to prevent losses. Therefore, the ability to accurately predict future features of running business process instances would be a very helpful aid when managing processes, especially under service level agreement constraints. However, making such accurate forecasts is not easy: many factors may influence the predicted features. Many approaches have been proposed to cope with this problem but all of them assume that the underling process is stationary. However, in real cases this assumption is not always true. In this work we present new methods for predicting the remaining time of running cases. In particular we propose a method, assuming process stationarity, which outperforms the state-of-the-art and two other methods which are able to make predictions even with nonstationary processes. We also describe an approach able to predict the full sequence of activities that a running case is going to take. All these methods are extensively evaluated on two real case studies.",
            "output": [
                "Time and Activity Sequence Prediction of Business Process Instances"
            ]
        },
        {
            "id": "task1540-ab8cd193742543ac98c412898fdfa421",
            "input": "We introduce a framework for representing a variety of interesting problems as inference over the execution of probabilistic model programs. We represent a “solution” to such a problem as a guide program which runs alongside the model program and influences the model program's random choices, leading the model program to sample from a different distribution than from its priors. Ideally the guide program influences the model program to sample from the posteriors given the evidence. We show how the KLdivergence between the true posterior distribution and the distribution induced by the guided model program can be efficiently estimated (up to an additive constant) by sampling multiple executions of the guided model program. In addition, we show how to use the guide program as a proposal distribution in importance sampling to statistically prove lower bounds on the probability of the evidence and on the probability of a hypothesis and the evidence. We can use the quotient of these two bounds as an estimate of the conditional probability of the hypothesis given the evidence. We thus turn the inference problem into a heuristic search for better guide programs. Problem Specification Given partial observations of a complicated system governed by known or unknown probabilistic rules, we would like to automatically reason about the likely state of hidden parts of the system. Systems with Known Rules We model our system as a program in a general purpose programming language. We call this the model program. We will be agnostic to what programming language we are using. We will only insist that it be deterministic except for a choose function which takes a probability distribution as an argument and returns a random choice from it. The model program thus defines a probability distribution P(x) over execution paths x. If over the course of an execution path x of the model program, the choose function is called n times with distributions (P1, P2 ... Pn) and the randomly chosen values are (c1, c2 .. cn) respectively, then the probability of that execution path is P(x) = ∏i Pi(ci). We are interested in the conditional expected value E(h(x)|e), where h is some function of the execution path, and e is some evidence such that we can easily compute P(e|x) for any x. Our programming language needs to include constructs for specifying P(e|x) and h(x). The model program reports P(e|x) as the product of all calls to a function: evidence. This is a particularly convenient in that the evidence function can be passed boolean values which are interpreted as 0 or 1. For example, we could represent an observation that the grass is wet with the call evidence(grass_wet). If grass_wet is false, P(e|x) is multiplied by 0, and if grass_wet is false, P(e|x) is left unchanged. The value of the hypothesis h(x) is defined as the final value of a global variable *h*. We may not have a hypothesis, and may only be interested in sampling runs of the program given the evidence. In this case, *h* might not be set or used. Example 1: Three fair dice are rolled and it is observed that their sum is 7. What is the probability that the first die rolled was a 5? The following model program (shown in pseudocode) might encode that problem. die1 := choose(uniform(1..6)) die2 := choose(uniform(1..6)) die3 := choose(uniform(1..6))",
            "output": [
                "Variational Program Inference"
            ]
        },
        {
            "id": "task1540-2c026db23fa5496583819916911efc21",
            "input": "In this memory we made the design of an indexing model for Arabic language and adapting standards for describing learning resources used (the LOM and their application profiles) with learning conditions such as levels education of students, their levels of understanding... the pedagogical context with taking into account the representative elements of the text, text's length,... in particular, we highlight the specificity of the Arabic language which is a complex language, characterized by its flexion, its voyellation and its agglutination. Keyword: indexing model, pedagogical indexation, complexity of the Arabic language, standard description of educational resources, pedagogical context, intrinsic and extrinsic properties, indexing text, prism, facet.",
            "output": [
                "Developing a model for a text database indexed pedagogically for teaching the Arabic language"
            ]
        },
        {
            "id": "task1540-2815a6fca8d04bb3accdb469c4fa6647",
            "input": "In this paper, we establish some theoretical connections between Sum-Product Networks (SPNs) and Bayesian Networks (BNs). We prove that every SPN can be converted into a BN in linear time and space in terms of the network size. The key insight is to use Algebraic Decision Diagrams (ADDs) to compactly represent the local conditional probability distributions at each node in the resulting BN by exploiting context-specific independence (CSI). The generated BN has a simple directed bipartite graphical structure. We show that by applying the Variable Elimination algorithm (VE) to the generated BN with ADD representations, we can recover the original SPN where the SPN can be viewed as a history record or caching of the VE inference process. To help state the proof clearly, we introduce the notion of normal SPN and present a theoretical analysis of the consistency and decomposability properties. We conclude the paper with some discussion of the implications of the proof and establish a connection between the depth of an SPN and a lower bound of the tree-width of its corresponding BN.",
            "output": [
                "On the Relationship between Sum-Product Networks and Bayesian Networks"
            ]
        },
        {
            "id": "task1540-b9303471aa2a4f8f910e220274ac67c5",
            "input": "Predicting the next activity of a running process is an important aspect of process management. Recently, artificial neural networks, so called deep-learning approaches, have been proposed to address this challenge. This demo paper describes a software application that applies the Tensorflow deep-learning framework to process prediction. The software application reads industry-standard XES files for training and presents the user with an easy-to-use graphical user interface for both training and prediction. The system provides several improvements over earlier work. This demo paper focuses on the software implementation and describes the architecture and user interface.",
            "output": [
                "XES Tensorflow – Process Prediction using the Tensorflow Deep-Learning Framework"
            ]
        },
        {
            "id": "task1540-0a0f5a6181a44491bb4779417cacbb86",
            "input": "Nowadays, supervised learning is commonly used in many domains. Indeed, many works propose to learn new knowledge from examples that translate the expected behaviour of the considered system. A key issue of supervised learning concerns the description language used to represent the examples. In this paper, we propose a method to evaluate the feature set used to describe them. Our method is based on the computation of the consistency of the example base. We carried out a case study in the domain of geomatic in order to evaluate the sets of measures used to characterise geographic objects. The case study shows that our method allows to give relevant evaluations of measure sets. Supervised feature evaluation; consistency computation; geomatic",
            "output": [
                "Supervised feature evaluation by consistency analysis: application to measure sets used to characterise geographic objects"
            ]
        },
        {
            "id": "task1540-877e8d6f0bdb4dafb4a368d99af51bc0",
            "input": "<lb>This paper introduces AdaSDCA: an adap-<lb>tive variant of stochastic dual coordinate as-<lb>cent (SDCA) for solving the regularized empir-<lb>ical risk minimization problems. Our modifica-<lb>tion consists in allowing the method adaptively<lb>change the probability distribution over the dual<lb>variables throughout the iterative process. AdaS-<lb>DCA achieves provably better complexity bound<lb>than SDCA with the best fixed probability dis-<lb>tribution, known as importance sampling. How-<lb>ever, it is of a theoretical character as it is expen-<lb>sive to implement. We also propose AdaSDCA+:<lb>a practical variant which in our experiments out-<lb>performs existing non-adaptive methods.",
            "output": [
                "Stochastic Dual Coordinate Ascent with Adaptive Probabilities"
            ]
        },
        {
            "id": "task1540-e89683cb9cce4bd6b7a0bc19c88d9a34",
            "input": "We present the AP16-OL7 database which was released as the training and test data for the oriental language recognition (OLR) challenge on APSIPA 2016. Based on the database, a baseline system was constructed on the basis of the i-vector model. We report the baseline results evaluated in various metrics defined by the AP16-OLR evaluation plan and demonstrate that AP16-OL7 is a reasonable data resource for multilingual research.",
            "output": [
                "AP16-OL7: A Multilingual Database for Oriental Languages and A Language Recognition Baseline"
            ]
        },
        {
            "id": "task1540-7dc75037d9a04682b61db865fcea2492",
            "input": "We introduce an abductive method for a coherent integration of independent datasources. The idea is to compute a list of data-facts that should be inserted to the amalgamated database or retracted from it in order to restore its consistency. This method is implemented by an abductive solver, called Asystem, that applies SLDNFA-resolution on a meta-theory that relates different, possibly contradicting, input databases. We also give a pure model-theoretic analysis of the possible ways to ‘recover’ consistent data from an inconsistent database in terms of those models of the database that exhibit as minimal inconsistent information as reasonably possible. This allows us to characterize the ‘recovered databases’ in terms of the ‘preferred’ (i.e., most consistent) models of the theory. The outcome is an abductive-based application that is sound and complete with respect to a corresponding model-based, preferential semantics, and – to the best of our knowledge – is more expressive (thus more general) than any other implementation of coherent integration of databases.",
            "output": [
                "Coherent Integration of Databases by Abductive Logic Programming"
            ]
        },
        {
            "id": "task1540-4f1125478e8c4f1caf7a9500ff813e14",
            "input": "An efficient algorithm for recurrent neural network training is presented. The approach increases the training speed for tasks where a length of the input sequence may vary significantly. The proposed approach is based on the optimal batch bucketing by input sequence length and data parallelization on multiple graphical processing units. The baseline training performance without sequence bucketing is compared with the proposed solution for a different number of buckets. An example is given for the online handwriting recognition task using an LSTM recurrent neural network. The evaluation is performed in terms of the wall clock time, number of epochs, and validation loss value.",
            "output": [
                "Accelerating Recurrent Neural Network Training"
            ]
        },
        {
            "id": "task1540-dac58a8aa43248948d5355df4d3e65f4",
            "input": "Learning a good representation of text is key to many recommendation applications. Examples include news recommendation where texts to be recommended are constantly published everyday. However, most existing recommendation techniques, such as matrix factorization based methods, mainly rely on interaction histories to learn representations of items. While latent factors of items can be learned eectively from user interaction data, in many cases, such data is not available, especially for newly emerged items. In this work, we aim to address the problem of personalized recommendation for completely new items with text information available. We cast the problem as a personalized text ranking problem and propose a general framework that combines text embedding with personalized recommendation. Users and textual content are embedded into latent feature space. e text embedding function can be learned end-to-end by predicting user interactions with items. To alleviate sparsity in interaction data, and leverage large amount of text data with lile or no user interactions, we further propose a joint text embedding model that incorporates unsupervised text embedding with a combination module. Experimental results show that our model can signicantly improve the eectiveness of recommendation systems on real-world datasets.",
            "output": [
                "Joint Text Embedding for Personalized Content-based Recommendation"
            ]
        },
        {
            "id": "task1540-1928306c62b64742a756a6bba8c366eb",
            "input": "This paper introduces a new computing model based on the cooperation among Turing machines called orchestrated machines. Like universal Turing machines, orchestrated machines are also designed to simulate Turing machines but they can also modify the original operation of the included Turing machines to create a new layer of some kind of collective behavior. Using this new model we can define some interested notions related to cooperation ability of Turing machines such as the intelligence quotient or the emotional intelligence quotient for Turing machines.",
            "output": [
                "Are there intelligent Turing machines?"
            ]
        },
        {
            "id": "task1540-2d424d3e4db0461b860a7a128f464eb1",
            "input": "This paper describes the speech processing activities conducted at the Polish consortium of the CLARIN project. The purpose of this segment of the project was to develop specific tools that would allow for automatic and semi-automatic processing of large quantities of acoustic speech data. The tools include the following: grapheme-to-phoneme conversion, speech-to-text alignment, voice activity detection, speaker diarization, keyword spotting and automatic speech transcription. Furthermore, in order to develop these tools, a large high-quality studio speech corpus was recorded and released under an open license, to encourage development in the area of Polish speech research. Another purpose of the corpus was to serve as a reference for studies in phonetics and pronunciation. All the tools and resources were released on the the Polish CLARIN website. This paper discusses the current status and future plans for the project.",
            "output": [
                "Polish Read Speech Corpus for Speech Tools and Services"
            ]
        },
        {
            "id": "task1540-9ec7afb4ffa24e3a9b77c6fb715cdd06",
            "input": "We present a neural architecture for sequence processing. The ByteNet is a stack of two dilated convolutional neural networks, one to encode the source sequence and one to decode the target sequence, where the target network unfolds dynamically to generate variable length outputs. The ByteNet has two core properties: it runs in time that is linear in the length of the sequences and it preserves the sequences’ temporal resolution. The ByteNet decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent neural networks. The ByteNet also achieves a performance on raw character-level machine translation that approaches that of the best neural translation models that run in quadratic time. The implicit structure learnt by the ByteNet mirrors the expected alignments between the sequences.",
            "output": [
                "Neural Machine Translation in Linear Time"
            ]
        },
        {
            "id": "task1540-3ada5b05e29746cf9a9f085940b2f37d",
            "input": "This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.",
            "output": [
                "DRAW: A Recurrent Neural Network For Image Generation"
            ]
        },
        {
            "id": "task1540-7be024277db640d4b317a3344e4ed300",
            "input": "We give solutions to two fundamental computational problems in ontologybased data access with the W3C standard ontology language OWL2QL: the succinctness problem for first-order rewritings of ontology-mediated queries (OMQs), and the complexity problem for OMQ answering. We classify OMQs according to the shape of their conjunctive queries (treewidth, the number of leaves) and the existential depth of their ontologies. For each of these classes, we determine the combined complexity of OMQ answering, and whether all OMQs in the class have polynomial-size first-order, positive existential, and nonrecursive datalog rewritings. We obtain the succinctness results using hypergraph programs, a new computational model for Boolean functions, which makes it possible to connect the size of OMQ rewritings and circuit complexity.",
            "output": [
                "Ontology-Mediated Queries: Combined Complexity and Succinctness of Rewritings via Circuit Complexity"
            ]
        },
        {
            "id": "task1540-f918d753e58d4733bb4c589a7cbf10d3",
            "input": "Recommender systems apply data mining techniques and prediction algorithms to predict users’ interest on information, products and services among the tremendous amount of available items. The vast growth of information on the Internet as well as number of visitors to websites add some key challenges to recommender systems. These are: producing accurate recommendation, handling many recommendations efficiently and coping with the vast growth of number of participants in the system. Therefore, new recommender system technologies are needed that can quickly produce high quality recommendations even for huge data sets. To address these issues we have explored several collaborative filtering techniques such as the item based approach, which identify relationship between items and indirectly compute recommendations for users based on these relationships. The user based approach was also studied, it identifies relationships between users of similar tastes and computes recommendations based on these relationships. In this paper, we introduce the topic of recommender system. It provides ways to evaluate efficiency, scalability and accuracy of recommender system. The paper also analyzes different algorithms of user based and item based techniques for recommendation generation. Moreover, a simple experiment was conducted using a data mining application -Wekato apply data mining algorithms to recommender system. We conclude by proposing our approach that might enhance the quality of recommender systems.",
            "output": [
                "A Survey Paper on Recommender Systems"
            ]
        },
        {
            "id": "task1540-6eb334155da04e7f816785a3c02372a3",
            "input": "Adequate representation of natural language semantics requires access to vast amounts of common sense and domain-specific world knowledge. Prior work in the field was based on purely statistical techniques that did not make use of background knowledge, on limited lexicographic knowledge bases such as WordNet, or on huge manual efforts such as the CYC project. Here we propose a novel method, called Explicit Semantic Analysis (ESA), for fine-grained semantic interpretation of unrestricted natural language texts. Our method represents meaning in a high-dimensional space of concepts derived from Wikipedia, the largest encyclopedia in existence. We explicitly represent the meaning of any text in terms of Wikipedia-based concepts. We evaluate the effectiveness of our method on text categorization and on computing the degree of semantic relatedness between fragments of natural language text. Using ESA results in significant improvements over the previous state of the art in both tasks. Importantly, due to the use of natural concepts, the ESA model is easy to explain to human users.",
            "output": [
                "Wikipedia-based Semantic Interpretation for Natural Language Processing"
            ]
        },
        {
            "id": "task1540-13594451ad034d66a0bafc6cb4877788",
            "input": "A branch-and-bound approach to solving influence diagrams has been previously proposed in the literature, but appears to have never been implemented and evaluated – apparently due to the difficulties of computing effective bounds for the branch-and-bound search. In this paper, we describe how to efficiently compute effective bounds, and we develop a practical implementation of depth-first branch-and-bound search for influence diagram evaluation that outperforms existing methods for solving influence diagrams with multiple stages.",
            "output": [
                "Solving Multistage Influence Diagrams using Branch-and-Bound Search"
            ]
        },
        {
            "id": "task1540-96f91f2553ad4e7083ab6c4a5b7974cb",
            "input": "A major challenge in designing neural network (NN) systems is to determine the best structure and parameters for the network given the data for the machine learning problem at hand. Examples of parameters are the number of layers and nodes, the learning rates, and the dropout rates. Typically, these parameters are chosen based on heuristic rules and manually fine-tuned, which may be very time-consuming, because evaluating the performance of a single parametrization of the NN may require several hours. This paper addresses the problem of choosing appropriate parameters for the NN by formulating it as a box-constrained mathematical optimization problem, and applying a derivative-free optimization tool that automatically and effectively searches the parameter space. The optimization tool employs a radial basis function model of the objective function (the prediction accuracy of the NN) to accelerate the discovery of configurations yielding high accuracy. Candidate configurations explored by the algorithm are trained to a small number of epochs, and only the most promising candidates receive full training. The performance of the proposed methodology is assessed on benchmark sets and in the context of predicting drug-drug interactions, showing promising results. The optimization tool used in this paper is open-source.",
            "output": [
                "An effective algorithm for hyperparameter optimization of neural networks"
            ]
        },
        {
            "id": "task1540-99e48527a3be446b9126b10d9b700ad1",
            "input": "While going deeper has been witnessed to improve the performance of convolutional neural networks (CNN), going smaller for CNN has received increasing attention recently due to its attractiveness for mobile/embedded applications. It remains an active and important topic how to design a small network while retaining the performance of large and deep CNNs (e.g., Inception Nets, ResNets). Albeit there are already intensive studies on compressing the size of CNNs, the considerable drop of performance is still a key concern in many designs. This paper addresses this concern with several new contributions. First, we propose a simple yet powerful method for compressing the size of deep CNNs based on parameter binarization. The striking difference from most previous work on parameter binarization/quantization lies at different treatments of 1× 1 convolutions and k×k convolutions (k > 1), where we only binarize k × k convolutions into binary patterns. The resulting networks are referred to as pattern networks. By doing this, we show that previous deep CNNs such as GoogLeNet and Inception-type Nets can be compressed dramatically with marginal drop in performance. Second, in light of the different functionalities of 1×1 (data projection/transformation) and k × k convolutions (pattern extraction), we propose a new block structure codenamed the pattern residual block that adds transformed feature maps generated by 1×1 convolutions to the pattern feature maps generated by k × k convolutions, based on which we design a small network with ∼ 1 million parameters. Combining with our parameter binarization, we achieve better performance on ImageNet than using similar sized networks including recently released Google MobileNets.",
            "output": [
                "SEP-Nets: Small and Effective Pattern Networks"
            ]
        },
        {
            "id": "task1540-66be79442e8e4e08b612c27cadd0db01",
            "input": "Mental illness is one of the most pressing public health issues of our time. While counseling and psychotherapy can be effective treatments, our knowledge about how to conduct successful counseling conversations has been limited due to lack of large-scale data with labeled outcomes of the conversations. In this paper, we present a large-scale, quantitative study on the discourse of text-message-based counseling conversations. We develop a set of novel computational discourse analysis methods to measure how various linguistic aspects of conversations are correlated with conversation outcomes. Applying techniques such as sequence-based conversation models, language model comparisons, message clustering, and psycholinguistics-inspired word frequency analyses, we discover actionable conversation strategies that are associated with better conversation outcomes.",
            "output": [
                "Large-scale Analysis of Counseling Conversations: An Application of Natural Language Processing to Mental Health"
            ]
        },
        {
            "id": "task1540-238a927f71c145c790fc1daaac728d76",
            "input": "The deployment of deep convolutional neural networks (CNNs) in many real world applications is largely hindered by their high computational cost. In this paper, we propose a novel learning scheme for CNNs to simultaneously 1) reduce the model size; 2) decrease the run-time memory footprint; and 3) lower the number of computing operations, without compromising accuracy. This is achieved by enforcing channel-level sparsity in the network in a simple but effective way. Different from many existing approaches, the proposed method directly applies to modern CNN architectures, introduces minimum overhead to the training process, and requires no special software/hardware accelerators for the resulting models. We call our approach network slimming, which takes wide and large networks as input models, but during training insignificant channels are automatically identified and pruned afterwards, yielding thin and compact models with comparable accuracy. We empirically demonstrate the effectiveness of our approach with several state-of-the-art CNN models, including VGGNet, ResNet and DenseNet, on various image classification datasets. For VGGNet, a multi-pass version of network slimming gives a 20× reduction in model size and a 5× reduction in computing operations.",
            "output": [
                "Learning Efficient Convolutional Networks through Network Slimming"
            ]
        },
        {
            "id": "task1540-0816275800c343558d01073b586b2eae",
            "input": "A long-standing challenge in coreference resolution has been the incorporation of entity-level information – features defined over clusters of mentions instead of mention pairs. We present a neural network based coreference system that produces high-dimensional vector representations for pairs of coreference clusters. Using these representations, our system learns when combining clusters is desirable. We train the system with a learning-to-search algorithm that teaches it which local decisions (cluster merges) will lead to a high-scoring final coreference partition. The system substantially outperforms the current state-of-the-art on the English and Chinese portions of the CoNLL 2012 Shared Task dataset despite using few hand-engineered features.",
            "output": [
                "Improving Coreference Resolution by Learning Entity-Level Distributed Representations"
            ]
        },
        {
            "id": "task1540-97f31986a97b4d2cbc76aee14f4de658",
            "input": "Occlusion edges in images which correspond to range discontinuity in the scene from the point of view of the observer are an important prerequisite for many vision and mobile robot tasks. Although occlusion edges can be extracted from range data, extracting them from images and videos is challenging and would be extremely beneficial for a variety of robotics based applications. We trained a deep convolutional neural network (CNN) to identify occlusion edges in images and videos with both RGB-D and RGB inputs. The use of CNN avoids hand-crafting of features for automatically isolating occlusion edges and distinguishing them from appearance edges. Other than quantitative occlusion edge detection results, qualitative results are provided to demonstrate the trade-off between high resolution analysis and frame-level computation time which is critical for real-time robotics applications.",
            "output": [
                "Using Deep Convolutional Networks for Occlusion Edge Detection in RGB-D Frames"
            ]
        },
        {
            "id": "task1540-1f3cee89eb0f4ebea67ac6a4b8197954",
            "input": "Retrieval tasks typically require a ranking of items given a query. Collaborative filtering tasks, on the other hand, learn to model user’s preferences over items. In this paper we study the joint problem of recommending items to a user with respect to a given query, which is a surprisingly common task. This setup differs from the standard collaborative filtering one in that we are given a query × user × item tensor for training instead of the more traditional user × item matrix. Compared to document retrieval we do have a query, but we may or may not have content features (we will consider both cases) and we can also take account of the user’s profile. We introduce a factorized model for this new task that optimizes the top-ranked items returned for the given query and user. We report empirical results where it outperforms several baselines.",
            "output": [
                "Latent Collaborative Retrieval"
            ]
        },
        {
            "id": "task1540-4fd69c38644d4e77870a7559ff668bc0",
            "input": "It has been a long time, since data mining technologies have made their ways to the field of data management. Classification is one of the most important data mining tasks for label prediction, categorization of objects into groups, advertisement and data management. In this paper, we focus on the standard classification problem which is predicting unknown labels in Euclidean space. Most efforts in Machine Learning communities are devoted to methods that use probabilistic algorithms which are heavy on Calculus and Linear Algebra. Most of these techniques have scalability issues for big data, and are hardly parallelizable if they are to maintain their high accuracies in their standard form. Sampling is a new direction for improving scalability, using many small parallel classifiers. In this paper, rather than conventional sampling methods, we focus on a discrete classification algorithm with O(n) expected running time. Our approach performs a similar task as sampling methods. However, we use column-wise sampling of data, rather than the row-wise sampling used in the literature. In either case, our algorithm is completely deterministic. Our algorithm, proposes a way of combining 2D convex hulls in order to achieve high classification accuracy as well as scalability in the same time. First, we thoroughly describe and prove our O(n) algorithm for finding the convex hull of a point set in 2D. Then, we show with experiments our classifier model built based on this idea is very competitive compared with existing sophisticated classification algorithms included in commercial statistical applications such as MATLAB.",
            "output": [
                "DataGrinder: Fast, Accurate, Fully non-Parametric Classification Approach Using 2D Convex Hulls"
            ]
        },
        {
            "id": "task1540-6eaf3074ff0746899879c01e100c7613",
            "input": "Motivated by an application in computational biology, we consider low-rank matrix factorization with {0, 1}-constraints on one of the factors and optionally convex constraints on the second one. In addition to the non-convexity shared with other matrix factorization schemes, our problem is further complicated by a combinatorial constraint set of size 2m·r, where m is the dimension of the data points and r the rank of the factorization. Despite apparent intractability, we provide − in the line of recent work on non-negative matrix factorization by Arora et al. (2012)− an algorithm that provably recovers the underlying factorization in the exact case with O(mr2r +mnr + rn) operations for n datapoints. To obtain this result, we use theory around the Littlewood-Offord lemma from combinatorics.",
            "output": [
                "Matrix factorization with Binary Components"
            ]
        },
        {
            "id": "task1540-d2a7146b7bf247f8a7d636946d2704ed",
            "input": "Positive unlabeled (PU) learning is useful in various practical situations, where there is a need to learn a classifier for a class of interest from an unlabeled data set, which may contain anomalies as well as samples from unknown classes. The learning task can be formulated as an optimization problem under the framework of statistical learning theory. Recent studies have theoretically analyzed its properties and generalization performance, nevertheless, little effort has been made to consider the problem of scalability, especially when large sets of unlabeled data are available. In this work we propose a novel scalable PU learning algorithm that is theoretically proven to provide the optimal solution, while showing superior computational and memory performance. Experimental evaluation confirms the theoretical evidence and shows that the proposed method can be successfully applied to a large variety of real-world problems involving PU learning.",
            "output": [
                "Efficient Training for Positive Unlabeled Learning"
            ]
        },
        {
            "id": "task1540-5bc7d33f1b524b2ab2d1f12194bc21d6",
            "input": "The problem of inferring an inductive invariant for verifying program safety can be formulated in terms of binary classification. This is a standard problem in machine learning: given a sample of good and bad points, one is asked to find a classifier that generalizes from the sample and separates the two sets. Here, the good points are the reachable states of the program, and the bad points are those that reach a safety property violation. Thus, a learned classifier is a candidate invariant. In this paper, we propose a new algorithm that uses decision trees to learn candidate invariants in the form of arbitrary Boolean combinations of numerical inequalities. We have used our algorithm to verify C programs taken from the literature. The algorithm is able to infer safe invariants for a range of challenging benchmarks and compares favorably to other ML-based invariant inference techniques. In particular, it scales well to large sample sets.",
            "output": [
                "Learning Invariants using Decision Trees"
            ]
        },
        {
            "id": "task1540-37c84d36fd224c948ca8b126e4c02fbc",
            "input": "The UCT algorithm, which combines the UCB algorithm and Monte-Carlo Tree Search (MCTS), is currently the most widely used variant of MCTS. Recently, a number of investigations into applying other bandit algorithms to MCTS have produced interesting results. In this research, we will investigate the possibility of combining the improved UCB algorithm, proposed by Auer et al. [2], with MCTS. However, various characteristics and properties of the improved UCB algorithm may not be ideal for a direct application to MCTS. Therefore, some modifications were made to the improved UCB algorithm, making it more suitable for the task of game tree search. The Mi-UCT algorithm is the application of the modified UCB algorithm applied to trees. The performance of Mi-UCT is demonstrated on the games of 9× 9 Go and 9× 9 NoGo, and has shown to outperform the plain UCT algorithm when only a small number of playouts are given, and rougly on the same level when more playouts are available.",
            "output": [
                "Adapting Improved Upper Confidence Bounds for Monte-Carlo Tree Search"
            ]
        },
        {
            "id": "task1540-a15c959076e94889b5e91fe8939c4338",
            "input": "Stochastic gradient descent (SGD) is a standard optimization method to minimize a training error with respect to network parameters in modern neural network learning. However, it typically suffers from proliferation of saddle points in the high-dimensional parameter space. Therefore, it is highly desirable to design an efficient algorithm to escape from these saddle points and reach a parameter region of better generalization capabilities. Here, we propose a simple extension of SGD, namely reinforced SGD, which simply adds previous first-order gradients in a stochastic manner with a probability that increases with learning time. As verified in a simple synthetic dataset, this method significantly accelerates learning compared with the original SGD. Surprisingly, it dramatically reduces over-fitting effects, even compared with state-of-the-art adaptive learning algorithm—Adam. For a benchmark handwritten digits dataset, the learning performance is comparable to Adam, yet with an extra advantage of requiring one-fold less computer memory. The reinforced SGD is also compared with SGD with fixed or adaptive momentum parameter and Nesterov’s momentum, which shows that the proposed framework is able to reach a similar generalization accuracy with less computational costs. Overall, our method introduces stochastic memory into gradients, which plays an important role in understanding how gradient-based training algorithms can work and its relationship with generalization abilities of deep networks.",
            "output": [
                "Reinforced stochastic gradient descent for deep neural network learning"
            ]
        },
        {
            "id": "task1540-3a29e2a1012e4518a9bf9033081f2679",
            "input": "This paper presents our recent work on the design and development of a new, large scale dataset, which we name MS MARCO, for MAchine Reading COmprehension. This new dataset is aimed to overcome a number of well-known weaknesses of previous publicly available datasets for the same task of reading comprehension and question answering. In MS MARCO, all questions are sampled from real anonymized user queries. The context passages, from which answers in the dataset are derived, are extracted from real web documents using the most advanced version of the Bing search engine. The answers to the queries are human generated. Finally, a subset of these queries has multiple answers. We aim to release one million queries and the corresponding answers in the dataset, which, to the best of our knowledge, is the most comprehensive real-world dataset of its kind in both quantity and quality. We are currently releasing 100,000 queries with their corresponding answers to inspire work in reading comprehension and question answering along with gathering feedback from the research community.",
            "output": [
                "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"
            ]
        },
        {
            "id": "task1540-06d8c52b6ec64fb38ea323121f79fc27",
            "input": "Demand response (DR) for residential and small commercial buildings is estimated to account for as much as 65% of the total energy savings potential of DR, and previous work shows that a fully automated Energy Management System (EMS) is a necessary prerequisite to DR in these areas. In this paper, we propose a novel EMS formulation for DR problems in these sectors. Specifically, we formulate a fully automated EMS’s rescheduling problem as a reinforcement learning (RL) problem (referred to as the device based RL problem), and show that this RL problem decomposes over devices under reasonable assumptions. Compared with existent formulations, our new formulation (1) does not require explicitly modeling the user’s dissatisfaction on job rescheduling, (2) enables the EMS to self-initiate jobs, (3) allows the user to initiate more flexible requests and (4) has a computational complexity linear in the number of devices. We also propose several new performance metrics for RL algorithms applied to the device based RL problem, and demonstrate the simulation results of applying Q-learning, one of the most popular and classical RL algorithms, to a representative example.",
            "output": [
                "Optimal Demand Response Using Device Based Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-b7a30772b0b84c6fb63bf5923d4e5646",
            "input": "This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound of the mutual information objective that can be optimized efficiently. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing supervised methods.",
            "output": [
                "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets"
            ]
        },
        {
            "id": "task1540-04a74f0735384985a3dc654cede8eb9c",
            "input": "Understanding a long document requires tracking how entities are introduced and evolve over time. We present a new type of language model, ENTITYNLM, that can explicitly model entities, dynamically update their representations, and contextually generate their mentions. Our model is generative and flexible; it can model an arbitrary number of entities in context while generating each entity mention at an arbitrary length. In addition, it can be used for several different tasks such as language modeling, coreference resolution, and entity prediction. Experimental results with all these tasks demonstrate that our model consistently outperforms strong baselines and prior work.",
            "output": [
                "Dynamic Entity Representations in Neural Language Models"
            ]
        },
        {
            "id": "task1540-0da571862b854589b3508fa026a24276",
            "input": "This article deals with plausible reasoning from incomplete knowledge about large-scale spatial properties. The available information, consisting of a set of pointwise observations, is extrapolated to neighbour points. We use belief functions to represent the influence of the knowledge at a given point to another point; the quantitative strength of this in­ fluence decreases when the distance between both points increases. These influences are aggregated using a variant of Dempster's rule of combination taking into account the rela­ tive dependence between observations.",
            "output": [
                "Plausible reasoning from spatial observations"
            ]
        },
        {
            "id": "task1540-cf532ea49b64402d841c9cd25e20a7e4",
            "input": "We consider the problem of using sentence compression techniques to facilitate queryfocused multi-document summarization. We present a sentence-compression-based framework for the task, and design a series of learning-based compression models built on parse trees. An innovative beam search decoder is proposed to efficiently find highly probable compressions. Under this framework, we show how to integrate various indicative metrics such as linguistic motivation and query relevance into the compression process by deriving a novel formulation of a compression scoring function. Our best model achieves statistically significant improvement over the state-of-the-art systems on several metrics (e.g. 8.0% and 5.4% improvements in ROUGE-2 respectively) for the DUC 2006 and 2007 summarization task.",
            "output": [
                "A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization"
            ]
        },
        {
            "id": "task1540-2d8592bf55134efb97d719e2d67d6aa0",
            "input": "<lb>Many machine learning approaches are characterized by information constraints on how<lb>they interact with the training data. These include memory and sequential access constraints<lb>(e.g. fast first-order methods to solve stochastic optimization problems); communication con-<lb>straints (e.g. distributed learning); partial access to the underlying data (e.g. missing features<lb>and multi-armed bandits) and more. However, currently we have little understanding how such<lb>information constraints fundamentally affect our performance, independent of the learning prob-<lb>lem semantics. For example, are there learning problems where any algorithm which has small<lb>memory footprint (or can use any bounded number of bits from each example, or has certain<lb>communication constraints) will perform worse than what is possible without such constraints?<lb>In this paper, we describe how a single set of results implies positive answers to the above, for<lb>a variety of settings.",
            "output": [
                "Fundamental Limits of Online and Distributed Algorithms for Statistical Learning and Estimation"
            ]
        },
        {
            "id": "task1540-c41cbb823f17483eae5a7c726e096ee1",
            "input": "In this work, a computational intelligence (CI) technique named flexible neural tree (FNT) was developed to predict die filling performance of pharmaceutical granules and to identify significant die filling process variables. FNT resembles feedforward neural network, which creates a tree-like structure by using genetic programming. To improve accuracy, FNT parameters were optimized by using differential evolution algorithm. The performance of the FNT-based CI model was evaluated and compared with other CI techniques: multilayer perceptron, Gaussian process regression, and reduced error pruning tree. The accuracy of the CI model was evaluated experimentally using die filling as a case study. The die filling experiments were performed using a model shoe system and three different grades of microcrystalline cellulose (MCC) powders (MCC PH 101, MCC PH 102, and MCC DG). The feed powders were roll-compacted and milled into granules. The granules were then sieved into samples of various size classes. The mass of granules deposited into the die at different shoe speeds was measured. From these experiments, a dataset consisting true density, mean diameter (d50), granule size, and shoe speed as the inputs and the deposited mass as the output was generated. Cross-validation (CV) methods such as 10FCV and 5x2FCV were applied to develop and to validate the predictive models. It was found that the FNT based CI model (in the cases of both CV methods) performed much better than other CI models. Additionally, it was observed that process variables such as the granule size and the shoe speed had a higher impact on ∗Corresponding author Neural Comput & Applic (2016) DOI:10.1007/s00521-016-2545-8 1 ar X iv :1 70 9. 04 31 8v 1 [ cs .N E ] 1 6 M ay 2 01 7 the predictability than that of the powder property such as d50. Furthermore, validation of model prediction with experimental data showed that the die filling behavior of coarse granules could be better predicted than that of fine granules.",
            "output": [
                "Predictive Modeling of Die Filling of the Pharmaceutical Granules Using the Flexible Neural Tree"
            ]
        },
        {
            "id": "task1540-eb5cbaa90f70403ca59c9610180e301a",
            "input": "Sparse Filtering is a popular feature learning algorithm for image classification pipelines. In this paper, we connect the performance of Sparse Filtering with spectral properties of the corresponding feature matrices. This connection provides new insights into Sparse Filtering; in particular, it suggests early stopping of Sparse Filtering. We therefore introduce the Optimal Roundness Criterion (ORC), a novel stopping criterion for Sparse Filtering. We show that this stopping criterion is related with pre-processing procedures such as Statistical Whitening and demonstrate that it can make image classification with Sparse Filtering considerably faster and more accurate. Introduction Standard ways to improve image classification are to collect more samples or to change the representation and the processing of the data. In practice, the number of samples is typically limited, so that the second approach becomes relevant. An important tool for this second approach are feature learning algorithms, which aim at easing the classification task by transforming the data. Recently proposed deep learning methods intend to jointly learn learn a feature transformation and the classification (Krizhevsky, Sutskever, and Hinton 2012). In this work, however, we focus on unsupervised feature learning, especially on Sparse Filtering, because of their simplicity and scalability. Feature learning algorithms for image classification pipelines typically consists of three steps: pre-processing, (un)supervised dictionary learning, and encoding. An abundance of procedures is available for each of these steps, but for accurate image classification, we need procedures that are effective and interact beneficially with each other (Agarwal and Triggs 2006; Coates and Ng 2011; Coates, Ng, and Lee 2011; Jia, Huang, and Darrell 2012; Le 2013; LeCun, Huang, and Bottou 2004). Therefore, a profound understanding of these procedures is crucial to ensure accurate results and efficient computations. In this paper, we study the performance of Sparse Filtering (Ngiam et al. 2011) for image classification. Our main contributions are: Copyright © 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. • we show that Sparse Filtering can strongly benefit from early stopping; • we show that the performance of Sparse Filtering is correlated with spectral properties of feature matrices on tests sets; • we introduce the Optimal Roundness Criterion (ORC), a stopping criterion for Sparse Filtering based on the above correlation, and demonstrate that the ORC can considerably improve image classification. Feature Learning for Image Classification Feature learning algorithms often consist of two steps: In a first step, a dictionary is learned, and in a second step, the samples are encoded based on this dictionary. A typical dictionary learning step for image classification is sketched in Figure 1: First, random patches (samples) are extracted from the training images. These patches are then pre-processed using, for example, Statistical Whitening or Contrast Normalization. Finally, an unsupervised learning algorithm is applied to learn a dictionary from the pre-processed patches. Once a dictionary is learnt, several further steps need to be applied to finally train an image classifier, see, for example, (Coates and Ng 2011; Coates, Ng, and Lee 2011; Jia, Huang, and Darrell 2012; Le 2013). Our pipeline is similar to the one in (Coates and Ng 2011): We extract square patches comprising 9 × 9 pixels, pre-process them with Contrast Normalization1 and/or Statistical Whitening, and finally pass them to Random Patches or Sparse Filtering. (Note that our outcomes differ slightly from those in (Coates and Ng 2011) because we use square patches comprising 9×9 pixels instead of 6×6 pixels.) Subsequently, we apply soft-thresholding for encoding, 4×4 spatial max pooling for extracting features from the training data images, and finally L2 SVM classification (cf. (Coates and Ng 2011)). Numerous examples show that feature learning can considerably improve classification. Therefore, insight in the underlying principles of feature learning algorithms such as Statistical Whitening and Sparse Filtering is of great interest. Contrast normalization consists of subtracting the mean and dividing by the standard deviation of the pixel values. ar X iv :1 40 9. 46 89 v2 [ cs .C V ] 2 4 M ay 2 01 5 Training images Extraction of random patches Pre-processing Unsupervised learning Dictionary Figure 1: A typical dictionary learning step. Statistical Whitening and Contrast Normalization are examples for preprocessing procedures; Random Patches and Sparse Filtering are examples for unsupervised learning procedures. In mathematical terms, a feature learning algorithm provides a transformation F : Rl×p → Rn×p X 7→ F(X) (1) of an original feature matrix X ∈ Rl×p to a new feature matrix F(X) ∈ Rn×p. We adopt the convention that the rows of the matrices correspond to the features, the columns to the samples; this convention implies in particular that l ∈ N is the number of original features, p ∈ N the number of samples, and n ∈ N the number of new features. The Optimal Roundness Criterion Roundness of Feature Matrices Feature learning can be seen as trade-off between reducing the correlations of the feature representation and preservation of relevant information. This trade-off can be readily understood looking at Statistical Whitening. For this, recall that pre-processing with Statistical Whitening transforms a set of image patches into a new set of patches by changing the local correlation structure. More precisely, Statistical Whitening transforms patches XPatch ∈ R ′×p (n′ < n), that is, subsets of the entire feature matrix, into new patches FPatch(XPatch) such that FPatch(XPatch)FPatch(XPatch) = n′ In′ . Statistical Whitening therefore acts locally: while the correlation structures of the single patches are directly and radically changed, the structure of the entire matrix is affected only indirectly. However, these indirect effects on the entire matrix are important for the following. To capture these effects, we therefore introduce the roundness of a feature matrix F := F(X) given an original feature matrix X . On a high level, we say that the new feature matrix F is round if the spectrum of the associated Gram matrixFF ∈ Rn×n is narrow. To specify this notion, we denote the ordered eigenvalues of FF by σ1(F ) ≥ · · · ≥ σn(F ) ≥ 0 and their mean by σ(F ) := 1 n ∑n i=1 σi(F ) and define roundness as follows: Definition 1. For any matrix F 6= 0, we define its roundness as",
            "output": [
                "Compute Less to Get More: Using ORC to Improve Sparse Filtering"
            ]
        },
        {
            "id": "task1540-b266c478ea1d484a81495e4b491bfdbc",
            "input": "As food becomes an important part of modern life, recipes shared on the web are a great indicator of civilizations and culinary attitudes in different countries. Similarly, ingredients, flavors, and nutrition information are strong signals of the taste preferences of individuals from various parts of the world. Yet, we do not have a thorough understanding of these palate varieties. In this paper, we present a large-scale study of recipes published on the Web and their content, aiming to understand cuisines and culinary habits around the world. Using a database of more than 157K recipes from over 200 different cuisines, we analyze ingredients, flavors, and nutritional values which distinguish dishes from different regions, and use this knowledge to assess the predictability of recipes from different cuisines. We then use country health statistics to understand the relation between these factors and health indicators of different nations, such as obesity, diabetes, migration, and health expenditure. Our results confirm the strong effects of geographical and cultural similarities on recipes, health indicators, and culinary preferences between countries around the world.",
            "output": [
                "Kissing Cuisines: Exploring Worldwide Culinary Habits on the Web"
            ]
        },
        {
            "id": "task1540-5e9cc1a8bd2149a7bc9a6fa952202a61",
            "input": "This paper reports a novel deep architecture referred to as Maxout network In Network (MIN), which can enhance model discriminability and facilitate the process of information abstraction within the receptive field. The proposed network adopts the framework of the recently developed Network In Network structure, which slides a universal approximator, multilayer perceptron (MLP) with rectifier units, to exact features. Instead of MLP, we employ maxout MLP to learn a variety of piecewise linear activation functions and to mediate the problem of vanishing gradients that can occur when using rectifier units. Moreover, batch normalization is applied to reduce the saturation of maxout units by pre-conditioning the model and dropout is applied to prevent overfitting. Finally, average pooling is used in all pooling layers to regularize maxout MLP in order to facilitate information abstraction in every receptive field while tolerating the change of object position. Because average pooling preserves all features in the local patch, the proposed MIN model can enforce the suppression of irrelevant information during training. Our experiments demonstrated the state-of-the-art classification performance when the MIN model was applied to MNIST, CIFAR-10, and CIFAR-100 datasets and comparable performance for SVHN dataset.",
            "output": [
                "Batch-normalized Maxout Network in Network"
            ]
        },
        {
            "id": "task1540-59e0f41cb96f485288b6aa0ea8a26f33",
            "input": "The sample complexity of active learning under the realizability assumption has been well-studied. The realizability assumption, however, rarely holds in practice. In this paper, we theoretically characterize the sample complexity of active learning in the non-realizable case under multiview setting. We prove that, with unbounded Tsybakov noise, the sample complexity of multiview active learning can be Õ(log 1ǫ ), contrasting to single-view setting where the polynomial improvement is the best possible achievement. We also prove that in general multi-view setting the sample complexity of active learning with unbounded Tsybakov noise is Õ(1ǫ ), where the order of 1/ǫ is independent of the parameter in Tsybakov noise, contrasting to previous polynomial bounds where the order of 1/ǫ is related to the parameter in Tsybakov noise.",
            "output": [
                "Multi-View Active Learning in the Non-Realizable Case"
            ]
        },
        {
            "id": "task1540-f3a6c06f0f2c4c20a7d9174d95ba69ce",
            "input": "In this paper we describe COLIN, a forward-chaining heuristic search planner, capable of reasoning with COntinuous LINear numeric change, in addition to the full temporal semantics of PDDL2.1. Through this work we make two advances to the state-of-the-art in terms of expressive reasoning capabilities of planners: the handling of continuous linear change, and the handling of duration-dependent effects in combination with duration inequalities, both of which require tightly coupled temporal and numeric reasoning during planning. COLIN combines FF-style forward chaining search, with the use of a Linear Program (LP) to check the consistency of the interacting temporal and numeric constraints at each state. The LP is used to compute bounds on the values of variables in each state, reducing the range of actions that need to be considered for application. In addition, we develop an extension of the Temporal Relaxed Planning Graph heuristic of CRIKEY3, to support reasoning directly with continuous change. We extend the range of task variables considered to be suitable candidates for specifying the gradient of the continuous numeric change effected by an action. Finally, we explore the potential for employing mixed integer programming as a tool for optimising the timestamps of the actions in the plan, once a solution has been found. To support this, we further contribute a selection of extended benchmark domains that include continuous numeric effects. We present results for COLIN that demonstrate its scalability on a range of benchmarks, and compare to existing state-of-the-art planners.",
            "output": [
                "COLIN: Planning with Continuous Linear Numeric Change"
            ]
        },
        {
            "id": "task1540-f2407b330ffd4e9eb0390bf59579ed38",
            "input": "Many studies on the cost-sensitive learning assumed that a unique cost matrix is known for a problem. However, this assumption may not hold for many real-world problems. For example, a classifier might need to be applied in several circumstances, each of which associates with a different cost matrix. Or, different human experts have different opinions about the costs for a given problem. Motivated by these facts, this study aims to seek the minimax classifier over multiple cost matrices. In summary, we theoretically proved that, no matter how many cost matrices are involved, the minimax problem can be tackled by solving a number of standard cost-sensitive problems and sub-problems that involve only two cost matrices. As a result, a general framework for achieving minimax classifier over multiple cost matrices is suggested and justified by preliminary empirical studies.",
            "output": [
                "Minimax Classifier for Uncertain Costs"
            ]
        },
        {
            "id": "task1540-02dc182a89254b79936f6dfcd5fb37bf",
            "input": "This paper details the implementation of an algorithm for automatically generating a high-level knowledge network to perform commonsense reasoning, specifically with the application of robotic task repair. The network is represented using a Bayesian Logic Network (BLN) (Jain, Waldherr, and Beetz 2009), which combines a set of directed relations between abstract concepts, including IsA, AtLocation, HasProperty, and UsedFor, with a corresponding probability distribution that models the uncertainty inherent in these relations. Inference over this network enables reasoning over the abstract concepts in order to perform appropriate objectconcepts in order to perform appropriate object substitution or to locate missing objects in the robot’s environment. The structure of the network is generated by combining information from two existing knowledge sources: ConceptNet (Speer and Havasi 2012), and WordNet (Miller 1995). This is done in a \"situated\" manner by only including information relevant a given context. Results show that the generated network is able to accurately predict object categories, locations, properties, and affordances in three different household",
            "output": [
                "Situated Structure Learning of a Bayesian Logic Network for Commonsense Reasoning"
            ]
        },
        {
            "id": "task1540-facfae36d001468c80f1654e4e235ca3",
            "input": "A key problem in sensor networks is to decide which sensors<lb>to query when, in order to obtain the most useful information<lb>(e.g., for performing accurate prediction), subject to con-<lb>straints (e.g., on power and bandwidth). In many applications<lb>the utility function is not known a priori, must be learned<lb>from data, and can even change over time. Furthermore for<lb>large sensor networks solving a centralized optimization prob-<lb>lem to select sensors is not feasible, and thus we seek a fully<lb>distributed solution. In this paper, we present Distributed<lb>Online Greedy (DOG), an efficient, distributed algorithm for<lb>repeatedly selecting sensors online, only receiving feedback<lb>about the utility of the selected sensors. We prove very strong theoretical no-regret guarantees that apply whenever the (un-<lb>known) utility function satisfies a natural diminishing returns<lb>property called submodularity. Our algorithm has extremely<lb>low communication requirements, and scales well to large sensor deployments. We extend DOG to allow observation-<lb>dependent sensor selection. We empirically demonstrate the<lb>effectiveness of our algorithm on several real-world sensing<lb>tasks.",
            "output": [
                "Online Distributed Sensor Selection"
            ]
        },
        {
            "id": "task1540-5bed75f452bb47faa0fdc04d863df939",
            "input": "<lb>The minimization of the logistic loss is a popular approach to batch supervised learning. Our<lb>paper starts from the surprising observation that, when fitting linear (or kernelized) classifiers,<lb>the minimization of the logistic loss is equivalent to the minimization of an exponential rado-loss<lb>computed (i) over transformed data that we call Rademacher observations (rados), and (ii) over<lb>the same classifier as the one of the logistic loss. Thus, a classifier learnt from rados can be<lb>directly used to classify observations. We provide a learning algorithm over rados with boosting-<lb>compliant convergence rates on the logistic loss (computed over examples). Experiments on<lb>domains with up to millions of examples, backed up by theoretical arguments, display that<lb>learning over a small set of random rados can challenge the state of the art that learns over<lb>the complete set of examples. We show that rados comply with various privacy requirements<lb>that make them good candidates for machine learning in a privacy framework. We give several<lb>algebraic, geometric and computational hardness results on reconstructing examples from rados.<lb>We also show how it is possible to craft, and efficiently learn from, rados in a differential privacy<lb>framework. Tests reveal that learning from differentially private rados can compete with learning<lb>from random rados, and hence with batch learning from examples, achieving non-trivial privacy<lb>vs accuracy tradeoffs.",
            "output": [
                "Rademacher Observations, Private Data, and Boosting"
            ]
        },
        {
            "id": "task1540-dbab2cc5d9a04dafa3921d49df7e149c",
            "input": "Two popular approaches for distributed training of SVMs on big data are parameter averaging and ADMM. Parameter averaging is efficient but suffers from loss of accuracy with increase in number of partitions, while ADMM in the feature space is accurate but suffers from slow convergence. In this paper, we report a hybrid approach called weighted parameter averaging (WPA), which optimizes the regularized hinge loss with respect to weights on parameters. The problem is shown to be same as solving SVM in a projected space. We also demonstrate an O( 1 N ) stability bound on final hypothesis given by WPA, using novel proof techniques. Experimental results on a variety of toy and real world datasets show that our approach is significantly more accurate than parameter averaging for high number of partitions. It is also seen the proposed method enjoys much faster convergence compared to ADMM in features space.",
            "output": [
                "Distributed Weighted Parameter Averaging for SVM Training on Big Data"
            ]
        },
        {
            "id": "task1540-30988980adef4ec4899fe96dc273b5e2",
            "input": "We introduce a copula mixture model to perform dependency-seeking clustering when cooccurring samples from different data sources are available. The model takes advantage of the great flexibility offered by the copulas framework to extend mixtures of Canonical Correlation Analysis to multivariate data with arbitrary continuous marginal densities. We formulate our model as a non-parametric Bayesian mixture, while providing efficient MCMC inference. Experiments on synthetic and real data demonstrate that the increased flexibility of the copula mixture significantly improves the clustering and the interpretability of the results.",
            "output": [
                "Copula Mixture Model for Dependency-seeking Clustering"
            ]
        },
        {
            "id": "task1540-d34cac63a39641ccbb7592723ad67990",
            "input": "We present the Bayesian Case Model (BCM), a general framework for Bayesian case-based reasoning (CBR) and prototype classification and clustering. BCM brings the intuitive power of CBR to a Bayesian generative framework. The BCM learns prototypes, the “quintessential” observations that best represent clusters in a dataset, by performing joint inference on cluster labels, prototypes and important features. Simultaneously, BCM pursues sparsity by learning subspaces, the sets of features that play important roles in the characterization of the prototypes. The prototype and subspace representation provides quantitative benefits in interpretability while preserving classification accuracy. Human subject experiments verify statistically significant improvements to participants’ understanding when using explanations produced by BCM, compared to those given by prior art.",
            "output": [
                "The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification"
            ]
        },
        {
            "id": "task1540-554f302ea2ab40e9ad0d36c35a969870",
            "input": "We present paired learning and inference algorithms for significantly reducing computation and increasing speed of the vector dot products in the classifiers that are at the heart of many NLP components. This is accomplished by partitioning the features into a sequence of templates which are ordered such that high confidence can often be reached using only a small fraction of all features. Parameter estimation is arranged to maximize accuracy and early confidence in this sequence. Our approach is simpler and better suited to NLP than other related cascade methods. We present experiments in left-to-right part-of-speech tagging, named entity recognition, and transition-based dependency parsing. On the typical benchmarking datasets we can preserve POS tagging accuracy above 97% and parsing LAS above 88.5% both with over a five-fold reduction in run-time, and NER F1 above 88 with more than 2x increase in speed.",
            "output": [
                "Learning Dynamic Feature Selection for Fast Sequential Prediction"
            ]
        },
        {
            "id": "task1540-dd37f8d76d5143e6879382c8b0c226cb",
            "input": "In this paper we formulate the framework of recovering a hidden orthonormal basis given access to a<lb>certain “Basis Encoding Function”. We describe the class of Basis Encoding Functions (BEF), such that<lb>their local maxima on the unit sphere are in one-to-one correspondence with the basis elements. This<lb>description relies on a certain “hidden convexity” property of these functions. A number of theoretical<lb>and practical problems of recent interest can be interpreted as recovering a hidden basis from potentially<lb>noisy observations. Specifically, we show how our simple and general framework applies to Independent<lb>Component Analysis (ICA), tensor decompositions, spectral clustering and Gaussian mixture learning.<lb>We describe a new algorithm, “gradient iteration”, for provable recovery of the hidden basis. We<lb>provide a complete theoretical analysis of Gradient Iteration both for the exact case as well as for the<lb>case when the observed function is a perturbation of the “true” underlying BEF. In both cases we show<lb>convergence and complexity bounds polynomial in dimension and other relevant parameters, such as<lb>perturbation size. Our perturbation results can be considered as a very general non-linear version of<lb>the classical Davis-Kahan theorem for eigenvectors of perturbations of symmetric matrices. In addition<lb>we show that in the exact case the algorithm converges superlinearly and give conditions relating the<lb>degree of convergence to properties of the Basis Encoding Function. Our algorithm can be viewed as a<lb>generalization of the classical power iteration method for eigenanalysis of symmetric matrices as well as<lb>a generalization of power iterations for tensors. Moreover, the Gradient Iteration algorithm can be easily<lb>and efficiently implemented in practice.",
            "output": [
                "Learning a Hidden Basis Through Imperfect Measurements: An Algorithmic Primitive"
            ]
        },
        {
            "id": "task1540-13bafeef944b4b84a190a6cdfc6e8e11",
            "input": "Determinantal point processes (DPPs) are distributions over sets of items that model diversity using kernels. Their applications in machine learning include summary extraction and recommendation systems. Yet, the cost of sampling from a DPP is prohibitive in large-scale applications, which has triggered an effort towards efficient approximate samplers. We build a novel MCMC sampler that combines ideas from combinatorial geometry, linear programming, and Monte Carlo methods to sample from DPPs with a fixed sample cardinality, also called projection DPPs. Our sampler leverages the ability of the hit-and-run MCMC kernel to efficiently move across convex bodies. Previous theoretical results yield a fast mixing time of our chain when targeting a distribution that is close to a projection DPP, but not a DPP in general. Our empirical results demonstrate that this extends to sampling projection DPPs, i.e., our sampler is more sample-efficient than previous approaches which in turn translates to faster convergence when dealing with costlyto-evaluate functions, such as summary extraction in our experiments.",
            "output": [
                "Zonotope Hit-and-run for Efficient Sampling from Projection DPPs"
            ]
        },
        {
            "id": "task1540-b0cacdd388584db88b18c003e5a1e28a",
            "input": "The method of random projections has become very popular for large-scale applications in statistical learning, information retrieval, bio-informatics and other applications. Using a well-designed coding scheme for the projected data, which determines the number of bits needed for each projected value and how to allocate these bits, can significantly improve the effectiveness of the algorithm, in storage cost as well as computational speed. In this paper, we study a number of simple coding schemes, focusing on the task of similarity estimation and on an application to training linear classifiers. We demonstrate that uniform quantization outperforms the standard existing influential method [8]. Indeed, we argue that in many cases coding with just a small number of bits suffices. Furthermore, we also develop a nonuniform 2-bit coding scheme that generally performs well in practice, as confirmed by our experiments on training linear support vector machines (SVM).",
            "output": [
                "Coding for Random Projections"
            ]
        },
        {
            "id": "task1540-1a93f3c38aa14ee2b1a1293c7aaeafbd",
            "input": "The role of semantics in zero-shot learning is considered. The effectiveness of previous approaches is analyzed according to the form of supervision provided. While some learn semantics independently, others only supervise the semantic subspace explained by training classes. Thus, the former is able to constrain the whole space but lacks the ability to model semantic correlations. The latter addresses this issue but leaves part of the semantic space unsupervised. This complementarity is exploited in a new convolutional neural network (CNN) framework, which proposes the use of semantics as constraints for recognition.Although a CNN trained for classification has no transfer ability, this can be encouraged by learning an hidden semantic layer together with a semantic code for classification. Two forms of semantic constraints are then introduced. The first is a loss-based regularizer that introduces a generalization constraint on each semantic predictor. The second is a codeword regularizer that favors semantic-to-class mappings consistent with prior semantic knowledge while allowing these to be learned from data. Significant improvements over the state-of-the-art are achieved on several datasets.",
            "output": [
                "Semantically Consistent Regularization for Zero-Shot Recognition"
            ]
        },
        {
            "id": "task1540-94ad0088b98e4c19b23f6de6c7ad91b1",
            "input": "For any stream of time-stamped edges that form a dynamic network, an important choice is the aggregation granularity that an analyst uses to bin the data. Picking such a windowing of the data is often done by hand, or left up to the technology that is collecting the data. However, the choice can make a big difference in the properties of the dynamic network. This is the time scale detection problem. In previous work, this problem is often solved with a heuristic as an unsupervised task. As an unsupervised problem, it is difficult to measure how well a given algorithm performs. In addition, we show that the quality of the windowing is dependent on which task an analyst wants to perform on the network after windowing. Therefore the time scale detection problem should not be handled independently from the rest of the analysis of the network. We introduce a framework that tackles both of these issues: By measuring the performance of the time scale detection algorithm based on how well a given task is accomplished on the resulting network, we are for the first time able to directly compare different time scale detection algorithms to each other. Using this framework, we introduce time scale detection algorithms that take a supervised approach: they leverage ground truth on training data to find a good windowing of the test data. We compare the supervised approach to previous approaches and several baselines on real data.",
            "output": [
                "A supervised approach to time scale detection in dynamic networks"
            ]
        },
        {
            "id": "task1540-34fcd74e1e5a4832b3347d9ba934303e",
            "input": "We proposed a deep learning method for interpretable diabetic retinopathy (DR) detection. The visualinterpretable feature of the proposed method is achieved by adding the regression activation map (RAM) after the global averaging pooling layer of the convolutional networks (CNN). With RAM, the proposed model can localize the discriminative regions of an retina image to show the specific region of interest in terms of its severity level. We believe this advantage of the proposed deep learning model is highly desired for DR detection because in practice, users are not only interested with high prediction performance, but also keen to understand the insights of DR detection and why the adopted learning model works. In the experiments conducted on a large scale of retina image dataset, we show that the proposed CNN model can achieve high performance on DR detection compared with the state-ofthe-art while achieving the merits of providing the RAM to highlight the salient regions of the input image.",
            "output": [
                "Diabetic Retinopathy Detection via Deep Convolutional Networks for Disciminative Localization and Visual Explanation"
            ]
        },
        {
            "id": "task1540-cf2786db5a894d618b82371c6571ee03",
            "input": "Assessing the degree of semantic relatedness between words is an important task with a variety of semantic applications, such as ontology learning for the Semantic Web, semantic search or query expansion. To accomplish this in an automated fashion, many relatedness measures have been proposed. However, most of these metrics only encode information contained in the underlying corpus and thus do not directly model human intuition. To solve this, we propose to utilize a metric learning approach to improve existing semantic relatedness measures by learning from additional information, such as explicit human feedback. For this, we argue to use word embeddings instead of traditional high-dimensional vector representations in order to leverage their semantic density and to reduce computational cost. We rigorously test our approach on several domains including tagging data as well as publicly available embeddings based on Wikipedia texts and navigation. Human feedback about semantic relatedness for learning and evaluation is extracted from publicly available datasets such as MEN or WS-353. We find that our method can significantly improve semantic relatedness measures by learning from additional information, such as explicit human feedback. For tagging data, we are the first to generate and study embeddings. Our results are of special interest for ontology and recommendation engineers, but also for any other researchers and practitioners of Semantic Web techniques.",
            "output": [
                "Learning Semantic Relatedness from Human Feedback Using Metric Learning"
            ]
        },
        {
            "id": "task1540-68acc779aa6d4f5c93f667f4a93bfb79",
            "input": "Prepositions are very common and very ambiguous, and understanding their sense is critical for understanding the meaning of the sentence. Supervised corpora for the preposition-sense disambiguation task are small, suggesting a semi-supervised approach to the task. We show that signals from unannotated multilingual data can be used to improve supervised prepositionsense disambiguation. Our approach pre-trains an LSTM encoder for predicting the translation of a preposition, and then incorporates the pre-trained encoder as a component in a supervised classification system, and fine-tunes it for the task. The multilingual signals consistently improve results on two preposition-sense datasets.",
            "output": [
                "Semi Supervised Preposition-Sense Disambiguation using Multilingual Data"
            ]
        },
        {
            "id": "task1540-cdba9dd83c2540ff9bdde7c04b207496",
            "input": "We define two algorithms for propagating information in classification problems with pairwise relationships. The algorithms are based on contraction maps and are related to non-linear diffusion and random walks on graphs. The approach is also related to message passing algorithms, including belief propagation and mean field methods. The algorithms we describe are guaranteed to converge on graphs with arbitrary topology. Moreover they always converge to a unique fixed point, independent of initialization. We prove that the fixed points of the algorithms under consideration define lower-bounds on the energy function and the max-marginals of a Markov random field. The theoretical results also illustrate a relationship between message passing algorithms and value iteration for an infinite horizon Markov decision process. We illustrate the practical application of the algorithms under study with numerical experiments in image restoration, stereo depth estimation and binary classification on a grid.",
            "output": [
                "Diffusion Methods for Classification with Pairwise Relationships"
            ]
        },
        {
            "id": "task1540-f70ab5f734f54c6eaf53a2ae26661f30",
            "input": "ion in Belief Networks: The Role of Intermediate States in Diagnostic Reasoning Gregory Provan* Institute for Decision Systems Research 4984 El Camino Real, Suite 110 Los Altos, CA 94022",
            "output": [
                "Abstraction in Belief Networks: The Role of Intermediate States in Diagnostic Reasoning"
            ]
        },
        {
            "id": "task1540-9948a8a3becd4c48804ce136b62127c2",
            "input": "Many modern multiclass and multilabel problems are characterized by increasingly large output spaces. For these problems, label embeddings have been shown to be a useful primitive that can improve computational and statistical efficiency. In this work we utilize a correspondence between rank constrained estimation and low dimensional label embeddings that uncovers a fast label embedding algorithm which works in both the multiclass and multilabel settings. The result is a randomized algorithm whose running time is exponentially faster than naive algorithms. We demonstrate our techniques on two large-scale public datasets, from the Large Scale Hierarchical Text Challenge and the Open Directory Project, where we obtain state of the art results.",
            "output": [
                "Fast Label Embeddings via Randomized Linear Algebra"
            ]
        },
        {
            "id": "task1540-85b19a9b735648058e0bdbc936f39352",
            "input": "We study a stochastic and distributed algorithm for nonconvex problems whose objective consists of a sum of N nonconvex Li/N -smooth functions, plus a nonsmooth regularizer. The proposed NonconvEx primal-dual SpliTTing (NESTT) algorithm splits the problem into N subproblems, and utilizes an augmented Lagrangian based primal-dual scheme to solve it in a distributed and stochastic manner. With a special non-uniform sampling, a version of NESTT achieves -stationary solution using O(( ∑N i=1 √ Li/N) / ) gradient evaluations, which can be up to O(N) times better than the (proximal) gradient descent methods. It also achieves Q-linear convergence rate for nonconvex `1 penalized quadratic problems with polyhedral constraints. Further, we reveal a fundamental connection between primal-dual based methods and a few primal only methods such as IAG/SAG/SAGA.",
            "output": [
                "NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and Stochastic Optimization"
            ]
        },
        {
            "id": "task1540-2a661f614c2c4a49a7cac343b7c2f5a2",
            "input": "Transferring knowledge across a sequence of related tasks is an important challenge in reinforce-<lb>ment learning. Despite much encouraging empirical evidence that shows benefits of transfer, there<lb>has been very little theoretical analysis. In this paper, we study a class of lifelong reinforcement-<lb>learning problems: the agent solves a sequence of tasks modeled as finite Markov decision processes<lb>(MDPs), each of which is from a finite set of MDPs with the same state/action spaces and different<lb>transition/reward functions. Inspired by the need for cross-task exploration in lifelong learning, we<lb>formulate a novel online discovery problem and give an optimal learning algorithm to solve it. Such<lb>results allow us to develop a new lifelong reinforcement-learning algorithm, whose overall sample<lb>complexity in a sequence of tasks is much smaller than that of single-task learning, with high prob-<lb>ability, even if the sequence of tasks is generated by an adversary. Benefits of the algorithm are<lb>demonstrated in a simulated problem.",
            "output": [
                "The Online Discovery Problem and Its Application to Lifelong Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-ce271dbf312d469ba9635466e87a1e30",
            "input": "This work explores the effects of relevant and irrelevant boolean variables on the accuracy of classifiers. The analysis uses the assumption that the variables are conditionally independent given the class, and focuses on a natural family of learning algorithms for such sources when the relevant variables have a small advantage over random guessing. The main result is that algorithms relying predominately on irrelevant variables have error probabilities that quickly go to 0 in situations where algorithms that limit the use of irrelevant variables have errors bounded below by a positive constant. We also show that accurate learning is possible even when there are so few examples that one cannot determine with high confidence whether or not any individual variable is relevant.",
            "output": [
                "On the Necessity of Irrelevant Variables"
            ]
        },
        {
            "id": "task1540-83483ee9c70545d6862c1aca9b40a0f1",
            "input": "Berkeley FrameNet is a lexico-semantic resource for English based on the theory of frame semantics. It has been exploited in a range of natural language processing applications and has inspired the development of framenets for many languages. We present a methodological approach to the extraction and generation of a computational multilingual FrameNet-based grammar and lexicon. The approach leverages FrameNet-annotated corpora to automatically extract a set of cross-lingual semantico-syntactic valence patterns. Based on data from Berkeley FrameNet and Swedish FrameNet, the proposed approach has been implemented in Grammatical Framework (GF), a categorial grammar formalism specialized for multilingual grammars. The implementation of the grammar and lexicon is supported by the design of FrameNet, providing a frame semantic abstraction layer, an interlingual semantic API (application programming interface), over the interlingual syntactic API already provided by GF Resource Grammar Library. The evaluation of the acquired grammar and lexicon shows the feasibility of the approach. Additionally, we illustrate how the FrameNet-based grammar and lexicon are exploited in two distinct multilingual controlled natural language applications. The produced resources are available under an open source license.",
            "output": [
                "A Multilingual FrameNet-based Grammar and Lexicon for Controlled Natural Language"
            ]
        },
        {
            "id": "task1540-59769ce69f3d4f349219be4e85f1072f",
            "input": "We propose an effective technique to solving review-level sentiment classification problem by using sentence-level polarity correction. Our polarity correction technique takes into account the consistency of the polarities (positive and negative) of sentences within each product review before performing the actual machine learning task. While sentences with inconsistent polarities are removed, sentences with consistent polarities are used to learn state-of-the-art classifiers. The technique achieved better results on different types of products reviews and outperforms baseline models without the correction technique. Experimental results show an average of 82% F-measure on four different product review domains.",
            "output": [
                "Review-Level Sentiment Classification with Sentence-Level Polarity Correction"
            ]
        },
        {
            "id": "task1540-9dded0becfc7409cabf0f4bf8bf78738",
            "input": "Most neural network models for document classification on social media focus on text information to the neglect of other information on these platforms. In this paper, we classify post stance on social media channels and develop UTCNN, a neural network model that incorporates user tastes, topic tastes, and user comments on posts. UTCNN not only works on social media texts, but also analyzes texts in forums and message boards. Experiments performed on Chinese Facebook data and English online debate forum data show that UTCNN achieves a 0.755 macroaverage f-score for supportive, neutral, and unsupportive stance classes on Facebook data, which is significantly better than models in which either user, topic, or comment information is withheld. This model design greatly mitigates the lack of data for the minor class without the use of oversampling. In addition, UTCNN yields a 0.842 accuracy on English online debate forum data, which also significantly outperforms results from previous work as well as other deep learning models, showing that UTCNN performs well regardless of language or platform.",
            "output": [
                "UTCNN: a Deep Learning Model of Stance Classification on Social Media Text"
            ]
        },
        {
            "id": "task1540-5b8df3c6670149028e3f1b202fdc8b92",
            "input": "Using deep neural nets as function approximator for reinforcement learning tasks have recently been shown to be very powerful for solving problems approaching real-world complexity such as [1]. Using these results as a benchmark, we discuss the role that the discount factor may play in the quality of the learning process of a deep Q-network (DQN). When the discount factor progressively increases up to its final value, we empirically show that it is possible to significantly reduce the number of learning steps. When used in conjunction with a varying learning rate, we empirically show that it outperforms original DQN on several experiments. We relate this phenomenon with the instabilities of neural networks when they are used in an approximate Dynamic Programming setting. We also describe the possibility to fall within a local optimum during the learning process, thus connecting our discussion with the exploration/exploitation dilemma.",
            "output": [
                "How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies"
            ]
        },
        {
            "id": "task1540-dd0e88383b9b46eeacb8a14cb0f93324",
            "input": "In this work, we explore a genre of puzzles (“image riddles”) which involves a set of images and a question. An-<lb>swering these puzzles require both capabilities involving vi-<lb>sual detection (including object, activity recognition) and,<lb>knowledge-based or commonsense reasoning. We compile<lb>a dataset of over 3k riddles where each riddle consists of 4<lb>images and a groundtruth answer. The annotations are validated using crowd-sourced evaluation. We also define an<lb>automatic evaluation metric to track future progress. Our<lb>task bears similarity with the commonly known IQ tasks<lb>such as analogy solving, sequence filling that are often used<lb>to test intelligence. We develop a Probabilistic Reasoning-based approach<lb>that utilizes probabilistic commonsense knowledge to an-<lb>swer these riddles with a reasonable accuracy. We demon-<lb>strate the results of our approach using both automatic and<lb>human evaluations. Our approach achieves some promising<lb>results for these riddles and provides a strong baseline for future attempts. We make the entire dataset and related ma-<lb>terials publicly available to the community in ImageRiddle<lb>Website (http://bit.ly/22f9Ala).",
            "output": [
                "Answering Image Riddles using Vision and Reasoning through Probabilistic Soft Logic"
            ]
        },
        {
            "id": "task1540-cbb54febb9d0425499285d30b279aad5",
            "input": "Opinion Mining and Sentiment Analysis is a process of identifying opinions in large unstructured/structured data and then analysing polarity of those opinions. Opinion mining and sentiment analysis have found vast application in analysing online ratings, analysing product based reviews, egovernance, and managing hostile content over the internet. This paper proposes an algorithm to implement aspect level sentiment analysis. The algorithm takes input from the remarks submitted by various teachers of a student. An aspect tree is formed which has various levels and weights are assigned to each branch to identify level of aspect. Aspect value is calculated by the algorithm by means of the proposed aspect tree. Dictionary based method is implemented to evaluate the polarity of the remark. The algorithm returns the aspect value clubbed with opinion value and sentiment value which helps in concluding the summarized value of remark. Keywords—aspect tree, aspect value, opinion mining, opinion value, sentiment analysis",
            "output": [
                "Aspect Based Sentiment Analysis to Extract Meticulous Opinion Value"
            ]
        },
        {
            "id": "task1540-ca128b705d254e9d90bbd9d442d79c9e",
            "input": "In recent years deep neural networks have achieved great success in sentiment classification for English, thanks in part to the availability of copious annotated resources. Unfortunately, most other languages do not enjoy such an abundance of annotated data for sentiment analysis. To combat this problem, we propose the Adversarial Deep Averaging Network (ADAN) to transfer sentiment knowledge learned from labeled English data to lowresource languages where only unlabeled data exists. ADAN is a “Y-shaped” network with two discriminative branches: a sentiment classifier and an adversarial language predictor. Both branches take input from a feature extractor that aims to learn hidden representations that capture the underlying sentiment of the text and are invariant across languages. Experiments on Chinese sentiment classification demonstrate that ADAN significantly outperforms several baselines, including a strong pipeline approach that relies on Google Translate, the state-of-the-art commercial machine translation system.",
            "output": [
                "Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification"
            ]
        },
        {
            "id": "task1540-65be896035754d61b0860c4228c98ea4",
            "input": "We explore deep reinforcement learning methods for multi-agent domains. We begin by analyzing the difficulty of traditional algorithms in the multi-agent case: Q-learning is challenged by an inherent non-stationarity of the environment, while policy gradient suffers from a variance that increases as the number of agents grows. We then present an adaptation of actor-critic methods that considers action policies of other agents and is able to successfully learn policies that require complex multiagent coordination. Additionally, we introduce a training regimen utilizing an ensemble of policies for each agent that leads to more robust multi-agent policies. We show the strength of our approach compared to existing methods in cooperative as well as competitive scenarios, where agent populations are able to discover various physical and informational coordination strategies.",
            "output": [
                "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"
            ]
        },
        {
            "id": "task1540-bf5b7189d4a64eb983e3131a69c38c82",
            "input": "In Passive POMDPs actions do not affect the world state, but still incur costs. When the agent is bounded by information-processing constraints, it can only keep an approximation of the belief. We present a variational principle for the problem of maintaining the information which is most useful for minimizing the cost, and introduce an efficient and simple algorithm for finding an optimum.",
            "output": [
                "Bounded Planning in Passive POMDPs"
            ]
        },
        {
            "id": "task1540-895300b581de4e669717f443e168577e",
            "input": "<lb>We consider a situation in which we see samples Xn ∈ R drawn i.i.d. from some<lb>distribution with mean zero and unknown covariance A. We wish to compute the<lb>top eigenvector of A in an incremental fashion with an algorithm that maintains<lb>an estimate of the top eigenvector in O(d) space, and incrementally adjusts the<lb>estimate with each new data point that arrives. Two classical such schemes are<lb>due to Krasulina (1969) and Oja (1983). We give finite-sample convergence rates<lb>for both.",
            "output": [
                "The Fast Convergence of Incremental PCA"
            ]
        },
        {
            "id": "task1540-1426c1623cb04d38b5c0ade6089a4e38",
            "input": "Previous studies on Chinese semantic role labeling (SRL) have concentrated on single semantically annotated corpus. But the training data of single corpus is often limited. Meanwhile, there usually exists other semantically annotated corpora for Chinese SRL scattered across different annotation frameworks. Data sparsity remains a bottleneck. This situation calls for larger training datasets, or effective approaches which can take advantage of highly heterogeneous data. In these papers, we focus mainly on the latter, that is, to improve Chinese SRL by using heterogeneous corpora together. We propose a novel progressive learning model which augments the Progressive Neural Network with Gated Recurrent Adapters. The model can accommodate heterogeneous inputs and effectively transfer knowledge between them. We also release a new corpus, Chinese SemBank, for Chinese SRL. Experiments on CPB 1.0 show that ours model outperforms state-of-the-art methods.",
            "output": [
                "A Progressive Learning Approach to Chinese SRL Using Heterogeneous Data"
            ]
        },
        {
            "id": "task1540-27d92c2a924a4e19b759110270cdb0e8",
            "input": "A major goal of computer vision is to enable computers to interpret visual situations—abstract concepts (e.g., “a person walking a dog,” “a crowd waiting for a bus,” “a picnic”) whose image instantiations are linked more by their common spatial and semantic structure than by low-level visual similarity. In this paper, we propose a novel method for prior learning and active object localization for this kind of knowledge-driven search in static images. In our system, prior situation knowledge is captured by a set of flexible, kernel-based density estimations— a situation model—that represent the expected spatial structure of the given situation. These estimations are efficiently updated by information gained as the system searches for relevant objects, allowing the system to use context as it is discovered to narrow the search. More specifically, at any given time in a run on a test image, our system uses image features plus contextual information it has discovered to identify a small subset of training images— an importance cluster—that is deemed most similar to the given test image, given the context. This subset is used to generate an updated situation model in an on-line fashion, using an efficient multipole expansion technique. As a proof of concept, we apply our algorithm to a highly varied and challenging dataset consisting of instances of a “dog-walking” situation. Our results support the hypothesis that dynamically-rendered, context-based probability models can support efficient object localization in visual situations. Moreover, our approach is general enough to be applied to diverse machine learning paradigms requiring interpretable, probabilistic representations generated from partially observed data.",
            "output": [
                "Fast On-Line Kernel Density Estimation for Active Object Localization"
            ]
        },
        {
            "id": "task1540-02a1e357ca194cb2866b1eac6118c556",
            "input": "Human vision greatly benefits from the information about sizes of objects. The role of size in several visual reasoning tasks has been thoroughly explored in human perception and cognition. However, the impact of the information about sizes of objects is yet to be determined in AI. We postulate that this is mainly attributed to the lack of a comprehensive repository of size information. In this paper, we introduce a method to automatically infer object sizes, leveraging visual and textual information from web. By maximizing the joint likelihood of textual and visual observations, our method learns reliable relative size estimates, with no explicit human supervision. We introduce the relative size dataset and show that our method outperforms competitive textual and visual baselines in reasoning about size comparisons.",
            "output": [
                "Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects"
            ]
        },
        {
            "id": "task1540-dac5c236d60f4f6688f486314bb79dc8",
            "input": "Machine Translation is one of the major oldest and the most active research area in Natural Language Processing. Currently, Statistical Machine Translation (SMT) dominates the Machine Translation research. Statistical Machine Translation is an approach to Machine Translation which uses models to learn translation patterns directly from data, and generalize them to translate a new unseen text. The SMT approach is largely language independent, i.e. the models can be applied to any language pair. Statistical Machine Translation (SMT) attempts to generate translations using statistical methods based on bilingual text corpora. Where such corpora are available, excellent results can be attained translating similar texts, but such corpora are still not available for many language pairs. Statistical Machine Translation systems, in general, have difficulty in handling the morphology on the source or the target side especially for morphologically rich languages. Errors in morphology or syntax in the target language can have severe consequences on meaning of the sentence. They change the grammatical function of words or the understanding of the sentence through the incorrect tense information in verb. Baseline SMT also known as Phrase Based Statistical Machine Translation (PBSMT) system does not use any linguistic information and it only operates on surface word form. Recent researches shown that adding linguistic information helps to improve the accuracy of the translation with less amount of bilingual corpora. Adding linguistic information can be done using the Factored Statistical Machine Translation system through pre-processing steps. And importantly, machine translation system for language pair with disparate morphological structure needs best pre-processing or modeling before translation. English and Tamil languages are belongs to different language family so it is difficult for system to automate the morpho-syntactic mapping between them using statistical methods. This paper investigates about how English side pre-processing is used to improve the accuracy of English-Tamil SMT system.",
            "output": [
                "Improving the Performance of English-Tamil Statistical Machine Translation System using Source-Side Pre-Processing"
            ]
        },
        {
            "id": "task1540-1f6cd367ffc947c5a3110646257e5c98",
            "input": "Sequence labeling for extraction of medical events and their attributes from unstructured text in Electronic Health Record (EHR) notes is a key step towards semantic understanding of EHRs. It has important applications in health informatics including pharmacovigilance and drug surveillance. The state of the art supervised machine learning models in this domain are based on Conditional Random Fields (CRFs) with features calculated from fixed context windows. In this application, we explored recurrent neural network frameworks and show that they significantly outperformed the CRF models.",
            "output": [
                "Bidirectional RNN for Medical Event Detection in Electronic Health Records"
            ]
        },
        {
            "id": "task1540-029eab49ccd04900b0ef751ad2edd860",
            "input": "Recently, sequence-to-sequence model by using encoder-decoder neural network has gained popularity for automatic speech recognition (ASR). The architecture commonly uses an attentional mechanism which allows the model to learn alignments between source speech sequence and target text sequence. Most attentional mechanisms used today is based on a global attention property which requires a computation of a weighted summarization of the whole input sequence generated by encoder states. However, it is computationally expensive and often produces misalignment on the longer input sequence. Furthermore, it does not fit with monotonous or left-to-right nature in speech recognition task. In this paper, we propose a novel attention mechanism that has local and monotonic properties. Various ways to control those properties are also explored. Experimental results demonstrate that encoder-decoder based ASR with local monotonic attention could achieve significant performance improvements and reduce the computational complexity in comparison with the one that used the standard global attention architecture.",
            "output": [
                "Local Monotonic Attention Mechanism for End-to-End Speech Recognition"
            ]
        },
        {
            "id": "task1540-9c7ee691bd764cf892e2b75bfab642c4",
            "input": "The goal of semi-supervised learning methods is to effectively combine labeled and unlabeled data to arrive at a better model. Many methods rely on graph-based approaches, where labels are propagated through a graph over the input examples. In most current methods, the propagation mechanism underlying the learning objective is based on random walks. While theoretically elegant, random walks suffer from several drawbacks which can hurt predictive performance. In this work, we explore dynamic infection processes as an alternative propagation mechanism. In these, unlabeled nodes can be “infected” with the label of their already infected neighbors. We provide an efficient, scalable, and parallelizable algorithm for estimating the expected infection outcomes. We also describe an optimization view of the method, relating it to Laplacian approaches. Finally, experiments demonstrate that the method is highly competitive across multiple benchmarks and for various learning settings.",
            "output": [
                "Semi-Supervised Learning with Competitive Infection Models"
            ]
        },
        {
            "id": "task1540-dd7c30102b1a4516aa28229ada75dfe0",
            "input": "Automated Essay Scoring (AES) has been quite popular and is being widely used. However, lack of appropriate methodology for rating nonnative English speakers’ essays has meant a lopsided advancement in this field. In this paper, we report initial results of our experiments with nonnative AES that learns from manual evaluation of nonnative essays. For this purpose, we conducted an exercise in which essays written by nonnative English speakers in test environment were rated both manually and by the automated system designed for the experiment. In the process, we experimented with a few features to learn about nuances linked to nonnative evaluation. The proposed methodology of automated essay evaluation has yielded a correlation coefficient of 0.750 with the manual evaluation.",
            "output": [
                "Exploring Automated Essay Scoring for Nonnative English Speakers"
            ]
        },
        {
            "id": "task1540-a272ecf95d0d435d9b59406fba8c9e2d",
            "input": "In Pawlak’s rough set theory, a set is approximated by a pair of lower and upper approximations. To measure numerically the roughness of an approximation, Pawlak introduced a quantitative measure of roughness by using the ratio of the cardinalities of the lower and upper approximations. Although the roughness measure is effective, it has the drawback of not being strictly monotonic with respect to the standard ordering on partitions. Recently, some improvements have been made by taking into account the granularity of partitions. In this paper, we approach the roughness measure in an axiomatic way. After axiomatically defining roughness measure and partition measure, we provide a unified construction of roughness measure, called strong Pawlak roughness measure, and then explore the properties of this measure. We show that the improved roughness measures in the literature are special instances of our strong Pawlak roughness measure and introduce three more strong Pawlak roughness measures as well. The advantage of our axiomatic approach is that some properties of a roughness measure follow immediately as soon as the measure satisfies the relevant axiomatic definition.",
            "output": [
                "An axiomatic approach to the roughness measure of rough sets"
            ]
        },
        {
            "id": "task1540-d59cf3cbac03494da472abeea4337a26",
            "input": "A number of representation schemes have been presented for use within Learning Classifier Systems, ranging from binary encodings to neural networks. This paper presents results from an investigation into using a discrete dynamical system representation within the XCS Learning Classifier System. In particular, asynchronous random Boolean networks are used to represent the traditional condition-action production system rules. It is shown possible to use self-adaptive, open-ended evolution to design an ensemble of such discrete dynamical systems within XCS to solve a number of wellknown test problems.",
            "output": [
                "Discrete Dynamical Genetic Programming in XCS"
            ]
        },
        {
            "id": "task1540-af78a3fa55664231824b0b78772e7e00",
            "input": "Feature subset selection, as a special case of the general subset selection problem, has been the topic of a considerable number of studies due to the growing importance of data-mining applications. In the feature subset selection problem there are two main issues that need to be addressed: (i) Finding an appropriate measure function than can be fairly fast and robustly computed for high-dimensional data. (ii) A search strategy to optimize the measure over the subset space in a reasonable amount of time. In this article mutual information between features and class labels is considered to be the measure function. Two series expansions for mutual information are proposed, and it is shown that most heuristic criteria suggested in the literature are truncated approximations of these expansions. It is well-known that searching the whole subset space is an NP-hard problem. Here, instead of the conventional sequential search algorithms, we suggest a parallel search strategy based on semidefinite programming (SDP) that can search through the subset space in polynomial time. By exploiting the similarities between the proposed algorithm and an instance of the maximumcut problem in graph theory, the approximation ratio of this algorithm is derived and is compared with the approximation ratio of the backward elimination method. The experiments show that it can be misleading to judge the quality of a measure solely based on the classification accuracy, without taking the effect of the non-optimum search strategy into account.",
            "output": [
                "A Semidefinite Programming Based Search Strategy for Feature Selection with Mutual Information Measure"
            ]
        },
        {
            "id": "task1540-ab14921167814f9e9d46b1f7745c91a3",
            "input": "Surely we want solid foundations. What kind of castle can we build on sand? What is the point of devoting effort to balconies and minarets, if the foundation may be so weak as to allow the structure to collapse of its own weight? We want our foundations set on bedrock, designed to last for generations. Who would want an architect who cannot certify the soundness of the foundations of his buildings?",
            "output": [
                "Why Do We Need Foundations for Modelling Uncertainties?"
            ]
        },
        {
            "id": "task1540-c854371ba1824adca892c781f19a71a5",
            "input": "Reinforcement learning can acquire complex behaviors from high-level specifications. However, defining a cost function that can be optimized effectively and encodes the correct task is challenging in practice. We explore how inverse optimal control (IOC) can be used to learn behaviors from demonstrations, with applications to torque control of high-dimensional robotic systems. Our method addresses two key challenges in inverse optimal control: first, the need for informative features and effective regularization to impose structure on the cost, and second, the difficulty of learning the cost function under unknown dynamics for high-dimensional continuous systems. To address the former challenge, we present an algorithm capable of learning arbitrary nonlinear cost functions, such as neural networks, without meticulous feature engineering. To address the latter challenge, we formulate an efficient sample-based approximation for MaxEnt IOC. We evaluate our method on a series of simulated tasks and real-world robotic manipulation problems, demonstrating substantial improvement over prior methods both in terms of task complexity and sample efficiency.",
            "output": [
                "Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization"
            ]
        },
        {
            "id": "task1540-4ffa131f4d814aceb61d267565d26e41",
            "input": "Count-based exploration algorithms are known to perform near-optimally when used in conjunction with tabular reinforcement learning (RL) methods for solving small discrete Markov decision processes (MDPs). It is generally thought that count-based methods cannot be applied in high-dimensional state spaces, since most states will only occur once. Recent deep RL exploration strategies are able to deal with high-dimensional continuous state spaces through complex heuristics, often relying on optimism in the face of uncertainty or intrinsic motivation. In this work, we describe a surprising finding: a simple generalization of the classic count-based approach can reach near state-of-the-art performance on various highdimensional and/or continuous deep RL benchmarks. States are mapped to hash codes, which allows to count their occurrences with a hash table. These counts are then used to compute a reward bonus according to the classic count-based exploration theory. We find that simple hash functions can achieve surprisingly good results on many challenging tasks. Furthermore, we show that a domain-dependent learned hash code may further improve these results. Detailed analysis reveals important aspects of a good hash function: 1) having appropriate granularity and 2) encoding information relevant to solving the MDP. This exploration strategy achieves near state-of-the-art performance on both continuous control tasks and Atari 2600 games, hence providing a simple yet powerful baseline for solving MDPs that require considerable exploration.",
            "output": [
                "#Exploration:A Study of Count-Based Explorationfor Deep Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-4f3bd61f2b8a4fc790e415ce7608742b",
            "input": "In this information technology age, a convenient and user friendly interface is required to operate the computer system on very fast rate. In human being, speech being a natural mode of communication has potential to being a fast and convenient mode of interaction with computer. Speech recognition will play an important role in taking technology to them. It is the need of this era to access the information with in seconds. This paper describes the design and development of speaker independent and English command interpreted system for computer. HMM model is used to represent the phoneme like speech commands. Experiments have been done on real world data and system has been trained in normal condition for real world subject.",
            "output": [
                "CONATION: English Command Input/Output System for Computers"
            ]
        },
        {
            "id": "task1540-21e95016e96846ab809e12d41e69103d",
            "input": "We propose a novel approach to automatically produce multiple colorized versions of a grayscale image. Our method results from the observation that the task of automated colorization is relatively easy given a low-resolution version of the color image. We first train a conditional PixelCNN to generate a low resolution color for a given grayscale image. Then, given the generated low-resolution color image and the original grayscale image as inputs, we train a second CNN to generate a high-resolution colorization of an image. We demonstrate that our approach produces more diverse and plausible colorizations than existing methods, as judged by human raters in a ”Visual Turing Test”.",
            "output": [
                "PIXCOLOR: PIXEL RECURSIVE COLORIZATION"
            ]
        },
        {
            "id": "task1540-0e1e569ad50b44f7a37fde838687f3e1",
            "input": "How can we automatically discover the most important correspondences between words from two or more languages? How can we do so allowing for correspondences between any subset of languages, without drowning in redundant results, and at the same time maintaining control over the level of detail? These are exactly the questions we answer in this paper. We approach the problem with the Minimum Description Length principle, and give an efficient algorithm for discovering statistically important correspondences. We test the efficacy of our method against a set of Slavic languages. The experiments show our method automatically discovers non-trivial associations, allowing for both quantitative and qualitative analysis of multiple languages.",
            "output": [
                "Discovering Correspondences between Multiple Languages by MDL"
            ]
        },
        {
            "id": "task1540-b6116854f769414199578d4835357808",
            "input": "The paper introduces a new method for discrimination of documents given in different scripts. The document is mapped into a uniformly coded text of numerical values. It is derived from the position of the letters in the text line, based on their typographical characteristics. Each code is considered as a gray level. Accordingly, the coded text determines a 1-D image, on which texture analysis by run-length statistics and local binary pattern is performed. It defines feature vectors representing the script content of the document. A modified clustering approach employed on document feature vector groups documents written in the same script. Experimentation performed on two custom oriented databases of historical documents in old Cyrillic, angular and round Glagolitic as well as Antiqua and Fraktur scripts demonstrates the superiority of the proposed method with respect to well-known methods in the state-of-the-art.",
            "output": [
                "Document Image Coding and Clustering for Script Discrimination"
            ]
        },
        {
            "id": "task1540-80c09b5ad8584af79fee920e6139b2de",
            "input": "Several speaker identification systems are giving good performance with clean speech but are affected by the degradations introduced by noisy audio conditions. To deal with this problem, we investigate the use of complementary information at different levels for computing a combined match score for the unknown speaker. In this work, we observe the effect of two supervised machine learning approaches including support vectors machines (SVM) and naïve bayes (NB). We define two feature vector sets based on mel frequency cepstral coefficients (MFCC) and relative spectral perceptual linear predictive coefficients (RASTA-PLP). Each feature is modeled using the Gaussian Mixture Model (GMM). Several ways of combining these information sources give significant improvements in a text-independent speaker identification task using a very large telephone degraded NTIMIT database.",
            "output": [
                "A Multi Level Data Fusion Approach for Speaker Identification on Telephone Speech"
            ]
        },
        {
            "id": "task1540-437adabda45a4105b5416a3fe2e99afb",
            "input": "In practical situations, interval-valued fuzzy sets are frequently encountered. In this paper, firstly, we present shadowed sets for interpreting and understanding interval fuzzy sets. We also provide an analytic solution to computing the pair of thresholds by searching for a balance of uncertainty in the framework of shadowed sets. Secondly, we construct errorsbased three-way approximations of interval-valued fuzzy sets. We also provide an alternative decision-theoretic formulation for calculating the pair of thresholds by transforming intervalvalued loss functions into single-valued loss functions, in which the required thresholds are computed by minimizing decision costs. Thirdly, we compute errors-based three-way approximations of interval-valued fuzzy sets by using interval-valued loss functions. Finally, we employ several examples to illustrate that how to take an action for an object with intervalvalued membership grade by using interval-valued loss functions.",
            "output": [
                "Decision-theoretic rough sets-based three-way approximations of interval-valued fuzzy sets"
            ]
        },
        {
            "id": "task1540-993bbc102b944b9995f23892b8920603",
            "input": "We present some arguments why existing methods for representing agents fall short in applications crucial to artificial life. Using a thought experiment involving a fictitious dynamical systems model of the biosphere we argue that the metabolism, motility, and the concept of counterfactual variation should be compatible with any agent representation in dynamical systems. We then propose an informationtheoretic notion of integrated spatiotemporal patterns which we believe can serve as the basic building block of an agent definition. We argue that these patterns are capable of solving the problems mentioned before. We also test this in some preliminary experiments.",
            "output": [
                "Towards information based spatiotemporal patterns as a foundation for agent representation in dynamical systems"
            ]
        },
        {
            "id": "task1540-287a4c1ea94d48f09c120992ed6a347a",
            "input": "Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HOLE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator HOLE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. In extensive experiments we show that holographic embeddings are able to outperform state-ofthe-art methods for link prediction in knowledge graphs and relational learning benchmark datasets.",
            "output": [
                "Holographic Embeddings of Knowledge Graphs"
            ]
        },
        {
            "id": "task1540-25cc7584d22d4b0a81a4feb0e494acac",
            "input": "As digital games continue to be explored as solutions to educational and behavioural challenges, the need for evaluation methodologies which support both the unique nature of the format and the need for comparison with other approaches continues to increase. In this workshop paper, a range of challenges are described related specifically to the case of cultural learning using digital games, in terms of how it may best be assessed, understood, and sustained through an iterative process supported by research. An evaluation framework is proposed, identifying metrics for reach and impact and their associated challenges, as well as presenting ethical considerations and the means to utilize evaluation outcomes within an iterative cycle, and to provide feedback to learners. Presenting as a case study a serious game from the Mobile Assistance for Social Inclusion and Empowerment of Immigrants with Persuasive Learning Technologies and Social Networks (MASELTOV) project, the use of the framework in the context of an integrative project is discussed, with emphasis on the need to view game-based learning as a blended component of the cultural learning process, rather than a standalone solution. The particular case of mobile gaming is also considered within this case study, providing a platform by which to deliver and update content in response to evaluation outcomes. Discussion reflects upon the general challenges related to the assessment of cultural learning, and behavioural change in more general terms, suggesting future work should address the need to provide sustainable, research-driven platforms for game-based learning content.",
            "output": [
                "Assessing the Reach and Impact of Game-Based Learning Approaches to Cultural Competency and Behavioural Change"
            ]
        },
        {
            "id": "task1540-331773d1a0ff40109df555bd94062dfe",
            "input": "Since its appearance, Generative Adversarial Networks (GANs) [2] have received a lot of interest in the AI community. In image generation several projects showed how GANs are able to generate photorealistic images but the results so far didn’t look adequate for the quality standard of visual media production industry. We present an optimized image generation process based on a Deep Convolutional Generative Adversarial Networks (DCGANs), in order to create photorealistic high-resolution images (up to 1024x1024 pixels). Furthermore, the system was fed with a limited dataset of images, less than two thousand images. All these results give more clue about future exploitation of GANs in Computer Graphics and Visual Effects.",
            "output": [
                "Megapixel Size Image Creation using Generative Adversarial Networks"
            ]
        },
        {
            "id": "task1540-2f621410160d452ea061f5a9cd2fc972",
            "input": "Consider the following fundamental estimation problem: there are n entities, each with an unknown parameter pi ∈ [0, 1], and we observe n independent random variables,X1, . . . , Xn, withXi ∼Binomial(t, pi). How accurately can one recover the “histogram” (i.e. cumulative density function) of the pis? While the empirical estimates would recover the histogram to earth mover distance Θ( 1 √ t ) (equivalently, `1 distance between the CDFs), we show that, provided n is sufficiently large, we can achieve error O( 1t ) which is information theoretically optimal. We also extend our results to the multi-dimensional parameter case, capturing settings where each member of the population has multiple associated parameters. Beyond the theoretical results, we demonstrate that the recovery algorithm performs well in practice on a variety of datasets, providing illuminating insights into several domains, including politics, and sports analytics.",
            "output": [
                "Optimally Learning Populations of Parameters"
            ]
        },
        {
            "id": "task1540-bd76278da64c43c7baba3013c0eb6180",
            "input": "This report presents a plan to develop an intelligent Meta search engine,<lb>iral. This Meta search engine is aimed to provide comprehensive, efficient and<lb>relevant search results for given queries by combining results from different search<lb>engines. This will provide users to cover a larger database of World Wide Web for<lb>their queries and to get more relevant search results. On the other hand this Meta<lb>search engine will be creating a larger user base and attracting online marketing for<lb>Abster-iT. This will provide a new business set-up for Abster-iT.",
            "output": [
                "Intelligent Search Optimization using Artificial fuzzy logic"
            ]
        },
        {
            "id": "task1540-12580220035f4043ab8ced5768a54dc8",
            "input": "This paper describes our approach for the Detecting Stance in Tweets task (SemEval-2016 Task 6). We utilized recent advances in short text categorization using deep learning to create word-level and character-level models. The choice between word-level and characterlevel models in each particular case was informed through validation performance. Our final system is a combination of classifiers using word-level or character-level models. We also employed novel data augmentation techniques to expand and diversify our training dataset, thus making our system more robust. Our system achieved a macro-average precision, recall and F1-scores of 0.67, 0.61 and 0.635 respectively.",
            "output": [
                "DeepStance at SemEval-2016 Task 6: Detecting Stance in Tweets Using Character and Word-Level CNNs"
            ]
        },
        {
            "id": "task1540-992683af9bb34481b370968f09b0b3d5",
            "input": "The Lumiere Project centers on harnessing probability and utility to provide assistance to computer software users. We review work on Bayesian user models that can be em­ ployed to infer a user's needs by consider­ ing a user's background, actions, and queries. Several problems were tackled in Lumiere research, including ( 1) the construction of Bayesian models for reasoning about the time-varying goals of computer users from their observed actions and queries, (2) gain­ ing access to a stream of events from soft­ ware applications, (3) developing a language for transforming system events into observa­ tional variables represented in Bayesian user models, ( 4) developing persistent profiles to capture changes in a user's expertise, and (5) the development of an overall architecture for an intelligent user interface. Lumiere proto­ types served as the basis for the Office Assis­ tant in the Microsoft Office '97 suite of pro­ ductivity applications.",
            "output": [
                "The Lumiere Project: Bayesian User Modeling for Inferring the Goals and Needs of Software Users"
            ]
        },
        {
            "id": "task1540-ded30079206a41cfbc4389ffaf5c159a",
            "input": "We propose a simple, scalable, and fast gradient descent algorithm to optimize a nonconvex objective for the rank minimization problem and a closely related family of semidefinite programs. WithO(r3κ2n log n) random measurements of a positive semidefinite n×nmatrix of rank r and condition number κ, our method is guaranteed to converge linearly to the global optimum.",
            "output": [
                "A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements"
            ]
        },
        {
            "id": "task1540-d35b621dfa17463b89fb8c0d7d7beb7f",
            "input": "Deep neural networks trained on large supervised datasets have led to impressive results in recent years. However, since well-annotated datasets can be prohibitively expensive and time-consuming to collect, recent work has explored the use of larger but noisy datasets that can be more easily obtained. In this paper, we investigate the behavior of deep neural networks on training sets with massively noisy labels. We show that successful learning is possible even with an essentially arbitrary amount of noise. For example, on MNIST we find that accuracy of above 90 percent is still attainable even when the dataset has been diluted with 100 noisy examples for each clean example. Such behavior holds across multiple patterns of label noise, even when noisy labels are biased towards confusing classes. Further, we show how the required dataset size for successful training increases with higher label noise. Finally, we present simple actionable techniques for improving learning in the regime of high label noise.",
            "output": [
                "Deep Learning is Robust to Massive Label Noise"
            ]
        },
        {
            "id": "task1540-a405c782040c4d9fa6f13418fcfbeea4",
            "input": "We study the problem of prediction with expert advice when the number of experts in question may be extremely large or even infinite. We devise an algorithm that obtains a tight regret bound of r OpǫT `N ` ? NT q, where N is the empirical ǫ-covering number of the sequence of loss functions generated by the environment. In addition, we present a hedging procedure that allows us to find the optimal ǫ in hindsight. Finally, we discuss a few interesting applications of our algorithm. We show how our algorithm is applicable in the approximately low rank experts model of Hazan et al., 2016, and discuss the case of experts with bounded variation, in which there is a surprisingly large gap between the regret bounds obtained in the statistical and online settings.",
            "output": [
                "Online Learning with Many Experts"
            ]
        },
        {
            "id": "task1540-f35712fd50014aa0a838b712c84f3387",
            "input": "Recent research shows that deep neural networks (DNNs) can be used to extract deep speaker vectors (d-vectors) that preserve speaker characteristics and can be used in speaker verification. This new method has been tested on text-dependent speaker verification tasks, and improvement was reported when combined with the conventional i-vector method. This paper extends the d-vector approach to semi textindependent speaker verification tasks, i.e., the text of the speech is in a limited set of short phrases. We explore various settings of the DNN structure used for d-vector extraction, and present a phone-dependent training which employs the posterior features obtained from an ASR system. The experimental results show that it is possible to apply d-vectors on semi text-independent speaker recognition, and the phone-dependent training improves system performance.",
            "output": [
                "Deep Speaker Vectors for Semi Text-independent Speaker Verification"
            ]
        },
        {
            "id": "task1540-1620a7b6fa774e2a94b535bcf9f34d29",
            "input": "We present a Bayesian approach to adapting parameters of a well-trained context-dependent, deep-neural-network, hidden Markov model (CD-DNN-HMM) to improve automatic speech recognition performance. Given an abundance of DNN parameters but with only a limited amount of data, the effectiveness of the adapted DNN model can often be compromised. We formulate maximum a posteriori (MAP) adaptation of parameters of a specially designed CD-DNN-HMM with an augmented linear hidden networks connected to the output tied states, or senones, and compare it to feature space MAP linear regression previously proposed. Experimental evidences on the 20,000-word open vocabulary Wall Street Journal task demonstrate the feasibility of the proposed framework. In supervised adaptation, the proposed MAP adaptation approach provides more than 10% relative error reduction and consistently outperforms the conventional transformation based methods. Furthermore, we present an initial attempt to generate hierarchical priors to improve adaptation efficiency and effectiveness with limited adaptation data by exploiting similarities among senones.",
            "output": [
                "Maximum a Posteriori Adaptation of Network Parameters in Deep Models"
            ]
        },
        {
            "id": "task1540-ad9c19a3ef4a41929914a67a86b0ade9",
            "input": "Standard LDA model suffers the problem that the topic assignment of each word is independent and word correlation hence is neglected. To address this problem, in this paper, we propose a model called Word Related Latent Dirichlet Allocation (WR-LDA) by incorporating word correlation into LDA topic models. This leads to new capabilities that standard LDA model does not have such as estimating infrequently occurring words or multi-language topic modeling. Experimental results demonstrate the effectiveness of our model compared with standard LDA.",
            "output": [
                "Modeling Word Relatedness in Latent Dirichlet Allocation"
            ]
        },
        {
            "id": "task1540-67fedecace364dfc983aab689230aca6",
            "input": "We introduce an exceptionally simple gated recurrent neural network (RNN) that achieves performance comparable to well-known gated architectures, such as LSTMs and GRUs, on the word-level language modeling task. We prove that our model has simple, predicable and non-chaotic dynamics. This stands in stark contrast to more standard gated architectures, whose underlying dynamical systems exhibit chaotic behavior.",
            "output": [
                "A RECURRENT NEURAL NETWORK WITHOUT CHAOS"
            ]
        },
        {
            "id": "task1540-d442a1f3ff27485f89ecbc5281f89df2",
            "input": "The paper presents a new script classification method for the discrimination of the South Slavic medieval labels. It consists in the textural analysis of the script types. In the first step, each letter is coded by the equivalent script type, which is defined by its typographical features. Obtained coded text is subjected to the run-length statistical analysis and to the adjacent local binary pattern analysis in order to extract the features. The result shows a diversity between the extracted features of the scripts, which makes the feature classification more effective. It is the basis for the classification process of the script identification by using an extension of a state-of-the-art approach for document clustering. The proposed method is evaluated on an example of hand-engraved in stone and handprinted in paper labels in old Cyrillic, angular and round Glagolitic. Experiments demonstrate very positive results, which prove the effectiveness of the proposed method.",
            "output": [
                "An Approach to the Analysis of the South Slavic Medieval Labels Using Image Texture"
            ]
        },
        {
            "id": "task1540-bfdcfc40b45f4156956c81a8f174c2e5",
            "input": "To achieve acceptable performance for AI tasks, one can either use sophisticated feature extraction methods as the first layer in a twolayered supervised learning model, or learn the features directly using a deep (multilayered) model. While the first approach is very problem-specific, the second approach has computational overheads in learning multiple layers and fine-tuning of the model. In this paper, we propose an approach called wide learning based on arc-cosine kernels, that learns a single layer of infinite width. We propose exact and inexact learning strategies for wide learning and show that wide learning with single layer outperforms single layer as well as deep architectures of finite width for some benchmark datasets.",
            "output": [
                "To go deep or wide in learning?"
            ]
        },
        {
            "id": "task1540-fa4c6bd8277e43cf952db592e74d9c37",
            "input": "Our hypothesis is that by equipping certain agents in a multi-agent system controlling an intelligent building with automated decision support, two important factors will be in­ creased. The first is energy saving in the building. The second is customer value-how the people in the building experience the ef­ fects of the actions of the agents. We give evi­ dence for the truth of this hypothesis through experimental findings related to tools for arti­ ficial decision making. A number of assump­ tions related to agent control, through moni­ toring and delegation of tasks to other kinds of agents, of rooms at a test site are relaxed. Each assumption controls at least one un­ certainty that complicates considerably the procedures for selecting actions part of each such agent. We show that in realistic deci­ sion situations, room-controlling agents can make bounded rational decisions even under dynamic real-time constraints. This result can be, and has been, generalized to other domains with even harsher time constraints.",
            "output": [
                "Artificial Decision Making Under Uncertainty in Intelligent Buildings"
            ]
        },
        {
            "id": "task1540-4737f24b6f0a4b9c8990c4a799a93a9a",
            "input": "We propose a Multi-Layer Network based on the Bayesian framework of the Factor Graphs in Reduced Normal Form (FGrn) applied to a two-dimensional lattice. The Latent Variable Model (LVM) is the basic building block of a quadtree hierarchy built on top of a bottom layer of random variables that represent pixels of an image, a feature map, or more generally a collection of spatially distributed discrete variables. The multi-layer architecture implements a hierarchical data representation that, via belief propagation, can be used for learning and inference. Typical uses are pattern completion, correction and classification. The FGrn paradigm provides great flexibility and modularity and appears as a promising candidate for building deep networks: the system can be easily extended by introducing new and different (in cardinality and in type) variables. Prior knowledge, or supervised information, can be introduced at different scales. The FGrn paradigm provides a handy way for building all kinds of architectures by interconnecting only three types of units: Single Input Single Output (SISO) blocks, Sources and Replicators. The network is designed like a circuit diagram and the belief messages flow bidirectionally in the whole system. The learning algorithms operate only locally within each block. The framework is demonstrated in this paper in a three-layer structure applied to images extracted from a standard data set.",
            "output": [
                "Towards Building Deep Networks with Bayesian Factor Graphs"
            ]
        },
        {
            "id": "task1540-90cbe5a397bd497f9042c2b0678b380b",
            "input": "Despite the advances made in artificial intelligence, software agents, and robotics, there is little we see today that we can truly call a fully autonomous system. We conjecture that the main inhibitor for advancing autonomy is lack of trust. Trusted autonomy is the scientific and engineering field to establish the foundations and ground work for developing trusted autonomous systems (robotics and software agents) that can be used in our daily life, and can be integrated with humans seamlessly, naturally and efficiently. In this paper, we review this literature to reveal opportunities for researchers and practitioners to work on topics that can create a leap forward in advancing the field of trusted autonomy. We focus the paper on the ‘trust’ component as the uniting technology between humans and machines. Our inquiry into this topic revolves around three sub-topics: (1) reviewing and positioning the trust modelling literature for the purpose of trusted autonomy; (2) reviewing a critical subset of sensor technologies that allow a machine to sense human states; and (3) distilling some critical questions for advancing the field of trusted autonomy. The inquiry is augmented with conceptual models that we propose along the way by recompiling and reshaping the literature into forms that enables trusted autonomous systems to become a reality. The paper offers a vision for a Trusted Cyborg Swarm, an extension of our previous Cognitive Cyber Symbiosis concept, whereby humans and machines meld together in a harmonious, seamless, and coordinated manner.",
            "output": [
                "A Review of Theoretical and Practical Challenges of Trusted Autonomy in Big Data"
            ]
        },
        {
            "id": "task1540-e6349a740239409e9cd07d21e165cc28",
            "input": "There are few knowledge representation (KR) techniques available for efficiently representing knowledge. However, with the increase in complexity, better methods are needed. Some researchers came up with hybrid mechanisms by combining two or more methods. In an effort to construct an intelligent computer system, a primary consideration is to represent large amounts of knowledge in a way that allows effective use and efficiently organizing information to facilitate making the recommended inferences. There are merits and demerits of combinations, and standardized method of KR is needed. In this paper, various hybrid schemes of KR were explored at length and details presented. KeywordsKnowledge representation; hybrid system; hybrid schema structure.",
            "output": [
                "Hybrid Systems for Knowledge Representation in Artificial Intelligence"
            ]
        },
        {
            "id": "task1540-e6f14a923bd54514be5ac55191fc429f",
            "input": "<lb>We consider online learning when the time horizon is unknown. We apply a<lb>minimax analysis, beginning with the fixed horizon case, and then moving on to<lb>two unknown-horizon settings, one that assumes the horizon is chosen randomly<lb>according to some known distribution, and the other which allows the adversary<lb>full control over the horizon. For the random horizon setting with restricted losses,<lb>we derive a fully optimal minimax algorithm. And for the adversarial horizon set-<lb>ting, we prove a nontrivial lower bound which shows that the adversary obtains<lb>strictly more power than when the horizon is fixed and known. Based on the mini-<lb>max solution of the random horizon setting, we then propose a new adaptive algo-<lb>rithm which “pretends” that the horizon is drawn from a distribution from a special<lb>family, but no matter how the actual horizon is chosen, the worst-case regret is of<lb>the optimal rate. Furthermore, our algorithm can be generalized in many ways,<lb>including handling other unknown information and other online learning settings.<lb>Experiments show that our algorithm outperforms many other existing algorithms<lb>in an online linear optimization setting.",
            "output": [
                "Online Learning with Unknown Time Horizon"
            ]
        },
        {
            "id": "task1540-139fc1fcd7ea4c1599bb734eb7b29410",
            "input": "Inspired by the recently introduced framework of AND/OR search spaces for graphical models, we propose to augment Multi-Valued Decision Diagrams (MDD) with AND nodes, in order to capture function decomposition structure and to extend these compiled data structures to general weighted graphical models (e.g., probabilistic models). We present the AND/OR Multi-Valued Decision Diagram (AOMDD) which compiles a graphical model into a canonical form that supports polynomial (e.g., solution counting, belief updating) or constant time (e.g. equivalence of graphical models) queries. We provide two algorithms for compiling the AOMDD of a graphical model. The first is search-based, and works by applying reduction rules to the trace of the memory intensive AND/OR search algorithm. The second is inference-based and uses a Bucket Elimination schedule to combine the AOMDDs of the input functions via the the APPLY operator. For both algorithms, the compilation time and the size of the AOMDD are, in the worst case, exponential in the treewidth of the graphical model, rather than pathwidth as is known for ordered binary decision diagrams (OBDDs). We introduce the concept of semantic treewidth, which helps explain why the size of a decision diagram is often much smaller than the worst case bound. We provide an experimental evaluation that demonstrates the potential of AOMDDs.",
            "output": [
                "AND/OR Multi-Valued Decision Diagrams (AOMDDs) for Graphical Models"
            ]
        },
        {
            "id": "task1540-df601d90397445b19d0865ec7753fd4f",
            "input": "CAPTCHAs or reverse Turing tests are real-time assessments used by programs (or computers) to tell humans and machines apart. This is achieved by assigning and assessing hard AI problems that could only be solved easily by human but not by machines. Applications of such assessments range from stopping spammers from automatically filling online forms to preventing hackers from performing dictionary attack. Today, the race between makers and breakers of CAPTCHAs is at a juncture, where the CAPTCHAs proposed are not even answerable by humans. We consider such CAPTCHAs as non user friendly. In this paper, we propose a novel technique for reverse Turing test we call it the Line CAPTCHAs that mainly focuses on user friendliness while not compromising the security aspect that is expected to be provided by such a system.",
            "output": [
                "User Friendly Line CAPTCHAs"
            ]
        },
        {
            "id": "task1540-0ca0eaf40e2440ecbc2e5375e2c6430b",
            "input": "This paper is a survey work for a bigger project for designing a Visual SLAM robot to generate 3D dense map of an unknown unstructured environment. A lot of factors have to be considered while designing a SLAM robot. Sensing method of the SLAM robot should be determined by considering the kind of environment to be modelled. Similarly the type of environment determines the suitable feature extraction method. This paper goes through the sensing methods used in some recently published papers. The main objective of this survey is to conduct a comparative study among the current sensing methodsandfeature extraction algorithms and to extract out the best for our work.",
            "output": [
                "A SURVEY ON SENSING METHODS"
            ]
        },
        {
            "id": "task1540-6017f816d6d44c8ba9022999ac5e101a",
            "input": "Hashtags are semantico-syntactic constructs used across various social networking and microblogging platforms to enable users to start a topic specific discussion or classify a post into a desired category. Segmenting and linking the entities present within the hashtags could therefore help in better understanding and extraction of information shared across the social media. However, due to lack of space delimiters in the hashtags (e.g #nsavssnowden), the segmentation of hashtags into constituent entities (“NSA” and “Edward Snowden” in this case) is not a trivial task. Most of the current state-of-the-art social media analytics systems like Sentiment Analysis and Entity Linking tend to either ignore hashtags, or treat them as a single word. In this paper, we present a context aware approach to segment and link entities in the hashtags to a knowledge base (KB) entry, based on the context within the tweet. Our approach segments and links the entities in hashtags such that the coherence between hashtag semantics and the tweet is maximized. To the best of our knowledge, no existing study addresses the issue of linking entities in hashtags for extracting semantic information. We evaluate our method on two different datasets, and demonstrate the effectiveness of our technique in improving the overall entity linking in tweets via additional semantic information provided by segmenting and linking entities in a hashtag.",
            "output": [
                "Towards Deep Semantic Analysis of Hashtags"
            ]
        },
        {
            "id": "task1540-580d36faf97d4d0a95c8ddcfc094fa3d",
            "input": "Prediction markets provide an efficient means to assess uncertain quantities from forecasters. Traditional and competitive strictly proper scoring rules have been shown to incentivize players to provide truthful probabilistic forecasts. However, we show that when those players can cooperate, these mechanisms can instead discourage them from reporting what they really believe. When players with different beliefs are able to cooperate and form a coalition, these mechanisms admit arbitrage and there is a report that will always pay coalition members more than their truthful forecasts. If the coalition were created by an intermediary, such as a web portal, the intermediary would be guaranteed a profit.",
            "output": [
                "Strictly Proper Mechanisms with Cooperating Players"
            ]
        },
        {
            "id": "task1540-6d5f388e603243c18cd2ef2670877ff0",
            "input": "Tissue segmentation is an important pre-requisite for efficient and accurate diagnostics in digital pathology. However, it is well known that whole-slide scanners can fail in detecting all tissue regions, for example due to the tissue type, or due to weak staining because their tissue detection algorithms are not robust enough. In this paper, we introduce two different convolutional neural network architectures for whole slide image segmentation to accurately identify the tissue sections. We also compare the algorithms to a published traditional method. We collected 54 whole slide images with differing stains and tissue types from three laboratories to validate our algorithms. We show that while the two methods do not differ significantly they outperform their traditional counterpart (Jaccard index of 0.937 and 0.929 vs. 0.870, p < 0.01).",
            "output": [
                "COMPARISON OF DIFFERENT METHODS FOR TISSUE SEGMENTATION IN HISTOPATHOLOGICAL WHOLE-SLIDE IMAGES"
            ]
        },
        {
            "id": "task1540-95a50954567148619889a2e87dbc5bd9",
            "input": "Social dynamics is concerned primarily with interactions among individuals and the resulting group behaviors, modeling the temporal evolution of social systems via the interactions of individuals within these systems. In particular, the availability of large-scale data from social networks and sensor networks offers an unprecedented opportunity to predict state-changing events at the individual level. Examples of such events include disease transmission, opinion transition in elections, and rumor propagation. Unlike previous research focusing on the collective effects of social systems, this study makes efficient inferences at the individual level. In order to cope with dynamic interactions among a large number of individuals, we introduce the stochastic kinetic model to capture adaptive transition probabilities and propose an efficient variational inference algorithm the complexity of which grows linearly — rather than exponentially— with the number of individuals. To validate this method, we have performed epidemic-dynamics experiments on wireless sensor network data collected from more than ten thousand people over three years. The proposed algorithm was used to track disease transmission and predict the probability of infection for each individual. Our results demonstrate that this method is more efficient than sampling while nonetheless achieving high accuracy.",
            "output": [
                "Using Social Dynamics to Make Individual Predictions: Variational Inference with a Stochastic Kinetic Model"
            ]
        },
        {
            "id": "task1540-cf2549be72d541d3b8560f3dbba964ea",
            "input": "Symbolic approaches to deep parsing often require large-coverage and fine-grained lexical information, such as a syntactic lexicon. LexiconGrammar tables (Gross 1975, 1994), carefully developed by linguists since the 70s, constitute such a syntactic resource. Each table represents a class of predicates sharing some syntactic features. Each row corresponds to a lexical entry (verb, predicative noun, predicative adjective, adverb, fixed expression) and each column corresponds to a syntactic feature (construction, argument distribution, and so on). However, they are not directly exploitable for NLP applications because pieces of information are not formally encoded although their informal descriptions are available in the literature. Some projects such as (Hathout et Namer 1998, Gardent et al. 2006, Sagot et Fort 2007, Danlos et Sagot 2009) attempted to reformat LexiconGrammar tables in a lexicon for NLP. In these projects, each class is assigned a specific configuration which encodes missing information and defines restructuration operations. For instance, each configuration in (Gardent et al. 2006) is represented by a graph that makes the class structure explicit and translates each column header into a feature structure. Nevertheless, Lexicon-Grammar tables are continually updated to be improved (e.g., addition and renaming of features) and this approach can be tedious to maintain. For example, if a same feature is added to several classes, all corresponding configurations have to be modified. In this paper, we describe LGExtract, a tool that uses a global approach. First, it relies on the so-called table of classes, which encodes pieces of information that are undefined in the original classes, especially features that are constant over a whole class. Next, as a syntactic feature has exactly one interpretation over the set of classes, our extraction script assigns to each feature a set of reformatting operations once. This paper is organized as follows. First, we briefly describe the LexiconGrammar classes and the table of classes, and their relevance to our work. Then, we present LGExtract in detail, illustrate it with a concrete example for French and discuss its main advantages and drawbacks.",
            "output": [
                "A generic tool to generate a lexicon for NLP from Lexicon-Grammar tables"
            ]
        },
        {
            "id": "task1540-39c244739ad24cd5b4a010fb448cac63",
            "input": "In this paper, we study a novel approach for named entity recognition (NER) and mention detection in natural language processing. Instead of treating NER as a sequence labelling problem, we propose a new local detection approach, which rely on the recent fixed-size ordinally forgetting encoding (FOFE) method to fully encode each sentence fragment and its left/right contexts into a fixed-size representation. Afterwards, a simple feedforward neural network is used to reject or predict entity label for each individual fragment. The proposed method has been evaluated in several popular NER and mention detection tasks, including the CoNLL 2003 NER task and TAC-KBP2015 and TAC-KBP2016 Trilingual Entity Discovery and Linking (EDL) tasks. Our methods have yielded pretty strong performance in all of these examined tasks. This local detection approach has shown many advantages over the traditional sequence labelling methods.",
            "output": [
                "A FOFE-based Local Detection Approach for Named Entity Recognition and Mention Detection"
            ]
        },
        {
            "id": "task1540-15b34e03a216413a9628270858197ef7",
            "input": "There are many complex combinatorial problems which involve searching for an undirected graph satisfying given constraints. Such problems are often highly challenging because of the large number of isomorphic representations of their solutions. This paper introduces effective and compact, complete symmetry breaking constraints for small graph search. Enumerating with these symmetry breaks generates all and only non-isomorphic solutions. For small search problems, with up to 10 vertices, we compute instance independent symmetry breaking constraints. For small search problems with a larger number of vertices we demonstrate the computation of instance dependent constraints which are complete. We illustrate the application of complete symmetry breaking constraints to extend two known sequences from the OEIS related to graph enumeration.",
            "output": [
                "Breaking Symmetries in Graph Search with Canonizing Sets"
            ]
        },
        {
            "id": "task1540-0e581ae6d613485394f0fcd0586b2e84",
            "input": "We present new algorithms for learning Bayesian networks from data with missing values without the assumption that data are missing at random (MAR). An exact Bayesian network learning algorithm is obtained by recasting the problem into a standard Bayesian network learning problem without missing data. To the best of our knowledge, this is the first exact algorithm for this problem. As expected, the exact algorithm does not scale to large domains. We build on the exact method to create a new approximate algorithm using a hill-climbing technique. This algorithm scales to large domains so long as a suitable standard structure learning method for complete data is available. We perform a wide range of experiments to demonstrate the benefits of learning Bayesian networks without assuming MAR.",
            "output": [
                "Learning Bayesian Networks without Assuming Missing at Random"
            ]
        },
        {
            "id": "task1540-13a41322319041c58a6f0934b4288e6d",
            "input": "We introduce polyglot language models, recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted. We apply these to the problem of modeling phone sequences—a domain in which universal symbol inventories and cross-linguistically shared feature representations are a natural fit. Intrinsic evaluation on held-out perplexity, qualitative analysis of the learned representations, and extrinsic evaluation in two downstream applications that make use of phonetic features show (i) that polyglot models better generalize to held-out data than comparable monolingual models and (ii) that polyglot phonetic feature representations are of higher quality than those learned monolingually.",
            "output": [
                "Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation Learning"
            ]
        },
        {
            "id": "task1540-dff70d51e8e34651a216318a2947d06c",
            "input": "Our goal is to deploy a high-accuracy system starting with zero training examples. We consider an on-the-job setting, where as inputs arrive, we use real-time crowdsourcing to resolve uncertainty where needed and output our prediction when confident. As the model improves over time, the reliance on crowdsourcing queries decreases. We cast our setting as a stochastic game based on Bayesian decision theory, which allows us to balance latency, cost, and accuracy objectives in a principled way. Computing the optimal policy is intractable, so we develop an approximation based on Monte Carlo Tree Search. We tested our approach on three datasets—named-entity recognition, sentiment classification, and image classification. On the NER task we obtained more than an order of magnitude reduction in cost compared to full human annotation, while boosting performance relative to the expert provided labels. We also achieve a 8% F1 improvement over having a single human label the whole set, and a 28% F1 improvement over online learning. “Poor is the pupil who does not surpass his master.” – Leonardo da Vinci",
            "output": [
                "On-the-Job Learning with Bayesian Decision Theory"
            ]
        },
        {
            "id": "task1540-5831b5b39bc84a80ade8bc4d47ecdff3",
            "input": "We describe recurrent neural networks (RNNs), which have attracted great attention on sequential tasks, such as handwriting recognition, speech recognition and image to text. However, compared to general feedforward neural networks, RNNs have feedback loops, which makes it a little hard to understand the backpropagation step. Thus, we focus on basics, especially the error backpropagation to compute gradients with respect to model parameters. Further, we go into detail on how error backpropagation algorithm is applied on long short-term memory (LSTM) by unfolding the memory unit.",
            "output": [
                "A Gentle Tutorial of Recurrent Neural Network with Error Backpropagation"
            ]
        },
        {
            "id": "task1540-363caffbcb224bbd801891e55bbd58f3",
            "input": "We propose a novel discriminative model that learns embeddings from multilingual and multi-modal data, meaning that our model can take advantage of images and descriptions in multiple languages to improve embedding quality. To that end, we introduce a modification of a pairwise contrastive estimation optimisation function as our training objective. We evaluate our embeddings on an image–sentence ranking (ISR), a semantic textual similarity (STS), and a neural machine translation (NMT) task. We find that the additional multilingual signals lead to improvements on both the ISR and STS tasks, and the discriminative cost can also be used in re-ranking n-best lists produced by NMT models, yielding strong improvements.",
            "output": [
                "Multilingual Multi-modal Embeddings for Natural Language Processing"
            ]
        },
        {
            "id": "task1540-9cb2b001e8e44904a0375a92cc131819",
            "input": "The proposed algorithmic approach deals with finding the sense of a word in an electronic data. Now a day, in different communication mediums like internet, mobile services etc. people use few words, which are slang in nature. This approach detects those abusive words using supervised learning procedure. But in the real life scenario, the slang words are not used in complete word forms always. Most of the times, those words are used in different abbreviated forms like sounds alike forms, taboo morphemes etc. This proposed approach can detect those abbreviated forms also using semi supervised learning procedure. Using the synset and concept analysis of the text, the probability of a suspicious word to be a slang word is also evaluated.",
            "output": [
                "Detection of Slang Words in e-Data using semi- Supervised Learning"
            ]
        },
        {
            "id": "task1540-a93bde414a6f4d72a89cf9905a29f8e6",
            "input": "Several authors have explained that the like­ lihood ratio measures the strength of the evi­ dence represented by observations in statisti­ cal problems. This idea works fine when the goal is to evaluate the strength of the avail­ able evidence for a simple hypothesis versus another simple hypothesis. However, the ap­ plicability of this idea is limited to simple hypotheses because the likelihood function is primarily defined on points simple hy­ potheses of the parameter space. In this paper we define a general weight of evidence that is applicable to both simple and compos­ ite hypotheses. It is based on the Dempster­ Shafer concept of plausibility and is shown to be a generalization of the likelihood ratio. Functional models are of a fundamental im­ portance for the general weight of evidence proposed in this paper. The relevant con­ cepts and ideas are explained by means of a familiar urn problem and the general analysis of a real-world medical problem is presented.",
            "output": [
                "From Likelihood to Plausibility"
            ]
        },
        {
            "id": "task1540-bd681bdf5bcc425cac791987c3939bf8",
            "input": "Concept Trees are a type of database that can organise arbitrary textual information using a very simple rule. Each tree tries to represent a single cohesive concept and the trees can link with each other for navigation and semantic purposes. The trees are therefore a type of semantic network and would benefit from having a consistent level of context for each of the nodes. The Concept Tree nodes have a mathematical basis allowing for a consistent build process. These would represent nouns or verbs in a text sentence, for example. New to the design can then be lists of descriptive elements for each of the nodes. The descriptors can also be weighted, but do not have to follow the strict counting rule of the tree nodes. With the new descriptive layers, a much richer type of knowledge can be achieved and still reasoned over automatically. The linking structure of the licas network is very relevant to building the concept trees now and forms the basis for their construction. The concept tree symbolic neural network relation is also extended further.",
            "output": [
                "Adding Context to Concept Trees"
            ]
        },
        {
            "id": "task1540-49bd1b52d1be4834be6b54c49a4cb9a1",
            "input": "The utility of Twitter data as a medium to support populationlevel mental health monitoring is not well understood. In an effort to better understand the predictive power of supervised machine learning classifiers and the influence of feature sets for efficiently classifying depression-related tweets on a large-scale, we conducted two feature study experiments. In the first experiment, we assessed the contribution of feature groups such as lexical information (e.g., unigrams) and emotions (e.g., strongly negative) using a feature ablation study. In the second experiment, we determined the percentile of top ranked features that produced the optimal classification performance by applying a three-step feature elimination approach. In the first experiment, we observed that lexical features are critical for identifying depressive symptoms, specifically for depressed mood (-35 points) and for disturbed sleep (-43 points). In the second experiment, we observed that the optimal F1-score performance of top ranked features in percentiles variably ranged across classes e.g., fatigue or loss of energy (5th percentile, 288 features) to depressed mood (55th percentile, 3,168 features) suggesting there is no consistent count of features for predicting depressive-related tweets. We conclude that simple lexical features and reduced feature sets can produce comparable results to larger feature sets.",
            "output": [
                "Feature Studies to Inform the Classification of Depressive Symptoms from Twitter Data for Population Health"
            ]
        },
        {
            "id": "task1540-aa70fbe45a1f43739913f609ff73b972",
            "input": "In this paper, we propose a new autonomous braking system based on deep reinforcement learning. The proposed autonomous braking system automatically decides whether to apply the brake at each time step when confronting the risk of collision using the information on the obstacle obtained by the sensors. The problem of designing brake control is formulated as searching for the optimal policy in Markov decision process (MDP) model where the state is given by the relative position of the obstacle and the vehicle’s speed, and the action space is defined as whether brake is stepped or not. The policy used for brake control is learned through computer simulations using the deep reinforcement learning method called deep Q-network (DQN). In order to derive desirable braking policy, we propose the reward function which balances the damage imposed to the obstacle in case of accident and the reward achieved when the vehicle runs out of risk as soon as possible. DQN is trained for the scenario where a vehicle is encountered with a pedestrian crossing the urban road. Experiments show that the control agent exhibits desirable control behavior and avoids collision without any mistake in various uncertain environments.",
            "output": [
                "Autonomous Braking System via Deep Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-8e43407e0d4641fb96127adc6ed8f10b",
            "input": "Multiagent planning and coordination problems are common and known to be computationally hard. We show that a wide range of two-agent problems can be formulated as bilinear programs. We present a successive approximation algorithm that significantly outperforms the coverage set algorithm, which is the state-of-the-art method for this class of multiagent problems. Because the algorithm is formulated for bilinear programs, it is more general and simpler to implement. The new algorithm can be terminated at any time and–unlike the coverage set algorithm–it facilitates the derivation of a useful online performance bound. It is also much more efficient, on average reducing the computation time of the optimal solution by about four orders of magnitude. Finally, we introduce an automatic dimensionality reduction method that improves the effectiveness of the algorithm, extending its applicability to new domains and providing a new way to analyze a subclass of bilinear programs.",
            "output": [
                "A Bilinear Programming Approach for Multiagent Planning"
            ]
        },
        {
            "id": "task1540-73852f12094f4a07b450fa782f6e9874",
            "input": "Achieving joint objectives by teams of cooperative planning agents requires significant coordination and communication efforts. For a singleagent system facing a plan failure in a dynamic environment, arguably, attempts to repair the failed plan in general do not straightforwardly bring any benefit in terms of time complexity. However, in multi-agent settings the communication complexity might be of a much higher importance, possibly a high communication overhead might be even prohibitive in certain domains. We hypothesize that in decentralized systems, where coordination is enforced to achieve joint objectives, attempts to repair failed multi-agent plans should lead to lower communication overhead than replanning from scratch. The contribution of the presented paper is threefold. Firstly, we formally introduce the multi-agent plan repair problem and formally present the core hypothesis underlying our work. Secondly, we propose three algorithms for multi-agent plan repair reducing the problem to specialized instances of the multi-agent planning problem. Finally, we present results of experimental validation confirming the core hypothesis of the paper.",
            "output": [
                "Decentralized Multi-agent Plan Repair in Dynamic Environments∗"
            ]
        },
        {
            "id": "task1540-90027342ce504b558ffd97f3328fdee7",
            "input": "In this paper, we attempt to solve the problem of Prepositional Phrase (PP) attachments in English. The motivation for the work comes from NLP applications like Machine Translation, for which, getting the correct attachment of prepositions is very crucial. The idea is to correct the PPattachments for a sentence with the help of alignments from parallel data in another language. The novelty of our work lies in the formulation of the problem into a dual decomposition based algorithm that enforces agreement between the parse trees from two languages as a constraint. Experiments were performed on the EnglishHindi language pair and the performance improved by 10% over the baseline, where the baseline is the attachment predicted by the MSTParser model trained for English.",
            "output": [
                "Prepositional Attachment Disambiguation Using Bilingual Parsing and Alignments"
            ]
        },
        {
            "id": "task1540-84fb9e8b40454e93b783bfe6eb2a0055",
            "input": "Image captioning has so far been explored mostly in English, as most available datasets are in this language. However, the application of image captioning should not be restricted by language. Only few studies have been conducted for image captioning in a cross-lingual seing. Dierent from these works that manually build a dataset for a target language, we aim to learn a cross-lingual captioning model fully from machine-translated sentences. To conquer the lack of uency in the translated sentences, we propose in this paper a uency-guided learning framework. e framework comprises a module to automatically estimate the uency of the sentences and another module to utilize the estimated uency scores to eectively train an image captioning model for the target language. As experiments on two bilingual (English-Chinese) datasets show, our approach improves both uency and relevance of the generated captions in Chinese, but without using any manually wrien sentences from the target language.",
            "output": [
                "Fluency-Guided Cross-Lingual Image Captioning"
            ]
        },
        {
            "id": "task1540-7abd84e21bee417e8ff545e16c072eea",
            "input": "In this article, an agent-based negotiation model for negotiation teams that negotiate a deal with an opponent is presented. Agent-based negotiation teams are groups of agents that join together as a single negotiation party because they share an interest that is related to the negotiation process. The model relies on a trusted mediator that coordinates and helps team members in the decisions that they have to take during the negotiation process: which offer is sent to the opponent, and whether or not the offers received from the opponent are accepted. The main strength of the proposed negotiation model is the fact that it guarantees unanimity within team decisions since decisions report a utility to team members that is greater than or equal to their aspiration levels at each negotiation round. This work analyzes how unanimous decisions are taken within the team and the robustness of the model against different types of manipulations. An empirical evaluation is also performed to study the impact of the different parameters of the model.",
            "output": [
                "Reaching Unanimous Agreements within Agent-Based Negotiation Teams with Linear and Monotonic Utility Functions"
            ]
        },
        {
            "id": "task1540-1a5deb6e330149fd9d92536870fc6ce0",
            "input": "Analysing sentiment of tweets is important as it helps to determine the users’ opinion. Knowing people’s opinion is crucial for several purposes starting from gathering knowledge about customer base, e-governance, campaignings and many more. In this report, we aim to develop a system to detect the sentiment from tweets. We employ several linguistic features along with some other external sources of information to detect the sentiment of a tweet. We show that augmenting the 140 character-long tweet with information harvested from external urls shared in the tweet as well as Social Media features enhances the sentiment prediction accuracy significantly.",
            "output": [
                "Sentiment Analysis for Twitter : Going Beyond Tweet Text"
            ]
        },
        {
            "id": "task1540-a7670353b2d04d1a94af5ac3fc4097c0",
            "input": "We propose a novel algorithm for optimizing multivariate linear threshold functions as split functions of decision trees to create improved Random Forest classifiers. Standard tree induction methods resort to sampling and exhaustive search to find good univariate split functions. In contrast, our method computes a linear combination of the features at each node, and optimizes the parameters of the linear combination (oblique) split functions by adopting a variant of latent variable SVM formulation. We develop a convex-concave upper bound on the classification loss for a one-level decision tree, and optimize the bound by stochastic gradient descent at each internal node of the tree. Forests of up to 1000 Continuously Optimized Oblique (CO2) decision trees are created, which significantly outperform Random Forest with univariate splits and previous techniques for constructing oblique trees. Experimental results are reported on multi-class classification benchmarks and on Labeled Faces in the Wild (LFW) dataset.",
            "output": [
                "CO2 Forest: Improved Random Forest by Continuous Optimization of Oblique Splits"
            ]
        },
        {
            "id": "task1540-d942b319ec134bd0813894ec60268d33",
            "input": "This paper presents a system which creates and visualizes probabilistic semantic links between concepts in a thesaurus and classes in a classification system. For creating the links, we build on the Polylingual Labeled Topic Model (PLL-TM) [6]. PLL-TM identifies probable thesaurus descriptors for each class in the classification system by using information from the natural language text of documents, their assigned thesaurus descriptors and their designated classes. The links are then presented to users of the system in an interactive visualization, providing them with an automatically generated overview of the relations between the thesaurus and the classification system. Lisa Posch GESIS – Leibniz Institute for the Social Sciences Cologne, Germany Institute for Web Science and Technologies University of Koblenz-Landau, Germany E-mail: lisa.posch@gesis.org Philipp Schaer GESIS – Leibniz Institute for the Social Sciences Cologne, Germany E-mail: philipp.schaer@gesis.org Arnim Bleier GESIS – Leibniz Institute for the Social Sciences Cologne, Germany E-mail: arnim.bleier@gesis.org Markus Strohmaier GESIS – Leibniz Institute for the Social Sciences Cologne, Germany Institute for Web Science and Technologies University of Koblenz-Landau, Germany E-mail: markus.strohmaier@gesis.org",
            "output": [
                "A System for Probabilistic Linking of Thesauri and Classification Systems"
            ]
        },
        {
            "id": "task1540-7a49af99d5ca40ba9fb429a199f00821",
            "input": "One difficulty faced in knowledge engineering for Bayesian Network (BN) is the quantification step where the Conditional Probability Tables (CPTs) are determined. The number of parameters included in CPTs increases exponentially with the number of parent variables. The most common solution is the application of the so-called canonical gates. The Noisy-OR (NOR) gate, which takes advantage of the independence of causal interactions, provides a logarithmic reduction of the number of parameters required to specify a CPT. In this paper, an extension of NOR model based on the theory of belief functions, named Belief Noisy-OR (BNOR), is proposed. BNOR is capable of dealing with both aleatory and epistemic uncertainty of the network. Compared with NOR, more rich information which is of great value for making decisions can be got when the available knowledge is uncertain. Specially, when there is no epistemic uncertainty, BNOR degrades into NOR. Additionally, different structures of BNOR are presented in this paper in order to meet various needs of engineers. The application of BNOR model on the reliability evaluation problem of networked systems demonstrates its effectiveness.",
            "output": [
                "THE BELIEF NOISY-OR MODEL APPLIED TO NETWORK RELIABILITY ANALYSIS"
            ]
        },
        {
            "id": "task1540-cc4bc7f15f4a4162984a20d156317269",
            "input": "We study the computational complexity of candidate control in elections with few voters (that is, we take the number of voters as a parameter). We consider both the standard scenario of adding and deleting candidates, where one asks if a given candidate can become a winner (or, in the destructive case, can be precluded from winning) by adding/deleting some candidates, and a combinatorial scenario where adding/deleting a candidate automatically means adding/deleting a whole group of candidates. Our results show that the parameterized complexity of candidate control (with the number of voters as the parameter) is much more varied than in the setting with many voters.",
            "output": [
                "Elections with Few Voters: Candidate Control Can Be Easy"
            ]
        },
        {
            "id": "task1540-6c0356917ef5456dbade601bdced33d4",
            "input": "Machine learning has been used to detect new malware in recent years, while malware authors have strong motivation to attack such algorithms.Malware authors usually have no access to the detailed structures and parameters of the machine learning models used by malware detection systems, and therefore they can only perform black-box attacks. This paper proposes a generative adversarial network (GAN) based algorithm named MalGAN to generate adversarial malware examples, which are able to bypass black-box machine learning based detection models. MalGAN uses a substitute detector to fit the black-box malware detection system. A generative network is trained to minimize the generated adversarial examples’ malicious probabilities predicted by the substitute detector. The superiority of MalGAN over traditional gradient based adversarial example generation algorithms is that MalGAN is able to decrease the detection rate to nearly zero and make the retraining based defensive method against adversarial examples hard to work.",
            "output": [
                "Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN"
            ]
        },
        {
            "id": "task1540-cbfe8dda6aeb4eafb19386521cdfa9ca",
            "input": "We investigate the use of pivot languages for phrase-based statistical machine translation (PB-SMT) between related languages with limited parallel corpora. We show that subword-level pivot translation via a related pivot language is: (i) highly competitive with the best direct translation model and (ii) better than a pivot model which uses an unrelated pivot language, but has at its disposal large parallel corpora to build the source-pivot (S-P) and pivot-target (P-T) translation models. In contrast, pivot models trained at word and morpheme level are far inferior to their direct counterparts. We also show that using multiple related pivot languages can outperform a direct translation model. Thus, the use of subwords as translation units coupled with the use of multiple related pivot languages can compensate for the lack of a direct parallel corpus. Subword units make pivot models competitive by (i) utilizing lexical similarity to improve the underlying S-P and P-T translation models, and (ii) reducing loss of translation candidates during pivoting.",
            "output": [
                "Utilizing Lexical Similarity for pivot translation involving resource-poor, related languages"
            ]
        },
        {
            "id": "task1540-ae8691e4b5af4455a3b7cf73bad288ca",
            "input": "Learning. Abstract: Document categorization is a technique where the category of a document is determined. In this paper three well-known supervised learning techniques which are Support Vector Machine(SVM), Naïve Bayes(NB) and Stochastic Gradient Descent(SGD) compared for Bengali document categorization. Besides classifier, classification also depends on how feature is selected from dataset. For analyzing those classifier performances on predicting a document against twelve categories several feature selection techniques are also applied in this article namely Chi square distribution, normalized TFIDF (term frequency-inverse document frequency) with word analyzer. So, we attempt to explore the efficiency of those three-classification algorithms by using two different feature selection techniques in this article.",
            "output": [
                "A Comparative Study on Different Types of Approaches to Bengali document Categorization"
            ]
        },
        {
            "id": "task1540-6aa7856d7d544e359e3ead49c1c5b786",
            "input": "The increasing diversity of languages used on the web introduces a new level of complexity to Information Retrieval (IR) systems. We can no longer assume that textual content is written in one language or even the same language family. In this paper, we demonstrate how to build massive multilingual annotators with minimal human expertise and intervention. We describe a system that builds Named Entity Recognition (NER) annotators for 40 major languages using Wikipedia and Freebase. Our approach does not require NER human annotated datasets or language specific resources like treebanks, parallel corpora, and orthographic rules. The novelty of approach lies therein using only language agnostic techniques, while achieving competitive performance. Our method learns distributed word representations (word embeddings) which encode semantic and syntactic features of words in each language. Then, we automatically generate datasets from Wikipedia link structure and Freebase attributes. Finally, we apply two preprocessing stages (oversampling and exact surface form matching) which do not require any linguistic expertise. Our evaluation is two fold: First, we demonstrate the system performance on human annotated datasets. Second, for languages where no gold-standard benchmarks are available, we propose a new method, distant evaluation, based on statistical machine translation.",
            "output": [
                "POLYGLOT-NER: Massive Multilingual Named Entity Recognition"
            ]
        },
        {
            "id": "task1540-10bfa40dde0f4a9f8ad1d027d65f2ee5",
            "input": "The paucity of videos in current action classification datasets (UCF-101 and HMDB-51) has made it difficult to identify good video architectures, as most methods obtain similar performance on existing small-scale benchmarks. This paper re-evaluates state-of-the-art architectures in light of the new Kinetics Human Action Video dataset. Kinetics has two orders of magnitude more data, with 400 human action classes and over 400 clips per class, and is collected from realistic, challenging YouTube videos. We provide an analysis on how current architectures fare on the task of action classification on this dataset and how much performance improves on the smaller benchmark datasets after pre-training on Kinetics. We also introduce a new Two-Stream Inflated 3D ConvNet (I3D) that is based on 2D ConvNet inflation: filters and pooling kernels of very deep image classification ConvNets are expanded into 3D, making it possible to learn seamless spatio-temporal feature extractors from video while leveraging successful ImageNet architecture designs and even their parameters. We show that, after pre-training on Kinetics, I3D models considerably improve upon the state-of-the-art in action classification, reaching 80.7% on HMDB-51 and 98.0% on UCF-101.",
            "output": [
                "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset"
            ]
        },
        {
            "id": "task1540-c9e2f1b5bef34808b062a415ca422ae3",
            "input": "Case-based reasoning (CBR) based on description logics (DLs) has gained a lot of attention lately. Adaptation is a basic task in CBR that can be modeled as a knowledge base revision problem which has been solved in propositional logic. However, in DLs, adaptation is still a challenge problem since existing revision operators only work well for DLs of the DL-Lite family. It is difficult to design revision algorithms that are syntax-independent and fine-grained. In this paper, we present a new method for adaptation based on the tractable DL EL⊥. Following the idea of adaptation as revision, we firstly extend the logical basis for describing cases from propositional logic to the DL EL⊥, and then present a formalism for adaptation based on EL⊥. With this formalism, we show that existing revision operators and algorithms in DLs do not work for it, and then present our adaptation algorithm. Our algorithm is syntax-independent and fine-grained, and satisfies the requirements on revision operators.",
            "output": [
                "Algorithm for Adapting Cases Represented in a Tractable Description Logic"
            ]
        },
        {
            "id": "task1540-e1830193b2b8425da4020b2ec09fc74c",
            "input": "Recent works have highlighted scale invariance or symmetry present in the weight space of a typical deep network and the adverse effect it has on the Euclidean gradient based stochastic gradient descent optimization. In this work, we show that a commonly used deep network, which uses convolution, batch normalization, reLU, max-pooling, and sub-sampling pipeline, possess more complex forms of symmetry arising from scaling-based reparameterization of the network weights. We propose to tackle the issue of the weight space symmetry by constraining the filters to lie on the unit-norm manifold. Consequently, training the network boils down to using stochastic gradient descent updates on the unit-norm manifold. Our empirical evidence based on the MNIST dataset shows that the proposed updates improve the test performance beyond what is achieved with batch normalization and without sacrificing the computational efficiency of the weight updates.",
            "output": [
                "Understanding symmetries in deep networks"
            ]
        },
        {
            "id": "task1540-1abeab57a0f543c396bf21fbd982df63",
            "input": "Advances in sensing technologies and the growth of the internet have resulted in an explosion in the size of modern datasets, while storage and processing power continue to lag behind. This motivates the need for algorithms that are efficient, both in terms of the number of measurements needed and running time. To combat the challenges associated with large datasets, we propose a general framework for active hierarchical clustering that repeatedly runs an off-the-shelf clustering algorithm on small subsets of the data and comes with guarantees on performance, measurement complexity and runtime complexity. We instantiate this framework with a simple spectral clustering algorithm and provide concrete results on its performance, showing that, under some assumptions, this algorithm recovers all clusters of size Ω(log n) using O(n log n) similarities and runs in O(n log n) time for a dataset of n objects. Through extensive experimentation we also demonstrate that this framework is practically alluring.",
            "output": [
                "Efficient Active Algorithms for Hierarchical Clustering"
            ]
        },
        {
            "id": "task1540-128ee05bbe3d4131bd00667eac9f4ad6",
            "input": "We demonstrate that an attention-based encoder-decoder model can be used for sentence-level grammatical error identification for the Automated Evaluation of Scientific Writing (AESW) Shared Task 2016. The attention-based encoder-decoder models can be used for the generation of corrections, in addition to error identification, which is of interest for certain end-user applications. We show that a character-based encoder-decoder model is particularly effective, outperforming other results on the AESW Shared Task on its own, and showing gains over a word-based counterpart. Our final model—a combination of three character-based encoder-decoder models, one word-based encoder-decoder model, and a sentence-level CNN—is the highest performing system on the AESW 2016 binary prediction Shared Task.",
            "output": [
                "Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction"
            ]
        },
        {
            "id": "task1540-30780bf9a0d64297944e5a46b78f1f38",
            "input": "An emerging way to deal with highdimensional non-euclidean data is to assume that the underlying structure can be captured by a graph. Recently, ideas have begun to emerge related to the analysis of time-varying graph signals. This work aims to elevate the notion of joint harmonic analysis to a full-fledged framework denoted as Time-Vertex Signal Processing, that links together the time-domain signal processing techniques with the new tools of graph signal processing. This entails three main contributions: (a) We provide a formal motivation for harmonic time-vertex analysis as an analysis tool for the state evolution of simple Partial Differential Equations on graphs. (b) We improve the accuracy of joint filtering operators by up-to two orders of magnitude. (c) Using our joint filters, we construct time-vertex dictionaries analyzing the different scales and the local time-frequency content of a signal. The utility of our tools is illustrated in numerous applications and datasets, such as dynamic mesh denoising and classification, still-video inpainting, and source localization in seismic events. Our results suggest that joint analysis of time-vertex signals can bring benefits to regression and learning.",
            "output": [
                "A Time-Vertex Signal Processing Framework Scalable processing and meaningful representations for time-series on graphs"
            ]
        },
        {
            "id": "task1540-ebf393d568dd4576998cacd50c25eef8",
            "input": "Compounding is a highly productive word-formation process in some languages that is often problematic for natural language processing applications. In this paper, we investigate whether distributional semantics in the form of word embeddings can enable a deeper, i.e., more knowledge-rich, processing of compounds than the standard string-based methods. We present an unsupervised approach that exploits regularities in the semantic vector space (based on analogies such as “bookshop is to shop as bookshelf is to shelf”) to produce compound analyses of high quality. A subsequent compound splitting algorithm based on these analyses is highly effective, particularly for ambiguous compounds. German to English machine translation experiments show that this semantic analogy-based compound splitter leads to better translations than a commonly used frequency-based method.",
            "output": [
                "Splitting Compounds by Semantic Analogy"
            ]
        },
        {
            "id": "task1540-64f584570a3f4dbea409f0945d7ca03a",
            "input": "The EM-algorithm is a general procedure to get maximum likelihood estimates if part of the observations on the variables of a network are missing. In this paper a stochastic version of the algorithm is adapted to probabilistic neural networks describing the associative dependency of variables. These networks have a proba­ bility distribution, which is a special case of the distribution generated by proba­ bilistic inference networks. Hence both types of networks can be combined al­ lowing to integrate probabilistic rules as well as unspecified associations in a sound way. The resulting network may have a number of interesting features including cycles of probabilistic rules, hidden 'un­ observable' variables, and uncertain and contradictory evidence.",
            "output": [
                "Integrating Probabilistic Rules into Neural Networks: A Stochastic EM Learning Algorithm"
            ]
        },
        {
            "id": "task1540-996ab8fa8fd640fdb3ebdf605a51c559",
            "input": "<lb>In multi-agent domains, an agent’s action may not just change the world and the agent’s knowledge and beliefs<lb>about the world, but also may change other agents’ knowledge and beliefs about the world and their knowledge and<lb>beliefs about other agents’ knowledge and beliefs about the world. Similarly, the goals of an agent in a multi-agent<lb>world may involve manipulating the knowledge and beliefs of other agents’ and again, not just their knowledge<lb>about the world, but also their knowledge about other agents’ knowledge about the world. The goal of this paper is to<lb>present an action language, called mA+, that has the necessary features to address the above aspects in representing<lb>and reasoning about actions and change in multi-agent domains.<lb>This action language can be viewed as a generalization of the single-agent action languages extensively studied<lb>in the literature, to the case of multi-agent domains. The language allows the representation of and reasoning about<lb>different types of actions that an agent can perform in a domain where many other agents might be present—such as<lb>world-altering actions, sensing actions, and announcement/communication actions. The action language also allows<lb>the specification of agents’ dynamic awareness of action occurrences which has future implications on what agents’<lb>know about the world and other agents’ knowledge about the world. The language mA+ considers three different<lb>types of awareness: full awareness, partial awareness, and complete oblivion of an action occurrence and its effects.<lb>This keeps the language simple, yet powerful enough to address a large variety of knowledge manipulation scenarios<lb>in multi-agent domains.<lb>The semantics of the language relies on the notion of state, which is described by a pointed Kripke model and<lb>is used to encode the agent’s knowledge and the real state of the world. The semantics is defined by a transition<lb>function that maps pairs of actions and states into sets of states. The paper illustrates properties of the action theories,<lb>including properties that guarantee finiteness of the set of initial states and their practical implementability. Finally,<lb>the paper relates mA+ to other related formalisms that contribute to reasoning about actions in multi-agent domains.",
            "output": [
                "An Action Language for Multi-Agent Domains: Foundations"
            ]
        },
        {
            "id": "task1540-487582a95b7e41d7868fe31f9488a401",
            "input": "Retention of residual skills for persons who partially lose their cognitive or physical ability is of utmost importance. Research is focused on developing systems that provide need-based assistance for retention of such residual skills. This paper describes a novel cognitive collaborative control architecture CA, designed to address the challenges of developing needbased assistance for wheelchair navigation. Organization of CA is detailed and results from simulation of the proposed architecture is presented. For simulation of our proposed architecture, we have used ROS (Robot Operating System) as a control framework and a 3D robotic simulator called USARSim (Unified System for Automation and Robot Simulation).",
            "output": [
                "C3A: A Cognitive Collaborative Control Architecture For an Intelligent Wheelchair"
            ]
        },
        {
            "id": "task1540-17d0635ecbf941a09b826c3aa2a70028",
            "input": "In recent years, Deep Neural Networks (DNN) based methods have achieved remarkable performance in a wide range of tasks and have been among the most powerful and widely used techniques in computer vision, speech recognition and Natural Language Processing. However, DNN-based methods are both computational-intensive and resource-consuming, which hinders the application of these methods on embedded systems like smart phones. To alleviate this problem, we introduce a novel Fixed-point Factorized Networks (FFN) on pre-trained models to reduce the computational complexity as well as the storage requirement of networks. Extensive experiments on large-scale ImageNet classification task show the effectiveness of our proposed method.",
            "output": [
                "Fixed-point Factorized Networks"
            ]
        },
        {
            "id": "task1540-459c915284d44708a3197bf6a6ebefe5",
            "input": "Language students are most engaged while reading texts at an appropriate difficulty level. However, existing methods of evaluating text difficulty focus mainly on vocabulary and do not prioritize grammatical features, hence they do not work well for language learners with limited knowledge of grammar. In this paper, we introduce grammatical templates, the expert-identified units of grammar that students learn from class, as an important feature of text difficulty evaluation. Experimental classification results show that grammatical template features significantly improve text difficulty prediction accuracy over baseline readability features by 7.4%. Moreover, we build a simple and human-understandable text difficulty evaluation approach with 87.7% accuracy, using only 5 grammatical template features.",
            "output": [
                "Grammatical Templates: Improving Text Difficulty Evaluation for Language Learners"
            ]
        },
        {
            "id": "task1540-36ac0c7858b44bd7888304a151701df4",
            "input": "Music emotion recognition (MER) is usually regarded as a multi-label tagging task, and each segment of music can inspire specific emotion tags. Most researchers extract acoustic features from music and explore the relations between these features and their corresponding emotion tags. Considering the inconsistency of emotions inspired by the same music segment for human beings, seeking for the key acoustic features that really affect on emotions is really a challenging task. In this paper, we propose a novel MER method by using deep convolutional neural network (CNN) on the music spectrograms that contains both the original time and frequency domain information. By the proposed method, no additional effort on extracting specific features required, which is left to the training procedure of the CNN model. Experiments are conducted on the standard CAL500 and CAL500exp dataset. Results show that, for both datasets, the proposed method outperforms state-of-the-art methods.",
            "output": [
                "CNN BASED MUSIC EMOTION CLASSIFICATION"
            ]
        },
        {
            "id": "task1540-2111453a2bc14cb196617ca72ea82531",
            "input": "Information sources such as relational databases, spreadsheets, XML, JSON, and Web APIs contain a tremendous amount of structured data that can be leveraged to build and augment knowledge graphs. However, they rarely provide a semantic model to describe their contents. Semantic models of data sources represent the implicit meaning of the data by specifying the concepts and the relationships within the data. Such models are the key ingredients to automatically publish the data into knowledge graphs. Manually modeling the semantics of data sources requires significant effort and expertise, and although desirable, building these models automatically is a challenging problem. Most of the related work focuses on semantic annotation of the data fields (source attributes). However, constructing a semantic model that explicitly describes the relationships between the attributes in addition to their semantic types is critical. We present a novel approach that exploits the knowledge from a domain ontology and the semantic models of previously modeled sources to automatically learn a rich semantic model for a new source. This model represents the semantics of the new source in terms of the concepts and relationships defined by the domain ontology. Given some sample data from the new source, we leverage the knowledge in the domain ontology and the known semantic models to construct a weighted graph that represents the space of plausible semantic models for the new source. Then, we compute the top k candidate semantic models and suggest to the user a ranked list of the semantic models for the new source. The approach takes into account user corrections to learn more accurate semantic models on future data sources. Our evaluation shows that our method generates expressive semantic models for data sources and services with minimal user input. These precise models make it possible to automatically integrate the data across sources and provide rich support for source discovery and service composition. They also make it possible to automatically publish semantic data into knowledge graphs.",
            "output": [
                "Learning the Semantics of Structured Data Sources"
            ]
        },
        {
            "id": "task1540-69da17d85a534975beee79a53d03efb9",
            "input": "Understanding the ways in which participants in public discussions frame their arguments is important in understanding how public opinion is formed. In this paper, we adopt the position that it is time for more computationallyoriented research on problems involving framing. In the interests of furthering that goal, we propose the following specific, interesting and, we believe, relatively accessible question: In the controversy regarding the use of genetically-modified organisms (GMOs) in agriculture, do proand anti-GMO articles differ in whether they choose to adopt a more “scientific” tone? Prior work on the rhetoric and sociology of science suggests that hedging may distinguish popular-science text from text written by professional scientists for their colleagues. We propose a detailed approach to studying whether hedge detection can be used to understanding scientific framing in the GMO debates, and provide corpora to facilitate this study. Some of our preliminary analyses suggest that hedges occur less frequently in scientific discourse than in popular text, a finding that contradicts prior assertions in the literature. We hope that our initial work and data will encourage others to pursue this promising line of inquiry. Publication venue: ACL Workshop on ExtraPropositional Aspects of Meaning in Computational Linguistics, 2012",
            "output": [
                "Hedge detection as a lens on framing in the GMO debates: A position paper"
            ]
        },
        {
            "id": "task1540-54d43d9ed9504905bdb3059064037a36",
            "input": "Pattern-based methods of IS-A relation extraction rely heavily on so called Hearst patterns. These are ways of expressing instance enumerations of a class in natural language. While these lexico-syntactic patterns prove quite useful, they may not capture all taxonomical relations expressed in text. Therefore in this paper we describe a novel method of IS-A relation extraction from patterns, which uses morpho-syntactical annotations along with grammatical case of noun phrases that constitute entities participating in IS-A relation. We also describe a method for increasing the number of extracted relations that we call pseudo-subclass boosting which has potential application in any pattern-based relation extraction method. Experiments were conducted on a corpus of about 0.5 billion web documents in Polish language.",
            "output": [
                "Grammatical Case Based IS-A Relation Extraction with Boosting for Polish"
            ]
        },
        {
            "id": "task1540-dc7eace3caec49c6888731153bd257b2",
            "input": "We present an unsupervised explainable word embedding technique, called EVE, which is built upon the structure of Wikipedia. The proposed model defines the dimensions of a semantic vector representing a word using humanreadable labels, thereby it readily interpretable. Specifically, each vector is constructed using the Wikipedia category graph structure together with the Wikipedia article link structure. To test the effectiveness of the proposed word embedding model, we consider its usefulness in three fundamental tasks: 1) intruder detection — to evaluate its ability to identify a non-coherent vector from a list of coherent vectors, 2) ability to cluster — to evaluate its tendency to group related vectors together while keeping unrelated vectors in separate clusters, and 3) sorting relevant items first — to evaluate its ability to rank vectors (items) relevant to the query in the top order of the result. For each task, we also propose a strategy to generate a task-specific human-interpretable explanation from the model. These demonstrate the overall effectiveness of the explainable embeddings generated by EVE. Finally, we compare EVE with the Word2Vec, FastText, and GloVe embedding techniques across the three tasks, and report improvements over the state-of-the-art.",
            "output": [
                "EVE: Explainable Vector Based Embedding Technique Using Wikipedia"
            ]
        },
        {
            "id": "task1540-7df25aec3c4e43768b808521a67f58d7",
            "input": "In the Internet of Things (IoT) domain, various heterogeneous ubiquitous devices would be able to connect and communicate with each other seamlessly, irrespective of the domain. Semantic representation of data through detailed standardized annotation has shown to improve the integration of the interconnected heterogeneous devices. However, the semantic representation of these heterogeneous data sources for environmental monitoring systems is not yet well supported. To achieve the maximum benefits of IoT for drought forecasting, a dedicated semantic middleware solution is required. This research proposes a middleware that semantically represents and integrates heterogeneous data sources with indigenous knowledge based on a unified ontology for an accurate IoT-based drought early warning system (DEWS).",
            "output": [
                "Towards Semantic Integration of Heterogeneous Sensor Data with Indigenous Knowledge for Drought Forecasting"
            ]
        },
        {
            "id": "task1540-3ad643f507d84ad58aa6b2c550ad8919",
            "input": "Many ubiquitous computing projects have addressed health and wellness behaviors such as healthy eating. Healthy meal recommendations have the potential to help individuals prevent or manage conditions such as diabetes and obesity. However, learning people’s food preferences and making healthy recommendations that appeal to their palate is challenging. Existing approaches either only learn high-level preferences or require a prolonged learning period. We propose Yum-me, a personalized healthy-meal recommender system designed to meet individuals’ health goals, dietary restrictions, and finegrained food preferences. Marrying ideas from user preference learning and healthy eating promotion, Yum-me enables a simple and accurate food preference profiling procedure via an image-based online learning framework, and projects the learned profile into the domain of healthy food options to find ones that will appeal to the user. We present the design and implementation of Yum-me, and further discuss the most critical component of it: FoodDist, a state-of-the-art food image analysis model. We demonstrate FoodDist’s superior performance through careful benchmarking, and discuss its applicability across a wide array of dietary applications. We validate the feasibility and effectiveness of Yum-me through a 60-person user study, in which Yum-me improves the recommendation acceptance rate by 42.63% over the traditional food preference survey. ACM Classification",
            "output": [
                "Yum-me: Personalized Healthy Meal Recommender System"
            ]
        },
        {
            "id": "task1540-42bb3cd0c09b4762bf3b5a008f3fde80",
            "input": "-This study proposes a framework of Uncertainty-based Group Decision Support System (UGDSS). It provides a platform for multiple criteria decision analysis in six aspects including (1) decision environment, (2) decision problem, (3) decision group, (4) decision conflict, (5) decision schemes and (6) group negotiation. Based on multiple artificial intelligent technologies, this framework provides reliable support for the comprehensive manipulation of applications and advanced decision approaches through the design of an integrated multi-agents architecture.",
            "output": [
                "Towards a Reliable Framework of Uncertainty-based Group Decision Support System"
            ]
        },
        {
            "id": "task1540-ea1cb2f5df8b44549b5dda0d7ef88a5a",
            "input": "The detection and identification of extreme weather events in large scale climate simulations is an important problem for risk management, informing governmental policy decisions and advancing our basic understanding of the climate system. Recent work has shown that fully supervised convolutional neural networks (CNNs) can yield acceptable accuracy for classifying well-known types of extreme weather events when large amounts of labeled data are available. However, there are many different types of spatially localized climate patterns of interest (including hurricanes, extra-tropical cyclones, weather fronts, blocking events, etc.) found in simulation data for which labeled data is not available at large scale for all simulations of interest. We present a multichannel spatiotemporal encoder-decoder CNN architecture for semi-supervised bounding box prediction and exploratory data analysis. This architecture is designed to fully model multichannel simulation data, temporal dynamics and unlabelled data within a reconstruction and prediction framework so as to improve the detection of a wide range of extreme weather events. Our architecture can be viewed as a 3D convolutional autoencoder with an additional modified one-pass bounding box regression loss. We demonstrate that our approach is able to leverage temporal information and unlabelled data to improve localization of extreme weather events. Further, we explore the representations learned by our model in order to better understand this important data, and facilitate further work in understanding and mitigating the effects of climate change.",
            "output": [
                "SEMI-SUPERVISED DETECTION OF EXTREME WEATHER EVENTS IN LARGE CLIMATE DATASETS"
            ]
        },
        {
            "id": "task1540-1891161a4d164ea395c1012551ca967b",
            "input": "Backward simulation is an approximate inference technique for Bayesian belief networks. It differs from existing simulation methods in that it starts simulation from the known evidence and works backward (i.e., contrary to the direction of the arcs). The technique's focus on the evidence leads to improved convergence in situations where the posterior beliefs are dominated by the evidence rather than by the prior probabilities. Since this class of situations is large, the technique may make practical the application of approximate inference in Bayesian belief networks to many real�world problems.",
            "output": [
                "Backward Simulation in Bayesian Networks"
            ]
        },
        {
            "id": "task1540-30c35f9a46184aacacc728235143b6ef",
            "input": "Markovian processes have long been used to model stochastic environments. Reinforcement learning has emerged as a framework to solve sequential planning and decision-making problems in such environments. In recent years, attempts were made to apply methods from reinforcement learning to construct decision support systems for action selection in Markovian environments. Although conventional methods in reinforcement learning have proved to be useful in problems concerning sequential decision-making, they cannot be applied in their current form to decision support systems, such as those in medical domains, as they suggest policies that are often highly prescriptive and leave little room for the user’s input. Without the ability to provide flexible guidelines, it is unlikely that these methods can gain ground with users of such systems. This paper introduces the new concept of non-deterministic policies to allow more flexibility in the user’s decision-making process, while constraining decisions to remain near optimal solutions. We provide two algorithms to compute non-deterministic policies in discrete domains. We study the output and running time of these method on a set of synthetic and real-world problems. In an experiment with human subjects, we show that humans assisted by hints based on non-deterministic policies outperform both human-only and computer-only agents in a web navigation task.",
            "output": [
                "Non-Deterministic Policies in Markovian Decision Processes"
            ]
        },
        {
            "id": "task1540-3bf53c52f2df48dd9ee1fe09c340f78f",
            "input": "Despite being so vital to success of Support Vector Machines, the principle of separating margin maximisation is not used in deep learning. We show that minimisation of margin variance and not maximisation of the margin is more suitable for improving generalisation in deep architectures. We propose the Halfway loss function that minimises the Normalised Margin Variance (NMV) at the output of a deep learning models and evaluate its performance against the Softmax Cross-Entropy loss on the MNIST, smallNORB and CIFAR-10 datasets.",
            "output": [
                "Effects of the optimisation of the margin distribution on generalisation in deep architectures"
            ]
        },
        {
            "id": "task1540-082b7d83f56641fb978ae1a165492e24",
            "input": "Literature on Constraint Satisfaction exhibits the definition of several “structural” properties that can be possessed by CSPs, like (in)consistency, substitutability or interchangeability. Current tools for constraint solving typically detect such properties efficiently by means of incomplete yet effective algorithms, and use them to reduce the search space and boost search. In this paper, we provide a unifying framework encompassing most of the properties known so far, both in CSP and other fields’ literature, and shed light on the semantical relationships among them. This gives a unified and comprehensive view of the topic, allows new, unknown, properties to emerge, and clarifies the computational complexity of the various detection problems. In particular, among the others, two new concepts, fixability and removability emerge, that come out to be the ideal characterisations of values that may be safely assigned or removed from a variable’s domain, while preserving problem satisfiability. These two notions subsume a large number of known properties, including inconsistency, substitutability and others. Because of the computational intractability of all the property-detection problems, by following the CSP approach we then determine a number of relaxations which provide sufficient conditions for their tractability. In particular, we exploit forms of language restrictions and local reasoning.",
            "output": [
                "A Unifying Framework for Structural Properties of CSPs: Definitions, Complexity, Tractability"
            ]
        },
        {
            "id": "task1540-1324365ad59740febe38788c84517582",
            "input": "In this work we extend to the interval-valued setting the notion of an overlap functions and we discuss a method which makes use of interval-valued overlap functions for constructing OWA operators with interval-valued weights. . Some properties of intervalvalued overlap functions and the derived interval-valued OWA operators are analysed. We specially focus on the homogeneity and migrativity properties.",
            "output": [
                "Generalized Interval-valued OWA Operators with Interval Weights Derived from Interval-valued Overlap Functions"
            ]
        },
        {
            "id": "task1540-66d69fdd2c464b9d91e6c1457cbfac74",
            "input": "We can program a Real-Time (RT) music improvisation system in C++ without a formal semantic or we can model it with process calculi such as the Non-deterministic Timed Concurrent Constraint (ntcc) calculus. “A Concurrent Constraints Factor Oracle (FO) model for Music Improvisation” (Ccfomi) is an improvisation model specified on ntcc. Since Ccfomi improvises non-deterministically, there is no control on choices and therefore little control over the sequence variation during the improvisation. To avoid this, we extended Ccfomi using the Probabilistic Non-deterministic Timed Concurrent Constraint calculus. Our extension to Ccfomi does not change the time and space complexity of building the FO, thus making our extension compatible with RT. However, there was not a ntcc interpreter capable of RT to execute Ccfomi. We developed Ntccrt –a RT capable interpreter for ntcc– and we executed Ccfomi on Ntccrt. In the future, we plan to extend Ntccrt to execute our extension to Ccfomi.",
            "output": [
                "Probabilistic Extension to the Concurrent Constraint Factor Oracle Model for Music Improvisation"
            ]
        },
        {
            "id": "task1540-5d2b446f930e4b20b31fa85fa9d150e6",
            "input": "Device-free (DF) localization is an emerging technology that allows the detection and tracking of entities that do not carry any devices not participate actively in the localization process. Typically, DF systems require a large number of transmitters and receivers to achieve acceptable accuracy, which is not available in many scenarios such as homes and small businesses. In this paper, we introduce MonoStream as an accurate single-stream DF localization system that leverages the rich Channel State Information (CSI) as well as MIMO information from the physical layer to provide accurate DF localization with only one stream. To boost its accuracy and attain low computational requirements, MonoStream models the DF localization problem as an object recognition problem and uses a novel set of CSI-context features and techniques with proven accuracy and efficiency. Experimental evaluation in two typical testbeds, with a side-by-side comparison with the state-of-the-art, shows that MonoStream can achieve an accuracy of 0.95m with at least 26% enhancement in median distance error using a single stream only. This enhancement in accuracy comes with an efficient execution of less than 23ms per location update on a typical laptop. This highlights the potential of MonoStream usage for real-time DF tracking applications.",
            "output": [
                "MonoStream: A Minimal-Hardware High Accuracy Device-free WLAN Localization System"
            ]
        },
        {
            "id": "task1540-e99855e5783e4b4ca676542909f1c4b7",
            "input": "Determinantal Point Processes (Dpps) are elegant probabilistic models of repulsion and diversity over discrete sets of items. But their applicability to large sets is hindered by expensive cubic-complexity matrix operations for basic tasks such as sampling. In light of this, we propose a new method for approximate sampling from discrete k-Dpps. Our method takes advantage of the diversity property of subsets sampled from a Dpp, and proceeds in two stages: first it constructs coresets for the ground set of items; thereafter, it efficiently samples subsets based on the constructed coresets. As opposed to previous approaches, our algorithm aims to minimize the total variation distance to the original distribution. Experiments on both synthetic and real datasets indicate that our sampling algorithm works efficiently on large data sets, and yields more accurate samples than previous approaches.",
            "output": [
                "Efficient Sampling for k-Determinantal Point Processes"
            ]
        },
        {
            "id": "task1540-7f783d62a74e419e92980e9c6257a00f",
            "input": "A BN20 network is a two level belief net in which parent interactions are modeled using the noisy-or interaction model. In this paper we discuss application of the SPI local expression language [1] to effi­ cient inference in large BN20 networks. In particular, we show that there is sig­ nificant structure which can be exploited to improve over the Quickscore result. We further describe how symbolic tech­ niques can provide information which can significantly reduce the computation required for computing all cause poste­ rior marginals. Finally, we present a novel approximation technique with pre­ liminary experimental results.",
            "output": [
                "Symbolic Probabilistic Inference in large BN20 networks"
            ]
        },
        {
            "id": "task1540-d3f7ac6bd3434a1f9e030e60de010529",
            "input": "Generic text embeddings are successfully used in a variety of tasks. However, they are often learnt by capturing the co-occurrence structure from pure text corpora, resulting in limitations of their ability to generalize. In this paper, we explore models that incorporate visual information into the text representation. Based on comprehensive ablation studies, we propose a conceptually simple, yet well performing architecture. It outperforms previous multimodal approaches on a set of well established benchmarks. We also improve the state-of-the-art results for image-related text datasets, using orders of magnitude less data.",
            "output": [
                "Better Text Understanding Through Image-To-Text Transfer"
            ]
        },
        {
            "id": "task1540-573b1e37bd364fa38abba2a43d9ee3f8",
            "input": "Traditional neural networks assume vectorial inputs as the network is arranged as layers of single line of computing units called neurons. This special structure requires the non-vectorial inputs such as matrices to be converted into vectors. This process can be problematic. Firstly, the spatial information among elements of the data may be lost during vectorisation. Secondly, the solution space becomes very large which demands very special treatments to the network parameters and high computational cost. To address these issues, we propose matrix neural networks (MatNet), which takes matrices directly as inputs. Each neuron senses summarised information through bilinear mapping from lower layer units in exactly the same way as the classic feed forward neural networks. Under this structure, back prorogation and gradient descent combination can be utilised to obtain network parameters efficiently. Furthermore, it can be conveniently extended for multimodal inputs. We apply MatNet to MNIST handwritten digits classification and image super resolution tasks to show its effectiveness. Without too much tweaking MatNet achieves comparable performance as the state-of-the-art methods in both tasks with considerably reduced complexity.",
            "output": [
                "Matrix Neural Networks"
            ]
        },
        {
            "id": "task1540-f95ba1cf431e49ae9d7c6fc4919a93c3",
            "input": "Extracting time expressions from free text is a fundamental task for many applications. We analyze the time expressions from four datasets and observe that only a small group of words are used to express time information, and the words in time expressions demonstrate similar syntactic behaviour. Based on the observations, we propose a type-based approach, named SynTime, to recognize time expressions. Specifically, we define three main syntactic types, namely time token, modifier, and numeral, to group time-related regular expressions over tokens. On the types we design simple heuristic rules to recognize time expressions. In recognition, SynTime first identifies the time tokens from raw text, then searches their surroundings for modifiers and numerals to form time segments, and finally merges the time segments to time expressions. As a light-weight rule-based tagger, SynTime runs in real time, and can be easily expanded by simply adding keywords for the text of different types and of different domains. Experiment results show that SynTime outperforms state-of-the-art methods on benchmark datasets and tweets data.",
            "output": [
                "Time Expression Analysis and Recognition Using Syntactic Types and Simple Heuristic Rules"
            ]
        },
        {
            "id": "task1540-52ebd5fbbed74f7386a9e064493c2681",
            "input": "Various tasks in decision making and decision support systems require selecting a preferred subset of a given set of items. Here we focus on problems where the individual items are described using a set of characterizing attributes, and a generic preference specification is required, that is, a specification that can work with an arbitrary set of items. For example, preferences over the content of an online newspaper should have this form: At each viewing, the newspaper contains a subset of the set of articles currently available. Our preference specification over this subset should be provided offline, but we should be able to use it to select a subset of any currently available set of articles, e.g., based on their tags. We present a general approach for lifting formalisms for specifying preferences over objects with multiple attributes into ones that specify preferences over subsets of such objects. We also show how we can compute an optimal subset given such a specification in a relatively efficient manner. We provide an empirical evaluation of the approach as well as some worst-case complexity results.",
            "output": [
                "Generic Preferences over Subsets of Structured Objects"
            ]
        },
        {
            "id": "task1540-32620d09bf374cfbafd5f7b5d92125c3",
            "input": "Sampling from hierarchical Bayesian models is often difficult for MCMC methods, because of the strong correlations between the model parameters and the hyperparameters. Recent Riemannian manifold Hamiltonian Monte Carlo (RMHMC) methods have significant potential advantages in this setting, but are computationally expensive. We introduce a new RMHMC method, which we call semi-separable Hamiltonian Monte Carlo, which uses a specially designed mass matrix that allows the joint Hamiltonian over model parameters and hyperparameters to decompose into two simpler Hamiltonians. This structure is exploited by a new integrator which we call the alternating blockwise leapfrog algorithm. The resulting method can mix faster than simpler Gibbs sampling while being simpler and more efficient than previous instances of RMHMC.",
            "output": [
                "Semi-Separable Hamiltonian Monte Carlo for Inference in Bayesian Hierarchical Models"
            ]
        },
        {
            "id": "task1540-651bcc720af64ba68e6189bc2331f5ca",
            "input": "Word embeddings are now a standard technique for inducing meaning representations for words. For getting good representations, it is important to take into account different senses of a word. In this paper, we propose a mixture model for learning multi-sense word embeddings. Our model generalizes the previous works in that it allows to induce different weights of different senses of a word. The experimental results show that our model outperforms previous models on standard evaluation tasks.",
            "output": [
                "A Mixture Model for Learning Multi-Sense Word Embeddings"
            ]
        },
        {
            "id": "task1540-bc113c7271ce455d95ffcaa89b35cb7f",
            "input": "Outlier detection in a large-scale database is a significant and complex issue in knowledge discovering field. As the data distributions are obscure and uncertain in high dimensional space, most existing solutions try to solve the issue taking into account the two intuitive points: first, outliers are extremely far away from other points in high dimensional space; second, outliers are detected obviously different in projected-dimensional subspaces. However, for a complicated case that outliers are hidden inside the normal points in all dimensions, existing detection methods fail to find such inner outliers. In this paper, we propose a method with twice dimension-projections, which integrates primary subspace outlier detection and secondary point-projection between subspaces, and sums up the multiple weight values for each point. The points are computed with local density ratio separately in twice-projected dimensions. After the process, outliers are those points scoring the largest values of weight. The proposed method succeeds to find all inner outliers on the synthetic test datasets with the dimension varying from 100 to 10000. The experimental results also show that the proposed algorithm can work in low dimensional space and can achieve perfect performance in high dimensional space. As for this reason, our proposed approach has considerable potential to apply it in multimedia applications helping to process images or video with large-scale attributes.",
            "output": [
                "Finding Inner Outliers in High Dimensional Space"
            ]
        },
        {
            "id": "task1540-4bc7fe6a832342f191e9aacad2de650e",
            "input": "In this article, how word embeddings can be used as features in Chinese sentiment classification is presented. Firstly, a Chinese opinion corpus is built with a million comments from hotel review websites. Then the word embeddings which represent each comment are used as input in different machine learning methods for sentiment classification, including SVM, Logistic Regression, Convolutional Neural Network (CNN) and ensemble methods. These methods get better performance compared with N-gram models using Naive Bayes (NB) and Maximum Entropy (ME). Finally, a combination of machine learning methods is proposed which presents an outstanding performance in precision, recall and F1 score. After selecting the most useful methods to construct the combinational model and testing over the corpus, the final F1 score is 0.920.",
            "output": [
                "An Empirical Study on Sentiment Classification of Chinese Review using Word Embedding"
            ]
        },
        {
            "id": "task1540-539dd761427941c7a107447e0936c217",
            "input": "The way experts manage uncertainty usually changes depending on the task they are performing. This fact has lead us to consider the problem of communicating modules (task implementations) in a large and structured knowledge based system when modules have different uncertainty calculi. In this paper, the analysis of the communication problem is made assuming that (i) each uncertainty calculus is an inference mechanism defining an entailment relation, and therefore the communication is considered to be inference-preserving, and (ii) we restrict ourselves to the case which the different uncertainty calculi are given by a class of truth­ functional Multiple-valued Logics.",
            "output": [
                "Combining Multiple-valued Logics in Modular Expert Systems"
            ]
        },
        {
            "id": "task1540-b16d4da1396f43dc9aa59e8466c72cc4",
            "input": "We present an OWL 2 ontology representing the Saint Gall plan, one of the most ancient documents arrived intact to us, that describes the ideal model of a Benedictine monastic complex, and that inspired the design of many European",
            "output": [
                "The Shape of a Benedictine Monastery: The SaintGall Ontology"
            ]
        },
        {
            "id": "task1540-a0d013cd69e94843b64622ce0177858b",
            "input": "Emotional content is a key element in user-generated videos. However, it is difficult to understand emotions conveyed in such videos due to the complex and unstructured nature of user-generated content and the sparsity of video frames that express emotion. In this paper, for the first time, we study the problem of transferring knowledge from heterogeneous external sources, including image and textual data, to facilitate three related tasks in video emotion understanding: emotion recognition, emotion attribution and emotion-oriented summarization. Specifically, our framework (1) learns a video encoding from an auxiliary emotional image dataset in order to improve supervised video emotion recognition, and (2) transfers knowledge from an auxiliary textual corpus for zero-shot recognition of emotion classes unseen during training. The proposed technique for knowledge transfer facilitates novel applications of emotion attribution and emotion-oriented summarization. A comprehensive set of experiments on multiple datasets demonstrate the effectiveness of our framework.",
            "output": [
                "Heterogeneous Knowledge Transfer in Video Emotion Recognition, Attribution and Summarization"
            ]
        },
        {
            "id": "task1540-174d871c048842f4a26a1343dda2364e",
            "input": "In this paper, a novel approach is proposed to automatically construct parallel discourse corpus for dialogue machine translation. Firstly, the parallel subtitle data and its corresponding monolingual movie script data are crawled and collected from Internet. Then tags such as speaker and discourse boundary from the script data are projected to its subtitle data via an information retrieval approach in order to map monolingual discourse to bilingual texts. We not only evaluate the mapping results, but also integrate speaker information into the translation. Experiments show our proposed method can achieve 81.79% and 98.64% accuracy on speaker and dialogue boundary annotation, and speaker-based language model adaptation can obtain around 0.5 BLEU points improvement in translation qualities. Finally, we publicly release around 100K parallel discourse data with manual speaker and dialogue boundary annotation.",
            "output": [
                "Automatic Construction of Discourse Corpora for Dialogue Translation"
            ]
        },
        {
            "id": "task1540-aea7d096df984357870044e753754d6a",
            "input": "As a step towards developing zero-shot task generalization capabilities in reinforcement learning (RL), we introduce a new RL problem where the agent should learn to execute sequences of instructions after learning useful skills that solve subtasks. In this problem, we consider two types of generalizations: to previously unseen instructions and to longer sequences of instructions. For generalization over unseen instructions, we propose a new objective which encourages learning correspondences between similar subtasks by making analogies. For generalization over sequential instructions, we present a hierarchical architecture where a meta controller learns to use the acquired skills for executing the instructions. To deal with delayed reward, we propose a new neural architecture in the meta controller that learns when to update the subtask, which makes learning more efficient. Experimental results on a stochastic 3D domain show that the proposed ideas are crucial for generalization to longer instructions as well as unseen instructions.",
            "output": [
                "Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-9b17569a2c4b4b3aa777c32691a655c7",
            "input": "Neural networks are capable of learning rich, nonlinear feature representations shown to be beneficial in many predictive tasks. In this work, we use these models to explore the use of geographical features in predicting colorectal cancer survival curves for patients in the state of Iowa, spanning the years 1989 to 2012. Specifically, we compare model performance using a newly defined metric – area between the curves (ABC) – to assess (a) whether survival curves can be reasonably predicted for colorectal cancer patients in the state of Iowa, (b) whether geographical features improve predictive performance, and (c) whether a simple binary representation or richer, spectral clustering-based representation perform better. Our findings suggest that survival curves can be reasonably estimated on average, with predictive performance deviating at the five-year survival mark. We also find that geographical features improve predictive performance, and that the best performance is obtained using richer, spectral analysis-elicited features.",
            "output": [
                "Learning Rich Geographical Representations: Predicting Colorectal Cancer Survival in the State of Iowa"
            ]
        },
        {
            "id": "task1540-38160ae075524ec39c8050e5a049b968",
            "input": "In this paper, we discussed CNF-SAT problem (NP-Complete problem) and analysis two solutions that can solve the problem, the PL-Resolution algorithm and the WalkSAT algorithm. PL-Resolution is a sound and complete algorithm that can be used to determine satisfiability and unsatisfiability with certainty. WalkSAT can determine satisfiability if it finds a model, but it cannot guarantee to find a model even there exists one. However, WalkSAT is much faster than PL-Resolution, which makes WalkSAT more practical; and we have analysis the performance between these two algorithms, and the performance of WalkSAT is acceptable if the problem is not so hard.",
            "output": [
                "A novel approach of solving the CNF-SAT problem"
            ]
        },
        {
            "id": "task1540-2146e17c8b914db1a87e5f58b9ba3c0d",
            "input": "In recent years, adaptive learning systems rely increasingly on learning hierarchy to customize the educational logic developed in their courses. Most approaches do not consider that the relationships of prerequisites between the skills are fuzzy relationships. In this article, we describe a new approach of a practical application of fuzzy logic techniques to the construction of learning hierarchies. For this, we use a learning hierarchy predefined by one or more experts of a specific field. However, the relationships of prerequisites between the skills in the learning hierarchy are not definitive and they are fuzzy relationships. Indeed, we measure relevance degree of all relationships existing in this learning hierarchy and we try to answer to the following question: Is the relationships of prerequisites predefined in initial learning hierarchy are correctly established or not?",
            "output": [
                "A New Approach of Learning Hierarchy Construction Based on Fuzzy Logic"
            ]
        },
        {
            "id": "task1540-1b2ef36b2c2e4a5b80c75b5c1e99bf2f",
            "input": "In this paper, we develop a novel paradigm, namely hypergraph shift, to find robust graph modes by probabilistic voting strategy, which are semantically sound besides the self-cohesiveness requirement in forming graph modes. Unlike the existing techniques to seek graph modes by shifting vertices based on pair-wise edges (i.e, an edge with 2 ends), our paradigm is based on shifting high-order edges (hyperedges) to deliver graph modes. Specifically, we convert the problem of seeking graph modes as the problem of seeking maximizers of a novel objective function with the aim to generate good graph modes based on sifting edges in hypergraphs. As a result, the generated graph modes based on dense subhypergraphs may more accurately capture the object semantics besides the self-cohesiveness requirement. We also formally prove that our technique is always convergent. Extensive empirical studies on synthetic and real world data sets are conducted on clustering and graph matching. They demonstrate that our techniques significantly outperform the existing techniques.",
            "output": [
                "Finding Modes by Probabilistic Hypergraphs Shifting"
            ]
        },
        {
            "id": "task1540-2c41e45636ee4a0c869e1ef3e928f5c0",
            "input": "Sensory inference under conditions of uncertainty is a major problem in both machine learning and computational neuroscience. An important but poorly understood aspect of sensory processing is the role of active sensing. Here, we present a Bayes-optimal inference and control framework for active sensing, C-DAC (Context-Dependent Active Controller). Unlike previously proposed algorithms that optimize abstract statistical objectives such as information maximization (Infomax) [Butko and Movellan, 2010] or one-step look-ahead accuracy [Najemnik and Geisler, 2005], our active sensing model directly minimizes a combination of behavioral costs, such as temporal delay, response error, and sensor repositioning cost. We simulate these algorithms on a simple visual search task to illustrate scenarios in which contextsensitivity is particularly beneficial and optimization with respect to generic statistical objectives particularly inadequate. Motivated by the geometric properties of the CDAC policy, we present both parametric and non-parametric approximations, which retain context-sensitivity while significantly reducing computational complexity. These approximations enable us to investigate a more complex search problem involving peripheral vision, and we notice that the performance advantage of C-DAC over generic statistical policies is even more evident in this scenario.",
            "output": [
                "Active Sensing as Bayes-Optimal Sequential Decision-Making"
            ]
        },
        {
            "id": "task1540-4b3521f6408c475d8c3f5fb3c774ef86",
            "input": "Segmental structure is a common pattern in many types of sequences such as phrases in human languages. In this paper, we present a probabilistic model for sequences via their segmentations. The probability of a segmented sequence is calculated as the product of the probabilities of all its segments, where each segment is modeled using existing tools such as recurrent neural networks. Since the segmentation of a sequence is usually unknown in advance, we sum over all valid segmentations to obtain the final probability for the sequence. An efficient dynamic programming algorithm is developed for forward and backward computations without resorting to any approximation. We demonstrate our approach on text segmentation and speech recognition tasks. In addition to quantitative results, we also show that our approach can discover meaningful segments in their respective application contexts.",
            "output": [
                "Sequence Modeling via Segmentations"
            ]
        },
        {
            "id": "task1540-7c82c22884aa4101805bc993027873d7",
            "input": "The expected supremum of a Gaussian process indexed by the image of an index set under a function class is bounded in terms of separate properties of the index set and the function class. The bound is relevant to the estimation of nonlinear transformations or the analysis of learning algorithms whenever hypotheses are chosen from composite classes, as is the case for multi-layer models.",
            "output": [
                "A chain rule for the expected suprema of Gaussian processes"
            ]
        },
        {
            "id": "task1540-5e77563c235343f7a5c1e0fcb3dff5a6",
            "input": "The paper introduces a generalization for known probabilistic models such as log-linear and graphical models, called here multiplicative models. These models, that express probabilities via product of parameters are shown to capture multiple forms of contextual independence between variables, including decision graphs and noisy-OR functions. An inference algorithm for multiplicative models is provided and its correctness is proved. The complexity analysis of the inference algorithm uses a more refined parameter than the tree-width of the underlying graph, and shows the computational cost does not exceed that of the variable elimination algorithm in graphical models. The paper ends with examples where using the new models and algorithm is computationally beneficial.",
            "output": [
                "Inference for Multiplicative Models"
            ]
        },
        {
            "id": "task1540-d0ec64e485504e7b9f8193f305b19d30",
            "input": "We compare the effectiveness of four different syntactic CCG parsers for a semantic slotfilling task to explore how much syntactic supervision is required for downstream semantic analysis. This extrinsic, task-based evaluation also provides a unique window into the semantics captured (or missed) by unsupervised grammar induction systems.",
            "output": [
                "Evaluating Induced CCG Parsers on Grounded Semantic Parsing"
            ]
        },
        {
            "id": "task1540-d5c47180098a4c9a90fb33a89a93e062",
            "input": "Multi Sentence Compression (MSC) is of great value to many real world applications, such as guided microblog summarization, opinion summarization and newswire summarization. Recently, word graph-based approaches have been proposed and become popular in MSC. Their key assumption is that redundancy among a set of related sentences provides a reliable way to generate informative and grammatical sentences. In this paper, we propose an effective approach to enhance the word graph-based MSC and tackle the issue that most of the state-of-the-art MSC approaches are confronted with: i.e., improving both informativity and grammaticality at the same time. Our approach consists of three main components: (1) a merging method based on Multiword Expressions (MWE); (2) a mapping strategy based on synonymy between words; (3) a re-ranking step to identify the best compression candidates generated using a POS-based language model (POS-LM). We demonstrate the effectiveness of this novel approach using a dataset made of clusters of English newswire sentences. The observed improvements on informativity and grammaticality of the generated compressions show that our approach is superior to state-of-the-art MSC methods.",
            "output": [
                "On Improving Informativity and Grammaticality for Multi-Sentence Compression"
            ]
        },
        {
            "id": "task1540-b87e1ce5b31144ccb426b84352110ca5",
            "input": "Number of web services available on Internet and its usage are increasing very fast. In many cases, one service is not enough to complete the business requirement; composition of web services is carried out. Autonomous composition of web services to achieve new functionality is generating considerable attention in semantic web domain. Development time and effort for new applications can be reduced with service composition. Various approaches to carry out automated composition of web services are discussed in literature. Web service composition using ontologies is one of the effective approaches. In this paper we demonstrate how the ontology based composition can be made faster for each customer. We propose a framework to provide precomposed web services to fulfil user requirements. We detail how ontology merging can be used for composition which expedites the whole process. We discuss how framework provides customer specific ontology merging and repository. We also elaborate on how merging of ontologies is carried out. Keywords— Semantic Web, Web service composition, domain ontology, OWL-S, ontology merging",
            "output": [
                "A Framework for Semi-automated Web Service Composition in Semantic Web"
            ]
        },
        {
            "id": "task1540-a899c6bc19dd4b9d934dee9d5a2b3fab",
            "input": "Modelling Consumer Indebtedness has proven to be a problem of complex nature. In this work we utilise Data Mining techniques and methods to explore the multifaceted aspect of Consumer Indebtedness by examining the contribution of Psychological Factors, like Impulsivity to the analysis of Consumer Debt. Our results confirm the beneficial impact of Psychological Factors in modelling Consumer Indebtedness and suggest a new approach in analysing Consumer Debt, that would take into consideration more Psychological characteristics of consumers and adopt techniques and practices from Data Mining.",
            "output": [
                "A Data Mining framework to model Consumer Indebtedness with Psychological Factors"
            ]
        },
        {
            "id": "task1540-26c5a8bc59a94730a31502faa0d570ef",
            "input": "We study a subclass of POMDPs, called Deterministic POMDPs, that is characterized by deterministic actions and observations. These models do not provide the same generality of POMDPs yet they capture a number of interesting and challenging problems, and permit more efficient algorithms. Indeed, some of the recent work in planning is built around such assumptions mainly by the quest of amenable models more expressive than the classical deterministic models. We provide results about the fundamental properties of Deterministic POMDPs, their relation with AND/OR search problems and algorithms, and their computational complexity.",
            "output": [
                "Deterministic POMDPs Revisited"
            ]
        },
        {
            "id": "task1540-5aa992ed9980425dace5f98cd3308ed7",
            "input": "Research has shown that convolutional neural networks contain significant redundancy, and high classification accuracy can be obtained even when weights and activations are reduced from floating point to binary values. In this paper, we present Finn, a framework for building fast and flexible FPGA accelerators using a flexible heterogeneous streaming architecture. By utilizing a novel set of optimizations that enable efficient mapping of binarized neural networks to hardware, we implement fully connected, convolutional and pooling layers, with per-layer compute resources being tailored to user-provided throughput requirements. On a ZC706 embedded FPGA platform drawing less than 25 W total system power, we demonstrate up to 12.3 million image classifications per second with 0.31 μs latency on the MNIST dataset with 95.8% accuracy, and 21906 image classifications per second with 283 μs latency on the CIFAR-10 and SVHN datasets with respectively 80.1% and 94.9% accuracy. To the best of our knowledge, ours are the fastest classification rates reported to date on these benchmarks.",
            "output": [
                "FINN: A Framework for Fast, Scalable Binarized Neural Network Inference"
            ]
        },
        {
            "id": "task1540-d470f289ade6431fa59b747becdb624e",
            "input": "Conjunctive database queries have been extended with a mechanism for object creation to capture important applications such as data exchange, data integration, and ontology-based data access. Object creation generates new object identifiers in the result, that do not belong to the set of constants in the source database. The new object identifiers can be also seen as Skolem terms. Hence, object-creating conjunctive queries can also be regarded as restricted second-order tuple-generating dependencies (SO tgds), considered in the data exchange literature. In this paper, we focus on the class of single-function object-creating conjunctive queries, or sifo CQs for short. The single function symbol can be used only once in the head of the query. We give a new characterization for oid-equivalence of sifo CQs that is simpler than the one given by Hull and Yoshikawa and places the problem in the complexity class NP. Our characterization is based on Cohen’s equivalence notions for conjunctive queries with multiplicities. We also solve the logical entailment problem for sifo CQs, showing that also this problem belongs to NP. Results by Pichler et al. have shown that logical equivalence for more general classes of SO tgds is either undecidable or decidable with as yet unknown complexity upper bounds.",
            "output": [
                "Mapping-equivalence and oid-equivalence of single-function object-creating conjunctive queries"
            ]
        },
        {
            "id": "task1540-2ab7c608b2644cbe94409ee94e55b4b8",
            "input": "Visual Question Answering (VQA) has received a lot of attention over the past couple of years. A number of deep learning models have been proposed for this task. However, it has been shown [1–4] that these models are heavily driven by superficial correlations in the training data and lack compositionality – the ability to answer questions about unseen compositions of seen concepts. This compositionality is desirable and central to intelligence. In this paper, we propose a new setting for Visual Question Answering where the test question-answer pairs are compositionally novel compared to training question-answer pairs. To facilitate developing models under this setting, we present a new compositional split of the VQA v1.0 [5] dataset, which we call Compositional VQA (C-VQA). We analyze the distribution of questions and answers in the C-VQA splits. Finally, we evaluate several existing VQA models under this new setting and show that the performances of these models degrade by a significant amount compared to the original VQA setting.",
            "output": [
                "C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset"
            ]
        },
        {
            "id": "task1540-e6bf71ed73944893908955a7550c16f4",
            "input": "Abundant data is the key to successful machine learning. However, supervised learning requires annotated data that are often hard to obtain. In a classification task with limited resources, Active Learning (AL) promises to guide annotators to examples that bring the most value for a classifier. AL can be successfully combined with self-training, i.e., extending a training set with the unlabelled examples for which a classifier is the most certain. We report our experiences on using AL in a systematic manner to train an SVM classifier for Stack Overflow posts discussing performance of software components. We show that the training examples deemed as the most valuable to the classifier are also the most difficult for humans to annotate. Despite carefully evolved annotation criteria, we report low inter-rater agreement, but we also propose mitigation strategies. Finally, based on one annotator’s work, we show that self-training can improve the classification accuracy. We conclude the paper by discussing implication for future text miners aspiring to use AL and self-training. Keywords-text mining, classification, active learning, selftraining, human annotation.",
            "output": [
                "On Using Active Learning and Self-Training when Mining Performance Discussions on Stack Overflow"
            ]
        },
        {
            "id": "task1540-2f7b06d64b5e4f679b3fd68de0bbac09",
            "input": "Dawid, Kjrerulff & Lauritzen (1994) provided a preliminary description of a hybrid between Monte-Carlo sampling methods and exact lo­ cal computations in junction trees. Utiliz­ ing the strengths of both methods, such hy­ brid inference methods has the potential of expanding the class of problems which can be solved under bounded resources as well as solving problems which otherwise resist ex­ act solutions. The paper provides a detailed description of a particular instance of such a hybrid scheme; namely, combination of ex­ act inference and Gibbs sampling in discrete Bayesian networks. We argue that this com­ bination calls for an extension of the usual message passing scheme of ordinary junction trees.",
            "output": [
                "HUGS: Combining Exact Inference and Gibbs Sampling in Junction Trees"
            ]
        },
        {
            "id": "task1540-24e8ab5d611c47e2812af339d3e11eb8",
            "input": "Approximations of Laplace-Beltrami operators on manifolds through graph Laplacians have become popular tools in data analysis and machine learning. These discretized operators usually depend on bandwidth parameters whose tuning remains a theoretical and practical problem. In this paper, we address this problem for the unnormalized graph Laplacian by establishing an oracle inequality that opens the door to a well-founded data-driven procedure for the bandwidth selection. Our approach relies on recent results by Lacour and Massart [LM15] on the so-called Lepski’s method.",
            "output": [
                "Data driven estimation of Laplace-Beltrami operator"
            ]
        },
        {
            "id": "task1540-03f51d7fad704d468a7a99a8df5c9bb2",
            "input": "Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered 4 distinct medical imaging applications in 3 specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from 3 different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pretrained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that (1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; (2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; (3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and (4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.",
            "output": [
                "Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?"
            ]
        },
        {
            "id": "task1540-fe56469b435e472c9fa4b5b05c0cd9ad",
            "input": "In this paper ∗–compatible extensions of fuzzy relations are studied, generalizing some results obtained by Duggan in case of crisp relations. From this general result are obtained as particular cases fuzzy versions of some important extension theorems for crisp relations (Szpilrajn, Hansson, Suzumura). Two notions of consistent closure of a fuzzy relation are introduced.",
            "output": [
                "Compatible extensions and consistent closures: a fuzzy approach"
            ]
        },
        {
            "id": "task1540-409f8389f9e94c45adb9aabd503517d7",
            "input": "We present a system for recognising human activity given a symbolic representation of video content. The input of our system is a set of time-stamped short-term activities (STA) detected on video frames. The output is a set of recognised long-term activities (LTA), which are pre-defined temporal combinations of STA. The constraints on the STA that, if satisfied, lead to the recognition of a LTA, have been expressed using a dialect of the Event Calculus. In order to handle the uncertainty that naturally occurs in human activity recognition, we adapted this dialect to a state-of-the-art probabilistic logic programming framework. We present a detailed evaluation and comparison of the crisp and probabilistic approaches through experimentation on a benchmark dataset of human surveillance videos.",
            "output": [
                "A Probabilistic Logic Programming Event Calculus"
            ]
        },
        {
            "id": "task1540-d97fb8cb888f4e9fb0e00eb2fce8dfad",
            "input": "For supervised and unsupervised learning, positive definite kernels allow to use large and potentially infinite dimensional feature spaces with a computational cost that only depends on the number of observations. This is usually done through the penalization of predictor functions by Euclidean or Hilbertian norms. In this paper, we explore penalizing by sparsity-inducing norms such as the l-norm or the block l-norm. We assume that the kernel decomposes into a large sum of individual basis kernels which can be embedded in a directed acyclic graph; we show that it is then possible to perform kernel selection through a hierarchical multiple kernel learning framework, in polynomial time in the number of selected kernels. This framework is naturally applied to non linear variable selection; our extensive simulations on synthetic datasets and datasets from the UCI repository show that efficiently exploring the large feature space through sparsity-inducing norms leads to state-of-the-art predictive performance.",
            "output": [
                "Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning"
            ]
        },
        {
            "id": "task1540-7c65c3f8689d46e889c083e25b4e4dfb",
            "input": "Malicious URL, a.k.a. malicious website, is a common and serious threat to cybersecurity. Malicious URLs host unsolicited content (spam, phishing, drive-by exploits, etc.) and lure unsuspecting users to become victims of scams (monetary loss, theft of private information, and malware installation), and cause losses of billions of dollars every year. It is imperative to detect and act on such threats in a timely manner. Traditionally, this detection is done mostly through the usage of blacklists. However, blacklists cannot be exhaustive, and lack the ability to detect newly generated malicious URLs. To improve the generality of malicious URL detectors, machine learning techniques have been explored with increasing attention in recent years. This article aims to provide a comprehensive survey and a structural understanding of Malicious URL Detection techniques using machine learning. We present the formal formulation of Malicious URL Detection as a machine learning task, and categorize and review the contributions of literature studies that addresses different dimensions of this problem (feature representation, algorithm design, etc.). Further, this article provides a timely and comprehensive survey for a range of different audiences, not only for machine learning researchers and engineers in academia, but also for professionals and practitioners in cybersecurity industry, to help them understand the state of the art and facilitate their own research and practical applications. We also discuss practical issues in system design, open research challenges, and point out some important directions for future research.",
            "output": [
                "Malicious URL Detection using Machine Learning: A Survey"
            ]
        },
        {
            "id": "task1540-119bfec590844469ba67fbe71d65f90e",
            "input": "<lb>The support vector machine (SVM) is a widely used method for classification. Although many<lb>efforts have been devoted to develop efficient solvers, it remains challenging to apply SVM to large-<lb>scale problems. A nice property of SVM is that the non-support vectors have no effect on the resulting<lb>classifier. Motivated by this observation, we present fast and efficient screening rules to discard non-<lb>support vectors by analyzing the dual problem of SVM via variational inequalities (DVI). As a result,<lb>the number of data instances to be entered into the optimization can be substantially reduced. Some<lb>appealing features of our screening method are: (1) DVI is safe in the sense that the vectors discarded<lb>by DVI are guaranteed to be non-support vectors; (2) the data set needs to be scanned only once to run<lb>the screening, whose computational cost is negligible compared to that of solving the SVM problem; (3)<lb>DVI is independent of the solvers and can be integrated with any existing efficient solvers. We also show<lb>that the DVI technique can be extended to detect non-support vectors in the least absolute deviations<lb>regression (LAD). To the best of our knowledge, there are currently no screening methods for LAD. We<lb>have evaluated DVI on both synthetic and real data sets. Experiments indicate that DVI significantly<lb>outperforms the existing state-of-the-art screening rules for SVM, and is very effective in discarding<lb>non-support vectors for LAD. The speedup gained by DVI rules can be up to two orders of magnitude.",
            "output": [
                "Scaling SVM and Least Absolute Deviations via Exact Data Reduction"
            ]
        },
        {
            "id": "task1540-02420e623d10421990ab8a75b36b94d6",
            "input": "Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Evolutionary algorithms provide a technique to discover such networks automatically. Despite significant computational requirements, we show that evolving models that rival large, hand-designed architectures is possible today. We employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions. To do this, we use novel and intuitive mutation operators that navigate large search spaces. We stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.",
            "output": [
                "Large-Scale Evolution of Image Classifiers"
            ]
        },
        {
            "id": "task1540-398c6dfa30af4adebae8ed723f48c00c",
            "input": "Given the advantage and recent success of English character-level and subword-unit models in several NLP tasks, we consider the equivalent modeling problem for Chinese. Chinese script is logographic and many Chinese logograms are composed of common substructures that provide semantic, phonetic and syntactic hints. In this work, we propose to explicitly incorporate the visual appearance of a character’s glyph in its representation, resulting in a novel glyph-aware embedding of Chinese characters. Being inspired by the success of convolutional neural networks in computer vision, we use them to incorporate the spatio-structural patterns of Chinese glyphs as rendered in raw pixels. In the context of two basic Chinese NLP tasks of language modeling and word segmentation, the model learns to represent each character’s task-relevant semantic and syntactic information in the character-level embedding.",
            "output": [
                "Glyph-aware Embedding of Chinese Characters"
            ]
        },
        {
            "id": "task1540-f9560af07eb347ccafa5e16b99f848a8",
            "input": "In this paper, we will expound upon the concepts proffered in [5], where we proposed an information theoretic approach to intelligence in the computational sense. We will examine data and meme aggregation, and study the effect of limited resources on the resulting meme amplitudes.",
            "output": [
                "The Computational Theory of Intelligence: Data Aggregation"
            ]
        },
        {
            "id": "task1540-9891e8e0fe724657ab2d34e00995fd1f",
            "input": "Concept drift is a major issue that greatly affects the accuracy and reliability of many real-world applications of machine learning. We argue that to tackle concept drift it is important to develop the capacity to describe and analyze it. We propose tools for this purpose, arguing for the importance of quantitative descriptions of drift in marginal distributions. We present quantitative drift analysis techniques along with methods for communicating their results. We demonstrate their effectiveness by application to three real-world learning tasks.",
            "output": [
                "Understanding Concept Drift"
            ]
        },
        {
            "id": "task1540-eb67c5a559fa47a38bc41fc1b091e802",
            "input": "Entity linking is the task of identifying mentions of entities in text, and linking them to entries in a knowledge base. This task is especially difficult in microblogs, as there is little additional text to provide disambiguating context; rather, authors rely on an implicit common ground of shared knowledge with their readers. In this paper, we attempt to capture some of this implicit context by exploiting the social network structure in microblogs. We build on the theory of homophily, which implies that socially linked individuals share interests, and are therefore likely to mention the same sorts of entities. We implement this idea by encoding authors, mentions, and entities in a continuous vector space, which is constructed so that socially-connected authors have similar vector representations. These vectors are incorporated into a neural structured prediction model, which captures structural constraints that are inherent in the entity linking task. Together, these design decisions yield F1 improvements of 1%-5% on benchmark datasets, as compared to the previous state-of-the-art.",
            "output": [
                "Toward Socially-Infused Information Extraction: Embedding Authors, Mentions, and Entities"
            ]
        },
        {
            "id": "task1540-03d1cc3b52c34c14a0ac36e40f2c5e90",
            "input": "In this paper, we present a joint compression and classification approach of EEG and EMG signals using a deep learning approach. Specifically, we build our system based on the deep autoencoder architecture which is designed not only to extract discriminant features in the multimodal data representation but also to reconstruct the data from the latent representation using encoder-decoder layers. Since autoencoder can be seen as a compression approach, we extend it to handle multimodal data at the encoder layer, reconstructed and retrieved at the decoder layer. We show through experimental results, that exploiting both multimodal data intercorellation and intracorellation 1) Significantly reduces signal distortion particularly for high compression levels 2) Achieves better accuracy in classifying EEG and EMG signals recorded and labeled according to the sentiments of the volunteer.",
            "output": [
                "Multimodal deep learning approach for joint EEG-EMG data compression and classification"
            ]
        },
        {
            "id": "task1540-61274b46e90b45cfb20bdf821c858937",
            "input": "IBM Watson is a cognitive computing system capable of question answering in natural languages. It is believed that IBM Watson can understand large corpora and answer relevant questions more effectively than any other question-answering system currently available. To unleash the full power of Watson, however, we need to train its instance with a large number of wellprepared question-answer pairs. Obviously, manually generating such pairs in a large quantity is prohibitively time consuming and significantly limits the efficiency of Watson’s training. Recently, a large-scale dataset of over 30 million question-answer pairs was reported. Under the assumption that using such an automatically generated dataset could relieve the burden of manual question-answer generation, we tried to use this dataset to train an instance of Watson and checked the training efficiency and accuracy. According to our experiments, using this auto-generated dataset was effective for training Watson, complementing manually crafted question-answer pairs. To the best of the authors’ knowledge, this work is the first attempt to use a largescale dataset of automatically generated questionanswer pairs for training IBM Watson. We anticipate that the insights and lessons obtained from our experiments will be useful for researchers who want to expedite Watson training leveraged by automatically generated question-answer pairs.",
            "output": [
                "Training IBM Watson using Automatically Generated Question-Answer Pairs"
            ]
        },
        {
            "id": "task1540-75f94d13decf45918c898f44e412e0e3",
            "input": "In this paper we present a new neurobiologically-inspired affective cognitive architecture: NEUCOGAR (NEUromodulating COGnitive ARchitecture). The objective of NEUCOGAR is the identification of a mapping from the influence of serotonin, dopamine and noradrenaline to the computing processes based on Von Neuman’s architecture, in order to implement affective phenomena which can operate on the Turing’s machine model. As basis of the modeling we use and extend the Lövheims Cube of Emotion with parameters of the Von Neumann architecture. Validation is conducted via simulation on a computing system of dopamine neuromodulation and its effects on the Cortex. In the experimental phase of the project, the increase of computing power and storage redistribution due to emotion stimulus modulated by the dopamine system, confirmed the soundness of the model.",
            "output": [
                "A Cognitive Architecture for the Implementation of Emotions in Computing Systems"
            ]
        },
        {
            "id": "task1540-5bf3897bdd35450db9fd67a7e1b2159e",
            "input": "We study a symmetric collaborative dialogue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models.",
            "output": [
                "Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings"
            ]
        },
        {
            "id": "task1540-8070986dbadd4638bfcae30fb3d0fd0d",
            "input": "Neural machine translation (NMT) approaches have improved the state of the art in many machine translation settings over the last couple of years, but they require large amounts of training data to produce sensible output. We demonstrate that NMT can be used for low-resource languages as well, by introducing more local dependencies and using word alignments to learn sentence reordering during translation. In addition to our novel model, we also present an empirical evaluation of low-resource phrase-based statistical machine translation (SMT) and NMT to investigate the lower limits of the respective technologies. We find that while SMT remains the best option for low-resource settings, our method can produce acceptable translations with only 70 000 tokens of training data, a level where the baseline NMT system fails completely.",
            "output": [
                "Neural machine translation for low-resource languages"
            ]
        },
        {
            "id": "task1540-f7be2b73136c406b82b6f27851d77d3c",
            "input": "We introduce a model for constructing vector representations of words by composing characters using bidirectional LSTMs. Relative to traditional word representation models that have independent vectors for each word type, our model requires only a single vector per character type and a fixed set of parameters for the compositional model. Despite the compactness of this model and, more importantly, the arbitrary nature of the form–function relationship in language, our “composed” word representations yield state-of-the-art results in language modeling and part-of-speech tagging. Benefits over traditional baselines are particularly pronounced in morphologically rich languages (e.g., Turkish).",
            "output": [
                "Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation"
            ]
        },
        {
            "id": "task1540-6f4504b7a7e24e3fa750459b9612a4cb",
            "input": "We use multilayer Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences – patches of image pixels and high-level representations (“percepts”) of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We try to visualize and interpret the learned features. We stress test the model by running it on longer time scales and on out-of-domain data. We further evaluate the representations by finetuning them for a supervised learning problem – human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only a few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.",
            "output": [
                "Unsupervised Learning of Video Representations using LSTMs"
            ]
        },
        {
            "id": "task1540-5f50aca046044fa8abea191a99d83f98",
            "input": "Word alignment is an important natural language processing task that indicates the correspondence between natural languages. Recently, unsupervised learning of log-linear models for word alignment has received considerable attention as it combines the merits of generative and discriminative approaches. However, a major challenge still remains: it is intractable to calculate the expectations of non-local features that are critical for capturing the divergence between natural languages. We propose a contrastive approach that aims to differentiate observed training examples from noises. It not only introduces prior knowledge to guide unsupervised learning but also cancels out partition functions. Based on the observation that the probability mass of log-linear models for word alignment is usually highly concentrated, we propose to use top-n alignments to approximate the expectations with respect to posterior distributions. This allows for efficient and accurate calculation of expectations of non-local features. Experiments show that our approach achieves significant improvements over stateof-the-art unsupervised word alignment methods.",
            "output": [
                "Contrastive Unsupervised Word Alignment with Non-Local Features"
            ]
        },
        {
            "id": "task1540-1d61def9d1ee44edb0d4f56f459b7379",
            "input": "Abstract—Spectral clustering is a powerful tool for unsupervised data analysis. In this paper, we propose a contextaware hypergraph similarity measure (CAHSM), which leads to robust spectral clustering in the case of noisy data. We construct three types of hypergraph—the pairwise hypergraph, the k-nearest-neighbor (kNN) hypergraph, and the high-order over-clustering hypergraph. The pairwise hypergraph captures the pairwise similarity of data points; the kNN hypergraph captures the neighborhood of each point; and the clustering hypergraph encodes high-order contexts within the dataset. By combining the affinity information from these three hypergraphs, the CAHSM algorithm is able to explore the intrinsic topological information of the dataset. Therefore, data clustering using CAHSM tends to be more robust. Considering the intracluster compactness and the inter-cluster separability of vertices, we further design a discriminative hypergraph partitioning criterion (DHPC). Using both CAHSM and DHPC, a robust spectral clustering algorithm is developed. Theoretical analysis and experimental evaluation demonstrate the effectiveness and robustness of the proposed algorithm.",
            "output": [
                "Context-Aware Hypergraph Construction for Robust Spectral Clustering"
            ]
        },
        {
            "id": "task1540-0d96c4624eef49f0866dbf1c0d635d77",
            "input": "The use of alluring headlines (clickbait) to tempt the readers has become a growing practice nowadays. For the sake of existence in the highly competitive media industry, most of the on-line media including the mainstream ones, have started following this practice. Although the wide-spread practice of clickbait makes the reader’s reliability on media vulnerable, a large scale analysis to reveal this fact is still absent. In this paper, we analyze 1.67 million Facebook posts created by 153 media organizations to understand the extent of clickbait practice, its impact and user engagement by using our own developed clickbait detection model. The model uses distributed sub-word embeddings learned from a large corpus. The accuracy of the model is 98.3%. Powered with this model, we further study the distribution of topics in clickbait and non-clickbait contents.",
            "output": [
                "Diving Deep into Clickbaits: Who Use Them to What Extents in Which Topics with What Effects?"
            ]
        },
        {
            "id": "task1540-43db4ee4ce1143a9b3fe93f5b034d97c",
            "input": "We design and analyze minimax-optimal algorithms for online linear optimization games where the player’s choice is unconstrained. The player strives to minimize regret, the difference between his loss and the loss of a post-hoc benchmark strategy. The standard benchmark is the loss of the best strategy chosen from a bounded comparator set. When the the comparison set and the adversary’s gradients satisfy L∞ bounds, we give the value of the game in closed form and prove it approaches √ 2T/π as T → ∞. Interesting algorithms result when we consider soft constraints on the comparator, rather than restricting it to a bounded set. As a warmup, we analyze the game with a quadratic penalty. The value of this game is exactly T/2, and this value is achieved by perhaps the simplest online algorithm of all: unprojected gradient descent with a constant learning rate. We then derive a minimax-optimal algorithm for a much softer penalty function. This algorithm achieves good bounds under the standard notion of regret for any comparator point, without needing to specify the comparator set in advance. The value of this game converges to √ e as T → ∞; we give a closed-form for the exact value as a function of T . The resulting algorithm is natural in unconstrained investment or betting scenarios, since it guarantees at worst constant loss, while allowing for exponential reward against an “easy” adversary.",
            "output": [
                "Minimax Optimal Algorithms for Unconstrained Linear Optimization"
            ]
        },
        {
            "id": "task1540-5ee63a5669a6414cbb0000e0d9fbe614",
            "input": "Recent work on word embeddings has shown that simple vector subtraction over pre-trained embeddings is surprisingly effective at capturing different lexical relations, despite lacking explicit supervision. Prior work has evaluated this intriguing result using a word analogy prediction formulation and hand-selected relations, but the generality of the finding over a broader range of lexical relation types and different learning settings has not been evaluated. In this paper, we carry out such an evaluation in two learning settings: (1) spectral clustering to induce word relations, and (2) supervised learning to classify vector differences into relation types. We find that word embeddings capture a surprising amount of information, and that, under suitable supervised training, vector subtraction generalises well to a broad range of relations, including over unseen lexical items.",
            "output": [
                "Take and Took, Gaggle and Goose, Book and Read: Evaluating the Utility of Vector Differences for Lexical Relation Learning"
            ]
        },
        {
            "id": "task1540-654a607fc3024494aba37a86e93ff73e",
            "input": "Federated Learning is a machine learning setting where the goal is to train a highquality centralized model with training data distributed over a large number of clients each with unreliable and relatively slow network connections. We consider learning algorithms for this setting where on each round, each client independently computes an update to the current model based on its local data, and communicates this update to a central server, where the client-side updates are aggregated to compute a new global model. The typical clients in this setting are mobile phones, and communication efficiency is of utmost importance. In this paper, we propose two ways to reduce the uplink communication costs. The proposed methods are evaluated on the application of training a deep neural network to perform image classification. Our best approach reduces the upload communication required to train a reasonable model by two orders of magnitude.",
            "output": [
                "Federated Learning: Strategies for Improving Communication Efficiency"
            ]
        },
        {
            "id": "task1540-a1d9591ac91e453a80db6219b13bb9e7",
            "input": "Sound events often occur in unstructured environments where they exhibit wide variations in their frequency content and temporal structure. Convolutional neural networks (CNN) are able to extract higher level features that are invariant to local spectral and temporal variations. Recurrent neural networks (RNNs) are powerful in learning the longer term temporal context in the audio signals. CNNs and RNNs as classifiers have recently shown improved performances over established methods in various sound recognition tasks. We combine these two approaches in a Convolutional Recurrent Neural Network (CRNN) and apply it on a polyphonic sound event detection task. We compare the performance of the proposed CRNN method with CNN, RNN, and other established methods, and observe a considerable improvement for four different datasets consisting of everyday sound events.",
            "output": [
                "Convolutional Recurrent Neural Networks for Polyphonic Sound Event Detection"
            ]
        },
        {
            "id": "task1540-83450ef1ed05440aab57bd4bc55974fa",
            "input": "The Stable Matching Problem with Couples (SMP-C) is a ubiquitous real-world extension of the stable matching problem (SMP) involving complementarities. Although SMP can be solved in polynomial time, SMP-C is NP-Complete. Hence, it is not clear which, if any, of the theoretical results surrounding the canonical SMP problem apply in this setting. In this paper, we use a recently-developed SAT encoding to solve SMP-C exactly. This allows us to enumerate all stable matchings for any given instance of SMP-C. With this tool, we empirically evaluate some of the properties that have been hypothesized to hold for SMP-C. We take particular interest in investigating if, as the size of the market grows, the percentage of instances with unique stable matchings also grows. While we did not find this trend among the random problem instances we sampled, we did find that the percentage of instances with an resident optimal matching seems to more closely follow the trends predicted by previous conjectures. We also define and investigate resident Pareto optimal stable matchings, finding that, even though this is important desideratum for the deferred acceptance style algorithms previously designed to solve SMP-C, they do not always find one. We also investigate strategy-proofness for SMP-C, showing that even if only one stable matching exists, residents still have incentive to misreport their preferences. However, if a problem has a resident optimal stable matching, we show that residents cannot manipulate via truncation.",
            "output": [
                "Exploring Strategy-Proofness, Uniqueness, and Pareto Optimality for the Stable Matching Problem with Couples"
            ]
        },
        {
            "id": "task1540-ed3e0cb3bfbd458ebe2da3d5b81f4262",
            "input": "Distributional word representation methods exploit word co-occurrences to build compact vector encodings of words. While these representations enjoy widespread use in modern natural language processing, it is unclear whether they accurately encode all necessary facets of conceptual meaning. In this paper, we evaluate how well these representations can predict perceptual and conceptual features of concrete concepts, drawing on two semantic norm datasets sourced from human participants. We find that several standard word representations fail to encode many salient perceptual features of concepts, and show that these deficits correlate with word-word similarity prediction errors. Our analyses provide motivation for grounded and embodied language learning approaches, which may help to remedy these deficits.",
            "output": [
                "Are distributional representations ready for the real world? Evaluating word vectors for grounded perceptual meaning"
            ]
        },
        {
            "id": "task1540-b2748a4ab21b476497822bd437c55879",
            "input": "Many large MDPs can be represented compactly using a dynamic Bayesian network. Although the structure of the value function does not re­ tain the structure of the process, recent work has suggested that value functions in factored MDPs can often be approximated well using a factored value function: a linear combination of restr icted basis functions, each of which refers only to a small subset of variables. An approximate fac­ tored value function for a particular policy can be computed using approximate dynamic pro­ gramming, but this approach (and others) can only produce an approximation relative to a dis­ tance metric which is weighted by the station­ ary distribution of the current policy. This type of weighted projection is ill-suited to policy im­ provement. We present a new approach to value determination, that uses a simple closed-form computation to compute a least-squares decom­ posed approximation to the value function for any weights directly. We then use this value de­ termination algorithm as a subroutine in a pol­ icy iteration process. We show that, under rea­ sonable restrictions, the policies induced by a factored value function can be compactly repre­ sented as a decision list, and can be manipulated efficiently in a policy iteration process. We also present a method for computing error bounds for decomposed value functions using a variable­ elimination algorithm for function optimization. The complexity of all of our algorithms depends on the factorization of the system dynamics and of the approximate value function.",
            "output": [
                "Policy Iteration for Factored MDPs"
            ]
        },
        {
            "id": "task1540-5a9fd9524bf848bebe1b7a7703f9b266",
            "input": "The rise of graph-structured data such as social networks, regulatory networks, citation graphs, and functional brain networks, in combination with resounding success of deep learning in various applications, has brought the interest in generalizing deep learning models to non-Euclidean domains. In this paper, we introduce a new spectral domain convolutional architecture for deep learning on graphs. The core ingredient of our model is a new class of parametric rational complex functions (Cayley polynomials) allowing to efficiently compute localized regular filters on graphs that specialize on frequency bands of interest. Our model scales linearly with the size of the input data for sparsely-connected graphs, can handle different constructions of Laplacian operators, and typically requires less parameters than previous models. Extensive experimental results show the superior performance of our approach on various graph learning problems.",
            "output": [
                "CayleyNets: Graph Convolutional Neural Networks with Complex Rational Spectral Filters"
            ]
        },
        {
            "id": "task1540-6294aa6da5d14df88e46fdad4b1762ee",
            "input": "Random utility theory models an agent’s preferences on alternatives by drawing a real-valued score on each alternative (typically independently) from a parameterized distribution, and then ranking the alternatives according to scores. A special case that has received significant attention is the Plackett-Luce model, for which fast inference methods for maximum likelihood estimators are available. This paper develops conditions on general random utility models that enable fast inference within a Bayesian framework through MC-EM, providing concave loglikelihood functions and bounded sets of global maxima solutions. Results on both real-world and simulated data provide support for the scalability of the approach and capability for model selection among general random utility models including Plackett-Luce.",
            "output": [
                "Random Utility Theory for Social Choice"
            ]
        },
        {
            "id": "task1540-a1708346c3174b3a803f466f4a7390f1",
            "input": "Although a number of related algorithms have been developed to evaluate influence diagrams, exploiting the conditional independence in the diagram, the exact solution has remained intractable for many important problems. In this paper we introduce decision circuits as a means to exploit the local structure usually found in decision problems and to improve the performance of influence diagram analysis. This work builds on the probabilistic inference algorithms using arithmetic circuits to represent Bayesian belief networks [Darwiche, 2003]. Once compiled, these arithmetic circuits efficiently evaluate probabilistic queries on the belief network, and methods have been developed to exploit both the global and local structure of the network. We show that decision circuits can be constructed in a similar fashion and promise similar benefits.",
            "output": [
                "Evaluating influence diagrams with decision circuits"
            ]
        },
        {
            "id": "task1540-c8fab0a0e7f949e6918fc7e913c201f6",
            "input": "Implementing an accurate and fast activation function with low cost is a crucial aspect to the implementation of Deep Neural Networks (DNNs) on FPGAs. We propose a highaccuracy approximation approach for the hyperbolic tangent activation function of artificial neurons in DNNs. It is based on the Discrete Cosine Transform Interpolation Filter (DCTIF). The proposed architecture combines simple arithmetic operations on stored samples of the hyperbolic tangent function and on input data. The proposed DCTIF implementation achieves two orders of magnitude greater precision than previous work while using the same or fewer computational resources. Various combinations of DCTIF parameters can be chosen to tradeoff the accuracy and complexity of the hyperbolic tangent function. In one case, the proposed architecture approximates the hyperbolic tangent activation function with 10 maximum error while requiring only 1.52 Kbits memory and 57 LUTs of a Virtex-7 FPGA. We also discuss how the activation function accuracy affects the performance of DNNs in terms of their training and testing accuracies. We show that a high accuracy approximation can be necessary in order to maintain the same DNN training and testing performances realized by the exact function.",
            "output": [
                "Accurate and Efficient Hyperbolic Tangent Activation Function on FPGA using the DCT Interpolation Filter"
            ]
        },
        {
            "id": "task1540-7e1ebecf927c4730acc468aa83966093",
            "input": "Numerous algorithms are used for nonnegative matrix factorization under the assumption that the matrix is nearly separable. In this paper, we show how to make these algorithms efficient for data matrices that have many more rows than columns, so-called “tall-and-skinny matrices”. One key component to these improved methods is an orthogonal matrix transformation that preserves the separability of the NMF problem. Our final methods need a single pass over the data matrix and are suitable for streaming, multi-core, and MapReduce architectures. We demonstrate the efficacy of these algorithms on terabyte-sized synthetic matrices and real-world matrices from scientific computing and bioinformatics.",
            "output": [
                "Scalable methods for nonnegative matrix factorizations of near-separable tall-and-skinny matrices"
            ]
        },
        {
            "id": "task1540-1faee0146cba407b8b215df0b0069865",
            "input": "MXNet is a multi-language machine learning (ML) library to ease the development of ML algorithms, especially for deep neural networks. Embedded in the host language, it blends declarative symbolic expression with imperative tensor computation. It offers auto differentiation to derive gradients. MXNet is computation and memory efficient and runs on various heterogeneous systems, ranging from mobile devices to distributed GPU clusters. This paper describes both the API design and the system implementation of MXNet, and explains how embedding of both symbolic expression and tensor operation is handled in a unified fashion. Our preliminary experiments reveal promising results on large scale deep neural network applications using multiple GPU machines.",
            "output": [
                "MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems"
            ]
        },
        {
            "id": "task1540-fe5318972cf7492ea6863de2d7b700bb",
            "input": "We introduce a simple, general framework for likelihood-free Bayesian reinforcement learning, through Approximate Bayesian Computation (ABC). The advantage is that we only require a prior distribution on a class of simulators. This is useful when a probabilistic model of the underlying process is too complex to formulate, but where detailed simulation models are available. ABC-RL allows the use of any Bayesian reinforcement learning technique in this case. It can be seen as an extension of simulation methods to both planning and inference. We experimentally demonstrate the potential of this approach in a comparison with LSPI. Finally, we introduce a theorem showing that ABC is sound.",
            "output": [
                "ABC Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-ff65c8da9e8b4fe8a0b6055d7cfb6f18",
            "input": "In large scale machine learning and data mining problems with high feature dimensionality, the Euclidean distance between data points can be uninformative, and Distance Metric Learning (DML) is often desired to learn a proper similarity measure (using side information such as example data pairs being similar or dissimilar). However, high dimensionality and large volume of pairwise constraints in modern big data can lead to prohibitive computational cost for both the original DML formulation in Xing et al. (2002) and later extensions. In this paper, we present a distributed algorithm for DML, and a large-scale implementation on a parameter server architecture. Our approach builds on a parallelizable reformulation of Xing et al. (2002), and an asynchronous stochastic gradient descent optimization procedure. To our knowledge, this is the first distributed solution to DML, and we show that, on a system with 256 CPU cores, our program is able to complete a DML task on a dataset with 1 million data points, 22-thousand features, and 200 million labeled data pairs, in 15 hours; and the learned metric shows great effectiveness in properly measuring distances.",
            "output": [
                "LARGE SCALE DISTRIBUTED DISTANCE METRIC LEARNING"
            ]
        },
        {
            "id": "task1540-1a90ceeb218748fea9e3a05f799d6ef9",
            "input": "Recurrent Neural Networks (RNNs) have become the state-of-the-art choice for extracting patterns from temporal sequences. However, current RNN models are ill-suited to process irregularly sampled data triggered by events generated in continuous time by sensors or other neurons. Such data can occur, for example, when the input comes from novel event-driven artificial sensors that generate sparse, asynchronous streams of events or from multiple conventional sensors with different update intervals. In this work, we introduce the Phased LSTM model, which extends the LSTM unit by adding a new time gate. This gate is controlled by a parametrized oscillation with a frequency range that produces updates of the memory cell only during a small percentage of the cycle. Even with the sparse updates imposed by the oscillation, the Phased LSTM network achieves faster convergence than regular LSTMs on tasks which require learning of long sequences. The model naturally integrates inputs from sensors of arbitrary sampling rates, thereby opening new areas of investigation for processing asynchronous sensory events that carry timing information. It also greatly improves the performance of LSTMs in standard RNN applications, and does so with an order-of-magnitude fewer computes at runtime.",
            "output": [
                "Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences"
            ]
        },
        {
            "id": "task1540-08857948a17541cda6bd12cd280ebf7b",
            "input": "We consider the problem of translating high-level textual descriptions to formal representations in technical documentation as part of an effort to model the meaning of such documentation. We focus specifically on the problem of learning translational correspondences between text descriptions and grounded representations in the target documentation, such as formal representation of functions or code templates. Our approach exploits the parallel nature of such documentation, or the tight coupling between high-level text and the low-level representations we aim to learn. Data is collected by mining technical documents for such parallel text-representation pairs, which we use to train a simple semantic parsing model. We report new baseline results on sixteen novel datasets, including the standard library documentation for nine popular programming languages across seven natural languages, and a small collection of Unix utility manuals.",
            "output": [
                "Learning Semantic Correspondences in Technical Documentation"
            ]
        },
        {
            "id": "task1540-e84f81aacc43420abe81891ba5a05310",
            "input": "Monte Carlo Tree Search (MCTS) has improved the performance of game engines in domains such as Go, Hex, and general game playing. MCTS has been shown to outperform classic αβ search in games where good heuristic evaluations are difficult to obtain. In recent years, combining ideas from traditional minimax search in MCTS has been shown to be advantageous in some domains, such as Lines of Action, Amazons, and Breakthrough. In this paper, we propose a new way to use heuristic evaluations to guide the MCTS search by storing the two sources of information, estimated win rates and heuristic evaluations, separately. Rather than using the heuristic evaluations to replace the playouts, our technique backs them up implicitly during the MCTS simulations. These minimax values are then used to guide future simulations. We show that using implicit minimax backups leads to stronger play performance in Kalah, Breakthrough, and Lines of Action.",
            "output": [
                "Monte Carlo Tree Search with Heuristic Evaluations using Implicit Minimax Backups"
            ]
        },
        {
            "id": "task1540-e109a951293349ba842c1915432b5964",
            "input": "Neural networks and rational functions efficiently approximate each other. In more detail, it is shown here that for any ReLU network, there exists a rational function of degreeO(poly log(1/ )) which is -close, and similarly for any rational function there exists a ReLU network of size O(poly log(1/ )) which is -close. By contrast, polynomials need degree Ω(poly(1/ )) to approximate even a single ReLU. When converting a ReLU network to a rational function as above, the hidden constants depend exponentially on the number of layers, which is shown to be tight; in other words, a compositional representation can be beneficial even for rational functions. 1. Overview Significant effort has been invested in characterizing the functions that can be efficiently approximated by neural networks. The goal of the present work is to characterize neural networks more finely by finding a class of functions which is not only well-approximated by neural networks, but also well-approximates neural networks. The function class investigated here is the class of rational functions: functions represented as the ratio of two polynomials, where the denominator is a strictly positive polynomial. For simplicity, the neural networks are taken to always use ReLU activation σr(x) := max{0, x}; for a review of neural networks and their terminology, the reader is directed to Section 1.4. For the sake of brevity, a network with ReLU activations is simply called a ReLU network. 1.1. Main results The main theorem here states that ReLU networks and rational functions approximate each other well in the sense University of Illinois, Urbana-Champaign; work completed while visiting the Simons Institute. Correspondence to: your friend <mjt@illinois.edu>. Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s). −1.00 −0.75 −0.50 −0.25 0.00 0.25 0.50 0.75 1.00 0 1 2 3 4 spike rat poly net Figure 1. Rational, polynomial, and ReLU network fit to “spike”, a function which is 1/x along [1/4, 1] and 0 elsewhere. that -approximating one class with the other requires a representation whose size is polynomial in ln(1 / ), rather than being polynomial in 1/ . Theorem 1.1. 1. Let ∈ (0, 1] and nonnegative integer k be given. Let p : [0, 1] → [−1,+1] and q : [0, 1] → [2−k, 1] be polynomials of degree ≤ r, each with≤ smonomials. Then there exists a function f : [0, 1] → R, representable as a ReLU network of size (number of nodes) O ( k ln(1 / ) + min { srk ln(sr / ), sdk ln(dsr / ) }) ,",
            "output": [
                "Neural networks and rational functions"
            ]
        },
        {
            "id": "task1540-27545c53c6904175a95118e90476355f",
            "input": "A modular method is proposed to learn and transfer visuo-motor policies from simulation to the real world in an efficient manner by combining domain randomization and adaptation. The feasibility of the approach is demonstrated in a table-top object reaching task where a 7 DoF arm is controlled in velocity mode to reach a blue cuboid in clutter through visual observations. The learned visuo-motor policies are robust to novel (not seen in training) objects in clutter and even a moving target, achieving a 93.3% success rate and 2.2 cm control accuracy.",
            "output": [
                "Sim-to-real Transfer of Visuo-motor Policies for Reaching in Clutter: Domain Randomization and Adaptation with Modular Networks*"
            ]
        },
        {
            "id": "task1540-1c751511db0f46729e081e9fe2923d74",
            "input": "Sample complexity and safety are major challenges when learning policies with reinforcement learning for real-world tasks, especially when the policies are represented using rich function approximators like deep neural networks. Model-based methods where the real-world target domain is approximated using a simulated source domain provide an avenue to tackle the above challenges by augmenting real data with simulated data. However, discrepancies between the simulated source domain and the target domain pose a challenge for simulated training. We introduce the EPOpt algorithm, which uses an ensemble of simulated source domains and a form of adversarial training to learn policies that are robust and generalize to a broad range of possible target domains, including unmodeled effects. Further, the probability distribution over source domains in the ensemble can be adapted using data from target domain and approximate Bayesian methods, to progressively make it a better approximation. Thus, learning on a model ensemble, along with source domain adaptation, provides the benefit of both robustness and learning/adaptation.",
            "output": [
                "EPOPT: LEARNING ROBUST NEURAL NETWORK POLICIES USING MODEL ENSEMBLES"
            ]
        },
        {
            "id": "task1540-4cb603db8aa742848ee08e62eadcc983",
            "input": "A fundamental advantage of neural models for NLP is their ability to learn representations from scratch. However, in practice this often means ignoring existing external linguistic resources, e.g., WordNet or domain specific ontologies such as the Unified Medical Language System (UMLS). We propose a general, novel method for exploiting such resources via weight sharing. Prior work on weight sharing in neural networks has considered it largely as a means of model compression. In contrast, we treat weight sharing as a flexible mechanism for incorporating prior knowledge into neural models. We show that this approach consistently yields improved performance on classification tasks compared to baseline strategies that do not exploit weight sharing.",
            "output": [
                "Exploiting Domain Knowledge via Grouped Weight Sharing with Application to Text Categorization"
            ]
        },
        {
            "id": "task1540-8423d65fd0fa44f8ac6763fa819b7d5e",
            "input": "In this correspondence, we will point out a problem with testing adaptive classifiers on autocorrelated data. In such a case random change alarms may boost the accuracy figures. Hence, we cannot be sure if the adaptation is working well.",
            "output": [
                "How good is the Electricity benchmark for evaluating concept drift adaptation"
            ]
        },
        {
            "id": "task1540-1c0bf0d471444593888716c425a3cbe7",
            "input": "Online media offers opportunities to marketers to deliver brand messages to a large audience. Advertising technology platforms enables the advertisers to find the proper group of audiences and deliver ad impressions to them in real time. The recent growth of the real time bidding has posed a significant challenge on monitoring such a complicated system. With so many components we need a reliable system that detects the possible changes in the system and alerts the engineering team. In this paper we describe the mechanism that we invented for recovering the representative metrics and detecting the change in their behavior. We show that this mechanism is able to detect the possible problems in time by describing some incident cases.",
            "output": [
                "Finding Needle in a Million Metrics: Anomaly Detection in a Large-scale Computational Advertising Platform"
            ]
        },
        {
            "id": "task1540-e940f2b987894d45984597d183160b16",
            "input": "Novel research in the field of Linked Data focuses on the problem of entity summarization. This field addresses the problem of ranking features according to their importance for the task of identifying a particular entity. Next to a more human friendly presentation, these summarizations can play a central role for semantic search engines and semantic recommender systems. In current approaches, it has been tried to apply entity summarization based on patterns that are inherent to the regarded data. The proposed approach of this paper focuses on the movie domain. It utilizes usage data in order to support measuring the similarity between movie entities. Using this similarity it is possible to determine the k-nearest neighbors of an entity. This leads to the idea that features that entities share with their nearest neighbors can be considered as significant or important for these entities. Additionally, we introduce a downgrading factor (similar to TF-IDF) in order to overcome the high number of commonly occurring features. We exemplify the approach based on a movie-ratings dataset that has been linked to Freebase entities.",
            "output": [
                "Leveraging Usage Data for Linked Data Movie Entity Summarization"
            ]
        },
        {
            "id": "task1540-c7dd5028ac9b4c0fb890763c49149e8a",
            "input": "We propose a pool-based non-parametric active learning algorithm for general metric spaces, called MArgin Regularized Metric Active Nearest Neighbor (MARMANN), which outputs a nearest-neighbor classifier. We give prediction error guarantees that depend on the noisy-margin properties of the input sample, and are competitive with those obtained by previously proposed passive learners. We prove that the label complexity of MARMANN is significantly lower than that of any passive learner with similar error guarantees. MARMANN is based on a generalized sample compression scheme, and a new label-efficient active model-selection procedure.",
            "output": [
                "Active Nearest-Neighbor Learning in Metric Spaces"
            ]
        },
        {
            "id": "task1540-33f0d3d8838d4f6cab56592d84768302",
            "input": "We investigate attention as the active pursuit of useful information. This contrasts with attention as a mechanism for the attenuation of irrelevant information. We also consider the role of short-term memory, whose use is critical to any model incapable of simultaneously perceiving all information on which its output depends. We present several simple synthetic tasks, which become considerably more interesting when we impose strong constraints on how a model can interact with its input, and on how long it can take to produce its output. We develop a model with a different structure from those seen in previous work, and we train it using stochastic variational inference with a learned proposal distribution.",
            "output": [
                "Testing Visual Attention in Dynamic Environments"
            ]
        },
        {
            "id": "task1540-e531bd47205347e1aac9dbdd68108502",
            "input": "In a real-world data set there is always the possibility, rather high in our opinion, that different features may have different degrees of relevance. Most machine learning algorithms deal with this fact by either selecting or deselecting features in the data preprocessing phase. However, we maintain that even among relevant features there may be different degrees of relevance, and this should be taken into account during the clustering process. With over 50 years of history, K-Means is arguably the most popular partitional clustering algorithm there is. The first K-Means based clustering algorithm to compute feature weights was designed just over 30 years ago. Various such algorithms have been designed since but there has not been, to our knowledge, a survey integrating empirical evidence of cluster recovery ability, common flaws, and possible directions for future research. This paper elaborates on the concept of feature weighting and addresses these issues by critically analysing some of the most popular, or innovative, feature weighting mechanisms based in K-Means.",
            "output": [
                "A survey on feature weighting based K-Means algorithms"
            ]
        },
        {
            "id": "task1540-158e65a5ffbb4d9f993168b1aa736511",
            "input": "We consider the problem of finding good finite-horizon policies for POMDPs under the expected reward metric. The policies con­ sidered are free finite-memory policies with limited memory; a policy is a mapping from the space of observation-memory pairs to the space of action-memory pairs (the policy up­ dates the memory as it goes), and the num­ ber of possible memory states is a parameter of the input to the policy-finding algorithms. The algorithms considered here are prelimi­ nary implementations of three search heuris­ tics: local search, simulated annealing, and genetic algorithms. We compare their out­ comes to each other and to the optimal poli­ cies for each instance. We compare run times of each policy and of a dynamic programming algorithm for POMDPs developed by Hansen that iteratively improves a finite-state con­ troller the previous state of the art for finite memory policies. The value of the best policy can only improve as the amount of memory increases, up to the amount needed for an optimal finite-memory policy. Our most surprising finding is that more memory helps in another way: given more memory than is needed for an optimal policy, the algo­ rithms are more likely to converge to optimal­ valued policies.",
            "output": [
                "My Brain is Full: When More Memory Helps"
            ]
        },
        {
            "id": "task1540-a67b70295a2d47a99207b23a9ac82153",
            "input": "We investigate crowdsourcing algorithms for finding the top-quality item within a large collection of objects with unknown intrinsic quality values. This is an important problem with many relevant applications, for example in networked recommendation systems. The core of the algorithms is that objects are distributed to crowd workers, who return a noisy evaluation. All received evaluations are then combined, to identify the top-quality object. We first present a simple probabilistic model for the system under investigation. Then, we devise and study a class of efficient adaptive algorithms to assign in an effective way objects to workers. We compare the performance of several algorithms, which correspond to different choices of the design parameters/metrics. We finally compare our approach based on scoring object qualities against traditional proposals based on comparisons and tournaments.",
            "output": [
                "Selecting the top-quality item through crowd scoring"
            ]
        },
        {
            "id": "task1540-9a93baa38ee8407e8d4b7089e56dfb8e",
            "input": "We consider the quantified constraint satisfaction problem (QCSP) which is to decide, given a structure and a first-order sentence (not assumed here to be in prenex form) built from conjunction and quantification, whether or not the sentence is true on the structure. We present a proof system for certifying the falsity of QCSP instances and develop its basic theory; for instance, we provide an algorithmic interpretation of its behavior. Our proof system places the established Q-resolution proof system in a broader context, and also allows us to derive QCSP tractability results.",
            "output": [
                "BEYOND Q-RESOLUTION AND PRENEX FORM: A PROOF SYSTEM FOR QUANTIFIED CONSTRAINT SATISFACTION"
            ]
        },
        {
            "id": "task1540-b80f46a5e1d8488da7c2d5fd60a11466",
            "input": "The problem of scheduling under resource constraints is widely applicable. One prominent example is power management, in which we have a limited continuous supply of power but must schedule a number of power-consuming tasks. Such problems feature tightly coupled continuous resource constraints and continuous temporal constraints. We address such problems by introducing the Time Resource Network (TRN), an encoding for resource-constrained scheduling problems. The definition allows temporal specifications using a general family of representations derived from the Simple Temporal network, including the Simple Temporal Network with Uncertainty, and the probabilistic Simple Temporal Network (Fang et al. (2014)). We propose two algorithms for determining the consistency of a TRN: one based on Mixed Integer Programing and the other one based on Constraint Programming, which we evaluate on scheduling problems with Simple Temporal Constraints and Probabilistic Temporal Constraints.",
            "output": [
                "Time Resource Networks"
            ]
        },
        {
            "id": "task1540-67405f12c9a6446599532ea41f5b5399",
            "input": "Bellemare et al. (2016) introduced the notion of a pseudo-count to generalize count-based exploration to non-tabular reinforcement learning. This pseudo-count is derived from a density model which effectively replaces the count table used in the tabular setting. Using an exploration bonus based on this pseudo-count and a mixed Monte Carlo update applied to a DQN agent was sufficient to achieve state-of-the-art on the Atari 2600 game Montezuma’s Revenge.",
            "output": [
                "Count-Based Exploration with Neural Density Models"
            ]
        },
        {
            "id": "task1540-14fac6770ea54756bfe7350c435856c5",
            "input": "Classification performance is often not uniform over the data. Some areas in the input space are easier to classify than others. Features that hold information about the ”difficulty” of the data may be nondiscriminative and are therefore disregarded in the classification process. We propose a meta-learning approach where performance may be improved by post-processing. This improvement is done by establishing a dynamic threshold on the base-classifier results. Since the base-classifier is treated as a “black box” the method presented can be used on any state of the art classifier in order to try an improve its performance. We focus our attention on how to better control the true-positive/false-positive tradeoff known as the ROC curve. We propose an algorithm for the derivation of optimal thresholds by redistributing the error depending on features that hold information about difficulty. We demonstrate the resulting benefit on both synthetic and real-life data.",
            "output": [
                "Bending the Curve: Improving the ROC Curve Through Error Redistribution"
            ]
        },
        {
            "id": "task1540-eecb6bf572bc42c491b97584fb3032d6",
            "input": "Background: A systematic review identifies and collates various clinical studies and compares data elements and results in order to provide an evidence based answer for a particular clinical question. The process is manual and involves lot of time. A tool to automate this process is lacking. Objective: The aim of this work is to develop a framework using natural language processing and machine learning to build information extraction algorithms to identify data elements in a new primary publication, without having to go through the expensive task of manual annotation to build gold standards for each data element type. Method: The system is developed in two stages. Initially, it uses information contained in existing systematic reviews to identify the sentences from the PDF files of the included references that contain specific data elements of interest using a modified Jaccard similarity measure. These sentences have been treated as labeled data. A Support Vector Machine (SVM) classifier is trained on this labeled data to extract data elements of interests from a new article. Results: We conducted experiments on Cochrane Database systematic reviews related to congestive heart failure using inclusion criteria as an example data element. The empirical results show that the proposed system automatically identifies sentences containing the data element of interest with a high recall (93.75%) and reasonable precision (27.05% which means the reviewers have to read only 3.7 sentences on average). Conclusions: The empirical results suggest that the tool is retrieving valuable information from the reference articles, even when it is time-consuming to identify them manually. Thus we hope that the tool will be useful for automatic data extraction from biomedical research publications. The future scope of this work is to generalize this information framework for all types of systematic reviews",
            "output": [
                "A Novel Framework to Expedite Systematic Reviews by Automatically Building Information Extraction Training Corpora"
            ]
        },
        {
            "id": "task1540-db13e18993ee430db6a1aee36998c1ce",
            "input": "We present a probabilistic language model for time-stamped text data which tracks the semantic evolution of individual words over time. The model represents words and contexts by latent trajectories in an embedding space. At each moment in time, the embedding vectors are inferred from a probabilistic version of word2vec (Mikolov et al., 2013b). These embedding vectors are connected in time through a latent diffusion process. We describe two scalable variational inference algorithms—skipgram smoothing and skip-gram filtering—that allow us to train the model jointly over all times; thus learning on all data while simultaneously allowing word and context vectors to drift. Experimental results on three different corpora demonstrate that our dynamic model infers word embedding trajectories that are more interpretable and lead to higher predictive likelihoods than competing methods that are based on static models trained separately on time slices.",
            "output": [
                "Dynamic Word Embeddings via Skip-Gram Filtering"
            ]
        },
        {
            "id": "task1540-f9b485e6cc014d04ab2297d3ba9ddd78",
            "input": "Recently, we see a new type of interfaces for programmers based on web technology. For example, JSFiddle, IPython Notebook and R-studio. Web technology enables cloud-based solutions, embedding in tutorial web pages, attractive rendering of results, web-scale cooperative development, etc. This article describes SWISH, a web front-end for Prolog. A public website exposes SWIProlog using SWISH, which is used to run small Prolog programs for demonstration, experimentation and education. We connected SWISH to the ClioPatria semantic web toolkit, where it allows for collaborative development of programs and queries related to a dataset as well as performing maintenance tasks on the running server and we embedded SWISH in the Learn Prolog Now! online Prolog book.",
            "output": [
                "SWISH: SWI-Prolog for Sharing"
            ]
        },
        {
            "id": "task1540-f20265a53496488d9c26a68dc09d396e",
            "input": "Automatic translation from natural language descriptions into programs is a long-<lb>standing challenging problem. In this work, we consider a simple yet impor-<lb>tant sub-problem: translation from textual descriptions to If-Then programs. We<lb>devise a novel neural network architecture for this task which we train end-to-<lb>end. Specifically, we introduce Latent Attention, which computes multiplicative<lb>weights for the words in the description in a two-stage process with the goal of<lb>better leveraging the natural language structures that indicate the relevant parts for<lb>predicting program elements. Our architecture reduces the error rate by 28.57%<lb>compared to prior art [3]. We also propose a one-shot learning scenario of If-Then<lb>program synthesis and simulate it with our existing dataset. We demonstrate a<lb>variation on the training procedure for this scenario that outperforms the original<lb>procedure, significantly closing the gap to the model trained with all data.",
            "output": [
                "Latent Attention For If-Then Program Synthesis"
            ]
        },
        {
            "id": "task1540-41c2ff86dab74629859eaf4a6750e0ff",
            "input": "Choquet expected utility (CEU) is one of the most sophisticated decision criteria used in decision theory under uncertainty. It provides a generalisation of expected utility enhancing both descriptive and prescriptive possibilities. In this paper, we investigate the use of CEU for path-planning under uncertainty with a special focus on robust solutions. We first recall the main features of the CEU model and introduce some examples showing its descriptive potential. Then we focus on the search for Choquet-optimal paths in multivalued implicit graphs where costs depend on different scenarios. After discussing complexity issues, we propose two different heuristic search algorithms to solve the problem. Finally, numerical experiments are reported, showing the practical efficiency of the proposed algorithms.",
            "output": [
                "Search for Choquet-optimal paths under uncertainty"
            ]
        },
        {
            "id": "task1540-0c24b86405b84c8d888f0e089f40ab1d",
            "input": "This paper reports the analysis of audio and visual features in predicting the emotion dimensions under the seventh Audio/Visual Emotion Subchallenge (AVEC 2017). For visual features we used the HOG (Histogram of Gradients) features, Fisher encodings of SIFT (Scale-Invariant Feature Transform) features based on Gaussian mixture model (GMM) and some pretrained Convolutional Neural Network layers as features; all these extracted for each video clip. For audio features we used the Bag-of-audio-words (BoAW) representation of the LLDs (low-level descriptors) generated by openXBOW provided by the organisers of the event. Then we trained fully connected neural network regression model on the dataset for all these different modalities. We applied multimodal fusion on the output models to get the Concordance correlation coefficient on Development set as well as Test set. Keywords—HOG, SIFT, GMM, Fisher, Neural Networks.",
            "output": [
                "Continuous Multimodal Emotion Recognition Approach for AVEC 2017"
            ]
        },
        {
            "id": "task1540-1d596f6fb46c416e8d3ae6c98f18790f",
            "input": "Discourse structure is the hidden link between surface features and document-level properties, such as sentiment polarity. We show that the discourse analyses produced by Rhetorical Structure Theory (RST) parsers can improve document-level sentiment analysis, via composition of local information up the discourse tree. First, we show that reweighting discourse units according to their position in a dependency representation of the rhetorical structure can yield substantial improvements on lexicon-based sentiment analysis. Next, we present a recursive neural network over the RST structure, which offers significant improvements over classificationbased methods.",
            "output": [
                "Better Document-level Sentiment Analysis from RST Discourse Parsing∗"
            ]
        },
        {
            "id": "task1540-7dbd57aa4e804a5e9ffb88c88e532d02",
            "input": "Inference in general Ising models is difficult, due to high treewidth making treebased algorithms intractable. Moreover, when interactions are strong, Gibbs sampling may take exponential time to converge to the stationary distribution. We present an algorithm to project Ising model parameters onto a parameter set that is guaranteed to be fast mixing, under several divergences. We find that Gibbs sampling using the projected parameters is more accurate than with the original parameters when interaction strengths are strong and when limited time is available for sampling.",
            "output": [
                "Projecting Ising Model Parameters for Fast Mixing"
            ]
        },
        {
            "id": "task1540-e6a32144ddc841649285479bff86991f",
            "input": "Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.",
            "output": [
                "TREE-STRUCTURED VARIATIONAL AUTOENCODER"
            ]
        },
        {
            "id": "task1540-86a546340b8f4614ab9f60a9b23d8468",
            "input": "Nonnegative matrix factorization (NMF) is the problem of decomposing a given nonnegative n × m matrix M into a product of a nonnegative n × d matrix W and a nonnegative d × m matrix H. Restricted NMF requires in addition that the column spaces of M and W coincide. Finding the minimal inner dimension d is known to be NP-hard, both for NMF and restricted NMF. We show that restricted NMF is closely related to a question about the nature of minimal probabilistic automata, posed by Paz in his seminal 1971 textbook. We use this connection to answer Paz’s question negatively, thus falsifying a positive answer claimed in 1974. Furthermore, we investigate whether a rational matrix M always has a restricted NMF of minimal inner dimension whose factors W and H are also rational. We show that this holds for matrices M of rank at most 3 and we exhibit a rank-4 matrix for which W and H require irrational entries. 1998 ACM Subject Classification F.1.1 Models of Computation, F.2.1 Numerical Algorithms and Problems",
            "output": [
                "On Restricted Nonnegative Matrix Factorization"
            ]
        },
        {
            "id": "task1540-f1a816fc631c4518911b33f5564d97c1",
            "input": "We introduce word vectors for the construction domain. Our vectors were obtained by running word2vec on an 11M-word corpus that we created from scratch by leveraging freely-accessible online sources of construction-related text. We first explore the embedding space and show that our vectors capture meaningful constructionspecific concepts. We then evaluate the performance of our vectors against that of ones trained on a 100B-word corpus (Google News) within the framework of an injury report classification task. Without any parameter tuning, our embeddings give competitive results, and outperform the Google News vectors in many cases. Using a keyword-based compression of the reports also leads to a significant speed-up with only a limited loss in performance. We release our corpus and the data set we created for the classification task as publicly available, in the hope that they will be used by future studies for benchmarking and building on our work.",
            "output": [
                "Word Embeddings for the Construction Domain"
            ]
        },
        {
            "id": "task1540-34823de39b9443d6aa0b1703e9187f13",
            "input": "In this paper, we introduce a notion of backdoors to Reiter’s propositional default logic and study structural properties of it. Also we consider the problems of backdoor detection (parameterised by the solution size) as well as backdoor evaluation (parameterised by the size of the given backdoor), for various kinds of target classes (cnf, horn, krom, monotone, positive-unit). We show that backdoor detection is fixed-parameter tractable for the considered target classes, and backdoor evaluation is either fixed-parameter tractable, in para-∆P2 , or in para-NP, depending on the target class.",
            "output": [
                "Strong Backdoors for Default Logic"
            ]
        },
        {
            "id": "task1540-7c019be59961478092e495a5bc6fe3a2",
            "input": "We consider a broad class of first-order optimization algorithms which are oblivious, in the sense that their step sizes are scheduled regardless of the function under consideration, except for limited sideinformation such as smoothness or strong convexity parameters. With the knowledge of these two parameters, we show that any such algorithm attains an iteration complexity lower bound of Ω( √ L/ǫ) for L-smooth convex functions, and Ω̃( √ L/μ ln(1/ǫ)) for L-smooth μ-strongly convex functions. These lower bounds are stronger than those in the traditional oracle model, as they hold independently of the dimension. To attain these, we abandon the oracle model in favor of a structure-based approach which builds upon a framework recently proposed in [1]. We further show that without knowing the strong convexity parameter, it is impossible to attain an iteration complexity better than Ω̃ ((L/μ) ln(1/ǫ)). This result is then used to formalize an observation regarding L-smooth convex functions, namely, that the iteration complexity of algorithms employing time-invariant step sizes must be at least Ω(L/ǫ).",
            "output": [
                "On the Iteration Complexity of Oblivious First-Order Optimization Algorithms"
            ]
        },
        {
            "id": "task1540-91f918d4a38d49c6b5650175c6a09afa",
            "input": "Open forms of global constraints allow the addition of new variables to an argument during the execution of a constraint program. Such forms are needed for difficult constraint programming problems where problem construction and problem solving are interleaved, and fit naturally within constraint logic programming. However, in general, filtering that is sound for a global constraint can be unsound when the constraint is open. This paper provides a simple characterization, called contractibility, of the constraints where filtering remains sound when the constraint is open. With this characterization we can easily determine whether a constraint has this property or not. In the latter case, we can use it to derive a contractible approximation to the constraint. We demonstrate this work on both hard and soft constraints. In the process, we formulate two general classes of soft constraints. Under consideration in Theory and Practice of Logic Programming (TPLP).",
            "output": [
                "Contractibility for Open Global Constraints"
            ]
        },
        {
            "id": "task1540-aa91485d6b7547b1837676e29243cf6c",
            "input": "This paper describes a class of probabilistic approximation algorithms based on bucket elimination which offer adjustable levels of accuracy and efficiency. We analyze the ap­ proximation for several tasks: finding the most probable explanation, belief updat­ ing and finding the maximum a posteriori hypothesis. We identify regions of com­ pleteness and provide preliminary empiri­ cal evaluation on randomly generated net­",
            "output": [
                "A scheme for approximating probabilistic inference"
            ]
        },
        {
            "id": "task1540-51f3323487bd47f09066e56461fbe998",
            "input": "In this paper, we introduce the task of targeted aspect-based sentiment analysis. The goal is to extract fine-grained information with respect to entities mentioned in user comments. This work extends both aspect-based sentiment analysis that assumes a single entity per document and targeted sentiment analysis that assumes a single sentiment towards a target entity. In particular, we identify the sentiment towards each aspect of one or more entities. As a testbed for this task, we introduce the SentiHood dataset, extracted from a question answering (QA) platform where urban neighbourhoods are discussed by users. In this context units of text often mention several aspects of one or more neighbourhoods. This is the first time that a generic social media platform in this case a QA platform, is used for fine-grained opinion mining. Text coming from QA platforms is far less constrained compared to text from review specific platforms which current datasets are based on. We develop several strong baselines, relying on logistic regression and state-of-the-art recurrent neural networks.",
            "output": [
                "SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods"
            ]
        },
        {
            "id": "task1540-2c8fce12f8c54ba084083937a0e34e35",
            "input": "Trilateration-based localization (TBL) has become a corner stone of modern technology. This study formulates the concern on how wireless sensor networks can take advantage of the computational intelligent techniques using both singleand multi-objective particle swarm optimization (PSO) with an overall aim of concurrently minimizing the required time for localization, minimizing energy consumed during localization, and maximizing the number of nodes fully localized through the adjustment of wireless sensor transmission ranges while using TBL process. A parameter-study of the applied PSO variants is performed, leading to results that show algorithmic improvements of up to 32% in the evaluated objectives.",
            "output": [
                "PARTICLE SWARM OPTIMIZED POWER CONSUMPTION OF TRILATERATION"
            ]
        },
        {
            "id": "task1540-6f6dbb36ed4547af9bcbf185f6c75a87",
            "input": "Clustering is one of the most fundamental and important tasks in data mining. Traditional clustering algorithms, such as K-means, assign every data point to exactly one cluster. However, in real-world datasets, the clusters may overlap with each other. Furthermore, often, there are outliers that should not belong to any cluster. We recently proposed the NEO-K-Means (Non-Exhaustive, Overlapping K-Means) objective as a way to address both issues in an integrated fashion. Optimizing this discrete objective is NPhard, and even though there is a convex relaxation of the objective, straightforward convex optimization approaches are too expensive for large datasets. A practical alternative is to use a low-rank factorization of the solution matrix in the convex formulation. The resulting optimization problem is non-convex, and we can locally optimize the objective function using an augmented Lagrangian method. In this paper, we consider two fast multiplier methods to accelerate the convergence of an augmented Lagrangian scheme: a proximal method of multipliers and an alternating direction method of multipliers (ADMM). For the proximal augmented Lagrangian or proximal method of multipliers, we show a convergence result for the non-convex case with bound-constrained subproblems. These methods are up to 13 times faster—with no change in quality—compared with a standard augmented Lagrangian method on problems with over 10,000 variables and bring runtimes down from over an hour to around 5 minutes.",
            "output": [
                "Fast Multiplier Methods to Optimize Non-exhaustive, Overlapping Clustering"
            ]
        },
        {
            "id": "task1540-21be62e74de54d02b8b04dd5e5339826",
            "input": "Optimal probabilistic approach in reinforcement learning is computationally infeasible. Its simplification consisting in neglecting difference between true environment and its model estimated using limited number of observations causes exploration vs exploitation problem. Uncertainty can be expressed in terms of a probability distribution over the space of environment models, and this uncertainty can be propagated to the action-value function via Bellman iterations, which are computationally insufficiently efficient though. We consider possibility of directly measuring uncertainty of the action-value function, and analyze sufficiency of this facilitated approach.",
            "output": [
                "Direct Uncertainty Estimation in Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-d4084359e2f948d995a3156aff7a7da6",
            "input": "Acoustic word embeddings — fixed-dimensional vector representations of variable-length spoken word segments — have begun to be considered for tasks such as speech recognition and query-by-example search. Such embeddings can be learned discriminatively so that they are similar for speech segments corresponding to the same word, while being dissimilar for segments corresponding to different words. Recent work has found that acoustic word embeddings can outperform dynamic time warping on query-by-example search and related word discrimination tasks. However, the space of embedding models and training approaches is still relatively unexplored. In this paper we present new discriminative embedding models based on recurrent neural networks (RNNs). We consider training losses that have been successful in prior work, in particular a cross entropy loss for word classification and a contrastive loss that explicitly aims to separate same-word and different-word pairs in a ”Siamese network” training setting. We find that both classifier-based and Siamese RNN embeddings improve over previously reported results on a word discrimination task, with Siamese RNNs outperforming classification models. In addition, we present analyses of the learned embeddings and the effects of variables such as dimensionality and network structure.",
            "output": [
                "DISCRIMINATIVE ACOUSTIC WORD EMBEDDINGS: RECURRENT NEURAL NETWORK-BASED APPROACHES"
            ]
        },
        {
            "id": "task1540-c923d781ab294db4a43ed3cdf625a35f",
            "input": "Reinforcement learning algorithms need to deal with the exponential growth of states and actions when exploring optimal control in high-dimensional spaces. This is known as the curse of dimensionality. By projecting the agent’s state onto a low-dimensional manifold, we can represent the state space in a smaller and more efficient representation. By using this representation during learning, the agent can converge to a good policy much faster. We test this approach in the Mario Benchmarking Domain. When using dimensionality reduction in Mario, learning converges much faster to a good policy. But, there is a critical convergence-performance trade-off. By projecting onto a low-dimensional manifold, we are ignoring important data. In this paper, we explore this trade-off of convergence and performance. We find that learning in as few as 4 dimensions (instead of 9), we can improve performance past learning in the full dimensional space at a faster convergence rate.",
            "output": [
                "Using PCA to Efficiently Represent State Spaces"
            ]
        },
        {
            "id": "task1540-f8e662b9582b4be3baf9a20b3b869b12",
            "input": "The approach described here allows to use the fuzzy Object Based Representation of imprecise and uncertain knowledge. This representation has a great practical interest due to the possibility to realize reasoning on classification with a fuzzy semantic network based system. For instance, the distinction between necessary, possible and user classes allows to take into account exceptions that may appear on fuzzy knowledge-base and facilitates integration of user's Objects in the base. This approach describes the theoretical aspects of the architecture of the whole experimental A.I. system we built in order to provide effective on-line assistance to users of new technological systems: the understanding of \"how it works\" and \"how to complete tasks\" from queries in quite natural languages. In our model, procedural semantic networks are used to describe the knowledge of an \"ideal\" expert while fuzzy sets are used both to describe the approximative and uncertain knowledge of novice users in fuzzy semantic networks which intervene to match fuzzy labels of a query with categories from our \"ideal\" expert.",
            "output": [
                "Uncertain and Approximative Knowledge Representation to Reasoning on Classification with a Fuzzy Networks Based System"
            ]
        },
        {
            "id": "task1540-2a3069acfbd6436193a64a9fe8209987",
            "input": "Several data mining problems are characterized by data in high dimensions. One of the popular ways to reduce the dimensionality of the data is to perform feature selection, i.e, select a subset of relevant and non-redundant features. Recently, Quadratic Programming Feature Selection (QPFS) has been proposed which formulates the feature selection problem as a quadratic program. It has been shown to outperform many of the existing feature selection methods for a variety of applications. Though, better than many existing approaches, the running time complexity of QPFS is cubic in the number of features, which can be quite computationally expensive even for moderately sized datasets. In this paper we propose a novel method for feature selection by integrating k-means clustering with QPFS. The basic variant of our approach runs k-means to bring down the number of features which need to be passed on to QPFS. We then enhance this idea, wherein we gradually refine the feature space from a very coarse clustering to a fine-grained one, by interleaving steps of QPFS with k-means clustering. Every step of QPFS helps in identifying the clusters of irrelevant features (which can then be thrown away), whereas every step of k-means further refines the clusters which are potentially relevant. We show that our iterative refinement of clusters is guaranteed to converge. We provide bounds on the number of distance computations involved in the k-means algorithm. Further, each QPFS run is now cubic in number of clusters, which can be much smaller than actual number of features. Experiments on eight publicly available datasets show that our approach gives significant computational gains (both in time and memory), over standard QPFS as well as other state of the art feature selection methods, even while improving the overall accuracy.",
            "output": [
                "Integrating K-means with Quadratic Programming Feature Selection"
            ]
        },
        {
            "id": "task1540-288a12145431418eab0e5320df9e167e",
            "input": "Hierarchical Reinforcement Learning (HRL) exploits temporal abstraction to solve large Markov Decision Processes (MDP) and provide transferable subtask policies. In this paper, we introduce an off-policy HRL algorithm: Hierarchical Q-value Iteration (HQI). We show that it is possible to effectively learn recursive optimal policies for any valid hierarchical decomposition of the original MDP, given a fixed dataset collected from a flat stochastic behavioral policy. We first formally prove the convergence of the algorithm for tabular MDP. Then our experiments on the Taxi domain show that HQI converges faster than a flat Q-value Iteration and enjoys easy state abstraction. Also, we demonstrate that our algorithm is able to learn optimal policies for different hierarchical structures from the same fixed dataset, which enables model comparison without recollecting data.",
            "output": [
                "Algorithms for Batch Hierarchical Reinforcement Learning"
            ]
        },
        {
            "id": "task1540-0142e93ba9014e93ab8a2f2a90a27f86",
            "input": "We introduce a method for learning the dynamics of complex nonlinear systems based on deep generative models over temporal segments of states and actions. Unlike dynamics models that operate over individual discrete timesteps, we learn the distribution over future state trajectories conditioned on past state, past action, and planned future action trajectories, as well as a latent prior over action trajectories. Our approach is based on convolutional autoregressive models and variational autoencoders. It makes stable and accurate predictions over long horizons for complex, stochastic systems, effectively expressing uncertainty and modeling the effects of collisions, sensory noise, and action delays. The learned dynamics model and action prior can be used for end-to-end, fully differentiable trajectory optimization and model-based policy optimization, which we use to evaluate the performance and sample-efficiency of our method.",
            "output": [
                "Prediction and Control with Temporal Segment Models"
            ]
        },
        {
            "id": "task1540-1a8d741cbdb543339edc01bcf991aba8",
            "input": "Planning is a notoriously difficult computational problem of high worst-case complexity. Researchers have been investing significant efforts to develop heuristics or restrictions to make planning practically feasible. Case-based planning is a heuristic approach where one tries to reuse previous experience when solving similar problems in order to avoid some of the planning effort. Plan reuse may offer an interesting alternative to plan generation in some settings. We provide theoretical results that identify situations in which plan reuse is provably tractable. We perform our analysis in the framework of parameterized complexity, which supports a rigorous worst-case complexity analysis that takes structural properties of the input into account in terms of parameters. A central notion of parameterized complexity is fixed-parameter tractability which extends the classical notion of polynomial-time tractability by utilizing the effect of structural properties of the problem input. We draw a detailed map of the parameterized complexity landscape of several variants of problems that arise in the context of case-based planning. In particular, we consider the problem of reusing an existing plan, imposing various restrictions in terms of parameters, such as the number of steps that can be added to the existing plan to turn it into a solution of the planning instance at hand.",
            "output": [
                "Parameterized Complexity Results for Plan Reuse"
            ]
        },
        {
            "id": "task1540-3b47735c3c0641e8985ba57103c4b9d6",
            "input": "Numerous machine learning algorithms contain pairwise statistical problems at their core— that is, tasks that require computations over all pairs of input points if implemented naively. Often, tree structures are used to solve these problems efficiently. Dual-tree algorithms can efficiently solve or approximate many of these problems. Using cover trees, rigorous worstcase runtime guarantees have been proven for some of these algorithms. In this paper, we present a problem-independent runtime guarantee for any dual-tree algorithm using the cover tree, separating out the problem-dependent and the problem-independent elements. This allows us to just plug in bounds for the problem-dependent elements to get runtime guarantees for dual-tree algorithms for any pairwise statistical problem without re-deriving the entire proof. We demonstrate this plug-and-play procedure for nearest-neighbor search and approximate kernel density estimation to get improved runtime guarantees. Under mild assumptions, we also present the first linear runtime guarantee for dual-tree based range search.",
            "output": [
                "Plug-and-play dual-tree algorithm runtime analysis"
            ]
        },
        {
            "id": "task1540-7a76c3ad1ae14cd7aab43ef0cbd4f298",
            "input": "We propose an approximation method for thresholding of singular values using Chebyshev polynomial approximation (CPA). Many signal processing problems require iterative application of singular value decomposition (SVD) for minimizing the rank of a given data matrix with other cost functions and/or constraints, which is called matrix rank minimization. In matrix rank minimization, singular values of a matrix are shrunk by hard-thresholding, softthresholding, or weighted soft-thresholding. However, the computational cost of SVD is generally too expensive to handle high dimensional signals such as images; hence, in this case, matrix rank minimization requires enormous computation time. In this paper, we leverage CPA to (approximately) manipulate singular values without computing singular values and vectors. The thresholding of singular values is expressed by a multiplication of certain matrices, which is derived from a characteristic of CPA. The multiplication is also efficiently computed using the sparsity of signals. As a result, the computational cost is significantly reduced. Experimental results suggest the effectiveness of our method through several image processing applications based on matrix rank minimization with nuclear norm relaxation in terms of computation time and approximation precision.",
            "output": [
                "Fast Singular Value Shrinkage with Chebyshev Polynomial Approximation Based on Signal Sparsity"
            ]
        },
        {
            "id": "task1540-839e205a1f6243c985e85d657bc3f075",
            "input": "Learning to localize objects with minimal supervision is an important problem in computer vision, since large fully annotated datasets are extremely costly to obtain. In this paper, we propose a new method that achieves this goal with only image-level labels of whether the objects are present or not. Our approach combines a discriminative submodular cover problem for automatically discovering a set of positive object windows with a smoothed latent SVM formulation. The latter allows us to leverage efficient quasiNewton optimization techniques. Our experiments demonstrate that the proposed approach provides a 50% relative improvement in mean average precision over the current state-of-the-art on PASCAL VOC 2007 detection.",
            "output": [
                "On learning to localize objects with minimal supervision"
            ]
        },
        {
            "id": "task1540-76fffbaec6f84b348e194759911da5f8",
            "input": "Experimenting with a new dataset of 1.6M user comments from a Greek news portal and existing datasets of English Wikipedia comments, we show that an RNN outperforms the previous state of the art in moderation. A deep, classification-specific attention mechanism improves further the overall performance of the RNN. We also compare against a CNN and a word-list baseline, considering both fully automatic and semi-automatic moderation.",
            "output": [
                "Deep Learning for User Comment Moderation"
            ]
        },
        {
            "id": "task1540-82d257b3f09c46059757522b0277400f",
            "input": "We investigate adversarial attacks for autoencoders. We propose a procedure that distorts the input image to mislead the autoencoder in reconstructing a completely different target image. We attack the internal latent representations, attempting to make the adversarial input produce an internal representation as similar as possible as the target’s. We find that autoencoders are much more robust to the attack than classifiers: while some examples have tolerably small input distortion, and reasonable similarity to the target image, there is a quasi-linear trade-off between those aims. We report results on MNIST and SVHN datasets, and also test regular deterministic autoencoders, reaching similar conclusions in all cases. Finally, we show that the usual adversarial attack for classifiers, while being much easier, also presents a direct proportion between distortion on the input, and misdirection on the output. That proportionality however is hidden by the normalization of the output, which maps a linear layer into non-linear probabilities.",
            "output": [
                "Adversarial Images for Variational Autoencoders"
            ]
        },
        {
            "id": "task1540-bf4f46519f254b1c9c2fd1df37bb3eda",
            "input": "In this paper, we present a heuristic operator which aims at simultaneously optimizing the orientations of all the edges in an interme­ diate Bayesian network structure during the search process. This is done by alternating between the space of directed acyclic graphs (DAGs) and the space of skeletons. The found orientations of the edges are based on a scoring function rather than on induced con­ ditional independences. This operator can be used as an extension to commonly employed search strategies. It is evaluated in experi­ ments with artificial and real-world data.",
            "output": [
                "On the Use of Skeletons when Learning in Bayesian Networks"
            ]
        },
        {
            "id": "task1540-a445440089c447fa97388f992d327fd6",
            "input": "The goal of minimizing misclassification error on a training set is often just one of several real-world goals that might be defined on different datasets. For example, one may require a classifier to also make positive predictions at some specified rate for some subpopulation (fairness), or to achieve a specified empirical recall. Other real-world goals include reducing churn with respect to a previously deployed model, or stabilizing online training. In this paper we propose handling multiple goals on multiple datasets by training with dataset constraints, using the ramp penalty to accurately quantify costs, and present an efficient algorithm to approximately optimize the resulting non-convex constrained optimization problem. Experiments on both benchmark and real-world industry datasets demonstrate the effectiveness of our approach.",
            "output": [
                "Satisfying Real-world Goals with Dataset Constraints"
            ]
        },
        {
            "id": "task1540-d66eb0d4e3cf4b57af13e1cc41306967",
            "input": "It is well-known that malware constantly evolves so as to evade detection and this causes the entire malware population to be non-stationary. Contrary to this fact, prior works on machine learning based Android malware detection have assumed that the distribution of the observed malware characteristics (i.e., features) do not change over time. In this work, we address the problem of malware population drift and propose a novel online machine learning based framework, named DroidOL to handle it and effectively detect malware. In order to perform accurate detection, the security-sensitive behaviors are captured from apps in the form of inter-procedural control-flow sub-graph features using a state-of-the-art graph kernel. In order to perform scalable detection and to adapt to the drift and evolution in malware population, an online passiveaggressive classifier is used. In a large-scale comparative analysis with more than 87,000 apps, DroidOL achieves 84.29% accuracy outperforming two state-of-the-art malware techniques by more than 20% in their typical batch learning setting and more than 3% when they are continuously re-trained. Our experimental findings strongly indicate that online learning based approaches are highly suitable for real-world malware detection. keywords — Online Learning, Graph Kernels, Malware Detection",
            "output": [
                "Adaptive and Scalable Android Malware Detection through Online Learning"
            ]
        }
    ],
    "Instance License": [
        "CC BY 4.0"
    ]
}