{
    "Contributors": [
        "Mihir Parmar",
        "Pegah Alipoormolabashi"
    ],
    "Source": [
        "Paper Reviews Dataset (dataset link- https://archive.ics.uci.edu/ml/datasets/Paper+Reviews)",
        "PeerRead (dataset link - https://github.com/allenai/PeerRead)"
    ],
    "Categories": [
        "Identification -> Language Identification -> Verification",
        "Classification -> Verification"
    ],
    "Input_language": [
        "Spanish",
        "English"
    ],
    "Output_language": [
        "English"
    ],
    "Instruction_language": [
        "English"
    ],
    "Definition": "In this task, you are given a paper review. Based on the review, your job is to identify language and generate \"en\" if the review is in English or generate \"es\" if the review is in Spanish. Note that URLs in the text have been replaced with [Link].",
    "Domains": [
        "Conference"
    ],
    "Positive Examples": [
        {
            "input": "Este artículo no es un artículo de investigación, ya que sólo muestra cómo programar un robot mediante la herramienta de lógica difusa. Este tema ya ha sido propuesto como solución en navegación de robots.",
            "output": "es",
            "explanation": "This review is written in spanish. Hence, the label is 'es'."
        },
        {
            "input": "I don't think the work reported in this paper is suitable for the SCCC conference. The author should consider reporting this experience on a conference more focused on practice in computer engineering than in CS reserarch. The material presented in the paper could be of interest for practicioners working with Oracle, namely a particular product.",
            "output": "en",
            "explanation": "This review is written in english. Hence, the label is 'en'."
        }
    ],
    "Negative Examples": [
        {
            "input": "Este artículo no es un artículo de investigación, ya que sólo muestra cómo programar un robot mediante la herramienta de lógica difusa. Este tema ya ha sido propuesto como solución en navegación de robots.",
            "output": "en",
            "explanation": "This review is written in spanish. But the label is 'en' which is wrong."
        },
        {
            "input": "I don't think the work reported in this paper is suitable for the SCCC conference. The author should consider reporting this experience on a conference more focused on practice in computer engineering than in CS reserarch. The material presented in the paper could be of interest for practicioners working with Oracle, namely a particular product.",
            "output": "es",
            "explanation": "This review is written in english. But the label is 'es' which is wrong."
        }
    ],
    "Instances": [
        {
            "input": "Buena práctica para mejor la calidad en la ingeniería de requisitos  - En el resumen no debería haber teoría - Debería haber un caso de estudio para ver mejor la aplicación de la metodología",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper discusses Hyperband, an extension of successive halving by Jamieson & Talwalkar (AISTATS 2016). Successive halving is a very nice algorithm that starts evaluating many configurations and repeatedly cuts off the current worst half to explore many configuration for a limited budget.  Having read the paper for the question period and just rereading it again, I am now not entirely sure what its contribution is meant to be: the only improvement of Hyperband vs. successive halving is in the theoretical worst case bounds (not more than 5x worse than random search), but you can (a) trivially obtain that bound by using a fifth of your time for running random configurations to completion and (b) the theoretical analysis to show this is said to be beyond the scope of the paper. That makes me wonder whether the theoretical results are the contribution of this paper, or whether they are the subject of a different paper and the current paper is mostly an empirical study of the method? I hope to get a response by the authors and see this made clearer in an updated version of the paper.  In terms of experiments, the paper fails to show a case where Hyperband actually performs better than the authors' previous algorithm successive halving with its most agressive setting of bracket b=4. Literally, in every figure, bracket b=4 is at least as good (and sometimes substantially better) than Hyperband. That makes me think that in practice I would prefer successive halving with b=4 over Hyperband. (And if I really want Hyperband's guarantee of not being more than 5x worse than random search I can run random search on a fifth of my machines.)  The experiments also compare to some Bayesian optimization methods, but not to the most relevant very closely related Multi-Task Bayesian Optimization methods that have been dominating effective methods for deep learning in that area in the last 3 years: \"Multi-Task Bayesian Optimization\" by Swersky, Snoek, and Adams (2013) already showed 5x speedups for deep learning by starting with smaller datasets, and there have been several follow-up papers showing even larger speedups.   Given that this prominent work on multitask Bayesian optimization exists, I also think the introduction, which sells Hyperband as a very new approach to hyperparameter optimization is misleading. I would've much preferred a more down-to-earth pitch that says \"configuration evaluation\" has been becoming a very important feature in hyperparameter optimization, including Bayesian optimization, that sometimes yields very large speedups (this can be quantified by examples from existing papers) and this paper adds some much-needed theoretical understanding to this and demonstrates how important configuration evaluation is even in the simplest case of being used with random search. I think this could be done easily and locally by adding a paragraph to the intro.  As another point regarding novelty, I think the authors should make clear that approaches for adaptively deciding how many resources to use for which evaluation have been studied for (at least) 23 years in the ML community -- see Maron & Moore, NIPS 1993: \"Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation\" (",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta el diseño de un prototipo que implementa un sistema para la adquisición de datos mediante dispositivos móviles inalámbricos, aplicado a la minería, específicamente en la monitorización de material particulado. Resulta interesante la aplicación de la tecnología móvil a un problema concreto de la industria minera chilena, además el artículo describe de forma muy clara la problemática y el prototipo propuesto.  El artículo resulta novedoso ya que se plantea el uso de la computación (procesamiento de de datos) y de las tecnologías de dispositivos móviles aplicadas a un problema concreto de la industria minera chilena.  El problema, la tecnología presentada (BUG) y el prototipo propuesto están descritos de forma clara.  Resulta relevante la aplicación  de tecnologías computacionales móviles actuales en sectores industriales importantes del país.  El título principal y el resumen deben estar escritos en español y en inglés (sólo vienen en español). Además, el artículo presenta una lista de 29 referencias, pero sólo hace referencia  a una (la primera de la lista). Incluso aparece en las Referencias PCFactory, y no queda muy  claro el porqué.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper introduces a new approach to semantic parsing in which the model is equipped with a neural sequence to sequence (seq2seq) model (referred to as the “programmer”) which encodes a natural language question and produces a program. The programmer is also equipped with a ‘key variable’ memory component which stores (a) entities in the questions (b) values of intermediate variables formed during execution of intermediate programs. These variables are referred to further build the program.                    The model is also equipped with certain discrete operations (such as argmax or 'hop to next edges in a KB'). A separate component (\"interpreter/computer\") executes these operations and stores intermediate values (as explained before). Since the ‘programmer' is inherently a seq2seq model, the \"interpreter/computer” also acts as a syntax/type checker only allowing the decoder to generate valid tokens. For example, the second argument to the “hop” operation has to be a KB predicate. Finally the model is trained with weak supervision and directly optimizes the metric which is used to evaluate the performance (F score). Because of the discrete operations and the non differentiable reward functions, the model is trained with policy gradients (REINFORCE). Since gradients obtained through REINFORCE have high variance, it is common to first pretrain the model with a max-likelihood objective or find some good sequences of actions trained through some auxiliary objective. This paper takes a latter approach in which it finds good sequences via an iterative maximum likelihood approach. The results and discussion sections are presented in a very nice way and the model achieves SOTA results on the WebQuestions dataset when compared to other weakly supervised model.  The paper is written clearly and is very easy to follow.  This paper presents a new and exciting direction and there is scope for a lot of future research in this direction. I would definitely love to see this presented in the conference.  Questions for the authors (important ones first)  1. Another alternative way of training the model would be to bootstrap the parameters (\\theta) from the iterative ML method instead of adding pseudo gold programs in the beam (Line 510 would be deleted). Did you try that and if so why do you think it didn’t work? 2. What was the baseline model in REINFORCE. Did you have a separate network which predicts the value function. This must be discussed in the paper in detail. 3. Were there programs which required multiple hop operations? Or were they limited to single hops. If there were, can you provide an example? (I will understand if you are bound by word limit of the response) 4. Can you give an example where the filter operation would be used? 5. I did not follow the motivation behind replacing the entities in the question with special ENT symbol  Minor comments: Line 161 describe -> describing Line 318 decoder reads ‘)’ -> decoder generates ‘)'",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes a method for generating datasets of pictures from simple building blocks, as well as corresponding logical forms and language descriptions. The goal seems to be to have a method where the complexity of pictures and corresponding desciptions can be controlled and parametrized.    - The biggest downside seems to be that the maximally achievable complexity is very limited, and way below the complexity typically faced with image-captioning and other multimodal tasks.   - The relative simplicity is also a big difference to the referenced bAbI tasks (which cover the whole qualitative spectrum of easy-to-hard reasoning tasks), whereas in the proposed method a (qualitatively) easy image reconition task can only be quantitatively made harder, by increasing the number of objects, noise etc in unnatural ways.  - This is also reflected in the experimental section. Whenever the experimental performance results are not satisfying, these cases seem like basic over/underfitting issues that may easily be tackled by restricting/extending the capacity of the networks or using more data. It is hard for me to spot any other qualitative insight.  - In the introduction it is stated that the \"goal is not too achieve optimal performance\" but to find out whether \"architectures are able to successfully demonstrate the desired understanding\" - there is a fundamental contradiction here, in that the proposed task on the one side is meant to provide a measure as to whether architectures demontrate \"understanding\", on the other hand the score is not supposed to be taken as meaningful/seriously.  General comments: The general approach should be made more tangible earlier (i.e. in the introction rather than in section 3)",
            "output": [
                "en"
            ]
        },
        {
            "input": "Los autores proponen el análisis de los datos a través de la metodología CRISP-DM, pero en el desarrollo no se utiliza el mismo.  Los autores hacen uso de la herramienta WEKA y de los algoritmo que tiene implementados dicha herramienta. Tal vez fuera mejor pensar en un algoritmo propio para este tipo de datos a analizar, o alguna mecanismo donde el experto no tenga que marcar las formas de los remolinos en las imágenes a procesar.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este trabajo se presenta como el desarrollo de un prototipo que incluye a las redes auto-organizativas como técnica secundaria de minería de datos aplicada sobre un árbol de decisión. Realiza una comparación de este prototipo con el software WEKA mediante encuestas a un grupo de personas que tienen conocimientos en minería de datos.  En las pruebas realizadas no indica si WEKA tiene el mismo tipo de herramienta (SOM u otra para aumentar la comprensión del modelo). En los análisis de resultados, sólo se muestran los resultados de la evaluación del prototipo y no de WEKA.  En la página 3, segunda columna repite la oración: ‘la visualización es una herramienta… soporta la interacción... involucrados en el proceso de MD’. (párrafos 2 y 3 de la segunda columna).  El párrafo  penúltimo de la página 4 no se entiende.  Las figuras 2 y 3 no se entienden debido a lo pequeño de la letra.  En la página 8, letra d) debería sacer Figura 2.  El artículo no está en el formato especificado, y tiene más de 8 páginas (específicamente 12).  Tiene algunas faltas de ortografía, por ejemplo, dice éste, en donde debería decir este. La referencia [18], no indica si es libro, Journal, Conferencia, etc.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper introduces a simple and effective method for morphological paradigm completion in low-resource settings. The method uses a character-based seq2seq model trained on a mix of examples in two languages: a resource-poor language and a closely-related resource-rich language; each training example is annotated with a paradigm properties and a language ID. Thus, the model enables transfer learning across languages when the two languages share common characters and common paradigms. While the proposed multi-lingual solution is not novel (similar architectures have been explored in syntax, language modeling, and MT), the novelty of this paper is to apply the approach to morphology. Experimental results show substantial improvements over monolingual baselines, and include a very thorough analysis of the impact of language similarities on the quality of results. The paper is interesting, very clearly written, I think it’ll be a nice contribution to the conference program.   Detailed comments:   — My main question is why the proposed general multilingual methodology was limited to pairs of languages, rather than to sets of similar languages? For example, all Romance languages could be included in the training to improve Spanish paradigm completion, and all Slavic languages with Cyrillic script could be mixed to improve Ukrainian. It would be interesting to see the extension of the models from bi-lingual to multilingual settings.   — I think Arabic is not a fair (and fairly meaningless) baseline, given how different is its script and morphology from the target languages. A more interesting baseline would be, e.g., a language with a partially shared alphabet but a different typology. For example, a Slavic language with Latin script could be used as a baseline language for Romance languages. If Arabic is excluded, and if we consider a most distant language in the same the same family as a baseline, experimental results are still strong.   — A half-page discussion of contribution of Arabic as a regularizer also adds little to the paper; I’d just remove Arabic from all the experiments and would add a regularizer (which, according to footnote 5, works even better than adding Arabic as a transfer language).                — Related work is missing a line of work on “language-universal” RNN models that use basically the same approach: they learn shared parameters for inputs in multiple languages, and add a language tag to the input to mediate between languages. Related studies include a multilingual parser (Ammar et al., 2016), language models (Tsvetkov et al., 2016), and machine translation (Johnson et al., 2016 )  Minor:  — I don’t think that the claim is correct in line 144 that POS tags are easy to transfer across languages. Transfer of POS annotations is also a challenging task.    References:   Waleed              Ammar, George Mulcaire, Miguel Ballesteros, Chris Dyer, and Noah A. Smith. \"Many languages, one parser.” TACL 2016.   Yulia Tsvetkov, Sunayana Sitaram, Manaal Faruqui, Guillaume Lample, Patrick Littell, David Mortensen, Alan W. Black, Lori Levin, and Chris Dyer. \"Polyglot neural language models: A case study in cross-lingual phonetic representation learning.” NAACL 2016.  Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat et al. \"Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation.\" arXiv preprint arXiv:1611.04558 2016.  -- Response to author response:   Thanks for your response & I'm looking forward to reading the final version!",
            "output": [
                "en"
            ]
        },
        {
            "input": "1. El artículo está muy mal escrito. Por ejemplo, cómo es posible que la introducción indique lo siguiente. \"Dado que las Pymes generan aproximadamente el 80% del empleo en Chile y dado que la Carga tributaria concentra tb. Aproximadamente un 50% del\" ¿Por qué usa abreviaciones en la introducción?  2. La propuesta no tiene ningún desarrollo que muestre resultados claros.  3. ¿Por qué indica referencias y bibliografía?, ¿cuál es la diferencia? Las siguientes referencias bibliográficas son \"ingenuas\"   \"De acuerdo a datos históricos, la facturación mensual del producto es de 80% de gas de 15 kilos, 15 % de 5 kg. y 5% de gas de 45 kg.\"  \"Proveedor contratista de empresa Prime del sector industrial, él, más 12 personas\"  Sinceramente es mejor escribir de nuevo el artículo y mejorar todo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This work showed that word representation learning can benefit from sememes when used in an appropriate attention scheme. Authors hypothesized that sememes can act as an essential regularizer for WRL and WSI tasks and proposed SE-WL model which detects word senses and learn representations simultaneously. Though experimental results indicate that WRL benefits, exact gains for WSI are unclear since a qualitative case study of a couple of examples has only been done. Overall, paper is well-written and well-structured.  In the last paragraph of introduction section, authors tried to tell three contributions of this work. (1) and (2) are more of novelties of the work rather than contributions. I see the main contribution of the work to be the results which show that we can learn better word representations (unsure about WSI) by modeling sememe information than other competitive baselines. (3) is neither a contribution nor a novelty.  The three strategies tried for SE-WRL modeling makes sense and can be intuitively ranked in terms of how well they will work. Authors did a good job explaining that and experimental results supported the intuition but the reviewer also sees MST as a fourth strategy rather than a baseline inspired by Chen et al. 2014 (many WSI systems assume one sense per word given a context). MST many times performed better than SSA and SAC. Unless authors missed to clarify otherwise, MST seems to be exactly like SAT with a difference that target word is represented by the most probable sense rather than taking an attention weighted average over all its senses. MST is still an attention based scheme where sense with maximum attention weight is chosen though it has not been clearly mentioned if target word is represented by chosen sense embedding or some function of it.  Authors did not explain the selection of datasets for training and evaluation tasks. Reference page to Sogou-T text corpus did not help as reviewer does not know Chinese language. It was unclear which exact dataset was used as there are several datasets mentioned on that page. Why two word similarity datasets were used and how they are different  (like does one has more rare words than another) since different models performed differently on these datasets. The choice of these datasets did not allow evaluating against results of other works which makes the reviewer wonder about next question.  Are proposed SAT model results state of the art for Chinese word similarity?  E.g. Schnabel et al. (2015) report a score of 0.640 on WordSim-353 data by using CBOW word embeddings.  Reviewer needs clarification on some model parameters like vocabulary sizes for words (Does Sogou-T contains 2.7 billion unique words) and word senses (how many word types from HowNet). Because of the notation used it is not clear if embeddings for senses and sememes for different words were shared. Reviewer hopes that is the case but then why 200 dimensional embeddings were used for only 1889 sememes. It would be better if complexity of model parameters can also be discussed.  May be due to lack of space but experiment results discussion lack insight into observations other than SAT performing the best. Also, authors claimed that words with lower frequency were learned better with sememes without evaluating on a rare words dataset.  I have read author's response.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- General Discussion:  This paper extends Zhou and Xu's ACL 2015 approach to semantic role labeling based on deep BiLSTMs. In addition to applying recent best practice techniques, leading to further quantitative improvements, the authors provide an insightful qualitative analysis of their results. The paper is well written and has a clear structure. The authors provide a comprehensive overview of related work and compare results to a representative set of other SRL models that hace been applied on the same data sets.  I found the paper to be interesting and convincing. It is a welcome research contribution that not only shows that NNs work well, but also analyzes merits and shortcomings of an end-to-end learning approach.  - Strengths:  Strong model, insightful discussion/error analysis.  - Weaknesses:  Little to no insights regarding the SRL task itself.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper comes up with a novel approach to searching the space of architectures for deep neural networks using reinforcement learning. The idea is straightforward and sensible: use a reinforcement learning strategy to iteratively grow a deep net graph (the space of actions is e.g. adding different layer types) via Q-learning. The reviewers agree that the idea is interesting, novel and promising but are underwhelmed with the execution of the experiments and the empirical results.     The idea behind the paper and the formulation of the problem are quite similar to a concurrent submission (",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper introduces a variant of the semi-supervised variational auto-encoder (VAE) framework. The authors present a way of introducing structure (observed variables) inside the recognition network.  I find that the presentation of the inference with auxiliary variables could be avoided, as it actually makes the presentation unnecessarily complicated. Specifically, the expressions with auxiliary variables are helpful for devising a unified implementation, but modeling-wise one can get the same model without these auxiliary variables and recover a minimal extension of VAE where part of the generating space is actually observed. The observed variables mean that the posterior needs to also condition on those, so as to incorporate the information they convey. The way this is done in this paper is actually not very different from Kingma et al. 2014, and I am surprised that the experiments show a large deviation in these two methods' results. Given the similarity of the models, it'd be useful if the authors could give a possible explanation on the superiority of their method compared to Kingma et al. 2014. By the way, I was wondering if the experimental setup is the same as in Kingma et al. 2014 for the results of Fig. 5 (bottom) - the authors mention that they use CNNs for feature extraction but from the paper it's not clear if Kingma et al. do the same.   On a related note, I was wondering the same for the comparison with Jampani et al. 2015. In particular, is that model also using the same rate of supervision for a fair comparison?  The experiment in section 4.3 is interesting and demonstrates a useful property of the approach.  The discussion of the supervision rate (and the pre-review answer) is helpful in giving some insight about what is a successful training protocol to use in semi-supervised learning.  Overall, the paper is interesting but the title and introduction made me expect something more from it. From the title I expected a method for interpreting general deep generative models, instead the described approach was about a semi-supervised variant of VAE - naturally including labelled examples disentangles the latent space, but this is a general property of any semi-supervised probabilistic model and not unique to the approach described here. Moreover, from the intro I expected to see a more general approximation scheme for the variational posterior (similar to Ranganath et al. 2015  which trully allows very flexible distributions), however this is not the case here.  Given the above, the contributions of this paper are in defining a slight variant of the semi-supervised VAE, and (perhaps more importantly) formulating it in a way that is amendable to easier automation in terms of software. But methodologically there is not much contribution to the current literature. The authors mention that they plan to extend the framework in the probabilistic programming setting. It seems indeed that this would be a very promising and useful extension.   Minor note: three of Kingma's papers are all cited in the main text as Kingma et al. 2014, causing confusion. I suggest using Kingma et al. 2014a etc.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper addresses the practical problem of generating rare or unseen words in the context of language modeling. Since language follows a Zipf’s law, most approaches limit the vocabulary (because of computation reasons) and hence rare words are often mapped to a UNK token. Rare words are especially important in context of applications such as question answering. MT etc. This paper proposes a language modeling technique which incorporates facts from knowledge bases (KBs) and thus has the ability to generate (potentially unseen) words from KBs. This paper also releases a dataset by aligning words with Freebase facts and corresponding Wikipedia descriptions.  The model first selects a KB fact based on the previously generated words and facts. Based on the selected fact, it then predicts whether to generate a word based on the vocabulary or to output a symbolic word from the KB. For the latter, the model is trained to predict the position of the word from the fact description.  Overall the paper could use some rewriting especially the notations in section 3. The experiments are well executed and they definitely get good results. The heat maps at the end are very insightful.   Comments  This contributions of this paper would be much stronger if it showed improvements in a practical applications such as Question Answering (although the paper clearly mentions that this technique could be applied to improve QA) In section 3, it is unclear why the authors refer the entity as a ‘topic'. This makes the text a little confusing since a topic can also be associated with something abstract, but in this case the topic is always a freebase entity.  Is it really necessary to predict a fact at every step before generating a word. In other words, how many distinct facts on average does the model choose to generate a sentence. Intuitively a natural language sentence would be describe few facts about an entity. If the fact generation step could be avoided (by adding a latent variable which decides if the fact should be generated or not), the model will also be faster. In equation 2, the model has to make a hard decision to choose the fact. For this to be end to end trained, every word needs to be annotated with a corresponding fact which might not be always a realistic scenario. For e.g., in domains such as social media text. Learning position embeddings for copying knowledge words seems a little counter-intuitive. Does the sequence of knowledge words follow any particular structure like word O_2 is always the last name (e.g. Obama). It would also be nice to compare to char-level LM's which inherently solves the unknown token problem.",
            "output": [
                "en"
            ]
        },
        {
            "input": "In this paper, the authors propose a new method to learn hierarchical representations of sentences, based on reinforcement learning. They propose to learn a neural shift-reduce parser, such that the induced tree structures lead to good performance on a downstream task. They use reinforcement learning (more specifically, the policy gradient method REINFORCE) to learn their model. The reward of the algorithm is the evaluation metric of the downstream task. The authors compare two settings, (1) no structure information is given (hence, the only supervision comes from the downstream task) and (2) actions from an external parser is used as supervision to train the policy network, in addition to the supervision from the downstream task. The proposed approach is evaluated on four tasks: sentiment analysis, semantic relatedness, textual entailment and sentence generation.  I like the idea of learning tree representations of text which are useful for a downstream task. The paper is clear and well written. However, I am not convinced by the experimental results presented in the paper. Indeed, on most tasks, the proposed model is far from state-of-the-art models:  - sentiment analysis, 86.5 v.s. 89.7 (accuracy);  - semantic relatedness, 0.32 v.s. 0.25 (MSE);  - textual entailment, 80.5 v.s. 84.6 (accuracy). From the results presented in the paper, it is hard to know if these results are due to the model, or because of the reinforcement learning algorithm.  PROS:  - interesting idea: learning structures of sentences adapted for a downstream task.  - well written paper. CONS:  - weak experimental results (do not really support the claim of the authors).  Minor comments: In the second paragraph of the introduction, one might argue that bag-of-words is also a predominant approach to represent sentences. Paragraph titles (e.g. in section 3.2) should have a period at the end.  ---------------------------------------------------------------------------------------------------------------------- UPDATE  I am still not convinced by the results presented in the paper, and in particular by the fact that one must combine the words in a different way than left-to-right to obtain state of the art results. However, I do agree that this is an interesting research direction, and that the results presented in the paper are promising. I am thus updating my score from 5 to 6.",
            "output": [
                "en"
            ]
        },
        {
            "input": "el trabajo presenta un estado del arte respecto de las redes de sensores sub acuáticas UWSN y  la robótica móvil autónoma submarina. En particular describe la problemática presentada, entregando topologías, estrategias y hardware para la comunicación.  El texto es muy descriptivo, poco analítico y crítico, generando escaso aporte y valor, más allá de una recopilación bibliográfica.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper is technically sound. It highlights well the strengths and weaknesses of the proposed simplified model.  In terms of impact, its novelty is limited, in the sense that the authors did seemingly the right thing and obtained the expected outcomes. The idea of modeling deep learning computation is not in itself particularly novel. As a companion paper to an open source release of the model, it would meet my bar of acceptance in the same vein as a paper describing a novel dataset, which might not provide groundbreaking insights, yet be generally useful to the community.  In the absence of released code, even if the authors promise to release it soon, I am more ambivalent, since that's where all the value lies. It would also be a different story if the authors had been able to use this framework to make novel architectural decisions that improved training scalability in some way, and incorporated such new insights in the paper.  UPDATED: code is now available. Revised review accordingly.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper is clearly written, and the claims are well-supported.  The Related Work in particular is very thorough, and clearly establishes where the proposed work fits in the field.  I had two main questions about the method: (1) phrases are mentioned in section 3.1, but only word representations are discussed.  How are phrase representations derived? (2) There is no explicit connection between M^+ and M^- in the model, but they are indirectly connected through the tanh scoring function.  How do the learned matrices compare to one another (e.g., is M^- like -1*M^+?)?  Furthermore, what would be the benefits/drawbacks of linking the two together directly, by enforcing some measure of dissimilarity?  Additionally, statistical significance of the observed improvements would be valuable.  Typographical comments: - Line 220: \"word/phase pair\" should be \"word/phrase pair\" - Line 245: I propose an alternate wording: instead of \"entities are translated to,\" say \"entities are mapped to\".  At first, I read that as a translation operation in the vector space, which I think isn't exactly what's being described. - Line 587: \"slightly improvement in F-measure\" should be \"slight improvement in F-measure\" - Line 636: extraneous commas in citation - Line 646: \"The most case\" should be \"The most likely case\" (I'm guessing) - Line 727: extraneous period and comma in citation",
            "output": [
                "en"
            ]
        },
        {
            "input": "Novedosa propuesta, muy valorable la vinculación de personas del ámbito empresarial lo que permite que la teoría y propuestas para ingeniería de software puedan ser probadas en ambientes reales. Bien estructurado y muy bien redactado.  Solo sugiero esquematizar las actividadesde aplicación de entrenamiento White Belt IR - SixSigma y revisar pequeños detalles de redacción.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El articulo presenta un análisis sobre las defunciones fetales en Mexico a través de un proceso de Inteligencia de Negocios (ETL - Datawarehouse - OLAP - KPI's) bien realizado. La debilidad se encuentra en la motivación del estudio, ya que no queda claro cómo surge y que induce a realizar el estudio, surge la inquietud de por qué en la UNAP se realiza un estudio que tiene que ver con muertes fetales en Mexico, ¿tendrán las conclusiones del estudio alguna repercusión en las políticas públicas de este país? o ¿es sólo un trabajo basado en datos abiertos?. Hubiera sido adecuado despejar estas dudas desde un comienzo de forma de valorar adecuadamente este trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Descripción de los componentes de la plataforma de cloud computing Windows Azure. - Sucinta descripción del concepto de cloud computing.   - Falta discusión respecto de las posibles desventajas o escenarios adversos de una \"implementación en la nube\" - El resumen habla de \"...detallar la experiencia en la construcción de una plataforma para construir cloud públicas y abiertas\", pero sólo se limita a la descripción de la plataforma Azure. - Poquísima profundidad en la descripción de la aplicación que se montó en la plataforma cloud. Dado el título y resumen, se espera más análisis en términos de las ventajas y desventajas del desarrollo usando esta plataforma. - Problemas de redacción al interior del mismo trabajo. - Ciertas secciones parecen más un \"brochure\" comercial que un trabajo académico.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo es una excelente guía para implantar un DATA CENTER, muy bien escrito, en donde utiliza bibliografía y conocimientos de manuales y libros, faltando literatura especializada. Es un trabajo de investigación aplicada,  original y  una aplicación muy interesante en una empresa.  Mejora sugeridas:  Falta Incorporar una sección de trabajos relacionados. También, medir el grado de efectividad de su implantación, en una sección de análisis de resultados y pruebas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Una revisión interesante de la literatura - La propuesta de Taxonomía presentada  - El Caso de Estudio está tratado de manera muy débil. Además, los resultados no son expresados de una manera más rigurosa (por ejemplo, con porcentajes o gráficos). - De acuerdo a formato, poner como mínimo 5 palabras clave. - Debe cumplir con formato exigido, por ejemplo, no debe usar “et al” ni en el texto ni en las referencias, debe dejar espacios entre párrafos, etc. - La referencia 10 ¿es una tesis o un informe técnico? - Sugiero cambiar color de letra de Figura 2 para mayor legibilidad. - La Figura 2, ¿es realmente la Figura 1? - El texto en azul ¿es figura o tabla? (no aparece su identificación) - Indica que el listado de la Tabla 3 corresponde a “cada uno” de los niveles descritos, pero en la Tabla 3 no aparece el tercer nivel y debe decir Figura 3 y no Tabla 3 - En Figura 3 respectiva, debe cambiar “D. Selección de Proveedores” por “F. Selección de Proveedores”. También debe cambiar “E. Establecimiento del acuerdo” por “G. Establecimiento del contrato”. - Debe utilizar la palabra “requisito” o “requerimiento” pero no ambas. - En “C. Procedimientos de verificación” debe cambiar “2. Entorno de validación” por “2. Entorno de verificación” y “3. Procedimiento y criterios de validación” por “3. Procedimiento y criterios de verificación” - Cambiar en referencia 24 “Standarization” por “Standardization”",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta una propuesta de un modelo para evaluar la calidad de productos de software para video conferencias basado en open source. Si bien es cierto es tema es de interés y la propuesta tiene elementos de interés, el artículo presenta algunas oportunidades de mejora que deberían ser abordadas antes de su aceptación.  Contenido: - El apartado de \"Antecedentes\" provee muy poca información para ser un apartado como tal. Se recomienda explicar brevemente el sustento teórico que entregan las investigaciones base utilizadas.  - En varias ocasiones se menciona que también se definieron métricas, pero en ningún momento se entrega alguna referencia respecto a dónde pueden ser vistas en detalles si el lector está interesado. Además, en la página 5 se indica que son 73 métricas, luego en la pág. 7 se dice que son 72 y en las conclusiones sólo se resaltan 68.  - Sugiero que la sección \"Algoritmo para aplicar el Modelo de Calidad...\" sea apoyado por algún diagrama para representar algoritmos, por ejemplo, un diagrama de flujo o de actividades, ya que el texto es algo confuso y no permite entender de manera fácil el algoritmo propuesto.  - No queda claro cómo se determinaron los valores de la Tabla 4.  - No queda claro cómo se aplicó el modelo, ¿cómo se calculan los porcentajes de la Tabla 5?  - La tablas 2 y 3 son muy extensas lo cual provoca que el lector se pierda un poco del contexto analizado. Sugiero separarlas en diferentes tablas (separar la tabla 2 por categoría y la tabla 3 por características)  Formato:  - En el apartado \"Metodología\" dice \"...el objeto se define....\" creo que debe decir \"...el objetivo se define...\"  - El nombre de la figura 1 presenta un error. Dice \"Caliad\" en lugar de \"Calidad\"  - El abstract en inglés no incorpora todo lo que dice en su versión en español (no se indica nada de las métricas)  - El formato de referencias bibliográficas indica que se numera según el orden de aparición, y en el artículo se parte por la referencia 6, luego del 6 salta al 13.  - Hay artículos mencionados en la sección de referencias que nunca son referenciadas en el texto del artículo.  - En la pág. 7 hay un error en el formato de las referencias, debe ser formato numerado, y aquí aparece \"(Basili et. al., 2001)",
            "output": [
                "es"
            ]
        },
        {
            "input": "El paper cuenta conlas secciones Introducción, Análisis Teórico, Resultados, y Conclusiones.  El paper está mal estructurado. En la sección Análisis Teórico se entremezclan conceptos básicos y aspectos metodológicos. La sección Resultados de un caso de estudio que en ningún lugar es definido. Posteriormente, se efectúa un análisis en palabras de resultados sobre una situación experimental tampoco descrita al detalle que garantice una replicabilidad experimental mínima. Finalmente, la sección Agradecimientos es altamente informal.  La redacción no sigue el canon usual de papers (redacción en tercera persona), sino que se presenta en primera persona. Se requiere mejorar sustancialmente el orden y la presentación de cada sección.  En resumen, el paper sugiere la idea de que la implementación de sistemas instrumentados de seguridad es vital para mejorar la seguridad y calidad de procesos en la industria. Sin embargo, no se proponen modelos, experiencias, resultados empíricos concretos u otro equivalente. No existen motivos reales para proponer la aceptación de este trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este artículo presenta el desarrollo de un sistema de detección de ataques SYN-FLOOD Y SATAN mediante técnicas de clustering basadas en el algoritmo DBSCAN en ventanas de tiempo de 5 minutos.  El artículo se presenta claro en su redacción y se agradece el resumen de arquitectura diseñada, pudiendo ser un artículo interesante para ser presentado en nuestro congreso.  Mis principales reparos son: - Figura 7 presenta gráficos con ventana de 10 minutos, siendo que el la propuesta indica 5 minutos - A mi parecer el sistema no representa un proceso de minería de datos debido a que no hay nuevo conocimiento accionable, sino más bien es un sistema de clasificación. Puede que exista nuevo conocimiento, pero el documento no refleja como el sistema realizado ayudó a obtener nuevo conocimiento de los ataques. - Existe poca explicación y falta de experimentación para argumentar y justificar el uso de DBSCAN  sobre otro tipo de clustering o incluso en lugar de un clasificador. - Se sabe que un ataque SYN-FLOOD produce un número elevado de conexiones en un momento dado, por lo que no queda claro si es necesario un sistema tan sofisticado para detectar este fenómeno, esto podría ser aclarado si se incluyera la comparativa con otros enfoques.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Paper Summary:  This paper presents a new comprehension dataset called NewsQA dataset, containing 100,000 question-answer pairs from over 10,000 news articles from CNN. The dataset is collected through a four-stage process -- article filtering, question collection, answer collection and answer validation. Examples from the dataset are divided into different types based on answer types and reasoning required to answer questions. Human and machine performances on NewsQA are reported and compared with SQuAD.  Paper Strengths:  -- I agree that models can benefit from diverse set of datasets. This dataset is collected from news articles, hence might pose different sets of problems from current popular datasets such as SQuAD. -- The proposed dataset is sufficiently large for data hungry deep learning models to train.  -- The inclusion of questions with null answers is a nice property to have. -- A good amount of thought has gone into formulating the four-stage data collection process. -- The proposed BARB model is performing as good as a published state-of-the-art model, while being much faster.      Paper Weaknesses:  -- Human evaluation is weak. Two near-native English speakers' performance on 100 examples each can hardly be a representative of the complete dataset. Also, what is the model performance on these 200 examples? -- Not that it is necessary for this paper, but to clearly demonstrate that this dataset is harder than SQuAD, the authors should either calculate the human performance the same way as SQuAD or calculate human performances on both NewsQA and SQuAD in some other consistent manner on large enough subsets which are good representatives of the complete datasets. Dataset from other communities such as VQA dataset (Antol et al., ICCV 2015) also use the same method as SQuAD to compute human performance.  -- Section 3.5 says that 86% of questions have answers agreed upon by atleast 2 workers. Why is this number inconsistent with the 4.5% of questions which have answers without agreement after validation (last line in Section 4.1)? -- Is the same article shown to multiple Questioners? If yes, is it ensured that the Questioners asking questions about the same article are not asking the same/similar questions? -- Authors mention that they keep the same hyperparameters as SQuAD. What are the accuracies if the hyperparameters are tuned using a validation set from NewsQA? -- 500 examples which are labeled for reasoning types do not seem enough to represent the complete dataset. Also, what is the model performance on these 500 examples? -- Which model's performance has been shown in Figure 1? -- Are the two \"students\" graduate/undergraduate students or researchers? -- Test set seems to be very small. -- Suggestion: Answer validation step is nice, but maybe the dataset can be released in 2 versions -- one with all the answers collected in 3rd stage (without the validation step), and one in the current format with the validation step.   Preliminary Evaluation:  The proposed dataset is a large scale machine comprehension dataset collected from news articles, which in my suggestion, is diverse enough from existing datasets that state-of-the-art models can definitely benefit from it. With a better human evaluation, I think this paper will make a good poster.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este artículo presenta un Análisis Comparativo de Modelos de Madurez en Business Intelligence, mostrando las técnicas DEA y MESME para realizar este análisis. Aun cuando el método en sí queda claro, no se entiende si el modelo resultante queda seleccionado para cualquier organización, es decir, si es general.  Debería utilizar Inteligencia de negocios, en vez de Business Intelligence.  Estos modelos seguramente están definidos para grandes empresas de Estados Unidos, por lo tanto funcionan igualmente en las empresas chilenas? La madurez en Inteligencia de Negocios en empresas de países desarrollados es distinta a países como Chile.  No es necesario incluir el punto II por sí solo.  En el punto V, párrafo 2, indica que se describe una adaptación de DEA y no especifica la referencia o si es una adaptación propuesta por los autores, además de indicar por qué se utiliza una adaptación.  En la página 4, primer párrafo indica que se excluye el modelo Hierarchy y luego lo vuelve a incorporar en los pasos siguientes.  En la página 5, letra E, no queda claro el fundamento de por qué para aumentar la eficiencia se debe aumentar en un 10% los output. En la letra F debe cambiar la palabra 'podemos' y en el segundo párrafo parece que la tabla a referenciar es la 5 y no la 6.  Debe describir los elementos de la ecuación (3).  En la letra B, de VI, no se entiende por qué se seleccionó el modelo EI, si tenía menor eficiencia.  En la figura 6 no quedan claros los gráficos de cada modelo. En los puntos V y VI los pasos los etiqueta con números y luego los describe con letras.  Debe utilizar un editor de ecuaciones.  El artículo no tiene el formato especificado para esto y tiene más de 8 páginas. En la página 7 al incluir la tabla produce un desajuste en el texto que debe arreglar.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposed to use the BPA criterion for classifier ensembles.  My major concern with the paper is that it attempts to mix quite a few concepts together, and as a result, some of the simple notions becomes a bit hard to understand. For example:  (1) \"Distributed\" in this paper basically means classifier ensembles, and has nothing to do with the distributed training or distributed computation mechanism. Granted, one can train these individual classifiers in a distributed fashion but this is not the point of the paper.  (2) The paper uses \"Transfer learning\" in its narrow sense: it basically means fine-tuning the last layer of a pre-trained classifier.  Aside from the concept mixture of the paper, other comments I have about the paper are:  (1) I am not sure how BPA address class inbalance better than simple re-weighting. Essentially, the BPA criteria is putting equal weights on different classes, regardless of the number of training data points each class has. This is a very easy thing to address in conventional training: adding a class-specific weight term to each data point with the value being the inverse of the number of data points will do.  (2) Algorithm 2 is not presented correctly as it implies that test data is used during training, which is not correct: only training and validation dataset should be used. I find the paper's use of \"train/validation\" and \"test\" quite confusing: why \"train/validation\" is always presented together? How to properly distinguish between them?  (3) If I understand correctly, the paper is proposing to compute the BPA in a batch fashion, i.e. BPA can only be computed when running the model over the full train/validation dataset. This contradicts with the stochastic gradient descent that are usually used in deep net training - how does BPA deal with that? I believe that an experimental report on the computation cost and timing is missing.  In general, I find the paper not presented in its clearest form and a number of key definitions ambiguous.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper proposed to analyze several recently developed machine readers and found that some machine readers could potentially take advantages of the entity marker (given that the same marker points out to the same entity). I usually like analysis papers, but I found the argument proposed in this paper not very clear.  I like the experiments on the Stanford reader, which shows that the entity marker in fact helps the Stanford reader on WDW. I found that results rather interesting.  However, I found the organization and the overall message of this paper quite confusing. First of all, it feels that the authors want to explain the above behavior with some definition of the “structures”. However, I am not sure that how successful the attempt is. For me, it is still not clear what the structures are. This makes reading section 4 a bit frustrating.   I am also not sure what is the take home message of this paper. Does it mean that the entity marking should be used in the MR models? Should we design models that can also model the entity reference at the same time? What are the roles of the linguistic features here? Should we use linguistic structure to overcome the reference issue?  Overall, I feel that the analysis is interesting, but I feel that the paper can benefit from having a more focused argument.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper presents an approach to tag word senses with temporal information (past, present, future or atemporal). They model the problem using a graph-based semi-supervised classification algorithm that allows to combine item specific information - such as the presence of some temporal indicators in the glosses - and the structure of Wordnet - that is semantic relations between synsets â, and to take into account unlabeled data. They perform a full annotation of Wordnet, based on a set of training data labeled in a previous work and using the rest of Wordnet as unlabeled data. Specifically, they take advantage of the structure of the label set by breaking the task into a binary formulation (temporal vs atemporal), then using the data labeled as temporal to perform a finer grained tagging (past, present or future). In order to intrinsically evaluate their approach, they annotate a subset of synsets in Wordnet using crowd-sourcing. They compare their system to the results obtained by a state-of-the-art time tagger (Stanford's SUTime) using an heuristic as a backup strategy, and to previous works. They obtain improvements around 11% in accuracy, and show that their approach allows performance higher than previous systems using only 400 labeled data. Finally, they perform an evaluation of their resource on an existing task (TempEval-3) and show improvements of about 10% in F1 on 4 labels.  This paper is well-constructed and generally clear, the approach seems sound and well justified. This work led to the development of a resource with fine grained temporal information at the word sense level that would be made available and could be used to improve various NLP tasks. I have a few remarks, especially concerning the settings of the experiments.  I think that more information should be given on the task performed in the extrinsic evaluation section. An example could be useful to understand what the system is trying to predict (the features describe âentity pairsâ but it has not been made clear before what are these pairs) and what are the features (especially, what are the entity attributes? What is the POS for a pair, is it one dimension or two? Are the lemmas obtained automatically?). The sentence describing the labels used is confusing, I'm not sure to understand what âevent to document creation timeâ and âevent to same sentence eventâ means, are they the kind of pairs considered? Are they relations (as they are described as relation at the beginning of p.8)? I find unclear the footnote about the 14 relations: why the other relations have to be ignored, what makes a mapping too âcomplexâ? Also, are the scores macro or micro averaged? Finally, the ablation study seems to indicate a possible redundancy between Lexica and Entity with quite close scores, any clue about this behavior?  I have also some questions about the use of the SVM.  For the extrinsic evaluation, the authors say that they optimized the parameters of the algorithm: what are these parameters?  And since a SVM is also used within the MinCut framework, is it optimized and how? Finally, if it's the LibSVM library that is used (Weka wrapper), I think a reference to LibSVM should be included.   Other remarks: - It would be interesting to have the number of examples per label in the gold data, the figures are given for coarse grained labels (127 temporal vs 271 atemporal), but not for the finer grained. - It would also be nice to have an idea of the number of words that are ambiguous at the temporal level, words like âpresentâ. - It is said in the caption of the table 3 that the results presented are âsignificantly betterâ but no significancy test is indicated, neither any p-value.  Minor remarks: - Related work: what kind of task was performed in (Filannino and Nenadic, 2014)? - Related work: ârequires a post-calibration procedureâ, needs a reference (and p.4 in 3.3 footnote it would be clearer to explain calibration) - Related work: âtheir model differ from oursâ, in what? - Table 3 is really too small: maybe, remove the parenthesis, put the â(p,r,f1)â in the caption and give only two scores, e.g. prec and f1. The caption should also be reduced. - Information in table 4 would be better represented using a graph. - Beginning of p.7: 1064 â 1264 - TempEval-3: reference ? - table 6: would be made clearer by ordering the scores for one column - p.5, paragraph 3: atemporal) â atemporal",
            "output": [
                "en"
            ]
        },
        {
            "input": "De acuerdo con la convocatoria, Infonor-Chile acepta reportes de trabajos de investigación en temas de interés en computación y tecnologías de la información y sus aplicaciones; el artículo presenta una reflexión, desde el punto de vista del autor (en algunos casos sustentado en citas bibliográficas), sobre los desafíos de los Métodos Formales en el ámbito de la Ingeniería de Software, sin embargo no ofrece aportes sustentados en algún tipo de validación, más que la opinión del autor sobre las oportunidades y desafíos de dicha área; incluso la revisión bibliográfica no ofrece evidencia de haber utilizado un proceso formal (p.e. revisión sistemática) para sustentar la reflexión propuesta.  Me parece que como trabajo de \"divulgación\" es muy interesante, pero como reporte de \"investigación\" es limitado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo describe el armado de un robot para docencia de pregrado, con la información de ecuaciones y control para su utilización. No presenta un trabajo de investigación específico, pero es una buena alternativa para ser mostrado en el congreso. Algunos comentarios de carácter general, que deben ser modificado para su aceptación final: 1.- Por las características de la comunicación, se entiende las pocas referencias que presenta. 2.- Las ecuaciones fueron copiadas y pegadas, en la mayoría de las veces, no se ven muy legibles, por lo que se aconseja reescribirlas con un editor de ecuaciones todas. 3.- Las figuras no presentan fuentes o referencias , de donde fueron extraídas. 4.- Existen párrafos largos que pueden acomodarse mejor con una puntuación.  En general es un trabajo bien escrito, se entiende fácilmente su contenido, su presentación con los \"copy paste\" atentan.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper addresses the network embedding problem by introducing a neural network model which uses both the network structure and associated text on the nodes, with an attention model to vary the textual representation based on the text of the neighboring nodes.  - Strengths:  The model leverages both the network and the text to construct the latent representations, and the mutual attention approach seems sensible.  A relatively thorough evaluation is provided, with multiple datasets, baselines, and evaluation tasks.  - Weaknesses:  Like many other papers in the \"network embedding\" literature, which use neural network techniques inspired by word embeddings to construct latent representations of nodes in a network, the previous line of work on statistical/probabilistic modeling of networks is ignored.  In particular, all \"network embedding\" papers need to start citing, and comparing to, the work on the latent space model of Peter Hoff et al., and subsequent papers in both statistical and probabilistic machine learning publication venues:  P.D. Hoff, A.E. Raftery, and M.S. Handcock. Latent space approaches to social network analysis. J. Amer. Statist. Assoc., 97(460):1090–1098, 2002.  This latent space network model, which embeds each node into a low-dimensional latent space, was written as far back as 2002, and so it far pre-dates neural network-based network embeddings.  Given that the aim of this paper is to model differing representations of social network actors' different roles, it should really cite and compare to the mixed membership stochastic blockmodel (MMSB):  Airoldi, E. M., Blei, D. M., Fienberg, S. E., & Xing, E. P. (2008). Mixed membership stochastic blockmodels. Journal of Machine Learning Research.  The MMSB allows each node to randomly select a different \"role\" when deciding whether to form each edge.  - General Discussion:  The aforementioned statistical models do not leverage text, and they do not use scalable neural network implementations based on negative sampling, but they are based on well-principled generative models instead of heuristic neural network objective functions and algorithms.  There are more recent extensions of these models and inference algorithms which are more scalable, and which do leverage text.  Is the difference in performance between CENE and CANE in Figure 3 statistically insignificant? (A related question: were the experiments repeated more than once with random train/test splits?)  Were the grid searches for hyperparameter values, mentioned in Section 5.3, performed with evaluation on the test set (which would be problematic), or on a validation set, or on the training set?",
            "output": [
                "en"
            ]
        },
        {
            "input": "This submission introduces a formulation of Generative Adversarial Networks (GANs) under the lens of density ratio estimation, when using Bregman divergences. Even thought GANs already perform density estimation, the motivation of using Bregman divergences is to obtain an objective function with stronger gradients. I have three concerns with this submission.  First, the exposition of the paper must be significantly improved. The current version of the manuscript is at some points unreadable, and does a poor job at motivating, describing, and justifying the contributions.  Second, the authors scatter a variety of alternatives and heuristics throughout the description of the proposed b-GAN. This introduces a great amount of complexity when it comes to understanding, implementing, and using b-GAN. Further work is necessary to rule out (in a principled manner!) many of the proposed variants of the algorithm.  Third, it is next to impossible to interpret the experimental results, in particular Figures 2, 3, 4. The authors claim that these figures show that \"learning does not stop\", but such behavior can also be attributed to the typical chaotic dynamics of GANs. Even after reading Appendix A, I am left unconvinced on whether the proposed approach provides with any practical advantage (even no comparison is offered to other GAN approaches with similar architectures).  Overall, I believe this submission calls for significant improvements before being considered for publication.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es un artículo que presenta una diagnóstico interesante de las empresas de desarrollo de software de Chile. Incorporan una base estadística inicial que da formalidad al trabajo realizado, de manera específica para la determinación de la muestra base para el desarrollo de las encuestas. Sin embargo, los datos estadísticos de los resultados no hacen parte del trabajo presentado.  Presentación de resultados estadísticos que validen las conclusiones presentadas y los hallazgos encontrados, acerca del diagnóstico.  Se recomienda a los autores continuar en el trabajo a fin incorporar las bases estadísticas tendiente en las empresas del sector en otros países.  Otras recomendaciones:  Revisión exhaustiva del inglés y de forma particular para la presentación de artículo, debería revisarse de forma cuidadosa la traducción de este idioma. Revisar particularmente el título, donde hay un error en la primera palabra.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths:  The authors present a novel adaptation of encoder-decoder neural MT using an approach that starts and ends with characters, but in between works with representations of morphemes and characters.   The authors release both their code as well as their final learned models for fr-en, cs-en, and en-cs. This is helpful in validating their work, as well as for others looking to replicate and extends this work.  The system reported appears to produce translation results of reasonable quality even after the first training epoch, with continued progress in future epochs.  The system appears to learn reasonable morphological tokenizations, and appears able to handle previously unseen words (even nonce words) by implicitly backing off to morphemes.  - Weaknesses:  In the paper, the authors do not explicitly state which WMT test and dev sets their results are reported on. This is problematic for readers wishing to compare the reported results to existing work (for example, the results at matrix.statmt.org). The only way this reviewer found to get this information was to look in the README of the code supplement, which indicates that the test set was newstest2015 and the dev test was newstest2013. This should have been explicitly described in the paper.  The instructions given in the software README are OK, but not great. The training and testing sections each could be enhanced with explicit examples of how to run the respective commands. The software itself should respond to a --help flag, which it currently does not.  The paper describes a 6-level architecture, but the diagram in Figure 2 appears to show fewer than 6 layers. What's going on? The caption should be more explicit, and if this figure is not showing all of the layers, then there should be a figure somewhere (even if it's in an appendix) showing all of the layers.  The results show comparison to other character-based neural systems, but do not show state-of-the-art results for other types of MT system. WMT (and matrix.statmt.org) has reported results for other systems on these datasets, and it appears that the state-of-the-art is much higher than any of the results reported in this paper. That should be acknowledged, and ideally should be discussed.  There are a handful of minor English disfluencies, misspellings, and minor LaTeX issues, such as reverse quotation marks. These should be corrected.  - General Discussion:  Paper is a nice contribution to the existing literature on character-based neural MT.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Extended the paper with experiments on the word relationship dataset, showing Doc2VecC generates better word embeddings in comparison to Word2Vec or Paragraph Vectors. ",
            "output": [
                "en"
            ]
        },
        {
            "input": "Resumen:  El artículo busca analizar las redes de colaboración existentes entre investigadores de Sistemas de Información (SI) en Chile y en Latinoamérica. Se utilizan las co-autorias de investigaciones publicadas en Contecsi e Infonor para realizar un análisis de redes sociales, explicando estas últimas. Se plantean 3 preguntas que se responden luego en el análisis de los resultados a través de tablas y grafos; concluyendo varias similitudes entre comunidades y que existe colaboración entre investigadores de SI, la cual es lamentablemente es en su mayoría intra-institucional.  Evaluación:  El trabajo está bien realizado. Presenta una estructura clara y concisa que ayuda al lector a entender las ideas que se están tratando. Es un trabajo interesante que pertenece a un proceso que aún no termina debido a la escasez y continuidad de datos. La primera provocada por problemas de registros y normalización de papers publicados, y la segunda debido a que habrá nuevas versiones de los congresos que entregaran nuevos datos.  Aun así, se logra identificar algunos problemas, estos son:  1) No se da un argumento basado en datos del por qué estos son los dos congresos elegidos, dados que estos congresos son pequeños.  2) Al ser un trabajo de un alcance pequeño (respecto a los congresos usados), la utilidad del resultado también lo es.  Comentario menor:  Existe un error en la numeración de las páginas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper addresses the problem of decoding barcode-like markers depicted in an image.  The main insight is to train a CNN from generated data produced from a GAN.  The GAN is trained using unlabeled images, and leverages a \"3D model\" that undergoes learnt image transformations (e.g., blur, lighting, background).  The parameters for the image transformations are trained such that it confuses a GAN discriminator.  A CNN is trained using images generated from the GAN and compared with hand-crafted features and from training with real images.  The proposed method out-performs both baselines on decoding the barcode markers.  The proposed GAN architecture could potentially be interesting.  However, I won’t champion the paper as the evaluation could be improved.  A critical missing baseline is a comparison against a generic GAN.  Without this it’s hard to judge the benefit of the more structured GAN.  Also, it would be worth seeing the result when one combines generated and real images for the final task.   A couple of references that are relevant to this work (for object detection using rendered views of 3D shapes):  [A] Xingchao Peng, Baochen Sun, Karim Ali, Kate Saenko, Learning Deep Object Detectors from 3D Models; ICCV, 2015.  [B] Deep Exemplar 2D-3D Detection by Adapting from Real to Rendered Views. Francisco Massa, Bryan C. Russell, Mathieu Aubry. CVPR 2016.  The problem domain (decoding barcode markers on bees) is limited.  It would be great to see this applied to another problem domain, e.g., object detection from 3D models as shown in paper reference [A], where direct comparison against prior work could be performed.    I found the writing to be somewhat vague throughout.  For instance, on first reading of the introduction it is not clear what exactly is the contribution of the paper.    Minor comments:  Fig 3 - Are these really renders from a 3D model?  The images look like 2D images, perhaps spatially warped via a homography.    Page 3: \"chapter\" => \"section\".  In Table 2, what is the loss used for the DCNN?  Fig 9 (a) - The last four images look like they have strange artifacts. Can you explain these?",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo trata de un trabajo simple de desarrollo de una aplicación para generar indicadores de gestión para una empresa y no presenta ningún aporte desde el punto de vista científico.  Tiene problemas de ajuste al formato solicitado y presenta muchos errores ortográficos, de puntuación y redacción.  El título no es acorde a su contenido, no describe nada acerca de la plataforma móvil.  La bibliografía es muy vaga, en algunos casos simples direcciones web, además no se ajusta a formato.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper looks at the problem of transferring a policy learned in a simulator to  a target real-world system.  The proposed approach considers using an ensemble of simulated source domains, along with adversarial training, to learn a robust policy that is able to generalize to several target domains.  Overall, the paper tackles an interesting problem, and provides a reasonable solution.  The notion of adversarial training used here does not seem the same as other recent literature (e.g. on GANs).  It would be useful to add more details on a few components, as discussed in the question/response round.  I also encourage including the results with alternative policy gradient subroutines, even if they don’t perform well (e.g. Reinforce), as well as results with and without the baseline on the value function. Such results are very useful to other researchers.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El documento describe una forma de aplicar técnicas actuales de ingeniería informática al problema de líneas de productos de software. El documento está bien explicado, pero se considera necesario profundizar en los resultados y la evaluación. El trabajo descrito es interesante ya que aplica Algoritmos Genéticos a un problema concreto, pero carece de  impacto innovador en el dominio. Se recomienda revisar la redacción (en general) del documento.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Update: After reading the rebuttal comments and the revised paper, I'm leaving the rating as it was before.  This paper proposes an unsupervised algorithm for transferring samples from one domain to another (related) domain under the constraint that some predefined f returns same result for the input and the result.  Pros: 1. The paper presents an interesting idea of comparing samples from different domains using a fixed perceptual function f.  2. The proposed method produces visually appealing results on several datasets  3. The authors demonstrate how their approach can be used for domain adaptation and obtain improved results on the SVHN->MNIST task  4. The paper is well-written and easy to read  Cons: 1. The novelty of the method is relatively minor (I consider f-constancy term as the main contribution)  2. It feels like the proposed approach would break for more dissimilar domains. The method relies on a fixed f which is trained on the source domain. This f can potentially drop information important for obtaining 1) better reconstructions in the target domain  2) more tightly related x and g(f(x)). I think the authors should consider either training all the modules in the model end-to-end or incorporating target samples into the training of f.  3. A single domain adaptation experiment is definitely not enough to consider the proposed method as a universal alternative to the existing DA approaches.  I would also like to point out that using super-resolved outputs as opposed to the actual model’s outputs can produce a false impression of the visual quality of the transferred samples. I’d suggest moving original outputs from the appendix into the main part.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Paper Strengths:  -- Elegant use of MoE for expanding model capacity and enabling training large models necessary for exploiting  very large datasets in a computationally feasible manner  -- The effective batch size for training the MoE drastically increased also  -- Interesting experimental results on the effects of increasing the number of MoEs, which is expected.   Paper Weaknesses:  --- there are many different ways of increasing model capacity to enable the exploitation of very large datasets; it would be very nice to discuss  the use of MoE and other alternatives in terms of computational efficiency and other factors.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper is an extension of Lenc&Vedaldi15 paper, showing CNN representations at FC7 layer are to certain extent equivariant to various classes of transformations and that training with a certain group of transformation makes the representations more equivalent.  Authors performed a large amount of experiments, training over 30 networks with different forms of jitter, which is quite impressive. However it is rather difficult to find a main message of this work. Yes, authors measured the properties on a different layer than the Lenc&Vedaldi15, however it is hard to find some novel insights other than the known fact that jitter helps to achieve invariance. The evaluation seems to be mostly correct, however the paper does not seem to be solving the task advertised in its title really well.  Major issues are in the experiments with the representation distances: * The selection of only FC7 is a bit controversial - it is followed only by a single classification layer (FC8) to the common output - class likelyhoods. Because the FC8 is just a linear projections, what the equivalence map does is just to re-project the FC8 weights of the attached network to the weights of the original network. Probably performing similar experiments but on more layers may be more useful (as the networks are already trained). * The experiment with representation distance is missing what is the classification error on the testing dataset. This would answer whether the representations are actually compatible up to linear transformation at all... * It is not clear for the experiment with K-NN whether this is measured per each test set example? After training the equivalence map? More clear would be to show that networks trained on similar group of jitter transformations are more compatible on the target task. * The proposed method does not seem to improve equivariance consistently on all tasks. Especially with \\lambda_1 and \\lambda_2 having such small values, the loss is basically equal to simple data jitter as it just adds up the loss of the original and transformed image. Maybe the issue is in the selection of the FC7 layer?  In general, this paper shows some interesting results on the FC7 equivariance, but it does not seem to be drawing many interesting new observations out of these experiments. Due to some issues with the equivalence experiments and the finetuning of equivariance, I would not recommend acceptance of this manuscript. However, refining the experiments on already trained networks and restructuring this manuscript into more investigative work may lead to interesting contribution to the field.  There are also few minor issues: * It is not experimentally verified that the new criterion for equivariance mapping helps to gain better results. * The angles on page 1 and 5 are missing units (degrees?). * On page three, \"In practice, it is difficult... \", it is not M_g which is maximised/minimised, but the loss over the M_g * Page 4, footnote 2 - if you are just halving the activations, it is hard to call it a dropout as this constant factor can be passed to the following/preceding weights * Is the network for RVL-CDIP the same architecture as Alexnet? * On page 7, Figure 3a+3b - in my opinion, turning the diagonal elements to white is really misleading, and probably even incorrect, as the distance between the same representations should be zero (which is also a way how to verify that the experiments are performed correctly).",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta recomendaciones prácticas para el desarrollo de software seguro. Se describen las mejores prácticas recomendadas para desarrollar software que sea proactivo ante los ataques, y se realiza un análisis de costos de estas prácticas en desarrollo de software. Todo basado en una revisión de prácticas propuestas en la bibliografía y su contraste con datos obtenidos de una encuesta en empresas. Finalmente se recomienda una guía.  Sería ideal aplicar la guía propuesta a empresas no involucradas en la encuesta que sirvió para originarla de modo de poder evaluar su efectividad en forma independiente.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo habla (en el resumen y un poco en la introducción) de una experiencia tecnológica de inter-operatividad entre plataformas de enseñanza, pero no se evidencia tal experiencia en sus líneas. Los resultados no son concretos, no hay experimentación o análisis de resultados que sustenten lo afirmado en el apartado de conclusiones. El apartado de conclusiones no se relaciona con lo dicho en el resumen no expresado en la introducción como objetivo del trabajo. A pesar de ser un estudio interesante respecto a estándares y tecnologías como e-learning o t-learning, los autores no logran describir la metodología de trabajo, procesos, experimentación, resultados y valoración de los resultados. En el apartado Resultados (al final) hablan de pruebas en dispositivos pero no se describen dichas pruebas, no hay evidencia de dichas pruebas en el documento.  Por otro lado, el texto tiene carencias importantes como las siguientes: 1. Tanto el Resumen como el Abstract tienen ideas difíciles de entender o están poco elaborados. 2. Se detectan errores ortográficos en el documento. 3. Lo dicho en la Introducción coincide poco con lo dicho en el Resumen. 4. Uso de siglas (abreviaturas) no descritas en el documento (como por ejemplo ETSI), no hay un glosario de términos. 5. Párrafos que contribuyen muy poco a entender el documento, como por ejemplo el que dice \"La Tabla 1 muestra el análisis de las características de las normas y estándares\" o el párrafo que dice \"Pruebas de acceso y despliegue sobre el BlackBerry Thorch\".",
            "output": [
                "es"
            ]
        },
        {
            "input": "[Summary] This paper proposes a new way for knowledge base completion which highlights: 1) adopting an implicit shared memory, which makes no assumption about its structure and is completely learned during training; 2) modeling a multi-step search process that can decide when to terminate.  The experimental results on WN18 and FB15k seem pretty good. The authors also perform an analysis on a shortest path synthetic task, and demonstrate that this model is better than standard seq2seq.  The paper is well-written and it is easy to follow.  [Major comments] I actually do like the idea and am also impressed that this model can work well. The main concern is that this paper presents too little analysis about how it works and whether it is sensitive to the hyper-parameters, besides that only reporting a final model on WN18 and FB15k.  One key hyper-parameter I believe is the size of shared memory (using 64 for the experiments). I don’t think that this number should be fixed for all tasks, at least it should depend on the KB scale. Could you verify this in your experiments? Would it be even possible to make a memory structure with dynamic size?  The RL setting (stochastic search process) is also one highlight of the paper, but could you demonstrate that how much it does really help? I think it is necessary to compare to the following: remove the termination gate and fix the number of inference steps and see how well the model does? Also show how the performance varies on # of steps?  I appreciate your attempts on the shortest path synthetic task. However, I think it would be much better if you can demonstrate that under a real KB setting. You can still perform the shortest path analysis, but using KB  (e.g., Freebase) entities and relations.  [Minor comments] I am afraid that the output gate illustrated in Figure 1 is a bit confusing. There should be only one output, depending on when the search process is terminated.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este trabajo se enmarca en el área de la arquitectura del negocio y propone un interesante modelo de automatización de reglas de negocio para mejorar la flexibilidad de los sistemas de información aplicado a entidades financieras. El modelo propuesto  se orienta a desacoplar la lógica de negocio de  las reglas de negocio.  La problemática que aborda el artículo está sustentada adecuadamente en las dificultades mencionadas en el ámbito de los proyectos de software y en el mundo financiero.  El autor podría profundizar un poco más en las experiencias de desarrollo de proyectos en otros ámbitos y la relevancia de las reglas de negocios en el desarrollo de sistemas de información eficientes en la empresa.  El objetivo declarado por el autor  es proponer una metodología que permita flexibilizar la operatoria de los sistemas de información en las entidades financieras  el que en general se explicita  en forma adecuada.  La revisión bibliográfica es pertinente a los temas que se abordan y las teorías y modelos considerados son  adecuados al objetivo que se ha planteado. Los análisis asociados al concepto de reglas de negocios y arquitectura del sistema son atingentes al tema. El autor debería especificar como se establece la relación entre el modelado de procesos y el diseño y caracterización de las reglas de negocio. Se menciona que utilizan las tablas de puntos de decisión, pero estas no se mencionan en detalle ni visualmente. El autor debería sustentar de mejor manera la elección de “Pipes and Filter”  como modelo de arquitectura del sistema. Sería importante destacar también si existen trabajos similares realizados en otros ámbitos  ( ya que el autor  no lo menciona)  El aspecto metodológico del trabajo se  enfoca a describir el proceso a través del cual se llega a la definición de la arquitectura de software para automatizar las reglas de negocios y las herramientas que se utilizaron en su desarrollo. Este enfoque metodológico es adecuado y se asocia claramente a una aplicación de estudio de caso. El aporte importante en este aspecto es la descripción detallada del proceso desde el levantamiento de las reglas hasta el diseño y desarrollo de la arquitectura de aplicación propuesta.  El autor  debería hacer un cuadro resumen en el que se represente este proceso en forma resumida.   Es claro que los resultados de este trabajo tienen la validez deseada, ya que se sustenta en la utilización de modelos y herramientas ya validados en el ámbito del diseño de plataformas de negocios basadas en reglas.  La contribución del trabajo es importante ya que sistematiza un proceso que es de amplia utilización en el desarrollo de sistemas de información que sean flexibles y adaptables al entorno cambiante. Sin embargo en las conclusiones no está reflejado con toda claridad estas contribuciones por lo cual se sugiere a los autores mejorar las conclusiones incluyendo los aportes significativos en términos metodológicos y de aporte a la disciplina en la que se enmarca el artículo.  Los aspectos formales del trabajo son satisfactorios para el congreso. Hay detalles menores  en la gramática como en el primer párrafo de la introducción que falta la letra U.  Se sugiere aceptar el artículo con modificaciones menores",
            "output": [
                "es"
            ]
        },
        {
            "input": "Summary: The paper proposes a neural model for predicting Python syntax trees from text descriptions. Guided by the actual Python grammar, the model generates tree nodes sequentially in a depth-first fashion. Key ideas include injecting the information from the parent node as part of the LSTM input, a pointer network for copying the terminals, and unary closure which collapses chains of unary productions to reduce the tree size. The model is evaluated on three datasets from different domains and outperforms almost all previous work.  Strengths:  The paper is overall very well-written. The explanation of system is clear, and the analysis is thorough.  The system itself is a natural extension of various ideas. The most similar work include tree-based generation with parent feeding (Dong and Lapata, 2016) and various RNN-based semantic parsing with copy mechanism (Jia and Liang, 2016; Ling et al., 2016). [The guidance of parsing based on grammar is also explored in Chen Liang et al., 2016 ([Link] where a code-assist system is used to ensure that the code is valid.] Nevertheless, the model is this paper stands out as it is able to generate much longer and more complex programs than most previous work mentioned.   Weaknesses:  The evaluation is done on code accuracy (exact match) and BLEU score. These metrics (especially BLEU) might not be the best metrics for evaluating the correctness of programs. For instance, the first example in Table 5 shows that while the first two lines in boxes A and B are different, they have the same semantics. Another example is that variable names can be different. Evaluation based on what the code does (e.g., using test cases or static code analysis) would be more convincing.  Another point about evaluation: other systems (e.g., NMT baseline) may generate code with syntactic error. Would it be possible to include the result on the highest-scoring well-formed code (e.g., using beam search) that these baseline systems generate? This would give a fairer comparison since these system can choose to prune malformed code.  General Discussion:  * Lines 120-121: some approaches that use domain-specific languages were also guided by a grammar. One example is Berant and Liang, 2014, which uses a pretty limited grammar for logical forms (Table 1). In addition to comparing to that line of work, emphasizing that the grammar in this paper is much larger than most previous work would make this work stronger.  * Lines 389-397: For the parent feeding mechanism, is the child index being used? In other words, is p_t different when generating a first child versus a second child? In Seq2Tree (Dong and Lapata, 2016) the two non-terminals would have different hidden states.  * Line 373: Are the possible tokens embedded? Is it assumed that the set of possible tokens is known beforehand?  * The examples in the appendix are nice.  ---  I have read the author response.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper introduces a variation to the CNN-based texture synthesis procedure of Gatys et al. that matches correlations between spatially shifted feature responses in addition to the correlations between feature responses at the same position in the feature maps.  The paper claims that this  a) improves texture synthesis for textures with long-range regular structures, that are not preserved with the Gatys et al. method b) improves performance on texture inpainting tasks compared to the Gatys et al. method c) improves results in season transfer when combined with the style transfer method by Gatys et al.  Furthermore the paper shows that d) by matching correlations between spatially flipped feature maps, symmetry properties around the flipping axis can be preserved.  I agree with claim a). However, the generated textures still have some issues such as greyish regions so the problem is not solved. Additionally, the procedure proposed is very costly which makes an already slow texture synthesis method substantially slower. For example, in comparison, the concurrent work by Liu et al. (",
            "output": [
                "en"
            ]
        },
        {
            "input": "Authors' response well answered my questions. Thanks.  Evaluation not changed.  ###  This paper proposes a neural model for generating tree structure output from scratch. The model does 1) separate the recurrence between depths and siblings; 2) separate the topology and label generation, and outperforms previous methods on a benchmark IFTTT dataset. Compared to previous tree-decoding methods, the model avoids manually annotating subtrees with special tokens, and thus is a very good alternative to such problems. The paper does solid experiments on one synthetic dataset, and outperforms alternative methods on one real-world IFTTT dataset.   There are couple of interesting results in the paper that I believe is worth further investigation. Firstly, on the synthetic dataset, the precision drops rapidly with the number of nodes. Is it because that the vector representation of the sequential encoder fails to provide sufficient information of long sequences, such that the tree decoder can not do a good job? Or is it because that such tree decoder is not tolerant to the long sequence input, i.e., large tree structure? I believe that it is important to understand this before a better model can be developed. For example, if it is the fault of encoder, maybe an attention layer can be added, as in a seq-to-seq model, to preserve more information of the input sequence.   Moreover, besides only showing how the precision changes with the number of nodes in the tree, it might be interesting to investigate how it goes with 1) number of depths; 2) number of widths; 3) symmetricity; etc. Moreover, as greedy search is used in decoding, it might be interesting to see how it helps, if it does, to use beam-search in tree decoding.   On the IFTTT dataset, listing more statistics about this dataset might be helpful for better understanding the difficulty of this task. How deep are the trees? How large are the vocabularies on both language and program sides?  The paper is well written, except for minor typo as mentioned in my pre-review questions.   In general, I believe this is a solid paper, and more can be explored in this direction. So I tend to accept it.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta una aplicación en el ámbito empresarial orientada al comercio minorista en la empresa comercial  “Caracol” en Cuba. La temática del trabajo está orientada  fundamentalmente a  presentar y comentar  la aplicación  InfoCom y el cómo eventualmente funciona en la empresa.  Sin embargo en términos de su discusión teórica, metodológica y del análisis de los resultados este artículo  presenta múltiples falencias que se detallan a continuación: La introducción del artículo en general destaca la relevancia de la aplicación construida para la empresa en particular  pero no detalla lo innovador de esta propuesta y porque este sistema de información es mejor en términos de desarrollo ó cuales son las características que lo distinguen de lo que existe actualmente en el mercado. Tampoco el autor establece con claridad la  motivación que le ha llevado   a desarrollar una nueva solución para el problema planteado.  No se define un  objetivo de investigación como tal del artículo ya que se menciona que este será el de “exponer un sistema de información comercial adaptable a cualquier negocio minorista……..”  . En general se desea presentar  la aplicación construida y no se especifica  que se espera del artículo, las  metodologías a ser utilizadas y  lo innovador en términos de desarrollo para la disciplina de los sistemas de información. Una de las limitantes principales de este artículo es el estado del arte.   La revisión de la literatura es casi inexistente en relación a  las teorías que sustentan el desarrollo de la aplicación y no están mencionados los principales autores  en temas de desarrollo de plataformas de esta naturaleza. No se establece en él artículo ningún marco teórico en términos de  diseño ó implementación  de la aplicación. Tampoco se discuten propuestas en  esos términos  por lo que es posible decir que no hay referencias teóricas en términos de análisis,  diseño e implementación.  Esta dificultad hace que la evaluación de lo que se ha desarrollado  sea  solamente basada en opiniones en general de lo que es el concepto de sistemas de información. La metodología de la investigación es otra importante falencia de este artículo. El artículo se mueve entre la importancia de  la aplicación a una descripción de lo que es posible hacer con ella sin establecer metodologías claras y aceptadas de desarrollo e implementación (ni para el diseño de la herramienta ó para  el análisis de los resultados obtenidos de su uso). Esto complica la evaluación del trabajo ya que no hay preguntas de investigación a responder,  ni formas de evaluar si se cumplen las expectativas del autor ó si los resultados obtenidos serán válidos.  El autor del artículo debería  presentar y describir los diseños de investigación a ser utilizados para permitir evaluar su validez.  La mayor parte del artículo está en el ítem desarrollo y en él se define y detalla las características de la empresa en la que se desarrollará el estudio. No se especifica con claridad cuales partes del sistemas son adquiridas comercialmente  y cuales se desarrollan internamente y como se logra la conexión con otras plataformas ya existentes. Tampoco se establecen modelos de procesos  ni de datos asociados a esta construcción. Los autores se limitan a explicar  las funcionalidades de la herramienta y cómo se utilizará en la empresa pero no es posible saber cómo se  implementó y  comparar los resultados que se destacan como relevantes de la implementación. Aunque la herramienta pueda ser muy sencilla desde un punto de vista de su diseño y arquitectura, se esperaría una descripción que presente modelos de procesos  utilizando herramientas ad-hoc y al menos una descripción de la etapa de diseño Los resultados obtenidos  en general son mencionados como algo que se consiguió realizar y como porcentajes  de mejoras en gestión y no es posible extraer conclusiones validas sobre ellos. La conclusión del artículo es débil en términos de los resultados obtenidos  del diseño e implementación de la aplicación y por sobre todo de la contribución del estudio  a la disciplina de los sistemas de información.  Considero que el artículo requiere de cambios mayores y  que se debe trabajar en la definición del objetivo, la metodología a utilizar  para el análisis y diseño de la plataforma.  Por lo tanto sugiero en esta oportunidad su rechazo para esta conferencia",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors propose a simple idea. They penalize confident predictions by using the entropy of the predictive distribution as a regularizer. The authors consider two variations on this idea. In one, they penalize the divergence from the uniform distribution. In the other variation, they penalize distance from the base rates. They term this variation \"unigram\" but I find the name odd as I've never seen multi-class labels described as unigrams before. What would a bigram be?   The idea is simple,  and while it's been used in the context of reinforcement learning, it hasn't been popularized as a regularizer for improving generalization in supervised learning.   The justifications for the idea still lacks analysis. And the author responses comparing it to L2 regularization have some holes. A simple number line example with polynomial regression makes clear how L2 regularization could prevent a model from badly overfitting to accommodate every data point. In contrast, it seems trivial to fit every data point and satisfy arbitrarily high entropy. Of course, the un-regularized optimization is to maximize log likelihood, not simply to maximize accuracy.  And perhaps something interesting may be happening at the interplay between the log likelihood objective and the regularization objective. But the paper doesn't indicate precisely what.  I could imagine the following scenario: when the network outputs probabilities near 0, it can get high loss (if the label is 1). The entropy regularization could be stabilizing the gradient, preventing sharp loss on outlier examples. The regularization then might owe mainly to faster convergence. Could the authors analyze the effect empirically, on the distribution of the gradient norms?   The strength of this paper is its empirical rigor. The authors take their idea and put it through its paces on a host of popular and classic benchmarks spanning CNNs and RNNs. It appears that on some datasets, especially language modeling, the confidence penalty outperforms label smoothing.   At present, I rate this paper as a borderline contribution but I'm open to revising my review pending further modifications.   Typo: In related work: \"Penalizing entropy\" - you mean penalizing low entropy",
            "output": [
                "en"
            ]
        },
        {
            "input": "SUMMARY.  The paper proposes a machine reading approach for cloze-style question answering. The proposed system first encodes the query and the document using a bidirectional gru. These two representations are combined together using a Gated Attention (GA). GA calculates the compatibility of each word in the document and the query as a probability distribution. For each word in the document a gate is calculated weighting the query representation according to the word compatibility. Ultimately, the gate is applied to the gru-encoded document word. The resulting word vectors are re-encoded with a bidirectional GRU. This process is performed for multiple hops. After k hops, the probability of a word to be part of the answer is calculated by a log-linear model that take as input the last word representations, and the concatenation of the last query representation before and after the cloze token. The probability of a candidate being the answer to the question is given by a linear combination of the single word probabilities.  The proposed model is tested on 4 different dataset.  The authors shown that the proposed model works well (state-of-the-art performance) for 3 out of 4 benchmarks.   ----------  OVERALL JUDGMENT The main contribution of the paper is the gated attention mechanism, that in my opinion, is a simple and interesting idea. The paper is well thought, and the ablation study on the benefits given by the gated attention are convincing. The GA reader as whole model outperforms previous state-of-the-art models on 3 benchmarks and seems very promising also on the CBT dataset. I would have liked to see some discussion on why the model works less well on the CBT dataset, though.   ----------  DETAILED COMMENTS  minor. In the introduction, Weston et al., 2014 do not use any attention mechanism.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This work proposes a convolutional architecture for any graph-like input data (where the structure is example-dependent), or more generally, any data where the input dimensions that are related by a similarity matrix. If instead each input example is associated with a transition matrix, then a random walk algorithm is used generate a similarity matrix.  Developing convolutional or recurrent architectures for graph-like data is an important problem because we would like to develop neural networks that can handle inputs such as molecule structures or social networks. However, I don't think this work contributes anything significant to the work that has already been done in this area.   The two main proposals I see in this paper are: 1) For data associated with a transition matrix, this paper proposes that the transition matrix be converted to a similarity matrix. This seems obvious. 2) For data associated with a similarity matrix, the k nearest neighbors of each node are computed and supply the context information for that node. This also seems obvious.  Perhaps I have misunderstood the contribution, but the presentation also lacks clarity, and I cannot recommend this paper for publication.   Specific Comments: 1) On page 4: \"An interesting attribute of this convolution, as compared to other convolutions on graphs is that, it preserves locality while still being applicable over different graphs with different structures.\"  This is false; the other proposed architectures can be applied to inputs with different structures (e.g. Duvenaud et. al., Lusci et. al. for NN architectures on molecules specifically).",
            "output": [
                "en"
            ]
        },
        {
            "input": "I reviewed the manuscript on December 5th.  Summary: The authors investigate the phenomenon of adversarial perturbations and ask whether one may build a system to independently detect an adversarial data point -- if one could detect an adversarial example, then might prevent a machine from automatically processing it. Importantly, the authors investigate whether it is possible to build an adversarial detector which is resilient to adversarial examples built against *both* the classifier and the detector. Their results suggest that training a detector in this more difficult setting still yields gains but does not entirely resolve the problem of detecting adversarial examples.  Major comments:  The authors describe a novel approach for dealing with adversarial examples from a security standpoint -- namely, build an independent system to detect the adversary so a human might intervene in those cases.   A potential confound of this approach is that an adversary might respond by constructing adversarial examples to fool *both* the original classifier and the new detector. If that were possible, then this approach is moot since an attacker could always outwit the original system. To their credit, the authors show that building a 'dynamic' detector to detect adversarial examples but also be resilient to an adversary mitigates this potential escalation (worse case from 55% to 70% detection rate). Even though the 'dynamic' detector  demonstrates positive gains, I am concerned about overall scores. Detecting adversarial examples at this rate would not be a reliable security procedure.  My second comment is about 'model transferability'. My definition of 'model transferability' is different then the one used in the paper. My definition means that one constructs an adversarial example on one network and measures how well the adversarial examples attack a second trained model -- where the second model has been trained with different initial conditions. (The author's definition of 'transferability' is based on seeing how well the detector generalizes across training methods). 'Model transferability' (per my definition) is quite important because it measures how general an adversarial example is across all models -- and not specific to a given trained model. Different methods have different levels of 'model transferability' (Kurakin et al, 2016) and I am concerned how well the detector they built would be able to detect adversarial examples across *all models* and not just the trained model in question. In other words, a good detector would be able to detect adversarial examples from any network and not just one particularly trained network. This question seems largely unaddressed in this paper but perhaps I missed some subtle point in their descriptions.  Minor comments:  If there were any points in the bottom-left of the Figure 2 left, then this would be very important to see -- perhaps move the legend to highlight if the area contains no points.  - X-axis label is wrong in Figure 2 right.  Measure the transferability of the detector?  - How is \\sigma labeled on Figure 5?  - Whenever an image is constructed to be an 'adversary', has the image actually been tested to see if it is adversarial? In other words, does the adversarial image actually result in a misclassification by the original network?",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es un trabajo bien hecho sin lugar a dudas, el autor dice que hace una contrastación en varias organizaciones sobre el tema.  Faltan antecedentes en relación a los ERP investigados. El modelo que él plantea no es novedoso, es más bien lógico y práctico. Es una investigación normal y su aporte es regular. Creo que un análisis cómo este requiere un análisis más profundo en aspectos económicos y financieros, porque las decisiones para la adquisición de este tipo de herramientas son: operacionales, económicas y financieras.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta una encuesta a dos mineras sobre la etapa de arquitectura del proceso de outsourcing de TI. El trabajo es exploratorio y por lo tanto su contribución es reducida ya que aún no se presentan resultados. Creo que en este estado es inadecuado para la conferencia donde se espera la presentación de resultados y contribuciones a la investigación. El documento debe ser mejorado en cuanto a su redacción.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Se presenta la necesidad de usar Objetos de Aprendizaje (OA) para la enseñanza del curso \"Introducción a la Teoría de Autómatas\". Sin embargo es muy poca la información dedicada en el artículo a los OA elegidos para el curso, no hay información de resultados de su aplicación ni sus consecuencias (resultados de aprendizaje, encuesta a los alumnos para validarlo, etc.). Es por ello que no se recomienda aceptar el artículo, salvo que se agregue información que respalde la aplicación de OA en este curso.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper essentially presents a new inductive bias in the architecture of (convolutional) neural networks (CNN). The mathematical motivations/derivations of the proposed architecture are detailed and rigorous. The proposed architecture promises to produce equivariant representations with steerable features using fewer parameters than traditional CNNs, which is particularly useful in small data regimes. Interesting and novel connections are presented between steerable filters and so called “steerable fibers”. The architecture is strongly inspired by the author’s previous work, as well as that of “capsules” (Hinton, 2011). The proposed architecture is compared on CIFAR10 against state-of-the-art inspired architectures (ResNets), and is shown to be superior particularly in the small data regime. The lack of empirical comparison on large scale dataset, such as ImageNet or COCO makes this largely a theoretical contribution. I would have also liked to see more empirical evaluation of the equivariance properties. It is not intuitively clear exactly why this architecture performs better on CIFAR10 as it is not clear that capturing equivariances helps to classify different instances of object categories. Wouldn’t action-recognition in videos, for example, not be a better illustrative dataset?",
            "output": [
                "en"
            ]
        },
        {
            "input": "This nicely written paper presents an end-to-end learning method for image compression. By optimizing for rate-distortion performance and a clever relaxation the method is able to learn an efficient image compression method by optimizing over a database of natural images.  As the method is interesting, results are interesting and analysis is quite thorough it's easy for me to recommend acceptance.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Comentarios generales: • Se recomienda revisar todo el escrito ya que hay palabras de más o palabras escritas de manera equivocada por ejemplo: imcompletas, ítemes (pag 3);  quedebe (pag 4), del de (pag 5)… etc • Revisar el espaciado de las palabras • Revisar la numeración de la bibliografía ya que tiene que ser listada en el orden en que ésta aparece. • Revisar que el texto sea del mismo tamaño  (ejemplo: final primera columna página 1)  Comentarios por secciones  II SCRUM YSPEM • Referenciar la parte dedicada a SCRUM así como la figura ya que no es propia de los autores si no tomada de alguien más  III LEVANTAMIENTO DE REQUERIMIENTOS UTILIZANDO SPEM • Revisar el concepto de stakeholder o referenciar de que referencia utilizó ese concepto, por ejemplo incluyo los conceptos de stakeholder para CMMI. “Parte interesada (stakeholder) Un grupo o individuo que se ve afectado por o es de alguna manera responsable del resultado de una empresa” “Parte interesada (stakeholder) Un grupo o individuo que se ve afectado por o es de alguna manera responsable del resultado de una empresa”  IV DESARROLLO DE SOFTWARE CON SCRUM • Título de Figura 5, puede mejorarse el título de la figura por ejemplo: modelo del proceso de desarrollo de software basado en SCRUM y utilizando SPEM para su modelado • Se recomienda reforzar la sección agregando referencias para los términos  V METRICAS PARA DEFINIR LA CALIDAD DEL DESARROLLO DEL SOFTWARE • Se recomienda agregar referencias cuando describe los conceptos de métricas  VI UN CASO PRÁCTICO • Se recomienda mejorar la descripción de la Tabla I (contenido de columnas y operación u operaciones llevadas a cabo para establecer las desviaciones estándar de peso y evaluación) • Hay una viñeta sin texto debajo de la Tabla 1 • Se recomienda apoyar la sección con una gráfica o tabla en la que se muestra un resumen de la medición de la calidad, para entender la medición “just in time” de la que habla en las conclusiones",
            "output": [
                "es"
            ]
        },
        {
            "input": "Es un buen artículo, y los autores son investigadores con bastante experiencia en el tema. Se recomienda su aceptación en su forma actual.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El presente paper realiza una categorización de formas de integrar reglas de negocio en un diseño utilizando el paradigma orientado a aspectos y propone una plantilla de documentación para reglas de negocio basado en dicha categorización.  El paper entrega información útil sobre el problema en particular, así como una categorización razonable de diferentes aspectos en este problema. Es un buen punto de partida para una investigación en esa línea.  Aunque la información entregada en el paper es de suma relevancia para una investigación en este tema, es insuficiente para aceptarlo como un trabajo completo y autocontenido. La razón es que el paper se enfoca en identificar problemas y proponer un artefacto (la plantilla) que debería resolver dichos problemas. Sin embargo no presenta evidencias de por qué esta plantilla es una buena alternativa para resolver dichos problemas. Para ello se requieren los elementos mencionados en el trabajo futuro, específicamente la especificación formal y la herramienta automática para crear plantillas y mapearlas a AOP.  Mi sugerencia es esperar a que estos elementos estén listos para completar este paper y enviarlo a una nueva conferencia.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Approaches like adaptive dropout also have the binary mask as a function of input to a neuron very similar to the proposed approach. It is not clear, even from the new draft, how the proposed approach differs to Adaptive dropout in terms of functionality. The experimental validation is also not extensive since comparison to SOTA is not included.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This is a solidly executed paper that received good reviews. However, the originality is a bit lacking. In addition, the paper would have been stronger with a comparison to the method proposed in Zweig et al. (2013). We recommend this paper for the workshop.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper presents a simple but effective approach for pruning ConvNet filters with extensive evaluation using several architectures on ImageNet and CIFAR-10.",
            "output": [
                "en"
            ]
        },
        {
            "input": "this proposes a multi-view learning approach for learning representations for acoustic sequences. they investigate the use of bidirectional LSTM with contrastive losses. experiments show improvement over the previous work.  although I have no expertise in speech processing, I am in favor of accepting this paper because of following contributions: - investigating the use of fairly known architecture on a new domain. - providing novel objectives specific to the domain - setting up new benchmarks designed for evaluating multi-view models  I hope authors open-source their implementation so that people can replicate results, compare their work, and improve on this work.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este artículo presenta para medir la calidad de los procesos de software. El título ya fue algo que me sorprendió. Existen miles de debates en qué se entiende por calidad en los procesos de software y los autores no concretan cuáles son la base de la que parten. Además, la clasificación que hacen en los apartados desde las etapas de desarrollo, los procesos de desarrollo es algo de lo que existen muchas alternativas en la literatura y los autores se centran en una que parecen dar o tomar como el referente más adecuado. La visión práctica en el caso concreto de INAPI sí que es de interés pero creo que hubiera sido más importante el decir porqué se aplican las cosas que intentar definir una visión global y como estándar de los conceptos con los que trabajo. Por otro lado, hay otras propuestas metodológicas para aplicar 9001 en el contexto del software. Creo que habría que potenciar de manera más adecuada el que se defienda qué aporta esta en realidad.",
            "output": [
                "es"
            ]
        },
        {
            "input": "From my original comments:  The results looks good but the baselines proposed are quite bad.  For instance in the table 2 \"Misclassification rate for a 784-1024-1024-1024-10 \" the result for the FC with floating point is 1.33%. Well far from what we can obtain from this topology, near to 0.8%. I would like to see \"significant\" compression levels on state of the art results or good baselines. I can get 0,6% with two FC hidden layers...  In CIFAR-10 experiments, i do not understand  why \"Sparsely-Connected 90% + Single-Precision Floating-Point\" is worse than \"Sparsely-Connected 90% + BinaryConnect\". So it is better to use binary than float.   Again i think that in the experiments the authors are not using all the techniques that can be easily applied to float but not to binary (gaussian noise or other regularizations). Therefore under my point of view the comparison between float and binary is not fair. This is a critic also for the original papers about binary and ternary precision.   In fact with this convolutional network, floating (standard) precision we can get lower that 9% of error rate. Again bad baselines.  ----  The authors reply still does not convince me.  I still think that the same technique should be applied on more challenging scenarios.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Trabajo muy mal presentado, con severos errores de ortografía y redacción. Pese al tema, interesante, no es posible encontrar un hilo adecuado en el desarrollo del trabajo.  Desde el inicio surgen los problemas, en el resumen se afirma que \"el objetivo de este artículo es la realización de un análisis a un conjunto de registros de diagnósticos médicos, puestos a manera de investigación, en busca de una mejor perspectiva y visualización de los datos para responder a los indicadores que se plantearon\" Primero, el objetivo del artículo no es la realización del análisis, sino mostrar el resultado de algún proceso (el proceso puede ser el análisis).La frase \"puestos a manera de investigación\" es del todo inadecuada.  No se responde a los indicadores..., ¿qué sentido tiene eso?  Las citas en itálico incluyen a los autores; faltó apoyo de alguien más experimentado en la escritura del artículo.  Lamentablemente, el trabajo está plagado de errores inaceptables.  No sólo de escritura.  La página 3 indica que uno de los problemas encontrados dice relación con la \"Estructuración de datos\". ¿Cuál es el problema? ¿Por qué se produce? ¿Cómo lo enfrenta el autor? ¿Es satisfactorio su enfoque?  Creo que esos antecedentes (que se repiten de manera similar en toda la extensión del texto), justifican mi rechazo.  Resumiendo, es muy pobre el trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper introduces a polynomial linear model for supervised classification tasks. The model is based on a combination of the Tensor Train (TT) tensor decomposition method and a form of stochastic Riemannian  optimization. A few empirical experiments are performed that demonstrate the good performance of the proposed model relative to appropriate baselines.  From a theoretical standpoint, I think the approach is interesting and elegant. The main machinery underlying this work are the TT decomposition and the geometric structure of the manifold of tensors with fixed TT-rank, which have been established in prior work. The novelty of this paper is in the combination of this machinery to form an efficient polynomial linear model. As such, I would have hoped that the paper mainly focused on the efficacy of this combination and how it is superior to obvious alternatives. For example, I would have really appreciated seeing how FMs performed when optimized over the manifold of positive definite matrices, as another reviewer mentioned. Instead, there is a bit too much effort devoted to explaining prior work.  I think the empirical analysis could be substantially improved. I am particularly puzzled by the significant performance boost obtained from initializing with the ordinary logistic regression solution. I would have liked some further analysis of this effect, especially whether or not it is possible to obtain a similar performance boost with other models. Regarding the synthetic data, I think an important baseline would be against a vanilla feed forward neural network, which would help readers understand how complicated the interactions are and how difficult the dataset is to model. I agree with the previous reviewer regarding a variety of other possible improvements to the experimental section.  A few typos: 'Bernoulli distrbution', 'reproduce the experiemnts', 'generilize better'.  Overall, I am on the fence regarding this paper. The main idea is quite good, but insufficient attention was devoted to analyzing the aspects of the model that make it interesting and novel.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Me ha gustado mucho  Lo dejaría tal cual.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Se recomienda mejorar los aspectos de redacción tales como:  - Corregir y tener cuidado con la redacción del abstract en inglés. - La figura 1 es ilegible y se encuentra parcialmente cubierta por una tabla. - La justificación necesita ser re-escrita, no queda claro el propósito del trabajo. - La tabla 1 se encuentra cortada, debe estar en una sola página. - Entre la tabla 2 y la tabla 3 el texto no se encuentra justificado. - Figura 3, 4 y 5 se encuentran cortadas.  Problemas de fondo:  - Las teorías del dominio son muy extensas y no aportan a la problemática propuesta por el trabajo. - La aplicación posee serios problemas de usabilidad, entre ellos el contraste entre el texto y el fondo de la aplicación. Se recomienda estudiar un poco de [Link] - No se describe la tecnología utilizada para el desarrollo de la aplicación, pero al parecer es HTML. Para este tipo de aplicaciones el desarrollo debería ser nativo. - Se esperaba una evaluación de la utilización de la misma por parte de los usuarios. - Las conclusiones no hacen referencia expresa a la construcción y resultados obtenidos al utilizar la aplicación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El formato simplemente pésimo, la redacción deja también bastante que desear, las figuras borrosas, tablas escaneadas de algún lugar sin referencia. El contenido no existe. Este debe ser uno de los artículos más malos que he visto en mi vida,",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors agree with the reviewers that this manuscript is not yet ready.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:  This paper presents a sophisticated application of Grid-type Recurrent Neural Nets to the task of determining predicate-argument structures (PAS) in Japanese.  The approach does not use any explicit syntactic structure, and outperforms the current SOA systems that do include syntactic structure.  The authors give a clear and detailed description of the implementation and of the results.  In particular, they pay close attention to the performance on dropped arguments, zero pronouns, which are prevalent in Japanese and especially challenging with respect to PAS. Their multi-sequence model, which takes all of the predicates in the sentence into account, achieves the best performance for these examples.  The paper is detailed and clearly written.  - Weaknesses:  I really only have minor comments. There are some typos listed below, the correction of which would improve English fluency. I think it would be worth illustrating the point about the PRED including context around the \"predicate\" with the example from Fig 6 where the accusative marker is included with the verb in the PRED string.  I didn't understand the use of boldface in Table 2, p. 7.  - General Discussion:  Typos:  p1 :  error propagation does not need a \"the\", nor does \"multi-predicate interactions\" p2: As an solution -> As a solution, single-sequence model -> a single-sequence model,                    multi-sequence model -> a multi-sequence model  p. 3 Example in Fig 4.                    She ate a bread -> She ate bread. p. 4 assumes the independence -> assumed independence, the multi-predicate interactions -> multi-predicate interactions, the multi-sequence model -> a multi-sequence model p.7: the residual connections -> residual connections, the multi-predicate interactions -> multi-predicate interactions (twice) p8 NAIST Text Corpus -> the NAIST Text Corpus, the state-of-the-art result -> state-of-the-art results  I have read the author response and am satisfied with it.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Thank you for an interesting read.  Given the huge interest in generative modelling nowadays, this paper is very timely and does provide very clear connections between methods that don't use maximum likelihood for training. It made a very useful observation that the generative and the discriminative loss do **not** need to be coupled with each other. I think this paper in summary provides some very useful insights to the practitioners on how to select the objective function to train the implicit generative model.  The only reason that I decided to hold back my strong acceptance recommendation is that I don't understand the acceptance criteria of ICLR. First this paper has the style very similar to the Sugiyama et al. papers that are cited (e.g. presenting in different perspectives that were all covered in those papers but in a different context), making me unsure about how to evaluate the novelty. Second this paper has no experiment nor mathematical theorem, and I'm not exactly sure what kinds of contributions the ICLR committee is looking for.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper presents a method to learn graph embeddings in a unsupervised way using random walks. It is well written and the execution appears quite accurate. The area of learning whole graph representations does not seem to be very well explored in general, and the proposed approach enjoys having very few competitors.  In a nutshell, the idea is to linearize the graph using random walks and to compute the embedding of the central segment of each walk using the skip-thought criterion. Being not an expert in biology, I can not comment whether or not this makes sense, but the gains reported in Table 2 are quite significant.   An anonymous public comment compared this work to a number of others in which the problem of learning representations of nodes is considered. While this is arguably a different goal, one natural baseline would be to pool these representations using mean- or max- pooling. It would very interesting to do such a comparison, especially given that the considered approach heavily relies on pooling (see Figure 3(c))  To sum up, I think it is a nice paper, and with more baselines I would be ready to further increase the numerical score.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:  This paper tackles an interesting problem and provides a (to my knowledge) novel and reasonable way of learning and combining cognitive features with textual features for sentiment analysis and irony detection. The paper is  clearly written and organized, and the authors provided a lot of useful detail and informative example and plots. Most of the results are convincing, and the authors did a good job comparing their approach and results with previous work.  - Weaknesses:  1. Just from the reading abstract, I expected that the authors' approach would significantly outperform previous methods, and that using both the eye-gaze and textual features consistently yields the best results. Upon reading the actual results section, however, it seems like the findings were more mixed. I think it would be helpful to update the abstract and introduction to reflect this.  2. When evaluating the model on dataset 1 for sentiment analysis, were the sarcastic utterances included? Did the model do better on classifying the non-sarcastic utterances than the sarcastic ones? 3. I understand why the eye-movement data would be useful for sarcasm detection, but it wasn't as obvious to me why it would be helpful for (non-sarcastic) sentiment classification beyond the textual features.   - General Discussion:  This paper contains a lot of interesting content, and the approach seems solid and novel to me. The results were a little weaker than I had anticipated from the abstract, but I believe would still be interesting to the larger community and merits publication.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:  This paper proposes to apply NLP to speech transcripts (narratives and descriptions) in order to identify patients with MCI (mild cognitive impairment, ICD-10 code F06.7). The authors claim that they were able to distinguish between healthy control participants and patients with MCI (lines 141-144). However in the conclusion, lines 781-785, they say that “… accuracy ranging from 60% to 85% …. means that it is not easy to distinguish between healthy subjects and those with cognitive impairments”. So the paper beginning is more optimistic than the conclusion but anyway the message is encouraging and the reader becomes curious to see more details about what has been actually done.  The corpus submitted in the dataset is constructed for 20 healthy patients and 20 control participants only (20+20), and it is non-understandable for people who do not speak Portuguese. It would be good to incorporate more technological details in the article and probably to include at least one example of a short transcript that is translated to English, and eventually a (part of a) sample network with embeddings for this transcript.  - Weaknesses:  The paper starts with a detailed introduction and review of relevant work. Some of the cited references are more or less NLP background so they can be omitted e.g. (Salton 1989) in section 4.2.3. Other references are not directly related to the topic e.g. “sentiment classification” and “pedestrian detection in images”, lines 652-654, and they can be omitted too. In general lines 608-621, section 4.2.3 can be shortened as well etc. etc. The suggestion is to compress the first 5 pages, focusing the review strictly on the paper topic, and consider the technological innovation in more detail, incl. samples of English translations of the ABCD and/or Cindarela narratives.  The relatively short narratives in Portuguese esp. in ABCD dataset open the question how the similarities between words have been found, in order to construct word embeddings. In lines 272-289 the authors explain that they generate word-level networks from continuous word representations. What is the source for learning the continuous word representations; are these the datasets ABCD+Cinderella only, or external corpora were used? In lines 513-525 it is written that sub-word level (n-grams) networks were used to generate word embeddings. Again, what is the source for the training? Are we sure that the two kinds of networks together provide better accuracy? And what are the “out-of-vocabulary words” (line 516), from where they come?  - General Discussion:  It is important to study how NLP can help to discover cognitive impairments; from this perspective the paper is interesting. Another interesting aspect is that it deals with NLP for Portuguese, and it is important to explain how one computes embeddings for a language with relatively fewer resources (compared to English).   The text needs revision: shortening sections 1-3, compressing 4.1 and adding more explanations about the experiments. Some clarification about the NURC/SP N. 338 EF and 331 D2 transcription norms can be given.  Technical comments:  Line 029: ‘… as it a lightweight …’ -> shouldn’t this be ‘… as in a lightweight …’  Line 188: PLN -> NLP  Line 264: ‘out of cookie out of the cookie’ – some words are repeated twice   Table 3, row 2, column 3: 72,0 -> 72.0  Lines 995-996: the DOI number is the same as the one at lines 1001-1002; the link behind the title at lines 992-993 points to the next paper in the list",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper describes an approach to learning the non-linear activation function in deep neural nets.  This is achieved by representing the activation function in a basis of non-linear functions and learning the coefficients.  Authors use Fourier basis in the paper.  A theoretical analysis of the proposed approach is also presented, using algorithmic stability arguments, to demonstrate good generalization behavior (vanishing generalization error with large data sets) of networks with learnt non-linearities.  The main question I have about this paper is that writing a non-linear activation function as a linear or affine combination of other non-linear basis functions is equivalent to making a larger network whose nodes have the basis functions as non-linearities and whose weights have certain constraints on them.  Thus, the value of the proposed approach of learning non-linearities over optimizing network capacity for a given task (with fixed non-linearities) is not clear to me.  Or could it be argued that the constrained implied by learnt non-linearity approach are somehow good thing to do?  Another question - In the two stage training process for CNNs, when ReLU activation is replaced by NPFC(L,T), is the NPFC(L,T) activation initialized to approximate ReLU, or is it initialized using random coefficients?  Few minor corrections/questions: - Pg 2. “ … the interval [-L+T, L+T] …” should be “ … the interval [-L+T, L-T] … “ ? - Pg 2., Equation for f(x), should it be “ (-L+T) i \\pi x / L “ in both sin and cos terms, or without “ x “ ? - Theorem 4.2 “ … some algorithm \\eps-uniformly stable …” remove the word “algorithm” - Theorem 4.5.  SGM undefined",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta el diseño de un Datamart para el registro de diagnósticos médicos. Además, presenta resultados \"genéricos\" de lo realizado.  No se visualiza una nueva propuesta, sino una experiencia práctica, que utiliza registros médicos de Practice Fusion, una comunidad de historial clínico electrónico. Presenta el artículo indicando que es muy común usar los métodos del paper en empresas de rubro comercial, y ahora la \"propuesta\" sería aplicarlos al área de salud. Sin embargo, lo más probable es que para el área de salud ya se haya considerado un trabajo similar.  Tampoco considera una situación real, para ver el resultado de su aplicación, lo cual podría haber sido más interesante.  Las Referencias 7 a la 11 no son usadas en el texto.  Otras observaciones menores: - Cambiar \"Palabras Claves\" por \"Palabras Clave\" - Hace referencia a \"indicadores clave\" e \"indicadores claves\" (la primera es la correcta) - No hace referencia a figuras en el texto. - Corregir \"a al peso\", \"restringen a base\", \"indicadores plateados\", \"donde existente\" - Cambiar \"REFERENCES\" por \"REFERENCIAS\".",
            "output": [
                "es"
            ]
        },
        {
            "input": "This work gives expected results and creates a structure for further research. I would suggest in addition of compass the use of radio waves for improving localization (WiFi for indoor and GPS for outdoor). In addition, there are some low cost platforms in the market that can be used and study, as for example Ardupilot or other similar systems. I was unable to see clearly enough, in the paper, the use of the camera; algorithms, environment settings, etc.; used for following robot. In Figure 7, it seems that camera trajectory is worse than that calculated with odometry, perhaps due to orientation error, but in my opinion it is not very clear during reading. Finally, I would suggest think if is it there some possible feedback of EKF results to odometry in order to reduce its error.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper presents a general approach to modeling for natural language understanding problems with two distinct textual inputs (such as a question and a source text) that can be aligned in some way. In the approach, soft attention is first used to derive alignments between the tokens of the two texts, then a comparison function uses the resulting alignments (represented as pairs of attention queries and attention results) to derive a representations that are aggregated by CNN into a single vector from which an output can be computed. The paper both presents this as an overall modeling strategy that can be made to work quite well, and offers a detailed empirical analysis of the comparison component of the model.  This work is timely. Language understanding problems of this kind are a major open issue in NLP, and are just at the threshold of being addressable with representation learning methods. The work presents a general approach which is straightforward and reasonable, and shows that it can yield good results. The work borders on incremental (relative to their earlier work or that of Parikh et al.), but it contributes in enough substantial ways that I'd strongly recommend acceptance.  Detail:  - The model, at least as implemented for the problems with longer sequences (everything but SNLI), is not sensitive to word order. It is empirically competitive, but this insensitivity places a strong upper bound on its performance. The paper does make this clear, but it seems salient enough to warrant a brief mention in the introduction or discussion sections. - If I understand correctly, your attention strategy is based more closely on the general/bilinear strategy of Luong et al. '15 than it is on the earlier Bahdanau work. You should probably cite the former (or some other more directly relevant reference for that strategy). - Since the NTN risks overfitting because of its large number of parameters, did you try using a version with input dimension l and a smaller output dimension m (so an l*l*m tensor)? - You should probably note that SubMultNN looks a lot like the strategy for *sentence*-level matching in the Lili Mou paper you cite. - Is there a reason you use the same parameters for preprocessing the question and answer in (1)? These could require different things to be weighted highly.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- El artículo describe varios enfoques para elaborar requisitos, y aplica uno de ellos (GAIA) a la construcción de sistemas multi-agentes (MAS).  - La Introducción es larguísima y cubre muchos temas; debería ser dividida en varias secciones, y dejar en Introducción sólo el contexto general y descripción del resto del artículo. - No hay un ejemplo para ilustrar la técnica, que es descrita en 1,5 páginas, siendo lo esencial de la contribución. - No hay validación de tipo alguno.",
            "output": [
                "es"
            ]
        },
        {
            "input": "*** Paper Summary ***  This paper applies adversarial and virtual adversarial training to LSTM for text classification. Since text inputs are discrete adversarial perturbation are applied to the (normalized) word embeddings. Extensive experiments are reported and demonstrate the advantage of these methods.  *** Review Summary ***  The paper reads well and has sufficent references. The application of adversarial training to text data is a simple but not trivial extension. The experimental section presents extensive experiments with comparison to alternative strategies. The proposed method is simple and effective and can be easily be applied after reading the paper.  *** Detailed Review ***  The paper reads well. I have only a few comments regarding experiments and link to prior resarch:  Experiments:  - In Table 2 (and for other datasets as well), could you include an SVM baseline? e.g. S Wang and C Manning 2012? - As another baseline, did you consider dropping words, i.e. masking noise? It is generally better than dropout/gaussian noise for text application (e.g. denoising autoencoders)? - I am not sure I understand why virtual adversarial is worse than the baseline in Table 5. If you tune epsilon, in the worse case you would get the same performance as the baseline? Was it that validation was unreliable?  Related Work:  I think it would be interesting to point at SVM, transductive SVM who achieve something similar to adversarial training. When maximizing the margin in a (transductive) SVM, it is equivalent to move the example toward the decision boundary, i.e. moving them in the direction of increase of the loss gradient.  Also it would be interesting to draw a parallel between adversarial training and contrastive divergence. The adversarial samples are very close in nature to the one step Markov Chain samples from CD. See Bengio 2009. Related to this technique are also approaches that try to explicitely cancel the Jacobian at data points, e.g. Rifai et al 2011.  *** References ***  Marginalized Denoising Autoencoders for Domain Adaptation. Minmin Chen, K Weinberger. Stacked Denoising Autoencoders. Pascal Vincent. JMLR 2011. Learning invariant features through local space contraction, Salah Rifai, Xavier Muller, Xavier Glorot, Gregoire Mesnil, Yoshua Bengio and Pascal Vincent, 2011. Learning Deep Architectures for AI, Yoshua Bengio 2009 Large Scale Transductive SVMs. Ronan Collobert et al 2006 Optimization for Transductive SVM.  O Chapelle, V Sindhwani, SS Keerthi JMLR 2008",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta una implementación simple de una BD para redes espaciales desarrollada con un SGBD open source. Describe previamente, de manera clara y adecuada la tecnología  y conceptos utilizados en este contexto de las redes espaciales. Plantea una metodología estándar para el desarrollo de una BD y modelo E-R simple (Nota: en la figura 2 está mal configurado el texto). Luego describe las tablas generadas por el modelo indicando los tipos de archivos utilizados. Continúa señalando que se implementó el algoritmo de búsqueda INE pero no existe evidencia de esto y de su uso. Finalmente señala en la evaluación, que esta etapa no se pudo llevar a cabo. En las conclusiones no se expresa ningún tipo y sólo se limita a resumir el trabajo realizado. En síntesis, un trabajo simple de diseño de BD que no proporciona un aporte científico, sólo una implementación útil y novedosa de redes espaciales. Se recomienda potenciar aspectos que puedan entregar un aporte, como evaluar distintas tecnologías de BDE, desempeño del algoritmo de búsqueda INE v/s otros, etc. Existen errores de acentuación de algunas palabras a lo largo del texto.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors introduce a new memory model which allows memory access in O(log n) time.  Pros: * The paper is well written and everything is clear. * It's a new model and I'm not aware of a similar model. * It's clear that memory access time is an issue for longer sequences and it is clear how this model solves this problem.  Cons: * The motivation for O(log n) access time is to be able to use the model on very long sequences. While it is clear from the definition that the computation time is low because of its design, it is not clear that the model will really generalize well to very long sequences. * The model was also not tested on any real-world task.  I think such experiments should be added to show whether the model really works on long sequences and real-world tasks, otherwise it is not clear if this is a useful model.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The authors of this work propose a learnable approach to reducing the dimensionality of learned filters in deep neural networks. This is an interesting approach, but the presented work looks a bit raw.  1. There are many typos in this manuscript.  2. The experimental results are rather weak and don't show much improvement in accuracy. Instead the authors could position this work as a compression mechanism and would have to compare to low rank approximation of filters for DNNs. Yet this is not done.  3. Aside from compression, OMG can be viewed as a form of regularization to reduce the unnecessary capacity of the network to improve generalization. Again, this is not addressed in enough detail. 4. If the authors care to compare their approach to other 1-shot learning methods, then they would have to evaluate their approach with siamese and triplet learning networks. This isn't done.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The authors propose an approach to learning optimization algorithms by framing the problem as a policy search task, then using the guided policy search algorithm. The method is a nice contribution to the \"learning to learn\" framework, and actually was developed simultaneously to a few papers that have since already been published. It's definitely a useful addition to this space.    The biggest issue with this paper is that the results simply aren't that compelling. The methodology and proposed approach is nice, and the text is improved upon a previous version posted to Arxiv, but it seems that for most problems the results aren't that much better than some of the more common off-the-shelf optimization approaches that _don't_ require learning anything. Furthermore, in the one domain where the method does seem to (marginally) outperform the other methods, the neural net domain, it's unclear why we'd want to use the proposed approaches instead of SGD-based methods and their like (which of course everyone actually does for optimization).    Pros:  + Nice contribution to the learning to learn framework  + Takes a different approach from past (concurrent) work, namely one based upon policy search    Cons:  - Experiments are not particularly compelling    Overall, this work is a little borderline. Still, the PCs have determined that it was deserving of appearing at the conference. We hope the authors can strengthen the empirical validation for the camera ready version.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The topic of the paper, model-based RL with a learned model, is important and timely. The paper is well written. I feel that the presented results are too incremental. Augmenting the frame prediction network with another head that predicts the reward is a very sensible thing to do. However neither the methodology not the results are novel / surprising, given that the original method of [Oh et al. 2015] already learns to successfully increment score counters in predicted frames in many games.  I’m very much looking forward to seeing the results of applying the learned joint model of frames and rewards to model-based RL as proposed by the authors.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo es una revisión del estado del arte sobre el procesado 3D desde una nube de puntos. Para ser una revisión del estado del arte se presentan pocos artículos relacionados al tema. No se entrega una descripción clara del procesamiento de la nube de puntos para la reconstrucción. En las aplicaciones faltan referencias asociadas, ya que existen muchos artículos relacionados a aplicaciones de reconstrucción de superficies.  El artículo tiene además algunos problemas de formato y redacción: párrafos no ajustados a ambos lados, abreviaturas que no se entienden (PCL)",
            "output": [
                "es"
            ]
        },
        {
            "input": "En cuanto a los aspectos generales, tres cosas: 1) los autores deberían de ser consistentes con la nomenclatura utilizada: principalmente requerimientos vs requisitos: por favor, utilicen solo una de las dos denominaciones, pero no mezclen a su antojo. 2) En segundo lugar, small settings (pequeños entornos) vs pequeñas y medianas empresas. Si van a la definición dada por el SEI, verán que no es lo mismo, siendo más amplio el concepto de small setting. En este caso creo que los autores se están refiriendo a pequeñas empresas. 3) Como tercer comentario, general, revisen los signos de puntuación, frases muy largos. En el resumen, los autores indican que van a ofrecer una propuesta de trabajo para pequeño entornos. No encuentro esa propuesta de trabajos en el artículo. Además, es mejor no poner referencias en el resumen. En la introducción, segundo párrafo, aparece \"ya que ésta permite garantizar DESDE ...\"  se espera un HASTA TAL COSA... En el apartado de proceso de revisión sistemática, no es necesario hacer una subsección, no tiene mucho sentido dividir una cosa en un solo apartado. En la subvención de fases de la revisión sistemática, primero dicen que hay 3 pasos y luego lo llaman fases. Cual de las dos es??? Los nombres dados a las fases, no coinciden con los de las secciones siguientes, ni tampoco con los de la Figura 1. La Figura 1 no aporta nada. En la sección de planificación, palabras como \"por sobre\" no son muy válidas en el lenguaje escrito. Igualmente en la planificación incluyen párrafos que justifican el porque de las PYMEs, esto está ya fuera de contexto aquí. Además indican que el objetivo de la revisión es encontrar modelos, metodologías, propuestas o procesos relacionados con la gestión de requerimientos. Bien, pues esto es lo que se espera que obtengan en los resultados de la revisión sistemática, Y esto, NO aparece apenas (solo aparece una lista de metodologías y poco mas). Además mezclan mejora de procesos software, con mejora de gestión de requerimientos. Luego indican que los resultados se miden por número de propuestas... cuando anteriormente han dicho otra cosa. Los apartados de la revisión no siguen fielmente las de Kitchenham, y Biolchini. Igualmente en la parte de \"cadena de búsqueda\" aparece \"es que\", que en el lenguaje escrito no queda bien. La lista de fuentes, ¿por qué aparece en la subvención de cadena de búsqueda? En la parte de revisión, la Tabla 3 y la Figura 2 son redundantes, si se añade una columna más a la tabla, indicando el porcentaje correspondiente, tenemos el mismo efecto. En la parte de Revisión, NO SE PUEDE DECIDIR INCLUIR SOLO LOS 20 PRIMEROS, entonces para qué hacemos la revisión sistemática???? Igualmente una solo subvención???. Cuáles son los 20 artículos que seleccionaron? ¿Dónde están referenciados? Igualmente pasa con la Figura 4 y la Tabla 4. Respecto a los Resultados, es de suponer que las referencias 18 a 29 son los artículos primarios??? En estos resultados solamente indican justificaciones relativas a la gestión de requerimientos, pero nada relativo a lo que indican en el objetivo de su revisión sistemática. En base a una referencia del año 2007, la 24, indican que no hada que trate la gestión de requerimientos en pequeñas empresas. Les indico solamente una tesis doctoral de la UPM de noviembre de 2013, titulada Metamodelo para la mejora del proceso de gestión de requisitos, cuyo autor es Ariel E. Serrano Rico y Director Jose A. Calvo-Manzano, para que vean que si existen cosas sobre gestión de requisitos. Aquí además es el único sitio donde indican una serie de metodologías.  Esto que se supone que es uno de los resultados esperados, solamente aparece en dos líneas del apartado de resultados. Luego añade una serie de factores clave, y de condiciones que parecen que aparecen por sí solas, sin ninguna referencia y que además no son el objetivo que dicen los autores respecto a la revisión que han hecho.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper aims to mine explicit rules from KB embedding space, and casts it into a sparse reconstruction problem. Experiments demonstrate its ability of extracting reasonable rules on a few link prediction datasets.  The solution part sounds plausible. However, it confuses me that why we need to mine rules from learned KB embeddings.   - It is still unclear what information these KB embeddings encode and it looks strange that we aim to learn rules including negation / disjunction from them.  - If the goal is to extract useful rules (for other applications), it is necessary to compare it to “graph random walk” (",
            "output": [
                "en"
            ]
        },
        {
            "input": "UPDATE:  I have read the authors' responses.  I did not read the social media comments about this paper prior to reviewing it.    I appreciate the authors' updates in response to the reviewer comments.  Overall, however, my review stands.  The authors have taken a task that had not yet been addressed with a straightforward modern deep learning approach, and addressed it with such an approach.  I assume that if we pick up any task that hasn't been worked on for a while, and give it a solid deep learning treatment, we will do well.  I do not see such papers as a contribution to ICLR, unless they also provide new insights, analysis, or surprising results (which, to my mind, this paper does not).  This is a general point and the program chairs may disagree with it, of course.  I have removed my recommendation that this be accepted as a workshop paper, as I have since noticed that the workshop track this year has a different focus.    ************************  ORIGINAL REVIEW:  The authors show that an appropriately engineered LSTM+CNN+CTC network does an excellent job of lipreading on the GRID corpus.  This is a nice result to know about--yet another example of a really nice result that one can get the first time one applies such methods to an old task--and all of the work that went into getting it looks solid (and likely involved some significant engineering effort).  However, this in itself is not sufficiently novel for publication at ICLR.  The paper also needs to be revised to better represent prior work, and ideally remove some of the vague motivational language.  Some specifics on what I think needs to be revised:  - First, the claim of being the first to do sentence-level lipreading.  As mentioned in a pre-review comment, this is not true.  The paper should be revised to discuss the prior work on this task (even though much of it used data that is not public).  Ideally the title should also be changed in light of this.  - The comparison with human lipreaders needs to be qualified a bit.  This task is presumably very unnatural for humans because of the unusual grammar, so perhaps what you are showing is that a machine can better take into account the strong contraints.  This is great, but not a general statement about LipNet vs. humans.  - The paper contains some unnecessary motivational platitudes.  We do not need to invoke Easton and Basala 1982 to motivate modeling context in a linguistic sequence prediction task, and prior work using older sequence models (e.g. HMMs) for lipreading has modeled context as well.  The McGurk effect does not show that lipreading plays a crucial role in human communication.  - It is worth noting that even without the spatial convolution, your Baseline-2D already does extremely well.  So I am not sure about the \"importance of spatiotemporal feature extraction\" as stated in the conclusion.  Some more minor comments, typos, etc.:  - citations for LSTMs, CTC, etc. should be provided the first time they are mentioned. - I did not quite follow the justification for upsampling. - what is meant by \"lip-rounding vowels\"?  They seem to include almost all English vowels. - Did you consider keeping the vowel visemes V1-V4 separate rather than collapsing them into one?  Since you list Neti et al.'s full viseme set, it is worth mentioning why you modified it. - \"Given that the speakers are British, the confusion between /aa/ and /ay/...\" -- I am not sure what this has to do with British speakers, as the relationship between these vowels exists in other English dialects as well (e.g. American). - The discussion about confusions within bilabial stops and within alveolar stops is a bit mismatched with the actual confusion data in Fig. 3(b,c).  For example, there does not seem to be any confusion between /m/ and /b/ or between /m/ and /p/. - \"lipreading actuations\":  I am not sure what \"actuations\" means in this context - \"palato-alvealoar\" --> \"palato-alveolar\" - \"Articulatorily alveolar\" --> \"Alveolar\"?",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo describe la navegación de un robot móvil utilizando ROS y el hardware Raspberry PI. La descripción cae en focalizarse en detalles de configuración, al punto de parecer un manual de instalación o puesta en marcha. No hay reporte de resultados, menos aún análisis de la solución propuesta. Dado lo anterior, y tal como se presenta no es un artículo para conferencia. Sólo un reporte de cómo utilizar y configurar la Raspberry PI.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper presents a layer architecture where a single parameter is used to  gate the output response of layer to amplify or suppress it. It is shown that such an architecture can ease optimization of a deep network as it is easy to learn identity mappings in layers helping in better gradient propagation to lower layers (better supervision).   Using an introduced SDI metric it shown that gated residual networks can most easily learn identity mappings compared to other architectures.   Although good theoretical reasoning is presented the observed experimental evidence of learned k values does not seem to strongly support the theory given that learned  k values are mostly very small and not varying much across layers. Also, experimental validation of the approach is not quite strong in terms of reported performances and number of large scale experiments.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper shows promising results but it is difficult to read and follow. It presents different things closely related and it is difficult to asses the performance of each one. Diversity, sparsity, regularization term, tying weights. Anyway results are good.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo es una buena idea Adolece de profundidad, se presenta muy someramente, no presenta una revisión de trabajos relacionados, no plantea el modelo y la red de sensores que va utilizar, por la redacción se estima que esta en un estado temprano de la investigación, falta desarrollo, ejemplo escenario de evaluación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo describe un conjunto de técnicas de extracción de datos principalmente encontradas en herramientas ETL, menciona las redes sociales que en principio señala como fuentes de datos para un estudio, pero que definitivamente no aplica o al menos no muestra su aplicación y resultados, lo mismo ocurre con las bases de datos NoSQL que menciona pero que se observa y describe un trabajo con ellas.  Si bien es cierto que se trata de una revisión, más parece un material docente para impartir una clase introductoria de ETL. Yo sugeriría aprovechar esta revisión preliminar para proponer una metodología de trabajo en redes sociales, además de establecer los pasos a seguir en este metodología para una extracción eficiente de datos desde los repositorios de redes sociales señaladas, quizás comparar el desempeño y utilidad de las técnicas en cada red social y evaluar que técnicas ETL son más apropiadas pero de manera empírica.  También se debe señalar que tiene algunos errores de redacción, repetición de artículos y palabras.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Revisar la redacción del documento, en varios sitios dice \"en base a\" debe ser \"con base en\"  Hace falta referenciar la fuente de las figuras 1 y 2.  En la página 8 el subtítulo debería estar completo \"Agentes Inteligentes\"  en la misma página 8 tilde en considerarán  En la página 10 indican que la lógica difusa es un enfoque basado en \"grados de verdad\" realmente es en \"grados de pertenencia\"  En la conclusión (4) ... e International...  El trabajo es interesante, considero que podría haberse condensado más la información de las 3 primeras páginas, quizá usar una tabla resumiendo todas las consideraciones en las búsquedas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Se propone un procedimiento para elaborar máquinas de estado con un dispositivo arduino, con el fin de eliminar posibles fallos usando la manera tradicional mediante circuitos integrados digitales, cableado y proto-board.  El artículo puede ser útil para enseñanza de electrónica digital y en algunas aplicaciones prácticas. El documento tiene varios errores, están indicados en el documento, sin embargo los autores deben corregir y revisar de nuevo el artículo completo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "In this paper authors propose a novel data augmentation scheme where instead of augmenting the input data, they augment intermediate feature representations.  Sequence auto-encoder based features are considered, and random perturbation, feature interpolation, and extrapolation based augmentation are evaluated. On three sequence classification tasks and on MNIST and CIFAR-10, it is shown that augmentation in feature space, specifically extrapolation based augmentation, results in good accuracy gains w.r.t. authors baseline.  My main questions and suggestions for further strengthening the paper are:  a) The proposed data augmentation approach is applied to a learnt auto-encoder based feature space termed ‘context vector’ in the paper.  The context vectors are then augmented and used as input to train classification models. Have the authors considered applying their feature space augmentation idea directly to the classification model during training, and applying it to potentially many layers of the model?  Also, have the authors considered convolutional neural network (CNN) architectures as well for feature space augmentation?  CNNs are now the state-of-the-art in many image and sequence classification task, it would be very valuable to see the impact of the proposed approach in that model.  b) When interpolation or extrapolation based augmentation was being applied, did the authors also consider utilizing nearby samples from competing classes as well?  Especially in case of extrapolation based augmentation it will be interesting to check if the extrapolated features are closer to competing classes than original ones.  c) With random interpolation or nearest neighbor interpolation based augmentation the accuracy seems to degrade pretty consistently.  This is counter-intuitive.  Do the authors have explanation for why the accuracy degraded with interpolation based augmentation?  d) The results on MNIST and CIFAR-10 are inconclusive.  For instance the error rate on CIFAR-10 is well below 10% these days, so I think it is hard to draw conclusions based on error rates above 30%.  For MNIST it is surprising to see that data augmentation in the input space substantially degrades the accuracy (1.093% -> 1.477%).  As mentioned above, I think this will require extending the feature space augmentation idea to CNN based models.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El articulo presenta un análisis sobre diagnósticos médicos (practice fusion) a través de un proceso de Inteligencia de Negocios (ETL - Datawarehouse - OLAP - KPI's) bien realizado. A diferencia del otro artículo de similares características de la UNAP, aquí queda claro que se trata de datos abiertos que han sido considerados para realizar el proceso de IN. Sin embargo, a diferencia del otro artículo, aquí las conclusiones están menos trabajadas y los resultados son menos claros, también el proceso ETL está más oculto y sólo se presenta a nivel de JOBS.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Los datos abiertos de Chile Este trabajo analiza de manera general un tema que ha adquirido real relevancia en los gobiernos a nivel mundial, los datos abiertos.  La problemática que aborda el artículo está sustentada adecuadamente en las necesidades que existen de proveer datos para evaluar la transparencia y el interés público. Se realiza una investigación aplicada a las principales plataformas web gubernamentales  en Chile. El objetivo está declarado por el autor  y establece que se  presenta el estado de los datos abiertos en Chile y se realiza un diagnóstico  de los principales sitios y herramientas provistas por el estado para mejorar la transparencia y potenciar la participación  ciudadana. La revisión bibliográfica es relevante al tema pero bastante general. El modelo que se utiliza para medir la calidad de los datos en la web  es elegido sin justificar a través de  un análisis que establezca su eficiencia en comparación a otros modelos.  La revisión que se realiza del concepto de datos abiertos es mínima y no está  presente en la revisión realizada como este tema ha sido abordado en diferentes países y  los resultados que han obtenido. Los autores deberían  profundizar más el concepto de datos abiertos a nivel gubernamental para transparencia y  el interés público y sustentar mejor esta división en la literatura. El aspecto metodológico del trabajo se  enfoca a utilizar el modelo de 5 estrellas y describir una clasificación general que se realiza en base a este modelo. Aunque este enfoque metodológico es adecuado y se asocia claramente a la temática no presenta proposiciones a evaluar (preguntas de investigación o hipótesis a testear). El diagnóstico es básico y general a partir de un cuatro variables que permiten clasificar a cada plataforma. El autor  debería establecer también una categorización de lo que son los  sujetos de estudio (se menciona al  de gobierno de Chile pero son solo cuatro plataformas del total de plataformas que posee el gobierno). En este sentido debería referirse a plataformas transversales de  servicio centrales (ya que no analiza gobiernos locales en ningún momento) Este trabajo  se sustenta en la utilización de un modelo de diagnóstico ya validado en la literatura  sin embargo su aplicación es limitada y a mi juicio no permite generalizar  para el gobierno en su totalidad.  La contribución del trabajo es importante ya que presenta información relevante en el proceso de llegar a lo que es el gobierno abierto. Sin embargo la generalización de sus resultados es cuestionable ya que  está limitada  a  cuatro variables y cuatro sitios web. En  las conclusiones no se reflejan  con toda claridad las principales  contribuciones del articulo y se sugiere a los autores mejorarlas  incluyendo aspectos relevantes a la temática evaluada (los sitios web), los aportes  al estudio del gobierno abierto en Chile y reconocer las limitaciones que tiene este estudio. Los aspectos formales del trabajo son satisfactorios para el congreso.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper aims to show new deployment alternative for recommender systems. To this end, the authors use two variations CHC genetic algorithm.  - It's a good job. - It is clear and very detailed.  - There are inconsistencies in the notation should be improved. The formula (7) has a notation different from the rest of the equations. - On the same point, the figure (3) refers to \"perfil\", \"pesos\", \"euclidiana\" and \"vecindad\"; these words aren't related with the text. - I think that the results shown in graphs would be more useful if they are shown in tables.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes the graph convolutional networks, motivated from approximating graph convolutions.  In one propagation step, what the model does can be simplified as, first linearly transform the node representations for each node, and then multiply the transformed node representations with the normalized affinity matrix (with self-connections added), and then pass through nonlinearity.  This model is used for semi-supervised learning on graphs, and in the experiments it demonstrated quite impressive results compared to other baselines, outperforming them by a significant margin.  The evaluation of propagation model is also interesting, where different variants of the model and design decisions are evaluated and compared.  It is surprising that such a simple model works so much better than all the baselines.  Considering that the model used is just a two-layer model in most experiments, this is really surprising as a two-layer model is very local, and the output of a node can only be affected by nodes in a 2-hop neighborhood, and no longer range interactions can play any roles in this.  Since computation is quite efficient (sec. 6.3), I wonder if adding more layers helped anything or not.  Even though motivated from graph convolutions, when simplified as the paper suggests, the operations the model does are quite simple.  Compared to Duvenaud et al. 2015 and Li et al. 2016, the proposed method is simpler and does almost strictly less things.  So how would the proposed GCN compare against these methods?  Overall I think this model is simple, but the connection to graph convolutions is interesting, and the experiment results are quite good.  There are a few questions that still remain, but I feel this paper can be accepted.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Resumen:  El trabajo muestra un modelo para medir el valor y buscar su trazabilidad. Se propone la co-creación de valor con el cliente como método de crear valor. Con el fin de analizar el aporte de la co-creación se introduce el concepto de trazabilidad. Luego explica una serie de variables propuestas para medir el valor co-creado bajo un modelo conceptual junto con otro modelo que permite la trazabilidad de los distintos aportes a través de enlaces. Finalmente se expone brevemente los resultados del modelo en un caso.  Evaluación:  Implementar tipos de co-creación es muy importante para las organizaciones actualmente. Es  interesante cómo el artículo mezcla la co-creación con la trazabilidad y propone maneras de medirla, presentando nuevas herramientas para la organización.  Lamentablemente el artículo posee grandes debilidades:  1) El alcance puede que no sea apropiado para un congreso como INFONOR.  2) Los resultados son breves y débilmente ejemplificados, lo que dificulta la comprensión de uso del modelo.  3) Podrían usarse más ejemplos con fines de facilitar la lectura.  4) El formato del paper tiene problemas.  Otros comentarios:  Se encuentran problemas de redacción: a)“Las organizaciones se comprometen con los consumidores en producir unos conceptos o unas ideas iniciales y utilizan los consumidores”  Abuso en la palabra consumidor  b)“se validó la el modelo de Arquetipos Sistémicos” pequeño error, claramente “la” está demás",
            "output": [
                "es"
            ]
        },
        {
            "input": "Justificación: Es un trabajo que no tiene mucha novedad, es un tema que se ha estudiado bastante, sobre todo los modelos gráficos. Estos conceptos están incorporados en las herramientas CASE, aun cuando en el documento no se presenta en profundidad. Tal vez un mayor aporte hubiese sido investigar los métodos formales y ampliar el análisis comparativo de métodos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This submission proposes to learn the word decomposition, or word to sub-word sequence mapping jointly with the attention based sequence-to-sequence model. A particular feature of this approach is that the decomposition is not static, instead, it also conditions on the acoustic input, and the mapping is probabilistic, i.e., one word may map to multiple sub-word sequences. The authors argue that the dynamic decomposition approach can more naturally reflect the acoustic pattern. Interestingly, the motivation behind this approach is analogous to learning the pronunciation mixture model for HMM based speech recognition, where the probabilistic mapping from a word to its pronunciations also conditions on the acoustic input, e.g.,  I. McGraw, I. Badr, and J. Glass, \"Learning lexicons form speech using a pronunciation mixture model,\" in IEEE Transactions on Audio, Speech, and Language Processing, 2013  L. Lu, A. Ghoshal, S. Renals, \"Acoustic data-driven pronunciation lexicon for large vocabulary speech recognition\", in Proc. ASRU   R. Singh, B. Raj, and R. Stern, \"Automatic generation of subword units for speech recognition systems,\"  in IEEE Transactions on Speech and Audio Processing, 2002  It would be interesting to put this work in the context by linking it to some previous works in the HMM framework.  Overall, the paper is well written, and it is theoretically convincing. The experimental study could be more solid, e.g., it is reasonable to have a word-level baseline, as the proposed approach lies in between the character-level and word-level systems. the vocabulary size of the WSJ si284 dataset is 20K at maximum, which is not very large for the softmax layer, and it is a closed vocabulary task. I guess the word-level system may be also competitive to the numbers reported in this paper. Furthermore, can you explain what is the computational bottleneck of the proposed approach? You downsampled the data by the factor of 4 using an RNN, and it still took around 5 days to converge. To me, it is a bit expensive, especially given that you only take one sample when computing the gradient. Table 2 is a little bit misleading, as CTC with language model and seq2seq with a language model model from Bahdanau et al. is much closer to the best number reported in this Table 2, while you may only get a very small improvement using a language model. Finally, \"O(5) days to converge\" sounds a bit odd to me.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Se propone la utilización de la metodología GAIA para la trazabilidad a los requisitos, el enfoque propuesto se basa en la capacidad social de los agentes para procesar conocimiento, percibir los cambios del entorno y comunicación. Se trata de una tarea compleja, pues en el desarrollo de software se emplean gran variedad de modelos y diagramas que facilitan la representación de del conocimiento, estos artefactos se modifican en el tiempo. Estos cambios vienen principalmente desde el usuario.  Se requiere profundizar en la aplicación práctica de la propuesta para evaluar de mejor manera el aporte científico y práctico.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Review: Multimodal Word Distributions  - Strengths:  Overall a very strong paper.  - Weaknesses: The comparison against similar approaches could be extended.  - General Discussion:  The main focus of this paper is the introduction of a new model for learning multimodal word distributions formed from Gaussian mixtures for multiple word meanings. i. e. representing a word by a set of many Gaussian distributions.  The approach, extend the model introduced by Vilnis and McCallum (2014) which represented word as unimodal Gaussian distribution. By using a multimodal, the current approach attain the problem of polysemy.  Overall, a very strong paper, well structured and clear. The experimentation is correct and the qualitative analysis made in table 1 shows results as expected from the approach.  There’s not much that can be faulted and all my comments below are meant to help the paper gain additional clarity.   Some comments:   _ It may be interesting to include a brief explanation of the differences between the approach from Tian et al. 2014 and the current one. Both split single word representation into multiple prototypes by using a mixture model.   _ There are some missing citations that could me mentioned in related work as :  Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space Neelakantan, A., Shankar. J. Passos, A., McCallum. EMNLP 2014 Do Multi-Sense Embeddings Improve Natural Language Understanding? Li and Jurafsky, EMNLP 2015 Topical Word Embeddings. Liu Y., Liu Z., Chua T.,Sun M. AAAI 2015  _ Also, the inclusion of the result from those approaches in tables 3 and 4 could be interesting.   _ A question to the authors: What do you attribute the loss of performance of w2gm against w2g in the analysis of SWCS?  I have read the response.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Falta sustento en la validación de la propuesta.  No existe ningún análisis sobre cómo esta propuesta mejora o complementa las técnicas tradicionales de trazabilidad de requisitos.  Me parece que proponer un código tan extenso en lugar de facilitar la trazabilidad, la hace más engorrosa, a menos que se utilice una herramienta de software que genere automáticamente estos códigos, aspecto que no se considera en la propuesta.  El caso de estudio presentado es meramente descriptivo, no hay un respaldo que permita validar si efectivamente se consiguieron mejoras respecto al uso de técnicas de trazabilidad tradicionales.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Ese trabajo muestra el procedimiento propuesto para la detección automática de fracturas en pozos. La metodología se ve novedosa e interesante. El artículo muestra bien la metodología y tiene una buena redacción, pero al finalizar el artículo falta una mejor presentación de los resultados en pozos reales.  No queda claro el aporte del artículo, primero indica que es la detección automática y en otra parte indica que es la modificación al algoritmo.  Debe mejorar la presentación de los resultados en pozos reales y compararlo con lo deseado y quizás con resultados de aplicar otras técnicas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposed a macro discourse structure scheme. The authors carried out a pilot study annotating a corpus consisting of 97 news articles from Chinese treebank 8.0. They then built a model to recognize the primary-secondary relations and 5 discourse relations (joint, elaboration, sequence, background, cause-result) in this corpus.  The paper is poorly written and I have difficulties to follow it. I strongly suggest that the authors should find a native English speaker to carefully proofread the paper. Regarding the content, I have several concerns:   1 The logic of the paper is not clear and justifiable:  1) what are \"logical semantics\" and \"pragmatic function\"(line 115-116)? I'd prefer the authors to define them properly.  2) macro discourse structure: there are some conflicts of the definition between macro structure and micro structure. Figure 4 demonstrates the combination of macro discourse structure and micro discourse structure. There, the micro discourse structure is presented *within paragraphs*. However, in the specific example of micro discourse structure shown in Figure 6, the micro-level discourse structure is *beyond the paragraph boundary* and captures the discourse relations across paragraphs. This kind of micro-level discourse structure is indeed similar to the macro structure proposed by the authors in Figure 5, and it's also genre independent. So, why can't we just use the structure in Figure 6? What's the advantage of macro discourse structure proposed in Figure 5? For me, it's genre dependent and doesn't provide richer information compared to Figure 6.  By the way, why sentence 6 and sentence 15 are missing in Figure 5? Is it because they are subtitles? But sentence 12 which is a subtitle is present there.  2 Corpus construction (section 4) is not informative enough: without a detailed example, it's hard to know the meaning of \"discourse topic, lead, abstract, paragraph topics (line 627-629)\". And you were saying you \"explore the relationships between micro-structure and macro-structure\", but I can't find the correspondent part.  Table 4 is about agreement study The authors claimed \"Its very difficult to achieve high consistence because the judgments of relation and structure are very subjective. Our measurement data is only taken on the layer of leaf nodes.\"--------> First, what are the leaf nodes? In the macro-level, they are paragraphs; in the micro-level, they are EDUs. Should we report the agreement study for macro-level and micro-level separately? Second, it seems for me that the authors only take a subset of data to measure the agreement. This doesn't reflect the overall quality of the whole corpus, i.e., high agreement on the leaf nodes annotation doesn't ensure that we will get high agreement on the non-leaf nodes annotation.  Some other unclear parts in section 4:  Table 4: \"discourse structure, discourse relation\" are not clear, what is discourse structure and what is discourse relation?  Table 5: \"amount of macro discourse relations\", still not clear to me, you mean the discourse relations between paragraphs? But in Figure 6, these relations can exist both between sentences and between paragraphs.  3 Experiments: since the main purpose of the paper is to provide richer discourse structure (both on macro and micro level), I would expect to see some initial results in this direction. The current experiment is not very convincing: a) no strong baselines; b) features are not clearly described and motivated; c) I don't understand why only a sub set of discourse relations from Table 6 is chosen to perform the experiment of discourse relation recognition.  In general, I think the paper needs major improvement and currently it is not ready for acceptance.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:  - Weaknesses: Many grammar errors, such as the abstract  - General Discussion:",
            "output": [
                "en"
            ]
        },
        {
            "input": "While I understand the difficulty of collecting audio data from animals, I think this type of feature engineering does not go in the right direction. I would rather see a model than learns the feature representation from data.  I would think it should be possible to collect a more substantial corpus in zoos / nature etc, and then train a generative model. The underlying learned feature representation could be then used to feed a classifier. I'm not familiar with the particularities of this task, it's hard to judge the improvements by using chirplets.",
            "output": [
                "en"
            ]
        },
        {
            "input": "After rebuttal:  Thanks for reporting the AlexNet results. The fact that they are not great is not so bad by itself, and as the authors mention, it would be interesting to understand why this happens. But the fact that these results  were not in the paper (and in fact still are not there) is disturbing. Moreover, some claims in the paper look wrong in the light of these results, for example: - \"This suggests that our gains stem from the CC-GAN method rather than the use of a better architecture.\" - \"Since discrimination of real/fake in-paintings is more closely related to the target task of object classification than extracting a feature representation suitable for in-filling, it is not surprising that we are able to exceed the performance of Pathak et al. (2016) on PASCAL classification.\"  These statements, and possibly other parts of the paper, have to be updated. I think the paper cannot be published in its current form. Perhaps after a revision.  -------- Initial review:  The paper demonstrates an application of generative adversarial networks (GAN) to unsupervised feature learning. The authors show that the representation learned by the discriminator of a conditional GAN trained for image inpainting performs well on image classification. As a side-effect, fairly convincing inpaintings are produced.  The proposed method combines two existing ideas: using the discriminator of a GAN as a feature learner [Radford et al. 2015] and performing unsupervised feature learning with image inpainting [Pathak et al. 2016]. Therefore conceptual novelty of the paper is limited. On the plus side, the authors implement their idea well and demonstrate state-of-the-art results on STL-10 and good results on Pascal VOC (although Pascal experiments are incomplete, see below). Overall, I am in the borderline mode, and I will gladly raise the score if the authors address my concerns regarding the experiments.  1) Experimental evaluation on Pascal VOC is not quite satisfactory. Comparison with prior work is unfair because the network architecture used by the authors (VGG) is different from the architecture used by all existing methods (AlexNet). It is great that the authors do not try to hide this fact in the paper, but I do not understand why the authors are not willing to simply run their method with AlexNet architecture, although two commenters asked them to do so. Such an experiment would strongly support authors’ claims. Current reasoning that “we thought it reasonable to use more current models while making the difference clear” is not convincing. It is great that better architectures lead to better results, but it is also very important to properly compare to prior work. On a related topic, Doersch et al. also tried using VGG architecture, would it be possible to compare to that? Yet another question: why are you not comparing to [Noroozi&Favaro, ECCV 2016] ? I would also like the authors to address the comment by Richard Zhang.  2) Qualitative inpainting results are incomplete: comparison with previous methods (for instance, [Pathak et al 2016]) is missing, and it is impossible to compare different versions of the proposed method because different images are used for different variants. I realize there may be too little space in the main paper to show all the results, but many more results should be shown in the supplementary material. Quantitative results are missing. Currently the inpainting results are just interesting pictures to look at, but they do not add as much to the paper as they could.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo presenta el procedimiento seguido para la digitalización del archivo histórico de la parroquia San Pedro de Coquimbo. El trabajo presenta una buena redacción, pero no presenta un aporte novedoso a la problemática planteada. Es un trabajo que podría ser presentado en el área de Educación en Ingeniería (Sochedi, Congreso Chileno de Educación Superior en Computación u otros afines), dándole la redacción de acuerdo a este tipo de congreso.  Los principales problemas del artículo, desde mi punto de vista son:  - La temática no es novedosa, ya que existe una organización que mantiene imágenes de este tipo de archivos ([Link]  - Muestra el procedimiento, pero no los resultados (cantidad de archivos indexados, horas-hombre utilizados en la digitalización, logros propuestos por la asignatura versus lo realmente logrado, problemas que debeieron resolver los alumnos,cuántas imágenes se devolvieron, etc)  - No indica cuál es la información relevante que se debe digitar por página.  - No indica la utilidad que le dieron los usuarios.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This work describes a gated attention-based recurrent neural network method for reading comprehension and question answering. This method employs a self-matching attention technique to counterbalance the limited context knowledge of gated attention-based recurrent neural networks when processing passages. Finally, authors use pointer networks  with signals from the question attention-based vector to predict the beginning and ending of the answer. Experimental results with the SQuAD dataset offer state-of-the-art performance compared with several recent approaches.   The paper is well-written, structured and explained. As far as I know, the mathematics look also good. In my opinion, this is a very interesting work which may be useful for the question answering community.  I was wondering if the authors have plans to release the code of this approach. From that perspective, I miss a bit of information about the technology used for the implementation (theano, CUDA, CuDNN...), which may be useful for readers.  I would appreciate if authors could perform a test of statistical significance of the results. That would highlight even more the quality of your results.  Finally, I know that the space may be a constraint, but an evaluation including some additional dataset would validate more your work.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Se presenta una aplicación que consiste en un sistema de vigilancia basado en cámaras ip y que puede ser monitoreado desde dispositivos móviles con android, donde el aporte del trabajo es crear un sistema centralizado para gestionar las cámaras. El paper muestra en detalle el diseño del sistema, lo cual puede ser de interés a la audiencia del congreso. El trabajo presenta algunos problemas en el formato: - presenta encabezados en cada página que parecen referenciar a que fue extraído o enviado a una revista, lo cual no se adecua al formato del workshop -muestra también fechas de envió y recepción, lo cual parece apunta en la misma dirección - presenta algunos problemas de redacción y sentido, como: \"También, a esto se suma la incomodidad el tener acceso de un computador\" \"presenta el desarrollo de un sistema de vídeo vigilancia con cámaras IP, que engloba las ¿¿desventajas?? antes nombradas\"  El paper debería arreglar los problemas en el formato para ser aceptado",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este paper involucra el desarrollo de una aplicación que simule el protocolo BB84, se aprecia un trabajo ordenado y sin duda la comprensión de algunos conceptos de la física cuántica que sustentan la criptografía cuántica como son el teorema de no-clonación y el principio de superposición y entrelazamiento es una labor que tiene sus méritos, además, se aprecia el uso de ingeniería de software en la construcción de la aplicación, lo cual es un aspecto muy positivo, pues generalmente cuando hay involucrado creación de software en áreas de conocimiento de frontera, se recurre al code-and-fix, con todas las desventajas que esto conlleva.  Yo creo que este manuscrito debería ser dirigido al área de criptografía y seguridad, en mi especialidad que es la computación en ambientes distribuidos no veo significativa relevancia y aporte del manuscrito, usar RMI según mi opinión no es una contribución per se, pues  RMI es fácil de usar si se maneja JAVA, sin embargo, no es interoperable ya que no soporta otros lenguajes de programación, además, los sistema basados en RMI a medida que crecen tienen un problema de rendimiento, mientras más crecen más lentos se tornan, por otro lado, según algunos puristas un sistema cliente/servidor no es un sistema distribuido, según otros el caso cliente/servidor es el caso más básico de computación distribuida, en fin, hablando estrictamente desde el área de computación distribuida no veo relevancia en esta área de este manuscrito, sin embargo, me parece que en otra área el paper podría ser pertinente, ya que es un trabajo ordenado, claro y bien escrito.  Yo no soy experto en el área de criptografía, pero hace unos años atrás en una oportunidad escuche en un seminario a un inglés hablar de criptografía cuántica y menciono una gran cantidad de simuladores y aplicaciones, incluso dijo tener aplicaciones que ya utilizaban criptografía cuántica entre varios kilómetros por medio de fibra óptica, entonces creo que lo mejor es evaluar este manuscrito en esa área y no en el área de grid/sistemas distribuidos, pues en esta área el paper según mi opinión no tiene aspectos originales, ya que usa aspectos triviales de los principios cliente/servidor.  Como ya lo he dicho anteriormente, el paper tiene más asuntos de física cuántica y criptografía que de computación distribuida, por lo cual abstrayéndome al área que me compete, veo el uso de una tecnología de ambiente distribuido usada como cliente/servidor, no interoperable y con restricciones de escalabilidad. Un aspecto positivo en el paper es que se aprecia el uso de ingeniería de software.  En lo que respecta al área de grid computing y sistemas distribuidos, el manuscrito no contiene aspectos relevantes, utiliza RMI para implementar un sistema cliente/servidor, sin obstante, RMI es fácil de usar y como buen paradigma conocido en computación, performance se contrapone con facilidad de usar, RMI no escapa a eso, porque es fácil de usar, pero no tiene escalabilidad.  El documento está bien presentado, quizás la tabla 2 y tabla 3 sería mejor fusionarlas utilizando filas como computador y en las columnas los detalles de la red, sobre todo si más que un esquema cliente/servidor se tiene por ejemplo, un anillo de distribución de claves cuánticas, con más de 2 computadores involucrados. Creo que presentado al área de criptografía y seguridad sería más pertinente.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper introduces a time dependent recommender system based on point processes parametrized by time dependent user and item latent representations. The later are modeled as coupled – autoregressive processes – i.e. the representation of a user/item changes when he interacts with an item/user, and is a function of both the user and the item representations before time t. This is called coevolution here and the autoregressive process is called recurrent NN. The model may also incorporate heterogeneous inputs. Experiments are performed on several datasets, and the model is compared with different baselines. There are several contributions in the paper: 1) modeling recommendation via parametrized point processes where the parameter dynamics are modeled by latent user/item representations, 2) an optimization algorithm for maximizing the likelihood of this process, with different technical tricks that seem to break its intrinsic complexity, 3) evaluation experiments for time dependent recommendation. The paper by the same authors (NIPS 2016) describes a similar model of continuous time coevolution, and a similar evaluation. The difference lies in the details of the model: the point process model is not the same and of the latent factor dynamic model is slightly different, but the modeling approach and the arguments are exactly the same. By the end, one does not know what makes this model perform better than the one proposed in NIPS, is it the choice for the process, the new parametrization? Both are quite similar. There is no justification on the choice of the specific form of the point process in the two papers. Did the authors tried other forms as well? The same remark applies for the form of the dynamical process: the non-linearity used for the modeling of the latent user/item vectors here is limited to a sigmoid function, which probably does not change much w.r.t. a linear model, but there is no evidence of the role of this non linearity in the paper. Note that there are some inconsistencies between the results in the two papers. Concerning the evaluation, the authors introduce two criteria. I did not get exactly how they evaluate the item recommendation: it is mentioned that at each time t, the model predicts the item the user will interact with. Do you mean, the next item the user will interact with after time t? For the time prediction, why is it a relevant metric for recommendation? A comparison of the complexity, or execution time of the different methods would be helpful. The complexity of your method is apparently proportional to #items*#users, what are the complexity limits of your methods. Overall, the paper is quite nice and looks technically sound, albeit many details are missing. On the other hand, I have a mixed feeling because of the similarity with NIPS paper. The authors should have make a better work at convincing us that this is not a marginal extension of previous work by the authors.  I was not convinced either by the evaluation criteria and there is no evidence that the model can be used for large datasets.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo realiza una reflexión sobre el estado actual y las posibles proyecciones de los métodos formales en el desarrollo de software.  Si bien la idea de realizar tal reflexión tiene un potencial interesante, el artículo queda corto en dos aspectos claves:  1. Hay muchísimas aseveraciones hechas en el documento que no tienen citas bibliográficas que las respalden, ni tampoco se desprenden de una deducción lógica a partir de premisas anteriores. Esto resta significativamente a la validez de los argumentos presentados. 2. Todas las aseveraciones presentadas en el documento que, según se interpreta, los autores quieren presentar como propias, son en realidad, problemas ampliamente conocidos en el área de métodos formales.  En resumen, el artículo no provee aseveraciones con evidencia suficiente o una línea argumentativa sólida, ni tampoco provee aseveraciones originales.  Por esos motivos considero que el artículo no es apto para ser publicado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "SUMMARY.  The paper propose a new scoring function for knowledge base embedding. The scoring function called TransGaussian is an novel take on (or a generalization of) the well-known TransE scoring function. The proposed function is tested on two tasks knowledge-base completion and question answering.  ----------  OVERALL JUDGMENT While I think this proposed work is very interesting and it is an idea worth to explore further, the presentation and the experimental section of the paper have some problems. Regarding the presentation, as far as I understand this is not an attention model as intended standardly in the literature. Plus, it has hardly anything to share with memory networks/neural Turing machines, the parallel that the authors try to make is not very convincing. Regarding the experimental section, for a fair comparison the authors should test their model on standard benchmarks, reporting state-of-the-art models. Finally, the paper lack of discussion of results and insights on the behavior of the proposed model.   ----------  DETAILED COMMENTS   In section 2.2 when the authors calculate \\mu_{context} do not they loose the order of relations? And if it is so, does it make any sense?",
            "output": [
                "en"
            ]
        },
        {
            "input": "El documento describe un trabajo exploratorio en el desarrollo de una aplicación software en el área de informática médica, concretamente en los sistemas HIS (Hospital Information System). La propuesta es interesante pero el documento denota que es un trabajo insipiente, o se entiende esto, dado que se describe la arquitectura propuesta y la metodología del proyecto, pero no se describe un escenario de prueba o un caso concreto de validación. Igualmente, no se observa en el documento la descripción de un software resultado del proyecto, y por el título del artículo y el abstract se espera la descripción de alguna propuesta software.",
            "output": [
                "es"
            ]
        },
        {
            "input": "In this work, the authors extend MS-COCO by adding an incorrect caption to each existing caption, with only one word of difference. The authors demonstrate that two state-of-the-art methods (one for VQA and one for captioning) perform extremely poorly at a) determining if a caption is fake, b) determining which word in a fake caption is wrong, and c) selecting a replacement word for a given fake word.  This work builds upon a wealth of literature regarding the underperformance of vision/language models relative to their apparent capacities. I think this work makes concrete some of the big, fundamental questions in this area: are vision/language models doing \"interesting\" things, or not? The authors consider a nice mix of tasks and models to shed light on the \"broken-ness\" of these settings, and perform some insightful analyses of factors associated with model failure (e.g., Figure 3).  My biggest concerns with the paper are similarity to Ding et al. That being said, I do think the authors make some really good points; Ding et al. generate similar captions, but the ones here differ by only one word and *still* break the models -- I think that's a justifiably fundamental difference. That observation demonstrates that Ding et al.'s engineering is not a requirement, as this simple approach still breaks things catastrophically.  Another concern is the use of NeuralTalk to select the \"hardest\" foils.              While a clever idea, I am worried that the use of this model creates a risk of self-reinforcement bias, i.e., NeuralTalk's biases are now fundamentally \"baked-in\" to FOIL-COCO.   I think the results section could be a bit longer, relative to the rest of the paper (e.g. I would've liked more than one paragraph -- I liked this part!)  Overall, I do like this paper, as it nicely builds upon some results that highlight defficiencies in vision/language integration. In the end, the Ding et al. similarity is not a \"game-breaker,\" I think -- if anything, this work shows that vision/language models are so easy to fool, Ding et al.'s method is not even required.  Small things:  I would've liked to have seen another baseline that simply concatenates BoW + extracted CNN features and trains a softmax classifier over them. The \"blind\" model is a nice touch, but what about a \"dumb\" vision+langauge baseline? I bet that would do close to as well as the LSTM/Co-attention. That could've made the point of the paper even stronger.  330: What is a supercategory? Is this from WordNet? Is this from COCO? I understand the idea, but not the specifics.  397: has been -> were  494: that -> than  693: artefact -> undesirable artifacts (?)  701: I would have included a chance model in T1's table -- is 19.53% [Line 592] a constant-prediction baseline? Is it 50% (if so, can't we flip all of the \"blind\" predictions to get a better baseline?) I am not entirely clear, and I think a \"chance\" line here would fix a lot of this confusion.  719: ariplane  ~~ After reading the author response...  I think this author response is spot-on. Both my concerns of NeuralTalk biases and additional baselines were addressed, and I am confident that these can be addressed in the final version, so I will keep my score as-is.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta un caso de aplicación de una arquitectura para el control de robots móviles. Primeramente se exponen las ventajas del enfoque basado en comportamiento y luego un caso de aplicación para el seguimiento de pared – evasión de obstáculos en un robot.  El artículo está bien escrito, pero puede mejorarse la descripción del caso o experimento. Sería deseable establecer previamente los objetivos para la observación. Las variables utilizadas podrían presentarse en una gráfica.  Si bien se menciona una mejora a partir de la inclusión del módulo de lógica difusa, se podría profundizar discutiendo el impacto de esto en las medidas. La sección de resultados puede mejorarse con una estructura más definida, tratando por separado los resultados de error, falsa lectura por reflexión, mapeo de pared en celdas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta un sistema de información comercial adaptable a cualquier negocio minorista a partir de facilitar el trabajo de consolidación de los datos y completar la automatización del proceso de importación, distribución y aprovisionamiento.  A pesar de buena presentación y lenguaje, no es un trabajo que presente resultados de una investigación. Más bien es el resumen del desarrollo de un sistema de mediana complejidad. Tampoco expone lecciones aprendidas o prácticas que pudieran aportar a otros desarrolladores. En conclusión, su novedad y contribución a la ciencia es limitada. En estas condiciones, creo que no puede aceptarse para el track de investigación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper gives a theoretical motivation for tieing the word embedding and output projection matrices in RNN LMs. The argument uses an augmented loss function which spreads the output probability mass among words with close word-embedding.   I see two main drawbacks from this framework: The augmented loss function has no trainable parameters and is used for only for regularization. This is not expected to give gains with large enough datasets.  The augmented loss is heavily “engineered” to produce the desired result of parameter tying. It’s not clear what happens if you try to relax it a bit, by adding parameters, or estimating y~ in a different way.   Nevertheless the argument is very interesting, and clearly written. The simulated results indeed validate the argument, and the PTB results seem promising.  Minor comments: Section 3: Can you clarify if y~ is conditioned on the t example or on the entire history. Eq. 3.5: i is enumerated over V (not |V|)",
            "output": [
                "en"
            ]
        },
        {
            "input": "Comentarios del artículo. De forma: •\tProblemas con el uso de mayúscula inicial. •\tDesconformidad? Sería mejor inconformidad •\tProblemas de ortografía. Faltan tildes en algunas palabras (por ejemplo: implantará), y sobran en otras (critérios). No tiene mucha presentación este tipo de errores teniendo en cuenta que los procesadores de texto cuentan con corrector de ortografía. •\tArtículos en español deben escribirse siempre en tercera persona. •\tProblemas con el sistema de referenciación.    De fondo: •\tLas figuras 1 y 2 no aportan al entendimiento del problema y la solución. Favor insertar solo figuras que permitan una mejor comprensión de la necesidad. •\tEl orden para presentar la información es confuso. Primero debería abordarse la sección de teoría y de trabajos previos para tener el background necesario y así entender porque es necesaria la construcción de una nueva aplicación. •\tEn la introducción siempre el último párrafo debe dar cuenta de la estructura del artículo. Falta esto para que el lector tenga una visión general del paper. •\tEn la sección teoría del dominio mencionan la definición de CRM, pero al parecer lo que ofrecen como solución no es una aplicación de este tipo. Esto genera confusión en la lectura. Igualmente parece que están mezclando las definiciones con la sección donde comparan otras aplicaciones, o cual tampoco favorece el entendimiento del artículo. •\tAl indicar las aplicaciones comparadas no queda muy claro qué criterios se usaron para su selección. Qué se revisó en cuanto a la literatura especializada? •\tLa calidad de la figura 3 no es adecuada para una publicación. •\tLa figura 4 y su etiqueta explicativa están en diferentes posiciones. Dicha figura también tiene problemas de calidad. •\tLa forma de mostrar la solución propuesta es muy confusa. Vale la pena reorganizar toda la sección para explicar primero el proceso propuesto en el desarrollo y posteriormente los resultados obtenidos. •\tTeniendo en cuenta el objetivo del artículo, una sección de modelo de indicadores de la extensión usada le roba espacio a aspectos más importantes a tratar como por ejemplo la utilidad de que la aplicación sea móvil y cuente con datos como la ubicación del vendedor. •\tEl título del trabajo no se compadece del contenido. No se hizo énfasis en el componente móvil que aparentemente era la mayor bondad de la aplicación. •\tLa sección de estadísticas no conecta con el resto del contenido, y tampoco se usan leyendas explicativas para lograr esta conexión.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Considero, antes que nada, que el ámbito de desarrollo de la temática (desarrollo de software en ambientes de investigación...) no \"otorga permiso\" para realizar este desarrollo en forma más informal (tiempos, relajos en versiones, escasa documentación, etc.). 2º, no veo porque se plantea sólo SCRUM, sin hacer comparaciones básicas con los otros exponentes \"clásicos\" de metodologías ágiles (XP y FDD), lo cual le otorga una cierta \"liviandad\" al análisis inicial de parte de los autores (sin duda se podría ahondar un poco más, sobretodo con XP).",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta un método algorítmico para la clasificación de la calidad de maderas relacionadas a postes de electricidad y pista ferroviaria. Este trabajo es interesante, pero su redacción no permite hacer una lectura fluida y con claridad del mismo.   Los que debería mejorar el artículo es:  - Mejorar la redacción del resumen. El resumen indica de test para probar la hipótesis, pero no indica cuál es la hipótesis.  - Eliminar aseveraciones sin referencias, como: 'Los defectos que se producen ... frecuencia significativa'  - Se realiza una aseveración que es ambigua respecto del trabajo: 'las señales de audio de la madera presentan la dificultad de no tener información bien definida...' y ' ...con el golpe del martillo puede ser más o menos complicado lograr determinar si...'. Entonces cómo se obtuvieron las características?, son estas características confiables?  - Hay frases contradictorias, como: '... hacer una captura de datos con lo máximo de interferencia posible,...' y ´'para que no haya ninguna interferencia...'  - Hay muchas palabras mal traducidas que no permiten una lectura fluida, como: poder urbano y rural, colectadas, podre, adiados, a seguir, cuantidad, tiendo, hacer parte, etc.  - Otras palabras que debe traducir de forma correcta: do, e, lo, Ajora,  - Las ecuaciones deben ajustarse al formato (ejemplo, 4 y 5). los títulos están corridos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "No concuerdo con lo que está escrito en el segundo parágrafo de la introducción. Una solución para un problema NP completo, por ejemplo el cajero viajante, puede ser programada de forma simple... el problema radica en que la respuesta del programa puede tardar mucho. Para contornar esto se buscan heurísticas o meta-heurísticas que tal vez no encuentren la respuesta ideal pero si un buena respuesta.  En la página 3, observe que Pa no es un elemento de A y si un subconjunto de A o más precisamente un subconjunto de A-{a}. En ese mismo parágrafo habla de \"dos tipos de restricciones\" pero la segunda no está explícitamente colocada. Al final del parágrafo sería interesante decir que \"o sea, ai pertenece a Paj\". La frase está muy larga: 16 líneas!  No queda claro en las figuras 1 y 2 la restricción de que \"la suma de la cantidad de tipo de recurso k utilizado en el período t, Rk(t), no debe exceder de Rk\".  En la formulación matemática  del RCPSP no está claro que significaría por ejemplo que Fj tome el valor 5 y el significado de pj y de A(t).  Faltó una comparación estadística de cuan buena es la calidad de la solución encontrada con el algoritmo propuesto de otras soluciones o al menos una comparación que muestre que tan distante está la solución encontrada de la ideal.  Las referencias parecen no tener un orden lógico (alfabético o orden de citación).",
            "output": [
                "es"
            ]
        },
        {
            "input": "- El artículo aborda un problema relevante y en boga en la comunidad (p.ej. CMMI-ACQ).  - No hay un estado del arte que revise intentos previos de resolver este problema. - La definición de patrones de proyecto de adquisición debería ceñirse a las definiciones usuales de patrón (máxime si se compara con los patrones de diseño, como se hace en las Conclusiones); p.ej. el estilo Portland de patrones de diseño reconoce contexto, problema y solución. - La técnica utilizada (MECT) parece adecuada para construir taxonomías, pero no patrones (al excluir consideraciones sobre causalidad etc.); el artículo parece asumir que los \"patrones de diseño\" son \"patrones de forma\", y no lo son. - La referencia [13] lista mal el nombre de la autora.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper introduces a segmentation procedure for breast tissue images using SVM.  General comments:  a) Concerning the proposed approach: The segmentation method introduced only considers local color/gray value information. Perhaps introducing other features related to the membrane's local (e.g. the membrane has symmetry properties that can be exploited) or global (e.g. continuity, approximately circular shape) properties may improve the segmentation results.  Feature selection is also a key component to improve performance. Use a feature selection procedure.  b) Concerning the experimentation: You should describe the experiments with sufficient detail so others can replicate them: a) Make your data publicly available b) Explain how you have selected the classifier's parameters (parameter selection in an SVM is critical and may improve notably the performance).  You should join Figs 10 and 9 in a single plot so we can better see the differences.  You only provide qualitative segmentation results (Figs. 12, 14, 15), but quantitative results are also very important. Specially when it comes to comparisons. You should quantitatively compare your algorithm with other competing works in the literature.  c) Concerning paper organization: The paper is well written and clearly introduces the problem, describes the relevant literature and presents the solution. I have a few comments concerning the paper organization: a) Problem statement and literature review (intro and theoretical framework sections) are in my opinion a bit long, compared to other important sections, e.g. feature extraction and experimentation which are just one paragraph each. b) Although English is in general correct, there are some small mistakes that could be solved by having it read by a professional. c) There are two \"proposed method\" sections  Well written paper. Good literature review.  It only shows very preliminary results.",
            "output": [
                "en"
            ]
        },
        {
            "input": "La aplicación de sistemas SCADA para la minería es algo interesante pero el trabajo solo se limita a mencionar las herramientas móviles y no existe un punto de comparación claro entre ellas. Tampoco queda claro el aporte específico de estas herramientas en un proceso minero real.  Existen problemas de consistencia en el resumen y la introducción. Las conclusiones no son suficientemente convincentes, además existen algunos problemas de redacción.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo realiza una descripción general del modelo CMMI y de las metodologías ágiles, tomando como casos particulares Scrum y XP. Se realiza una discusión sobre la combinación de estos enfoques para la mejora de procesos, realizando un mapeo de las áreas de proceso REQM y PPQA con sus equivalentes en las metodologías ágiles.  El artículo realiza descripciones generales correctas de las metodologías, pero no contiene elementos de investigación novedosos que aporten al conocimiento en esta área. Para la comunidad técnica/científica de ingeniería de software resulta evidente que los enfoques tienen distintos puntos de partida, pero son combinables. Esto es especialmente cierto para expertos en mejora de proceso de software.  La revisión que se realiza sobre la investigación de la combinación de agilidad y CMMI no es sistemática. Por estado del arte no se entiende una descripción simple de cada enfoque, sino recoger la investigación más actualizada sobre este tema.  Si bien puede ser interesante realizar un mapeo entre áreas de proceso y prácticas ágiles, no se explica que pasos se van a seguir para realizar esto. Tampoco se realiza una validación de este mapeo o se explica cómo puede ser aplicado, por ejemplo por un consultor en mejora de procesos. No se aporta ninguna evidencia empírica de la aplicabilidad o utilidad del mapeo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Ese trabajo muestra el procedimiento propuesto para la Identificación automática de fracturas en imágenes de pozos. La metodología se ve novedosa e interesante. El artículo muestra bien la metodología y tiene una buena redacción. Se agregaron métricas para medir la efectividad del algoritmo.  Este trabajo fue presentado en INFONOR 2014 y la redacción actual es la misma, que si bien es cierto es buena, presenta los mismos pequeños errores que en el artículo anterior. Por lo tanto, debe volver a revisarlo.  Aunque ahora muestra métricas para medir el resultado no se indica qué tan efectivo es este sistema respecto al utilizado antes.  Debe mejorar las figuras 12 y 15, en donde muestras las métricas. La figura 2, izquierda no se distingue. Falta incluir una referencia a la figura 11 en el texto.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposed an iterative query updating mechanism for cloze-style QA. The approach is novel and interesting and while it is only verified in the paper for two Cloze-style tasks (CBT and WDW), the concept of read/compose/write operations seem to be more general and can be potentially applied to other reasoning tasks beyond Cloze-style QA. Another advantage of the proposed model is to learn when to terminate the iteration by the so-called adaptive computation model, such that it avoids the issue of treating the number of iterations as another hyper-parameter, which is a common practice of iterative models/multi-hop reasoning in previous papers.  There are a couple places that this paper can improve. First, I would like to see the results from CNN/Daily Mail as well to have a more comprehensive comparison. Secondly, it will be useful to visualize the entire M^q sequence over time t (not just z or the query gating) to help understand better the query regression and if it is human interpretable.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Sorry to pop up late, but I've been looking over ICLR accepted papers, and I noticed this one. Something very similar, by combining word and character information at the feature level using sigmoid gating, has been done before, see ",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es un buen tema para el congreso. Presenta una buena propuesta de trabajo de vinculación  Está redactado como un abstract extendido, debe ser re-escrito para ser aceptado definitivamente para el congreso. No hay referencias y las que coloca al final son pobres. Por la presentación debería ser castigado",
            "output": [
                "es"
            ]
        },
        {
            "input": "Important problem, simple (in a positive way) idea, broad experimental evaluation; all reviewers recommend accepting the paper, and the AC agrees. Please incorporate any remaining reviewer feedback.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes a framework for evaluation of word embeddings based on data efficiency and simple supervised tasks. The main motivation is that word embeddings are generally used in a transfer learning setting, where evaluation is done based on how faster is to train a target model. The approach uses a set of simple tasks evaluated in a supervised fashion, including common benchmarks such as word similarity and word analogy. Experiments on a broad set of embeddings show that ranks tend to be task-specific and change according to the amount of training data used.  Strengths  - The transfer learning / data efficiency motivation is an interesting one, as it directly relates to the idea of using embeddings as a simple \"semi-supervised\" approach.  Weaknesses  - A good evaluation approach would be one that propagates to end tasks. Specifically, if the approach gives some rank R for a set of embeddings, I would like it to follow the same rank for an end task like text classification, parsing or machine translation. However, the approach is not assessed in this way so it is difficult to trust the technique is actually more useful than what is traditionally done. - The discussion about injective embeddings seems completely out-of-topic and does not seem to add to the paper's understanding. - The experimental section is very confusing. Section 3.7 points out that the analysis results in answers to questions as \"is it worth fitting syntax specific embeddings even when supervised datset is large?\" but I fail to understand where in the evaluation the conclusion was made. - Still in Section 3.7, the manuscript says \"This hints, that purely unsupervised large scale pretraining might not be suitable for NLP applications\". This is a very bold assumption and I again fail to understand how this can be concluded from the proposed evaluation approach. - All embeddings were obtained as off-the-shelf pretrained ones so there is no control over which corpora they were trained on. This limits the validity of the evaluation shown in the paper. - The manuscript needs proofreading, especially in terms of citing figures in the right places (why Figure 1, which is on page 3, is only cited in page 6?).  General Discussion  I think the paper starts with a very interesting motivation but it does not properly evaluate if their approach is good or not. As mentioned above, for any intrinsic evaluation approach I expect to see some study if the conclusions propagate to end tasks and this is not done in the paper. The lack of clarity and proofreading in the manuscript also hinders the understanding. In the future, I think the paper would vastly benefit from some extrinsic studies and a more controlled experimental setting (using the same corpora to train all embeddings, for instance). But in the current state I do not think it is a good addition to the conference.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This is an interesting paper about quantized networks that work on temporal difference inputs.  The basic idea is that when a network has only to process differences then this is computational much more efficient specifically with natural video data since large parts of an image would be fairly constant so that the network only has to process the informative sections of the image (video stream). This is of course how the human visual system works, and it is hence of interest even beyond the core machine learning community.   As an aside, there is a strong community interested in event-based vision such as the group of Tobi Delbrück, and it might be interesting to connect to this community. This might even provide a reference for your comments on page 1.  I guess the biggest novel contribution is that a rounding network can be replaced by a sigma-delta network, but that the order of discretization and summation doe make some difference in the actual processing load. I think I followed the steps and  Most of my questions have already been answers in the pre-review period. My only question remaining is on page 3, “It should be noted that when we refer to “temporal differences”, we refer not to the change in the signal over time, but in the change between two inputs presented sequentially. The output of our network only depends on the value and order of inputs, not on the temporal spacing between them.”  This does not make sense to me. As I understand you just take the difference between two frames regardless if you call this temporal or not it is a change in one frame. So this statement rather confuses me and maybe should be dropped unless I do miss something here, in which case some more explanation would be necessary.  Figure 1 should be made bigger.  An improvement of the paper that I could think about is a better discussion of the relevance of the findings. Yes, you do show that your sigma-delta network save some operation compared to threshold, but is this difference essential for a specific task, or does your solution has relevance for neuroscience?",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo aborda el problema de la navegación autónoma de robots móviles mediante la definición de una arquitectura de control reactiva.  Los autores deben ser más claros en indicar por qué utilizar una arquitectura reactiva, en relación con otros enfoques disponibles.  Es necesario mejorar la legibilidad de las ecuaciones.  El trabajo es correcto y pertinente. El ámbito de la robótica móvil tiene múltiples aplicaciones.  Es necesario incorporar algunos lineamientos sobre trabajo futuro.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Se trata de un artículo bastante particular que propone una extensión a los modelos de datos existentes considerando la idea de \"sistema\" (de objetos). Para esto se propone un lenguaje (LATIN) y un modelo de datos ¿universal?, MED, basado en un \"volumen esférico\" con dos polos \"mayor\" y \"diario\" basados en ideas contables. Este es, a mi juicio, el aspecto más crítico de la propuesta, ya que surge la duda, de si todo sistema debería calzar en este esquema, o estamos hablando de un conjunto particular de casos. Las ideas posteriores son interesante y, al menos, generan un quiebre con respecto a las ideas clásicas de la orientación a objetos. Cito la idea de sistema propuesta: \"un sistema es un conjunto de clases enlazadas e inter-actuantes según un mismo método, el cual no es particular a cada clase sino emergente de todas ellas\". Otras ideas asocian transacción con conjunto referencial, macros, tipos, instancias, ... lo que en términos globales constituyen un nuevo cuerpo de ideas. No habiendo en las referencias alguna cita a algún artículo anterior del autor que trate estas ideas, me parece que puede llegar a ser interesante escuchar esta propuesta y debatir al respecto. En términos de formalidad, el artículo no cumple cabalmente con el formato del congreso, y el número de páginas excede las ocho solicitadas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "I'd like to thank the authors for their detailed response and clarifications.  This work proposes new training scheme for online sparse dictionary learning. The model assumes a non-stationary flow of the incoming data. The goal (and the challenge) is to learn a model in an online manner in a way that is capable of  adjusting to the new incoming data without forgetting how to represent previously seen data. The proposed approach deals with this problem by incorporating a mechanism for adding or deleting atoms in the dictionary. This procedure is inspired by the adult neurogenesis phenomenon in the dentate gyrus of the hippocampus.   The paper has two main innovations over the baseline approach (Mairal et al): (i) “neuronal birth” which represents an adaptive way of increasing the number of atoms in the dictionary (ii) \"neuronal death\", which corresponds to removing “useless” dictionary atoms.  Neural death is implemented by including an group-sparsity regularization to the dictionary atoms themselves (the group corresponds to a column of the dictionary). This promotes to shrink to zero atoms that are not very useful, keeping controlled the increase of the dictionary size.  I believe that the strong side of the paper is its connections with the adult neurogenesis phenomenon, which is, in my opinion a very nice feature. The paper is very well written and easy to follow.  On the other hand, the overall technique is not very novel. Although not exactly equivalent, similar ideas have been explored. While the neural death is implemente elegantly with a sparsity-promoting regularization term, the neural birth is performed by relying on heuristics that measure how well the dictionary can represent new incoming data. Which depending on the \"level\" of non-stationarity in the incoming data (or presence of outliers) could be difficult to set. Still, having adaptive dictionary size is very interesting.  The authors could also cite some references in model selection literature. In particular, some ideas such as MDL have been used for automatically selecting the dictionary size (I believe this work does not address the online setting, but still its a relevant reference to have). For instance,  Ramirez, Ignacio, and Guillermo Sapiro. \"An MDL framework for sparse coding and dictionary learning.\" IEEE Transactions on Signal Processing 60.6 (2012): 2913-2927.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The idea of building a graph-based differentiable memory is very good. The proposed approach is quite complex, but it is likely to lead to future developments and extensions. The paper has been much improved since the original submission. The results could be strengthened, with more comparisons to existing results on bAbI and baselines on the experiments here. Exploring how it performs with less supervision, and different types of supervision, from entirely labeled graphs versus just node labels, would be valuable.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents. The paper is well written, clear in its presentation and backed up by good experiments. They demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states, allowing more accurate classification with less training data. They also show how the information learned by the network is interpretable and organised in a hierarchy.  Weaknesses: - a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper. - moreover, a discussion on how this approach could scale to more challenging scenarios \"involving animals\" and visual input for instance and more general \"behaviours\" is also missing; The criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios, making the original claim a little bit far fetched unless its backed up by additional evidence. Using \"Insects\", or \"fruit flies\" would be more appropriate than \"animals\".",
            "output": [
                "en"
            ]
        },
        {
            "input": "Abstract: Needs to have a definition of ERP - can't assume the reader knows what this means.  Intro: Avoid 1 sentence paragraphs (page 1) The introduction is rather long - it seems to actually be two different sections: an introduction (1st four paragraphs) and 1+ page of background and hypothesis. Overall - at 1.5 pages the intro is rather long for a paper that is 4 pages total.  Methodology: I think there are a lot of assumptions in regards to what ERP are and how they work.  While the paper is a statistical study, it would have benefited with a context of an actual example.  The samples are from small to medium size companies (how many?) with 49 use case (how do these relate?).  Results: Discussion is too limited - it assumes that a reader is very familiar with the area, and that may not be the case.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Overview: This work seems very promising, but I believe it should be compared with more baselines, and more precisely described and explained, from a signal processing point of view.  Pros: New descriptor Fast implementation  Cons: a) Lack of rigor b) Too long accordingly to the content c) The computational gain of the algorithm is not clear d) The work is not compared with its most obvious baseline: a scattering transform  I will detail each cons.  a) Section 1: The author  motivates the use of scattering transform because it defines a contraction of the space that relies on geometric features. \" The nonlinearity used in the scattering network is the complex modulus which is piecewise linear.\" A real modulus is piecewise linear. A complex modulus has a shape of bell when interpreting C as R^2. Could you clarify? \\Omega is not introduced.  Could you give a precise reference (page+paper) of this claim: “Higher order nonlinearity refers to |x|^2 instead of |x| as it is usually done in the scattering network.” ?  Section 2: The motivation of the non-linearity is not clear. First, this non-linearity might potentially increase a lot the variance of your architecture since it depends on higher moments(up to 4). I think a fair analysis would be to compute numerically the normalized variance (e.g. divided by the averaged l^2 norm), as a sanity check. Besides, one should prove that the energy is decreasing. It is not possible to argue that this architecture is similar to a scattering transform which has precise mathematical foundations and those results are required, since the setting is different.  Permutation is not a relevant variability.  The notion of sparsity during the whole paper sometimes refers to the number of 0 value, either the l^1 norm. Mathematically, a small value, even 10^-1000 is still a non 0 value.  Did you compute the graph of the figure 4 on the bird dataset? You might use a ratio instead for clarity.   The wavelet that is defined is not a morlet wavelet (",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: The idea to investigate the types of relations between lexical items is very interesting and challenging. The authors make a good argument why going beyond analogy testing makes sense.    - Weaknesses: The paper does not justify or otherwise contextualize the choice of clustering for evaluation, rather than using a classification task, despite the fact that classification tasks are more straightforward to evaluate. No attempt is being made to explain the overall level of the results. How well would humans do on this task (given only the words, no context)?  - General Discussion:  I have read the authors' response.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: The paper presents an interesting extension to attention-based neural MT approaches, which leverages source-sentence chunking as additional piece of information from the source sentence. The model is modified such that this chunking information is used differently by two recurrent layers: while one focuses in generating a chunk at a time, the other focuses on generating the words within the chunk. This is interesting. I believe readers will enjoy getting to know this approach and how it performs. The paper is very clearly written, and alternative approaches are clearly contrasted. The evaluation is well conducted, has a direct contrast with other papers (and evaluation tables), and even though it could be strengthened (see my comments below), it is convincing.  - Weaknesses: As always, more could be done in the experiments section to strengthen the case for chunk-based models. For example, Table 3 indicates good results for Model 2 and Model 3 compared to previous papers, but a careful reader will wonder whether these improvements come from switching from LSTMs to GRUs. In other words, it would be good to see the GRU tree-to-sequence result to verify that the chunk-based approach is still best.  Another important aspect is the lack of ensembling results. The authors put a lot of emphasis is claiming that this is the best single NMT model ever published. While this is probably true, in the end the best WAT system for Eng-Jap is at 38.20 (if I'm reading the table correctly) - it's an ensemble of 3. If the authors were able to report that their 3-way chunk-based ensemble comes top of the table, then this paper could have a much stronger impact.  Finally, Table 3 would be more interesting if it included decoding times. The authors mention briefly that the character-based model is less time-consuming (presumably based on Eriguchi et al.'16), but no cite is provided, and no numbers from chunk-based decoding are reported either. Is the chunk-based model faster or slower than word-based? Similar? Who know... Adding a column to Table 3 with decoding times would give more value to the paper.  - General Discussion: Overall I think the paper is interesting and worth publishing. I have minor comments and suggestions to the authors about how to improve their presentation (in my opinion, of course).   * I think they should clearly state early on that the chunks are supplied externally - in other words, that the model does not learn how to chunk. This only became apparent to me when reading about CaboCha on page 6 - I don't think it's mentioned earlier, and it is important.  * I don't see why the authors contrast against the char-based baseline so often in the text (at least a couple of times they boast a +4.68 BLEU gain). I don't think readers are bothered... Readers are interested in gains over the best baseline.  * It would be good to add a bit more detail about the way UNKs are being handled by the neural decoder, or at least add a citation to the dictionary-based replacement strategy being used here.  * The sentence in line 212 (\"We train a GRU that encodes a source sentence into a single vector\") is not strictly correct. The correct way would be to say that you do a bidirectional encoder that encodes the source sentence into a set of vectors... at least, that's what I see in Figure 2.  * The motivating example of lines 69-87 is a bit weird. Does \"you\" depend on \"bite\"? Or does it depend on the source side? Because if it doesn't depend on \"bite\", then the argument that this is a long-dependency problem doesn't really apply.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper presents several weakly supervised methods for developing NERs. The methods rely on some form of projection from English into another language. The overall approach is not new and the individual methods proposed are improvements of existing methods. For an ACL paper I would have expected more novel approaches.  One of the contributions of the paper is the data selection scheme. The formula used to calculate the quality score is quite straightforward and this is not a bad thing. However, it is unclear how the thresholds were calculated for Table 2. The paper says only that different thresholds were tried. Was this done on a development set? There is no mention of this in the paper. The evaluation results show clearly that data selection is very important, but one may not know how to tune the parameters for a new data set or a new language pair.   Another contribution of the paper is the combination of the outputs of the two systems developed in the paper. I tried hard to understand how it works, but the description provided is not clear.   The paper presents a number of variants for each of the methods proposed. Does it make sense to combine more than two weakly supervised systems? Did the authors try anything in this direction.  It would be good to know a bit more about the types of texts that are in the \"in-house\" dataset.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper considers the problem of KB completion and proposes ITransF for this purpose. Unlike STransE that assigns each relation an independent matrix, this paper proposes to share the parameters between different relations. A model is proposed where a tensor D is constructed that contains various relational matrices as its slices and a selectional vector \\alpha is used to select a subset of relevant relational matrix for composing a particular semantic relation. The paper then discuss a technique to make \\alpha sparse. Experimental results on two standard benchmark datasets shows the superiority of ITransF over prior proposals.  The paper is overall well written and the experimental results are good. However, I have several concerns regarding this work that I hope the authors will answer in their response.  1. Just by arranging relational matrices in a tensor and selecting (or more appropriately considering a linearly weighted sum of the relational matrices) does not ensure any information sharing between different relational matrices. This would have been the case if you had performed some of a tensor decomposition and projected the different slices (relational matrices) into some common lower-dimensional core tensor. It is not clear why this approach was not taken despite the motivation to share information between different relational matrices. 2. The two requirements (a) to share information across different relational matrices and (b) make the attention vectors sparse are some what contradictory. If the attention vector is truly sparse and has many zeros then information will not flow into those slices during optimisation.  3. The authors spend a lot of space discussing techniques for computing sparse attention vectors. The authors mention in page 3 that \\ell_1 regularisation did not work in their preliminary experiments. However, no experimental results are shown for \\ell_1 regularisation nor they explain why \\ell_1 is not suitable for this task. To this reviewer, it appears as an obvious baseline to try, especially given the ease of optimisation. You use \\ell_0 instead and get into NP hard optimisations because of it. Then you propose a technique and a rather crude approximation in the end to solve it. All that trouble could be spared if \\ell_1 was used. 4. The vector \\alpha is performing a selection or a weighing over the slices of D. It is slightly misleading to call this as “attention” as it is a term used in NLP for a more different type of models (see attention model used in machine translation). 5. It is not clear why you need to initialise the optimisation by pre-trained embeddings from TransE. Why cannot you simply randomly initialise the embeddings as done in TransE and then update them? It is not fair to compare against TransE if you use TransE as your initial point.  Learning the association between semantic relations is an idea that has been used in related problems in NLP such as relational similarity measurement [Turney JAIR 2012] and relation adaptation [Bollegala et al. IJCAI 2011]. It would be good to put the current work with respect to such prior proposals in NLP for modelling inter-relational correlation/similarity.  Thanks for providing feedback. I have read it.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: This paper introduced a novel method to improve zero pronoun resolution performance.. The main contributions of this papers are: 1) proposed a simple method to automatically generate a large training set for zero pronoun resolution task; 2) adapted a two step learning process to transfer knowledge from large data set to the specific domain data; 3) differentiate unknown words using different tags. In general, the paper is well written. Experiments are thoroughly designed.   - Weaknesses:  But I have a few questions regarding finding the antecedent of a zero pronoun: 1. How will an antecedent be identified, when the prediction is a pronoun? The authors proposed a method by matching the head of noun phrases. It’s not clear how to handle the situation when the head word is not a pronoun. 2. What if the prediction is a noun that could not be found in the previous contents? 3. The system achieves great results on standard data set. I’m curious is it possible to evaluate the system in two steps? The first step is to evaluate the performance of the model prediction, i.e. to recover the dropped zero pronoun into a word; the second step is to evaluate how well the systems works on finding an antecedent.  I’m also curious why the authors decided to use attention-based neural network. A few sentences to provide the reasons would be helpful for other researchers.  A minor comment: In figure 2, should it be s1, s2 … instead of d1, d2 ….?   - General Discussion: Overall it is a great paper with innovative ideas and solid experiment setup.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper studies neural models that can be applied to set-structured inputs and thus require permutation invariance or equivariance. After a first section that introduces necessary and sufficient conditions for permutation invariance/equivariance, the authors present experiments in supervised and semi-supervised learning on point-cloud data as well as cosmology data.    The reviewers agreed that this is a very promising line of work and acknowledged the effort of the authors to improve their paper after the initial discussion phase. However, they also agree that the work appears to be missing more convincing numerical experiments and insights on the choice of neural architectures in the class of permutation-covariant.     In light of these reviews, the AC invites their work to the workshop track.   Also, I would like to emphasize an aspect of this work that I think should be addressed in the subsequent revision.    As the authors rightfully show (thm 2.1), permutation equivariance puts very strong constraints in the class of 1-layer networks. This theorem, while rigorous, reflects a simple algebraic property of matrices that commute with permutation matrices. It is therefore not very surprising, and the resulting architecture relatively obvious. So much so that it already exists in the literature. In fact, it is a particular instance of the graph neural network model of Scarselli et al. '09 (",
            "output": [
                "en"
            ]
        },
        {
            "input": "It is an interesting idea to go after saddle points in the optimization with an SR1 update and a good start in experiments, but missing important comparisons to recent 2nd order optimizations such as Adam, other Hessian free methods (Martens 2012), Pearlmutter fast exact multiplication by the Hessian. From the mnist/cifar curves it is not really showing an advantage to AdaDelta/Nag (although this is stated), and much more experimentation is needed to make a claim about mini-batch insensitivity to performance, can you show error rates on a larger scale task?",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta una revisión bibliográfica sobre técnicas de elicitación de requisitos. Este trabajo hace énfasis en clasificar las técnicas de elicitación a partir del área de conocimiento de los estudios bibliográficos revisado y a partir de atributos como Eficiencia, Efectividad, entre otros. Sin embargo, es importante que los autores mejoren ciertos aspectos del artículo que le bajan la calidad de investigación que debe tener un trabajo. Por ejemplo:  Es recomendable mejorar la calidad del inglés. Tal como se presenta el artículo se hace difícil leerlo y entender lo que se expresa.  El título no es muy adecuado para lo que se expresa en la introducción y las conclusiones. Es recomendable considerar una modificación del título que indique claramente lo que se trabajó en el documento. El trabajo está enfocado a analizar las opiniones y trabajos realizados por diferentes autores (revisión de literatura) respecto a las técnicas de elicitación de requisitos.  El trabajo presenta un aporte importante estableciendo una clasificación a partir de categorías y dominios, al parecer identificados por los autores. Sin embargo, dichas categorías y dominios han sido identificados sin indicar qué autores proponen dicha clasificación o bien, si son los autores del artículo, de qué forma (metodología o criterios) se establecieron para definir los criterios y los dominios.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper evaluates several strategies to reduce output vocabulary size in order to speed up NMT decoding and training. It could be quite useful to practitioners, although the main contributions of the paper seem somewhat orthogonal to representation learning and neural networks, and I am not sure ICLR is the ideal venue for this work.  - Do the reported decoding times take into account the vocabulary reduction step? - Aside from machine translation, might there be applications to other settings such as language modeling, where large vocabulary is also a scalability challenge? - The proposed methods are helpful because of the difficulties induced by using a word-level model. But (at least in my opinion) starting from a character or even lower-level abstraction seems to be the obvious solution to the huge vocabulary problem.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Paper Summary:  Authors investigate identity re-parametrization in the linear and the non linear case.   Detailed comments:  — Linear Residual Network:  The paper shows that for a linear residual network any critical point is a global optimum. This problem is non convex it is interesting that this simple re-parametrization leads to such a result.    — Non linear Residual Network:  Authors propose a construction that maps the points to their labels via a resnet , using an initial random projection, followed by a residual block that clusters the data based on their label, and a last layer that maps the clusters to the label.   1- In Eq 3.4  seems the dimensions are not matching q_j in R^k and e_j in R^r. please clarify   2- The construction seems fine, but what is special about the resnet here in this construction? One can do a similar construction if we did not have the identity? can you discuss this point? In the linear case it is clear from a spectral point of view how the identity is helping the optimization. Please provide some intuition.    3-   Existence of a network in the residual  class that overfits does it give us any intuition on why residual network outperform other architectures? What does an existence result of such a network tell us about its representation power ?  A simple linear model under the assumption that points can not be too close can overfit the data, and get fast convergence rate (see for instance tsybakov noise condition).  4- What does the construction tell us about the number of layers?   5- clustering the activation independently from the label, is an old way to pretrain the network. One could use those centroids as weights for the next layer (this is also related to Nystrom approximation see for instance",
            "output": [
                "en"
            ]
        },
        {
            "input": "El tema es interesante y está bien estructurado en lo que se refiere a diseño de la propuesta.  El tema trata de un enfoque para la mejora, sin embargo solo establece una propuesta de arquitectura, centrándose en el diseño, y no indica cómo se evaluará o medirá esta mejora para los SDW, se recomienda agregar métricas u otros aspectos para ello. No entrega muchos detalles, se recomienda aumentar el nro. de páginas para sí mejorar este aspecto. No hay muchas referencias bibliográficas a trabajos o esfuerzos relacionados sobre el tema.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper tests zoneout against a variety of datasets - character level, word level, and pMNIST classification - showing applicability in a wide range of scenarios. While zoneout acts as a regularizer to prevent overfitting, it also has similarities to residual connections. The continued analysis of this aspect, including analyzing how the gradient flow improves the given tasks, is of great interest and helps show it as an inherent property of zoneout.  This is a well written paper with a variety of experiments that support the claims. I have also previously used this technique in a recurrent setting and am confident on the positive impact it can have upon tasks. This is likely to become a standard technique used within RNNs across various frameworks.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:  The paper is well-written and easy to understand. The methods and results are interesting.  - Weaknesses:  The evaluation and the obtained results might be problematic (see my comments below).  - General Discussion:  This paper proposes a system for end-to-end argumentation mining using neural networks. The authors model the problem using two approaches: (1) sequence labeling (2) dependency parsing. The paper also includes the results of experimenting with a multitask learning setting for the sequence labeling approach. The paper clearly explains the motivation behind the proposed model. Existing methods are based on ILP, manual feature engineering and manual design of ILP constraints. However, the proposed model avoids such manual effort. Moreover, the model jointly learns the subtasks in argumentation mining and therefore, avoids the error back propagation problem in pipeline methods. Except a few missing details (mentioned below), the methods are explained clearly.  The experiments are substantial, the comparisons are performed properly, and the results are interesting. My main concern about this paper is the small size of the dataset and the large capacity of the used (Bi)LSTM-based recurrent neural networks (BLC and BLCC). The dataset includes only around 320 essays for training and 80 essays for testing. The size of the development set, however, is not mentioned in the paper (and also the supplementary materials). This is worrying because very few number of essays are left for training, which is a crucial problem. The total number of tags in the training data is probably only a few thousand. Compare it to the standard sequence labeling tasks, where hundreds of thousands (sometimes millions) of tags are available. For this reason, I am not sure if the model parameters are trained properly. The paper also does not analyze the overfitting problem. It would be interesting to see the training and development \"loss\" values during training (after each parameter update or after each epoch). The authors have also provided some information that can be seen as the evidence for overfitting: Line 622 \"Our explanation is that taggers are simpler local models, and thus need less training data and are less prone to overfitting\".  For the same reason, I am not sure if the models are stable enough. Mean and standard deviation of multiple runs (different initializations of parameters) need to be included. Statistical significance tests would also provide more information about the stability of the models and the reliability of results. Without these tests, it is hard to say if the better results are because of the superiority of the proposed method or chance.  I understand that the neural networks used for modeling the tasks use their regularization techniques. However, since the size of the dataset is too small, the authors need to pay more attention to the regularization methods. The paper does not mention regularization at all and the supplementary material only mentions briefly about the regularization in LSTM-ER. This problem needs to be addressed properly in the paper.  Instead of the current hyper-parameter optimization method (described in supplementary materials) consider using Bayesian optimization methods.  Also move the information about pre-trained word embeddings and the error analysis from the supplementary material to the paper. The extra one page should be enough for this.  Please include some inter-annotator agreement scores. The paper describing the dataset has some relevant information. This information would provide some insight about the performance of the systems and the available room for improvement.  Please consider illustrating figure 1 with different colors to make the quality better for black and white prints.  Edit:  Thanks for answering my questions. I have increased the recommendation score to 4. Please do include the F1-score ranges in your paper and also report mean and variance of different settings. I am still concerned about the model stability. For example, the large variance of Kiperwasser setting needs to be analyzed properly. Even the F1 changes in the range [0.56, 0.61] is relatively large. Including these score ranges in your paper helps replicating your work.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This is a nice paper on morphological segmentation utilizing word  embeddings. The paper presents a system which uses word embeddings to  both measure local semantic similarity of word pairs with a potential  morphological relation, and global information about the semantic validity of potential morphological segment types. The paper is well written and  represents a nice extension to earlier approaches on semantically driven  morphological segmentation.  The authors present experiments on Morpho Challenge data for three  languages: English, Turkish and Finnish. These languages exhibit varying  degrees of morphological complexity. All systems are trained on Wikipedia  text.   The authors show that the proposed MORSE system delivers clear  improvements w.r.t. F1-score for English and Turkish compared to the well  known Morfessor system which was used as baseline. The system fails to  reach the performance of Morfessor for Finnish. As the authors note, this  is probably a result of the richness of Finnish morphology which leads to  data sparsity and, therefore, reduced quality of word embeddings. To  improve the performance for Finnish and other languages with a similar  degree of morphological complexity, the authors could consider word  embeddings which take into account sub-word information. For example,  @article{DBLP:journals/corr/CaoR16,   author    = {Kris Cao and                Marek Rei},   title     = {A Joint Model for Word Embedding and Word Morphology},   journal   = {CoRR},   volume    = {abs/1606.02601},   year                  = {2016},   url                 = {[Link]},   timestamp = {Fri, 01 Jul 2016 17:39:49 +0200},   biburl    = {[Link]},   bibsource = {dblp computer science bibliography, [Link]} }  @article{DBLP:journals/corr/BojanowskiGJM16,   author    = {Piotr Bojanowski and                Edouard Grave and                Armand Joulin and                Tomas Mikolov},   title     = {Enriching Word Vectors with Subword Information},   journal   = {CoRR},   volume    = {abs/1607.04606},   year                  = {2016},   url                 = {[Link]},   timestamp = {Tue, 02 Aug 2016 12:59:27 +0200},   biburl    = {[Link]},   bibsource = {dblp computer science bibliography, [Link]} }  The authors critique the existing Morpho Challenge data sets.  For example, there are many instances of incorrectly segmented words in  the material. Moreover, the authors note that, while some segmentations  in the the data set may be historically valid (for example the  segmentation of business into busi-ness), these segmentations are no  longer semantically motivated. The authors provide a new data set  consisting of 2000 semantically motivated segmentation of English word  forms from the English Wikipedia. They show that MORSE deliver highly  substantial improvements compared to Morfessor on this data set.  In conclusion, I think this is a well written paper which presents  competitive results on the interesting task of semantically driven  morphological segmentation. The authors accompany the submission with  code and a new data set which definitely add to the value of the  submission.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper presents two approaches for generating English poetry. The first approach combine a neural phonetic encoder predicting the next phoneme with a phonetic-orthographic HMM decoder computing the most likely word corresponding to a sequence of phonemes. The second approach combines a character language model with a weigthed FST to impose rythm constraints on the output of the language model. For the second approach, the authors also present a heuristic approach which permit constraining the generated poem according to theme (e.g;, love) or poetic devices (e.g., alliteration). The generated poems are evaluated both instrinsically by comparing the rythm of the generated lines with a gold standard and extrinsically by asking 70 human evaluators to (i) determine whether the poem was written by a human or a machine and (ii) rate poems wrt to readability, form and evocation.  The results indicate that the second model performs best and that human evaluators find it difficult to distinguish between human written and machine generated poems.  This is an interesting, clearly written article with novel ideas (two different models for poetry generation, one based on a phonetic language model the other on a character LM) and convincing results.   For the evaluation, more precision about the evaluators and the protocol would be good. Did all evaluators evaluate all poems and if not how many judgments were collected for each poem for each task ? You mention 9 non English native speakers. Poems are notoriously hard to read. How fluent were these ?   In the second model (character based), perhaps I missed it, but do you have a mechanism to avoid generating non words ? If not, how frequent are non words in the generated poems ?  In the first model, why use an HMM to transliterate from phonetic to an orhographic representation rather than a CRF?   Since overall, you rule out the first model as a good generic model for generating poetry, it might have been more interesting to spend less space on that model and more on the evaluation of the second model. In particular, I would have been interested in a more detailed discussion of the impact of the heuristic you use to constrain theme or poetic devices. How do these impact evaluation results ? Could they be combined to jointly constrain theme and poetic devices ?   The combination of a neural mode with a WFST is reminiscent of the following paper which combine character based neural model to generate from dialog acts with an WFST to avoid generating non words. YOu should relate your work to theirs and cite them.   Natural Language Generation through Character-Based RNNs with Finite-State Prior Knowledge Goyal, Raghav and Dymetman, Marc and Gaussier, Eric and LIG, Uni COLING 2016",
            "output": [
                "en"
            ]
        },
        {
            "input": "Overall, this is a nice paper. Developing a unifying framework for these newer neural models is a worthwhile endeavor.  However, it's unclear if the DRAGNN framework (in its current form) is a significant standalone contribution. The main idea is straightforward: use a transition system to unroll a computation graph. When you implement models in this way you can reuse code because modules can be mixed and matched. This is nice, but (in my opinion) is just good software engineering, not machine  learning research.  Moreover, there appears to be little incentive to use DRAGNN, as there are no 'free things' (benefits) that you get by using the framework. For example:  - If you write your neuralnet in an automatic differentiation library (e.g.,   tensorflow or dynet) you get gradients for 'free'.  - In the VW framework, there are efficiency tricks that 'the credit assignment   compiler' provides for you, which would be tedious to implement on your   own. There is also a variety of algorithms for training the model in a   principled way (i.e., without exposure bias).  I don't feel that my question about the limitations of the framework has been satisfactorily addressed. Let me ask it in a different way: Can you give me examples of a few models that I can't (nicely) express in the DRAGNN framework? What if I wanted to implement",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Buena revisión de tendencias, tecnologías y estándares que podrían utilizarse para la implementación de sistemas de telemedicina. - Interesante caso práctico que hacen del sistema SAT y sus posibles aplicaciones desde la Ing. de Software  - Las iniciativas y tendencias que muestran en telemedicina, deberían describirlas en función de los apartados que tratan en el artículo: integración, interoperabilidad y desarrollo de aplicaciones, y no en general como lo presentan. Por esta desarticulación, es posible que no sea muy clara la consecuencia entre lo que presentan en el resumen y lo que se encuentra en el desarrollo del paper. - Considero que el título no debería enfocarse solo hacia 'Herramientas', pues al comenzar a leer el trabajo queda la idea q el aporte y la revisión es mas a nivel operativo y de sistemas que apoyen el proceso, mas no de iniciativas en cuanto a estándares, proyectos y tecnologías desarrolladas para tal fin. El título no tiene el alcande del contenido.  El artículo describe en el caso chileno, cuáles podrían ser iniciativas, tendencias y tecnologías para la aplicación de ingeniería de software en el ámbito de la telemedicina. No representa originalidad como tal en ninguna de las dos áreas.  La calidad técnica es buena en cuanto a que la revisión que describen está soportada bibliográficamente, con tendencias, tecnologías y estándares actuales. En cuanto a la escritura técnica, sí hay errores en el adecuado uso de las siglas, en algunos casos no muestran su significado, en algunos otros casos no son bien utilizadas. (Por ejemplo: Se debe decir TIC, no TICs; en la citación de las referencias en el texto, se debe suprimir la puntuación antes del número --> especialista [14].; las figuras pueden mejorarse significativamente). La descripción de las 'tendencias' e 'iniciativas' daría mayor valor al artículo que ejemplos como el incluido en esta última sección donde muestran la representación de un mensaje en sintaxis diferentes.  Es relevante para el contexto chileno, en cuando presentan una propuesta interesante para que los diferentes actores (gobierno, desarrolladores, compañías) tengan en cuenta para impulsar esta área de trabajo.  La organización del documento se puede mejorar en los aspectos nombrados en 'calidad técnica, al igual que aspectos que evidencien una consecuencia y coherencia entre título, resumen y desarrollo del artículo. Así mismo, hay errores ortográficos y de redacción que, si se evitan, pueden darle mayor valor a la presentación del artículo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo trata la construcción de sistemas de recuperación de imágenes basada en el contenido (de las imágenes), CBIR. Se introduce el problema del CBIR y se presentan algunos algoritmos que permiten acelerar las búsquedas de vecinos más cercanos a un vector de entrada (correspondiente a una imagen) en el espacio de características elegido para representar las imágenes.  Se utilizan características basadas en el color, la respuesta en frecuencia y globales para cada uno de los cuadros locales en los que se divide una imagen de entrada. De esta forma se introduce información de diferentes tipos al sistema CBIR para representar las imágenes.  - El artículo no delimita claramente sus aportaciones. Parece que se aporta algo en cuanto al espacio de características en el que se representan las imágenes y también parece que aporta algo en los algoritmos y estructuras de datos necesarias para acelerar las búsquedas en espacios métricos.  - En general el artículo emplea poco espacio en explicar la aproximación propuesta a CBIR (se dan dos referencias a tesis de máster). En las conclusiones se presentan resultados experimentales, cuando claramente deberían ir en una sección anterior con los experimentos.  - En cuanto a las características visuales empleadas para representar una imagen:    Se echan en falta experimentos que permitan establecer lo que aporta cada una de las características que se plantea utilizar. Esto es, creo que es importante responder a la pregunta ¿Por qué estas y no otras? y también a la pregunta ¿Es alguna de ellas redundante y se podría dejar de utilizar? Si bien es cierto que se utiliza un procedimiento de selección de características, se echa de menos un experimento estableciendo cuál es el efecto de la selección ¿Cuánto se gana en tasa de acierto sobre la utilización del vector completo?  Parece que el espacio de características después de la selección tiene una dimensión de 3078 (sección 2.4). ¿Es así o las 3078 características se han extraído \"manualmente\"?  - No se entiende el experimento de comparación de sistemas CBIR (sección 2.3). ¿Qué se hace con las 100 imágenes comunes a las bases de datos? ¿Se hace la misma query en todos los sistemas y se mide la precisión y recall utilizando únicamente las 100 imágenes comunes cuando aparecen o no en la respuesta del sistema? Eso no está explicado en absoluto en el artículo.  - Cuando se da un dato como la sensibilidad y especificidad en las conclusiones, hay que decir sobre qué conjunto de datos se ha probado. Es posible hacer una prueba sobre unos datos y obtener un resultado completamente diferente sobre otros. Por tanto sensibilidad y especificidad sin referencia a los datos de los que se ha obtenido carecen de sentido.  - A este revisor le parece que un artículo sobre CBIR no debería pasar por alto desarrollos en Visión por Computadora basados en características locales (ya clásicos) como:    Sivic, J. and Zisserman, A.   Video Google: A Text Retrieval Approach to Object Matching in Videos   Proceedings of the IEEE International Conference on Computer Vision (2003)    D. Nistér and H. Stewénius,   Scalable recognition with a vocabulary tree   Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (2006)    - Algunas de las referencias, como la [10,11,13], están incompletas ¿A qué se refieren? ¿Un artículo? ¿Un sistema de ejemplo funcionando en una URL?    - El sistema funcionando en la URL que refieren los autores da fallos de ejecución cuando se intenta probar con imágenes extraídas de google images.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El documento propone un modelo de visualización gráfico para arboles de decisión basado en el esquema VAM-DM que fue probado por medio de una aplicación con usuarios novatos y expertos.  El documento presenta varios problemas de forma más que de fondo.  Tiene errores de ortografía, en la puntuación y tipográficos.  En algunas partes parece ser una traducción mal hecha. Todo esto dificulta la comprensión del texto.  El significado de las siglas debe explicarse desde su primera utilización.  Faltan referencias en el lugar apropiado. Por ejemplo: desde la primera vez que se habla del esquema VAM-DM se debe poner la referencia o se utiliza la palabra varios autores sin referencias.  La encuesta debería estar disponible, ya sea en un Anexo o en algún sitio en Internet.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta un estudio de la percepción que tienen los ingenieros de requisitos (noveles y expertos) en relación a la efectividad de las diferentes técnicas de educción  para el descubrimiento de los requisitos en un proyecto de desarrollo de software.  El articulo trata un tema que merece cierta atención ante la gran cantidad de técnicas de educción que existen y la desorientación de los ingenieros de requisitos respecto de cuál utilizar en un determinado contexto.  El estudio realizado considera como noveles Ingenieros que no tienen conocimiento de técnicas de educción y uno de los atributos que debe ser calificado como base del estudio comparativo, es precisamente su experiencia. De hecho como conclusión se expresa que “una más amplia formación y principalmente de tipo práctica, es necesaria para que los ingenieros noveles puedan decidir….”, eso es de Perogrullo. Debería ser considera una gama mayor de atributos del contexto como los sugeridos en [14], que permitan conclusiones más veraces.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Un Objeto de Aprendizaje sirve como apoyo al proceso educativo, para desarrollar competencias en los estudiantes en alguno de los tres tipos de saberes (domino conceptual, dominio de procedimientos y desarrollo de actitudes y valores). En ninguno de estos ámbitos se dan evidencias que lo demuestren. Además de que las experiencias son muy básicas, el abstract, lo cito textual: \"El Artículo presenta, las experiencias recabadas de la aplicación de Objetos de Aprendizaje en el desarrollo de la asignatura de Introducción a la Teoría de Autómatas, debido a que en el desarrollo del curso se han desplegado cambios significativos, planteando un seguimiento académico detallado y exhaustivo mediante un esquema de “Retroalimentación Rápida” y “Preguntas Cortas”.\", no se muestran las experiencias recabadas ni tampoco se menciona como las obtendrían.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths: This paper presents an extension to A* CCG parsing to include dependency information.  Achieving this while maintaining speed and tractability is a very impressive feature of this approach.  The ability to precompute attachments is a nice trick.                  I also really appreciated the evaluation of the effect of the head-rules on normal-form violations and would love to see more details on the remaining cases.  - Weaknesses: I'd like to see more analysis of certain dependency structures.  I'm particularly interested in how coordination and relative clauses are handled when the predicate argument structure of CCG is at odds with the dependency structures normally used by other dependency parsers.  - General Discussion: I'm very happy with this work and feel it's a very nice contribution to the literature.  The only thing missing for me is a more in-depth analysis of the types of constructions which saw the most improvement (English and Japanese) and a discussion (mentioned above) reconciling Pred-Arg dependencies with those of other parsers.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Studying the Hessian in deep learning, the experiments in this paper suggest that the eigenvalue distribution is concentrated around zero and the non zero eigenvalues are related to the complexity of the input data. I find most of the discussions and experiments to be interesting and insightful. However, the current paper could be significantly improved.  Quality: It seems that the arguments in the paper could be enhanced by more effort and more comprehensive experiments. Performing some of the experiments discussed in the conclusion could certainly help a lot. Some other suggestions: 1- It would be very helpful to add other plots showing the distribution of eigenvalues for some other machine learning method for the purpose of comparison to deep learning. 2- There are some issues about the scaling of the weights and it make sense to normalize the weights each time before calculating the Hessian otherwise the result might be misleading. 3- It might worth trying to find a quantity that measures the singularity of Hessian because it is difficult to visually conclude something from the plots. 4- Adding some plots for the Hessian during the optimization is definitely needed because we mostly care about the Hessian during the optimization not after the convergence.  Clarity: 1- There is no reference to figures in the main text which makes it confusing for the reading to know the context for each figure. For example, when looking at Figure 1, it is not clear that the Hessian is calculated at the beginning of optimization or after convergence. 2- The texts in the figures are very small and hard to read.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta una aplicación para celulares que ayudaría al ciudadano mexicano a mejorar la gestión del pago de los impuestos federales. El principal problema de este artículo es que no muestra  el uso de técnicas de construcción de softwares ni esgrime detalles de la propia solución (la arquitectura del software).  Un segundo punto más fuerte para mi evaluación negativa, es la pésima calidad del texto. Por ejemplo:  1) Errores tipográficos, como por ejemplo \"fiscas\" en el resumen  2) Frases largas y confusas como en el primer parágrafo de la introducción y las dos últimas de la columna  izquierda en la página 2.  3) Frases que no respetan la concordancia de género y número como por ejemplo \"la investigaciones está organizado\" en la página 2.  4) El cuadro 2 es citado antes del cuadro 1, no existe un cuadro 3, en el cuadro 4 los porcentajes están errados, y  el cuadro 5 además de no ser citado en el texto, contiene intervalos muy pequeños (podría juntar los dos intervalos de edad intermediarios) y trabaja con edades fraccionadas...es mejor tener porcentajes menos redondos que edades fraccionadas.  5) El texto solo tiene dos secciones: Introducción y Conclusión (que ellos llamaron de reflexiones).  6) Las referencias no siguen un padrón único.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo propone la aplicación de Diagramas de Clases UML Orientados a Aspectos JPI. En general, el artículo está bien planteado y no hay grandes observaciones. Es más, se observa una preocupación por hacer una buena presentación del trabajo. Sólo haría algunas sugerencias menores, especialmente, con los aspectos metodológicos que deberían ser un poco más detallados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes a novel strategy for zero-resource translation where (source, pivot) and (pivot, target) parallel corpora are available. A teacher model for p(target|pivot) is first trained on the (pivot, target) corpus, then a student model for p(target|source) is trained to minimize relative entropy with respect to the teacher on the (source, pivot) corpus. When using word-level relative entropy over samples from the teacher, this approach is shown to outperform previous variants on standard pivoting, as well as other zero-resource strategies.  This is a good contribution: a novel idea, clearly explained, and with convincing empirical support. Unlike some previous work, it makes fairly minimal assumptions about the nature of the NMT systems involved, and hence should be widely applicable.  I have only a few suggestions for further experiments. First, it would be interesting to see how robust this approach is to more dissimilar source and pivot languages, where intuitively the true p(target|source) and p(target|pivot) will be further apart. Second, given the success of introducing word-based diversity, it was surprising not to see a sentence n-best or sentence-sampling experiment. This would be more costly, but not much more so since you’re already doing beam search with the teacher. Finally, related to the previous, it might be interesting to explore transition from word-based diversity to sentence-based as the student converges and no longer needs the signal from low-probability words.  Some further comments:  line 241: Despite its simplicity -> Due to its simplicity  277: target sentence y -> target word y  442: I assume that K=1 and K=5 mean that you compare probabilities of the most probable and 5 most probable words in the current context. If so, how is the current context determined - greedily or with a beam?  Section 4.2. The comparison with an essentially uniform distribution doesn’t seem very informative here: it would be extremely surprising if p(y|z) were not significantly closer to p(y|x) than to uniform. It would be more interesting to know to what extent p(y|z) still provides a useful signal as p(y|x) gets better. This would be easy to measure by comparing p(y|z) to models for p(y|x) trained on different amounts of data or for different numbers of iterations. Another useful thing to explore in this section would be the effect of the mode approximation compared to n-best for sentence-level scores.  555: It’s odd that word beam does worse than word greedy, since word beam should be closer to word sampling. Do you have an explanation for this?  582: The claimed advantage of sent-beam here looks like it may just be noise, given the high variance of these curves.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Interesante trabajo.  si bien el documento muestra una propuesta, sería interesante mostrar aplicaciones.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths: The paper proposes an end-to-end neural model for semantic graph parsing, based on a well-designed transition system.  The work is interesting, learning semantic representations of DMRS, which is capable of resolving semantics such as scope underspecification. This work shows a new scheme for computational semantics, benefiting from an end-to-end transition-based incremental framework, which resolves the parsing with low cost.  - Weaknesses:   My major concern is that the paper only gives a very common introduction for the definition of DMRS and EP, and the example even makes me a little confused because I cannot see anything special for DMRS. The description can be a little more detailed, I think. However, upon the space limitation, it is understandable. The same problem exists for the transition system of the parsing model. If I do not have any background of MRS and EP, I can hardly learn something from the paper, just seeing that this paper is very good.  - General Discussion:   Overall, this paper is very interesting to me. I like the DMRS for semantic parsing very much and like the paper very much. Hope that the open-source codes and datasets can make this line of research being a hot topic.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El paper describe el contexto actual del uso de tecnologías disponibles para controlar de manera automática la dosificación de macronutrientes en los tratados de cultivos sin suelo.  El trabajo es pertinente en su definición y desarrollo. Sin embargo, el título induce a una expectativa que no se logra satisfacer en el documento. El paper ofrece una discusión sobre el estado del arte en tecnología para la problemática abordada, sin embargo, no ofrece un framework comparativo, criterios de selección, o sugerencia sobre buenas prácticas.  Como primer acercamiento al área de investigación es pertinente, sin embargo, algo más de trabajo propio debe ser añadido al paper.",
            "output": [
                "es"
            ]
        },
        {
            "input": "I reviewed the manuscript as of December 6th.  The authors perform a systematic investigation of various retraining methods for making a classification network robust to adversarial examples. The authors achieve lower error rates using their RAD and IAEC methods perform better then previously introduced distillation methods for retraining networks to be robust to adversarial examples. This method suggests a promising direction for building a defense for adversarial examples.  Major Comments: I find the paper to not be lacking in exposition and clarity. The paper has a laundry list of related results (page 2) but no clear message. I *think* one larger point is the superior performance of their retraining techniques but it is not clear how well these techniques perform compared to other retraining techniques, nor are the details of the retraining techniques clear. The paper requires more discussion and a clear exposition about the methods the authors introduced (i.e. RAD, IAEC). What follow are some more detailed comments along this theme of improving the exposition and clarity:  - The authors should provide more details about how they constructed the auto-encoder in the IAEC method (diagram?). The same needs to be said for the RAD method. The authors point to a previous workshop submission (",
            "output": [
                "en"
            ]
        },
        {
            "input": "Fondo: - Se menciona de manera muy superficial el lenguaje a utilizar en forma posterior a Scratch, quizás no es necesario o se debe ahondar más en el tema. - El número de alumnos sobre el cual se aplicó el estudio es muy pequeño para obtener resultados concluyentes. - Sería deseable una comparación o estudio entre la utilización de Scratch y Alice (mencionado en el trabajo). - Concluir a partir del experimento que Scratch es una herramienta adecuada para la educación en Chile, sin incluir resultados con otros lenguajes es un poco apresurado. - Sería deseable mencionar que instituciones o trabajos relacionados con lenguajes para fomentar el pensamiento lógico se han realizado en Chile. No se menciona ninguno como referencia o en la bibliografía. - El ejercicio utilizado en el experimento es uno sólo, se deberían utilizar más si se desea objetivamente evaluar su utilización como lenguaje para mejorar el razonamiento lógico. - La primera cita proviene de un portal de noticias Colombiano y del 2006. Sería deseable una referencia más sólida y local asociada quizás a los lineamientos y planes de estudio del ministerio de educación.   Forma: - Se debe re-escribir el abstract: posee muchas palabras separadas por comas y la redacción incluye ideas desconectadas entre sí. - Se cita 8 veces la cita 7/8. Con la mitad de ellas queda clara la referencia. - \".. pero pocos aprender a programar ..\" debería ser: \".. pero pocos aprendeN a programar ..\". - La cita 2 dice .. \"Fundamentos de POgramacion\".. debería ser: \".. Fundamentos de Programación\".",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta en detalle el proceso realizado para la digitalización del archivo histórico de la parroquia San Pedro de Coquimbo. Se entregan los antecedentes previos, el análisis realizado y se explica la solución implementada.  Los autores muestran claramente los pasos realizados para implementar la solución propuesta.  Si bien la solución propuesta es correcta para el problema planteado, no se destaca un aporte significativo respecto a previas soluciones tecnológicas asociadas a digitalización de documentos.  El artículo no muestra resultados o evaluaciones realizadas al sistema implementado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper addresses an important and timely topic in a creative way. I consider it to have three flaws (and one good idea).  1) insufficient context of what is known and had been studied before (in shallow RL), for example within the field of “robust RL”. A good place to start might be with the work of Shie Mannor.  2) an ill-defined general problem setup. Does it make sense to do post-hoc labeling of certain actions as “catastrophic” if the agent is not informed about that metric during learning? Training a system to do one thing (maximize reward), but then evaluating it with a different metric is misleading. On the training metric, it could even be that the baseline outperforms the new algorithm? So I’d want to see plots for “average reward” in fig 3 as well. Also, what would the baseline learn if it was given large negative rewards for entering these otherwise invisible “danger states”?  3) a somewhat ad-hoc solution, that introduces new domain-specific hyperparameters (k_r, k_lambda and lambda) a second deep network and and two additional replay memories. In terms of results, I’m also unsure whether I can trust the results, given the long-standing track-record of cart-pole being fully solved by many methods: is DQN an outlier here? Or is the convnet not an appropriate function-approximator? Actually: which exact variant “state-of-the-art” variant of DQN are you using?  The good idea that I encourage the authors to pursue further is D_d, this set of rare but dangerous states, that should be kept around in some form. I see it as an ingredient for continual learning that most typical methods lack -- it is also one of the big differences between RL and supervised learning, where such states would generally be discarded as outliers.  Given my comment a couple of weeks ago, and the prompt response (“we implemented expected SARSA”), I would have expected that the paper had been revised with the new results by now? In any case, I’m open to discussing all these points and revising my opinion based on an updated version of the paper.  Minor comment: the bibliography is done sloppily, with missing years, conference venues and missing/misspelled author lists, e.g. “Sergey et al. Levine”. I also think it is good form to cite the actual conference publications instead of arXiv where applicable.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Two things I really liked about this paper: 1. The whole idea of having a data-dependent proposal distribution for MCMC. I wasn't familiar with this, although it apparently was previously published. I went back: the (Zhu, 2000) paper was unreadable. The (Jampani, 2014) paper on informed sampling was good. So, perhaps this isn't a good reason for accepting to ICLR.  2. The results are quite impressive. The rough rule-of-thumb is that optimization can help you speed up code by 10%. The standard MCMC results presented on the paper on randomly-generated programs roughly matches this (15%). The fact that the proposed algorithm get ~33% speedup is quite surprising, and worth publishing.  The argument against accepting this paper is that it doesn't match the goals of ICLR. I don't go to ICLR to hear about generic machine learning papers (we have NIPS and ICML for that). Instead, I go to learn about how to automatically represent data and models. Now, maybe this paper talks about how to represent (generated) programs, so it tangentially lives under the umbrella of ICLR. But it will compete against more relevant papers in the conference -- it may just be a poster. Sending this to a programming language conference may have more eventual impact.  Nonetheless, I give this paper an \"accept\", because I learned something valuable and the results are very good.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: 1) an interesting task, 2) the paper is very clearly written, easy to follow, 3) the created data set may be useful for other researchers, 4) a detailed analysis of the performance of the model.  - Weaknesses: 1) no method adapted from related work for a result comparison 2) some explanations about the uniqueness of the task and discussion on limitations of previous research for solving this problem can be added to emphasize the research contributions further.   - General Discussion: The paper presents supervised and weakly supervised models for frame classification in tweets. Predicate rules are generated exploiting language-based and Twitter behavior-based signals, which are then supplied to the probabilistic soft logic framework to build classification models. 17 political frames are classified in tweets in a multi-label classification task. The experimental results demonstrate the benefit of the predicates created using the behavior-based signals. Please find my more specific comments below:  The paper should have a discussion on how frame classification differs from stance classification. Are they both under the same umbrella but with different levels of granularity?  The paper will benefit from adding a brief discussion on how exactly the transition from long congressional speech to short tweets adds to the challenges of the task. For example, does past research rely on any specific cross-sentential features that do not apply to tweets? Consider adapting the method of a frame classification work on congressional speech (or a stance classification work on any text) to the extent possible due to its limitations on Twitter data, to compare with the results of this work.  It seems “weakly supervised” and “unsupervised” – these two terms have been interchangeably used in the paper (if this is not the case, please clarify in author response). I believe \"weakly supervised\" is the more technically correct terminology under the setup of this work that should be used consistently throughout. The initial unlabeled data may not have been labeled by human annotators, but the classification does use weak or noisy labels of some sort, and the keywords do come from experts. The presented method does not use completely unsupervised data as traditional unsupervised methods such as clustering, topic models or word embeddings would.    The calculated Kappa may not be a straightforward reflection of the difficulty of frame classification for tweets (lines: 252-253), viewing it as a proof is a rather strong claim. The Kappa here merely represents the annotation difficulty/disagreement. Many factors can contribute to a low value  such as poorly written annotation guidelines, selection of a biased annotator, lack of annotator training etc. (on top of any difficulty of frame classification for tweets by human annotators, which the authors actually intend to relate to). 73.4% Cohen’s Kappa is strong enough for this task, in my opinion, to rely on the annotated labels.   Eq (1) (lines: 375-377) will ignore any contextual information (such as negation or conditional/hypothetical statements impacting the contributing word) when calculating similarity of a frame and a tweet. Will this have any effect on the frame prediction model? Did the authors consider using models that can determine similarity with larger text units such as perhaps using skip thought vectors or vector compositionality methods?    An ideal set up would exclude the annotated data from calculating statistics used to select the top N bi/tri-grams (line: 397 mentions entire tweets data set has been used), otherwise statistics from any test fold (or labeled data in the weakly supervised setup) still leaks into the selection process. I do not think this would have made any difference in the current selection of the bi/tri-grams or results as the size of the unlabeled data is much larger, but would have constituted a cleaner experimental setup.    Please add precision and recall results in Table 4.   Minor: please double check any rules for footnote placements concerning placement before or after the punctuation.",
            "output": [
                "en"
            ]
        },
        {
            "input": "NO ME ENCUENTRO CAPACITADO PARA EFECTUAR ESTA REVISION. ESTA MUY LEJOS DE MI ESPECIALIZACION.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Presenta un trabajo de gran relevancia para la ciencia en Chile, mencionando elementos muy necesarios para el desarrollo de las comunicaciones de alto desempeño en los polos tecnológicos y de investigación  Podría profundizar en una breve descripción técnica de la tecnología que se menciona en el paper, dado que el trabajo no es autocontenido.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo describe una interesante aplicación de control de un dispositivo físico (para el caso en estudio, un robot móvil de Lego Mindstorms), mediante el procesamiento de las señales derivadas de cambios de índole facial y/o mental, provenientes de un casco  Emotiv EEG, el cual realiza un electroencefalograma de alta resolución. Sin embargo a pesar de lo interesante del trabajo presentado, el artículo carece del rigor que caracteriza al proceso metodológico de investigación, no se observa una discusión bibliográfica critica, no hay una definición clara del problema a investigar, presenta una pobre discusión  de resultados y abundantes errores de forma (Ej. la página 3  presenta el siguiente texto “¡Error! No se encuentra el origen de la referencia”, no existe página 2, etc.), que denotan que el autor no fue riguroso en su revisión antes del envío. Finalmente en mi opinión el trabajo es un buen aporte como un excelente trabajo de proyecto o taller dentro la malla curricular de alguna carrera de Informática o Electrónica.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El paper corresponde a una muy buena aplicación de una plataforma para interfaz gestual de acciones con un robot. Esta bien redactado y con buen uso de las referencias",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors apply the image captioning architecture of Xu et al. 2015 to video captioning. The model is extended to have attention over multiple layers of the ConvNet instead of just a single layer. Experiments on YouTube2Text, M-VAD and MSR-VTT show that this works better than only using one of the layers at a time.  I think this is solid work on the level of a well-executed course project or a workshop paper. The model makes sense, it is adequately described, and the experiments show that attending over multiple layers works better than attending over any one layer in isolation. Unfortunately, I don't think there is enough to get excited about here from a technical perspective and it's not clear what value the paper brings to the community. Other aspects of the paper, such as including the hard attention component, don't seem to add to the paper but take up space.   If the authors want to contribute a detailed, focused exploration of multi-level features this could become a more valuable paper, but in that case I would expect a much more thorough exploration of the choices and tradeoffs of different schemes without too many spurious aspects such as video features, hard attention, etc.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper is very interesting, I like the idea, and to make it a work publishable in vennue reaching a wider international audience it is necessary to validate the proposed ideas through extensive experimentation with actual data and users, please go ahead.",
            "output": [
                "en"
            ]
        },
        {
            "input": "## Paper summary  The paper reconsiders the idea of using a binary classifier to do two-sample testing. The idea is to split the sample into two disjoint training and test sets, train a classifier on the training set, and use the accuracy on the test set as the test statistic. If the accuracy is above chance level, one concludes that the two samples are from different distributions i.e., reject H0.  A theoretical result on an asymptotic approximate test power is provided. One implication is that the test is consistent, assuming that the classifier is better than coin tossing. Experiments on toy problems, evaluation of GANs, and causal discovery verify the effectiveness of the test. In addition, when the classifier is a neural net, examining the first linear filter layer allows one to see features which are most activated. The result is an interpretable visual indicator of how the two samples differ.  ## Review summary   The paper is well written and easy to follow. The idea of using a binary classifier for a two-sample testing is not new, as made clear in the paper. The main contributions are the analysis of the asymptotic test power, the use of modern deep nets as the classifier in this context, and the empirical studies on various tasks. The empirical results are satisfactorily convincing.  Although not much discussion is made on why the method works well in practice, overall contributions have a potential to start a new direction of research on model criticisms of generative models, as well as visualization of where a model fails. I vote for an acceptance.  ## Major comments / questions   My main concern is on Theorem 1 (asymptotic test power) and its assumptions.  But, I understand that these can be fixed as discussed below.  * Under H0, the distribution of the test statistic (i.e., sum of 0-1 classification results) follows Binomial(nte, 1/2) as stated.  However, under H1, terms in the sum are independent but *not* identical Bernoulli random variable. This is because each term depends on a data point z_i, which can be from either P or Q. So, in the paragraph in Sec3.1: \"... the random variable n_te \\hat{t} follows a Binomial(nte, p)...\" is not correct. Essentially p depends on z_i. It should follow a Poisson binomial distribution.  * In the same paragraph, for the same reason, the alternative distribution of Binomial(nte, p=p_{risk}) is probably not correct. I guess you mention it to use Moivre-Laplace to get the asymptotic normality.   Anyway, I see no reason why you would need this statement as the Binomial is not required in the proof, but only its asymptotic normality. A variant of the central limit theorem (instead of the Moivre-Laplace theorem) for independent, non-identical variables would still allow you to conclude the asymptotic normality of the Poisson binomial (with some conditions). See for example",
            "output": [
                "en"
            ]
        },
        {
            "input": "Important task (attention models), interesting distillation application, well-written paper. The authors have been responsive in updating the paper, adding new experiments, and being balanced in presenting their findings. I support accepting this paper.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes Generative Adversarial Parallelization (GAP), one schedule to train N Generative Adversarial Networks (GANs) in parallel. GAP proceeds by shuffling the assignments between the N generators and the N discriminators at play every few epochs. Therefore, GAP forces each generator to compete with multiple discriminators at random. The authors claim that such randomization reduces undesired \"mode collapsing behaviour\", typical of GANs.  I have three concerns with this submission.  1) After training the N GANs for a sufficient amount of time, the authors propose to choose the best generator using the GAM metric. I oppose to this because of two reasons. First, a single GAN will most likely be unable to express the full richness of the true data begin modeled. Said differently, a single generator with limited power will either describe a mode well, or describe many modes poorly. Second, GAM relies on the scores given by the discriminators, which can be ill-posed (focus on artifacts). Since there is There is nothing wrong with mode collapsing when this happens under control. Thus, I believe that a better strategy would be to not choose and combine all generators into a mixture. Of course, this would require a way to decide on mixture weights. This can be done, for instance, using rejection sampling based on discriminator scores.  2) The authors should provide a theoretical (or at least conceptual) comparison to dropout. In essence, this paper has a very similar flavour: every generator is competing against all N discriminators, but at each epoch we drop N-1 for every generator. Related to the previous point, after training dropout keeps all the neurons, effectively approximating a large ensemble of neural networks.  3) The qualitative results are not convincing. Most of the figures show only results about GAP. How do the baseline samples look like? The GAN and LAPGAN papers show very similar samples. On the other hand, I do not find Figures 3 and 4 convincing: for instance, the generator in Figure 3 was most likely under-parametrized.  As a minor comment, I would remove Figure 2. This is because of three reasons: it may be protected by copyright, it occupies a lot of space, and it does not add much value to the explanation. Also, the indices (i_t) are undefined in Algorithm 1.  Overall, this paper shows good ideas, but it needs further work in terms of conceptual development and experimental evaluation.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este artículo propone un sistema que agrega componentes difusos a ciertos atributos de una base de datos con información sobre el estado físico de personas.  La aplicación del trabajo es interesante, ya que son escasas las experiencias donde en la práctica se utilicen atributos difusos para almacenamiento y consulta en nuestro país, por lo que puede hacer que el tema tratado sea interesante para nuestro congreso.  Sin embargo los siguientes aspectos, o no quedan claros o están incompletos: - Utilizar formato solicitado por el congreso. - Mejorar redacción general del resumen/introducción - Redactar en tercera persona el punto 3, 4.1.1 cuando se refiere al cliente - Cuidar el uso de abreviaturas que a veces se usan en minúsculas o mayúsculas - Redactar la conclusión con un enfoque donde se deje claro qué beneficios que obtuvo el usuario del sistema con respecto a un sistema no difuso - No queda claro cómo se determinaron las funciones de pertenencia utilizadas. - Falto algún tipo de estudio/comparativa para comprobar el aporte que un sistema como el propuesto mejora o complementa un sistema tradicional en el área aplicada  Debido a lo anterior, se recomienda aceptar el artículo para su presentación en el Workshop de aplicaciones empresariales.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper presents a variational inference based method for learning nonlinear dynamical systems. Unlike the deep Kalman filter, the proposed method learns a state space model, which forces the latent state to maintain all of the information relevant to predictions, rather than leaving it implicit in the observations. Experiments show the proposed method is better able to learn meaningful representations of sequence data.  The proposed DVBF is well motivated, and for the most part the presentation is clear. The experiments show interesting results on illustrative toy examples. I think the contribution is interesting and potentially useful, so I’d recommend acceptance.  The SVAE method of Johnson et al. (2016) deserves more discussion than the two sentences devoted to it, since the method seems pretty closely related. Like the DVBF, the SVAE imposes a Markovianity assumption, and it is able to handle similar kinds of problems. From what I understand, the most important algorithmic difference is that the SVAE q network predicts potentials, whereas the DVBF q network predicts innovations. What are the tradeoffs between the two?  Section 2.2 says they do the latter in the interest of solving control-related tasks, but I’m not clear why this follows.   Is there a reason SVAEs don’t meet all the desiderata mentioned at the end of the Introduction?  Since the SVAE code is publicly available, one could probably compare against it in the experiments.   I’m a bit confused about the role of uncertainty about v. In principle, one could estimate the transition parameters by maximum likelihood (i.e. fitting a point estimate of v), but this isn’t what’s done. Instead, v is integrated out as part of the marginal likelihood, which I interpret as giving the flexibility to model different dynamics for different sequences. But if this is the case, then shouldn’t the q distribution for v depend on the data, rather than being data-independent as in Eqn. (9)?",
            "output": [
                "en"
            ]
        },
        {
            "input": "En esta investigación se trata un tema que cada vez es más importante en ámbitos académicos y empresariales. Por otra parte, se utilizan métodos de análisis de datos complejos y muy adecuados a los objetivos de la investigación y los autores los que sirven de referencia básica para la investigación son muy adecuados.  En la medida en que el objeto material de la investigación es el individuo, entiendo que, cuando se describe la muestra, es conveniente, no sólo describir el perfil de la empresa, sino el perfil del individuo entrevistado (edad, sexo, puesto que ocupa, etc.). •\tEl apartado conclusiones merece, a mi juicio, una mayor atención, que incluya no sólo los resultados de la investigación, sino una discusión más amplia. •\tLas limitaciones de la investigación hacen referencia al tamaño de la muestra y al tipo de muestreo empleado, pero no hacen referencia a la dimensión del modelo. En este sentido, sería conveniente plantear, como línea de investigación futura, la ampliación del modelo con nuevas variables e indicadores •\tlas referencias bibliográficas son anteriores al año 2009. Sugiero consultar las siguientes o\tThe effect of organizational support on ERP implementation DonHee Lee,  Sang M. Lee, David L. Olson, Soong Hwan Chung.  Industrial Management + Data Systems.  Wembley:2010.  Vol. 110,  Iss. 2,  p. 269-283 o\tPredicting the behavioral intention to use enterprise resource planning systems :An exploratory extension of the technology acceptance model Fethi Calisir,  Cigdem Altin Gumussoy,  Armagan Bayram.  Management Research News.  Patrington:2009.  Vol. 32,  Iss. 7,  p. 597-613 o\tOrganizational adoption of information technologies: Case of enterprise resource planning systems Onur Kerimoglu,  Nuri Basoglu,  Tugrul Daim.  Journal of High Technology Management Research.  Greenwich:2008.  Vol. 19,  Iss. 1,  p. 21",
            "output": [
                "es"
            ]
        },
        {
            "input": "En este trabajo se presenta  una revisión de Sistemas Inmunes Artificiales  y  sus aplicaciones.  Observaciones:  Un trabajo de revisión tiene que ser cuidadoso y amplio, con comentarios críticos, sugerencias y conclusiones que sirvan como contribuciones del trabajo.  El artículo propuesto no incluye en la revisión trabajos  y aplicaciones recientes.  Luego, la revisión no es completa.  Por otro lado, no presenta  discusión crítica ni conclusiones de la revisión realizada. En consecuencia, el  autor no  alcanzó  ninguno de los dos objetivos esperados  para este trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Reviewers agree that the findings are not clear enough to be of interest, though the effort to do a controlled study is appreciated.",
            "output": [
                "en"
            ]
        },
        {
            "input": "In light of the authors' responsiveness and the updates to the manuscript -- in particular to clarify the meta-learning task -- I am updating my score to an 8.  -----  This manuscript proposes to tackle few-shot learning with neural networks by leveraging meta-learning, a classic idea that has seen a renaissance in the last 12 months. The authors formulate few-shot learning as a sequential meta-learning problem: each \"example\" includes a sequence of batches of \"training\" pairs, followed by a final \"test\" batch. The inputs at each \"step\" include the outputs of a \"base learner\" (e.g., training loss and gradients), as well as the base learner's current state (parameters). The paper applies an LSTM to this meta-learning problem, using the inner memory cells in the *second* layer to directly model the updated parameters of the base learner. In doing this, they note similarities between the respective update rules of LSTM memory cells and gradient descent. Updates to the LSTM meta-learner are computed based on the base learner's prediction loss for the final \"test\" batch. The authors make several simplifying assumptions, such as sharing weights across all second layer cells (analogous to using the same learning rate for all parameters). The paper recreates the Mini-ImageNet data set proposed in Vinyals et al 2016, and shows that the meta-learner LSTM is competitive with the current state-of-the-art (Matchin Networks, Vinyals 2016) on 1- and 5-shot learning.  Strengths: - It is intriguing -- and in hindsight, natural -- to cast the few-shot learning problem as a sequential (meta-)learning problem. While the authors did not originate the general idea of persisting learning across a series of learning problems, I think it is fair to say that they have advanced the state of the art, though I cannot confidently assert its novelty as I am not deeply familiar with recent work on meta-learning. - The proposed approach is competitive with and outperforms Vinyals 2016 in 1-shot and 5-shot Mini-ImageNet experiments. - The base learner in this setting (simple ConvNet classifier) is quite different from the nearest-neighbor-on-top-of-learned-embedding approach used in Vinyals 2016. It is always exciting when state-of-the-art results can be reported using very different approaches, rather than incremental follow-up work. - As far as I know, the insight about the relationship between the memory cell and gradient descent updates is novel here. It is interesting regardless. - The paper offers several practical insights about how to design and train an LSTM meta-learner, which should make it easier for others to replicate this work and apply these ideas to new problems. These include proper initialization, weight sharing across coordinates, and the importance of normalizing/rescaling the loss, gradient, and parameter inputs. Some of the insights have been previously described (the importance of simulating test conditions during meta-training; assuming independence between meta-learner and base learner parameters when taking gradients with respect to the meta-learner parameters), but the discussion here is useful nonetheless.  Weaknesses: - The writing is at times quite opaque. While it describes very interesting work, I would not call the paper an enjoyable read. It took me multiple passes (as well as consulting related work) to understand the general learning problem. The task description in Section 2 (Page 2) is very abstract and uses notation and language that is not common outside of this sub-area. The paper could benefit from a brief concrete example (based on MNIST is fine), perhaps paired with a diagram illustrating a sequence of few-shot learning tasks. This would definitely make it accessible to a wider audience. - Following up on that note, the precise nature of the N-class, few-shot learning problem here is unclear to me. Specifically, the Mini-ImageNet data set has 100 labels, of which 64/16/20 are used during meta-training/validation/testing. Does this mean that only 64/100 classes are observed through meta-training? Or does it mean that only 64/100 are observed in each batch, but on average all 100 are observed during meta-training? If it's the former, how many outputs does the softmax layer of the ConvNet base learner have during meta-training? 64 (only those observed in training) or 100 (of which 36 are never observed)? Many other details like these are unclear (see question). - The plots in Figure 2 are pretty uninformative in and of themselves, and the discussion section offers very little insight around them.  This is an interesting paper with convincing results. It seems like a fairly clear accept, but the presentation of the ideas and work therein could be improved. I will definitely raise my score if the writing is improved.",
            "output": [
                "en"
            ]
        },
        {
            "input": "•I recommend to change the paper title in order to be according to paper‘ body •Review the English grammar, some but not all of the errors founded in the review are:  •Abstract   o what does it mean that for them?--> what does it mean that for them?   o …utilized to represent its appropriateness.--> …utilized to represent their appropriateness.   •Introducction   o …has like first phase… --> ?   o auscultating --> is it a verb?   •Background   o A systematic mapping study is a methodology that is used --> A systematic mapping study is a methodology used   o …of existing research on performance evaluation… -->…of existing research on the performance evaluation…   o Only Dieste and Juristo’s work [10] deals --> Only the work of Dieste and Juristo [10] deals   •Methodology   o Review the use of –ly with the verb to be   o Third question: What kind of studies does use with a higher frequency certain constructs for   o appropriateness of techniques? --> ? review the types question structure   •Classification schema   o In order to answer the research questions, the literature review focused --> literature or mapping?   •Analysis of the result   o in Figure 1 en DCM format -->in Figure 1 en DCM format.   o article --> paper   •Conclusions and future works   o For this reason, it is necessary that more proposals are carried out to help --> For this reason, it is necessary to carry out more proposals to help   •Figures: be careful on the figure´s title, the title must be following the figure  •Type of studies  •Paragraph after figure 5: Experimental (paragraph) o experiment (figure)  •Techniques considered: I recommend performing a mapping between domains and techniques and or with the constructors and show the a graphic of the results instead of the figure 8",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:  When introducing the task, the authors use illustrative examples as well as the contributions of this paper.  Related Works section covers the state of the art, at the same time pointing similarities and differences between related Works and the proposed method. The presentation of the method is very clear, since the authors separate the tagging scheme and the end-to-end model. Another strong point of this work is the baselines used to compare the proposed methods with several classical triplet extraction methods. At last, the presentation of examples from dataset used to illustrate the advantages and disadvantages of the methods was very important. These outputs complement the explanation of tagging and evaluation of triplets.   - Weaknesses:  One of the main contributions of this paper is a new tagging scheme described in Section 3.1, however there are already other schemes for NER and RE being used, such as IO, BIO and BILOU.  Did the authors perform any experiment using other tagging scheme for this method? Regarding the dataset, in line 14, page 5, the authors cite the number of relations (24), but they do not mention the number or the type of named entities. In Section 4.1, the evaluation criteria of triplets are presented. These criteria were based on previous work? As I see it, the stage of entity identification is not complete if you consider only the head of the entity. Regarding example S3, shown in Table 3, the output of the LSTM-LSTM-Bias was considered correct? The text states that the relation role is wrong, although it is not clear if the relation role is considered in the evaluation.   - General Discussion:  This paper proposes a novel tagging scheme and investigates the end-to-end models to jointly extract entities and relations.  The article is organized in a clear way and it is well written, which makes it easy to understand the proposed method.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo está bien estructurado, respeta el formato establecido. Se presentan dos propuestas asociadas a distintas etapas de los procesos de cocreación de valor. Ambas propuestas se presentan de forma resumida. Se sugiere extender un poco más la presentación de cada una de ella, y ejemplificarlas mediante su aplicación en algún caso de estudio. Se observan algunos errores de acentuación y de edición en algunas partes (Ej. Sección Resultados, \"se validó la el modelo...\") Se observa un problema de formato en las referencias. Algunas de las referencias bibliográficas son muy antiguas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo describe básicamente los componentes de un aerodeslizador, y el sensor que podría ser utilizado para el control de navegación.  Es un estudio más bien teórico que no presenta evidencias de su construcción.  No queda claro si la propuesta ya fue publicada por el inserto en pie de página.  Se deben corregir varios errores de tipo gramatical; Ejemplos: Primer párrafo introducción ”con el término” y no “el término” C. Sistema de propulsión … a los cuales se acoplará Texto figura 2 debe incorporarse al pie de la figura Figura 3 sin título Figura 6 después de la 3? Penúltimo párrafo hoja 4 (“con estés….”) Enumerar ecuaciones.",
            "output": [
                "es"
            ]
        },
        {
            "input": "La verificación de la arquitectura de un producto software puede ser una gran contribución a la calidad del mismo, por lo cual, cualquier herramienta que facilite esta labor es un aporte a la ingeniería de software. Presentan evidencias de una revisión previa de métodos y herramientas alternativas o complementarias a la propuesta. Las descripciones presentadas se acompañan de ejemplos aclaratorios.  No queda claro el rol e interacción del experto del dominio. En las secciones iniciales dice que la herramienta realiza análisis estático y dinámico, sin embargo al final del artículo, en la identificación de posibles mejoras de SAVE se propone incluir el análisis dinámico, lo que se contradice con la afirmación inicial. La descripción del funcionamiento de la herramienta no está lo suficientemente claro. La calidad de la figuras no es adecuada, por el tamaño y resolución de las mismas no es posible apreciar bien los detalles. La redacción de artículo puede ser mejorada. Hay varias frases en donde faltan conectores, por ejemplo \"En el presente apartado, veremos S.A.V.E. logra recuperar las dependencias existentes en el código fuente....\" Muchos errores en la acentuación de las palabras.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This work investigates the performance of transfer learning from resource-rich setup (BookTest, CNN/Daily Mail corpora) to low-resource (bAbI, SQuAD benchmarks) settings. Experiments show poor improvements in 0-shot learning. However, when the model is exposed to few training instances some improvements are observed.  The claims made here require a more comprehensive analysis. I criticize the use of bAbI as a low-resource real-world scenario. bAbI is designed as a unit test and is far from representing many natural language phenomena. Thus, the claims related to bAbI can only be weak evidence for questioning transfer learning high-resource to low-resource in real-world scenarios. I highly recommend using recently proposed real-world scenarios [1,2].  More importantly, the work does not explain why and how do we get improvement using transfer learning. They remotely address this by hypothesizing the knowledge of transfer is not just encoded in embeddings but also in the model. Considering the related work [3], these claims bring a marginal novelty and still \"how and why\" should be central in this work.    [1]",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta el desarrollo de una solución al problema de analizar tendencias en el desembarco de especies marinas en el borde costero chileno, utilizando herramientas de inteligencia de negocios.  a) aspectos de forma  1. la versión en inglés del título y el resumen del artículo contiene errores gramaticales, de redacción, y de estilo.  2. Uso de mayúsculas: chile --> Chile servicio nacional de pesca --> Servicio Nacional de Pesca kettle --> Kettle tabla 1 --> Tabla 1 api --> API etc.  3. Figura 2 no es referenciada Esta figura muestra --> La Figura 10 muestra  4. parráfo despues de la Figura 1 esta escrito en 1 columna. debe ser en 2 columnas  5. formato no concuerda totalmente con el formato Infonor.  b) aspectos de fondo   1. El artículo no reporta resultados de investigación. Se trata de una aplicación de técnicas de BI para proveer soporte de análisis en línea de datos.  2. Es débil en cuanto a background de procesos y técnicas utilizados. Aunque se listan 12 referencias, solo se citan 2 o 3 de ellas en forma reiterada. No hay revisión de trabajos relacionados (casos de aplicaciones de BI.)  3. Dada la orientación del artículo, debe detallarse mucho más el uso (potencial) de los resultados. En este sentido, debe haber una mayor y mejor interpretación/evaluación por parte de los usuarios de los análisis de la información.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper applies the idea of normalizing flows (NFs), which allows us to build complex densities with tractable likelihoods, to maximum entropy constrained optimization.  The paper is clearly written and is easy to follow.  Novelty is a weak factor in this paper. The main contributions come from (1) applying previous work on NFs to the problem of MaxEnt estimation and (2) addressing some of the optimization issues resulting from stochastic approximations to E[||T||] in combination with the annealing of Lagrange multipliers. Applying the NFs to MaxEnt is in itself not very novel as a framework. For instance, one could obtain a loss equivalent to the main loss in eq. (6) by minimizing the KLD between KL[p_{\\phi};f], where f is the unormalized likelihood f \\propto exp \\sum_k( - \\lambda_k T - c_k ||T_k||^2  ). This type of derivation is typical in all previous works using NFs for variational inference. A few experiments on more complex data would strengthen the paper's results. The two experiments provided show good results but both of them are toy problems.   Minor point:  Although intuitive, it would be good to have a short discussion of step 8 of algorithm 1 as well.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The following statement best summarizes the contribution: \"This paper shows that model free RL methods can learn how to gather information about physical properties of objects, even when this information is not available to a passive observer, and use this information to make decisions.\" So this is not a paper about new theory or algorithms, but rather about solving the problem of acquiring knowledge about the physics of the world around us, which is important for many problems and helps explain human performance in many tasks. There are still some concerns about the depth-of-analysis of the paper, but on balance, it is seen as an unconventional but interesting paper. As per AnonReviewer6, the final version could still aim to better address \"What should other researchers focus on if they are trying to build agents that can understand physics intuitively (building off this work)?\"  -- Area chair",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper takes a model based on that of Graves and retrofits it with a representation derived from the work of Plamondon.  part of the goal of deep learning has been to avoid the use of hand-crafted features and have the network learn from raw feature representations, so this paper is somewhat against the grain.   The paper relies on some qualitative examples as demonstration of the system, and doesn't seem to provide a strong motivation for there being any progress here.  The paper does not provide true text-conditional handwriting synthesis as shown in Graves' original work.   Be more consistent about your bibliography (e.g. variants of Plamondon's own name, use of \"et al.\" in the bibliography etc.)",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo presenta el diseño de AMADEUS, una plataforma que permite implementar trayectorias de robots móviles en ambientes semi-estructurados, para la investigación de los algoritmos asociados.  El trabajo en general es adecuado, sin embargo carece de algo importante: la comparación de la plataforma presentada con otras plataformas similares. Esto se ve claramente reflejado en el número de referencias. Sería adecuado el presentar referencias respecto a otras plataformas similares, e indicar cuál es la diferencia de AMADEUS respecto a ellas, lo que dejaría claramente presentado el aporte del trabajo.  Problemas en la redacción del resumen (Para llevar a cabo los movimientos definidos...). También el inglés debe ser revisado.  La calidad de las ecuaciones usadas debe ser mejorada.  La tabla en la página 9 no se ve bien, esto debe ser mejorado.  la sección 10 se llama \"resultados\", sin embargo lo que muestra son casos de estudio o aplicación de la plataforma.  En resumen, el trabajo es adecuado para ser aceptado, sin embargo el estado del arte respecto a plataformas similares debe ser mejorado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Un muy bien escrito e interesante artículo. Habría sido interesante incluir los algoritmos originales y los propuestos de forma más rigorosa (paso 1, paso 2, etc.) así como un análisis estadístico de la calidad de las respuestas de ambos.   Citar en el texto la figura 4.  Mejorar la calidad de las figuras 6 y 7.   En algunas partes coloca ecuación (n), en otras ec. (n) y en otras ecuación ec. (n)... padronzar para el primero o el segundo.  Padronizar también el nombre de los autores en las referencias bibliográficas, pues algunos usan iniciales, en otro los nombres completos y en otros mixtos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Observación de fondo:  No se presenta un ejemplo de implementación (un ejemplo que sea interesante) de una máquina secuencial mediante la metodolgía propuesta y la tradicional cableada con el fin de establecer comparativos y métricas de desempeño.  Observaciones de forma: realizar las siguientes correcciones:  Omitir el punto final del título en español.  En página 3, segunda columna: \"... entrada y las variables de estado de la máquina a secuencial.\"  En página 4, primera columna: justificación a la izquierda.  En página 5, primera columna: \"... cantidad de puertos de entrada y salid ...\"  En página 5, primera columna: \"... completo a partir de la dirección de cada de cada ...\", \"... máquina con hasta 15 considerando la suma de ...\".  En página 5, segunda columna: \"... máquina con hasta 15 considerando la suma de ...\".",
            "output": [
                "es"
            ]
        },
        {
            "input": "Summary: This paper on autoregressive generative models explores various extensions of PixelCNNs. The proposed changes are to replace the softmax function with a logistic mixture model, to use dropout for regularization, to use downsampling to increase receptive field size, and the introduction of particular skip connections. The authors find that this allows the PixelCNN to outperform a PixelRNN on CIFAR-10, the previous state-of-the-art model. The authors further explore the performance of PixelCNNs with smaller receptive field sizes.  Review: This is a useful contribution towards better tractable image models. In particular, autoregressive models can be quite slow at test time, and the more efficient architectures described here should help with that.  My main criticism regards the severe neglect of related work. Mixture models have been used a lot in autoregressive image modeling, including for multivariate conditional densities and including downsampling to increase receptive field size, albeit in a different manner: Domke (2008), Hosseini et al. (2010), Theis et al. (2012), Uria et al. (2013), Theis et al. (2015). Note that the logistic distribution is a special case of the Gaussian scale mixture (West, 1978).  The main difference seems to be the integration of the density to model integers. While this is clearly a good idea and the right way forward, the authors claim but do not support that not doing this has “proved to be a problem for earlier models based on continuous distributions”. Please elaborate, add a reference, or ideally report the performance achieved by PixelCNN++ without integration (and instead adding uniform noise to make the variables continuous).  60,000 images are not a lot in a high-dimensional space. While I can see the usefulness of regularization for specialized content – and this can serve as a good example to demonstrate the usefulness of dropout – why not use “80 million tiny images” (superset of CIFAR-10) for natural images? Semi-supervised learning should be fairly trivial here (because the model’s likelihood is tractable), so this data could even be used in the class-conditional case.  It would be interesting to know how fast the different models are at test time (i.e., when generating images).",
            "output": [
                "en"
            ]
        },
        {
            "input": "el trabajo presenta una posible solución a una problemática real, es interesante la propuesta de la SOS veterinaria. En el trabajo se plantean elementos importantes a tener en cuenta para el desarrollo de una aplicación móvil, aunque en algunas partes del texto es presentada como un desarrollo web. En el trabajo promete el desarrollo de la aplicación. El articulo muestra cómo podría obtenerse una mayor rentabilidad y una mejor gestión organizativa en un SOS Veterinaria, pero no hay un aporte claro que se evidencie en la implementación de un sistema de este tipo.  La figura 2 Process Diagram Level 0 of the Application debe mejorarse, es borrosa. En la figura 3 se presenta la descripción de la solución pero la información debería acompañarse de información que dé cuenta del proceso de forma detallada. hace falta identificar la manera de almacenar y gestionar los datos. La información estará almacenada en una BD? en archivos XML?..... hace falta una pequeña descripción de la arquitectura del sistema. La calidad de las figuras 4 hasta la 12 no es buena, los textos son borrosos.  El artículo debería centrarse en el aporte y los resultados de la aplicación de este tipo de desarrollos.  Se mencionan muchas tecnologías y técnicas de desarrollo pero no es evidente en el desarrollo de la SOS veterinaria.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo trata de un proceso de data mining orientado a describir agrupamientos para el análisis de lavados de activos en el rubro bancario. Utiliza como referencia metodológica el proceso CRISP-DM y lo sigue con cierta dedicación.  En cuanto al fondo: detalla demasiados aspectos que guardan relación con la parte descriptiva del tema financiero y del banco en particular donde se circunscribe el desarrollo del trabajo. También enfatiza la obtención de la vista minable que está bien, pero descuida la generación del modelo data mining, específicamente no muestra el modelo de clustering, tampoco los niveles de cobertura y confianza en cada regala de cada clúster, no realiza un análisis estadístico acerca de los patrones y tampoco se observa un validación del modelo y patrones obtenidos. Esto último es la mayor debilidad del trabajo.  En referencia a la forma: hay muchos errores de ortografía y redacción, excesivo el largo de algunos párrafos y redacción de algunos tópicos que se debieran resumir, también redacta en cuarta persona y en algunas partes en tiempo futuro, debiera estandarizar la redacción a 3era persona y tiempo presente, salvo en las conclusiones que puede ocupar tiempo pasado. Excede el nro. de páginas establecidas como máximo. Finalmente, presenta poca bibliografía (sólo 4) y además no las referencias en ningún lado.  Es un artículo que puede ser aceptado pero requiere un re-ordenamiento profundo en cuanto a la forma, y fundamentalmente en relación al modelo de data mining, su análisis y exhaustiva evaluación, así como sus resultados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Revisar la redacción del documento, en varios sitios dice \"en base a\" debe ser \"con base en\"  Error tipográfico en la figura 3  En la página 4 antes del subtitulo \"Modelo de movimiento\" dice del modelo de medida, creo que se refiere al  modelo de medición  Estimo conveniente resaltar cuales son las ventajas del modelo propuesto, tal como esta no es atractivo indican una diferencia con respecto a la referencia entre 7 y 5 cms, esto es  una desviación considerable. Además indica dentro de las desventajas que no es aceptable para trabajar en aplicaciones reales. Sino es así entonces para qué es útil?",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper provides two RNN-based architectures for extractive document summarization. The first, \"Classify\", reads in the whole document and traverses the sentences a second time to decide whether to include them or not (0/1 decisions). The second, \"Select\",  reads in the whole document and picks the most relevant sentence one at the time. The models assume that oracle extractive summaries exist, and a pseudo ground-truth generation procedure is used, which mimics Svore et al. (2007) among others.   Overall, this paper seems a small increment over Cheng & Lapata (2016) and performance is similar or worse to that paper. The problem of single document extractive summarization is not particularly exciting since in DUC 2002 (14 years ago) existing models could not beat the lead baseline (which selects the first sentences of the document). It's a pity that this paper doesn't address the most interesting problems of abstractive summarization or apply the proposed approach to multi-document summarization. It's also a little disappointing that the maximum sentence length had to be capped to 50, which suggests the model has some trouble to scale.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo describe algunos aspectos generales de la aplicación de minería de datos a redes sociales.  La revisión de información no es completa y dista mucho de ser considerada como el estado del arte del tema.  Sugiero primero revisar artículos de revistas indexadas en el tema, identificar un problema de investigación concreto, donde se pueda realizar un aporte en el tema, y plantear una propuesta de investigación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Considera el uso de tecnologías móviles para incorporar en la medición de material particulado que existe en el interior de una mina. Será interesante ver las ventajas y desventajas de esta aplicación con otras existentes.  Es un estudio solamente. Todavía no hay resultados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El paper tiene una estructura relativamente coherente, introduce una serie de conceptos que para alguien que desconoce el tema podría ser útil, habla sobre patrones arquitectónicos y describe windows azure  Para alguien que conoce el tema resulta tedioso leer definiciones ya conocidas, por otro lado, el título del paper no es coherente con lo escrito en el manuscrito, de hecho a ratos me daba la sensación de estar leyendo un folleto comercial más que un trabajo científico, cloud computing y sobre todo sus implementaciones, como por ejemplo windows azure tienen ventajas y desventajas, por mencionar algunas desventajas: la pérdida de control, desempeño, privacidad, en latino américa todos los países tienen serios problemas de ancho de banda, por lo cual cloud computing puede constituir un riesgo más que un beneficio sino se mejora un aspecto básico, mejorar las redes de datos. Creo que el caso práctico debió explicarse más, ya que es la esencia que evidencia si cloud computing es útil o simplemente es otro buzzword que nos quiere vender el área comercial de las empresas TI. El paper se limita principalmente a explicar conceptos y bondades más que mostrar los beneficios y cualidades mediante un ejemplo o caso práctico.  El caso práctico no está detallado y el desarrollo de aplicaciones no es visto desde un punto de vista crítico, solo se mencionan aspectos positivos y no los negativos.  Aunque cloud es un término actual, después de participar en varios congresos de grid computing y sistemas colaborativos, no tengo claro aún si cloud es un buzzword del área comercial o si realmente tiene algo nuevo que no tenían los conceptos que se acuñaron antes, aunque falto una visión critica y objetiva de la temática, en partes parece un folleto comercial, creo que se puede generar una discusión abierta del tema para ayudar a responder las dudas que existen entorno al termino de cloud computing.  El paper tiene errores de redacción en el resumen, sin embargo, tiene coherencia y una evolución del tema, aunque el tema en que evoluciona no es alineado con el título del documento.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Es un buen trabajo, bien escrito, trata un tema nuevo en red de sensores acuáticos, reportara las pruebas más en detalle y la efectividad en la aplicación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Resumen: Este artículo analiza un conjunto de estudios con el objetivo de conocer que piensan los investigadores sobre la técnica de educación más adecuada.  Evaluación: El trabajo tiene una estructura de un paper y la propuesta se ve interesante. Sin embargo,  - Aunque el trabajo discute las consecuencias de los resultados, (creo que) no discute claramente las potenciales causas. Tal vez, se pueden obtener conclusiones interesantes de por qué existe esta divergencia mencionada.  - No me queda claro de por qué se quiere tener una convergencia absoluta sobre estas técnicas. A una simple vista, me da la impresión que un conjunto técnicas aplicadas a cierto contexto parece ser apropiado.  - Background es demasiado corto para introducir los conceptos necesarios para comprender la propuesta y  Related work es sumamente pobre (hay solamente 1 cita)  Detalles menores:  1) El nombre de la sección 2 “background & …” es sumamente ambiguo, lo cual se vuelve difícil de saber de qué se trata la sección. Sugiero ser más específico (ej. “systematic review for elicitation techniques”?) 2) No se explica “systematic mapping”, solamente se explica su uso. 3) ¿Por qué no se habla de meta-analisis? Meta-analisis pareciera que puede contribuir a esta discusión. 4) Reemplazaría “authors” por “we” cuando amerita (ej. párrafo 2 - página 2). En ocasiones, cuesta saber si hablan de autores de un trabajo en particular o del trabajo que están presentando. 5) Reemplazaría “you” por “one”. “You” es informal. 6) “El **estudio** identificó 42 **estudios**” —> demasiado “estudio” ??? 7) Texto de “Figure 3” está separado de su imagen. 8) Hay una página en blanco en el medio del documento. 9) “In order to move in this direction, this study aims auscultating how researchers represent the appropriateness of the techniques.” ¿Cuál dirección? Es ambiguo está oración.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo describe un caso de innovación empresarial que apoya los procesos de aprendizaje organizacional. El principal mérito del caso es que se ha logrado un impacto muy significativo con una inversión modesta de recursos. Adicionalmente se enfatiza al conocimiento como un elemento estratégico para la organización, el cual requiere acciones concretas de gestión y asignación de recursos. Finalmente, se debe destacar una redacción impecable y amena del caso.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El documento intenta mostrar una evaluación de atributos de calidad de software basada en el estándar ISO 9126. El documento muestra una propuesta de una plantilla con una serie de preguntas para analizar la calidad de diferentes atributos de calidad de un producto software desarrollado. Sin embargo, el documento carece de estructura. La redacción es deficiente. En algunas partes del documento no se siguen los parámetros de formato exigidos en la guía de autores. Por ejemplo, el resumen (abstract) está centrado y según la guía del evento debe estar justificado. De la misma forma se presentan algunos párrafos del documento. En cuanto a la redacción, el documento es difícil de leer, faltan o están mal ubicados los signos de puntuación. Las palabras claves no coinciden como palabras claves del artículo. Faltan referencias bibliográficas que sustenten las afirmaciones que se hacen. A pesar de que la plantilla puede ser tan útil como intentan asegurar en el trabajo, es necesario buscar una validación más consolidada que permita asegurar su utilidad. Las estadísticas presentadas carecen de justificaciones válidas y el formato de presentación es deficiente. Gran parte del documento se centra en hacer afirmaciones descritas en el estándar ISO 1926 y: 1. No se encuentra debidamente citado como referencia principal del trabajo. 2. Centrar el artículo para resumir la definición de cada característica o subcaracterística del estándar no parece muy apropiado para este tipo de trabajos. El formato de presentación de la plantilla carece de claridad. Pareciera que es un formato de cuestionario pero no se muestra como tal. Existe un listado de afirmaciones y preguntas poco claras. Algunas de dichas preguntas son mencionadas en los resultados, sin embargo no aparecen en el listado denominado por la autora como \"plantila\", es el caso de: ¿El sistema opera junto con otro sistema?. En términos generales el trabajo debe refinar mucho más.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Summary: The paper proposes a large-scale dataset for reading comprehension, with the final goal of releasing 1 million questions and answers. The authors have currently released 100,000 queries and their answers. The dataset differs from existing reading comprehension datasets mainly w.r.t queries being sampled from user queries rather than being generated by crowd-workers and answers being generated by crowd-workers rather than being spans of text from the provided passage. The paper presents some analysis of the dataset such as distribution of answer types. The paper also presents the results of some generative and some cloze-style models on the MS MARCO dataset.  Strengths:  1. The paper provides useful insights about the limitations of the existing reading comprehension datasets – questions asked by crowd-workers have different distribution compared to that of questions asked by actual users of intelligent agents, answers being restricted to span from the reading text rather than requiring reasoning across multiple pieces of text/passages.  2. MS MARCO dataset has novel useful characteristics compared to existing reading comprehension datasets – questions are sampled from user queries, answers are generated by humans.  3. The experimental evaluation of the existing baseline models on the MS MARCO dataset is satisfactory.  Weaknesses/Suggestions:  1. The paper does not report human performance on the dataset. Human performance should be reported to estimate the difficulty of the dataset. The degree of inter-human agreement will also reflect how well the metric (being used to compute inter-human agreement and accuracies of the baseline models) can deal with variance in the sentence structure with similar semantics.  2. I would like to see the comparison between the answer type distribution in the MS MARCO dataset and that in existing reading comprehension datasets such as SQuAD. This would ground the claim made in the paper the distributions of questions asked by crowd-workers is different from that of user queries.  3. The paper uses automatic metrics such as ROUGE, BLEU for evaluating natural language answers. However, it is known that such metrics poorly correlate with human judgement for tasks such as image caption evaluation (Chen et al., Microsoft COCO Captions: Data Collection and Evaluation Server, CoRR abs/1504.00325 (2015)). So, I wonder how authors justify using such metrics for evaluating open-ended natural language answers.  4. The paper mentions that a classifier was used to filter answer seeking queries from all Bing queries. It would be good to mention the accuracy of this classifier. This will provide insights into what percentage of the MS MARCO questions are answer seeking queries. Similarly, what is the accuracy of the information retrieval based system used to retrieve passages for filtered queries?  5. Please include the description of the best passage baseline in the paper.    6. Fix opening quotes, i.e. ” -> “ (for instance, on page 5, ”what” -> “what”).  Review Summary: The paper is well motivated, the use of user queries and human generated answers makes the dataset different from existing datasets. However, I would like to see the human performance on the dataset and quantitative comparison between the distribution of questions obtained from user queries and that of crowd-sourced questions. I would also like the authors to comment on the use of automatic metrics (such as ROUGE, BLEU) in the light of the fact that such metrics do not correlate well with human judgements for tasks such as image caption evaluation.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Loa autores siguen las metodologías SEMMA y CRISP-DM para el desarrollo del proyecto. A lo largo del paper los autores van describiendo la fase de la metodología, el trabajo realizado y los resultados obtenidos en esa fase, excepto en la fase de minería de datos (y clustering) que los autores posponen la descripción del trabajo y de los resultados a la sección 5 del paper. Esto hace que la estructura del paper no sea del todo clara.  Otro cosa, es la simplificación de las variables a tener en cuenta a la hora de hacer el proceso de data mining, puesto que habría que tener en cuenta otros aspectos relativos al cliente, al receptor, ...",
            "output": [
                "es"
            ]
        },
        {
            "input": "El paper está bien escrito y de fácil lectura.  Se ajusta al formato del evento.  Estado del arte bien planteado y revisado.  El rechazo débil es por qué no está de acuerdo a los tópicos de interés de los trabajos de INFONOR, ver listado en [Link]#areas-interes  El paper debería ser presentado en un evento de Educación en Ingeniería. Para los cual se sugiere que los resultados obtenidos sean comparables con asignaturas sin tutorías y analizar los resultados de aprendizajes que logran los alumnos en grupos de control y experimental.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper presents an approach to non-linear kernel dimensionality reduction with a trace norm regularizer in the feature space. The authors proposed an iterative minimization approach in order to obtain a local optimum of a relaxed problem.  The paper contains errors and the experimental evaluation is not convincing. Only old techniques are compared against in very toy datasets.   The authors claim state-of-the-art, however, the oil dataset is not a real benchmark, and the comparisons are to very old approaches.  The experimental evaluation should demonstrate robustness to more complex noise and outliers, as this was one of the motivations in the introduction.  The authors do not address the out-of-sample problem. This is a problem of kernel-based methods vs LVMs, and thus should be address here.   The paper contains errors:  - The last paragraph of section 1 says that this paper proposes a closed form solution to robust KPCA. This is simply wrong, as the proposed approach consists of iteratively solving iterativey a set of closed form updates  and Levenberg-Marquard optimizationd. This is not any more closed form!  - In the same paragraph (and later in the text) the authors claim that the proposed approach can be trivially generalized to incorporate other cost functions. This is not true, as in general there will be no more inner loop closed form updates and the authors will need to solve a much more complex optimization problem.   - The third paragraph of section 2 claims that this paper presents a novel energy minimization framework to solve problems of the general form of eq. (2). However, this is not what the authors solve at the end. They solve a different problem that has been subject to at least two relaxations. It is not clear how solving for a local optima of this double relaxed problem is related to the original problem they want to solve.   - The paper says that Geiger et al defined non linearities on a latent space of pre-defined dimensionality. This is wrong. This paper discovers the dimensionality of the latent space by means of a regularizer that encourages the singular values to be sparse. Thus, it does not have a fixed dimensionality, the latent space is just bounded to be smaller or equal than the dimensionality of the original space.    It is not clear to me why the author say for LVMs such as GPLVM that \"the latent space is learned a priority with clean training data\". One can use different noise models within the GP framework. Furthermore, the proposed approach assumes Gaussian noise (see eq. 6), which is also the trivial case for GP-based LVMs.     It is not clear what the authors mean in the paper by \"pre-training\" or saying that techniques do not have a training phase. KPCA is trained via a closed-form update, but there is still training.",
            "output": [
                "en"
            ]
        },
        {
            "input": "*** Paper Summary ***  This paper formalizes the properties required for addressing (indexing) memory augmented neural networks as well as how to pair the addressing with read/write operation. It then proposes a framework in which any Lie group as the addressing space. Experiments on algorithmic tasks are reported.  *** Review Summary ***  This paper brings unity and formalism in the requirement for memory addressing while maintaining differentiable memories. Its proposal provide a generic scheme to build addressing mechanisms. When comparing the proposed approach with key-value networks, the unbounded number of memory cells and the lack of incentive to reuse indexes might reveal impractical.   *** Detailed Review ***  The paper reads well, has appropriate relevance to related work. The unified presentation of memory augmented networks is clear and brings unity to the field. The proposed approach is introduced clearly, is powerful and gives a tool that can be reused after reading the article. I do not appreciate that the growing memory is not mentioned as a drawback. It should be stressed and a discussion on the impact it has on efficiency/scalability is needed.",
            "output": [
                "en"
            ]
        },
        {
            "input": "SYNOPSIS: The paper proposes a new neural network-based model for reading comprehension (reading a passage of text and answering questions based on the passage). It is similar in spirit to several other recent models, with the main exception that it is able to predict answers of different lengths, as opposed to single words/tokens/entities. The authors compare their model on the Stanford Question Answering Dataset (SQuAD), and show improvements over the baselines, while apparently lagging quite far behind the current state of the art reported on the SQuAD leaderboard.  THOUGHTS: The main novelty of the method is to be able to identify phrases of different lengths as possible answers to the question. However, both approaches considered -- using a POS pattern trie tree to filter out word sequences with POS tags matching those of answers in the training set, and brute-force enumeration of all phrases up to length N -- seem somewhat orthogonal to the idea of \"learning end-to-end \" an answer chunk extraction model. Furthermore, as other reviews have pointed out, it seems that the linguistic features actually contribute a lot to the final accuracy (Table 3). One could argue that these are easy to obtain using standard taggers, but it takes away even more from the idea of an \"end-to-end trained\" system.  The paper is generally well written, but there are several crucial sections in parts describing the model where it was really hard for me to follow the descriptions. In particular, the attention mechanism seems fairly standard to me in a seq2seq sense (i.e. there is nothing architecturally novel about it, as is for instance the case with the Gated Attentive Reader). I may be missing something, but even after the clarification round I still don't understand how it is novel compared to standard attention used in for instance seq2seq models.  Finally, although the method is shown to outperform the baseline method reported in the original paper introducing the SQuAD dataset, it currently seems to be 12th (out of 15 systems) on the leaderboard (",
            "output": [
                "en"
            ]
        },
        {
            "input": "In this interesting paper the authors explore the idea of using an ensemble of multiple discriminators in generative adversarial network training. This comes with a number of benefits, mainly being able to use less powerful discriminators which may provide better training signal to the generator early on in training when strong discriminators might overpower the generator.  My main comment is about the way the paper is presented. The caption of Figure 1. and Section 3.1 suggests using the best discriminator by taking the maximum over the performance of individual ensemble members. This does not appear to be the best thing to do because we are just bound to get a training signal that is stricter than any of the individual members of the ensemble. Then the rest of the paper explores relaxing the maximum and considers various averaging techniques to obtain a ’soft-discriminator’. To me, this idea is far more appealing, and the results seem to support this, too. Skimming the paper it seems as if the authors mainly advocated always using the strongest discriminator, evidenced by my premature pre-review question earlier.  Overall, I think this paper is a valuable contribution, and I think the idea of multiple discriminators is an interesting direction to pursue.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El  trabajo \"Liderazgo en adopción de TI en PYMEs ¿Sólo el involucramiento del propietario importa?\" explora a través de la metodología IA la relación entre involucramiento del propietario y el éxito de la TI en PYME. Si bien es un buen trabajo, el texto puede ser mejorado en algunos aspectos de forma y fondo: 1.\tLos autores deben declarar el objetivo del estudio para facilitar la lectura del trabajo. 2.\tLamentablemente los autores cometen un error importante al colocar a  D&M como modelo de aceptación a nivel individual (\"Otros modelos de aceptación a nivel individual incluyen: el modelo de DeLone y McLean (D&M) [5]\"). De hecho, a partir de ese error la redacción del texto confunde dimensiones del éxito del uso de sistemas de información (el modelo D&M) con modelos de adopción de tecnologías de información (TAM y sucesores). Los autores deben revisar D&M y ver las implicaciones para su trabajo de la correcta interpretación de este modelo. 3.\tAsociado a lo anterior, ¿que entienden los autores por éxito del uso de sistemas de información? deben explicarlo, ¿los beneficios individuales y los beneficios organizaciones son parte de ellos?,  ¿es posible que otras dimensiones del éxito del uso de sistemas de información, como la calidad de la información y la calidad de servicio de la función informática, sean variables importantes para explorar en los dos proyectos estudiados?",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper proposes a recurrent neural architecture that can skip irrelevant input units. This is achieved by specifying R (# of words to read at each \"skim\"), K (max jump size), and N (max # of jumps allowed). An LSTM processes R words, predicts the jump size k in {0, 1...K} (0 signals stop), skips the next k-1 words and continues until either the number of jumps reaches N or the model reaches the last word. While the model is not differentiable, it can be trained by standard policy gradient. The work seems to have been heavily influenced by Shen et al. (2016) who apply a similar reinforcement learning approach (including the same variance stabilization) to multi-pass machine reading.   - Strengths:  The work simulates an intuitive \"skimming\" behavior of a reader, mirroring Shen et al. who simulate (self-terminated) repeated reading. A major attribute of this work is its simplicity. Despite the simplicity, the approach yields favorable results. In particular, the authors show through a well-designed synthetic experiment that the model is indeed able to learn to skip when given oracle jump signals. In text classification using real-world datasets, the model is able to perform competitively with the non-skimming model while being clearly faster.   The proposed model can potentially have meaningful practical implications: for tasks in which skimming suffices (e.g., sentiment classification), it suggests that we can obtain equivalent results without consuming all data in a completely automated fashion. To my knowledge this is a novel finding.   - Weaknesses:  It's a bit mysterious on what basis the model determines its jumping behavior so effectively (other than the synthetic dataset). I'm thinking of a case where the last part of the given sentence is a crucial evidence, for instance:   \"The movie was so so and boring to the last minute but then its ending blew me away.\"   In this example, the model may decide to skip the rest of the sentence after reading \"so so and boring\". But by doing so it'll miss the turning point \"ending blew me away\" and mislabel the instance as negative. For such cases a solution can be running the skimming model in both directions as the authors suggest as future work. But in general the model may require more sophisticated architecture for controlling skimming.  It seems one can achieve improved skimming by combining it with multi-pass reading (presumably in reverse directions). That's how humans read to understand text that can't be digested in one skim; indeed, that's how I read this draft.   Overall, the work raises an interesting problem and provides an effective but intuitive solution.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper reports several connections between the image representations in state-of-the are object recognition networks and findings from human visual psychophysics: 1) It shows that the mean L1 distance in the feature space of certain CNN layers is predictive of human noise-detection thresholds in natural images. 2) It reports that for 3 different 2-AFC tasks for which there exists a condition that is hard and one that is easy for humans, the mutual information between decision label and quantised CNN activations is usually higher in the condition that is easier for humans. 3) It reproduces the general bandpass nature of contrast/frequency detection sensitivity in humans.   While these findings appear interesting, they are also rather anecdotal and some of them seem to be rather trivial (e.g. findings in 2). To make a convincing statement it would be important to explore what aspects of the CNN lead to the reported findings. One possible way of doing that could be to include good baseline models to compare against. As I mentioned before, one such baseline should be reasonable low-level vision model. Another interesting direction would be to compare the results for the same network at different training stages.  In that way one might be able to find out which parts of the reported results can be reproduced by simple low-level image processing systems,  which parts are due to the general deep network’s architecture and which parts arise from the powerful computational properties (object recognition performance) of the CNNs.  In conclusion, I believe that establishing correspondences between state-of-the art CNNs and human vision is a potentially fruitful approach. However to make a convincing point that found correspondences are non-trivial, it is crucial to show that non-trivial aspects of the CNN lead to the reported findings, which was not done. Therefore, the contribution of the paper is limited since I cannot judge whether the findings really tell me something about a unique relation between high-performing CNNs and the human visual system.  UPDATE:  Thank you very much for your extensive revision and inclusion of several of the suggested baselines.  The results of the baseline models often raise more questions and make the interpretation of the results more complex, but I feel that this reflects the complexity of the topic and makes the work rather more worthwhile.   One further suggestion: As the experiments with the snapshots of the CaffeNet shows, the direct relationship between CNN performance and prediction accuracy of biological vision known from Yamins et al. 2014 and Cadieu et al. 2014 does not necessarily hold in your experiments. I think this should be discussed somewhere in the paper.  All in all, I think that the paper now constitutes a decent contribution relating state-of-the art CNNs to human psychophysics and I would be happy for this work to be accepted.  I raise the my rating for this paper to 7.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: This paper proposes an evaluation metric for automatically evaluating the quality of dialogue responses in non-task-oriented dialogue. The metric operates on continuous vector space representations obtained by using RNNs and it comprises two components: one that compares the context and the given response and the other that compares a reference response and the given response. The comparisons are conducted by means of dot product after projecting the response into corresponding context and reference response spaces. These projection matrices are learned by minimizing the squared error between the model predictions and human annotations.  I think this work gives a remarkable step forward towards the evaluation of non-task-oriented dialogue systems. Different from previous works in this area, where pure semantic similarity was pursued, the authors are going beyond pure semantic similarity in a very elegant manner by learning projection matrices that transform the response vector into both context and reference space representations. I am very curious on how your projection matrices M and N differ from the original identity initialization after training the models. I think the paper will be more valuable if further discussion on this is introduced, rather than focusing so much on resulting correlations.   - Weaknesses:  The paper also leaves lots questions related to the implementation. For instance, it is not clear whether the human scores used to train and evaluate the system were single AMT annotations or the resulting average of few annotations. Also, it is not clear how the dataset was split into train/dev/test and whether n-fold cross validation was conducted or not. Also, it would be nice to better explain why in table 2 correlation for ADEM related scores are presented for the validation and test sets, while for the other scores they are presented for the full dataset and test set. The section on pre-training with VHRED is also very clumsy and confusing, probably it is better to give less technical details but a better high level explanation of the pre-training strategy and its advantages.  - General Discussion:  “There are many obvious cases where these metrics fail, as they are often incapable of considering the semantic similarity between responses (see Figure 1).” Be careful with statements like this one. This is not a problem of semantic similarity! Opposite to it, the problem is that completely different semantic cues might constitute pragmatically valid responses. Then, semantic similarity itself is not enough to evaluate a dialogue system response. Dialogue system response evaluation must go beyond semantics (This is actually what your M and N matrices are helping to do!!!)   “an accurate model that can evaluate dialogue response quality automatically — what could be considered an automatic Turing test —“ The original intention of Turing test was to be a proxy to identify/define intelligent behaviour. It actually proposes a test on intelligence based on an “intelligent” machine capability to imitate human behaviour in such a way that it would be difficult for a common human to distinguish between such a machine responses and actual human responses. It is of course related to dialogue system performance, but I think it is not correct to say that automatically evaluating dialogue response quality is an automatic Turing test. Actually, the title itself “Towards an Automatic Turing Test” is somehow misleading!  “the simplifying assumption that a ‘good’ chatbot is one whose responses are scored highly on appropriateness by human evaluators.” This is certainly the correct angle to introduce the problem of non-task-oriented dialogue systems, rather than “Turing Test”. Regarding this, there has been related work you might like to take a look at, as well as to make reference to, in the WOCHAT workshop series (see the shared task description and corresponding annotation guidelines).  In the discussion session: “and has has been used” -> “and it has been used”",
            "output": [
                "en"
            ]
        },
        {
            "input": "RESUMEN:  Este trabajo presenta/ofrece una aplicación Web móvil que permite, a través de una Geo-Localización del dispositivo, crear un mapa del crimen en la ciudad de Lima, Perú.   EVALUACIÓN GENERAL:  El documento no sigue la estructura de un artículo científico y parece que tampoco sigue el formato de INFONOR. Además, el trabajo presentado parece más bien un trabajo de ingeniería que científico. Aunque esta aplicación Web móvil podría ser interesante,  se debe mencionar no ofrece ninguna dirección URL donde (com)probar la aplicación presentada.  La Sección 2 debería discutir el trabajo relacionado y algunos conceptos, pero en el medio de esta sección, se describe parte de la propuesta. Además, el trabajo define en casi una columna qué es la delincuencia usando extensas citas (“ … ”).  La sección discusión de experimentos y resultados no se describe experimentos ni resultados (estos últimos son descritos pero no discutidos), solo se muestra algunas facetas/pantallas de la aplicación. Además, justifica el uso de Android a través de una cita muy larga (“ … “).   DETALLES MENORES:  - El abstract en Ingles puede ser mejorable, comenzando por eliminar la primera palabra del paper. Se pudo escribir en español el abstract. - El formato del documento no sigue el estándar de INFONOR, especialmente con los márgenes, - En algunas partes del documento, se puede observar la palabra “tesis” y no artículo. En otras partes del texto, se puede observar la palabra “ponencia”. - La Figura 1 no aporta en casi nada al documento. - Después de cada título, se puede observar “:” que no es necesario. - La sección 2 usa de manera excesiva citas “…” - La sección 2.2 habla sobre tipos de delincuencia, pero en los sub-títulos de esta sección dice “Análisis” - El título de la sección 2.3 choca con el texto de la columna de la izquierda - La tabla 2, la cual menciona a las aplicaciones, no es evaluadas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta una comparación cuantitativa (Técnica DEA) y comparación cualitativa (Metodología MESME) de modelos de madurez BI seleccionados. El artículo es una aproximación para la generación de una futura guía metodológica enfocada a implementar mejoras en la madurez en BI para una organización. Por lo tanto, es una investigación inicial, pero la comparativa realizada es interesante.  Para la comparación cuantitativa se seleccionaron 5 de las 6 metodologías. Después, cuando se hizo el análisis cualitativo se trabajó con 6 metodologías y no con 5, incluyendo la ya descartada.  En la página 2 dice \"La presente investigación, tiene como objetivo identificar ...\". El objetivo no es \"identificar\" sino \"realizar una comparación para seleccionar ...\".  En la sección IV se habla de una revisión sistemática, pero no pone ninguna referencia asociada a ese trabajo anteriormente realizado. ¿Cómo seleccionó los modelos y de dónde?  Otras observaciones y/o dudas: - La Referencia 18 no es citada en el texto. - Hay 4 referencias asociadas a modelos de madurez ([3], [11], [15], [17]), ¿Ninguna hace una comparativa? - Revisar el inglés en Keywords - Cambiar \"Palabras claves\" por \"Palabras clave\" - En página 2, cambiar \"En la sección V detalla\" por \"En la sección V se detalla\" o por \"La sección V detalla\". - El mismo problema ocurre en la página 3 con \"La Figura 3 se aprecia\", \"La Tabla 2 se describe\", \"La Figura 6 se muestra\", \"Se observa en la Tabla 11 se contabiliza\". - Debe corregir palabras \"pegadas\". Por ejemplo, cambiar \"aanalizar\", \"dedetalle\", etc. - No indica el significado de cada uno de los elementos de la ecuación 3. - Antes de la Tabla 7, hay texto solamente en una columna. - En página 8, Tabla 9, cambiar \"para integran\" por \"para integrar\". - Corregir palabras mal escritas: \"escazas\", \"se precia\". - En la página 9 habla de \"investigación de tesis\" y no de artículo. - En Referencia [7] está escrito \"Jour-nal\", En Referencia [13] aparece un número después del apellido de los autores (ejemplo: \"Tan1\", \"Sin1\", \"Yeoh2\" - En Referencia [18] aparece \"2010b\"",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo expone el desarrollo de un caso de estudio de reconocimiento de patrones para identificar remolinos oceánicos por medio de imágenes de satélite.  El articulo está bien escrito y estructurado. Su presentación sigue una secuencia lógica de desarrollo.  En lo que corresponde al estado del arte, se mencionan métodos para la detección de \"eddies\". Salvo el caso de redes neuronales, no se mencionan resultados cuantitativos obtenidos con cada método.  Por lo mismo, no es posible establecer una comparación del rendimiento obtenido versus otros métodos referenciados en el estado del arte.  La parte de entendimiento y exploración de los datos es débil.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes new initialization for particular architectures and a correction trick to batch normalization to correct variance introduced by dropout. While authors state interesting observations, the claims are not supported with convincing results.  I guess Figure 1 is only for mnist and for only two values of p with one particular network architecture, the dataset and empirical setup is not clear.  The convergence is demonstrated only for three dropout values in Figure 2 which may cause an unfair comparison. For instance how does the convergence compare for the best dropout rate after cross-validation (three figures each figure has three results for one method with different dropouts [bests cv result for each one])? Also how is the corresponding validation error and test iterations?  Also only mnist does not have to generalize to other benchmarks.  Figure 3 gives closer results for Adam optimizer, learning rate is not selected with random search or bayesian optimization, learning decay iterations fixed and regularization coefficient is set to a small value without tuning. A slightly better tuning of parameters may close the current gap. Also Nesterov based competitor gives unreasonably worse accuracy compared to recent results which may indicate that this experiment should not be taken into account.   In Table 2, there is no significant improvement on CIFAR10. The CIFAR100 difference is not significant without including batch normalization variance re-estimation. However there is no result for 'original with BN update' therefore it is not clear whether the BN update helps in general or not. SVHN also does not have result for original with BN update.  There should be baselines with batch normalizations for Figure 1,2 3 to support the claims convincingly.  The main criticism about batch normalization is additional computational cost by giving (Mishkin et al, 2016 ) as reference however this should not be a reason to not to compare the initialization to batch-normalization.  In fact, (Mishkin et al, 2016) performs comparison to batch normalization and also with and without data augmentation with recent state of art architectures.  None of the empirical results have data augmentation. It is not clear if the initialization or  batch normalization update will help or make it worse for that case.  Recent state of art methods methods like Res Net variant and Dense Net scale to many depths and report result for ImageNet. Although the authors claim that this can be extended to residual network variants, it is not clear if there is going to be any empirical gain for that architectures.    This work requires a comprehensive and fair comparison. Otherwise the contribution is not significant.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo \"Un análisis empírico de las recomendaciones comerciales en los Sitios de Redes Sociales\"  es de relevancia científica y actualidad. Los datos estudiados muestran resultados interesantes a partir de una muestra principalmente hispanoamericana. Deberían los autores seguir sus líneas futuras de investigación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este artículo describe los resultados de simulación del problema de pliegue de proteínas en base a una secuencia de aminoácidos.  En general, el artículo presenta varios problemas de redacción y de ortografía (e.g., segundo párrafo, lineas 4 y 8 del resumen). También, usualmente se utilizan párrafos muy extensos que hacen difícil seguir la idea de lo expuesto (e.g., segundo párrafo de introducción, sección redes neuronales artificiales).  Algunas figuras (e.g., 1, 3, 4,...) requieren mayor resolución.  No obstante ser un problema bien explorado, la revisión del estado del arte y trabajos relacionados es limitada.  Los resultados se presentan mediante imágenes de la estructura molecular. Es conveniente presentar medidas de rendimiento y una descripción en notación formal abstracta del algoritmo  utilizado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este trabajo muy bueno, solo que comete errores de redacción, por ejemplo, el artículo en general tiene muchos  párrafos largos y sin puntuación. No está en formato Ingeniare, hay errores de letras repetidas. Tiene la fortaleza de estar bien planteado, con buenas referencias y realiza una propuesta de desarrollo, la cual realiza una simulación. Me pareció muy corta la sección de pruebas, por lo que le quita mérito al trabajo, también  se puede pensar que es una buena comunicación de inicio de proyecto que se está ad-porta de buscar escenarios de pruebas ya sea para simular o aplicar en la realidad.  Errores: Página 1 en el resumen se menciona DARP, y no se indica el significado del nemónico, el cual se menciona en las palabras claves Falta el resumen en inglés El cuarto párrafo está muy largo sin puntuación Página 2 Me parece un error dice MultiaAgente No se referencia la figura 1 en el texto, y no se indica la fuente La figura 2, no se indica la fuente Página 3 falta la traducción de Scheduling Problem, podría ser El Problema de Planificación No se define MADARP, tal vez el subtítulo debería ser  MultiAgente ... (MADARP) Página 4 Trabajos relacionados, se podria resumir más, mostrando un relato de los trabajos relacionados existentes e indicar al final cuales se consideran en este trabajo, también considerando más trabajos existentes. Fig. 3 sin referencia Página 5 Figuras sin referencia o sin indicar la fuente Página 6 Existe una referencia [XX]?? Página 8, 9, 10, 11 referencias o fuentes de las figuras  Página 11 El diseño y Pruebas, requiere más explicación, está muy reducido Conclusiones muy generales Falta Trabajo Futuro",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths: The approach described in the manuscript outperformed the previous approaches and achieved the state-of-the-art result.  Regarding data, the method used the combination of market and text data.  The approach used word embeddings to define the weight of each lexicon term by extending it to the similar terms in the document.  - Weaknesses: Deep-learning based methods were known to be able to achieve relatively good performances without much feature engineering in sentimental analysis. More literature search is needed to compare with the related works would be better.  The approach generally improved performance by feature-based methods without much novelty in model or proposal of new features.  - General Discussion: The manuscript described an approach in sentimental analysis. The method used a relatively new method of using word embeddings to define the weight of each lexicon term. However, the novelty is not significant enough.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El documento presenta un estudio del estado de situación de las técnicas y métodos que el corpus de la investigación ofrece para el tratamiento de requisitos en entornos ágiles. La temática es totalmente actual y coincido con los autores es que hay poco realizado aún y es un campo de explotación. Hay sin embargo, dos comentarios que me gustaría trasladar a los revisores. El primero es que no queda claro porque no han hecho una revisión sistemática de la literatura de manera más formal. La justificación que ofrecen no me parece convincente. Por otro lado, me gustaría que hubiesen desarrollado algo más los trabajos futuros. Tras un buen trabajo no me queda claro qué han aprendido para ponerlo en práctica en su futura investigación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Se explica en forma ordenada y didáctica una experiencia de uso de TIC para la colaboración académica.  La originalidad del trabajo no es su dimensión fuerte, ver trabajos de larga data como Gorton et al. (1997) y actuales como Lanunile et al. (2010). Sin embargo, la relevancia del tema como patrón de referencia en actividades relacionadas a tesis científicas, asociada a su buena presentación,  hacen de él un aporte.  Se sugiere, en miras a una publicación en revista, que se compare la eficiencia y efectividad de las actividades sin el apoyo de estas herramientas versus la actual realidad (con herramientas). Ejemplos de preguntas posibles a responder de este análisis exploratorio: ¿Cuáles son las principales actividades donde el uso de herramientas colaborativas es clave? ¿Qué cambios en el diseño de estas herramientas se deberían desarrollar en el futuro? ¿Existen perfiles de estudiantes/académicos más propicios para la adopción de estas plataformas?  Referencias:  Gorton, I., Hawryszkiewycz, I., and Ragoonaden, K. 1997. Collaborative tools and processes to support software engineering shift work. BT Technology Journal 15, 3 (Jul. 1997), 189-198. Filippo Lanubile, Christof Ebert, Rafael Prikladnicki, Aurora Vizcaíno, \"Collaboration Tools for Global Software Engineering,\" IEEE Software, vol. 27, no. 2, pp. 52-55, Mar./Apr. 2010.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Artículo enfocado en las técnicas de educción de requisitos. Como comentario general, en las frases del tipo sujeto+verbo, no es necesario poner una coma después del sujeto (por ej., en la sección de introducción \"la educación de requisitos de software, es aquella ...\", en la de background \"la ingeniería del software, es una disciplina ..\"). Respecto a la Tabla 2, sería conveniente que los autores pusieran las filas de la tabla en el mismo orden en que los enumeran. Un par de cuestiones me surgen: ¿Cómo se construye la situación contextual de un proyecto? (candado) Aunque me imagino que será un proceso similar, ¿Cómo se construye el perfil de adecuación de las técnicas? (llave) Consiste en poner el gráfico de la técnica por dimensión en forma plana? Si pudieran aclarar con alguna frase. Por ejemplo, indicar que las dimensiones tienen un número (indicadlo en la Tabla 4 por ejemplo), para luego ver claramente los gráficos de la Figura 4. Lo mismo para los factores y la Figura 3.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Un trabajo impecable.   Bien presentado, enfocando un tema de actualidad e interés. Ameno y bien estructurado.  Sin observaciones de mi parte. Creo que es un aporte real que cautivará el interés de los asistentes.  El hecho de utilizar como elemento componente una herramienta de impacto en las redes sociales captura de inmediato la atención del lector; y la presentación que se inicia con un vistazo a los conceptos más relevantes busca aclarar que se trata de un trabajo al alcance de aquellos que participan en las redes sociales.  Si bien puede ser leído sin dificultad por una gama amplia de lectores, no carece del rigor necesario para ser una propuesta atractiva, consistente y bien planteada.  Apoyo su inclusión en Infonor con entusiasmo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors propose and evaluate using SPN's to generate embeddings of input and output variables, and using MPN to decode output embeddings to output variables. The advantage of predicting label embeddings is to decouple dependencies in the predicted space. The authors show experimentally that using SPN based embeddings is better than those produced by RBM's.  This paper is fairly dense and a bit hard to read. After the discussion, the main contributions of the authors are:  1. They propose the scheme of learning SPN's over Y and then using MPN's to decode the output, or just SPNs to embed X. 2. They propose how to decode MPN's with partial data. 3. They perform some analysis of when their scheme will lead to perfect encoding/decodings. 4. They run many, many experiments comparing various ways of using their proposed method to make predictions on multi-label classification datasets.  My main concerns with this paper are as follows:  - The point of this paper is about using generative models for representation learning. In their experiments, the main task is discriminative; e.g. predict multiple Y from X. The only discriminative baseline is a L2 regularized logistic regression, which does not have any structure on the output; it'd be nice to see how a discriminative structured prediction method would do, such as CRF or belief propagation.   - The many experiments suggest that their encoder/decoder scheme is working better than the alternatives; can you please give more details on the relative computation complexity of each method?  - One thing I'm still having trouble understanding is *why* this method works better than MADE and the other alternatives. Is it learning a better model of the distribution of Y? Is it better at separating out correlations in the output into individual nodes?  Does it have larger representations?   - I think the experiments are overkill and if anything, they way they are presented detract from the paper. There's already far too many numbers and graphs presented to be easy to understand.  If I have to dig through hundreds of numbers to figure out if your claim is correct, the paper is not clear enough. And, I said this before in my comments, please do not refer to Q1, Q2, etc. -- these shortcuts let you make the paper more dense with fewer words but at the cost of readability.  I *think* I convinced myself that your method works...I would love to see a table that shows, for each condition: (A) a baseline X->Y, (B) one *average* result across datasets for your method, and (C) one *average* result from a reasonable best competitor method. Please show for both the exact match and hamming losses, as that will demonstrate the gap between independent linear prediction and structured prediction. That would still be plenty of numbers but would make it much easier for the reader to verify your claims and you can put everything else in the Appendix.  E.g. something like:  Input | Predicted Output | Decoder | Hamming | Exact Match ---- X | P(Y) | CRF | xx.xx | xx.xx   (this is your baseline) SPN E_X | P(Y) | n/a | xx.xx | xx.xx  X | SPN E_Y | MPN | xx.xx | xx.xx  (given X, predict E_Y, then decode it with an MPN)  Does a presentation like that make sense? It's just really hard and time-consuming for me as a reviewer to verify your results, the way you've laid them out currently.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta una revisión de los SGBD móviles y NoSQL.  No obstante lo anterior, el trabajo es más bien descriptivo y carece de resultados experimentales.  Lo que señala en la página 8, metodología, considera dos fases, de las cuales solo se presenta, al parecer los resultados de la primera fase.  Se sugiere realizar la segunda fase, que conlleva un trabajo experimental de recolección de datos y su análisis, y luego generar un artículo con estos resultados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper creates a physics simulator using theano, and uses it to learn a neural network policy by back propagating gradients through the simulation. The approach is novel, and is motivated by being able to learn policies for robotics.  My two key reservations with the paper are as follows: 1. The method is motivated by learning policies for robotics. However, the proposed method is *only* useful for robotics if the learned policy can transfer the real world. Transferring policies from simulation to real-world is an open research problem, and is particularly challenging with less realistic simulators. 2. They key novelty/benefit of this approach over other model-based approaches is that the simulator is differentiable. However, the only empirical comparison in the paper is to a model-free approach (CMA-ES). To appropriately demonstrate the approach, it should be compared to other model-based approaches, which do not require analytic derivatives of the model.  For the reader to fully understand the pros and cons of the approach, the paper should also include quantitative comparison between the speed of the proposed simulator, and that of standard simulation platforms.  Because the idea is interesting and novel, I think it lies above the acceptance threshold. However, it would be significantly improved with the aforementioned comparisons.  Lastly, the writing of the paper could be improved, as it is rather informal and/or imprecise in a number of places. Here are some examples: -- “we model the use of a neural network as a general controller for a robot” - can be more concisely phrased as something like “we model the robot controller using a neural network” or “the robot controller is modeled using a neural network\" -- “In previous research, finding a gradient…” - This is a run-on sentence. -- “We basically jam this entire equation into” - This sentence is informal and imprecise. -- “deep learning neural network” - the word “learning” should be omitted -- “one big RNN, where we unfold over time” - should be “…RNN, which we unfold over time” or “…RNN, unfolded over time”  The writing would also be improved by making it more concise and fitting the paper into 8 pages.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Se presenta el desarrollo de un prototipo para una herramienta de asignación automática de requisitos de software entre los desarrolladores. Esta herramienta puede ser muy útil para los equipos de desarrollo de software. Se trata de realizar un aporte mediante esta herramienta a  la calidad de los productos desarrollados.  No se explica cuál es la heurística utilizada para la asignación de requisitos a los programadores. No se presentan un estudio de las herramientas de gestión de requisitos existentes, en donde se demuestre que no existen herramientas alternativas a la presentada. Y en caso de existir alternativas, justificar por qué desarrollar una nueva. No se explica claramente las funcionalidades de la herramienta. No hay evidencia de la mejora del proceso al incluir esta herramienta, sólo se dice en las conclusiones que \"es perceptible el cambio en la calidad del proceso\" Las referencias bibliográficas utilizadas son en su mayoría páginas web, no se nota una revisión bibliográfica en bases de datos especializadas. Las figuras no se distinguen bien. Las referencias bibliográficas no cumplen el formato establecido. Debe redactar en tercera persona.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Me parece un trabajo interesante, con énfasis en cubrir brechas prácticas. Su contenido y estructura están técnicamente bien presentados. Sin embargo, por otro lado, no existe una distinción clara entre los trabajos previos y la propuesta original de este trabajo. El artículo expone que existen trabajos previos respecto a este maridaje CMMI-ÄGIL pero no indica si estas propuestas son suficientes o insuficientes para la mejora. Es decir, la motivación o justificación de este trabajo no está explícita.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper extends preceding works to create a mapping between the word embedding space of two languages. The word embeddings had been independently trained on monolingual data only, and various forms of bilingual information is used to learn the mapping. This mapping is then used to measure the precision of translations.  In this paper, the authors propose two changes: \"CCA\" and \"inverted softmax\".  Looking at Table 1, CCA is only better than Dina et al in 1 out of 6 cases (It/En @1).  Most of the improvements are in fact obtained by the introduction of the inverted softmax normalization.  Overall, I wonder which aspect of this paper is really new. You mention:  - Faruqui & Dyer 2014 already used CCA and dimensionality reduction  - Xing et al 2015 argued already that Mikolov's linear matrix should be orthogonal  Could you make clear in what aspect your work is different from Faruqui & Dyer 2014 (other the fact that you applied the method to measure translation precision) ?  Using cognates instead of a bilingual directory is a nice trick. Please explain how you obtained this list of cognates ? Obviously, this only works for languages with the same alphabet (for instance Greek and Russian are excluded)  Also, it seems to me that in linguistics the term \"cognate\" refers to words which have a common etymological origin - they don't necessarily have the same written form (e.g. night, nuit, noche, Nacht). Maybe, you should use a different term ? Those words are probably proper names in news texts.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper describes a new deterministic dependency parsing algorithm and analyses its behaviour across a range of languages. The core of the algorithm is a set of rules defining permitted dependencies based on POS tags. The algorithm starts by ranking words using a slightly biased PageRank over a graph with edges defined by the permitted dependencies. Stepping through the ranking, each word is linked to the closest word that will maintain a tree and is permitted by the head rules and a directionality constraint.  Overall, the paper is interesting and clearly presented, though seems to differ only slightly from Sogaard (2012), \"Unsupervised Dependency Parsing without Training\". I have a few questions and suggestions:  Head Rules (Table 1) - It would be good to have some analysis of these rules in relation to the corpus. For example, in section 3.1 the fact that they do not always lead to a connected graph is mentioned, but not how frequently it occurs, or how large the components typically are.  I was surprised that head direction was chosen using the test data rather than training or development data. Given how fast the decision converges (10-15 sentences), this is not a major issue, but a surprising choice.  How does tie-breaking for words with the same PageRank score work? Does it impact performance significantly, or are ties rare enough that it doesn't have an impact?  The various types of constraints (head rules, directionality, distance) will lead to upper bounds on possible performance of the system. It would be informative to include oracle results for each constraint, to show how much they hurt the maximum possible score. That would be particularly helpful for guiding future work in terms of where to try to modify this system.  Minor:  - 4.1, \"we obtain [the] rank\"  - Table 5 and Table 7 have columns in different orders. I found the Table 7 arrangement clearer.  - 6.1, \"isolate the [contribution] of both\"",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper introduces a mechanism for active learning with convolutional neural networks (CNNs). I would not go as far as the authors in calling these \"deep\", seeing that they seem to have only 2 hidden layers with only 20 filters each. The active learning criterion is a greedy selection scheme based on variational free energy and a series of approximations.  The paper is sometimes hard to read, due to (a) many grammatical errors and (b) sloppy notation in some places (e.g., on page 5, line 1, f is used but never introduced before). Overall, I give an accepting score, but a weak one because of the grammatical errors. If the paper is accepted, these should be fixed for the final version, optimally by a native speaker.   The paper's topic is interesting, and the paper appears to succeed in its goal of showing a proof of concept for active learning in CNNs (if only on toy datasets). I'm surprised by the new results on uncertainty sampling and curriculum learning the authors added: why do these methods both break for USPS? In particular, uncertainty sampling did very well (in fact, better than the authors' new method) on MNIST, but apparently horribly on USPS; some explanation for this would be useful.  I have one more question: why is it necessary to first sample a larger subset D \\subset U, from which we select using active learning? Is this merely done for reasons of computational efficiency, or can it actually somehow improve results? (If so, it would be instrumental to see the worse results when this is not done.)",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta principalmente una aplicación móvil y hay poco de investigación  - Indica que es un trabajo de \"tesis\" - Falta resumen en español y palabras clave - Las figuras no deben ir en colores (según formato) - Poner un nombre más adecuado a la Tabla 2. - Poner acento a \"significara\", \"perdida\" - Ajustar el texto a los márgenes - Leyendas como \"Figura6\" aparecen sin espacio en blanco",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes an \"interactive\" version of the bAbI dataset by adding supporting questions/answers to the dataset in cases where there is not enough information to answer the question. Interactive QA is certainly an interesting problem and is well-motivated by the paper. However, I don't feel like the bAbI extension is adequately explained. For example, the baseline DMN and MemN2N models on the IQA task are \"take both statements and question as input and then estimate an answer.\" Their task is then fundamentally more difficult from the CAN's because they do not distinguish \"feedback\" from the original context; perhaps a more fair approach would be to treat **every** question (both supporting and original questions) as individual instances. Also, how were the supporting questions and the user feedback generated? How many templates / words were used to create them? The dataset creation details are missing, and if space is an issue, a lot of basic exposition on things like GRU / sentence encodings can be cut (or at least greatly shortened) and replaced with pointers to the original papers.   Another issue I had is that the model attempts to generate these synthetic questions; if there are just one or two templates, why not just predict the values that fill these templates? So instead of generating \"Which bedroom, master one or guest one?\" with an RNN decoder, just predict \"which\" or \"which bedroom\"... isn't this sufficient? In the end, these just seem like more supporting facts, not actual interaction with users, and the fact that it is run on only three of the original twenty tasks make the conclusions hard to trust.  In conclusion, I think the paper has a strong idea and motivation, but the experiments are not convincing for the paper to be accepted at ICLR.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo es interesante, sin embargo, se requiere de una muestra estadística más amplia para poder sacar conclusiones cercanas a la realidad.  Tan solo 4 pacientes no constituyen una muestra importante, y los promedios  encontrados pueden no estar acordes con los resultados de un estudio más amplio. De todos modos, este proyecto es muy útil para la sociedad.  Anexo envío el artículo con algunas correcciones en redacción y puntuación, sin embargo, los autores deben revisar el documento completamente",
            "output": [
                "es"
            ]
        },
        {
            "input": "A new sparse coding model is introduced that learns features jointly with their transformations. It is found that inference over per-image transformation variables is hard, so the authors suggest tying these variables across all data points, turning them into global parameters, and using multiple transformations for each feature. Furthermore, it is suggested to use a tree of transformations, where each path down the tree generates a feature by multiplying the root feature by the transformations associated with the edges. The one-layer tree model achieves similar reconstruction error as traditional sparse coding, while using fewer parameters.  This is a nice addition to the literature on sparse coding and the literature on learning transformation models. The authors identify and deal with a difficult inference problem that can occur in transformation models. That said, I am skeptical about the usefulness of the general approach. The authors take it as a given that “learning sparse features and transformations jointly” is an important goal in itself, but this is never really argued or demonstrated with experiments. It doesn’t seem like this method enables new applications, extends our understanding of learning what/where pathways in the brain, or improve our ability to model natural images.  The authors claim that the model extracts pose information, but although the model explicitly captures the transformation that relates different features in a tree, at test time, inference is only performed over the (sparse) coefficient associated with each (feature, transformation) combination, just like in sparse coding. It is not clear what we gain by knowing that each coefficient is associated with a transformation, especially since there are many models that do this general “what / where” split.  It would be good to check that the x_{v->b} actually change significantly from their initialization values. The loss surface still looks pretty bad even for tied transformations, so they may actually not move much. Does the proposed model work better according to some measure, compared to a model where x_{v->b} are fixed and chosen from some reasonable range of parameter values (either randomly or spaced evenly)?  One of the conceptually interesting aspects of the paper is the idea of a tree of transformations, but the advantage of deeper trees is never demonstrated convincingly. It looks like the authors have only just gotten this approach to work on toy data with vertical and horizontal bars.  Finally, it is not clear how the method could be extended to have multiple layers. The transformation operators T can be defined in the first layer because they act on the input space, but the same cannot be done in the learned feature space. It is also not clear how the pose information should be further processed in a hierarchical manner, or how learning in a deep version should work.  In summary, I do not recommend this paper for publication, because it is not clear what problem is being solved, the method is only moderately novel and the novel aspects are not convincingly shown to be beneficial.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Overall I think this is an interesting paper which shows empirical performance improvement over baselines. However, my main concern with the paper is regarding its technical depth, as the gist of the paper can be summarized as the following: instead of keeping the batch norm mean and bias estimation over the whole model, estimate them on a per-domain basis. I am not sure if this is novel, as this is a natural extension of the original batch normalization paper. Overall I think this paper is more fit as a short workshop presentation rather than a full conference paper.  Detailed comments:  Section 3.1: I respectfully disagree that the core idea of BN is to align the distribution of training data. It does this as a side effect, but the major purpose of BN is to properly control the scale of the gradient so we can train very deep models without the problem of vanishing gradients. It is plausible that intermediate features from different datasets naturally show as different groups in a t-SNE embedding. This is not the particular feature of batch normalization: visualizing a set of intermediate features with AlexNet and one gets the same results. So the premise in section 3.1 is not accurate.  Section 3.3: I have the same concern as the other reviewer. It seems to be quite detatched from the general idea of AdaBN. Equation 2 presents an obvious argument that the combined BN-fully_connected layer forms a linear transform, which is true in the original BN case and in this case as well. I do not think it adds much theoretical depth to the paper. (In general the novelty of this paper seems low)  Experiments:  - section 4.3.1 is not an accurate measure of the \"effectiveness\" of the proposed method, but a verification of a simple fact: previously, we normalize the source domain features into a Gaussian distribution. the proposed method is explicitly normalizing the target domain features into the same Gaussian distribution as well. So, it is obvious that the KL divergence between these two distributions are closer - in fact, one is *explicitly* making them close. However, this does not directly correlate to the effectiveness of the final classification performance.  - section 4.3.2: the sensitivity analysis is a very interesting read, as it suggests that only a very few number of images are needed to account for the domain shift in the AdaBN parameter estimation. This seems to suggest that a single \"whitening\" operation is already good enough to offset the domain bias (in both cases shown, a single batch is sufficient to recover about 80% of the performance gain, although I cannot get data for even smaller number of examples from the figure). It would thus be useful to have a comparison between these approaches, and also a detailed analysis of the effect from each layer of the model - the current analysis seems a bit thin.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo detalla una propuesta de gestión de requisitos basada en KAIZEN. Los autores describen diferentes métodos y técnicas para complementar Kaizen  Entiendo que el principal aporte de este trabajo es, según los autores, complementar y mejorar Kaizen para elicitación y gestión de requisitos. Sin embargo, los autores del artículo presentan únicamente una construcción teórica de su propuesta.  Entiendo que al artículo le falta trabajo por desarrollar, con el fin de validar la propuesta. Sin embargo al ser un artículo que desarrollan seis investigadores, considero que debe incluir aspectos más aplicativos de la propuesta.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo esta adecuadamente escrito, excepto por algunos problemas de acentos (implementara, utilizaran, ...) Las herramientas utilizadas, así como los algoritmos implementados se encuentran adecuadamente descritos. La única crítica esta en la implementación de los mismos, realizada en una única máquina (seguramente por un problema de recursos), algo que quita méritos a lo realizado, considerando que se esta hablando de técnicas pensadas para ser usadas en forma distribuida (donde debería estar su máximo aprovechamiento).  Pese a lo anterior, pienso que es un trabajo bien presentado, valioso en la discusión de las limitaciones de Hadoop vs Giraph, y cuyos resultados son interesantes de conocer y debatir en el ámbito del congreso.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El articulo muestra los resultados empíricos de la integración (acoplamiento) del algoritmo apriori en un SGBD.  Indican que el trabajo expuesto se basa en el trabajo de Agrawal & Shim, este trabajo es del año 1996, al respecto ¿no hay trabajos más recientes? , ¿Se puede escoger otro trabajo más reciente? , ¿Por qué escoger este trabajo? ¿Por qué este enfoque?  En la introducción faltan referencias que permitan fundamentar el trabajo como un aporte un poco más cercano a algo científico. Por ejemplo \" Existen algunas investigaciones focalizadas\"....¿ cuáles ?  El trabajo esta escribo más bien como un experimento técnico, que como un artículo de congreso.  Se valora el tiempo y esfuerzo en realizar las pruebas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "__Note__: An earlier version of the review (almost identical to the present one) for an earlier version of the paper (available on arXiV) can be found here:",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es un artículo bien escrito que da una idea de cómo usar técnicas de mineración de datos en redes sociales como el Facebook. Es un tema actual e intrigante. Pero sentí falta de cosas más concretas, o sea una implementación concreta de una de las técnicas mencionadas aplicadas al facebook o a otra red social.  La frase \"el cual puede convertir datos cuyo almacenamiento es innecesario.\" en la página 3 parese inconclusa. Convertir en que?",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes a weakly supervised, end-to-end neural network model for solving a challenging natural language understanding task.  As an extension of the Neural Programmer, this work aims at overcoming the ambiguities imposed by natural language.  By predefining a set of operations, the model is able to learn the interface between the language reasoning and answer composition using backpropagation.  On the WikiTableQuestions dataset, it is able to achieve a slightly better performance than the traditional semantic parser methods.   Overall, this is a very interesting and promising work as it involves a lot of real-world challenges about natural language understanding.  The intuitions and design of the model are very clear, but the complication makes the paper a bit difficult to read, which means the model is also difficult to be reimplemented. I would expect to see more details about model ablation and it would help us figure out the prominent parts of the model design.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Presenta un framework para el trabajo de MVC con PHP de forma simple.  Podría ser un poco más técnico en cuanto a elementos de configuración y agregar comparación con otros frameworks existentes para entender por qué CakePHP y no otra alternativa.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Correcciones de Formato:  1.\tEn palabras claves dejar sólo 5 las más relevantes. 2.\tEliminar las siguientes expresiones: •\t“De ahí que en el sistema solar desentone la chatarra de los satélites artificiales, o en el sistema circulatorio sanguíneo produzca hemorragia  la incrustación de una cuchilla:” •\t“Si  fuera  más definitiva esta dimensión  valdría  una sartén sobre el escritorio  junto al computador. Si no fueran ciertos los sistemas  valdría dentro de este artículo un párrafo del Quijote.” •\t“”El gran error garrafal”, con  el que  censuró el hecho de  identificar cada relación (varrel en sus términos) como una clase.”  Correcciones de Contenido: 1.- El titulo debería ser “Una propuesta de Modelo de Datos para…..”  ya que el titulo actual no refleja el contenido del artículo.  2.- Falta fundamentar mejor la idea de lo que se propone, es decir, realizar un análisis “claro” de las  ventajas  de por qué es interesante e importante la propuesta. Por ejemplo, se puede hacer una tabla con las ventajas sobre otros modelos, por ejemplo, de base de datos relacionales, orientadas a objetos y  distribuidas,…, como los discutidos en los trabajos relacionados.  3.- Debe basarse en un modelo que exista para extender al modelo propuesto y su notación. Actualmente no es claro en cuál es la base para la propuesta.  4.- Si el objetivo es el análisis ¿por qué no sirve una base de datos multidimensional?  5.- En las conclusiones se indica que “En otras palabras,  el MED  es un modelo conceptual  a la medida de bases de datos distribuidas.” Esta afirmación es incorrecta debido a que no se muestra a MED modelado conceptualmente  ¿qué notación conceptual es la que se muestra?.  Debe corregir esto indicando claramente cuál es la notación a ocupar.  6.- En el caso de estudio de la página www.cootracolta.com no hay nada visible por lo cual quizás no sea bueno indicar dicha página web.  7.- El artículo debería seguir los patrones de los artículos que han propuesto modelos de datos por ejemplo cuando se propuso el modelo orientado a objetos GOLD para modelamiento multidimensional.",
            "output": [
                "es"
            ]
        },
        {
            "input": "all reviewers agree that the paper is not convincing enough at this stage but needs more work to be ready for ICLR (e.g. missing comparisons to other existing methods).",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta una prueba de concepto respecto a la asociación de sonido a un índice financiero (RSI).  El artículo tiene una estructura adecuada, presenta los conceptos, trabajo relacionado y la propuesta de \"sonificación\" en forma clara. No obstante, es escueto en la descripción de la implementación, los resultados obtenidos y su análisis.  Algunos errores gramaticales menores:  - pag. 1, columna derecha, primer párrafo. \"Is in this context\" - pag. 3, columna derecha, segund párrafo. \"minimums and maximums frequencies...\"; \"to void damaging...\"  Algunos aspectos a mejorar:  No queda claro cuál podría ser la ventaja respecto a otras posibles formas de asociar sonido al RSI.  Se requiere mayor explicación y detalle respecto a la implementación.  El trabajo carece de una parte empírica donde se pueda juzgar o estimar el valor del esquema propuesto frente a otras posibles opciones. Esto se explica por su carácter de prueba de concepto, pero no se menciona esto como trabajo futuro.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper presents an intriguing study of how one can pose architecture search as a meta learning problem. By collecting features from networks trained on various datasets and training a “ranking classifier” (the actual details of the classifier do not seem to be described in detail) one can potentially infer what a good architecture for a new problem could be by simply running the ranker on the extracted features for a new problem setup.  One notable comment from the paper is that the authors fix some important hyper-parameters for all the networks. I am of the opinion that optimizing the learning rate (and its decay schedule) is actually quite important. I hypothesize that a lot of the conclusions of this paper may change quite a bit if the authors did an actual search over the rates instead. I suspect that instead of training 11k nets, one can train 2k nets with 5 learning rates each and get a much better result that is actually compelling.  I am not convinced that the protocol for generating the various architectures is doing a good job at creating a diversity of architecture (simply because of the max depth of 8 layers and 14 components overall). I suspect that most of these generated architectures are actually almost identical performance-wise and that it’s a waste to train so many of them on so many tasks. Unless the authors are already doing this, they should define a pruning mechanism that filters out nets that are too similar to already existing ones.  The batch normalization experiments in Table 2 seem odd and under-explained. It is also well-known that the optimal learning rates when using batch norm vs. not using batch norm can differ by an order of magnitude so given the fixed learning rate throughout all experiments, I take these results with some grain of salt.  I am not sure we got many insights into the kinds of architectures that ended up being at the top. Either visualizations, or trends (or both), would be great.  This work seems to conflate the study of parallel vs. serial architectures with the study of meta learning, which are somewhat distinct issues. I take issue with the table that compares parallel vs. serial performance (table 2) simply because the right way would be to filter the architectures by the same number of parameters / capacity.  Ultimately the conclusion seems to be that when applying deep nets in a new domain, it is difficult to come up with a good architecture in advance. In that sense, it is hard to see the paper as a constructive result, because it’s conclusions are that while the ranker may do a good job often-times, it’s not that reliable. Thus I am not convinced that this particular result will be of practical use to folks who are intending to use deep nets for a new domain.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper describes a system to assist written test scoring.  - Strengths: The paper represents an application of an interesting NLP problem -- recognizing textual entailment -- to an important task -- written test scoring.  - Weaknesses: There isn't anything novel in the paper. It consist of an application of an existing technology to a known problem.  The approach described in the paper is not autonomous -- it still needs a human to do the actual scoring. The paper lacks any quantitative or qualitative evaluation of how useful such system is. That is, is it making the job of the scorer easier? Is the scorer more effective as compared to not having automatic score?  The system contains multiple components and it is unclear how the quality of each one of them contributes to the overall experience.  The paper needs more work with the writing. Language and style is rough in several places.  The paper also contains several detailed examples, which don't necessarily add a lot of value to the discussion.   For the evaluation of classification, what is the baseline of predicting the most frequent class?  - General Discussion: I find this paper not very inspiring. I don't see the message in the paper apart from announcing having build such a system",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo pretende ofrecer una visión del uso de herramientas EVA en los diferentes entornos de asignaturas de enseñanza superior (presenciales, no presenciales y semipresenciales). La idea del paper es clara pero me cuesta trabajo encontrar la justificación de investigación del mismo. Los resultados que se obtienen son bastante segados y la propuesta no está definida como un experimento claro. Creo que hubiese sido interesante un mayor rigor a la hora de plantearlo. Hay además algunos aspectos, como por ejemplo, el hecho de la lista de evas seleccionadas que no se justifica, ¿de dónde se ha obtenido esa lista? ¿es cerrada?.  Por todo ello, abogo por no aceptar este trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "1.\tLo que se propone es interesante como una aplicación pero no es un trabajo científico.  2.    Ya no es interesante la aplicación de un Datamart desde el punto de vista técnico como es presentado por la autora pues existe mucha documentación y trabajos al respecto.  3. La autora debe buscar otros caminos si desea investigar el área.  4. Hay errores de diseño en las medidas de la tabla de hechos. Por lo cual es posible que no estén buenos algunos resultados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El documento ofrece una comparación respecto a la aplicación de algoritmos para la eliminación de ruidos impulsivos en dos tipos de arquitecturas de hardware: GPU y CPU.  El documento en general tiene una mala redacción, especialmente desde la página 4 en adelante.  El resumen del trabajo es adecuado, sin embargo hay que revisar su redacción, por ej. el uso de comas.  En la introducción se parte hablando de (i) procesamiento de imágenes, en medio (ii) se señala lo que se hace en el presente trabajo y luego se continua con (iii) una comparación entre GPU y CPU. Esta estructura no es adecuada, debería ser i-iii-ii, o simplemente mover iii a las secciones posteriores y dejar i-ii. Además de eso, no se habla mucho respecto al diseño experimental y a los resultados obtenidos, cosas que deben ser incluídas en al introducción.  La página 3 tiene un espacio en blanco grande que debe ser arreglado.  La sección \"A. Fase de revisión\" no tiene mucho valor como sección independiente, ya que menciona algo que es natural en un estudio de este tipo, que es la revisión bibliográfica. Se vería mucho mejor unirla con la sección siguiente (B).  la sección \"D. Artefactos resultantes del proyecto\" habla de \"resultados de investigación\", pero sólo se mencionan aspectos del software construidos más una planilla de resultados, sin embargo resultados directamente asociados a la investigación no se observan.  La página 5 tiene otro espacio en blanco.  En general, la presentación de resultados es pobre. No hay una tabla que indique claramente los resultados y los gráficos presentados no se ven bien. El análisis de los resultados es adecuado pero falta profundidad y relevancia respecto a que es lo que se quiere comparar exactamente en ambas arquitecturas. Las imágenes no son usadas ni explicadas en la comparación.  En resumen, el trabajo tiene buen destino pero requiere de un profundo trabajo correctivo para ser adecuado y científicamente aceptable.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Paper fácil de leer y bien escrito.  Está en la línea de los trabajos de INFONOR.  Sin embargo, no queda claro cómo aplica la \"Teoría de la relevancia\", es demasiado escueto en este ámbito del artículo que a mi parecer es lo más importante. Por lo que no es posible dar una opinión certera sobre el trabajo.  Se sugiere expandir la sección 2.2, en lo referente a cómo los aspectos para determinar la relevancia son utilizados o mezclados para determinar si una \"news\" es relevante o no.  La herramienta elaborada es interesante como también los elementos utilizados en su desarrollo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Overview:  The paper proposes a new model for training sense embeddings grounded in a lexical-semantic resource (in this case WordNet). There is no direct evaluation that the learned sense vectors are meaningful; instead, the sense vectors are combined back into word embeddings, which are evaluated in a downstream task: PP attachment prediction.  - Strengths:  PP attachment results seem solid.  - Weaknesses:  Whether the sense embeddings are meaningful remains uninvestigated.   The probabilistic model has some details that are hard to understand. Are the \\lambda_w_i hyperparameters or trained? Where does “rank” come from, is this taken from the sense ranks in WordNet?  Related work: the idea of expressing embeddings of words as a convex combination of sense embeddings has been proposed a number of times previously. For instance, Johansson and Nieto Piña “Embedding a semantic network in a word space” (NAACL, 2015) decomposed word embeddings into ontology-grounded sense embeddings based on this idea. Also in unsupervised sense vector training this idea has been used, for instance by Arora et al “Linear Algebraic Structure of Word Senses, with Applications to Polysemy”.  Minor comments:  no need to define types and tokens, this is standard terminology  why is the first \\lamba_w_i in equation 4 needed if the probability is unnormalized?  - General Discussion:",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper is motivated by the ability that human's visual system can recognize contents of environment by from critical features, and tried to investigate whether neural networks can also have this kind of ability.  Specifically, the paper proposed to use Auto-Encoder (AE) as the network to reconstruct the low fidelity of visual input. Moreover, similar to Mnih et al. (2014),  the paper also proposed to use a recurrent fashion to mimic the sequential behavior the  human visual system.   I think the paper is well motivated. However, there are several concerns: 1. The baselines of the paper are too weak. Nearest neighbor, bilinear, bicubic and cubic interpolations without any learning procedure are of course performed worse than AE based models. The author should compare with the STOA methods such as",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: Zero-shot relation extraction is an interesting problem. The authors have created a large dataset for relation extraction as question answering which would likely be useful to the community.  - Weaknesses: Comparison and credit to existing work is severely lacking. Contributions of the paper don't seen particularly novel.  - General Discussion:  The authors perform relation extraction as reading comprehension. In order to train reading comprehension models to perform relation extraction, they create a large dataset of 30m “querified” (converted to natural language) relations by asking mechanical turk annotators to write natural language queries for relations from a schema. They use the reading comprehension model of Seo et al. 2016, adding the ability to return “no relation,” as the original model must always return an answer. The main motivation/result of the paper appears to be that the authors can perform zero-shot relation extraction, extracting relations only seen at test time.  This paper is well-written and the idea is interesting. However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.  First, the authors are missing a great deal of related work: Neelakantan at al. 2015 ([Link] perform zero-shot relation extraction using RNNs over KB paths. Verga et al. 2017 ([Link] perform relation extraction on unseen entities. The authors cite Bordes et al. ([Link] who collect a similar dataset and perform relation extraction using memory networks (which are commonly used for reading comprehension). However, they merely note that their data was annotated at the “relation” level rather than at the triple (relation, entity pair) level… but couldn’t Bordes et al. have done the same in their annotation? If there is some significant difference here, it is not made clear in the paper. There is also a NAACL 2016 paper ([Link] which performs relation extraction using a new model based on memory networks… and I’m sure there are more. Your work is so similar to much of this work that you should really cite and establish novelty wrt at least some of them as early as the introduction -- that's how early I was wondering how your work differed, and it was not made clear.  Second, the authors neither 1) evaluate their model on another dataset or 2) evaluate any previously published models on their dataset. This makes their empirical results extremely weak. Given that there is a wealth of existing work that performs the same task and the lack of novelty of this work, the authors need to include experiments that demonstrate that their technique outperforms others on this task, or otherwise show that their dataset is superior to others (e.g. since it is much larger than previous, does it allow for better generalization?)",
            "output": [
                "en"
            ]
        },
        {
            "input": "First, I'd like to thank the authors for their answers and clarifications. I find, the presentation of the multi-stage version of the model much clearer now.  Pros:  + The paper states a sparse coding problem using cosine loss, which allows to solve the problem in a single pass.  + The energy-based formulation allows bi-directional coding that incorporates top-down and bottom-up information in the feature extraction process.   Cons:  + The cost of running the evaluation could be large in the  multi-class setting, rendering the approach less attractive and the computational cost comparable to recurrent architectures.  + While the model is competitive and improves over the baseline, the paper would be more convincing with other comparisons (see text). The experimental evaluation is limited (a single database and a single baseline)  ------  The motivation of the sparse coding scheme is to perform inference in a feed forward manner. This property does not hold in the multi stage setting, thus optimization would be required (as clarified by the authors).  Having an efficient way of performing a bi-directional coding scheme is very interesting. As the authors clarified, this could not necessarily be the case, as the model needs to be evaluated many times for performing a classification.  Maybe an interesting combination would be to run the model without any class-specific bias, and evaluation only the top K predictions with the energy-based setting.  Having said this, it would be good to include a discussion (if not direct comparisons) of the trade-offs of using a model as the one proposed by Cao et al. Eg. computational costs, performance.  Using the bidirectional coding only on the top layers seems reasonable: one can get a good low level representation in a class agnostic way. This, however could be studied in more detail, for instance showing empirically the trade offs. If I understand correctly, now only one setting is being reported.  Finally, the authors mention that one benefit of using the architecture derived from the proposed coding method is the spherical normalization scheme, which can lead to smoother optimization dynamics. Does the baseline (or model) use batch-normalization? If not, seems relevant to test.   Minor comments:  I find figure 2 (d) confusing. I would not plot this setting as it does not lead to a function (as the authors state in the text).",
            "output": [
                "en"
            ]
        },
        {
            "input": "This work address the problem of supervised learning from strongly labeled data with label noise. This is a very practical and relevant problem in applied machine learning.  The authors note that using sampling approaches such as EM isn't effective, too slow and cannot be integrated into end-to-end training. Thus, they propose to simulate the effects of EM by a noisy adaptation layer, effectively a softmax, that is added to the architecture during training, and is omitted at inference time. The proposed algorithm is evaluated on MNIST and shows improvements over existing approaches that deal with noisy labeled data.  A few comments. 1. There is no discussion in the work about the increased complexity of training for the model with two softmaxes.   2. What is the rationale for having consecutive (serialized) softmaxes, instead of having a compound objective with two losses, or a network with parallel losses and two sets of gradients?  3. The proposed architecture with only two hidden layers isn't not representative of larger and deeper models that are practically used, and it is not clear that shown results will scale to bigger networks.   4. Why is the approach only evaluated on MNIST, a dataset that is unrealistically simple.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes a hybrid architecture that combines traditional CNN layers with separable RNN layers that quickly increase the receptive field of intermediate features. The paper demonstrates experiments on CIfar-10 and semantic segmentation, both by fine-tuning pretrained CNN models and by training them from scratch, showing numerical improvements.     The reviewers agreed that this paper presents a sound modification of standard CNN architectures in a clear, well-presented manner. They also highlighted the clear improvement of the manuscipt between the first draft and subsequent revisions.   However, they also agreed that the novelty of the approach is limited compared to recent works (e.g. Bell'16), despite acknowledging the multiple technical differences between the approaches. Another source of concern is the lack of large-scale experiments on imagenet, which would potentially elucidate the role of the proposed interleaved lrnn modules in the performance boost and demonstrate its usefulness to other tasks.     Based on these remarks, the AC recommends rejection of the current manuscript, and encourages the authors to resubmit the work once the large-scale experiments are completed.",
            "output": [
                "en"
            ]
        },
        {
            "input": "EL TEMA QUE ABORDA ESTE TRABAJO ES INTERESANTE. SIN EMBARGO, NO QUEDA CLARO CUÁL ES SU APORTE ORIGINAL. LA ARQUITECTURA PLANTEADA Y LOS DISPOSITIVOS USADOS SON AMPLIAMENTE UTILIZADOS.  COMENTARIOS DE FORMA: 1) Mejorar la redacción, por ejemplo: \"Los campos para esta tecnología es muy amplia como lo son juegos...\" \"...se había comentado en la sección sistema propuesto...\" NO EXISTE TAL SECCIÓN. 2) Detallar la descripción del dispositivo Emotiv EEG. ¿Canales en la figura 1? , etc.  RECOMENDACIONES, visitar sitios como: 1) [Link] 2) [Link]",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta una evaluación de tres sistemas software de videoconferencia, la evaluación se realiza tomando como referencia algunos modelos de calidad existentes.  Si bien el trabajo resulta de interés para la comunidad, éste requiere de mayores mejoras. Se recomienda mejorar los siguientes aspectos:  -Para evitar posibles sesgos en la evaluación se recomienda utilizar varios evaluadores no solamente uno. -No está claramente justificado el porqué de la elección de los tres sistemas evaluados habiendo más en el mercado. -Falta mejorar el estilo de redacción, por ejemplo se observan inconsistencias en el uso de referencias, se emplea tanto formato numérico como por nombres (pag. 7). La tabla 2 puede colocarse como apéndice, en los sumarios no suelen colocarse referencias.",
            "output": [
                "es"
            ]
        },
        {
            "input": "En  Cap III no veo diferencias o aportes  sustantivos a lo ya manifestado en documento “la necesidad en Chile de una infraestructura tecnológica colaborativa de apoyo a la investigación astronómica” Red Universitaria Nacional, Noviembre 2008. De manera que corresponde citarlo como referencia o sino hacer los aportes o diferencias sustantivas, al igual que [Link]  Finalmente, el artículo carece de relevancia, ya que los aportes no se diferencias de lo que presenta.   Más aún, las figuras no se explican, como tampoco se cita su fuente que están dadas en [Link]   No cabe duda que lo relevante serán los resultados que se obtengan del  proyecto (FONDEF D11I1060, adjudicado el año 2011), en el sentido del diseño e implementación de un observatorio virtual, el cual deberá cumplir con los estándares de IVOA, sin embargo, por ahora, no veo aportes sustantivos.  Además, no se mencionan las \"instancias donde presentarán problemáticas\", tampoco la o las \"problemáticas que enfrentan\" como comunidad ante el procesamiento de datos que serán resueltos mediante \"técnicas computacionales\", las que hasta ahora son desconocidas.  Por otro lado la arquitectura que se muestra y me parece natural es la de IVOA, sin embargo, no se muestran, al menos por ahora, los aportes que se han realizado en este sentido.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper presents a set of experiments investigating what kinds of information are captured in common unsupervised approaches to sentence representation learning. The results are non-trivial and somewhat surprising. For example, they show that it is possible to reconstruct word order from bag of words representations, and they show that LSTM sentence autoencoders encode interpretable features even for randomly permuted nonsense sentences.  Effective unsupervised sentence representation learning is an important and largely unsolved problem in NLP, and this kind of work seems like it should be straightforwardly helpful towards that end. In addition, the experimental paradigm presented here is likely more broadly applicable to a range of representation learning systems. Some of the results seem somewhat strange, but I see no major technical concerns, and think that that they are informative. I recommend acceptance.  One minor red flag:  - The massive drop in CBOW performance in Figures 1b and 4b are not explained, and seem implausible enough to warrant serious further investigation. Can you be absolutely certain that those results would appear with a different codebase and different random seed implementing the same model? Fortunately, this point is largely orthogonal to the major results of the paper.  Two writing comments: - I agree that the results with word order and CBOW are surprising, but I think it's slightly misleading to say that CBOW is predictive of word order. It doesn't represent word order at all, but it's possible to probabilistically reconstruct word order from the information that it does encode. - Saying that \"LSTM auto-encoders are more effective at encoding word order than word content\" doesn't really make sense. These two quantities aren't comparable.",
            "output": [
                "en"
            ]
        },
        {
            "input": "•Recomiendo un cambio en la estructura del artículo para un mejor entendimiento de las aportaciones de los autores:  (1) agregar una sección en la que resalte los elementos que se agregan en los diagramas UML JPI, (2) agregar una sección en la que se incluya la comparativa entre diagramas, resaltando sus diferencias y terminaría con una tabla comparativa y las ventajas que esta ofrece  •Resumen  •Cuando aparecen por primera vez las siglas debes de incluir su significado  •Abstract  •Revisar la redacción del abstract frases como:   o Permitts modularizong -->allows modularizing   o Modules for crosscutting concerns or aspect -->crosscutting concerns or aspects modules   o Try -->tries   o Case study classic of AOSD -->classic AOSD case study  •Introducción   oRevisar la congruencia de número por ejemplo:    - Para lograr dicho fin, este trabajo presenta y aplica …y verifica la hegemonía …    - Evitar palabras como:  luego…posteriormente, después  •Análisis teórico   oÚltimo párrafo página 3, frases muy largas, no se entiende el párrafo- rehacer el párrafo.  •Caso de estudio   oÚltimo párrafo página 3, frases muy largas, no se entiende el párrafo- rehacer el párrafo.   oRevisar bien al usar el concepto de “caso práctico”, revisar la opción de cambiar el título de la sección   oRevisar el último párrafo de la primera columna representa “un clásico para ejemplificar el uso de POA”  un cásico qué?  •Conclusiones:   •Final del primer párrafo: interfaces --> interfaz",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta una aproximación para la programación de proyectos mediante algoritmo de colonia de abejas. El trabajo, aun cuando tiene una buena redacción, es carente de la aplicación del algoritmo, no presenta un ejemplo o varios de aplicación.  Muestra la metodología, define bien el problema, pero no muestra un ejemplo de aplicación del algoritmo. En la figura 2 muestra una posible solución a un ejemplo planteado, pero no indica si es a través del algoritmo propuesto u otro método.  No queda claro el aporte de la investigación, ni los resultados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta un interesante desarrollo de un caso, como una propuesta más de metodología de inicio para la didáctica de la lógica de programación. Las conclusiones presentadas no tienen mucho fundamento en términos del logro del objetivo de inducir de esta manera el razonamiento lógico.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Propuesta novedosa de planificación de requisitos para una fábrica de software, como un aporte hacia el mejoramiento de la calidad de proyectos.  - A pesar que el título del artículo se orienta hacia la 'planificación de requerimientos', este punto solo se vuelve a abordar cuando narran cómo implementaron el prototipo. - No incluyen una base conceptual que permita sustentar el papel que juega la administración de requisitos en el proceso de desarrollo de software y particularmente en el aseguramiento de la calidad del proceso. - No se evidencia cómo con un aporte en la planificación automática de los requisitos para la fábrica de software, ésto le permitirá reducir sus tiempos de desarrollo (estimados vs reales) y por ende asegurar una mayor calidad. - No es muy clara la relación que existe entre la propuesta que hace en el marco de CMMI.  El artículo propone un modelo de planificación de requisitos, apoyado por una herramienta automática.  El prototipo que proponen es interesante y relevante. Pienso que puede organizarse mejor el modelo y método que proponen asociado a él, que en realidad es el aporte real de los autores. Considero que desde el punto de vista técnico sería importante que el análisis de resultados que plantean con el caso de estudio del banco, se hiciera por medio de una interpretación o comparación cuantitativa, que realmente evidencie que con esa planificación automática realmente se está mejorando la calidad del proceso y/o al menos la estimación y ejecución real de tiempos de desarrollo serán menores, escenario que según antecedentes ya ha sido justificado en su relación directa con la calidad.  Es una propuesta interesante que puede ser aplicada en casos reales de procesos de administración de ingeniería de requisitos. Actualmente aportaría en la disminución de tiempos asociados a esta fase de desarrollo de productos software, y consecuentemente con la calidad del proceso. Teniendo en cuenta que la Ingeniería de Requisitos tiene tantas causas y acciones problémicas, que generan crisis de software y por ende una afectación en la gestión de la calidad, queda como un interrogante abierto el que realmente un aporte hacia la 'planificación' del requerimiento logre un efecto considerable, con respecto a otras causas o puntos cruciales como la 'priorización de requisitos', la validación y/o su trazabilidad como tal.  La organización del documento puede mejorar en los siguientes aspectos: - Algunas de las figuras que se incluyen no son necesarias, pues realmente no aportan algo adicional de lo descrito en el texto, además que visualmente no dicen mucho. - En el apartado de 'Diseño de APARD' nombran muchos aspectos de orden técnico característicos de las fábricas de software de referencia, que no le dan mayor peso a la intención del artículo, ni están dando datos realmente influyentes parra la aplicación. - Se puede optimizar la calidad de las figuras (principalmente las que muestran los componentes internos del algoritmo y las acciones de uso del sistema -perfiles, pues son las que evidencian el mayor aporte). - Hay varios errores de redacción que deben ser revisados (p. ejemplo: el uso de 'en base de', debería cambiarse por 'con base en'; 'se hace uso', por 'se usa'.. )",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este artículo propone un conjunto de medidas de cuantificación basadas en la triangulación de Delaunay de características de las huellas dactilares como principios para un esquema de indexación.  El trabajo se expone mayoritariamente claro y las propuestas y resultados son interesantes para el congreso. Cabe hacer notar los siguientes aspectos negativos o que no quedan claros en el trabajo:  - Cuidado con mezclar títulos en inglés y contenido en español (revisar) - Revisar la redacción de la conclusión   \"siendo esta casa vez menor a medida\" - De los resultados mostrados, sólo la tabla 2 realiza presenta un resultado comparativo con otras soluciones, por lo que otros gráficos deberían también incluirse en forma \"comparativa\" - No queda claro la eficiencia de la propuesta ni el tamaño de la bd, más bien parece pequeña en relación a la cantidad de huellas que se espera que un sistema real maneje. Esto dificulta el apreciar y encontrar justificación a los 45 segundos presentados cuando el sistema se \"estabiliza\" - Se echa de menos que ante la definición de cualquier tipo de índice, no haya un desarrollo más elaborado de la complejidad computacional, estructura de datos y ambiente de pruebas utilizado para tomar los tiempos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo es interesante, pertinente. En particular el esquema de control propuesto. Se sugiere realizar las siguientes correcciones:  1. El resumen (español) y el abstract (inglés) presentan algunas diferencias menores. Se sugiere corregir para que ambos textos expresen exactamente lo mismo. Igual pasa con las palabras clave y las keywords.  2. En español los guiones para separar palabras tienen reglas ortográficas: el guión no debe separar las letras de una misma sílaba.  3. La ecuación (2) debe ser referenciada en el texto.  4. En la página 3, segunda columna: \"... es la señal de control a designar, ...\". No es \"designar\" sino \"diseñar\". Asimismo: \"... retroalimentaci ́ n de estados que ...\": Sería más bien : \"... retroalimentación de estados tal que ...\".  5. En la página 4, primera columna: \"Se utilizaran motores ...\", agregar tilde.  6. En la página 4, figura 5: corregir la leyenda \"CONTROL SEUNDARIO\" al interior de bloque correspondiente.  7. En la página 4, segunda columna: \"Los sensores utilizados en el gripper son sen- sores resistivo, uno de rotación para medir la artivulaci ́ n del brazo\", resistivos (coherencia de número), articulación (error tipográfico). \"... de Texas Instrument para leer ...\". Es Texas Instruments. Aclarar el término \"control calculador\".  8. En la página 5, segunda columna: se referencia la figura 9 cuando debería ser la 8.  9. En la página 6, primera y segunda columna: \"... es la salida del derivador [?].\". Aclarar la interrogación. \"... en el esquema de la Figura.\". ¿Qué figura?. En las figuras 10 y 11 se debe ser consistente con el término empleado: STA en lugar de \"AST\".  10. En la página 7, primera columna: \"resultadis\", \"compoara\", omisión de punto al final del párrafo, \"los resultado\", \"En las Figuras 15, 15 y 16\". Agregar dos o tres párrafos donde se discuta acerca de estas tres figuras.  11. En las conclusiones: interogante, ¿la implementación del PD fue a nivel de simulación o se controló realmente el quadrotor?. Aclarar.  Se sugiere realizar una revisión completa del texto para realizar correcciones menores: espacio después de una coma, tildes, separación de palabras con guiones cuando se pasa de una línea a otra, separación entre palabras, etc.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo lleva a cabo una comparación de performance para implementaciones basadas en GPU y en CPU para el mismo algoritmo. La programación de GPUs es un tema muy actual en HPC.  Existen problemas en la presentación del artículo y las imágenes no están bien contextualizadas.  Implementaciones y comparaciones de performance entre GPU y CPU son un tema ya abordado en trabajos existentes.  El artículo describe en forma relativamente específica la implementación y sus detalles, en conjunto con los problemas encontrados.  El tema de programación GPU es un tema muy actual en computación de alto rendimiento y su comparación con programación basada en CPU me parece relevante.  Sería recomendable mejorar el orden del artículo, relacionando de mejor manera las imágenes y tablas. Existen faltas de ortografía evidentes dentro del contenido del trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper describes how to approximate the FastText approach such that its memory footprint is reduced by several orders of magnitude, while preserving its classification accuracy. The original FastText approach was based on a linear classifier on top of bag-of-words embeddings. This type of method is extremely fast to train and test, but the model size can be quite large.  This paper focuses on approximating the original approach with lossy compression techniques. Namely, the embeddings and classifier matrices A and B are compressed with Product Quantization, and an aggressive dictionary pruning is carried out. Experiments on various datasets (either with small or large number of classes) are conducted to tune the parameters and demonstrate the effectiveness of the approach. With a negligible loss in classification accuracy, an important reduction in term of model size (memory footprint) can be achieved, in the order of 100~1000 folds compared to the original size.  The paper is well written overall. The goal is clearly defined and well carried out, as well as the experiments. Different options for compressing the model data are evaluated and compared (e.g. PQ vs LSH), which is also interesting. Nevertheless the paper does not propose by itself any novel idea for text classification. It just focuses on adapting existing lossy compression techniques, which is not necessarily a problem. Specifically, it introduces:   - a straightforward variant of PQ for unnormalized vectors,   - dictionary pruning is cast as a set covering problem (which is NP-hard), but a greedy approach is shown to yield excellent results nonetheless,   - hashing tricks and bloom filter are simply borrowed from previous papers.  These techniques are quite generic and could as well be used in other works.    Here are some minor problems with the paper:    - it is not made clear how the full model size is computed. What is exactly in the model? Which proportion of the full size do the A and B matrices, the dictionary, and the rest, account for? It is hard to follow where is the size bottleneck, which also seems to depend on the target application (i.e. small or large number of test classes). It would have been nice to provide a formula to calculate the total model size as a function of all parameters (k,b for PQ and K for dictionary, number of classes).      - some parts lack clarity. For instance, the greedy approach to prune the dictionary is exposed in less than 4 lines (top of page 5), though it is far from being straightforward. Likewise, it is not clear why the binary search used for the hashing trick would introduce an overhead of a few hundreds of KB.     Overall this looks like a solid work, but with potentially limited impact research-wise.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El título del trabajo induce al lector a la espera de encontrarse con el diseño e implementación de un sistema de control de regadío, sin embargo a medida que se profundiza en la lectura del documento esto se ve cada vez más lejano, ya que el autor nos propone una revisión de diversos resultados de trabajos realizados por terceros en una especie de recopilación de información referente al tema, para finalmente plantear desde su punto de vista cuales de estos resultados pudiesen ser considerados de interés dependiendo del tipo de cultivo.  Es necesario modificar el nombre del artículo ya que induce a confusión al lector, pues al finalizar de revisar el documento no se ha obtenido como resultado el diseño ni menos la construcción del sistema de regadío, sólo se han obtenido alternativas a considerar dependiendo de diversos factores. Tal vez es necesario enfocarse en un tipo de cultivo específico para realizar en detalle el diseño y la implementación del sistema de regadío con la finalidad de realizar pruebas que validen el trabajo realizado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "ResNet and other architectures that use shortcuts have shown empirical success in several domains and therefore, studying the optimization for such architectures is very valuable. This paper is an attempt to address some of the properties of networks that use shortcuts. Some of the experiments in the paper are interesting. However, there are two main issues with the current paper:  1- linear vs non-linear: I think studying linear networks is valuable but we should be careful not to extend the results to networks with non-linear activations without enough evidence. This is especially true for Hessian as the Hessian of non-linear networks have very large condition number (see the ICLR submission \"Singularity of Hessian in Deep Learning\") even in cases where the optimization is not challenging. Therefore, I don't agree with the claims in the paper on non-linear networks. Moreover, one plot on MNIST is not enough to claim that non-linear networks behave similar to linear networks.  2- Hessian at zero initial point: The explanation of why we should be interested in Hessain at zero initial point is not acceptable. The zero initial point is not interesting because it is a very particular point that cannot tell us about the Hessian during optimization.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper describes a deep-learning-based model for parsing the creole Singaporean English to Universal Dependencies. They implement a parser based on the model by Dozat and Manning (2016) and add neural stacking (Chen et al., 2016) to it. They train an English model and then use some of the hidden representations of the English model as input to their Singlish parser. This allows them to make use of the much larger English training set along with a small Singlish treebank, which they annotate. They show that their approach (LAS 76.57) works better than just using an English parser (LAS 65.6) or training a parser on their small Singlish data set (LAS 64.01). They also analyze for which common constructions, their approach improves parsing quality.   They also describe and evaluate a stacked POS model based on Chen et al. (2016), they discuss how common constructions should be analyzed in the UD framework, and they provide an annotated treebank of 1,200 sentences. 100 of them were annotated by two people and their inter-annotator agreement was 85.3 UAS and 75.7 LAS.  - Strengths:   - They obtain good results and their experimental setup appears to be solid.   - They perform many careful analyses and explore the influence on many parameters of their model.   - They provide a small Singlish treebank annotated according to the Universal Dependencies v1.4 guidelines.   - They propose very sound guidelines on how to analyze common Singlish constructions in UD.   - Their method is linguistically informed and they nicely exploit similarity between standard English and the creole Singaporean English.   - The paper presents methods for a low-resource language.   - They are not just applying an existing English method to another language but instead present a method that can be potentially used for other closely related language pairs.   - They use a well-motivated method for selecting the sentences to include in their treebank.   - The paper is very well written and easy to read.  - Weaknesses:   - The annotation quality seems to be rather poor. They performed double annotation of 100 sentences and their inter-annotator agreement is just 75.72% in terms of LAS. This makes it hard to assess how reliable the estimate of the LAS of their model is, and the LAS of their model is in fact slightly higher than the inter-annotator agreement.   UPDATE: Their rebuttal convincingly argued that the second annotator who just annotated the 100 examples to compute the IAA didn't follow the annotation guidelines for several common constructions. Once the second annotator fixed these issues, the IAA was reasonable, so I no longer consider this a real issue.  - General Discussion:  I am a bit concerned about the apparently rather poor annotation quality of the data and how this might influence the results, but overall, I liked the paper a lot and I think this would be a good contribution to the conference.  - Questions for the authors:   - Who annotated the sentences? You just mention that 100 sentences were annotated by one of the authors to compute inter=annotator agreement but you don't mention who annotated all the sentences.   - Why was the inter-annotator agreement so low? In which cases was there disagreement? Did you subsequently discuss and fix the sentences for which there was disagreement?   - Table A2: There seem to be a lot of discourse relations (almost as many as dobj relations) in your treebank. Is this just an artifact of the colloquial language or did you use \"discourse\" for things that are not considered \"discourse\" in other languages in UD?   - Table A3: Are all of these discourse particles or discourse + imported vocab? If the latter, perhaps put them in separate tables, and glosses would be helpful.  - Low-level comments:   - It would have been interesting if you had compared your approach to the one by Martinez et al. (2017, [Link] Perhaps you should mention this paper in the reference section.   - You use the word \"grammar\" in a slightly strange way. I think replacing \"grammar\" with syntactic constructions would make it clearer what you try to convey. (e.g., line 90)   - Line 291: I don't think this can be regarded as a variant of it-extraposition. But I agree with the analysis in Figure 2, so perhaps just get rid of this sentence.   - Line 152: I think the model by Dozat and Manning (2016) is no longer state-of-the art, so perhaps just replace it with \"very high performing model\" or something like that.   - It would be helpful if you provided glosses in Figure 2.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:   - The paper is clearly written and well-structured.    - The system newly applied several techniques including global optimization to end-to-end neural relation extraction, and the direct incorporation of the parser representation is interesting.   - The proposed system has achieved the state-of-the-art performance on both ACE05 and CONLL04 data sets.   - The authors include several analyses.  - Weaknesses:   - The approach is incremental and seems like just a combination of existing methods.     - The improvements on the performance (1.2 percent points on dev) are relatively small, and no significance test results are provided.  - General Discussion:  - Major comments:   - The model employed a recent parser and glove word embeddings. How did they affect the relation extraction performance?   - In prediction, how did the authors deal with illegal predictions?  - Minor comments:   - Local optimization is not completely \"local\". It \"considers structural correspondences between incremental decisions,\" so this explanation in the introduction is misleading.   - Points in Figures 6 and 7 should be connected with straight lines, not curves.   - How are entities represented in \"-segment\"?   - Some citations are incomplete. Kingma et al. (2014) is accepted to ICLR, and Li et al. (2014) misses pages.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This work reframes paragraph vectors from a generative point of view and in so doing, motivates the existing method of inferring paragraph vectors as well as applying a L2 regularizer on the paragraph embeddings. The work also motivates joint learning of a classifier on the paragraph vectors to perform text classification.  The paper has numerous citation issues both in formatting within the text and the formatting of the bibliography, e.g. on some occasions including first names, on others not. I suggest the authors use a software package like BibTex to have a more consistent bibliography. There seems to be little novelty in this work.   The authors claim that there is no proposed method for inferring unseen documents for paragraph vectors. This is untrue. In the original paragraph vector paper, the authors show that to get a new vector, the rest of the model parameters are held fixed and gradient descent is performed on the new paragraph vector. This means the original dataset is not needed when inferring a paragraph vector for new text. This work seems to be essentially doing the same thing when finding the MAP estimate for a new vector. Thus the only contribution from the generative paragraph vector framing is the regularization on the embedding matrix.  The supervised generative paragraph vector amounts to jointly training a linear classifier on the paragraph vectors, while inference for the paragraph vector is unchanged. For the n-gram based approach, the authors should cite Li et al., 2015.  In the experiments, table 1 and 2 are badly formatted with .0 being truncated. The authors also do not state the size of the paragraph vector. Finally the SGPV results are actually worse than that reported in the original paragraph vector paper where SST-1 got 48.7 and SST-2 got 86.3.  Bofang Li, Tao Liu, Xiaoyong Du, Deyuan Zhang, Zhe Zhao, Learning Document Embeddings by Predicting N-grams for Sentiment Classification of Long Movie Reviews, 2015.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Me parece un trabajo interesante, principalmente por aportar evidencia empírica sobre técnicas de co-creación. Su contenido y estructura están técnicamente bien presentados. No obstante, el trabajo tiene omisiones relevantes para valorar su contribución científica. Por ejemplo, no presenta análisis estadístico de los datos arrojados. Solo expone una distribución de los resultados sin evidenciar significancia estadística. También extraño una sección (o en las conclusiones) sobre limitaciones a la validez del experimento. Creo que tiene varias amenazas a la validez que no han sido tratadas. Por nombrar algunas: no se explica si la asignación a los grupos fue aleatoriamente; el tiempo de las sesiones es distinta; el aprendizaje en sesiones anteriores, etc.  Otras sugerencias:  pág. 1\tTítulo\tCreo que no es adecuado el título. No representa el core del trabajo que es un experimento. pág. 4\tSegunda columna\tErrores en formato de viñetas  pág. 4\tTercera viñeta segunda columna\tcada VEZ que  pág. 5\tÚltima viñeta primera columna\tparéntesis",
            "output": [
                "es"
            ]
        },
        {
            "input": "Interesting application domain.  Nothing new from a machine learning perspective. They authors should provide more information about the models they have obtained with the different classifiers (feature subset selection used, selected features, accuracies, statistical significance on the differences on accuracies, the models themselves, ...). Semi-supervised classification is the appropriate method for the last paragraph in the \"Methodology\" section.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo muestra el diseño de una investigación sobre el impacto de las competencias TI en la percepción del éxito profesional, pero no es lo que señala en su título. Se observa una sección correspondiente a una extensa revisión de trabajos previos y definiciones, en comparación con la sección que muestra el diseño de la investigación, la cual es bastante breve. En mi opinión era conveniente haber presentado el artículo como una revisión sistemática sobre la literatura existente del tema con el objeto de encontrar brechas y/o similitudes en el diseño de la investigación, o haber puesto más énfasis en esto último. Si bien el tema puede ser novedoso, el artículo no lo demuestra, ya que solo es la presentación de un diseño de investigación.  En la sección de conclusiones, no se muestran conclusiones concretas a partir del trabajo realizado, solo se plantean posibles escenarios de un trabajo futuro.  Con respecto a la forma, el artículo se encuentra bien estructurado, pero se observan detalles a corregir:  - abuso de “TI” - en algunos párrafos se señalan trabajos previos sin ser referenciados - la figura del modelo es muy básica (no es un aporte) - párrafos no alineados (justificados) - la figura 1 debió ser una tabla - error en la correlación de figuras",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta una propuesta para una plataforma de generación de contenidos educacionales que permite acceso ubicuo. Este tema es de mucha actualidad e interés.  Al parecer habría sido presentado en otro congreso, con muy pequeñas variaciones y que sería bueno destacar y especificar esas similitudes y/o diferencias.  La redacción y uso de referencias es correcta.",
            "output": [
                "es"
            ]
        },
        {
            "input": "UPDATE: The authors addressed all my concerns in the new version of the paper, so I raised my score and now recommend acceptance. -------------- This paper combines the recent progress in variational autoencoder and autoregressive density modeling in the proposed PixelVAE model. The paper shows that it can match the NLL performance of a PixelCNN with a PixelVAE that has a much shallower PixelCNN decoder. I think the idea of capturing the global structure with a VAE and modeling the local structure with a PixelCNN decoder makes a lot of sense and can prevent the blurry reconstruction/samples of VAE. I specially like the hierarchical image generation experiments.  I have the following suggestions/concerns about the paper:  1) Is there any experiment showing that using the PixelCNN as the decoder of VAE will result in better disentangling of high-level factors of variations in the hidden code? For example, the authors can train a PixelVAE and VAE on MNIST with 2D hidden code and visualize the 2D hidden code for test images and color code each hidden code based on the digit and show that the digits have a better separation in the PixelVAE representation. A semi-supervised classification comparison between VAE and the PixelVAE will also significantly improve the quality of the paper.  2) A similar idea is also presented in a concurrent ICLR submission \"Variational Lossy Autoencoder\". It would be interesting to have a discussion included in the paper and compare these works.  3) The answer to the pre-review questions made the architecture details of the paper much more clear, but I still ask the authors to include the exact architecture details of all the experiments in the paper and/or open source the code. The clarity of the presentation is not satisfying and the experiments are difficult to reproduce.  4) As pointed out in my pre-review question, it would be great to include two sets of MNIST samples maybe in an appendix section. One with PixelCNN and the other with PixelVAE with the same pixelcnn depth to illustrate the hidden code in PixelVAE actually captures the global structure.  I will gladly raise the score if the authors address my concerns.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este trabajo muestra los resultados del desarrollo de un CBIR basado en los índices de distancias métricas, comparándolo con sistemas existentes a través de la precisión de recuperación y comparando los resultados de eficiencia en tiempo para distintos enfoques de indexación como GNAT, NAT, etc. El trabajo aborda un problema importante de los sistemas de recuperación, su estructura es correcta y los resultados aparentan ser fundamentados.  Quizás los criterios de evaluación no son suficientes para poder determinar la superioridad de un enfoque sobre otro, aunque los autores reconocen las principales falencias respecto a este punto y visualizan trabajos futuros en esta dirección. La explicación de la sección 2.3, sobre la precisión, es poco clara en definir como se conoce de ante mano sobre las correctas imágenes más similares a una consulta para poder calcular la precisión. Los gráficos de tiempo de la figura 3, no indican la escala.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Summary: This paper introduces a heuristic approach for training a deep directed generative model, where similar to the transition operator of a Markov chain each layer samples from the same conditional distribution. Similar to optimizing a variational lower bound, the approach is to approximate the gradient by replacing the posterior over latents with an alternative distribution. However, the approximating distribution is not updated to improve the lower bound but heuristically constructed in each step. A further difference to variational optimization is that the conditional distributions are optimized greedily rather than following the gradient of the joint log-likelihood.  Review: The proposed approach is interesting and to me seems worth exploring more. Given that there are approaches for training the same class of models which are 1) theoretically more sound, 2) of similar computational complexity, and 3) work well in practice (e.g. Rezende & Mohamed, 2015), I am nevertheless not sure of its potential to generate impact. My bigger concern, however, is that the empirical evaluation is still quite limited.  I appreciate the authors included proper estimates of the log-likelihood. This will enable and encourage future comparisons with this method on continuous MNIST. However, the authors should point out that the numbers taken from Wu et al. (2016) are not representative of the performance of a VAE. (From the paper: “Therefore, the log-likelihood values we report should not be compared directly against networks which have a more flexible observation model.” “Such observation models can easily achieve much higher log-likelihood scores, […].”)  Comparisons with inpainting results using other methods would have been nice. How practical is the proposed approach compared to other approaches? Similar to the diffusion approach by Sohl-Dickstein et al. (2015), the proposed approach seems to be both efficient and effective for inpainting. Not making this a bigger point and performing the proper evaluations seems like a missed opportunity.  Minor: – I am missing citations for “ordered visible dimension sampling” – Typos and frequent incorrect use of \\citet and \\citep",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo nos presenta una alternativa de plataforma factible de ser considerada en robótica con fines educativos, dado que dependiendo del nivel en que se utilice puede enfocarse el estudio del móvil a alguna de las áreas que se ven involucradas, como la instrumentación (sensores y actuadores) o bien en la programación (navegación del móvil). Si bien el autor no hace referencia en profundidad al aspecto electrónico, es evidente la posibilidad de enfocarse también en la comunicación existente entre las placas o bien en el sistema de control de los motores, que ya por si sólo constituye una problemática de interés. Además se plantea la posibilidad de realizar mejoras, tal vez incorporando sensores de diversos tipos que permitan captar mayor información del entorno. Todo esto contribuye a que la plataforma Amadeus pueda ser considerada como una referencia para la didáctica de la robótica y la investigación.  Tanto el desarrollo del tema como las conclusiones planteadas tienen coherencia con lo presentado en el resumen del artículo, se destaca su utilización en cursos de pre y post-grado, lo cual fortalece su postura como herramienta didáctica y de investigación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Thank you for an interesting read.   To my knowledge, very few papers have looked at transfer learning with **no** target domain data (the authors called this task as \"extrapolation\"). This paper clearly shows that the knowledge of the underlying system dynamics is crucial in this case. The experiments clearly showed the promising potential of the proposed EQL model. I think EQL is very interesting also from the perspective of interpretability, which is crucial for data analysis in scientific domains.  Quesions and comments:  1. Multiplication units. By the universal approximation theorem, multiplication can also be represented by a neural network in the usual sense. I agree with the authors' explanation of interpolation and extrapolation, but I still don't quite understand why multiplication unit is crucial here. I guess is it because this representation generalises better when training data is not that representative for the future?  2. Fitting an EQL vs. fitting a polynomial. It seems to me that the number of layers in EQL has some connections to the degree of the polynomial. Assume we know the underlying dynamics we want to learn can be represented by a polynomial. Then what's the difference between fitting a polynomial (with model selection techniques to determine the degree) and fitting an EQL (with model selection techniques to determine the number of layers)? Also your experiments showed that the selection of basis functions (specific to the underlying dynamics you want to learn) is crucial for the performance. This means you need to have some prior knowledge on the form of the equation anyway!  3. Ben-David et al. 2010 has presented some error bounds for the hypothesis that is trained on source data but tested on the target data. I wonder if your EQL model can achieve better error bounds?  4. Can you comment on the comparison of your method to those who modelled the extrapolation data with **uncertainty**?",
            "output": [
                "en"
            ]
        },
        {
            "input": "RESUMEN:  El trabajo se presenta y describa la aplicación de una red social para noticias (4x4News), donde las noticias más relevantes estarán presentes (entre otras características). Esta aplicación se caracteriza por una pantalla divida en una matriz de 16x16, donde cada celda  es una noticia.   EVALUACIÓN GENERAL:  El trabajo está bien escrito y sigue un formato (casi) completamente adecuado para INFONOR. La aplicación suena interesante y potencialmente útil como un add-on para redes sociales ya comúnmente usadas (ej. Facebook).  Hay varios puntos independientes que considero que son importantes de resolver:  1) Si bien es un trabajo de ingeniería interesante, no puedo ver cuál es el aporte/contribución desde el punto científico ¿Qué se puede re-utilizar de este trabajo para un futuro trabajo científico?  2) Dado que ustedes ofrecen una aplicación, creo que es fundamental un link para (com)probar esta aplicación.  3) En mi opinión, el sitio Web [Link] se aproxima a lo propuesto por este trabajo. Estó es así, porque terra permite registro de usuarios (perfiles), comentar noticias, valorar noticias, y configurar el sitio Web para mostrar las noticias que un usuario desea.  4) Este podría ser un detalle menor, pienso que el uso de redes sociales se podría usar para algo más que solamente mostrar la noticia más importante (ej. mostrar una especie de tracking (social) de una(s) noticia(s) similar).  DETALLES MENORES:  - Al final de la introducción, el uso de BOLD no es recomendado. - “Los titulares no realizan un buen análisis”. ¿Qué es un “buen” análisis?. Durante el trabajo, se observa varios adjetivos usados de manera ambiguas y que son innecesarios (ej. “complejo proceso” en la sección 2.1). - Dentro de la sección 2: “Desarrollo”, se encuentra el trabajo relacionado (sección 2.1). Esta sección debería ser re-estructurada. - Las citas del tipo “X, y otros, AÑO” (ej. sección 2.2 “Wilson, y otros, 2014”), creo que están incorrectas. Deberían usar “et al”. - Sección 2.2, ¿la coincidencia de palabras es suficiente para decir que dos noticias son similares? Creo que un análsis más profundo es un necesario. - Explicar un poco más el concepto “bundles”. - En las referencias se usan números [1], pero en el texto no usa números. Recomiendo seguir el formato de INFONOR.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths: The authors have nice coverage of a different range of language settings to isolate the way that relatedness and amount of morphology interact (i.e., translating between closely related morphologically rich languages vs distant ones) in affecting what the system learns about morphology. They include an illuminating analysis of what parts of the architecture end up being responsible for learning morphology, particularly in examining how the attention mechanism leads to more impoverished target side representations. Their findings are of high interest and practical usefulness for other users of NMT.   - Weaknesses: They gloss over the details of their character-based encoder. There are many different ways to learn character-based representations, and omitting a discussion of how they do this leaves open questions about the generality of their findings. Also, their analysis could've been made more interesting had they chosen languages with richer and more challenging morphology such as Turkish or Finnish, accompanied by finer-grained morphology prediction and analysis.  - General Discussion: This paper brings insight into what NMT models learn about morphology by training NMT systems and using the encoder or decoder representations, respectively, as input feature representations to a POS- or morphology-tagging classification task. This paper is a straightforward extension of \"Does String-Based Neural MT Learn Source Syntax?,\" using the same methodology but this time applied to morphology. Their findings offer useful insights into what NMT systems learn.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: The paper addresses a relevant topic: learning the mapping between natural language and KB relations, in the context of QA (where we have only partial information for one of the arguments), and in the case of having a very large number of possible target relations.  The proposal consists in a new method to combine two different representations of the input text: a word level representation (i.e. with segmentation of the target relation names and also the input text), and relations as a single token (i.e without segmentation of relation names nor input text).   It seems, that the main contribution in QA is the ability to re-rank entities after the Entity Linking step.  Results show an improvement compared with the state of the art.   - Weaknesses: The approach has been evaluated in a limited dataset.   - General Discussion:  I think, section 3.1 fits better inside related work, so the 3.2 can become section 3 with the proposal. Thus, new section 3 can be splitted more properly.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The primary point made by this paper is that given certain architectural characteristics of multi-GPU systems, namely the use of bi-directional PCI-E for communication and the integration of two independent DMA engines on recent GPU devices (providing support for simultaneous independent communications), and given the characteristics of the communications patterns required by synchronous SGD trainers for deep neural networks, namely that the messages are large, dense, and have a fixed length, it makes sense to design communication collectives such as broadcast, reduce, and allreduce specifically for the use case of synchronous SGD training on a multi-GPU system.  The paper describes the implementation of these three collectives (broadcast, reduce, and allreduce) using a linear pipelining (LP) scheme on a (logical) ring topology.  The paper compares the LP collectives to two alternatives:  collectives based on a minimal spanning tree (MST) topology and collectives based on bidirectional exchange (BE).  First, a theoretical comparison is made using a standard cost model used in the high performance computing community.  When assumptions based on multi-GPU system architecture (very low latency for messages) and on the communication characteristics of synchronous SGD training (very large messages) are integrated into the model, the paper finds that the LP collectives should be less costly than BE collectives by a factor of 2 and less costly than MST collectives by a factor of log(p), where p is the number of GPUs being used.  Second, an empirical comparison is performed in which (1) the time required to perform each of the different collectives on a 4-device (k40m) system is measured as a function of message size and (2) the time required to perform each of the different collectives with a 200 MB message length is measured as a function of the number of devices in the system.  These measurements show that the LP-based collectives are consistently the fastest.  Third, DNN training experiments with AlexNet and GoogLeNet are performed on a 4-device system using three different synchronous SGD algorithms with the different implementations of the collectives (a total of 6 different algorithms in all).  Measurements of the communication and computation costs show that the LP collectives reduce communication costs without affecting computation costs (as expected).  Measurements of the convergence of the training loss as a function of time for the two DNN architectures show that use of the LP collectives leads to faster training.  While the theory says that the costs of LP collectives should be invariant to the number of devices in a multi-GPU system, the empirical work shows that in practice this does not hold going from 4 to 5 devices (in the tested configuration) because in a 5-device system messages must traverse the QPI.  Are there other practical considerations that the authors are aware of that affect the scaling of the LP collectives?  If so, these should be mentioned in the paper.  In the sentence \"Worringen (2003) proposed a pipeline collective model in shared memory environment for CPU data, but communications of different MPI processes sharing the same CPU memory bus within the same CPU socket.\" I really can't figure out what the words after \"but communications of different MPI processes\" are trying to convey.  This sentence is not comprehensible.  \"Please note the latency term is log pα, which is the smallest among algorithms in Table.1. Therefore, MST only suits for high frequent short messages.\"  The claim that MST collectives are only suitable for high-frequency, short messages does not follow from the statement that MST collectives have the smallest latency term.  You also need to consider the way the cost scales with message size (the bandwidth term).  If the MST collectives had a better bandwidth term than the other collectives, then they would also be superior for large messages.  \"Let’s take an appropriate block size b to ensure n/b ≪ α.\"  This looks wrong, since n > b.  Should it be b/n ≪ α?  \"However, the parameters are not consistent after several iterations due to the precision issues of float multiplications in Gradient Update.\"  Are you sure the inconsistency in weight estimates across devices is due to multiplication?  I would expect that it would be due to gradients being accumulated in different orders; that is, because floating point addition is not commutative.  I recommend replacing the term \"sub-gradients\" in this paper with \"partial gradients.\"  In the optimization literature, the term \"sub-gradient\" has a very specific meaning that differs from this paper's use of the term (see",
            "output": [
                "en"
            ]
        },
        {
            "input": "Me parece un artículo interesante que pudo centrarse más en el desarrollo de una aplicación sobre Kurogo (un producto atractivo descrito en el artículo) que en el estudio de la ubicuidad de tecnologías para su interoperabilidad.  En este punto me saltan diversas dudas, ya que el estudio concluye la siguiente configuración de interoperabilidad:   \"DVB-2T como el estándar internacional de transmisión de TVDi escogido por Colombia, MHP como el middleware para la TVDi, MPEG como el formato de codificación y decodificación de audio y video de los contenidos y SCORM como estándar óptimo para la generación de contenidos.\"  Eso significa que en los estudios se debió utilizar transmisión por tv digital??? Y, por lo que entiendo, se usó un \"logitech revenue\" lo que convierte al tv en una salida de una conexión a internet, por lo que sería lo mismo que las comparaciones sobre un PC común. ¿Estoy en lo correcto?  Con esta duda, aún me parece que el artículo puede ser interesante de considerar (weak accept) y aclarar los conceptos en la presentación del mismo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Muy buen artículo para comprender la ubicación espacial de objetos, con propósitos de control, en este caso aplicable a un conjunto de robot en un juego de futbol.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper presents a generative model of video sequence data where the frames are assumed to be generated by a static background with a 2d sprite composited onto it at each timestep.  The sprite itself is allowed to dynamically change its appearance and location within the image from frame to frame.  This paper follows the VAE (Variational Autoencoder) approach, where a recognition/inference network allows them to recover the latent state at each timestep.  Some results are presented on simple synthetic data (such as a moving rectangle on a black background or the “Moving MNIST” data.  However, the results are preliminary and I suspect that the assumptions used in the paper are far too strong too be useful in real videos.  On the Moving MNIST data, the numerical results are not competitive to state of the art numbers.  The model itself is also not particularly novel and the work currently misses some relevant citations.  The form of the forward model, for example, could be viewed as a variation on the DRAW paper by Gregor et al (ICML 2014).  Efficient Inference in Occlusion-Aware Generative Models of Images by Huang & Murphy (ICLR) is another relevant work, which used a variational auto-encoder with a spatial transformer and an RNN-like sequence model to model the appearance of multiple sprites on a background.  Finally, the exposition in this paper is short on many details and I don’t believe that the paper is reproducible from the text alone.  For example, it is not clear what the form of the recognition model is…  Low-level details (which are very important) are also not presented, such as initialization strategy.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The authors proposed to use leaky rectified linear units replacing binary units in Gaussian RBM.  A sampling method was presented to train the leaky-ReLU RBM. In the experimental section, AIS estimated likelihood on Cifar10 and SVHN were reported.   It's interesting for trying different nonlinear hidden units for RBM. However, there are some concerns for the current work.  1. The author did not explain why the proposed sampling method (Alg. 2) is correct. And the additional computation cost (the inner loop and the projection) should be discussed.  2. The results (both the resulting likelihood and the generative samples) of Gaussian RBM are much worse than what we have experienced. It seems that the Gaussian RBM were not trained properly.  3. The representation learned from a good generative model often helps the classification task when there are fewer label samples. Gaussian RBM works well for texture synthesis tasks in which mixing is an important issue. The authors are encouraged to do more experiments in these two direction.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper makes three main methodological contributions:  - definition of Neural Feature (NF) as the pixel average of the top N images that highly activation a neuron  - ranking of neurons based on color selectivity  - ranking of neurons based on class selectivity  The main weaknesses of the paper are that none of the methodological contributions are very significant, and no singularly significant result arises from the application of the methods.  However, the main strengths of the paper are its assortment of moderately-sized interesting conclusions about the basic behavior of neural nets. For example, a few are:  - “Indexing on class selectivity neurons we found highly class selective neurons like digital-clock at conv2, cardoon at conv3 and ladybug at conv5, much before the fully connected layers.” As far as I know, this had not been previously reported.  - Color selective neurons are found even in higher layers. (25% color selectivity in conv5)  - “our main color axis emerge (black-white, blue-yellow, orange-cyan and cyan- magenta). Curiously, these two observations correlate with evidences in the human visual system (Shapley & Hawken (2011)).” Great observation!  Overall, I’d recommend the paper be accepted, because although it’s difficult to predict at this time, there’s a fair chance that one of the “smaller conclusions” would turn out to be important in hindsight a few years hence.   Other small comments:  - The cite for “Learning to generate chairs…” is wrong (first two authors combined resulting in a confusing cite)   - What exactly is the Color Selectivity Index computing? The Opponent Color Space isn’t well defined and it wasn’t previously familiar to me. Intuitively it seems to be selecting for units that respond to a constant color, but the highest color selectivity NF in Fig 5 i for a unit with two colors, not one. Finally, the very last unit (lowest color selectivity) is almost the same edge pattern, but with white -> black instead of blue -> orange. Why are these considered to be so drastically different? This should probably be more clearly described.   - For the sake of argument, imagine a mushroom sensitive neuron in conv5 that fires highly for mushrooms of *any* color but not for anything else. If the dataset contains only red-capped mushrooms, would the color selectivity index for this neuron be high or low? If it is high, it’s somewhat misleading because the unit itself actually isn’t color selective; the dataset just happens only to have red mushrooms in it. (It’s a subtle point but worth considering and probably discussing in the paper)",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es una aplicación interesante, sin embargo los KPI no deben ser equivalentes a las medidas que finalmente quedarán en la tabla de hechos. Por ejemplo, el indicador promedio de defunciones por año, se debe implementar a través de la medida \"cantidad de defunciones\" que es una medida aditiva y se puede agregar por los distintos niveles de la dimensión (así puede obtenerse el KPI promedio por dia, mes, trimestre, etc). Hay varias dimensiones que están agrupadas en el modelo, siendo que son distintas (por ejemplo, caracteristica_madre). Se debe corregir el diseño, es posible que los resultados obtenidos por el sistema estén con errores.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper describes an experience concerning the automated inspection of spectra for the Pipeline Hubble Legacy Archive Grism data.  Comments:  In the conclusions the authors say that \"We have identified two classes of flawed spectra which were not picked up by the automatic classification because of their very small number of training samples. Per construction machine learning techniques can not classify such outliers.\" This sentence should be further explained. As Hastie, Tibshirani, and Friedman say in The Elements of Statistical Learning (see Chapter 7): \"it is too difficult to give a general rule on how much training data is enough; among other things, this depends on the signal-to-noise ratio of the underlying function, and the complexity of the models being fit to the data. \" So, by just saying that the number of training samples is small you do not provide enough information to decide whether machine learning techniques are adequate or not to solve a problem.  Other minor comments:  + If reference [2] has not yet been written or published it should be deleted from the paper.  The dataset may be of scientific importance.  It is mainly descriptive.",
            "output": [
                "en"
            ]
        },
        {
            "input": "I reviewed the manuscript as of December 7th.  Summary: The authors investigate the transferability of adversarial examples in deep networks. The authors confirm that transferability exists even in large models but demonstrate that it is difficult to manipulate the network to adversarially perturb an image into a specifically desired label. The authors additionally demonstrate real world attacks on a vision web service and explore the geometric properties of adversarial examples.  Major Comments: 1. The paper contains a list of many results and it is not clear what single message this paper provides. As mentioned in the comments, this paper is effectively 15 pages and 9 page of results in the Appendix heavily discussed throughout the main body of the paper. Although there is no strict page limit for this conference, I do feel this pushes the spirit of a conference publication. I do not rule out this paper for acceptance based on the length but I do hold it as a negative because clarity of presentation is an important quality. If this paper is ultimately accepted, I would suggest that the authors make some effort to cut down the length even further beyond the 13 pages posted elsewhere. I have marked some sections to highlight areas that may be trimmed.  2. The section of geometric understanding is similar to results of 'Adversarial Perturbations of Deep Neural Networks' in Warde-Farley and Goodfellow (2015). See Figure 1.2. I am not clear what the authors show above-and-beyond these results. If there are additional findings, the authors should emphasize them.  3. The authors expand on observations by Goodfellow et al (2014) and Szegedy et al (2013) demonstrating that large-scale models are susceptible to adversarial perturbations (see also Kurakin et al (2016)). The authors additionally demonstrate that attempting to perform adversarial manipulation to convert an image to a particular, desired label is more difficult.  4. The authors demonstrate that they can target a real-world vision API. These results are compelling but it is not clear what these results demonstrate above-and-beyond Papernot et al (2016).   As far I can understand, I think that the most interesting result from this paper not previously described in the literature is to note about the unique difficulty about performing adversarial manipulation to convert an image to a particular, desired label. The rest of the results appear to expand on other results that have already appeared in the literature and the authors need to better explain what these makes these results unique above-and-beyond previous work.  Areas to Trim the Paper: - Table 1 is not necessary. Just cite other results or write the Top-1 numbers in the text. - Condense Section 2.2.1 and cite heavily. - Figure 2 panels may be overlaid to highlight a comparison.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates. Several techniques are presented in a clear way and parameterized method is proposed and evaluated on the CIFAR task. The concept is easy to understand and the authors chose state-of-the-art models to show the performance of their algorithm. The relevance of these results goes beyond image classification.   Pros:  - Simple and effective method to improve convergence - Good evaluation on well known database   Cons:  - Connection of introduction and topic of the paper is a bit unclear - Fig 2, 4 and 5 are hard to read. Lines are out of bounds and maybe only the best setting for T_0 and T_mult would be clearer. The baseline also doesn't seem to converge  Remarks: An loss surface for T_0 against T_mult would be very helpful. Also understanding the relationship of network depth and the performance of this method would add value to this analysis.",
            "output": [
                "en"
            ]
        },
        {
            "input": "A pesar de que el tema referente a la problemática de la navegación autónoma de robots móviles es de interés, el trabajo presentado no necesariamente tendría que serlo. Sin embargo a medida que el lector aborda en profundidad el documento es posible darse cuenta que el trabajo presentado constituye un aporte al tema. Ya desde el título se plantea con claridad lo que el lector encontrará en el documento, lo cual se ve reforzado con un planteamiento sencillo del tema por parte del autor facilitando la comprensión del trabajo realizado. Por otra parte, se presenta un prototipo cuya implementación es posible de replicar en laboratorio por quien se sienta interesado en el tema, lo cual contribuye a que este trabajo sea considerado como posible referencia en el ámbito educacional.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Here is a summary of the reviews:    Strengths  Experiments are done on state-of-the-art networks, on a real speech recognition problem (R3, R1)  Networks themselves are of a very large size (R3)  Computational gains are substantial (R3, R4)  Paper is clear (R1)    Weaknesses  Experiments are all done on a private dataset (R3)  No comparison to other pruning approaches (e.g. Han et al.) (R3); AC notes that reviewers added new results which compare to an existing pruning method  No comparison to distillation techniques (R1)  Paper doesn't present much novelty in terms of ideas (R3)    The AC encouraged feedback from the reviewers following author rebuttal and paper improvements. Reviewers stated that the improvements made to the paper made it publishable but was still closer to the threshold. R1 who had originally rated the paper 3: a \"clear reject\" updated the score to 6 (just above acceptance).    Considering the reviews and discussions, the AC thinks that this paper is a poster accept. There are no serious flaws, the improvements made to the paper during the discussion paper have satisfied the reviewers, and this is an important topic with practical benefits; evaluated on a real large-scale problem.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este paper presenta una herramienta (SAVE) para la verificación de arquitectura de software. SAVE realiza un chequeo estático de reglas asociadas a dependencias permitidas y prohibidas entre elementos del diseño y del código, y permite entregar un reporte sobre la consistencia entre ambos niveles respecto a dichas reglas.  En general la herramienta parece bastante poderosa por dos motivos: el uso de reglas sencillas y la inclusión de sets de reglas pre-definidas para patrones de diseño de amplia utilización. Esto, a mi juicio, es la diferencia más importante con otros frameworks similares.  La redacción es, en algunos lugares, poco objetiva. En particular sugeriría evitar el uso excesivo de adjetivos para los cuales no se provee de evidencia que los soporte. Por ejemplo, en varios lugares noté el uso de \"poderosa herramienta\", \"herramienta intuitiva\" o similares (no solamente referidos a SAVE, sino a otros trabajos). En todos esos casos, no se provee en forma explícita una evidencia que soporte el uso de dichos adjetivos.  Otro detalle que requiere arreglo es el título que aparece en el archivo PDF: \"Predicción de la dinámica del comportamiento...\", el cual no coincide con el título del paper. Probablemente los autores utilizaron una plantilla de un paper anterior con dicho título.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El articulo narra la experiencia del desarrollo de una solución robotizada para el problema industrial de reparación de motores eléctricos. En particular, el problema de realizar soldaduras de precisión de motores eléctricos mediante un brazo robótico. El artículo presenta aspectos prácticos del desarrollo de la solución, complementado con ilustraciones que ayudan a entender el problema y el proceso de desarrollo de la solución.  Entendiendo que se trata de una experiencia de transferencia tecnológica a la industria de servicios especializados de apoyo a la principal actividad económica regional (minería), se encontraron las siguientes falencias:  Aspectos de forma:  1. Se incurre recurrentemente en términos no técnicos, que confunden y no aportan antecedentes objetivos, además de fallas de redacción y ortografía. por ejemplo:  fallas infantiles --> simplemente debe ser \"fallas\" resultados óptimos --> si se emplea \"óptimo\" debe proveerse evidencia que sustente que es la mejor solución y no hay otra mejor. tasa de falla bastante alta --> es preferible indicar que la tasa de falla estimada es del 55% (5/9). \"bastante alta\" es ambigua. suelda --> solda? como le requerido --> como lo requerido como la General Electric, con muy buenos resultados --> como General Electric, con buenos resultados.  2. emplear siempre tercera persona.  esto nos entregó --> esto entregó lo que obtuvimos es lo siguiente --> lo que se obtuvo fue lo siguiente  3. no es relevante mencionar ciertas empresas a las cuales se le compró o se les encargó ciertos estudios: MOTORFIL, INDURA  4. Se asume que el lector conoce los términos y es capaz de identificar piezas como bobinas y conmutador desde las figuras. Esto no se debe asumir, y se debe explicar de manera clara y sencilla, e ilustrar su posición en las figuras donde se muestran motores eléctricos. Debe explicarse a pié de página nombres como Innova Chile y su rol en el proyecto.  5. Figura 6 es relevante en la explicación. Lamentablemente, es poco legible y esto debe ser corregido.  6. usar términos de alcanzable global más que local. por ejemplo, costo cercano al millón de pesos (chilenos?) --> costo equivalente a U$2.000 aprox.  7. Gráfico 1 (debe ser Figura 4): uniformar tamaños de fonts e indicar la variable en el eje X.  Aspectos de fondo:  1. falta una sección de background que permita entender luego términos que se utilizan posteriormente sin haberlos definidos/explicados previamente. En este sentido, hay un párrafo que explica que es un robot, pero aparece dentro de la sección de Robotización del Proceso de Soldadura, por lo que está mal ubicado. Debe estar antes junto con los demás elementos del background.  2. cuando se explica cómo se realizó la programación del robot, falta un dibujo o figura que apoye la explicación (plano de referencia, plano de usuario, plano de herramienta, etc.). Lo mismo es válido para la explicación de porqué se agregó un sensor óptico (agregar un dibujo o figura ilustrativa).  3. Se hacen afirmaciones que no se sustentan con referencias a estudios o documentos. Por el contrario, las referencias no son citadas dentro del cuerpo del artículo.  4. revisar la versión en inglés del resumen. Hay varios errores de redacción y gramática.  5. no hay información técnica en detalle de cómo se realizaron los pasos de programación del robot, por ejemplo. Solo hay descripciones generales.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta un metodo de detección de fracturas en imágenes de pozos.  El trabajo en general, es muy poco convincente por varias razones:  1.- Invierte MUCHO espacio en describir los fundamentos pero no comparar y/o discutir con el estado del arte. Existen MUCHOS métodos adaptivos de clasificación de imágenes, y el problema que se presenta no tiene nada diferente, salvo una aplicación diferente.  2.- No está clara la hipótesis, por lo que no se puede medir la contribución del trabajo.  3.- El metodo de detección que se describe solo define formulas matemáticas para la caracterización geométrica de las fracturas. Esto es un procedimiento bastante poco robusto y más aún, los resultados evaluando el metodo tampoco son convincentes en  métricas estándares utilizadas (accuracy, error,  ROC curve, etc).  4.- La metodología experimental es muy débil, tampoco compara el metodo con el estado del arte, ni usa métricas estándares para analizar la precision/exactitud del metodo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper introduces an extension of the entity grid model. A convolutional neural network is used to learn sequences of entity transitions indicating coherence, permitting better generalisation over longer sequences of entities than the direct estimates of transition probabilities in the original model.  This is a nice and well-written paper. Instead of proposing a fully neural approach, the authors build on existing work and just use a neural network to overcome specific issues in one step. This is a valid approach, but it would be useful to expand the comparison to the existing neural coherence model of Li and Hovy. The authors admit being surprised by the very low score the Li and Hovy model achieves on their task. This makes the reader wonder if there was an error in the experimental setup, if the other model's low performance is corpus-dependent and, if so, what results the model proposed in this paper would achieve on a corpus or task where the other model is more successful. A deeper investigation of these factors would strengthen the argument considerably.  In general the paper is very fluent and readable, but in many places definite articles are missing (e.g. on lines 92, 132, 174, 488, 490, 547, 674, 764 and probably more). I would suggest proofreading the paper specifically with article usage in mind. The expression \"...limits the model to do X...\", which is used repeatedly, sounds a bit unusual. Maybe \"limits the model's capacity to do X\" or \"stops the model from doing X\" would be clearer.  --------------  Final recommendation adjusted to 4 after considering the author response. I agree that objective difficulties running other people's software shouldn't be held against the present authors. The efforts made to test the Li and Hovy system, and the problems encountered in doing so, should be documented in the paper. I would also suggest that the authors try to reproduce the results of Li and Hovy on their original data sets as a sanity check (unless they have already done so), just to see if that works for them.",
            "output": [
                "en"
            ]
        },
        {
            "input": "First, let me praise the authors for generating and releasing an NLP data set: a socially useful task.  The authors use an algorithm to generate a 500-cluster-per-language data set in semantic similarity. This brings up a few points.  1. If the point of using the algorithm is to be scalable, why release such a small data set? It's roughly the same order of magnitude as the data sets released in the SemEval tasks over the recent years. I would have expected something orders of magnitude larger.  2. The authors hand checked a small subset of the clusters: they found one where it was ambiguous, and should probably have been removed. Mechanical Turk can scale pretty well -- why not post-facto filter all of the clusters using MT? This is (in effect) how ImageNet was created, and it has millions of items.  3. Evaluating data set papers is an tricky issue. What makes a data set \"good\" or publishable? There are a number of medium-sized NLP data sets released every year (e.g., through SemEval). Those are designed to address tasks in NLP that people find interesting. I don't know of a data set that exactly addresses the task that the authors propose: the task is trying to address the idea of semantic similarity, which has had multiple data sets thrown at it since SemEval 2012. I wish that the paper had included comparisons to show that the particular task / data combination is better suited for analyzing semantic similarity than other existing data sets.  Two final notes:  A. This paper doesn't seem very well-suited to ICLR.  New NLP data sets may be indirectly useful for evaluating word embeddings (and hence representations). But, I didn't learn much from the paper: GloVe is empirically less good for semantic similarity than other embeddings? If true, why? That would be interesting.  B. The first proposal for the \"put a word into a cluster and see if it stands out\" task (in the context of human evaluation of topic models), is  Jonathan Chang, Jordan Boyd-Graber, Chong Wang, Sean Gerrish, and David M. Blei. Reading Tea Leaves: HowHumans Interpret Topic Models. Neural Information Processing Systems, 2009  which deserves a citation, I think.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo es interesante por la temática que aborda y los resultados de los análisis realizados, más que por la metodología en sí. Me quedan dudas acerca de cómo se alimentan los análisis con la nueva información y cómo se integra el sistema a los sistemas transaccionales de la USACH. Sin embargo, es una aplicación interesante.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- summary  The paper proposes a differntiable Neural Physics Engine (NPE). The NPE consists of an encoder and a decoder function. The NPE takes as input the state of pairs of objects (within a neighbourhood of a focus object) at two previous time-steps in a scene. The encoder function summarizes the interaction of each pair of objects. The decoder then outputs the change in velocity of the focus object at the next time step. The NPE is evaluated on various environments containing bouncing balls.  - novelty  The differentiable NPE is a novel concept. However, concurrently Battaglia et al. (NIPS 2016) proposes a very similar model. Just as this work, Battaglia et al. (NIPS 2016) consider a model which consists of a encoder function (relation-centric) which encodes the interaction among a focus object and other objects in the scene and a decoder (relation-centric) function which considers the cumulative (encoded) effect of object interactions on the focus object and predicts effect of the interactions.  Aspects like only considering objects interactions within a neighbourhood (versus the complete object interaction graph in Battaglia et al.) based on euclideian distance  are novel to this work. However, the advantages (if any) of NPE versus the model of Battaglia et al. are not clear. Moreover, it is not clear how this neighbourhood thresholding scene would preform in case of n-ball systems, where gravitational forces of massive objects can be felt over large distances.  - citations   This work includes all relevant citations.  - clarity  The article is well written and easy to understand.  - experiments   Battaglia et al. evaluates on wider variety senerios compared to this work (e.g. n-bodies under gravitation, falling strings). Such experiments demonstrate the ability of the models to generalize. However, this work does include more in-depth experiments in case of bouncing balls compared to Battaglia et al. (e.g. mass estimation and varying world configurations with obstacles in the bouncing balls senerio).   Moreover, an extensive comparison to Fragkiadaki et al. (2015) (in the bouncing balls senerios) is missing. The authors (referring to answer to question 4) do point out to comaprable numbers in both works, but the experimental settings are different.  Comparison in a billiard table senerio like that Fragkiadaki et al. (2015) where a initial force is applied to a ball, would have been enlightening.   The authors only evaluate the error in velocity in the bouncing balls senerios. We understand that this model predicts only the velocity (refer to answer of question 2). Error analysis also with respect to ground truth ball position would be more enlightening. As small errors in velocity can quickly lead to entirely different scene configuration.  - conclusion / recommendation  The main issue with this work is the unclear novelty with respect to work of Battaglia et al. at NIPS'16. A quantitative and qualitative comparison with Battaglia et al. is lacking.  But the authors state that their work was developed independently.  Differentiable physics engines like NPE or that of Battaglia et al. (NIPS 2016) requires generation of an extensive amount of synthetic data to learn about the physics of a certain senerio. Moreover, extensive retraining is required to adapt to new sceneries (e.g. bouncing balls to n-body systems). Any practical advantage versus generating new code for a physics engine is not clear. Other \"bottom-up\" approaches like that of  Fragkiadaki et al. (2015) couple vision along with learning dynamics. However, they require very few input parameters (position, mass, current velocity, world configuration), as approximate parameter estimation can be done from the visual component.  Such approaches could be potentially more useful of a robot in \"common-sense\" everyday tasks (e.g. manipulation). Thus, overall potential applications of a differentiable physics engine like NPE is unclear.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This is an interesting article, present develop of a mobile robot use as beach cleaner.  I have 2 comments about the design, I think will be interesting define what is the dimension of collector and storage compartment for know what is the capacity of this cleaner.  In page 2 in the first paragraph a typo mistake was found.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Poca información sobre aspectos técnicos utilizados en el desarrollo del sistema.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Problemas de forma identificados:  - Figura 7 no es clara en su contenido. - Figura 5 y 6 no aportan al trabajo desarrollado. - El proceso de transacción debería estar numerado. - Cuadro debería ser Tabla, además la tabla 2, 3 y 4 no son legibles. Se deberían re-escribir. - Página 3 el texto de la palabra Samsung no es del mismo tipo de fuente. - Figura 8 no tiene título. - Se debe corregir y mejorar la ortografía (conclusiones).   Problemas de fondo:  - El apartado 3.1.2 no se encuentra relacionado directamente con el problemática planteada. - La descripción de las arquitecturas y modalidades de utilización de NFC no aporta a la solución expuesta. - En la sección 4.1 se hace mención a la máquina virtual Dalvik, sin embargo, desde la versión de Android Lollipop hacia arriba, se utiliza ART y no Dalvik. - La tabla 6 no aporta el trabajo desarrollado. - El trabajo desarrollado utiliza 8 de 11 páginas en introducción y tecnologías, sin embargo, sólo se utiliza 1 página para mostrar las evidencias. - Se plantean algunos indicadores, sin embargo, no se da evidencia de los valores obtenidos. - Las figuras 10, 11 y 12 muestran capturas de la aplicación?, sin embargo, no se indican en detalle la forma de aplicación de las tecnologías en Android. - Falta evidencias de la aplicación descrita, en particular desde al área de la ingeniería de software.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Un muy buen trabajo, presenta integración de varias tecnologías de una forma clara y coherente  A pesar de que lo mencionan como trabajo futuro, se debería tener en cuenta el HL7 desde ya",
            "output": [
                "es"
            ]
        },
        {
            "input": "Un muy buen artículo. Solo sugiero lo siguiente:  Las tablas en la sección de resultados deben ser explicadas.  Las tablas solo contienen el menor, mayor y media entre esos dos valores. Sería interesante considerar también la media general y la desviación estándar.  En las tablas 4, 5 y 6 solo algunas líneas contienen un valor destacado, las veces el mayor de la línea y otras el menor... Explicar mejor el significado de esas marcaciones en todas las tablas.  La referencia [12] comienza con \"and\" y no con el nombre del primer  autor (de echo parece que están con problemas también el resto de los autores).  La referencia [22] es la única que no usa iniciales para el nombre del autor.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo realiza un recorrido por definiciones de calidad, calidad de software y modelos de calidad. Algunos modelos se tratan primero en una sección preliminar y otros luego del análisis teórico, sugiero re-organizar la presentación de conceptos. En mi opinión, los conceptos de modelo de calidad y modelo conceptual no son equivalentes, aunque se tratan de forma conjunta en la introducción.  En la segunda sección se presentan varios modelos, pero no se establece claramente las relaciones entre ellos y cuál es el criterio para tenerlos en cuenta en esta línea de investigación. Existen múltiples propuestas de modelos de calidad de software y modelos específicos para web. Por otro lado, las guías de OWASP son relevantes para la seguridad de aplicaciones web, no son un modelo de calidad.  Sugiero exponer el análisis teórico (que incluye definiciones básicas de calidad) antes de la descripción y justificación de los modelos considerados. Por otro lado, se podrían agregar conceptos / atributos / modelos de la calidad específicos en el contexto de los sistemas bancarios.  En mi opinión, dedicar tanto espacio a definir el concepto de banca electrónica,  banca por internet y luego el de banca móvil, no resulta necesario en el estado del arte actual y el conocimiento público de estos conceptos. Sugiero centrarse en los objetivos de investigación de este trabajo en particular.  Las descripciones del marco metodológico DESMET y la metodología investigación – acción son muy breves. Es necesario establecer antes los objetivos de la investigación.  Los modelos conceptuales obtenidos son el resultado principal del trabajo. Se deben utilizar notaciones más legibles (sugiero también poner información extendida como anexo del artículo o en la web). Se debería explicar además como estos modelos fueron validados, para que sean confiables si son utilizados para definir ontologías o usados en trabajos posteriores.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths: A well written paper, examining the use of context in lexical entailment task is a great idea, a well defined approach and experimental set-up and good analysis of the results   - Weaknesses: Some information is missing or insufficient, e.g., the table captions should be more descriptive, a clear description for each of the word type features should be given.  General Discussion:   The paper presents a proposal of consideration of context in lexical entailment task. The results from the experiments demonstrate that context-informed models do better than context-agnostic models on the entailment task.   I liked the idea of creating negative examples to get negative annotations automatically in the two ways described in the paper based on WordNet positive examples. (new dataset; an interesting method to develop dataset)  I also liked the idea of transforming already-used context-agnostic representations into contextualized representations, experimenting with different ways to get contextualized representations (i.e., mask vs contetx2vec), and testing the model on 3 different datasets (generalizability not just across different datasets but also cross-linguistically).  Motivations for various decisions in the experimental design were good to see, e.g., why authors used the split they used for CONTEXT-PPDB (it showed that they thought out clearly what exactly they were doing and why).  Lines 431-434: authors might want to state briefly how the class weights were determined and added to account for the unbalanced data in the CONTEXT-WN experiments. Would it affect direct comparisons with previous work, in what ways?   Change in Line 589: directionality 4 --> directionality, as in Table 4  Suggested change in Line 696-697: is-a hierarchy of WordNet --> \"is-a\" hierarchy of WordNet   For the sake of completeness, represent \"mask\" also in Figure 1.  I have read the author response.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper develops Submodular Sum Product Networks (SSPNs) and an efficient inference algorithm for approximately computing the most probable labeling of variables in the model. The main application in the paper is on scene parsing. In this context, SSPNs define an energy function with a grammar component for representing a hierarchy of labels and an MRF for encoding smoothness of labels over space. To perform inference, the authors develop a move-making algorithm, somewhat in the spirit of fusion moves (Lempitsky et al., 2010) that repeatedly improves a solution by considering a large neighborhood of alternative segmentations and solving an optimization problem to choose the best neighbor. Empirical results show that the proposed algorithm achieves better energy that belief propagation of alpha expansion and is much faster.  This is generally a well-executed paper. The model is interesting and clearly defined, the algorithm is well presented with proper analysis of the relevant runtimes and guarantees on the behavior. Overall, the algorithm seems effective at minimizing the energy of SSPN models.  Having said that, I don't think this paper is a great fit for ICLR. The model is even somewhat to the antithesis of the idea of learning representations, in that a highly structured form of energy function is asserted by the human modeller, and then inference is performed. I don't see the connection to learning representations. One additional issue is that while the proposed algorithm is faster than alternatives, the times are still on the order of 1-287 seconds per image, which means that the applicability of this method (as is) to something like training ConvNets is limited.  Finally, there is no attempt to argue that the model produces better segmentations than alternative models. The only evaluations in the paper are on energy values achieved and on training data.  So overall I think this is a good paper that should be published at a good machine learning conference, but I don't think ICLR is the right fit.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper analyzes the story endings (last sentence of a 5-sentence story) in the corpus built for the story cloze task (Mostafazadeh et al. 2016), and proposes a model based on character and word n-grams to classify story endings. The paper also shows better performance on the story cloze task proper (distinguishing between \"right\" and \"wrong\" endings) than prior work.  Whereas style analysis is an interesting area and you show better results than prior work on the story cloze task, there are several issues with the paper. First, how do you define \"style\"? Also, the paper needs to be restructured (for instance, your section \"Results\" actually mixes some results and new experiments) and clarified (see below for questions/comments): right now, it is quite difficult for the reader to follow what data is used for the different experiments, and what data the discussion refers to.  (1) More details about the data used is necessary in order to assess the claim that \"subtle writing task [...] imposes different styles on the author\" (lines 729-732). How many stories are you looking at, written by how many different persons? And how many stories are there per person? From your description of the post-analysis of coherence, only pairs of stories written by the same person in which one was judged as \"coherent\" and the other one as \"neutral\" are chosen. Can you confirm that this is the case? So perhaps your claim is justified for your \"Experiment 1\". However my understanding is that in experiment 2 where you compare \"original\" vs. \"right\" or \"original\" vs. \"wrong\", we do not have the same writers. So I am not convinced lines 370-373 are correct.  (2) A lot in the paper is simply stated without any justifications. For instance how are the \"five frequent\" POS and words chosen? Are they the most frequent words/POS? (Also theses tables are puzzling: why two bars in the legend for each category?). Why character *4*-grams? Did you tune that on the development set? If these were not the most frequent features, but some that you chose among frequent POS and words, you need to justify this choice and especially link the choice to \"style\". How are these features reflecting \"style\"?  (3) I don't understand how the section \"Design of NLP tasks\" connects to the rest of the paper, and to your results. But perhaps this is because I am lost in what \"training\" and \"test\" sets refer to here.  (4) It is difficult to understand how your model differs from previous work. How do we reconcile lines 217-219 (\"These results suggest that real understanding of text is required in order to solve the task\") with your approach?  (5) The terminology of \"right\" and \"wrong\" endings is coming from Mostafazadeh et al., but this is a very bad choice of terms. What exactly does a \"right\" or \"wrong\" ending mean (\"right\" as in \"coherent\" or \"right\" as in \"morally good\")? I took a quick look, but couldn't find the exact prompts given to the Turkers. I think this needs to be clarified: as it is, the first paragraph of your section \"Story cloze task\" (lines 159-177) is not understandable.  Other questions/comments:  Table 1. Why does the \"original\" story differ from the coherent and incoherent one? From your description of the corpus, it seems that one Turker saw the first 4 sentences of the original story and was then ask to write one sentence ending the story in a \"right\" way (or did they ask to provide a \"coherent\" ending?) and one sentence ending the story in a \"wrong\" way (or did they ask to provide an \"incoherent\" ending)? I don't find the last sentence of the \"incoherent\" story that incoherent... If the only shoes that Kathy finds great are $300, I can see how Kathy doesn't like buying shoes ;-) This led me to wonder how many Turkers judged the coherence of the story/ending and how variable the judgements were. What criterion was used to judge a story coherent or incoherent? Also does one Turker judge the coherence of both the \"right\" and \"wrong\" endings, making it a relative judgement? Or was this an absolute judgement? This would have huge implications on the ratings.  Lines 380-383: What does \"We randomly sample 5 original sets\" mean?  Line 398: \"Virtually all sentences\"? Can you quantify this?  Table 5: Could we see the weights of the features?   Line 614: \"compared to ending an existing task\": the Turkers are not ending a \"task\"  Line 684-686: \"made sure each pair of endings was written by the same author\" -> this is true for the \"right\"/\"wrong\" pairs, but not for the \"original\"-\"new\" pairs, according to your description.  Line 694: \"shorter text spans\": text about what? This is unclear.  Lines 873-875: where is this published?",
            "output": [
                "en"
            ]
        },
        {
            "input": "Conclusiones: \"... cambiar el paradigma del actual desarrollo de aplicaciones enfocadas en esta área, la pregunta a realizar ya no debe ser ¿Cómo se realizará el plegado de la proteína?, sino el cómo se puede mejorar la forma de aplicar las reglas de Meckler. ...\"  LAS CONCLUSIONES NO SON CLARAS. HAY MUCHO TRABAJO A FUTURO. POR EJEMPLO: \"...queda abierta la interrogante acerca de cómo se puede mejorar la simulación de tal manera que la secuencia de aminoácidos...\"  DEBEN REDACTAR LAS CONCLUSIONES BASADAS EN LOS RESULTADOS EXPERIMENTALES Y LA TEORÍA USADA.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Muestra una mezcla de tecnologías web para su desarrollo e implementa una solución nativa.  No muestra cuanto ancho de banda se consume en las troncales por la aplicación cuando están las cámaras funcionando todas juntas. Necesita mostrar más resultados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper presents a method to learn both a model and inference procedure at the same time with recurrent neural networks in the context of inverse problems. The proposed method is interesting and results are quite good. The paper is also nicely presented.   I would be happy to see some discussion about what the network learns in practice about natural images in the case of denoising. What are the filters like? Is it particularly sensitive to different structures in images? edges? Also, what is the state in the recurrent unit used for? when are the gates open etc.  Nevertheless, I think this is nice work which should be accepted.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This work proposes to compute embeddings of symbolic expressions (e.g., boolean expressions, or polynomials) such that semantically equivalent expressions are near each other in the embedded space.  The proposed model uses recursive neural networks where the architecture is made to match that of the parse tree of a given symbolic expression.  To train the model parameters, the authors create a dataset of expressions where semantic equivalence relationships are known and minimize a loss function so that equivalent expressions are closer to each other than non-equivalent expressions via a max-margin loss function.  The authors also use a “subexpression forcing” mechanism which, if I understand it correctly, encourages the embeddings to respect some kind of compositionality.  Results are shown on a few symbolic expression datasets created by the authors and the proposed method is demonstrated to outperform baselines pretty convincingly.  I especially like the PCA visualization where the action of negating an expression is shown to correspond roughly to negating the embedding in its vector space — it is a lot like the man - woman + queen = king type embeddings that we see in the word2vec and glove style papers.    The weakest part of the paper is probably that the setting seems somewhat contrived — I can’t really think of a real setting where it is easy to have a training set of known semantic equivalences, but still more worth it to use a neural network to do predictions.   The authors have also punted on dealing with variable names, assuming that distinct variables refer to different entities in the domain.  This is understandable, as variable names add a whole new layer of complexity on an already difficult problem, but also seems high limiting.  For example, the proposed methods would not be useable in an “equation search engine” unless we were able to accurately canonicalize variable names in some way.  Other miscellaneous points: * Regarding problem hardness, I believe that the problem of determining if two expressions are equivalent is actually undecidable — see the “word problem for Thue systems”.  Related to this, I was not able to figure out how the authors determine ground truth equivalence in their training sets.  They say that expressions are simplified into a canonical form and grouped, but this seems to not be possible in general, so one question is — is it possible that equivalent expressions in the training data would have been mapped to different canonical forms?  Would it have been easier/possible to construct and compare truth tables? * The “COMBINE” operation uses what the authors describe as a residual-like connection.  Looking at the equations, the reason why this is not actually a residual connection is because of the weight matrix that is multiplied by the lower level l_0 features.  A true residual connection would have passed the features through unchanged (identity connection) and would have also been better at fighting gradient explosion…. so is there a reason why this was used rather than an identity connection? * In table 3, the first tf-idf entry: a + (c+a) * c seems equivalent to a + (c * (a+c)) * Vertical spacing between Figure 4 caption and body of text is very small and looks like the caption continues into the body of the text.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposed a dynamic coattention network for the question answering task with long contextual documents.  The model is able to encode co-dependent representations of the question and the document, and a dynamic decoder iteratively pointing the potential answer spans to locate the final answer.   Overall, this is a well-written paper.  Although the model is a bit complicated (coattention encoder, iterative dynamic pointering decoder and highway maxout network), the intuitions behind and the details of the model are clearly presented.  Also the performance on the SQuAD dataset is good.  I would recommend this paper to be accepted.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El paper presenta una investigación enfocada a evaluar el impacto de los sistemas instrumentados de seguridad en los procesos a los cuales se aplican.  La cantidad de referencias es pobre, considerando la naturaleza de la investigación. Es especialmente escaso el uso de referencias en la sección introductoria. También, la introducción no deja muy claro el aporte de la investigación ni la metodología utilizada, ambas cosas deberían ser parte de esta sección de manera concisa.  Se debe evitar el uso de primera persona plural en la redacción (ej., 3er párrafo de la sección \"análisis teórico\").  Colocar las referencias dentro del párrafo, no fuera (ej., párrafo \"Medidas de seguridad\", \"... iniciado. [7]\", debería ser \"... iniciado [7].\". Esto se repite en otras partes del documento.  Error de escritura en primer párrafo de 3era página.  Formato de referencias inconsistente (segundo párrafo en \"Riesgo remanente aceptado\"). También mal uso de puntuación (Primer párrafo de 4ta página).  Sobre los resultados, estos no son claros. La pregunta de investigación está mal o ambiguamente planteada. En base a esto, es imposible entender el aporte o el enfoque planteado. Esto sumado al escaso marco teórico entregado, no se justifica la relevancia de la investigación presentada.  Las conclusiones no hacen referencia a ningún aspecto de investigación ni trabajo futuro.  Se debe revisar el formato de las referencias.  Por todos los motivos expuestos anteriormente, el trabajo no tiene la calidad suficiente para ser aceptado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El tema es de vital actualidad, factible de realizar (se dan evidencias de aquello) y se recrea al mismo tiempo la ejecución de la \"tercera misión\" a través de la propuesta. Me parece meritoria e interesante el efecto multiplicador que esto ha tenido, al incorporar los actores a la propuesta.  En específico me refiero a las empresas o pymes, las universidades e institutos (alumnos), INDAP, en abordar problemas reales, con \"personas\" reales.  La propuesta logra presentar una dinámica, en este caso, de la sociedad agrícola, que apalanque la gestión del conocimiento. Una derivada interesante de la propuesta es que ha servido para identificar las oportunidades que existen en la Región y su entorno, a la luz de las acciones que se están ejerciendo con el fin de obtener aún más de ellas, en lo específico me refiero a la Universidad, entidades gubernamentales y la sociedad.  Carencia de referencias internacionales de los estándares (si es que existen?) que se desean alcanzar en éste ámbito. Se compromete a mejorar la \"rentabilidad de los pequeños productores\", pero no se dice cómo, ya que con sólo la incorporación de la tecnología no es suficiente.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presentado a Infonor - Chile, cumple con las expectativas siguientes: 1. Realiza una acertada discusión bibliográfica 2. Incorpora un algoritmo híbrido de búsqueda novedosa 3. Los resultados obtenidos con scheduling con restricciones usando el algoritmo (recursos limitados) muestra resultados alentadores.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Most dialog systems are based on chit-chat models. This paper explores goal-directed conversations, such as those that arise in booking a restaurant. While the methodology is rather thin, this is not the main focus of the paper. The authors provide creative evaluation protocols, and datasets. The reviewers liked the paper, and so does the AC. The paper will make a nice oral, on a topic that is largely explored but opening a direction that is quite novel.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo se titula \"Arquitectura de Software para la Automatización de Reglas de Negocio en la Recepción de Solicitudes de Crédito en Entidades Financieras\". En el resumen se indica que el trabajo tiene como objetivo  proponer un modelo de automatización de reglas de negocio que logre desacoplar la lógica de negocio, sin embargo durante el documento no se hace referencia a ningún modelo. Se presenta una metodología en el apartado con su nombre, pero no queda claro cómo dicha metodología permite generar un modelo de automatización de reglas de negocio. Al artículo le falta una secuencia lógica de apartados que den cuenta de la propuesta explícita citada en el resumen. En el apartado Arquitectura del sistema, se presenta la arquitectura de un sistema y se explican aspectos de la arquitectura. Sin embargo, en dicho apartado tampoco se logra identificar un modelo de automatización de reglas de negocio.  Teniendo en cuenta que al artículo le falta un trabajo fuerte para mejorar la presentación del mismo que permita entender la propuesta que se realiza, sugiero rechazarlo.  A continuación remito algunas observaciones que pueden sevir para mejorar el trabajo:  Si bien, la metodología utilizada está explicada detalladamente por fases, en ninguna de ellas se hace referencia a los resultados logrados en su implementación en el caso del trabajo que se expone, es decir aplicado en un entorno de entidades financieras.  En el apartado de arquitectura del sistema, se presenta la figura 5 y la figura 6 pero no se explican ni se contextualizan dentro del documento. Esto genera confusión. En este apartado no se identifica la aplicación de la metodología expuesta en el apartado anterior, con relación a la arquitectura generada. Debería indicarse claramente cómo se logró la arquitectura a partir de la metodología seleccionada y explicada en el apartado Metodología.  En la introducción que queda clara cuál es la propuesta del trabajo presentado. Debe estructurarse un párrafo donde se incluya una definición del objetivo el trabajo y la propuesta de solución que se hace teniendo en cuenta el título del trabajo.  Se deben corregir algunos errores de redacción en como:  - En el resumen...Para lo cual la se propone....? - En la introducción... no de los retos principales de la ingeniería de software es generar ...? - En la página 3 la fase Un término posee un significado para el negocio que debe ser comprendido y compartido, está repetida dos veces. - En la página 4 la palabra valido, lleva acento y en el último párrafo el acento está por fuera de la palabra esta´. - Al final de la página 5 el título queda divido (viuda). - Se sugiere mejorar la redacción del párrafo... Se ha observado la vulnerabilidad arquitectónica de los sistemas de software en la prestación en los servicios que presta respecto a las libranzas... -Las figuras no están citadas en el texto, solamente se indica siguiente figura, lo que constituye problemas tanto de forma como edición del artículo. Deben citarse las figuras en el texto, con el número correspondiente en el título de la figura. - La figura 3 no se entiende. El texto es muy pequeño y no se logra identificar el modelo de proceso de negocio al que se hace referencia en el párrafo inmediatamente anterior. - El último párrafo de la página 6 no se entiende y se habla en primera persona. Debería corregirse la redacción. - En el apartado Metodología, se hace referencia a un proyecto que no se ha descrito antes. Sería conveniente explicar de qué se trata el proyecto al que se hace referencia. En este apartado no es claro el tipo de metodología a la que se hace referencia. Se puede tratar de una metodología de investigación o una metodología de desarrollo de arquitectura.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta un sistema detección y seguimiento de ojos para ayuda al análisis clínico psicológico.  Comentarios generales.  En el tema que aborda el artículo se ha publicado bastante. Sin embargo, no se citan otros trabajos relevantes directamente relacionados, que nos ayuden a ubicar la propuesta dentro de la literatura. Un buen punto de inicio puede ser el número especial de la revista: Computer Vision and Image Understanding Volume 98 ,  Issue 1  (April 2005) Special issue on eye detection and tracking  La parte experimental del trabajo es muy breve. Es importante describir detalladamente los datos empleados en la experimentación, cuáles son las condiciones de captura, e incluso hacerlos públicos para que otros investigadores puedan comparar con ellos. En cuanto a los resultados, no basta con dar un porcentaje de aciertos. Hay que analizar los falsos positivos y negativos y relacionarlos con la técnica utilizada y, si es posible, con los futuros temas a investigar.  Otros comentarios:  En el artículo se menciona que se ha considerado la velocidad de respuesta, pero no se proporcionan cifras.  En la introducción se cita la referencia [3] en la revisión relacionada sobre los aspectos psicológicos del artículo, cuando esta referencia parece ser de morfología matemática.  Algunas referencias están incompletas: + En la 1 y 2 falta la editorial + En la 3 la conferencia/revista. + En la 5 el volumen, número y páginas  El artículo aborda un tema de gran interés técnico y práctico.  Se describe un sistema que parece no estar completamente desarrollado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo trata sobre la colaboración en la creación de contenido a través de redes sociales. El articulo está bien estructurado y con algunos detalles de redacción. La bibliografía no cumple el formato exigido por el congreso.  Con respecto al tema del artículo, inicialmente se tuvo la duda sobre si era pertinente el artículo para el congreso, ya que era un experimento sobre el comportamiento social de unos individuos a través de redes sociales. Posteriormente al revisar el experimento, se puede apreciar que la pertinencia  está en la perspectiva de educación en ingeniería informática. Por lo anterior recomiendo que en el artículo se modifique el resumen mencionando el alcance del experimento para que el lector, desde un principio, tenga mayor conocimiento sobre el artículo. Además, para mayor pertinencia con el congreso, se recomienda dar mayor énfasis en la colaboración para el desarrollo de algunas tareas propias de la disciplina, tales como el análisis y/o diseño de sistemas. Por último el artículo es novedoso en la manera de cómo realizar algunas tareas a través de redes sociales.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This work combines a LDA-type topic model with a RNN and models this by having an additive effect on the predictive distribution via the topic parameters. A variational auto-encoder is used to infer the topic distribution for a given piece of text and the RNN is trained as a RNNLM. The last hidden state of the RNNLM and the topic parameters are then concatenated to use as a feature representation.  The paper is well written and easy to understand. Using the topic as an additive effect on the vocabulary allows for easy inference but intuitively I would expect the topic to affect the dynamics too, e.g. the state of the RNN. The results on using this model as a feature extractor for IMDB are quite strong. Is the RNN fine-tuned on the labelled IMDB data? However, the results for PTB are weaker. From the original paper, an ensemble of 2 LSTMs is able to match the topicRNN score. This method of jointly modelling topics and a language model seems effective and relatively easy to implement.  Finally, the IMDB result is no longer state of the art since this result appeared in May (Miyato et al., Adversarial Training Methods for Semi-Supervised Text Classification).  Some questions: How important is the stop word modelling? What do the results look like if l_t = 0.5 for all t?  It seems surprising that the RNN was more effective than the LSTM. Was gradient clipping tried in the topicLSTM case? Do GRUs also fail to work?  It is also unfortunate that the model requires a stop-word list. Is the link in footnote 4 the one that is used in the experiments?  Does factoring out the topics in this way allow the RNN to scale better with more neurons? How reasonable does the topic distribution look for individual documents? How peaked do they tend to be? Can you show some examples of the inferred distribution? The topics look odd for IMDB with the top word of two of the topics being the same: 'campbell'. It would be interesting to compare these topics with those inferred by LDA on the same datasets.  Minor comments: Below figure 2: GHz -> GB \\Gamma is not defined.",
            "output": [
                "en"
            ]
        },
        {
            "input": "La novedad del tema a tratar hace del artículo una investigación interesante. Tiene una muy buena presentación y es fácil de leer, lo cual da un aspecto llamativo al tema. A pesar de ser un tema que incluye dos disciplinas muy distintas, han logrado sincronizar adecuadamente los conceptos de tal forma que la investigación es importante y aporta conocimiento desde la parte inicial del trabajo realizado, hasta las propias conclusiones Se recomienda a los autores seguir con el trabajo a fin de acabar otros aspectos relacionados con la salud pública.    Recomendaciones: Es indispensable mejorar la calidad de las figuras, existen algunas que es imposible visualizar, como es el caso de Figura 4, Figura 6, Figura 7 y Figura 8.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper presents a new environment, called Retro Learning Environment (RLE), for reinforcement learning. The authors focus on Super Nintendo but claim that the interface supports many others (including ALE). Benchmark results are given for standard algorithms in 5 new Super Nintendo games, and some results using a new \"rivalry metric\".  These environments (or, more generally, standardized evaluation methods like public data sets, competitions, etc.) have a long history of improving the quality of AI and machine learning research. One example in the past few years was the Atari Learning Environment (ALE) which has now turned into a standard benchmark for comparison of algorithms and results. In this sense, the RLE could be a worthy contribution to the field by encouraging new challenging domains for research.  That said, the main focus of this paper is presenting this new framework and showcasing the importance of new challenging domains. The results of experiments themselves are for existing algorithms. There are some new results that show reward shaping and policy shaping (having a bias toward going right in Super Mario) help during learning. And, yes, domain knowledge helps, but this is obvious. The rivalry training is an interesting idea, when training against a different opponent, the learner overfits to that opponent and forgets to play against the in-game AI; but then oddly, it gets evaluated on how well it does against the in-game AI!   Also the part of the paper that describes the scientific results (especially the rivalry training) is less polished, so this is disappointing. In the end, I'm not very excited about this paper.  I was hoping for a more significant scientific contribution to accompany in this new environment. It's not clear if this is necessary for publication, but also it's not clear that ICLR is the right venue for this work due to the contribution being mainly about the new code (for example, mloss.org could be a better 'venue', JMLR has an associated journal track for accompanying papers:",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:  Detailed guidelines and explicit illustrations.  - Weaknesses:  The document-independent crowdsourcing annotation is unreliable.   - General Discussion:  This work creates a new benchmark corpus for concept-map-based MDS. It is well organized and written clearly. The supplement materials are sufficient. I have two questions here. 1)              Is it necessary to treat concept map extraction as a separate task? On the one hand, many generic summarization systems build a similar knowledge graph and then generate summaries accordingly. On the other hand, with the increase of the node number, the concept map becomes growing hard to distinguish. Thus, the general summaries should be more readable. 2)              How can you determine the importance of a concept independent of the documents? The definition of summarization is to reserve the main concepts of documents. Therefore, the importance of a concept highly depends on the documents. For example, in the given topic of coal mining accidents, assume there are two concepts: A) an instance of coal mining accidents and B) a cause of coal mining accidents. Then, if the document describes a series of coal mining accidents, A is more important than B. In comparison, if the document explores why coal mining accidents happen, B is more significant than A. Therefore, just given the topic and two concepts A&B, it is impossible to judge their relative importance.  I appreciate the great effort spent by authors to build this dataset. However, this dataset is more like a knowledge graph based on common sense rather than summary.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper presents a dialogue agent where the belief tracker and the dialogue manager are jointly optimised using the reinforce algorithm. It learns from interaction with a user simulator. There are two training phases. The first is an imitation learning phase where the system is initialised using supervising learning from a rule-based model. Then there is a reinforcement learning phase where the system has jointly been optimised using the RL objective.  - Strengths: This paper presents a framework where a differentiable access to the KB is integrated in the joint optimisation. This is the biggest contribution of the paper.   - Weaknesses: Firstly, this is not a truly end-to-end system considering the response generation was handcrafted rather than learnt. Also, their E2E model actually overfits to the simulator and performs poorly in human evaluation. This begs the question whether the authors are actually selling the idea of E2E learning or the soft-KB access. The soft-KB access actually brings consistent improvement, however the idea of end-to-end learning not so much. The authors tried to explain the merits of E2E in Figure 5 but I also fail to see the difference. In addition, the authors didn't motivate the reason for using the reinforce algorithm which is known to suffer from high variance problem. They didn't attempt to improve it by using a baseline or perhaps considering the natural actor-critic algorithm which is known to perform better.  - General Discussion: Apart from the mentioned weaknesses, I think the experiments are solid and this is generally an acceptable paper. However, if they crystallised the paper around the idea which actually improves the performance (the soft KB access) but not the idea of E2E learning the paper would be better.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper describes an MT training data selection approach that scores and ranks general-domain sentences using a CNN classifier. Comparison to prior work using continuous or n-gram based language models is well done, even though  it is not clear of the paper also compared against bilingual data selection (e.g. sum of difference of cross-entropies). The motivation to use a CNN instead of an RNN/LSTM was first unclear to me, but it is a strength of the paper to argue that certain sections of a text/sentence are more important than others and this is achieved by a CNN. However, the paper does not experimentally show whether a BOW or SEQ (or the combination of both( representation is more important and why. The textual description of the CNN (one-hot or semi-supervised using pre-trained embeddings)  is clear, detailed, and points out the important aspects. However, a picture of the layers showing how inputs are combined would be worth a thousand words.  The paper is overall well written, but some parentheses for citations are not necessary (\\citet vs. \\citep) (e.g line 385).  Experiments and evaluation support the claims of the paper, but I am a little bit concerned about the method of determining the number of selected in-domain sentences (line 443) based on a separate validation set: - What validation data is used here? It is also not clear on what data hyperparameters of the CNN models are chosen. How sensitive are the models to this? - Table 2 should really compare scores of different approaches with the same number of sentences selected. As Figure 1 shows, the approach of the paper still seems to outperform the baselines in this case.   Other comments: - I would be interested in an experiment that compares the technique of the paper against baselines when more in-domain data is available, not just the development set. - The results or discussion section could feature some example sentences selected by the different methods to support the claims made in section 5.4. - In regards to the argument of abstracting away from surface forms in 5.4: Another baseline to compare against could have been the work of Axelrod, 2015, who replace some words with POS tags to reduce LM data sparsity to see whether the word2vec embeddings provide an additional advantage over this. - Using the sum of source and target classification scores is very similar to source & target Lewis-Moore LM data selection: sum of difference of cross-entropies. A reference to this work around line 435 would be reasonable.  Finally, I wonder if you could learn weights for the sum of both source & target classification scores by extending the CNN model to the bilingual/parallel setting.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo propone, según el artículo, una plataforma computacional relacionada con información académica del Propedeútico de la USACH. Posteriormente, en \"III. Desarrollo de la Propuesta\" se plantea una metodología. No queda claro si es plataforma computacional, si es una metodología, si es una sistematización de información...  El Abstract debe ser mejorado, al igual que las Conclusiones.  El artículo es breve, podría haber presentado mejor la propuesta si se hubiese extendido un poco más (la propuesta se presenta en menos de 2 hojas).  Otras observaciones: - Cambiar \"Palabras Reservadas\" por \"Palabras Clave\" - En Introducción, las páginas web mencionadas deben ser declaradas en Referencias. - Se confunde las Referencias con la identificación de los títulos de sub-secciones. Por ejemplo: \"[1] Decisión Multicriterio\" (no es la Referencia 1). - En página 3, cambiar \"organziados\" por \"organizados\". - En página 5, dice \"Tabla 2\", debe decir \"Tabla 3\".",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper considers the energy-based model interpretation of GAN, where the discriminator is an unnormalized model for the likelihood of a generative model p(x|theta) and the generator is a directed model that approximates this distribution. The generator is used to draw approximate negative phase samples that are used in stochastic maximum likelihood / contrastive divergence learning of the EBM / discriminator.  The main idea in the paper is to fit the generator by following the Stein variational gradient. In practice this gradient consists of the usual gradient provided by the discriminator with an added term that provides a repulsive force between the sampled data points to increase sample diversity.  The idea of using a kernel to push apart the sampled points is interesting, and will work in low dimensions, but it is hard to see how it can work in full scale images. For high dimensional samples x, the proposed kernel is unlikely to provide a useful distance measure between points. There are no convincing experiments in the paper that show otherwise. Specifically:  - There is no experiment that compares between standard GAN and GAN + repulsion, using the same architecture. (please address this in the rebuttal) - If the Stein variational idea is taken literally, the right thing to do would be to fully optimize the generator at every step, and then taking a single optimization step on the discriminator. Instead, each is updated in turn, and the learning rates of both steps are adjusted to keep the two \"in line\". - The kernel used to fit the generator is defined in the auto-encoder space of the discriminator, and thus depends on the discriminator parameters. The objective that is used to fit the generator thus changes at every step, and the procedure can no longer be interpreted as stochastic gradient descent with respect to any single well defined objective.  The authors obtain good results: The generated images clearly look better than those generated by DCGAN. However, their approach has a number of changes compared to DCGAN, so it is not clear where the improvement comes from. In addition, by now the DCGAN is no longer a very strong baseline, as various other techniques have been proposed.  Note: The use of phi for both the \"particle gradient direction\" and energy function is confusing",
            "output": [
                "en"
            ]
        },
        {
            "input": "El paper muestra una aplicación práctica desarrollada con realidad aumentada aplicada a entregar información turística en espacios abiertos El trabajo permitirá dar a conocer la tecnología a nivel nacional y sus potencialidades, por lo que se considera un aporte. Sin embargo, el paper carece de un estudio comparativo con otros trabajos similares aplicando esta tecnología a este mismo objetivo, por lo que no se logra obtener una idea del grado de originalidad del mismo, ni da la posibilidad de contrastar algunas de las limitaciones del mismo que el autor menciona al final del paper con trabajos ya desarrollados anteriormente.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Summary:   The paper introduces a new dataset for a sarcasm interpretation task and a system (called Sarcasm SIGN) based on machine translation framework Moses. The new dataset was collected from 3000 sarcastic tweets (with hashtag `#sarcasm) and 5 interpretations for each from humans. The Sarcasm SIGN is built based on Moses by replacing sentimental words by their corresponding clusters on the source side (sarcasm) and then de-cluster their translations on the target side (non-sarcasm). Sarcasm SIGN performs on par with Moses on the MT evaluation metrics, but outperforms Moses in terms of fluency and adequacy.   - Strengths:  the paper is well written  the dataset is collected in a proper manner  the experiments are carefully done and the analysis is sound.  - Weaknesses:  lack statistics of the datsets (e.g. average length, vocabulary size)  the baseline (Moses) is not proper because of the small size of the dataset  the assumption \"sarcastic tweets often differ from their non sarcastic interpretations in as little as one sentiment word\" is not supported by the data.   - General Discussion: This discussion gives more details about the weaknesses of the paper.   Half of the paper is about the new dataset for sarcasm interpretation. However, the paper doesn't show important information about the dataset such as average length, vocabulary size. More importantly, the paper doesn't show any statistical evidence to support their method of focusing on sentimental words.   Because the dataset is small (only 3000 tweets), I guess that many words are rare. Therefore, Moses alone is not a proper baseline. A proper baseline should be a MT system that can handle rare words very well. In fact, using clustering and declustering (as in Sarcasm SIGN) is a way to handle rare words.  Sarcasm SIGN is built based on the assumption that \"sarcastic tweets often differ from their non sarcastic interpretations in as little as one sentiment word\". Table 1 however strongly disagrees with this assumption: the human interpretations are often different from the tweets at not only sentimental words. I thus strongly suggest the authors to give statistical evidence from the dataset that supports their assumption. Otherwise, the whole idea of Sarcasm SIGN is just a hack.  --------------------------------------------------------------  I have read the authors' response. I don't change my decision because of the following reasons:   - the authors wrote that \"the Fiverr workers might not take this strategy\": to me it is not the spirit of corpus-based NLP. A model must be built to fit given data, not that the data must follow some assumption that the model is built on.  - the authors wrote that \"the BLEU scores of Moses and SIGN are above 60, which is generally considered decent in the MT literature\": to me the number 60 doesn't  show anything at all because the sentences in the dataset are very short. And that, if we look at table 6, %changed of Moses is only 42%, meaning that even more than half of the time translation is simply copying, the BLUE score is more than 60.  - \"While higher scores might be achieved with MT systems that explicitly address rare words, these systems don't focus on sentiment words\": it's true, but I was wondering whether sentiment words are rare in the corpus. If they are, those MT systems should obviously handle them (in addition to other rare words).",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper presents a new dataset with annotations of products coming from online cybercrime forums. The paper is clear and well-written and the experiments are good. Every hypothesis is tested and compared to each other.  However, I do have some concerns about the paper:  1. The authors took the liberty to change the font size and the line spacing of the abstract, enabling them to have a longer abstract and to fit the content into the 8 pages requirement.  2. I don't think this paper fits the tagging, chunking, parsing area, as it is more an information extraction problem.  3. I have difficulties to see why some annotations such as sombody in Fig. 1 are related to a product.  4. The basic results are very basic indeed and - with all the tools available nowadays in NLP -, I am sure that it would have been possible to have more elaborate baselines without too much extra work.  5. Domain adaptation experiments corroborate what we already know about user-generated data where two forums on video games, e.g., may have different types of users (age, gender, etc.) leading to very different texts. So this does not give new highlights on this specific problem.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes an approach for multi-lingual named entity recognition using features from Wikipedia. By relying on a cross-lingual Wikifier, it identifies English Wikipedia articles for phrases in a target language and uses features based on the wikipedia entry. Experiments show that this new feature helps not only in the monolingual case, but also in the more interesting direct transfer setting, where the English model is tested on a target language.  I liked this paper. It proposes a new feature for named entity recognition and conducts a fairly thorough set of experiments to show the utility of the feature. The analysis on low resource and the non-latin languages are particularly interesting.  But what about named entities that are not on Wikipedia? In addition to the results in the paper, it would be interesting to see results on how these entities are affected by the proposed method.   The proposed method is strongly dependent on the success of the cross-lingual wikifier. With this additional step in the pipeline, how often do we get errors in the prediction because of errors in the wikifier?  Given the poor performance of direct transfer on Tamil and Bengali when lexical features are added, I wonder if it is possible to regularize the various feature classes differently, so that the model does not become over-reliant on the lexical features.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: Nicely written and understandable. Clearly organized. Targeted answering of research questions, based on  different experiments.  - Weaknesses: Minimal novelty. The \"first sentence\" heuristic has been in the summarization literature for many years. This work essentially applies this heuristic (evolved) in the keyword extraction setting. This is NOT to say that the work is trivial: it is just not really novel.  Lack of state-of-the-art/very recent methods. The experiment on the system evaluation vs state-of-the-art systems simply uses strong baselines. Even though the experiment answers the question \"does it perform better than baselines?\", I am not confident it illustrates that the system performs better than the current state-of-the-art. This somewhat reduces the value of the paper.  - General Discussion: Overall the paper is good and I propose that it be published and presented.   On the other hand, I would propose that the authors position themselves (and the system performance) with respect to: Martinez‐Romo, Juan, Lourdes Araujo, and Andres Duque Fernandez. \"SemGraph: Extracting keyphrases following a novel semantic graph‐based approach.\" Journal of the Association for Information Science and Technology 67.1 (2016): 71-82. (with which the work holds remarkable resemblance in some points)  Le, Tho Thi Ngoc, Minh Le Nguyen, and Akira Shimazu. \"Unsupervised Keyphrase Extraction: Introducing New Kinds of Words to Keyphrases.\" Australasian Joint Conference on Artificial Intelligence. Springer International Publishing, 2016.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper describes interesting and ambitious work: the automated conversion of Universal Dependency grammar structures into [what the paper calls] semantic logical form representations.  In essence, each UD construct is assigned a target construction in logical form, and a procedure is defined to effect the conversion, working ‘inside-out’ using an intermediate form to ensure proper nesting of substructures into encapsulating ones.  Two evaluations are carried out: comparing the results to gold-standard lambda structures and measuring the effectiveness of the resulting lambda expressions in actually delivering the answers to questions from two QA sets.    It is impossible to describe all this adequately in the space provided.  The authors have taken some care to cover all principal parts, but there are still many missing details.  I would love to see a longer version of the paper!  Particularly the QA results are short-changed; it would have been nice to learn which types of question are not handled, and which are not answered correctly, and why not.  This information would have been useful to gaining better insight into the limitations of the logical form representations.    That leads to my main concern/objection.  This logical form representation is not in fact a ‘real’ semantic one.                          It is, essentially, a rather close rewrite of the dependency structure of the input, with some (good) steps toward ‘semanticization’, including the insertion of lambda operators, the explicit inclusion of dropped arguments (via the enhancement operation), and the introduction of appropriate types/units for such constructions as eventive adjectives and nouns like “running horse” and “president in 2009”.  But many (even simple) aspects of semantic are either not present (at least, not in the paper) and/or simply wrong.  Missing: quantification (as in “every” or “all”); numbers (as in “20” or “just over 1000”); various forms of reference (as in “he”, “that man”, “what I said before”); negation and modals, which change the semantics in interesting ways; inter-event relationships (as in the subevent relationship between the events in “the vacation was nice, but traveling was a pain”; etc. etc.  To add them one can easily cheat, by treating these items as if they were just unusual words and defining obvious and simple lambda formulas for them.  But they in fact require specific treatment; for example, a number requires the creation of a separate set object in the representation, with its own canonical variable (allowing later text to refer to “one of them” and bind the variable properly).  For another example, Person A’s model of an event may differ from Person B’s, so one needs two representation symbols for the event, plus a coupling and mapping between them.  For another example, one has to be able to handle time, even if simply by temporally indexing events and states.  None of this is here, and it is not immediately obvious how this would be added.  In some cases, as DRT shows, quantifier and referential scoping is not trivial.    It is easy to point to missing things, and unfair to the paper in some sense; you can’t be expected to do it all.  But you cannot be allowed to make obvious errors.  Very disturbing is the assignment of event relations strictly in parallel with the verb’s (or noun’s) syntactic roles.  No-one can claim seriously that “he broke the window” and “the window broke” has “he” and “the window” filling the same semantic role for “break”.  That’s simply not correct, and one cannot dismiss the problem, as the paper does, to some nebulous subsequent semantic processing.                          This really needs adequate treatment, even in this paper.  This is to my mind the principal shortcoming of this work; for me this is the make-or-break point as to whether I would fight to have the paper accepted in the conference.  (I would have been far happier if the authors had simply acknowledged that this aspect is wrong and will be worked on in future, with a sketch saying how: perhaps by reference to FrameNet and semantic filler requirements.)                            Independent of the representation, the notation conversion procedure is reasonably clear.  I like the facts that it is rather cleaner and simpler than its predecessor (based on Stanford dependencies), and also that the authors have the courage of submitting non-neural work to the ACL in these days of unbridled and giddy enthusiasm for anything neural.",
            "output": [
                "en"
            ]
        },
        {
            "input": "En este trabajo se realiza una propuesta exploratoria sobre un perfil de adecuación de técnicas de educción de requisitos de software. El trabajo es una extensión de un trabajo previo.  Se recomienda mejorar algunos aspectos de este manuscrito como son: -Describir a más detalle el trabajo previo en el que se basa este escrito y mencionar las diferencias y contenido nuevo. -Consistencia entre los términos requisitos y requerimientos, en la pág. 3 se emplea el término requerimientos. -En la medida de lo posible mantener términos en castellano. -Añadir acento en \"solo\" siempre y cuando se refiera a \"únicamente\". -Corregir \"Lo\" por \"Los\" final de pág. 4, después de ref. 15., añadir acento a \"comparara\", en misma pág., corregir \"cuatros\" final pág. 6. -Corregir alineación de texto en primeros párrafos de ambas columnas en pág. 10, el primer párrafo de la segunda columna debería estar en la primera columna.",
            "output": [
                "es"
            ]
        },
        {
            "input": "En este trabajo se realiza una propuesta para la identificación de riesgos relativos al proceso de outsourcing de software, para lo cual se diseña una taxonomía que es aplicada preliminarmente en una organización como forma de validación, aunque sólo en la forma de una encuesta de opinión.  Para robustecer el aporte científico sería ideal contar con una aplicación real que acompañe el proceso de outsourcing de comienzo a fin de modo de poder dimensionar de mejor manera el real aporte y efectividad de la taxonomía propuesta",
            "output": [
                "es"
            ]
        },
        {
            "input": "Very interesting paper. Maybe you could read paper by Gleizes about cooperative agent, self-organization and resolution through emergence … This paper could interest you : Self-adaptive complex systems, Marie-Pierre Gleizes, 2011, EUMAS.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper compares different ways of inducing embeddings for the task of polarity classification. The authors focus on different types of corpora and find that not necessarily the largest corpus provides the most appropriate embeddings for their particular task but it is more effective to consider a corpus (or subcorpus) in which a higher concentration of subjective content can be found. The latter type of data are also referred to as \"task-specific data\". Moreover, the authors compare different embeddings that combine information from \"task-specific\" corpora and generic corpora. A combination outperforms embeddings just drawn from a single corpus. This combination is not only evaluated on English but also on a less resourced language (i.e. Catalan).  - Strengths: The paper addresses an important aspect of sentiment analysis, namely how to appropriately induce embeddings for training supervised classifers for polarity classification. The paper is well-structured and well-written. The major claims made by the authors are sufficiently supported by their experiments.  - Weaknesses: The outcome of the experiments is very predictable. The methods that are employed are very simple and ad-hoc. I found hardly any new idea in that paper. Neither are there any significant lessons that the reader learns about embeddings or sentiment analysis. The main idea (i.e. focusing on more task-specific data for training more accurate embeddings) was already published in the context of named-entity recognition by Joshi et al. (2015). The additions made in this paper are very incremental in nature.  I find some of the experiments inconclusive as (apparently) no statistical signficance testing between different classifiers has been carried out. In Tables 2, 3 and 6, various classifier configurations produce very similar scores. In such cases, only statistical signficance testing can really give a proper indication whether these difference are meaningful. For instance, in Table 3 on the left half reporting results on RT, one may wonder whether there is a significant difference between \"Wikipedia Baseline\" and any of the combinations. Furthermore, one doubts whether there is any signficant difference between the different combinations (i.e. either using \"subj-Wiki\", \"subj-Multiun\" or \"subj-Europarl\") in that table. The improvement by focusing on subjective subsets is plausible in general. However, I wonder whether in real life, in particular, a situation in which resources are sparse this is very helpful. Doing a pre-selection with OpinionFinder is some pre-processing step which will not be possible in most languages other than English. There are no equivalent tools or fine-grained datasets on which such functionality could be learnt. The fact that in the experiments for Catalan, this information is not considered proves that.   Minor details:  - lines 329-334: The discussion of this dataset is confusing. I thought the task is plain polarity classification but the authors here also refer to \"opinion holder\" and \"opinion targets\". If these information are not relevant to the experiments carried out in this paper, then they should not be mentioned here.  - lines 431-437: The variation of \"splicing\" that the authors explain is not very well motivated. First, why do we need this? In how far should this be more effective than simple \"appending\"?  - lines 521-522: How is the subjective information isolated for these configurations? I assume the authors here again employ OpinionFinder? However, there is no explicit mention of this here.  - lines 580-588: The definitions of variables do not properly match the formula (i.e. Equation 3). I do not find n_k in Equation 3.  - lines 689-695: Similar to lines 329-334 it is unclear what precise task is carried out. Do the authors take opinion holders and targets in consideration?  ***AFTER AUTHORS' RESPONSE*** Thank you very much for these clarifying remarks. I do not follow your explanations regarding the incorporation of opinion holders and targets, though.  Overall, I will not change my scores since I think that this work lacks sufficient novelty (the things the authors raised in their response are just insufficient to me). This submission is too incremental in nature.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper presents a method to learn a low-dimensional state representations from raw obervation for multi-task setting. In contrast to classic multi-task learning setting where a joint representation is usually learned by exploring the transferable information among different tasks, the method aims to identify individual task and solve them separately. To this end, the authors extend the learning with robotic priors approach by extending the loss function with additional term for task coherence, i.e., a task only changes representation between training episodes. The method has been evaluated on two tasks, multi-task slot-car racing and mobile navigation to prove its efficacy.  there were several unclear issues:  1. The first question is that if the method is only appealing on the scenario like the slot-car racing, otherwise it should be benchmarked with mutli-task learning. While the author made the argument in the related work, the proposed method is orthogonal to multi-task learning they did admit both explore shared knowledge between tasks. What's the advantage and disadvantage for the proposed method for general mutiple task setting, in particular over the multi-task learning? The reply of the authors was not fully satisfactory. The argument did not support the lack of comparison to multi-task joint-learning. It seems they don't plan to include any comparison neither. I think it's important for the fundamental motivation for the work, without such comparison, the method seems to be purely an alternative to multi-task joint-learning without any(or much) practical advantage.  2.Following up to the previous question, please clarify the results on the mobile navigation scenario. It's not clear how the plot on the right indicates MT-LRP identifies all tasks as the author claimed and and seems very weak to support the method, in particular compared to the multi-slot car-racing driving experiment, there is too little results to make sound argument (almost no comparison to alternative methods, i.e. no baseline method, is that true for the problem). The explanation of the authors did provide more details and more explicit information.   3. The proposed gated neural network architecture seems to be a soft gated structure(correct me if I am wrong), a possible baseline would be a hard gated unit, how would this affect the conclusion. This is particularly interesting as the authors reflect on the constraint that the representation should stay consistent during the training. The author simply stated again what they did for the modeling without counter the comparison to hard-gating, but it's probably less an issue compared to Question 1.  In summary, while there are remaining concerns about lacking comparisons, the is a weak tendency towards accepting the submission.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes a novel approach ParMAC, a parallel and distributed framework of MAC (the Method of Auxiliary Coordinates) to learn nested and non-convex models which is based on the composition of multiple processing layers (i.e., deep nets). The basic idea of MAC to optimise the nested objective function, which is traditionally learned using methods based on the chain-rule gradients but inconvenient and is hard to parallelise, is to break nested functional relationships judiciously by introducing new variables ( the auxiliary coordinates) as equality constraints, and then to optimise a penalised function using alternating optimisation over the original parameters (W step) and over the coordinates (Z step).  The minimisation (W step) updates the parameters by splitting the nested model into independent submodels and training them using existing algorithms, and the coordination (Z step) ensures that corresponding inputs and outputs of submodels eventually match.  In this paper, the basic assumptions of ParMAC are that with large datasets in distributed systems, it is imperative to minimise data movement over the network because of the communication time generally far exceeds the computation time in modern architectures. Thus, the authors propose the ParMAC to translate the parallelism inherent in MAC into a distributed system by data parallelism and model parallelism. They also analyse its parallel speedup and convergence, and demonstrated it with MPI-based implementation to optimise binary autoencoders. The proposed ParMAC is tested on 3 colour image retrieval datasets.   The organization of the paper is well written, and the presentation is clear. My questions are included in the following: - The MAC framework solves the original problem approximately. If people use the sigmoid function to smooth the stepwise function, the naive optimization methods can be easier applied. What is the difference between these two? Or why do we want to use a new approach to solve it? - The authors do not compare their ParMAC model with other distributed approaches for the same nested function optimization problem.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El campo de utilización de la aplicación es muy buena y necesaria, por lo que contribuye a la robótica. En la utilización de visión, falta incorporar tecnologías de visión computacional más actuales que la detección de objetos por flujo óptico, tal vez en este caso sea más factible utilizar tecnología de dos vistas con imágenes sucesivas. Su contenido es bastante claro.  Debe mejorar los siguiente:   Página 1\tResumen y título : Si bien está en inglés, falta escribir el resumen y el título en español o portugués  Página 2\tNo presenta trabajos relacionados, Si bien presenta referencias, no hace una presentación de trabajos relacionados  Página 3\tNo indica fielmente como detecta las botellas plásticas u obstáculos \tEn vez de colocar a la popular Lena, seria más interesante colocar el cómo detecta las botellas plásticas u otros objetos con el detector de borde que utiliza.  Página 3        La referencia [10]\tExisten trabajos de flujo óptico más actuales  al indicado  Página 6\tEn Resultados\tFalta medir el grado efectividad de la recolección de objetos, se debería presentar medidas al respecto.  A que velocidad funciona el limpiador .. Falta mas trabajo en este ítem. Página 6\tRobustez estructural alcanzada \tNo presenta datos que permitan aseverar esto. Página 7\tÍdem párrafo 2\tNo presentan la efectividad de la tecnología de visión computacional ni como  contribuye a evitar obstáculos, detección y recolección.. Es decir, se entiende que lo presentado se puede lograr, pero no presenta datos para concluir aquello.",
            "output": [
                "es"
            ]
        },
        {
            "input": "1.\tLo que se propone es interesante como una aplicación pero no es un trabajo científico. Además ya no es interesante la aplicación de un Datamart desde el punto de vista técnico como es presentado por el autor pues existe mucha documentación y trabajos al respecto. Por este motivo ahora hay que buscar \"otros aspectos (diseño, metodología, etc.)\" que hagan interesante un artículo del área Datamart.  2. Hay errores de diseño, por lo cual lo más probable es que los resultados que se muestran estén erróneos.  3. Debe tener cuidado con la sumarización.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo describe muy bien los SGBD para móviles, así como también algunos motores de BD con tecnología no-relacional conocidas como NoSQL, en un contexto de almacenamiento de datos en la nube o cloud-computing. Realiza una  buena comparación de las características técnicas de algunos gestores de BD en este ámbito (tabla 3). Plantea una metodología, al parecer para definir y realizar un experimento que permita evaluar y comparar BD de este tipo, según lo definido en el título del artículo. Sin embargo,  sólo llega a establecer una comparación simple y cualitativa de componentes y otros aspectos como servicios (tabla 4). No hay evidencias de una comparación cuantitativa y objetiva, a nivel de desempeño y con datos, transacciones y tiempos de procesamiento que permitan realmente sostener, como lo hace sin estas variables, cual BD es más eficiente respecto a otra. El resumen no se condice ni identifica el trabajo completo. Las conclusiones se plantean en base a las características y no a pruebas comparativas de desempeño. En síntesis, es un trabajo desde el punto de vista que sería un aporte si formalizara la metodología y describiera la aplicación cuantitativa de una experimentación que realmente permita comparar los SGBD en un contexto de cloud-computing. Se sugiere complementar con un experimento controlado con datos y registro de transacciones de prueba y medir variables, obtener estadísticas objetivas que permitan evaluar los desempeños de los sistemas de BD móviles y NoSQL, bajo condiciones y parámetros claramente definidos y en las mismas condiciones medio-ambientales (ancho de banda, tas de transacciones, volumen de datos, equipo, etc).",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo cumple con el formato establecido y posee referencias bibliográficas actualizadas.  No se explica claramente qué es JPI, no queda claro el objetivo del artículo. El artículo es una descripción de la aplicación del concepto de JPI, el cual no está bien desarrollado, no queda claro si los autores son quienes proponen esta nueva estrategia o están aplicando una propuesta de otros investigadores. La redacción puede ser mejorada. Se sugiere extender el artículo para que expliquen claramente todos los conceptos, alcances y objetivos de la investigación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Se ajusta al formato solicitado y se puede leer sin dificultad.  El artículo básicamente es un revisión de las herramientas Xpath, Xquery y SQL/XML en Oracle 10g, ilustrando su uso con varios ejemplos.  No hay un aporte, en ya sea nuevo conocimiento o aplicación de la tecnología para resolver un problema real.  No hay resultados de investigación que mostrar ni discutir.",
            "output": [
                "es"
            ]
        },
        {
            "input": "EDIT: Updated score. See additional comment.  I quite like the main idea of the paper, which is based on the observation in Sec. 3.0 - that the authors find many predictable patterns in the independent evolution of weights during neural network training. It is very encouraging that a simple neural network can be used to speed up training by directly predicting weights.  However the technical quality of the current paper leaves much to be desired, and I encourage the authors to do more rigorous analysis of the approach. Here are some concrete suggestions:  - The findings in Section 3.0 which motivate the approach, should be clearly presented in the paper. Presently they are stated as anecdotes.  - A central issue with the paper is that the training of the Introspection network I is completely glossed over. How well did the training work, in terms of training, validation/test losses? How well does it need to work in order to be useful for speeding up training? These are important questions for anyone interested in this approach.  - An additional important issue is that of baselines. Would a simple linear/quadratic model also work instead of a neural network? What about a simple heuristic rule to increase/decrease weights? I think it's important to compare to such baselines to understand the complexity of the weight evolution learned by the neural network.  - I do not think that default tensorflow example hyperparameters should be used, as mentioned by authors on OpenReview. There is no scientific basis for using them. Instead, first hyperparameters which produce good results in a reasonable time should be selected as the baseline, and then added the benefit of the introspection network to speed up training (and reaching a similar result) should be shown.  - The authors state in the discussion on OpenReview that they also tried RNNs as the introspection network but it didn't work with small state size. What does \"didn't work\" mean in this context? Did it underfit? I find it hard to imagine that a large state size would be required for this task. Even if it is, that doesn't rule out evaluation due to memory issues because the RNN can be run on the weights in 'mini-batch' mode. In general, I think other baselines are more important than RNN.  - A question about jump points:  The I is trained on SGD trajectories. While using I to speed up training at several jump points, if the input weights cross previous jump points, then I gets input data from a weight evolution which is not from SGD (it has been altered by I). This seems problematic but doesn't seem to affect your experiments. I feel that this again highlights the importance of the baselines. Perhaps I is doing something extremely simple that is not affected by this issue.  Since the main idea is very interesting, I will be happy to update my score if the above concerns are addressed.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This work presents a novel 3D CNN architecture for climate event detection that combines an unsupervised auto-encoder reconstruction loss with YOLO like bounding box prediction. The approach is trained and evaluated on a large-scale, simulated climate dataset labeled by a costly heuristic approach called TECA.   For the most part, the paper is nicely written (minor comments below) and addresses an important and well motivated problem. The authors provide sufficient model details to allow reproduction (although public code would be preferred). I find the experiments a bit unconvincing (see below) but appreciate the attention to model capacity (via number of parameter) when comparing the 2D and 3D model variants.  I am concerned that the evaluation may be insufficient to assess the effectiveness of this method. An IoU threshold of 0.1 allows for many rather poor detections to count as true positives. If the goal of this work is to count the number of such instances this is defensible, but for localization this seems overly loose.Furthermore, the 3D CNN architecture (which is one of the the core novelties of this work compared to past efforts) does not seem capable of producing variable sized boxes (as noted in the last paragraph of page 7), which I imagine results in poorer performance at higher IoU thresholds (as many of the weather events appear small).  The experiments also feel inconclusive about the effect of temporal modeling and semi-supervision. The temporal component does not seem to matter in the supervised settings (2D 51.45 mAP - 3D 51.00 mAP) but improves somewhat in the semi-supervised case (2D 51.11 mAP - 3D 52.92 mAP). Whereas the additional unlabeled data seems to hurt in the 2D case but improve results for the 3D model. Could the authors provide confidence intervals for these numbers? I would like to see further discussion of these trends especially with respect to the effect of the loss weights (alpha, beta, and gamma).   I also note that it is not clear if both the 2D and 3D models were trained for equivalent time periods (seems like no from last paragraph of page 7). Could a plot of training and validation accuracy for each model be presented for comparison?   Finally, is there any baseline approach the authors could report or compare too? Without one, it is difficult to evaluate the performance of the approach with respect to the difficulty of the problem.  Preliminary Rating: I think this is an interesting paper that is well motivated but feel the experiments as presented do not seem adequate to support any conclusive trends. I would like to see the mAP trends across a wider range of IoU values and further discussion of training procedure, loss weight settings, and reasons for lack of bounding box variability in the 3D model (as stated above).   Clarification: In the paper you say \"While climate models are run on a 3D grid, with the vertical dimension corresponding to 30 levels; we only consider surface quantities (i.e. 2D data) in this study.\" Could you elaborate on what the surface quantities correspond to? Is it the highest cloud level?  Minor notes: \tPlease provide years for Prabhat et al. references rather than a and b. \tFootnote in 4.2 could be inline text with similar space. \t4.3 second paragraph the word table is not capitalized like elsewhere. \t4.3 4th paragraph the word section is not capitalized like elsewhere.  Edit: I appreciate the authors responding to my questions but still feel the relatively poor localization performance at stricter IoU thresholds fails to justify the complexity of the approach. I encourage the authors to continue pursuing this line of research.",
            "output": [
                "en"
            ]
        },
        {
            "input": "A lo largo del artículo se exagera el rol de la automatización de las pruebas dentro de las pruebas de software y en forma más general en el marco de aseguramiento. Un modelo de madurez para la prueba de software necesariamente incluye más aspectos que la automatización. Los casos automatizados siempre van coexistir con casos manuales y evaluaciones realizadas por personas. Como está tratado en el artículo, automatización es un concepto demasiado general, puede abarcar la generación, ejecución, evaluación (por ejemplo: mutación, criterios de cobertura) y validación (problema del oráculo).  Aunque la motivación está claramente expresada en la introducción, hacen falta referencias para fundamentar las afirmaciones realizadas sobre el rol de la prueba y el impacto de la automatización en la misma. Decir que la automatización permite realizar las pruebas más rápido o a menor costo es simplista: esto depende del contexto. Los costos de generar casos de prueba automáticos, la estimación sobre la evaluación futura del software y la caducidad de los casos de prueba, junto con otros factores, deben ser tenidos en cuenta en el modelo de costos para determinar la conveniencia de automatizar cierta parte de la prueba.  La sección dedicada a la prueba de software realiza definiciones generales y recorre la historia de la prueba desde los mainframes. Para un artículo de investigación, sugiero realizar definiciones más específicas relacionadas con el foco del estudio (estudios experimentales sobre técnicas de prueba, automatización, costos de las pruebas, modelos de madurez).  Sería adecuado poner el desarrollo del modelo de madurez luego de presentar el trabajo relacionado. No se describe el proceso para obtener la propuesta de un modelo de madurez para testing.  Se debe vincular el desarrollo del modelo a otros modelos de madurez existentes (por ejemplo el Testing Maturity Model) establecer conexiones con la literatura aceptada de testing o normas (por ejemplo ISO 29119) y en general  con modelos de procesos de software.  No se explicita el string de búsqueda utilizado. No todos los modelos encontrados deben catalogarse como ‘modelos de madurez’. Algunos de los modelos incluidos son claramente modelos más generales, que no se enfocan en el problema de la automatización de las pruebas. Se debería al menos discutir estas diferencias.  No se explican los atributos utilizados en la tabla III, ni la forma de obtener los resultados de nivel de madurez. ¿Qué significa ‘nivel de las opiniones publicadas’? Este concepto resulta ambiguo. Se debe reforzar la descripción de este proceso de investigación ya que resulta clave para obtener el resultado de nivel ‘adolescente’.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper explores a VAE architecture and training procedure that allows to generate new samples of a concept based on several exemplars that are shown to the model. The proposed architecture processes the set of exemplars with a recurrent neural network and aggregation procedure similar to the one used in Matching Networks. The resulting \"summary\" is used to condition a generative model (a VAE) that produces new samples of the same kind as the exemplars shown. The proposed aggregation and conditioning procedure are better suited to sets of exemplars that come from several classes than simple averaging. Perhaps surprisingly the model generalizes from generation conditioned on samples from 2 classes to generation conditioned on samples from 4 classes. The experiments are conducted on the OMNIGLOT dataset and are quite convincing. An explicit comparison to previous works is lacking, but this is explained in the appendices, and a comparison to architectures similar to previous work is presented.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:  [+] Well motivated, tackles an interesting problem;  [+] Clearly written and structured, accompanied by documented code and dataset;  [+] Encouraging results.  - Weaknesses:  [-] Limited to completely deterministic, hand-engineered minimization rules;  [-] Some relevant literature on OIE neglected;  [-] Sound but not thorough experimental evaluation.  - General Discussion:  This paper tackles a practical issue of most OIE systems, i.e. redundant, uninformative and inaccurate extractions. The proposed approach, dubbed MinOIE, is designed to actually \"minimize\" extractions by removing overly specific portions and turning them into structured annotations of various types (similarly to OLLIE). The authors put MinIE on top of a state-of-the-art OIE system (ClausIE) and test it on two publicly available datasets, showing that it effectively leads to more concise extractions compared to standard OIE approaches, while at the same time retaining accuracy.  Overall, this work focuses on an interesting (and perhaps underinvestigated) aspect of OIE in a sound and principled way. The paper is clearly written, sufficiently detailed, and accompanied by supplementary material and a neat Java implementation. My main concern is, however, with the entirely static, deterministic and rule-based structure of MinIE. Even though I understand that a handful of manually engineered rules is technically the best strategy when precision is key, these approaches are typically very hard to scale, e.g. in terms of languages (a recent trend of OIE, see Faruqui and Kumar, 2015; Falke et al., 2016). In other words, I think that this contribution somehow falls short of novelty and substance in proposing a pipeline of engineered rules that are mostly inspired by other OIE systems (such as ClausIE or ReVerb); for instance, I would have really appreciated an attempt to learn these minimization rules instead of hard-coding them.  Furthermore, the authors completely ignore a recent research thread on “semantically-informed” OIE (Nakashole et al., 2012; Moro and Navigli, 2012; 2013; Delli Bovi et al., 2015) where traditional extractions are augmented with links to underlying knowledge bases and sense inventories (Wikipedia, Wikidata, Yago, BabelNet). These contributions are not only relevant in terms of related literature: in fact, having text fragments (or constituents) explicitly linked to a knowledge base would reduce the need for ad-hoc minimization rules such as those in Sections 6.1 and 6.2. In the example with \"Bill of Rights\" provided by the authors (line 554), an OIE pipeline with a proper Entity Linking module would recognize automatically the phrase as mention of a registered entity, regardless of the shape of its subconstituents. Also, an underlying sense inventory would seamlessly incorporate the external information about collocations and multi-word expressions used in Section 6.2: not by chance, the authors rely on WordNet and Wiktionary to compile their dictionary of collocations.  Finally, some remarks on the experimental evaluation:  - Despite the claim of generality of MinIE, the authors choose to experiment only with ClausIE as underlying OIE system (most likely the optimal match). It would have been very interesting to see if the improvement brought by MinIE is consistent also with other OIE systems, in order to actually assess its flexibility as a post-processing tool.  - Among the test datasets used in Section 7, I would have included the recent OIE benchmark of Stanovsky and Dagan (2016), where results are reported also for comparison systems not included in this paper (TextRunner, WOIE, KrakeN).  References:  - Manaal Faruqui and Shankar Kumar. Multilingual Open Relation Extraction using Cross-lingual Projection. NAACL-HLT, 2015.  - Tobias Falke, Gabriel Stanovsky, Iryna Gurevych and Ido Dagan. Porting an Open Information Extraction System from English to German. EMNLP 2016.  - Ndapandula Nakashole, Gerhard Weikum and Fabian Suchanek. PATTY: A Taxonomy of Relational Patterns with Semantic Types. EMNLP 2012.  - Andrea Moro, Roberto Navigli. WiSeNet: Building a Wikipedia-based Semantic Network with Ontologized Relations. CIKM 2012.  - Andrea Moro, Roberto Navigli. Integrating Syntactic and Semantic Analysis into the Open Information Extraction Paradigm. IJCAI 2013.  - Claudio Delli Bovi, Luca Telesca and Roberto Navigli. Large-Scale Information Extraction from Textual Definitions through Deep Syntactic and Semantic Analysis. TACL vol. 3, 2015.  - Gabriel Stanovsky and Ido Dagan. Creating a Large Benchmark for Open Information Extraction. EMNLP 2016.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es innegable el interés que ocasiona la problemática de la navegación de robots, por lo que el trabajo presentado constituye una alternativa para la elección de la arquitectura de control, dado que nos plantea mediante la comparación de métricas una posible solución al problema, sin embargo debe tenerse presente que ha sido realizado en un ambiente de simulación, bajo ciertas condiciones que no necesariamente se replicarán en la práctica lo cual a mi parecer restringe el ámbito de aplicación de los resultados obtenidos. Por otra parte las referencias y desarrollo de cálculos estadísticos dan validez a los resultados obtenidos con la consideración del ambiente en que fue realizada la prueba.  Trabajo bien desarrollado, aunque se plantea la necesidad de realizar pruebas con el móvil real, bajo diversas condiciones de entorno del robot, para validar los resultados obtenidos en simulador.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Because the authors did not respond to reviewer feedback, I am maintaining my original review score.  -----  This paper proposes to model relational (i.e., correlated) time series using a deep learning-inspired latent variable approach: they design a flexible parametric (but not generative) model with Gaussian latent factors and fit it using a rich training objective including terms for reconstruction (of observed time series) error, smoothness in the latent state space (via a KL divergence term encouraging neighbor states to be similarly distributed), and a final regularizer that encourages related time series to have similar latent state trajectories. Relations between trajectories are hard coded based on pre-existing knowledge, i.e., latent state trajectories for neighboring (wind speed) base stations should be similar. The model appears to be fit using gradient simple descent. The authors propose several elaborations, including a nonlinear transition function (based on an MLP) and a reconstruction error term that takes variance into account. However, the model is restricted to using a linear decoder. Experimental results are positive but not convincing.  Strengths: - The authors target a worthwhile and challenging problem: incorporating the modeling of uncertainty over hidden states with the power of flexible neural net-like models. - The idea of representing relationships between hidden states using KL divergence between their (distributions over) corresponding hidden states is clever. Combined with the Gaussian distribution over hidden states, the resulting regularization term is simple and differentiable. - This general approach -- focusing on writing down the problem as a neural network-like loss function -- seems robust and flexible and could be combined with other approaches, including variants of variational autoencoders.  Weaknesses: - The presentation is a muddled, especially the model definition in Sec. 3.3. The authors introduce four variants of their model with different combinations of decoder (with and without variance term) and linear vs. MLP transition function. It appears that the 2,2 variant is generally better but not on all metrics and often by small margins. This makes drawing a solid conclusions difficult: what each component of the loss contributes, whether and how the nonlinear transition function helps and how much, how in practice the model should be applied, etc. I would suggest two improvements to the manuscript: (1) focus on the main 2,2 variant in Sec. 3.3 (with the hypothesis that it should perform best) and make the simpler variants additional \"baselines\" described in a paragraph in Sec. 4.1; (2) perform more thorough experiments with larger data sets to make a stronger case for the superiority of this approach. - The authors only allude to learning (with references to gradient descent and ADAM during model description) in this framework. Inference gets its one subsection but only one sentence that ends in an ellipsis (?). - It's unclear what is the purpose of introducing the inequality in Eq. 9. - Experimental results are not convincing: given the size of the data, the differences vs. the RNN and KF baselines is probably not significant, and these aren't particularly strong baselines (especially if it is in fact an RNN and not an LSTM or GRU). - The position of this paper is unclear with respect to variational autoencoders and related models. Recurrent variants of VAEs (e.g., Krishnan, et al., 2015) seem to achieve most of the same goals as far as uncertainty modeling is concerned. It seems like those could easily be extended to model relationships between time series using the simple regularization strategy used here. Same goes for Johnson, et al., 2016 (mentioned in separate question).  This is a valuable research direction with some intriguing ideas and interesting preliminary results. I would suggest that the authors restructure this manuscript a bit, striving for clarity of model description similar to the papers cited above and providing greater detail about learning and inference. They also need to perform more thorough experiments and present results that tell a clear story about the strengths and weaknesses of this approach.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Aunque el paper está bien escrito y estructurado, y la experimentación parece extensa, no se percibe un grado de originalidad en la versión del algoritmo presentado en el paper respecto de las anteriores versiones del mismo existentes en la literatura y que han sido ya aplicadas a la misma problemática.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper explores different strategies for instance-level image retrieval with deep CNNs. The approach consists of extracting features from a network pre-trained for image classification (e.g. VGG), and post-process them for image retrieval. In other words, the network is off-the-shelf and solely acts as a feature extractor. The post-processing strategies are borrowed from traditional retrieval pipelines relying on hand-crafted features (e.g. SIFT + Fisher Vectors), denoted by the authors as \"traditional wisdom\".  Specifically, the authors examine where to extract features in the network (i.e. features are neurons activations of a convolution layer), which type of feature aggregation and normalization performs best, whether resizing images helps, whether combining multiple scales helps, and so on.   While this type of experimental study is reasonable and well motivated, it suffers from a huge problem. Namely it \"ignores\" 2 major recent works that are in direct contradictions with many claims of the paper ([a] \"End-to-end Learning of Deep Visual Representations for Image Retrieval\" by  Gordo et al. and [b] \"CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples\" by Radenović et al., both ECCV'16 papers). These works have shown that training for retrieval can be achieved with a siamese architectures and have demonstrated outstanding performance. As a result, many claims and findings of the paper are either outdated, questionable or just wrong.  Here are some of the misleading claims:     - \"Features aggregated from these feature maps have been exploited for image retrieval tasks and achieved state-of-the-art performances in recent years.\"   Until [a] (not cited), the state-of-the-art was still largely dominated by sparse invariant features based methods (see last Table in [a]).      - \"the proposed method [...] outperforms the state-of-the-art methods on four typical datasets\"   That is not true, for the same reasons than above, and also because the state-of-the-art is now dominated by [a] and [b].      - \"Also in situations where a large numbers of training samples are not available, instance retrieval using unsupervised method is still preferable and may be the only option.\".   This is a questionable opinion. The method exposed in \"End-to-end Learning of Deep Visual Representations for Image Retrieval\" by Gordo et al. outperforms the state-of-the-art on the UKB dataset (3.84 without QE or DBA) whereas it was trained for landmarks retrieval and not objects, i.e. in a different retrieval context. This demonstrates that in spite of insufficient training data, training is still possible and beneficial.    - Finally, most findings are not even new or surprising (e.g. aggregate several regions in a multi-scale manner was already achieved by Tolias at al, etc.). So the interest of the paper is limited overall.  In addition, there are some problems in the experiments. For instance, the tuning experiments are only conducted on the Oxford dataset and using a single network (VGG-19), whereas it is not clear whether these conditions are well representative of all datasets and all networks (it is well known that the Oxford dataset behaves very differently than the Holidays dataset, for instance). In addition, tuning is performed very aggressively, making it look like the authors are tuning on the test set (e.g. see Table 3).   To conclude, the paper is one year too late with respect to recent developments in the state of the art.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Trabajo muy interesante pues incorpora una evaluación con usuarios del prototipo propuesto. Está bien redactado y los resultados son claros.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors propose a RNN-method for time-series classification with missing values, that can make use of potential information in missing values. It is based on a simple linear imputation of missing values with learnable parameters. Furthermore, time-intervals between missing values are computed and used to scale the RNN computation downstream. The authors demonstrate that their method outperforms reasonable baselines on (small to mid-sized) real world datasets. The paper is clearly written. IMO the authors propose a reasonable approach for dealing with missing values for their intended application domain, where data is not abundant and requires smallish models. I’m somewhat sceptical if the benefits would carry over to big datasets, where more general, less handcrafted multi-layer RNNs are an option.",
            "output": [
                "en"
            ]
        },
        {
            "input": "-\tNo existen bases científicas explicitas en este trabajo y su aporte a la práctica es nulo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper explores the ability of nonlinear recurrent neural networks to account for neural response properties that have otherwise eluded the ability of other models.  A multilayer rnn is trained to imitate the stimulus-response mapping measured from actual retinal ganglion cells in response to a sequence of natural images.  The rnn performs significantly better, especially in accounting for transient responses, than conventional LN/GLM models.  This work is an important step in understanding the nonlinear response properties of visual neurons.  Recent results have shown that the responses of even retinal ganglion cells in response to natural movies are difficult to explain in terms of standard receptive field models.  So this presents an important challenge to the field.  If we even had *a* model that works, it would be a starting point.  So this work should be seen in that light.  The challenge now of course is to tease apart what the rnn is doing.  Perhaps it could now be pruned and simplified to see what parts are critical to performance.  It would have been nice to see such an analysis.   Nevertheless this result is a good first start and I think important for people to know about.  I am a bit confused about what is being called a \"movie.\"  My understanding is that it is essentially a sequence of unrelated images shown for 1 sec. each.  But then it is stated that the \"frame rate\" is 1/8.33 ms.  I think this must refer to the refresh rate of the monitor, right?     I would guess that the deviations from the LN model are even stronger when you show actual dynamic natural scenes - i.e., real movies.  Here I would expect the rnn to have an even more profound effect, and potentially be much more informative.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper introduces a new pruning method for neural networks based on the second-order Taylor expansion and compares the results against a first-order method and brute-force pruning. It performs experiments of the three methods on several toy examples - including a two-layer network on MNIST - and shows that the second-order method behaves much worse then the brute-force baseline. In addition, from the success of the brute-force pruning the authors conclude that the hypothesis of Mozer et al - that neurons either contribute to performance or cancel out the effect of other neurons - is probably correct.  The authors put in considerable effort to explain all details of the paper clearly and at length, so the content of the paper is accessible even to people novel to pruning methods. Additionally, the authors have very carefully answered all questions that were coming up through the pre-review and have been very responsive.  My major criticism is that the paper lacks focus, does not have a concrete conclusion and does not explain what it adds to the literature. To make this apparent, I here summarise each paragraph of the conclusion section:  Paragraph 1: We do not benchmark / Pruning methods do not fare well against brute-force baseline / Some evidence for hypothesis of Mozer & Smolensky, but further investigation needed  Paragraph 2: Introduced 2nd order Taylor method / Does not fare well against baseline  Paragraph 3: Re-training may help but is not fair  Paragraph 4: Brute-force can prune 40-70% in shallow networks  Paragraph 5: Brute-force less effective in deep networks  Paragraph 6: Not all neurons contribute equally to performance of network  The title of the paper and answers of the authors to the pre-review questions seemed to strongly suggest that the paper is not about the new second-order method, is not about benchmarking pruning algorithms but is instead about the learnt representations. But only two or three sentences in the conclusion, and no sentence in the part on results in the abstract, even refers to neural representations. In an answer to the pre-review questions the authors stated:  > Furthermore, we do not have to accept the conclusion that re-training is a necessary part of pruning because a brute force search reveals that neurons can in fact be  > pruned from trained networks in a piecemeal fashion with no retraining and minimal adverse effect on the overall performance of the network. This would be  > impossible if neurons did not belong to the distinct classes we describe.\"  But this can already be concluded from the 2nd order method, which has a similar characteristic and is based on other 2nd order methods (not shown here). What is the motivation to introduce a new 2nd order method here?  In addition, some other minor conclusions about representations - in particular the cancellation effect - might be based on side-effects of the greedy serial pruning method. Optimally, one would need to consider all the different ways of pruning (which, of course, scales exponentially with the number of neurons and is computationally infeasible). Notably, the authors do consider this limitation in the context of conventional pruning methods in the conclusions: \"Third, we assumed that pruning could be done in a serial fashion [...]. We found that all of these assumptions are deeply flawed in the sense that the true relevance of a neuron can only be partially approximated [...] at certain stages of the pruning process\". But the brute-force pruning process is also serial - why is that not a problem?  All in all it is unclear to me what the paper adds: there are little conclusions regarding the learnt representations nor is there sufficient benchmarking against state-of-the-art pruning methods. I would suggest to focus the paper in the following way: first, use a state-of-the-art pruning method from the literature (that works without re-training) or do not use any other pruning methods besides brute-force (depending on whether you want to compare pruning methods against brute-force, or want to learn something about the learnt representations). In this way you need to write little about this second-order tuning methods, and readers are not so easily confused about the purpose of this paper (plus it will be considerably shorter!). Then concentrate on 2-layer MNIST and a deeper CIFAR10 network. Further focus the paper by adding an itemised list of the exact contributions that you make, and streamline the paper accordingly. These measures could strongly boost the impact of your work but will require a major revision.  PS: I think the confusion starts with the following sentence in the abstract: \"In this work we set out to test several long-held hypothesis about neural network learning representations and numerical approaches to pruning.\" Both aspects are pretty orthogonal, but are completely mixed up in the paper.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Overall the paper address an important problem: how to evaluate more appropriately automatic dialogue responses given the fact that current practice to automatically evaluate (BLEU, METEOR, ...) is often insufficient and sometimes misleading. The proposed approach using an LSTM-based encoding of dialogue context, reference response and model response(s) that are then scored in a linearly transformed space. While the overall approach is simple it is also quite intuitiv and allows end-to-end training. As the authors rightly argue simplicity is a feature both for interpretation as well as for speed.   The experimental section reports on quite a range of experiments that seem fine to me and aim to convince the reader about the applicability of the approach. As mentioned also by others more insights from the experiments would have been great. I mentioned an in-depth failure case analysis and I would also suggest to go beyond the current dataset to really show generalizability of the proposed approach. In my opinion the paper is somewhat weaker on that front that it should have been.  Overall I like the ideas put forward and the approach seems sensible though and the paper can thus be accepted.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo presenta una alternativa viable para resolver el problema del cambio de las reglas de negocio.  Se puede mejorar agregando algo más de background al tema de aspectos, dado que se asume un conocimiento previo de este tema, por lo que el paper no es autocontenido.",
            "output": [
                "es"
            ]
        },
        {
            "input": "this paper applies an advanced algorithm to gait control, but is seems that more explanations are needed for a clearer understanding and comparison with other traditional algorithms. It depends on two another papers for its complete understanding. The math is very well stated but I was unable to see the advantages or purpose of that math regarding gait control. Also, it is not clear for the reader how fast or slow is the calculation time regarding task time.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper extends the NTM by a trainable memory addressing scheme. The paper also investigates both continuous/differentiable as well as discrete/non-differentiable addressing mechanisms.  Pros: * Extension to NTM with trainable addressing. * Experiments with discrete addressing. * Experiments on bAbI QA tasks.  Cons: * Big gap to MemN2N and DMN+ in performance. * Code not available. * There could be more experiments on other real-world tasks.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper presents an investigation of various neural language models designed to query context information from their recent history using an attention mechanism. The authors propose to separate the attended vectors into key, value and prediction parts. The results suggest that this helps performance. The authors also found that a simple model which which concatenates recent activation vectors performs at a similar level as the more complicated attention-based models.  The experimental methodology seems sound in general. I do have some issues with the way the dimensionality of the vectors involved in the attention-mechanism is chosen. While it’s good that the hidden layer sizes are adapted to ensure similar numbers of trainable parameters for all the models, this doesn’t control for the fact that key/value/prediction vectors of a higher dimensionality may simply work better regardless of whether their dimensions are dedicated to one particular task or used together. This separation clearly saves parameters but there could also be benefits of having some overlap of information assuming that vectors that lead to similar predictions may also be required in similar contexts for example. Some tasks may also require more dimensions than others and the explicit separation prevents the model from discovering and exploiting this.   While memory augmented RNNs and RNNs with attention mechanisms are not new, some of these architectures had not yet been applied to language modeling. Similarly (and as acknowledged by the authors), the strategy of separating key and value functionality has been proposed before, but not in the context of natural language modeling. I’m not sure about the novelty of the proposed n-gram RNN because I recall seeing similar architectures before but I understand that novelty was not the point of that architecture as it mainly serves as a proof of the lack of ability of the more complicated architectures to do better. In that sense I do consider it an inventive baseline that could be used in future work to test the ability of other models that claim to exploit long-term dependencies.   The exact computation of the representation h_t was initially not that clear to me (the terms hidden and output can be ambiguous at times) but besides this, the paper is quite clear and generally well-written.  The results in this paper are important because they show that learning long-term dependencies is not a solved problem by any means. The authors provide a very nice comparison to prior results and the fact that their n-gram RNN is often at least competitive with far more complicated approaches is a clear indication that some of those methods may not capture as much context information as previously thought. The success of the separation of key/value/prediction functionality in attention-based system is also noteworthy although I think this is something that needs to be investigated more thoroughly (i.e., with more control for hyperparameter choices).    Pros: Impressive and also interesting results. Good comparison with earlier work. The n-gram RNN is an interesting baseline.   Cons: The relation between the attention-mechanism type and the number of hidden units weakens the claim that the key/value/prediction separation is the reason for the increase in performance somewhat. The model descriptions are not entirely clear. I would have liked to have seen what happens when the attention is applied to a much larger context size.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este paper presenta problemas importantes en su formulación.  Los papers de experiencias prácticas deben entregar algo más que una simple descripción del sistema desarrollado: deben indicar claramente qué nuevo conocimiento, técnica o solución se obtuvo de dicha experiencia. Consecuentemente, un paper de esta naturaleza debería incluir, al menos, los siguientes elementos esenciales:  - Una introducción que explique claramente el propósito del trabajo: (a) el problema que fue resuelto directa o indirectamente con la experiencia práctica, (b) por qué el problema es importante y no trivial y (c) por qué que esta experiencia entregó información nueva dentro de dicho contexto (no obtenida con experiencias similares). - Marco teórico - La descripción del sistema: no debe ser una mera enumeración de sus componentes y funcionalidades, sino indicar claramente aquellos elementos que, durante su desarrollo, aportaron información relevante al problema del estudio. - Conclusiones: deben estar alineadas con los elementos de la introducción y deben estar soportados por la evidencia entregada en la descripción del sistema.  Analizando el paper bajo esta perspectiva, encontramos problemas importantes:  Primero, la introducción no es clara respecto al propósito del trabajo y. La única parte donde se mencionan los objetivos es en el 5o párrado, donde se indica que el caso de estudio es \"para demostrar empíricamente los costos de desarrollo\" asociados a las tecnologías mostradas en el paper. Esto, junto con \"destacar las principales características y potenciales virtudes de CakePHP y MVC..\" parecen ser los elementos centrales del paper.  Segundo, la descripción del sistema no difiere mucho de un manual de sistema; falta evidencia esencial para soportar los elementos de la introducción: costos de desarrollo asociados (tiempo, personas, recursos) que, se supone, deberían ser menores que con otra metodología. Si bien las secciones que describen CakePHP y MVC tienen información relevante para el problema, no aportan valor al trabajo si no están respaldadas por evidencia obtenida directamente de la experiencia de desarrollo con esta tecnología. Por sobre todo, eché de menos una comparación con alguna otra experiencia similar, indicando, claramente qué mejoras al desarrollo introduce CakePHP/MVC.  Por último, las conclusiones del paper no están alineadas con los elementos indicados en la introducción; algunas de ellas entregan información fuera del contexto (conclusiones #5 y #6) o son irrelevantes (conclusión #2); otras carecen de evidencias que las soporten (conclusión #1) o no son explicitas en asociar la evidencia con lo concluido (conclusiones #3 y #4).  Al margen de las observaciones anteriores, el paper también requiere mejoras en la presentación de la información. Por ejemplo, no es explícito el valor que el código SQL de las figuras 10 y 11 entregan al paper. Las Figuras 12-15 no están adecuadamente descritas. Una persona que no comprenda bien el trabajo con línea de comando puede terminar totalmente desorientada y no entenderá los argumentos esgrimidos.  Por todos esos motivos el paper no está en condiciones de ser aceptado para publicación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper describes an approach to predict (unseen) future frames of a video given a set of known past frames. The approach is based on a CNN that, in contrast to most related papers, work in the space of affine transformations (instead of pixels or flow). Said another way, the network takes as input a set of affine transforms that describe the motion of patches in the past frames, and likewise, outputs a set of affine transforms that predict future patch motion.  To that aim, the authors make a few simplifying hypotheses, namely, that a sequence of frames can be modeled accurately enough in their patch-affine framework. This is not unreasonable. A lot of papers in the optical flow community are based on similar hypotheses, i.e. model the flow as a smoothly varying affine field (for instance see \"Locally affine sparse-to-dense matching for motion and occlusion estimation\" by Leordeanu et al., \"EpicFlow: Edge-Preserving Interpolation of Correspondences for Optical Flow\" by Revaud et al., \"Optical Flow With Semantic Segmentation and Localized Layers\" by Sevilla-Lara et al.). These methods are state of the art, which gives a hint about the validity of this kind of approach.  In addition, it also seems very reasonable to reformulate the prediction task as predicting motion rather than predicting raw pixels. Indeed, the (patch-affine) motion space is considerably smaller than the image space, making the problem much more tractable and amenable to high-resolution videos.  While I agree with the authors on these points, I also find that the paper suffer from important flaws. Specifically:    - the choice of not comparing with previous approaches in term of pixel prediction error seems very \"convenient\", to say the least. While it is clear that the evaluation metric is imperfect, it is not a reason to completely dismiss all quantitative comparisons with previous work. The frames output by the network on, e.g. the moving digits datasets (Figure 4), looks ok and can definitely be compared with other papers. Yet, the authors chose not to, which is suspicious.      - The newly proposed metric poses several problems. First, action classification is evaluated with C3D, which is not a state-of-the-art approach at all for this task. Second, this metric actually *does not* evaluate what the network is claimed to do, that is, next frame prediction. Instead, it evaluates if another network, which was never trained to distinguish between real or synthetic frames by the way, can accurately classify an action from the predicted frames. I find that this proxy metric is only weakly related to what is supposed to be measured. In adition, it does not really make sense to train a network for something else that the final task it is evaluated for.      - how is the affine motion of patches estimated? It is only explained that the problem is solved globally (not treating each patch independently) in a pretty vague manner. Estimating the motion of all patches is akin to solving the optical flow, which is still an active subject of research. Therefore, an important flaw of the paper lies in the potentially erroneous etimation of the motion input to the network. In the videos made available, it is clear that the motion is wrongly estimated sometimes. Since the entire approach depends on this input, I find it important to discuss this aspect. How do motion estimation failures impact the network? Also, the patch-affine hypothesis does not hold when patches are large enough that they cover several objects with contradictory motion. Which appears to be the case on UCF101 videos.      - Even ignoring the weird proxy-evaluation part, the network is still not trained end-to-end. That is, the network is trained to minimize the difference between (noisy) ground-truth and output affine transforms, instead of minimizing a loss in the actual output space (frame pixels) for which an (exact) ground-truth is available. It is true that the MSE loss on raw pixels leads to blurry results, but other types of losses do exist, for instance the gradient loss introduced by Mathieu et al. was shown to solve this issue. As noted by the authors themselves, minimizing a loss in the transformation space, where affine parameters are harder to intepret, introduces unexpected artifacts. The motion is often largely underestimated, as is obvious in Figure 5 where it is hard to tell the difference between the input and output frames.       - The proposed approach is not sufficiently compared to previous work. In particular, the approach is closely related to \"SPATIO-TEMPORAL VIDEO AUTOENCODER WITH DIFFERENTIABLE MEMORY\" of Taraucean et al, ICLR'15. This paper also output prediction in the motion space. Experimental results should compare against it.    - The comparison with optical flow is unfair. First, the approach of Brox et al. is more than 10 years old. Second, it is not really fair to assume a constant flow for all frames. At least some basic extrapolation could be done to take into account the flow of all pairs of input frames and not just the last one. Overall, the approach is not compared to very challenging baselines.    - I disagree with the answer that the authors gave to a reviewer's question. Denote ground-truth frames as {X_0, X_1 ...} and predicted frames as {Y_1, Y_2, ...}. When asked if the videos at",
            "output": [
                "en"
            ]
        },
        {
            "input": "Interesante propuesta de desarrollo de un vídeo juego para tratar el deterioro cognitivo del adulto mayor. Se ve como una propuesta novedosa, y que abre un nuevo campo de desarrollo de video juegos. Desde este sentido se considera un aporte al congreso.  Sin embargo, lo que el paper presenta es todavía una propuesta en desarrollo, por lo que todavía no se puede validar el enfoque del proyecto, lo cual se presenta como trabajo futuro. Por lo mismo, tampoco queda muy claro como encajaría el uso del video juego dentro de una estrategia mayor del tratamiento del deterioro mental de los adultos mayores, dentro de la cual el juego debería ser una herramienta más.  Por último, hay algunas afirmaciones que no están debidamente respaldadas por evidencias en el paper, tales como: \"cuando hay tareas complejas es mucho más difícil para el joven que para el adulto mayor, ya que el adulto mayor tiene la experiencia mientras que el entrenamiento es sólo práctico\"",
            "output": [
                "es"
            ]
        },
        {
            "input": "- El tema es muy interesante y puede ser de mucha ayuda una guía para incorporar prácticas de seguridad. - La presentación (descripción, etapa y uso) de las 9 prácticas para el desarrollo de software seguro.  - El “estado real del desarrollo de software en Chile” (como lo indica en su paper) no se puede lograr con solamente 22 encuestas de un total de 50. - Presenta nueve tablas que corresponden a las prácticas para el desarrollo de software seguro, pero la guía presenta 10 prácticas. ¿explica por qué? - Sugiero mejorar la guía, el mayor aporte está en la secuencia de incorporación que propone.  Además, no debería explicar la práctica en Observaciones ni diferenciarla con otras prácticas en esa columna, sino que debería dar sugerencias de cómo aplicarla. - En el texto indica “Más adelante, se presentan además tres prácticas extras…” ¿cuáles son o no leí correctamente? - De acuerdo a formato, poner como mínimo 5 palabras clave. - Sugiero mencionar las prácticas antes de mostrar cada tabla. - Algunas referencias están incompletas, por ejemplo, falta año en referencia 17, falta año y tipo de evento en referencia 11, falta editorial en referencia 19 (¿es un libro?) - Algunos títulos llevan una coma dentro de las comillas, ejemplo, referencia 1",
            "output": [
                "es"
            ]
        },
        {
            "input": "El tema es de actualidad y se recrea la tercera misión a través de la propuesta. Me parece meritoria e interesante, además del efecto multiplicador que esto conlleva para las empresas y las universidades en abordar problemas reales, con \"personas\" reales.  Los Acrónimos definidos no presentan o representan su origen o fuente. Por ejemplo, FCAB, dice empresa de Ferrocarriles, pero no se ajusta a la realidad, pues debería ser Ferrocarriles de Antofagasta. Y así con otras, como CMM, HPC, AMPL, los que carecen de significado.  No queda claramente discutido el tema de la propuesta en su contexto, ni los aportes y/o innovaciones en contraste con otras propuestas de la misma naturaleza que se pudiesen citar en referencias, bibliografía, papers o artículos, en donde bien pueden dar o entregar algunas consideraciones sobre el estado del arte del problema. Lo anterior, bien se podría realizar en la introducción o en la presentación del problema.  Falta de claridad en la forma de expresarse o en la definición. Me refiero a por ejemplo, \"diagrama normal\", \"problema del diagrama normal\" y el \"problema del diagrama NxN.\" (en este último al menos se menciona un ejemplo.), \"modelo de diagrama equilibrado\", entre otros.  Se hacen muchos juicios de valor sin tener el respaldo para ello. Me refiero a que se menciona textual... \"este algoritmo es de convergencia lenta...\" \".... los sistemas comerciales y muchos sistemas de libre disposición en la Web......usan técnicas heurísticas, con el fin de hacerlo eficiente.\" \"lento\", ¿en qué sentido?, ya que existe un entramado de posibilidades que podrían justificar tal juicio, a cuál se refiere?. \"sistemas comerciales\", ¿a cuáles se refiere? \"sistemas libres\", se refiere a sistemas FOSS (Free and open source software)? \"técnicas heurísticas\", ¿cuáles de los mencionados usan esta técnica?. \"hacerlo más eficiente\", al igual que antes, ¿en qué sentido, hacerlo más eficiente.?. A caso, no lo es ahora?.  Falta fundamentar y sustentar tales juicios con trabajos y/o referencias bibliográficas, por ejemplo.  Se habla de un grafo, que estaría representando el problema. Existiendo tantas herramientas de modelamiento, que lástima que no se presente o se visualice un modelo gráfico sobre el particular.  Se desconoce el formato de los archivos de entrada, y/o transformaciones que deberán sufrir estos para alimentar los archivos AMPL en el proceso de Leer/transformar datos a AMPL. Análogamente, para cuando la recupera en formato AMPL y la traduce al formato XML. El uso de DSL (Domain-Specific Language) sería una solución plausible?.  Por qué SSH?, ¿qué estudio avala tal decisión.?? Cómo se realiza la autenticación?. que método utiliza?. Autenticación vía password, tarjeta, voz, etc...  Se hacen referencia a una serie de libros clásicos, los cuales no se correlacionan con la presentación, ni con el contexto de la propuesta. Muy genérico. Podría ser más específico respecto del porque citar estos libros. Además no se mencionan en la propuesta el enlace (numeración)a las Referencias.  Carece de conclusiones, o agradecimientos. Me imagino que FCAB facilitó la infraestructura y la problemática.  Carece de enlaces a los portales de las herramientas que utilizaron o utilizaran. Por ejemplo. [Link] [Link] entre otros.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper considers the problem of decoding diverge solutions from neural sequence models. It basically adds an additional term to the log-likelihood of standard neural sequence models, and this additional term will encourage the solutions to be diverse. In addition to solve the inference, this paper uses a modified beam search.  On the plus side, there is not much work on producing diverse solutions in RNN/LSTM models. This paper represents one of the few works on this topic. And this paper is well-written and easy to follow.  The novel of this paper is relatively small. There has been a lot of prior work on producing diverse models in the area of probailistic graphical models. Most of them introduce an additional term in the objective function to encourage diversity. From that perspective, the solution proposed in this paper is not that different from previous work. Of course, one can argue that most previous work focues on probabilistic graphical models, while this paper focuses on RNN/LSTM models. But since RNN/LSTM can be simply interpreted as a probabilistic model, I would consider it a small novelty.  The diverse beam search seems to straightforward, i.e. it partitions the beam search space into groups, and does not consider the diversity within group (in order to reduce the search space). To me, this seems to be a simple trick. Note most previous work on diverse solutions in probabilistic graphical models usually involve developing some nontrivial algorithmic solutions, e.g. in order to achieve efficiency. In comparison, the proposed solution in this paper seems to be simplistic for a paper.  The experimental results how improvement over previous methods (Li & Jurafsky, 2015, 2016). But it is hard to say how rigorous the comparisons are, since they are based on the authors' own implementation of (Li & Jurasky, 2015, 2016).  --------------- update: given that the authors made the code available (I do hope the code will remain publicly available), this has alleviated some of my concerns about the rigor of the experiments. I will raise my rate to 6.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este paper, según los revisores, no contempla directamente una contribución científica, sin embargo la experiencia y el tema tratado son interesantes de presentar en el congreso.  A pesar de que no puede ser presentado como paper regular en el congreso, ser recomienda aceptar el artículo para su presentación en el workshop de educación de Infonor 2013.",
            "output": [
                "es"
            ]
        },
        {
            "input": "1.\tLo que se propone es interesante como una aplicación pero no es un trabajo científico.  2.\tEn el resumen no se indica nada respecto a la metodología que se propone por lo cual quizás el título “Desarrollo de una Metodología”…. Debería estar orientado a “Una propuesta para la sistematización del sistema de información del propedéutico…”.  3.\tNo se propone ninguna metodología es una aplicación “interesante” pero no una metodología.  4.\tEn la página 3 corregir error de redacción “en la Figura 1, organziados como”.  5.\tFalta fundamentar mejor la idea de lo que se propone, es decir, realizar un análisis “claro” de las  ventajas  de por qué es interesante e importante la propuesta. Por ejemplo, se puede hacer una tabla con las ventajas sobre otros modelos. Así como esta no indica una ventaja por sobre otros métodos porque no se analizan otros métodos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El tema de la automatización si bien es de interés, en este artículo tiene un enfoque muy general, sería interesante por ejemplo referirse a los PLC compactos vs. PLC modulares, además podría incorporarse en la comparación a los microcontroladores de gama alta, dado que al proveerlos de una etapa de potencia se pueden lograr resultados muy interesantes de aplicación a bajo costo. El título tiende a confundir dado que se espera la presentación de las últimas tecnologías utilizadas en la automatización industrial y más bien se enfoca en primer lugar en una revisión histórica de los avances del área para luego dedicarse a comparar sólo dos de los tipos de controladores existentes en la industria. El contenido expuesto es frecuentemente encontrado en la literatura referente al área, por lo que no representa a mi parecer una contribución relevante al tema.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths:  * Elaborate evaluation data creation and evaluation scheme.  * Range of compared techniques: baseline/simple/complex  - Weaknesses:  * No in-depth analysis beyond overall evaluation results.  - General Discussion: This paper compares several techniques for robust HPSG parsing.  Since the main contribution of the paper is not a novel parsing technique but the empirical evaluation, I would like to see a more in-depth analysis of the results summarized in Table 1 and 2. It would be nice to show some representative example sentences and sketches of its analyses, on which the compared methods behaved differently.  Please add EDM precision and recall figures to Table 2. The EDM F1 score is a result of a mixed effects of (overall and partial) coverage, parse ranking, efficiency of search, etc. The overall coverage figures in Table 1 are helpful but addition of EDM recall to Table 2 would make the situations clearer.  Minor comment: - Is 'pacnv+ut' in Table 1 and 2 the same as 'pacnv' described in 3.4.3?",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo busca resumir y revisar los algoritmos de filtrado y segmentación de nubes de puntos en visión por computador. En palabras de los autores \"El objetivo de este trabajo es realizar una revisión del estado del arte en cuanto al tratamiento de nubes de puntos\". En mi opinión no logra este objetivo declarado por ellos. Mis razones son expresadas a continuación. Primero, llama la atención que como artículo que pretendiendo establecer el estado del arte, tenga una bibliografía muy escasa (14 artículos). En ese sentido, sería más apropiado indicar que este trabajo es de tipo preliminar (si es que así lo fuera) ya que de esa forma se justificaría una tan baja cantidad de artículos revisados. Segundo, y que me parece de mayor relevancia, el trabajo no hace un resumen adecuado de la bibliografía, sino que más bien pareciera ser un apunte sobre algunos métodos de filtrado y segmentación. Una revisión del estado del arte, en mi opinión, debería tener un propósito como por ejemplo identificar las principales brechas de la literatura o las oportunidades de investigación. Tercero, aunque una revisión bibliográfica es, en esencia, un resumen, ésta debe ser sistemática. Es decir, debe tener un método que tiene que ser especificado. Por ejemplo, cuál fue la ecuación de búsqueda usada y cuál fue el rango de tiempo y criterios de selección de los artículos revisados o cuáles fueron eliminados y por qué. Por último, aunque no tiene que ver con el contenido ni el objetivo del artículo, hay evidentes  problemas de formato. Por ejemplo, toda la sección de conclusiones está centrada en vez de justificada. Además, hay problemas de redacción que en algunas partes hace difícil el entendimiento del texto. Por ejemplo, el primer párrafo en la subsección \"Segmentación\" dice \"El proceso de generar un modelo de superficie desde una nube de puntos, la segmentación que extrae los bordes y particiones del mundo 3D, los puntos juegan un importante rol en el encaje de las superficies.\" También hay errores ortográficos como escribir \"laser\" y \"láser\" en diferentes partes del documento. En síntesis, el artículo no logra su objetivo de ser una revisión del estado del arte y, además, tiene errores de formato evidente.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Novedosa propuesta. Bien estructurada. Correctamente escrita. Sólo sugiero: Explicar con más detalle la función trapezoidal de la página 2. Redactar nuevamente  el  párrafo  anterior a la función trapezoidal A(x). Agrandar el esquema de la figura 1. Explicar la arquitectura propuesta mostrada en la figura 2. Revisar referencia de Feng et al. que es la referencia 2 y en un párrafo de la columna 2 página 1 está marcada como referencia 1.  Artículo no está en el formato pedido por Infonor, por favor cambiar a éste formato.",
            "output": [
                "es"
            ]
        },
        {
            "input": "De forma: •\tSe recomienda cambiar la palabra “catastros” del título •\tProblemas de ortografía. Ejemplo: agiles (primer párrafo de la introducción), ingles (sección criterios de inclusión y exclusión) •\tSe recomienda siempre redactar en tercera persona para textos en español. •\tLas páginas 6 y 8 del artículo están en blanco.  De fondo: •\tEl artículo es claro en su estructura y de fácil lectura. •\tSe muestra de forma inicial el proceso seguido para el mapeo sistemático y luego de forma ordenada se muestran los resultados al ejecutar cada paso. •\tSe recomienda cambiar la figura 2 al idioma español, para los casos en que sea posible. •\tSe aborda un tema interesante y relevante para la comunidad científica y empresarial, y el alcance logrado está acorde con el tipo de productos solicitados para el evento INFONOR.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta una aproximación por Algoritmos Genéticos (AG) para resolver ecuaciones de difusión de luz en medios turbios.  Se indica que una de las principales ventajas del AG sobre métodos tradicionales es la eliminación del ruido de las imágenes resultantes. Sin embargo no queda muy claro a qué se debe esto ni es evidente que se haya utilizado un método cuantitativo para determinar la ausencia de ruido. Es imperativo que los autores resuelvan este problema para darle suficiente solidez al artículo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper describes a method to evaluate generative models such as VAE, GAN and GMMN. This is very much needed in our community where we still eyeball generated images to judge the quality of a model. However, the technical increment over the NIPS 16 paper: “Measuring the reliability of MCMC inference with bidirectional Monte Carlo” is very small, or nonexistent (but please correct me if I am wrong!).  (Grosse et al). The relative contribution of this paper is the application of this method to generative models.  In section 2.3 the authors seem to make a mistake. They write E[p’(x)] <= p(x) but I think they mean: E[log p’(x)] <= log E[p’(x)] = log p(x). Also,  for what value of x? If p(x) is normalized it can’t be true for all values of x. Anyways, I think there are typos here and there and the equations could be more precise. On page 5 top of the page it is said that the AIS procedure can be initialized with q(z|x) instead of p(z). However, it is unclear what value of x is then picked? Is it perhaps Ep(x)[q(z|x)] ? I am confused with the use of the term overfitting (p8 bottom). Does a model A overfit relative to a another model B if the test accuracy of A is higher than that of B even though the gap between train and test accuracy is also higher for B than for A. I think not. Perhaps the last sentence on page 8 should say that VAE-50 underfits less than GMMN-50? The experimental results are interesting in that it exposes the fact that GANs and GMMNs seem to have much lover test accuracy than VAE despite the fact that their samples look great.",
            "output": [
                "en"
            ]
        },
        {
            "input": "RESUMEN. El trabajo propone un modelo para evaluar la calidad de un software orientado a agentes. Básicamente, el modelo considera tres propiedades para evaluar su calidad: habilidad social, autonomía y pro-actividad.  Para evaluar estas propiedades, el autor descompone estas propiedades en varias sub-propiedades medibles. El autor evalúa este modelo a través de un caso estudio: un sistema bancario.  Comentarios Generales: De manera notaría, la estructura del documento tiene los aspectos necesarios para ser considerado un artículo científico. La contribución del artículo pareciese ser relevante.  Dicho esto, este trabajo carece de algunos puntos que (para mí) es importante abordar:  * El autor menciona que no hay modelo para evaluar la calidad del software de agente, y el propone uno. Su propuesta es una adaptación de ISO/IEC, sin embargo, el autor no justifica por qué es la apropiada.  * Con respecto al punto anterior, el párrafo 1 de la introducción dice que no hay modelo de que mida la calidad del software. Luego, el párrafo 2 menciona que hay algunos trabajos acerca de esto. El autor debería clarificar su contribución.  * El autor menciona que se desarrolló un software para este trabajo, sin embargo, este trabajo aparece como otra publicación más (y de otro autor). Si es el software mencionado no es parte de las contribuciones del trabajo, por favor, eliminar estas frases.  Otros comentarios:  * En la sección del caso de estudio no es tan fácil entenderla. Por ejemplo, figuras 2, 5 y 7 no se entiende a que se refiere sus siglas (ej. AMS). Supongo que corresponden a los sub-propiedades.  * Se recomienda intercambiar la sección 3 por la sección 2. Es decir, primero explicar que es un agente y luego hablar del trabajo relacionado.  * No me queda claro si es \"agente software\" o \"agente de software\". Incluso, el autor también confunde esta terminología (primera oración de la sección 4).",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta el desarrollo de una aplicación móvil, no incluye ningún elemento de investigación asociada a dicho desarrollo. Simplemente se centra en la aplicación del proceso RUP para el desarrollo. No se referencian los textos o artículos utilizados para definiciones o aseveraciones realizadas, por ejemplo, sobre RUP \"....es enfocada hacia \"diagramas de los casos de uso, y manejo de los riesgos y el manejo de la arquitectura\" como tal \"   Si está entre cremillas, supongo será una copia textual de alguna parte que no se indica No se presenta un análisis profundo de la estrategia de solución ¿cuál es la lógica detrás de la aplicación móvil? Se observan algunos problemas en la redacción en el texto, por ejemplo, \"...su objetivo es asegurar la producción de software de alta y mayor calidad....\" La estructura del artículo tiene algunas deficiencias La figura 1 no aporta información al trabajo realizado, no es necesaria. La figura 2 no se distingue bien, además está tomada del libro de UML de Larman y no aparece la referencia en el texto. Las conclusiones del trabajo son extremadamente básicas",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Update after rebuttal  I appreciate the authors taking the time to clarify their implementation of the baseline and to provide some evidence of the significance of the improvements they report. These clarifications should definitely be included in the camera-ready version. I very much like the idea of using visual features for these languages, and I am looking forward to seeing how they help more difficult tasks in future work.  - Strengths:  - Thinking about Chinese/Japanese/Korean characters visually is a great idea!  - Weaknesses:  - Experimental results show only incremental improvement over baseline, and the choice of evaluation makes it hard to verify one of the central arguments: that visual features improve performance when processing rare/unseen words.  - Some details about the baseline are missing, which makes it difficult to interpret the results, and would make it hard to reproduce the work.  - General Discussion:  The paper proposes the use of computer vision techniques (CNNs applied to images of text) to improve language processing for Chinese, Japanese, and Korean, languages in which characters themselves might be compositional. The authors evaluate their model on a simple text-classification task (assigning Wikipedia page titles to categories). They show that a simple one-hot representation of the characters outperforms the CNN-based representations, but that the combination of the visual representations with standard one-hot encodings performs better than the visual or the one-hot alone. They also present some evidence that the visual features outperform the one-hot encoding on rare words, and present some intuitive qualitative results suggesting the CNN learns good semantic embeddings of the characters.  I think the idea of processing languages like Chinese and Japanese visually is a great one, and the motivation for this paper makes a lot of sense. However, I am not entirely convinced by the experimental results. The evaluations are quite weak, and it is hard to say whether these results are robust or simply coincidental. I would prefer to see some more rigorous evaluation to make the paper publication-ready. If the results are statistically significant (if the authors can indicate this in the author response), I would support accepting the paper, but ideally, I would prefer to see a different evaluation entirely.  More specific comments below:  - In Section 3, paragraph \"lookup model\", you never explicitly say which embeddings you use, or whether they are tuned via backprop the way the visual embeddings are. You should be more clear about how the baseline was implemented. If the baseline was not tuned in a task-specific way, but the visual embeddings were, this is even more concerning since it makes the performances substantially less comparable.  - I don't entirely understand why you chose to evaluate on classifying wikipedia page titles. It seems that the only real argument for using the visual model is its ability to generalize to rare/unseen characters. Why not focus on this task directly? E.g. what about evaluating on machine translation of OOV words? I agree with you that some languages should be conceptualized visually, and sub-character composition is important, but the evaluation you use does not highlight weaknesses of the standard approach, and so it does not make a good case for why we need the visual features.   - In Table 5, are these improvements statistically significant?  - It might be my fault, but I found Figure 4 very difficult to understand. Since this is one of your main results, you probably want to present it more clearly, so that the contribution of your model is very obvious. As I understand it, \"rank\" on the x axis is a measure of how rare the word is (I think log frequency?), with the rarest word furthest to the left? And since the visual model intersects the x axis to the left of the lookup model, this means the visual model was \"better\" at ranking rare words? Why don't both models intersect at the same point on the x axis, aren't they being evaluated on the same set of titles and trained with the same data? In the author response, it would be helpful if you could summarize the information this figure is supposed to show, in a more concise way.   - On the fallback fusion, why not show performance for for different thresholds? 0 seems to be an edge-case threshold that might not be representative of the technique more generally.  - The simple/traditional experiment for unseen characters is a nice idea, but is presented as an afterthought. I would have liked to see more eval in this direction, i.e. on classifying unseen words  - Maybe add translations to Figure 6, for people who do not speak Chinese?",
            "output": [
                "en"
            ]
        },
        {
            "input": "• Revisar los conceptos de metodologías, métodos y modelos ya que son utilizados de manera indistinta, recomiendo revisar los términos,  elegir el más apropiado y estandarizar su uso  • Agregar referencia a afirmaciones que haces dentro de las diferentes secciones por ejemplo: ”la calidad de un sistema o producto está muy influenciada por la calidad del proceso empleado para desarrollarlo y mantenerlo”  •Resumen:   •Revisa redacción en el uso de palabras como:    oconstrucción --> desarrollo    omodelos: metodologías? las metodologías ágiles son empleadas para mejorar la calidad de los procesos? revisar conceptos de modelos de mejora y metodologías de desarrollo de software ágiles    o“estos dos modelos”: cuales modelos, si estás hablando de un modelos y metodologías ágiles  •Abstract   •Revisar la redacción del abstract frases como:    o Give --> provide?    o Consisting of \"heavy\" development --> processes?    o The agile software development models --> methodologies?    o With --> between    o Models --> methodology and model   •Introducción    o Basar los desarrollos --> el desarrollo    o Lo antes dicho argumenta la selección de procesos ágiles.. procesos o metodologías?    o … han aplicado técnicas como procesos de mejora del proceso o certificaciones con excelentes resultados prácticos --> aquí dos comentarios: (1) no veo la relación entre procesos de mejora de proceso y certificaciones... y (2) ¿estás hablando de procesos de mejoras procesos o iniciativas de mejora de procesos?   •Estado del arte    o Procesos ágiles y CMMI?    o “Para asegurarse esa posición, muchas empresas recurren a certificaciones” --> a certificaciones o a implementación de mejoras siguiendo modelos como CMMI   •Propósito y niveles de CMMI    o En concreto, la propuesta de CMMI consiste de una serie de prácticas y procesos de alto nivel que ayudan a las organizaciones a construir un modelo para mejorar sus procesos --> CMMI no es para construir modelos, te proporciona un conjunto de buenas prácticas que pueden ser implementadas en las organizaciones para mejorar sus procesos.... como lo mencionas en la frase siguiente!    o Referencias de las Tablas    •Modelos ágiles de desarrollo de software:    o En toda la sección, ¿estás hablando de modelos o metodologías? Ya que usas modelos, método y metodología indistintamente    •Aseguramiento de la calidad del proceso y del producto:    o Referencia de la fuente de la fuente de los conceptos de esta sección    o Tabla 4: Recomiendo agregar una breve descripción de la práctica CMMI para que sea mejor entendida la relación que propones    o Tabla 5: revisar “Fase de planificación: EN esta fase se detectan y corrigen las no conformidades” --> ¿estás seguro?    •Gestión de Requisitos (REQM):    o Referencia de la fuente de la fuente de los conceptos de esta sección    o “El Product Backlog, que permite trazar un requisito y un papel responsable para el seguimiento de ella” --> no se entiende    o Tabla 6: (1) recomiendo agregar una breve descripción de las prácticas CMMI; (2) “entre los cuales están los proveedores de los requisitos” --> te estas refiriendo al product owner?;    o Pregunta: ¿quien valida esta trazabilidad? o ¿cómo se ha realizado la validación?   •Conclusiones:    o “Últimamente se vienen aplicando en la industria diversas metodologías” --> ¿cuáles metodologías?    o“El llegar a un nivel superior indica que hay una serie de prácticas importantes que aumentan la madurez de la organización a la hora de enfrentarse a problemas más exigentes.”  --> indica que la organización va estandarizando su forma de trabajar... todos trabajan de la misma manera    o Resaltando las limitaciones y proponiendo soluciones a los problemas en estas áreas, este estudio genera una nueva comprensión de la mejora de procesos de desarrollo de software mediado con prácticas ágiles y CMMI. -->¿?    o se sugiere el desarrollo de una guía para facilitar la mejora organizativa de nivel del aseguramiento de la calidad del proceso y del producto y gestión de requisitos de CMMI. -->¿ en qué parte?, esto no lo veo en el desarrollo del artículo    o También se muestra que el conjunto de uso combinado de las prácticas XP y Scrum mejora algunos aspectos de comunicación dentro de los equipos de desarrollo --> ¿en qué parte del artículo se menciona esto?    o Así, la relación de correspondencia definida en este trabajo, establece una guía de apoyo para toda aquella organización ágil que desee certificarse de acuerdo al modelo de procesos CMMI. --> desde mi punto de vista, el trabajo presentado no tiene la profundidad para asegurar esta conclusión   •Referencias:    o Revisar el formato de las referencias de acuerdo a la guía del congreso    o Referencia 9 --> Editirial?",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta una metodología para abordar al complejidad de implementar reglas de negocios sin realizar cambios en la funcionalidad base de un sistema.  Propone una metodología clara basada en documentación mediante plantillas para manejar y analizar el impacto de realizar la implementación de una regla de negocio vía orientación al aspecto.  Las razones presentadas para indicar que el enfoque OA para encapsular la conexión entre las reglas de negocio y la funcionalidad base no es una tarea trivial, son generales y deberían ser abordadas con mayor profundidad.  No presenta evidencias formales de que la utilización de las plantillas propuestas resuelvan de forma concreta un problema.  Se sugiere presentar un problema resuelto por medio de la herramienta que se encuentra en desarrollo que maneje automáticamente las plantillas. En su defecto, demostrar la aplicación a un problema específico.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Presenta una búsqueda de respuesta a partir de una solicitud en un call center.  El trabajo está bien presentado, pero muy largo, y eso no permite ver bien lo que quieren aportar los autores.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper shows:    1. Easy, constructive proofs to derive e-error upper-bounds on neural networks with O(log 1/e) layers and O(log 1/e) ReLU units.   2. Extensions of the previous results to more general function classes, such as smooth or vector-valued functions.   3. Lower bounds on the neural network size, as a function of its number of layers. The lower bound reveals the need of exponentially many more units to approximate functions using shallow architectures.  The paper is well written and easy to follow. The technical content, including the proofs in the Appendix, look correct. Although the proof techniques are simple (and are sometimes modifications of arguments by Gil, Telgarsky, or Dasgupta), they are brought together in a coherent manner to produce sharp results. Therefore, I am leaning toward acceptance.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo es de baja calidad académica (describe sólo una idea de proyecto y no da evidencias útiles para ser reportadas en ambientes académicos) y de muy pobre redacción (no depurado y sin claridad). No creo que sea un aporte al congreso.  Ejemplos de carencias:  1. No existe ABSTRACT en inglés, sólo un RESUMEN con título de ABSTRACT, lo mismo en el caso de las KEYWORDS.  2. Errores gramaticales:  ·\tEliminar “,” en diversos lugares sin sentido gramatical. Ejemplos: ·\t\"En este artículo, se describen los antecedentes y la fundamentación teórica del proyecto\". ·\t“… y la participación ciudadana, de donde surge la necesidad de realizar el proyecto” ·\t“ Este cuestionamiento, permitirá que el lector se enfoque …” ·\t“… más fácilmente, la forma” ·\tFaltan “.” Finales: ·\tQue el funcionamiento de una nación pueda basarse en el principio de democracia representativa ·\tLas instituciones de una nación proporcionen a los ciudadanos medios y posibilidades de expresar su opinión ·\tFaltan “y” ·\t“… cuentas, desmonte de la cultura de corrupción.”, debe ser “… cuentas, y desmonte de la cultura de corrupción.” ·\tTiempos verbales errados: a.\t“… lector se enfoque en el objetivo primordial de los desarrollos y podrá”,  podrá debe ser pueda. ·\tUso de “;”  y “,” en “ El artículo se estructura de la siguiente forma: en la sección 2 se describen las razones y el contexto actual que dieron origen a la idea que motivó el proyecto; en la sección 3 se plantean los objetivos propuestos; luego, en la sección 4, se delinea la metodología y se describen brevemente cada una de las fases o etapas de desarrollo y finalmente en la sección 5, se plantean las conclusiones a las que se ha podido llegar, luego de la ejecución de las fases 1, 2 y 3.” ·\tUso de punto aparte en vez de puntos seguido en varios párrafos.   3. En las referencias ·\tMalas llamadas a las referencia en el texto, dice “[2], [3], [4], [5]” y debe ser “[2, 3, 4, 5]” ó “[2-5]” ·\tIncompletas para [1] ¿Editorial, año? ·\tReferencias en mal reportadas según estandar: ·\t[2] Batista, C. TICs y Buen Gobierno: La contribución de las Tecnologías de la Información y la Comunicación al Gobierno Local en América Latina. Núcleo de Investigación en Políticas Públicas. Universidad de Brasilia, Brasil. UNESCO. 2003. ·\t[3] Revelo, H. Gobernabilidad y Tecnologías de Información y Comunicaciones: Uso de las TIC para el fomento de condiciones para la Gobernabilidad, con énfasis en el ámbito Local. En: XI Congreso Iberoamericano de Derecho e Informática. Quito – Ecuador. Septiembre 28 al 30 del 2005. ·\t[4] Toro Giraldo G. et al. Gobierno Electrónico Local e Inclusión Digital. Federación Colombiana de Municipios GTZ, 2006. ·\t[5] [Link]  ·\t[8] Solano, D., Perez, L., Velez-Langs, O. Citizen participation through web: e-democracy in Monteria.. Proceedings of the 3rd International Conference on Theory and Practice of Electronic Governance. Bogota Noviembre 2009. ·\t[9] Perez Negrete, L., Velez Langs, O., Solano Oviedo, D. Análisis de la Recepción de un Portal de e-Democracia en Montería .. V Congreso Colombiano de Computación. Cartagena de Indias - Colombia Abril 2010. ·\t[10] [Link] ·\t[11] [Link]  4. No existen  fuentes de las figuras 1 y 2. 5. Dice que el objetivo general del proyecto es “proporcionar una arquitectura de apoyo a la toma de decisiones grupales y de comunicaciones, que facilite la participación ciudadana en aquellos procesos públicos relacionados con la toma de decisiones, promover su empleo en decisiones importantes y explorar los aspectos político-legales asociados al mismo” (falta . final) y se puede entender que el objetivo de artículo descrito como  “se describen los antecedentes y la fundamentación teórica del proyecto de investigación con el mismo nombre” … que como dice (finalmente) en  las conclusiones es “Desarrollo de Mecanismos de Participación Ciudadana en Montería a través de Internet”.  Este último objetivo no se cumple a mí entender. 6. En las conclusiones se entregan elementos desarrollo del trabajo como es “la opción escogida para el desarrollo del portal, siendo el manejador de contenidos Joomla! la herramienta utilizada para ello, debido a la facilidad de uso, administración y mantenimiento de todo portal o sitio web construido con este [8]. Joomla! fue elegido posteriormente a un estudio en donde también se consideraron otras tecnologías como DWR [10] o Wicket [11]. Dicha facilidad de administración y mantenimiento….”",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes to use RNN and reinforcement learning for solving combinatorial optimization problems. The use of pointer network is interesting as it enables generalization to arbitrary input size. The proposed method also \"fintunes\" on test examples with active search to achieve better performance.  The proposed method is theoretically interesting as it shows that RNN and RL can be combined to solve combinatorial optimization problems and achieve comparable performance to traditional heuristic based algorithms.  However, the lack of complexity comparison against baselines make it impossible to tell whether the proposed method has any practical value. The matter is further complicated by the fact that the proposed method runs on GPU while baselines run on CPU: it is hard to even come up with a meaningful unit of complexity. Money spent on hardware and electricity per instance may be a viable option.  Further more, the performance comparisons should be taken with a grain of salt as traditional heuristic based algorithms can often give better performance if allowed more computation, which is not controlled across algorithms.",
            "output": [
                "en"
            ]
        },
        {
            "input": "UPDATE: I have read the authors' rebuttal and also the other comments in this paper's thread. My thoughts have not changed.  The authors propose using a mixture prior rather than a uni-modal prior for variational auto-encoders. They argue that the simple uni-modal prior \"hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution.\"  I find the motivation of the paper suspicious because while the prior may be uni-modal, the posterior distribution is certainly not. Furthermore, a uni-modal distribution on the latent variable space can certainly still lead to the capturing of complex, multi-modal data distributions. (As the most trivial case, take the latent variable space to be a uniform distribution; take the likelihood to be a point mass given by applying the true data distribution's inverse CDF to the uniform. Such a model can capture any distribution.)  In addition, multi-modality is arguably an overfocused concept in the literature, where the (latent variable) space is hardly anymore worth capturing from a mixture of simple distributions when it is often a complex nonlinear space. It is unclear from the experiments how much the influence of the prior's multimodality influences the posterior to capture more complex phenomena, and whether this is any better than considering a more complex (but still reparameterizable) distribution on the latent space.  I recommend that this paper be rejected, and encourage the authors to more extensively study the effect of different priors.  I'd also like to make two additional comments:  While there is no length restriction at ICLR, the 14 page document can be significantly condensed without loss of describing their innovation or clarity. I recommend the authors do so.  Finally, I think it's important to note the controversy in this paper. It was submitted with many significant incomplete details (e.g., no experiments, many missing citations, a figure placed inside that was pencilled in by hand, and several missing paragraphs). These details were not completed until roughly a week(?) later. I recommend the chairs discuss this in light of what should be allowed next year.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo es interesante. Se nota que se invirtió bastante tiempo en la revisión bibliográfica del tema. El aporte es que permite revisar las técnicas de extracción de información para bases de datos noSQL. Una vez que se apliquen las técnicas se encontraran nuevos desafíos que se pueden \"ver\" sólo al momento de la implementación. Por otro lado el riesgo está en cuantos investigadores están trabajando en el tema en distintas partes. Esto debido a que es un tema de línea principal. ¿Qué hay implementado al respecto? ¿Vale la pena aplicar las técnicas? Una mirada a estos aspectos es importante para no encontrar sorpresas en la implementación.  El trabajo está bien presentado y es claro.  Hay algunos errores: - Los números de páginas no están correlativos. Después de la página 5 vuelve a la página 3. - El esquema de la figura 2 indica que la \" selección de fuentes\" y \" procesamiento:calidad de datos\" son actividades de \" 1. Determinación de objetivos\". Sin embargo en la redacción están asociadas a \"2. Preparación de datos\" ¿A qué actividad están asociadas 1 o 2?",
            "output": [
                "es"
            ]
        },
        {
            "input": "Thank you for an interesting read.  I found this paper very interesting. Since I don't think (deterministic) approximate inference is separated from the modelling procedure (cf. exact inference), it is important to allow the users to select the inference method to suit their needs and constraints. I'm not an expert of PPL, but to my knowledge this is the first package that I've seen which put more focus on compositional inference. Leveraging tensorflow is also a plus, which allows flexible computation graph design as well as parallel computation using GPUs.  The only question I have is about the design of flexible objective functions to learn hyper-parameters (or in the paper those variables associated with delta q distributions). It seems hyper-parameter learning is also specified as inference, which makes sense if using MAP. However the authors also demonstrated other objective functions such as Renyi divergences, does that mean the user need to define a new class of inference method whenever they want to test an alternative loss function?",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposed COCONET, which is a neural autoregressive model with convolution, to do music composition task. This paper also proposed to use blocked Gibbs sampling instead of the ancestral sampling of the original NADE model to generate better pieces of music. The experimental results showed that the NLL of COCONET is better than the other baselines and the human evaluation task by Amazon’s Mechanical Turk illustrated that the model can generate compelling music.  In general, I think the paper is good. Using NADE based model with convolution operations on music generation tasks and using blocked Gibbs sampling contains some kind of novelty. However, the novelty of the paper is incremental, since the blocked Gibbs sampling for NADE model is already proposed by Yao et al., (2014) and the using NADE based model for music modeling has also been proposed by Boulanger-Lewandowski  et al., (2012).",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo es interesante, abarca en profundidad muchos términos. Algunas observaciones son: - Deben ser entre 5 y 10 palabras clave. - Cambiar palabra \"entonro\" - Quitar acento a \"éste modo\" - No usar color según instrucciones de papers Infonor - Cambiar palabra \"Dendrograma\" -  Revisar \"realizar un paneo\"",
            "output": [
                "es"
            ]
        },
        {
            "input": "This work proposes to use visualization of gradients to further understand the importance of features (i.e. pixels) for visual classification. Overall, this presented visualizations are interesting, however, the approach is very ad hoc. The authors do not explain why visualizing regular gradients isn't correlated with the importance of features relevant to the given visual category and proceed to the interior gradient approach.   One particular question with regular gradients at features that form the spatial support of the visual class. Is it the case that the gradients of the features that are confident of the prediction remain low, while those with high uncertainty will have strong gradients?  With regards to the interior gradients, it is unclear how the scaling parameter \\alpha affects the feature importance and how it is related to attention.  Finally, does this model use batch normalization?",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposed the group sparse auto-encoder for feature extraction. The author then stack the group sparse auto-encoders on top of CNNs to extract better question sentence representation for QA tasks.   Pros:  - group-sparse auto-encoder seems new to me. - extensive experiments on QA tasks.   Cons: - The idea is somewhat incremental. - Writing need to be improved.  - Lack of ablation studies to show the effectiveness of the proposed approach.   Moreover, I am not convinced by the author's answer regarding the baseline. A separate training stages of CNN+SGL for comparison is fine. The purpose is to validate and analyze why the proposed SGA is preferred rather than group lasso, e.g. joint training could improve, or the proposed group-sparse regularization outperforms l_21 norm, etc. However, we can't see it from the current experiments.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta un estudio de caso sobre el desarrollo de una aplicación móvil de realidad aumentada. La aplicación tiene como objetivo brindar información multimedia sensible al contexto (ubicación) y permite realizar tours  sobre distintos puntos de interés.  Si bien el tema (Realidad Aumentada) es muy interesante desde el punto de vista de la investigación, los objetivos del estudio de caso deben ser presentados explícitamente. El objetivo del prototipo puede ser la experimentación con tecnologías de desarrollo disponible para RA, el desarrollo de un software funcional para ser puesto en producción o ambos.  En la sección central del artículo (Solución Propuesta) hay múltiples secciones donde se mezclan conceptos: selección de herramientas, diseño de la arquitectura de la aplicación, lista de funcionalidades (que debe ser revisara para ser una extensión de los requerimientos de la sección III). Sugiero separar y seleccionar solo uno de estos aspectos para tratar en mayor profundidad. Por ejemplo, la selección y justificación de herramientas está dispersa en varios puntos del artículo.  Existe la oportunidad de explicar las lecciones aprendidas del desarrollo de una aplicación de RA con mayor detalle. La lista de beneficios y la discusión de resultados solo trata de aspectos generales.  Sugiero incluir más referencias a la literatura sobre RA: definiciones, investigación reciente, casos de desarrollos similares.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths:  Improves over the state-of-the-art. Method might be applicable for other domains.  - Weaknesses:  Not much novelty in method.  Not quite clear if data set is general enough for other domains.  - General Discussion:  This paper describes a rule-based method for generating additional weakly labeled data for event extraction.  The method has three main stages.  First, it uses Freebase to find important slot fillers for matching sentences in Wikipedia (using all slot fillers is too stringent resulting in too few matches).  Next, it uses FrameNet to to improve reliability of labeling trigger verbs and to find nominal triggers.  Lastly, it uses a multi-instance learning to deal with the noisily generated training data.  What I like about this paper is that it improves over the state-of-the-art on a non-trival benchmark.  The rules involved don't seem too obfuscated, so I think it might be useful for the practitioner who is interested to improve IE systems for other domains.  On the other hand, some some manual effort is still needed, for example for mapping Freebase event types to ACE event types (as written in Section 5.3 line 578).  This also makes it difficult for future work to calibrate apple-to-apple against this paper.              Apart from this, the method also doesn't seem too novel.  Other comments:  - I'm also concern with the generalizability of this method to other   domains.  Section 2 line 262 says that 21 event types are selected   from Freebase.  How are they selected?  What is the coverage on the 33 event types in the ACE data.  - The paper is generally well-written although I have some   suggestions for improvement.              Section 3.1 line 316 uses \"arguments liked time, location...\".  If you mean roles or arguments, or maybe you want to use actual realizations of time and location as examples.  There are minor typos, for e.g. line 357 is missing a \"that\", but this is not a major concern I have for this paper.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes integrating word sense inventories into existing approaches for the lexical substitution task by using these inventories to filter candidates. To do so, the authors first propose a metric to measure the mutual substitutability of sense inventories with human judgments for the lexsub task, and empirically measure the substitutability of inventories from various sources such as WordNet and PPDB. Next, they propose clustering different paraphrases of a word from PPDB using a multi-view clustering approach, to automatically generate a sense inventory instead of using the aforementioned inventories. Finally, they use these clusters with a naive (majority in top 5) WSD technique to filter existing ranked list of substitution candidates.  - Strengths:  * The key idea of marrying vector space model based approaches and sense inventories for the lexsub task is useful since these two techniques seem to have complementary information, especially since the vector space models are typically unaware of sense and polysemy.  * The oracle evaluation is interesting as it gives a clear indication of how much gain can one expect in the best case, and while there is still a large gap between the oracle and actual scores, we can still argue for the usefulness of the proposed approach due to the large difference between the unfiltered GAP and the oracle GAP.  - Weaknesses:  * I don't understand effectiveness of the multi-view clustering approach. Almost all across the board, the paraphrase similarity view does significantly better than other views and their combination. What, then, do we learn about the usefulness of the other views? There is one empirical example of how the different views help in clustering paraphrases of the word 'slip', but there is no further analysis about how the different clustering techniques differ, except on the task directly. Without a more detailed analysis of differences and similarities between these views, it is hard to draw solid conclusions about the different views.                                    * The paper is not fully clear on a first read. Specifically, it is not immediately clear how the sections connect to each other, reading more like disjoint pieces of work. For instance, I did not understand the connections between section 2.1 and section 4.3, so adding forward/backward pointer references to sections should be useful in clearing up things. Relatedly, the multi-view clustering section (3.1) needs editing, since the subsections seem to be out of order, and citations seem to be missing (lines 392 and 393).  * The relatively poor performance on nouns makes me uneasy. While I can expect TWSI to do really well due to its nature, the fact that the oracle GAP for PPDBClus is higher than most clustering approaches is disconcerting, and I would like to understand the gap better. This also directly contradicts the claim that the clustering approach is generalizable to all parts of speech (124-126), since the performance clearly isn't uniform.  - General Discussion:  The paper is mostly straightforward in terms of techniques used and experiments. Even then, the authors show clear gains on the lexsub task by their two-pronged approach, with potentially more to be gained by using stronger WSD algorithms.  Some additional questions for the authors :  * Lines 221-222 : Why do you add hypernyms/hyponyms? * Lines 367-368 : Why does X^{P} need to be symmetric? * Lines 387-389 : The weighting scheme seems kind of arbitrary. Was this indeed arbitrary or is this a principled choice? * Is the high performance of SubstClus^{P} ascribable to the fact that the number of clusters was tuned based on this view? Would tuning the number of clusters based on other matrices affect the results and the conclusions? * What other related tasks could this approach possibly generalize to? Or is it only specific to lexsub?",
            "output": [
                "en"
            ]
        },
        {
            "input": "Resumen: Este trabajo describe una experiencia del uso de un lenguaje \"gráfico\" en una escuela.  Evaluación: El tópico del trabajo es interesante, sin embargo, a) la descripción del trabajo es débil y b) los resultados parecen no repetibles.  Por ejemplo para a), la descripción no muestra ninguna imagen de cómo funciona el lenguaje (recordar que es un lenguaje gráfico). Un ejemplo de scratch es fuertemente recomendable para introducir el lenguaje.  Por ejemplo para b), no hay una clara descripción de la configuración de los experimentos, los resultados que se quieren medir y tabla para apreciar fácilmente los resultados obtenidos.  Detalles menores: a) El comienzo del abstract es súper complejo de entender b) Un excesivo uso de \"esto es\" c) algunas faltas de ortografía como \"preunta\" d) Oraciones muy largas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "In this paper, the authors explicitly design geometrical structure into a CNN by combining it with a Scattering network. This aids stability and limited-data performance. The paper is well written, the contribution of combining Scattering and CNNs is novel and the results seem promising. I feel that such work was a missing piece in the Scattering literature to make it useful for practical applications.  I wish the authors would have investigated the effect of the stable bottom layers with respect to adversarial examples. This can be done in a relatively straightforward way with software like cleverhans [1] or deep fool [2]. It would be very interesting if the first layer's stability in the hybrid architectures increases robustness significantly, as this would tell us that these fooling images are related to low-level geometry. Finding that this is not the case, would be very interesting as well.  Further, the proposed architecture is not evaluated on real limited data problems. This would further strengthen the improved generalization claim. However, I admit that the Cifar-100 / Cifar-10 difference already seems like a promising indicator in this regard.  If one of the two points above will be addressed in an additional experiment, I would be happy to raise my score from 6 to 7.  Summary:   + An interesting approach is presented that might be useful for real-world limited data scenarios. + Limited data results look promising. - Adversarial examples are not investigated in the experimental section. - No realistic small-data problem is addressed.  Minor: - The authors should add a SOTA ResNet to Table 3, as NiN is indeed out of fashion these days. - Some typos: tacke, developping, learni.  [1]",
            "output": [
                "en"
            ]
        },
        {
            "input": "Summary of the paper  The paper studies the invertiblity of convolutional neural network in the random model. A reconstruction algorithm similar to IHT is proposed for layer-wise inversion of the network.    Clarity:  - The paper is confusing wrt to standard notations in deep learning.  Comments:  The paper makes two simplifications in the analysis of a CNN, that makes it map to a model based compressive sensing framework:  1-  The non linearity (RELU) is dropped. This is a big simplification, for random gaussian weights for instance we know by JL that we can preserve L_2 distance, when RELU is applied the metric changes (see for instance the kernel for n=1 in",
            "output": [
                "en"
            ]
        },
        {
            "input": "Me parece un artículo interesante de ser considerado, aunque el objetivo final del mismo es algo oscuro: \"medir la posición de robot en un campo de futbol\". En particular, no es claro si el trabajo se orienta a un objetivo posterior más ambicioso (múltiples robots, movimiento del equipo en tiempo real, y que hacer finalmente con estos datos???).  Por lo que puede deducirse, aunque no es explícitamente dicho, se hicieron mediciones de \"un\" robot \"ubicándolo\" en diferentes posiciones del campo, pero no con este moviéndose en tiempo real. Se presentan así resultados, que podrían haberse obtenido con otra configuración más clásica del área de visión computacional (el aporte del robot y el campo de futbol, al menos hasta ahora no tienen una relevancia fundamental en el trabajo desarrollado).  Finalmente, no me parece que los resultados obtenidos sean estrictamente novedosos, pero aun así puede ser una experiencia atractiva de ser conocida.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Strengths:  - Innovative idea: sentiment through regularization - Experiments appear to be done well from a technical point of view - Useful in-depth analysis of the model  Weaknesses:  - Very close to distant supervision - Mostly poorly informed baselines  General Discussion:  This paper presents an extension of the vanilla LSTM model that incorporates sentiment information through regularization.  The introduction presents the key claims of the paper: Previous CNN approaches are bad when no phrase-level supervision is present. Phrase-level annotation is expensive. The contribution of this paper is instead a \"simple model\" using other linguistic resources.  The related work section provides a good review of sentiment literature. However, there is no mention of previous attempts at linguistic regularization (e.g., [YOG14]).  The explanation of the regularizers in section 4 is rather lengthy and repetitive. The listing on p. 3 could very well be merged with the respective subsection 4.1-4.4. Notation in this section is inconsistent and generally hard to follow. Most notably, p is sometimes used with a subscript and sometimes with a superscript.  The parameter \\beta is never explicitly mentioned in the text. It is not entirely clear to me what constitutes a \"position\" t in the terminology of the paper. t is a parameter to the LSTM output, so it seems to be the index of a sentence. Thus, t-1 is the preceding sentence, and p_t is the prediction for this sentence. However, the description of the regularizers talks about preceding words, not sentences, but still uses. My assumption here is that p_t is actually overloaded and may either mean the sentiment of a sentence or a word. However, this should be made clearer in the text.  One dangerous issue in this paper is that the authors tread a fine line between regularization and distant supervision in their work. The problem here is that there are many other ways to integrate lexical information from about polarity, negation information, etc. into a model (e.g., by putting the information into the features). The authors compare against a re-run or re-implementation of Teng et al.'s NSCL model. Here, it would be important to know whether the authors used the same lexicons as in their own work. If this is not the case, the comparison is not fair. Also, I do not understand why the authors cannot run NSCL on the MR dataset when they have access to an implementation of the model. Would this not just be a matter of swapping the datasets? The remaining baselines do not appear to be using lexical information, which makes them rather poor. I would very much like to see a vanilla LSTM run where lexical information is simply appended to the word vectors.  The authors end the paper with some helpful analysis of the models. These experiments show that the model indeed learns intensification and negation to some extent. In these experiments, it would be interesting to know how the model behaves with out-of-vocabulary words (with respect to the lexicons). Does the model learn beyond memorization, and does generalization happen for words that the model has not seen in training? Minor remark here: the figures and tables are too small to be read in print.  The paper is mostly well-written apart from the points noted above.  It could benefit from some proofreading as there are some grammatical errors and typos left. In particular, the beginning of the abstract is hard to read.  Overall, the paper pursues a reasonable line of research. The largest potential issue I see is a somewhat shaky comparison to related work. This could be fixed by including some stronger baselines in the final model. For me, it would be crucial to establish whether comparability is given in the experiments, and I hope that the authors can shed some light on this in their response.  [YOG14] [Link]  --------------  Update after author response  Thank you for clarifying the concerns about the experimental setup.   NSCL: I do now believe that the comparison is with Teng et al. is fair.  LSTM: Good to know that you did this. However, this is a crucial part of the paper. As it stands, the baselines are weak. Marginal improvement is still too vague, better would be an open comparison including a significance test.  OOV: I understand how the model is defined, but what is the effect on OOV words? This would make for a much more interesting additional experiment than the current regularization experiments.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper introduces a maximum total correlation procedure, adds a target and then adds noise perturbations.  Technical issues:  The move from (1) to (2) is problematic. Yes it is a lower bound, but by igoring H(Z), equation (2) ignores the fact that H(Z) will potentially vary more significantly that H(Z|Y). As a result of removing H(Z), the objective (2) encourages Z that are low entropy as the H(Z) term is ignored, doubly so as low entropy Z results in low entropy Z|Y. Yes the -H(X|Z) mitigates against a complete entropy collapse for H(Z), but it still neglects critical terms. In fact one might wonder if this is the reason that semantic noise addition needs to be done anyway, just to push up the entropy of Z to stop it reducing too much.  In (3) arbitrary balancing paramters lamda_1 and lambda_2 are introduced ex-nihilo - they were not there in (2). This is not ever justified.  Then in (5), a further choice is made by simply adding L_{NLL} to the objective. But in the supervised case, the targets are known and so turn up in H(Z|Y). Hence now H(Z|Y) should be conditioned on the targets. However instead another objective is added again without justification, and the conditional entropy of Z is left disconnected from the data it is to be conditioned on. One might argue the C(X,Y,Z) simply acts as a prior on the networks (and hence implicitly on the weights) that we consider, which is then combined with a likelihood term, but this case is not made. In fact there is no explicit probabilistic or information theoretic motivation for the chosen objective.  Given these issues, it is then not too surprising that some further things need to be done, such as semantic noise addition to actually get things working properly. It may be the form of noise addition is a good idea, but given the troublesome objective being used in the first place, it is very hard to draw conclusions.  In summary, substantially better theoretical justification of the chosen model is needed, before any reasonable conclusion on the semantic noise modelling can be made.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper provides a new perspective to understanding the ResNet and Highway net. The new perspective assumes that the blocks inside the networks with residual or skip-connection are groups of successive layers with the same hidden size, which performs to iteratively refine their estimates of the same feature instead of generate new representations. Under this perspective, some contradictories with the traditional representation view induced by ResNet and Highway network and other paper can be well explained.  The pros of the paper are: 1. A novel perspective to understand the recent progress of neural network is proposed. 2. The paper provides a quantitatively experimentals to compare ResNet and Highway net, and shows contradict results with several claims from previous work. The authors also give discussions and explanations about the contradictories, which provides a good insight of the disadvantages and advantages between these two kind of networks.  The main cons of the paper is that the experiments are not sufficient. For example, since the main contribution of the paper is to propose the “unrolled iterative estimation\" and the stage 4 of Figure 3 seems not follow the assumption of \"unrolled iterative estimation\" and the authors says: \"We note that stage four (with three blocks) appears to be underestimating the representation values, indicating a probable weak link in the architecture.\". Thus, it would be much better to do experiments to show that under some condition, the performance of stage 4 can follow the assumption.   Moreover, the paper should provide more experiments to show the evidence of \"unrolled iterative estimation\", not comparing ResNet with Highway Net. The lack of experiments on this point is the main concern from myself.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper propose to find an optimal decoder for binary data using a min-max decoder on the binary hypercube given a linear constraint on the correlation between the encoder and the  data.  The paper gives finally that the optimal decoder as logistic of the lagragian W multiplying the encoding e.   Given the weights of the ‘min-max’decoder W the paper finds the best encoding for the data distribution considered, by minimizing that error as a function of the encoding.  The paper then alternates that optimization between the encoding and the min-max decoding, starting from random weights W.   clarity:  -The paper would be easier to follow if the real data (x in section 3 ) is differentiated from the worst case data played by the model (x in section 2).    significance  Overall I like the paper, however I have some doubts on what the alternating optimization optimum ends up being.  The paper ends up implementing a single layer network. The correlation constraints while convenient in the derivation, is  a bit intriguing. Since linear relation between the encoding and the data  seems to be weak modeling constraint and might be not different from what PCA would implement.  - what is the performance of PCA on those tasks? one could you use a simple sign function to decode. This is related to one bit compressive sensing.  - what happens if you initialize W in algorithm one with PCA weights? or weighted pca weights?  - Have you tried on more complex datasets such as cifar?",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este artículo presenta una comparación, en base a una lista de criterios, de dos enfoques de bases de datos: relacional vs. temporal.  El artículo en general tiene un orden lógico y es legible. No obstante, la comparativa presenta al menos dos inconvenientes:  1) falta mucha información de cómo se obtuvieron los resultados de las tablas 3 y 4. Debe existir una descripción suficientemente detallada para luego poder replicar el trabajo.  2) El caso de estudio que se presenta forma la base de la comparación. Una real comparación debe sustentarse en una variedad de casos y dominios, para poder luego concluir con una base más amplia.  Sugiero abordar estos dos aspectos primero para sustentar mejor los resultados y conclusiones.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper describes an idea to learn phrasal representation and facilitate them in RNN-based language models and neural machine translation  -Strengths:  The  idea to incorporate phrasal information into the task is interesting.  - Weaknesses:  - The description is hard to follow. Proof-reading by an English native speaker would benefit the understanding - The evaluation of the approach has several weaknesses  - General discussion  - In Equation 1 and 2 the authors mention a phrase representation give a fix-length word embedding vector. But this is not used in the model. The representation is generated based on an RNN. What the propose of this description? - Why are you using GRU for the Pyramid and LSTM for the sequential part? Is the combination of two architectures a reason for your improvements? - What is the simplified version of the GRU? Why is it performing better? How is it performing on the large data set? - What is the difference between RNNsearch (groundhog) and RNNsearch(baseline) in Table 4? -  What is the motivation for only using the ending phrases and e.g. not using the starting phrases? - Did you use only the pyramid encoder? How is it performing? That would be a more fair comparison since it normally helps to make the model more complex. - Why did you run RNNsearch several times, but PBNMT only once?  - Section 5.2: What is the intent of this section",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es un estudio del estado del arte de control distribuido multi robot. Lamentablemente estamos ante la presencia preliminar de la investigación, por lo que sus referencias son de acuerdo al avance. El problema es que no se percibe el problema a solucionar de manera específica, si manifiesta la intensión futura de una línea de trabajo, indicando espacios abiertos para investigar.  Se nota falta de preparación del trabajo, se utilizan nemónicos que no se definen previamente.  Se debe evitar escribir en primera persona.  Las referencias están apropiadas, pero con poco análisis, las cuales podrían hacerlo más interesante el trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo se titula \"Madurez actual del desarrollo de la automatización de las pruebas del software\". El documento muestra una serie de apartados que dan cuenta de un trabajo realizado en términos de revisión de literatura y algunos acercamientos a una propuesta para restructurar una escala de niveles de madurez particular para el proceso de automatización de pruebas.  Sin embargo, el trabajo carece de una estructura lógica que permita determinar si su aporte u objetivo principal está en la revisión de literatura o en la propuesta de nuevos niveles de madurez para el proceso de pruebas.  Se recomienda hacer una revisión completa de la información que se presenta y posiblemente re-estructurar el documento presentado. El reporte de esta revisión fue divido por secciones, con el fin de aportar sugerencia que permitan mejorar el trabajo.   Sección -Revisión sistemática  Es importante que los autores revisen el hecho de utilizar un método de revisión sistemática que aún no está publicado existiendo varios métodos publicados, probados y reconocidos para ingeniería de Software. Deberían justificar la selección del método propuesto por Serna M. identificado con el número [16] en el trabajo.  Es indispensable explicar la validación que se hace respecto a la revisión por pares de los artículos, pues no es claro cómo puede tenerse acceso a una revisión por pares de los artículos publicados para poder validarlos y de qué forma se realiza un proceso de validación a partir de dicha información, teniendo en cuenta la cantidad de revisiones que tendría que hacerse por cada artículo encontrado (978).  Automatización de pruebas  Si bien, en el trabajo se reporta un modelo propuesto para evaluar la madurez del proceso de automatización de pruebas de software. El modelo como tal no está descrito. El artículo se limita a presentar una escala de referencia asociada a la madurez de un ser humano. Por tanto, es indispensable que el artículo indique varios aspectos para considerar la estructuración y definición de un modelo. Dentro de los aspectos más importantes a considerar están:  1. Una justificación científica y formal sobre la cual los autores del trabajo se basen para proponer el modelo de madurez y la selección de los niveles de madurez de un ser humano como punto de comparación con un posible nivel de madurez del proceso de automatización de pruebas.  2. Justificación formal de por qué no usar el modelo CMMI y la estructura de niveles de madurez que en él se proponen para evaluar el proceso de automatización de pruebas. Lo anterior, teniendo en cuenta que el modelo de madurez define una escala de madurez apropiada para evaluar procesos en ingeniería de software. Es decir, ¿por qué es necesario replantear esos niveles de madurez para el proceso de automatización de pruebas y proponer una nueva escala basada en la madurez de un ser humano?  3. A nivel de investigación cómo se caracterizan los niveles de madurez en términos de la automatización de pruebas?. Si bien, en el artículo se caracteriza cada nivel indicando las posibles características en las que está el proceso de automatización de pruebas, no se indica cómo se determinó dicha caracterízación, ni se muestra una justificación formal y científica relacionada.  Trabajo relacionado  El trabajo presenta una revisión sistemática, bajo la cual es posible identificar trabajo relacionado con el área de estudio, en este caso automatización de pruebas o niveles de madurez para la automatización de pruebas. Sin embargo, los autores presentan la revisión sistemática aparte de la sección trabajo relacionado, cuando pareciera que los estudios seleccionados como trabajo relacionado deberían ser parte del análisis de resultados de la revisión sistemática.  Además, la revisión sistemática permite determinar vacíos o nichos de investigación (oportunidades de investigación) para determinar una área de trabajo con alguna problemática concreta y, a partir de ahí, proponer una posible solución a dicho problema. En este caso, el artículo presenta la revisión sistemática como un trabajo adicional y posterior a la propuesta de niveles de madurez para el proceso de automatización de pruebas.  Así mismo, los autores muestran la selección de algunos trabajos relacionados, se entiende que son relacionados con la automatización de pruebas, no obstante del primero Michael Grottke, indican precisamente que no se enfoca en el tema a tratar en el trabajo que presentan sino en una propuesta estadística de la automatización de pruebas. Por lo tanto no entraría como trabajo relacionado.   Madurez del desarrollo de la automatización de las pruebas del software   Para realizar una comparación del proceso de automatización de pruebas y los niveles de madurez, los autores presentan la Tabla 3. En ella se indica que en la primera columna se ubican las etapas tradicionales de un proceso de pruebas. Es necesario indicar bajo qué metodología se seleccionan estas etapas como tradicionales o tener una referencia como justificación para la selección de estas y no otras etapas.  En este apartado no existe una explicación clara de la determinación sobre los niveles de madurez en cada etapa. Es indispensable tener descrito el análisis de investigación realizado que da como resultado la definición del nivel de madurez en que se encuentra cada una de las etapas del proceso de pruebas. La tabla no es suficiente explicación para el análisis, pues solo reporta los resultados.  En este punto, si lo que se busca es proponer una nueva escala de madurez para el proceso de pruebas o automatización de pruebas, lo más conveniente es validar dicha escala propuesta con un caso de estudio. En este trabajo, si bien, los autores muestran una tabla donde parecen determinar que el nivel de madurez es \"adolecente\", no se logra comprender en qué contexto se está evaluando el proceso de automatización de pruebas. Debería, al menos, contextualizarse un caso donde se indique: región, tiempo, tipo de proyectos o empresas y metodología utilizada para evaluar el proceso de automatización de pruebas. Lo anterior es la base para justificar que en determinado contexto el proceso de automatización de pruebas se encuentra en X nivel de madurez (de la escala propuesta). Argumentando, además, los criterios que se tuvieron en cuenta para asignar dicho nivel de madurez.",
            "output": [
                "es"
            ]
        },
        {
            "input": "es interesante constatar la preocupación de personas individuales que se preocupen de la seguridad y el mejor servicio que pueda brindar la empresa.   La figura 1 no es auto explicativa en términos de explicar los componentes del sistema, por ejemplo, TVL, que está a bordo de las locomotoras. Los Acrónimos definidos no presentan o representan su origen o fuente. Por ejemplo, VHF, SMS, XML, GPS, PLC, los que carecen de significado. Se dice que la información está disponible en diagramas y herramientas como Google Earth, cómo así.? Acaso, permite visualizar imágenes en 3D, combina imágenes de satélite, mapas y el motor de búsqueda de Google, permitiendo ver imágenes a escala de un lugar específico de la ruta.?.es eso lo que se logró?. Existen una serie de conclusiones, las cuales no son documentadas. Se dice, presentó un alza de 6%, sobre cuánto?. ¿Cómo son o cómo se obtienen los indicadores de eficiencia.? Bibliografía, mal citada.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper introduces a general method for improving NLP tasks using embeddings from language models. Context independent word representations have been very useful, and this paper proposes a nice extension by using context-dependent word representations obtained from the hidden states of neural language models. They show significant improvements in tagging and chunking tasks from including embeddings from large language models. There is also interesting analysis which answers several natural questions.  Overall this is a very good paper, but I have several suggestions: - Too many experiments are carried out on the test set. Please change Tables 5 and 6 to use development data - It would be really nice to see results on some more tasks - NER tagging and chunking don't have many interesting long range dependencies, and the language model might really help in those cases. I'd love to see results on SRL or CCG supertagging. - The paper claims that using a task specific RNN is necessary because a CRF on top of language model embeddings performs poorly. It wasn't clear to me if they were backpropagating into the language model in this experiment - but if not, it certainly seems like there is potential for that to make a task specific RNN unnecessary.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo se deja leer con facilidad, en especial en su primera mitad. Luego, hay errores de escritura y redacción que van afectando la comprensión de lo realizado (PostgrSQL en vez de PostgresSQL, con tiene en vez de contiene, ...). Adicionalmente se detallan pasos, que caen en detalles irrelevantes, como indicar que debe instalarse tal o cual herramienta, sin entrar en los aspectos realmente importantes, especialmente en la implementación del acoplamiento medio (donde, no se detalla que se implementó a nivel del SABD y que a nivel externo). Lo más criticable es el uso de dos SABD (PostgreSQL para el acoplamiento débil, y Oracle para los acoplamientos medio y fuerte) en la experimentación, esto hace que sea muy discutible la comparación que, ya no sólo tienen la implementación del algoritmo como variable independiente, sino también el SABD a utilizar.  Pse a lo anterior, pienso que el trabajo es digno de ser presentado, de forma de mostrar, en particular, las diferentes alternativas de integración de algoritmos de Minería de Datos con Sistemas Administradores de Bases de Datos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Los autores presentan una aproximación para resolver problemas de programación de proyectos con recursos limitados (RCPSP) a través de un algoritmo de colonia artificial de abejas (ABC).  La idea parece relevante para el problema enfrentado. Sin embargo es importante hacer las siguientes mejoras al documento:  - Establecer claramente que la aplicación de ABC en RCPSP es algo que no se ha realizado antes. De no ser así, agregar un análisis comparativo de la solución propuesta frente a otras similares.  - El enlace [Link] está roto. Reemplazar por un enlace que no lo esté.  - En las tablas no es claro qué es el Makespan. Es la duración del schedule \"canónico\" para ese problema? Es la duración del schedule teórico óptimo? Es la duración del schedule del mejor algoritmo para es problema? Es la duración obtenida por el algoritmo ABC-RCPSP? Explicar esto con precisión  - Sería recomendable tener una descripción cuantitativa breve del desempeño del algoritmo en términos de tiempo vs tamaño del problema.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This is a developed application to support information with sounds. Although it is a particular situation to aid with the use of sounds, it does not presents new knowledge in any areas or has any type of empirical validation; one from the user point of view might add some value.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es un proyecto de alta envergadura que necesita ser conocido por la comunidad académica  Colocará en la presentación los valores del proyecto",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper explores the topic of intrinsic motivation in the context of deep RL. It proposes a couple of variants derived from an auxiliary model-learning process (prediction error, surprise and learning progress), and shows that those can help exploration on a number of continuous control tasks (and the Atari game “venture”, maybe).  Novelty: none of the proposed types of intrinsic motivation are novel, and it’s arguable whether the application to deep RL is novel (see e.g. Kompella et al 2012).  Potential: the idea of seeking out states where a transition model is uncertain is sensible, but also limited -- I would encourage the authors to also discuss the limitations. For example in a game like Go the transition model is trivially learned, so this approach would revert to random exploration. So other forms of learning progress or surprise derived from the agent’s competence instead might be more promising in the long run? See also Srivastava et al 2012 for further thoughts.  Computation time: I find the paper’s claimed superiority over VIME to be overblown: the gain seems to stem almost exclusively from a faster initialization, but have very similar per-step cost? So given that VIME is also performing very competitively, what arguments can you advance for your own method(s)?",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper presents a system approach to combine multiple modalities to perform classification in a practical scenario (e-commerce).  In general, I find the proposed approach in the paper sound and solid, but do not see novelty in the paper: feature fusion and decision time fusion are both standard practices in multi-modal analysis, and the rest of the paper offers no surprise in implementing such approaches. This seems to be a better fit for venues that focus more on production systems, and seems to be a bad fit for ICLR where the focus is more on research of novel algorithms and theories.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta un experimento que compara distintas arquitecturas de navegación para un robot móvil. Se describen las arquitecturas (algoritmos, enfoques) utilizados, así como las métricas definidas para evaluar la performance en la navegación. Los resultados son analizados estadísticamente utilizando análisis de varianza.  El artículo está bien escrito y el experimento se presenta en forma clara. Las referencias bibliográficas parecen son adecuadas. En la introducción se justifica correctamente los objetivos de comparación y se describen en forma general los enfoques posibles para la navegación de un robot.  La selección de métricas está justificada e intenta ir más allá de una combinación de mediciones simples. El experimento está bien descrito, aunque se podría explicar por qué no se incluyeron otras configuraciones de obstáculos en la observación. Los métodos estadísticos (análisis de varianza) están aplicados correctamente, aunque se podría incluir un análisis de la normalidad en la distribución.  Uno de los puntos débiles del trabajo es que hace falta una discusión más profunda de los resultados. Más allá de indicar que uno de las arquitecturas tiene mejor rendimiento, se debería discutir las razones y realizar nuevas conjeturas.  La generalización de los resultados y la discusión de amenazas a la validez debe ser parte de la discusión. Por ejemplo: ¿En qué tipo de obstáculos funciona mejora cada algoritmo? ¿Cuál es el esfuerzo de programación de cada uno de las arquitecturas? ¿Cuáles son los objetivos de navegación de alto nivel del robot (comportamiento deliberativo)?",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo está muy bien escrito y se lee con facilidad, teniendo básicamente características de un artículo de divulgación.  Se discuten aspectos centrados esencialmente en los problemas de recuperación de información ante el crecimiento exponencial de los datos. La propuesta realizada al final del artículo es interesante, aunque, desde mi punto de vista la inclusión del tema Big Data está dado con cierta liviandad y requiere un análisis más detallado de lo que se describe.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths:  This paper presents a 2 x 2 x 3 x 10 array of accuracy results based on systematically changing the parameters of embeddings models:  (context type, position sensitive, embedding model, task), accuracy  - context type ∈ {Linear, Syntactic} - position sensitive ∈ {True, False} - embedding model ∈ {Skip Gram, BOW, GLOVE} - task ∈ {Word Similarity, Analogies, POS, NER, Chunking, 5 text classific. tasks}  The aim of these experiments was to investigate the variation in performance as these parameters are changed. The goal of the study itself is interesting for the ACL community and similar papers have appeared before as workshop papers and have been well cited, such as Nayak et al.'s paper mentioned below.  - Weaknesses: Since this paper essentially presents the effect of systematically changing the  context types and position sensitivity, I will focus on the execution of the investigation and the analysis of the results, which I am afraid is not  satisfactory.  A) The lack of hyper-parameter tuning is worrisome. E.g.    - 395 Unless otherwise notes, the number of word embedding dimension is set to 500.    - 232 It still enlarges the context vocabulary about 5 times in practice.    - 385 Most hyper-parameters are the same as Levy et al' best configuration.    This is worrisome because lack of hyperparameter tuning makes it difficult to make statements like method A is better than method B. E.g. bound methods may perform better with a lower dimensionality than unbound models, since their effective context vocabulary size is larger.  B) The paper sometimes presents strange explanations for its results. E.g.    - 115 \"Experimental results suggest that although it's hard to find any  universal insight, the characteristics of different contexts on different models are concluded according to specific tasks.\"     What does this sentence even mean?      - 580 Sequence labeling tasks tend to classify words with the same syntax  to the same category. The ignorance of syntax for word embeddings which  are learned by bound representation becomes beneficial.      These two sentences are contradictory, if a sequence labeling task    classified words with \"same syntax\" to same category then syntx becomes    a ver valuable feature. Bound representation's ignorance of syntax    should cause a drop in performance just like other tasks which does not    happen.  C) It is not enough to merely mention Lai et. al. 2016 who have also done a    systematic study of the word embeddings, and similarly the paper     \"Evaluating Word Embeddings Using a Representative Suite of Practical    Tasks\", Nayak, Angeli, Manning. appeared at the repeval workshop at     ACL 2016. should have been cited. I understand that the focus of Nayak    et al's paper is not exactly the same as this paper, however they    provide recommendations about hyperparameter tuning and experiment    design and even provide a web interface for automatically running    tagging experiments using neural networks instead of the \"simple linear    classifiers\" used in the current paper.  D) The paper uses a neural BOW words classifier for the text classification tasks    but a simple linear classifier for the sequence labeling tasks. What is    the justification for this choice of classifiers? Why not use a simple    neural classifier for the tagging tasks as well? I raise this point,    since the tagging task seems to be the only task where bound    representations are consistently beating the unbound representations,    which makes this task the odd one out.   - General Discussion: Finally, I will make one speculative suggestion to the authors regarding the analysis of the data. As I said earlier, this paper's main contribution is an analysis of the following table. (context type, position sensitive, embedding model, task, accuracy) So essentially there are 120 accuracy values that we want to explain in terms of the aspects of the model. It may be beneficial to perform factor analysis or some other pattern mining technique on this 120 sample data.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The authors propose a Gated Muiltimodal Unit to combine multi-modal information (visual and textual). They also collect a large dataset of movie summers and posters. Overall, the reviewers were quite positive, while AR4 points to related models and feels that the contribution in the current version is too weak for ICLR. The AC read the paper and the authors responses but tends to agree with AR4. The authors are encouraged to strengthen their work and resubmit to a future conference.",
            "output": [
                "en"
            ]
        },
        {
            "input": "-\tEl tema es de relevancia científica. -\tEn el trabajo se desarrolló un análisis de la literatura sobre calidad de datos en las aplicaciones de e-government municipal. -\tMetodológicamente existen tres limitaciones importantes a superar. Primero, no se ha considerado el factor de impacto de la publicaciones, con lo cual se ha desestimado el desarrollo asociado a este tipo de revisiones, mezclando trabajos de alto impacto (ejemplo, artículos de revistas ISIs factor de impacto >2, como MISQ) con trabajos sin una revisión de calidad (ejemplo, lo que Scholar \"lanza\" sólo por coincidir en la búsqueda). Segundo, se dice que se tomarán referencias del 2008 en adelante prioritariamente, pero muchas de sus referencias  son de antes de esa fecha, y eso no es raro, pues entre 2001 y 2004 hay una explosión de trabajos en este ámbito específico. Tercero, no se han incluido explícitamente trabajos de conferencias del área de alto impacto en la comunidad científica como AMCIS o ECIS (la primera tiene una base de datos privada, no accesible por google y la segunda es libre). -\tLas limitaciones antes expuestas restringen los alcances de los interesantes  resultados expuestos en el trabajo. -\tFinalmente, se sugiere avanzar en las escalas de medida de dimensiones seleccionadas  antes de desarrollar caso de estudio indicado en las conclusiones.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Strengths -- An interesting proposal for a smaller CNN architecture designed for embedded CNN applications.  -- Balanced exploration of CNN macroarchitecture and microarchitecture with fire modules. -- x50 less memory usage than AlexNet, keeping similar accuracy  -- strong experimental results  Weaknesses --Would be nice to test Sqeezenet on multiple tasks  --lack of insights and rigorous analysis into what factors are responsible for the success of SqueezeNet. For example, how are ResNet and GoogleNet connected to the current architecture? Another old paper (Analysis of correlation structure for a neural predictive model with application to speech recognition, Neural Networks, 1994) also showed that the “by-pass” architecture by mixing linear and nonlinear prediction terms improves long term dependency in NN based on rigorous perturbation analysis. Can the current work be placed more rigorously on theoretical analysis?",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper proposes a model that aims at learning to label nodes of graph in a semi-supervised setting. The idea of the model is based on the use of the graph structure to regularize the representations learned at the node levels. Experimental results are provided on different tasks  The underlying idea of this paper (graph regularization) has been already explored in different papers – e.g 'Learning latent representations of nodes for classifying in heterogeneous social networks' [Jacob et al. 2014],   [Weston et al 2012] where a real graph structure is used instead of a built one. The experiments lack of strong comparisons with other graph models (e.g Iterative Classification, 'Learning from labeled and unlabeled data on a directed graph', ...). So the novelty of the paper and the experimental protocol are not strong enough to accpet the paper.  Pros: * Learning over graph is an important topic  Cons: * Many existing approaches have already exploited the same types of ideas, resulting in very close models * Lack of comparison w.r.t existing models",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper develops a differentiable interpreter for the Forth programming language. This enables writing a program \"sketch\" (a program with parts left out), with a hole to be filled in based upon learning from input-output examples. The main technical development is to start with an abstract machine for the Forth language, and then to make all of the operations differentiable. The technique for making operations differentiable is analogous to what is done in models like Neural Turing Machine and Stack RNN. Special syntax is developed for specifying holes, which gives the pattern about what data should be read when filling in the hole, which data should be written, and what the rough structure of the model that fills the hole should be. Motivation for why one should want to do this is that it enables composing program sketches with other differentiable models like standard neural networks, but the experiments focus on sorting and addition tasks with relatively small degrees of freedom for how to fill in the holes.  Experimentally, result show that sorting and addition can be learned given strong sketches.  The aim of this paper is very ambitious: convert a full programming language to be differentiable, and I admire this ambition. The idea is provocative and I think will inspire people in the ICLR community.  The main weakness is that the experiments are somewhat trivial and there are no baselines. I believe that simply enumerating possible values to fill in the holes would work better, and if that is possible, then it's not clear to me what is practically gained from this formulation. (The authors argue that the point is to compose differentiable Forth sketches with neural networks sitting below, but if the holes can be filled by brute force, then could the underlying neural network not be separately trained to maximize the probability assigned to any filling of the hole that produces the correct input-output behavior?)  Related, one thing that is missing, in my opinion, is a more nuanced outlook of where the authors believe this work is going. Based on the small scale of the experiments and from reading other related papers in the area, I sense that it is hard to scale up differentiable forth to large real-world problems. It would be nice to have more discussion about this, and perhaps even an experiment that demonstrates a failure case. Is there a problem that is somewhat more complex than the ones that appear in the paper where the approach does not work? What has been tried to make it work? What are the failure modes? What are the challenges that the authors believe need to be overcome to make this work.  Overall, I think this paper deserves consideration for being provocative. However, I'm hesitant to strongly recommend acceptance because the experiments are weak.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes a character-aware attention residual network for sentence embedding. Several text classification tasks are used to evaluate the effectiveness of the proposed model. On two of the three tasks, the residual network outforms a few baselines, but couldn't beat the simple TFIDF-SVM on the last one.  This work is not novel enough. Character information has been applied in many previously published work, as cited by the authors. Residual network is also not new.  Why not testing the model on a few more widely used datasets for short text classification, such as TREC? More competitive baselines can be compared to. Also, it's not clear how the \"Question\" dataset was created and which domain it is.  Last, it is surprising that the format of citations throughout the paper is all wrong.   For example: like Word2Vec Mikolov et al. (2013) -> like Word2Vec (Mikolov et al., 2013)  The citations can't just mix with the normal text. Please refer to other published papers.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper shows that a deep RL approach augmented with auxiliary tasks improves performance on navigation in complex environments. Specifically, A3C is used for the RL problem, and the agent is simultaneously trained on an unsupervised depth prediction task and a self-supervised loop closure classification task. While the use of auxiliary tasks to improve training of models including RL agents is not new, the main contribution here is the use of tasks that encourage learning an intrinsic representation of space and movement that enables significant improvements on maze navigation tasks.  The paper is well written, experiments are convincing, and the value of the auxiliary tasks for the problem are clear. However, the contribution is relatively incremental given previous work on RL for navigation and on auxiliary tasks. The work could become of greater interest provided broader analysis and insights on either optimal combinations of tasks for visual navigation (e.g. the value of other visual / geometry-based tasks), or on auxiliary tasks with RL in general.  As it is, it is a useful demonstration of the benefit of geometry-based auxiliary tasks for navigation, but of relatively narrow interest.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Correcciones a artículo: “Manejo de información, un continuo reto de la tecnología”. Evaluación general  El trabajo es interesante pero falta algo de implementación, pues en general es una buena revisión a la literatura existente. Al leer el artículo da la impresión que falta algo (la implementación). Se debería haber planteado un esquema con el modelo que se propone y eso dejaría más claro la buena intención de la investigación que se hará a futuro. El trabajo actualmente es una revisión a la literatura con la presentación de una intención de investigación. Un mejor título habría sido una revisión al estado del arte en……ABC o indicar propuesta de modelo XYZ   Correcciones de Formato Verificar el orden que pide  revista Ingeniare, en cuanto a las referencias.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Los autores han diseñado una metodología para desarrollar software de apoyo a proyectos de investigación científica. Identifican con bastante precisión las diferencias entre el desarrollo de software de investigación y software con fines comerciales. Asimismo, proponen una metodología siguiendo un enfoque de métodos ágiles de desarrollo de software.  La propuesta se encuentra en una fase de diseño, ha sido elaborada a partir de entrevistas a potenciales usuarios y es susceptible de ser probada en investigaciones futuras.  En mi opinión, en el artículo hace falta un apartado que dé cuenta de la metodología que los autores siguieron para llegar a la propuesta. Se hace referencia a entrevistas a: \"participantes en este tipo de proyectos\", no obstante, no se informa  cuántas personas fueron consultadas, cómo se seleccionó a los entrevistados, qué instrumentos se aplicaron y cómo se analizaron los datos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This is an 18 page paper plus appendix which presents a mathematical derivation for infomax for an actual neural population with noise.  The original Bell & Sejnowski infomax framework only considered the no noise case.  Results are shown for natural image patches and the mnist dataset, which qualitatively resemble results obtained with other methods.  This seems like an interesting and potentially more general approach to unsupervised learning.  However the paper is quite long and it was difficult for me to follow all the twists and turns.  For example the introduction of the hierarchical model was confusing and it took several iterations to understand where this was going.  'Hierarchical' is probably not the right terminology here because it's not like a deep net hierarchy, it's just decomposing the tuning curve function into different parts.  I would recommend that the authors try to condense the paper so that the central message and important steps are conveyed in short order, and then put the more complete mathematical development into a supplementary document.  Also, the authors should look at the work of Karklin & Simoncelli 2011 which is highly related.  They also use an infomax framework for a noisy neural population to derive on and off cells in the retina, and they show the conditions under which orientation selectivity emerges.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo describe los conceptos de data warehouse y minería de datos, luego plantea unos pasos para describir un proceso simple de reposición de stock para un caso de empresa distribuidora de gas licuado. Solo se queda en el discurso y no plantea algo concreto. No es un trabajo que genere un aporte científico y no es relevante para el congreso",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta una propuesta interesante para evaluar el paradigma de desarrollo de software orientado a agentes y aunque es un trabajo en curso tiene buenas bases.  Se sugiere volver a redactar el Resumen de manera que sea más comprensible, utilizando de nuevo los sustantivos cuando sea necesario y con una estructura menos rígida.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta un caso de estudio de aplicación de una plantilla para medir calidad según la norma ISO 9126. Si bien es cierto se ajusta a los alcances del evento y su propuesta puede ser de interés para los ingenieros de software que deseen tener algún instrumento práctico para aplicar en sus sistemas de calidad, el trabajo tiene serias deficiencias que deben ser mejorados para ser publicado.  La presentación técnica del documento tiene falencias que no cumplen las normas establecidas para escribir el artículo. En particular, podemos mencionar algunas:  - El formato no es uniforme como puede verse en el abstract que tiene ajustes diferentes en su extensión. También hay diferencias en el espacio después de cada párrafo. A veces existe y a veces no. Las viñetas tienen diferentes sangrías. Las referencias bibliográficas tienen diferentes sangrías.  - Lo más grave es la ortografía y redacción. El documento requiere una profunda revisión de edición. En sólo los dos primeros párrafos de la introducción he encontrado más de 5 faltas.  Respecto a su estructura creo que debe ser reorganizada para mejorar su presentación. Creo que los objetivos deben ir dentro de la introducción. La presentación de los criterios de la ISO deben ser resumidos en una tabla descriptiva. Es latosamente extensa y creo que puede ser referenciada para ver detalles. Por otro lado, creo que debería aclararse si la plantilla es preexistente o es una propuesta del trabajo, en cuyo caso debería ser resaltado ya que sería la contribución principal del artículo. Su presentación es desafortunada. Creo que debe ser resumida en una tabla y estipular claramente lo que puede responderse. La mayoría ni siquiera están presentadas como preguntas. Insisto en que si la plantilla es la contribución debería facilitarse su uso por otros ingenieros. Su presentación no ayuda a esto. (por ejemplo la primera, \" Al interactuar con el sistema, identifique lo predecible que resulta ser\": que respondo?) El instrumento debe ser autocontenido de manera que claramente contenga  una guía para su aplicación. Más aún, no ofrece claridad para saber cómo combino las respuestas a las consultas para obtener una métrica de calidad. Creo que queda demasiado trabajo al lector.  Los resultados no son presentados de una forma legible. Creo que una tabla ayudaría. Incluso, menciona varias veces la tabulación de los resultados pero esto no aparece. Como es un caso de estudio me gustaría ver en esa tabla las respuestas que se obtuvieron y cómo se calcularon los porcentajes que miden calidad.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta una introducción  a la investigación del efecto del Outsourcing TI en la minería de la segunda región, pero no muestra resultados concretos. En el mismo artículo se  indica que la investigación no se encuentra finalizada. Sería interesante contar con la totalidad del análisis de los resultados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This work is an extension of previous works on pointer models, that mixes its outputs with standard softmax outputs.  The idea is appealing in general for context biasing and the specific approach appears quite simple.  The idea is novel to some extent, as previous paper had already tried to combine pointer-based and standard models, but not as a mixture model, as in this paper.  The paper is clearly written and the results seem promising. The new dataset the authors created (WikiText) also seems of high interest.   A comment regarding notation: The symbol p_ptr is used in two different ways in eq. 3 and eq. 5. : p_ptr(w) vs. p_ptr(y_i|x_i)  This is confusing as these are two different domains: for eq 3. the domain is a *set* of words and for eq. 5 the domain is a *list* of context words. It would be helpful to use different symbol for the two objects.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo presenta el desarrollo un web framework para la transmisión con capacidad de análisis de imágenes de cámaras IP.  La bibliografía presentada son páginas webs relacionadas a las herramientas utilizadas para el desarrollo, pero no a temas relacionados  u otras aplicaciones relacionadas.  Problemas de formato (revisar ortografía,  saltos de línea cuando no debería, identación,  Indica en el resumen que el sistema tiene capacidad de análisis, pero al final indica que está desactivada.  ¿Cuál es la ventaja del ahorro en uso de Ips reales?  Falta un análisis de la situación anterior con la actual. En qué mejoró el sistema.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta un sistema en desarrollo de detección de posición de los ojos para apoyar el análisis psicológico de una persona.  Se presenta una forma para detectar globos oculares y su dirección.  Además de una pequeña mención a C/C++ no se especifica en forma explícita la utilización de librerías de apoyo, tales como filtros, captura de imágenes, etc.  Se menciona que la velocidad de respuesta del sistema ha sido considerada, sin embargo, no se presentan evidencias de este factor.  No se menciona el conjunto de datos sobre los cuales se realizó el estudio, si este es pre-existente o fue desarrollado específicamente para este trabajo por los autores. No se presenta además detalles de los rostros de este conjunto de datos (edad, raza, sexo, etc).  No se especifica si los resultados obtenidos fueron revisados por un profesional del área clínica y sus conclusiones.  Las referencias son muy pocas en relación al campo del trabajo desarrollado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The reviewers seem to agree that the framework presented is not very novel, something I agree with.  The experiments show that the low rank + diagonal parameterization can be useful, however. The paper could be improved by making a more tightened message, and clearer arguments. As it currently stands, however it does not seem ready for publication in ICLR.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Los comentarios aparecen en el archivo adjunto",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors made an exhaustive study on publication related to application of IA algorithms to Supply Chain regarding SCORM level affected, last years tendencies, future forecast of their use.  I would highly recommend:  1. use of color for better graphics understanding 2. mention names of authors or books, to not begin with references.  I miss a comparison table of efficiency, advantages, disadvantages and uses for all AI algorithms used.",
            "output": [
                "en"
            ]
        },
        {
            "input": "-          Ambicioso en el título, logros expuestos en el artículo más bien moderados.  -          Referencia de TOGAF es cuestionable en el tenor del artículo.  -          Cómo se seleccionaron los modelos de referencia??? Qué otros modelos existen y no fueron considerados??",
            "output": [
                "es"
            ]
        },
        {
            "input": "# Summary  This paper presents an empirical study to identify a latent dimension of sentiment in word embeddings.  # Strengths   S1) Tackles a challenging problem of unsupervised sentiment analysis.   S2) Figure 2, in particular, is a nice visualisation.  # Weaknesses   W1) The experiments, in particular, are very thin. I would recommend also measuring F1 performance and expanding the number of techniques compared.   W2) The methodology description needs more organisation and elaboration. The ideas tested are itemised, but insufficiently justified.    W3) The results are quite weak in terms of the reported accuracy and depth of analysis. Perhaps this work needs more development, particularly with validating the central assumption that the Distributional Hypothesis implies that opposite words, although semantically similar, are separated well in the vector space?",
            "output": [
                "en"
            ]
        },
        {
            "input": "La ponencia es muy completa es un tema importante y original, con una calidad técnica muy adecuada y una presentación magnífica",
            "output": [
                "es"
            ]
        },
        {
            "input": "This manuscript tries to tackle neural network regularization by blending the target distribution with predictions of the model itself. In this sense it is similar in spirit to scheduled sampling (Bengio et al) and SEARN (Daume et al) DAgger (Ross et al) which consider a \"roll-in\" mixture of the target and model distributions during training. It was clarified in the pre-review questions that these targets are generated on-line rather than from a lagged distribution, which I think makes the algorithm pseudocode somewhat misleading if I understand it correctly.  This is an incremental improvement on the idea of label softening/smoothing that has recently been revived, and so the novelty is not that high. The author points out that co-label similarity is better preserved by this method but it doesn't follow that this is causal re: regularization; a natural baseline would be a fixed, soft label distribution, as well as one where the softening/temperature of the label distribution is gradually reduced (as one would expect for this method to do as the model gets closer and closer to reproducing the target distribution).  It's an interesting and somewhat appealing idea but the case is not clearly made that this is all that useful. The dropout baselines for MNIST seem quite far from results already in the literature (Srivastava et al 2014 achieves 1.06% with a 3x1024 MLP with dropout and a simple max norm constraint; the dropout baselines here fail to break 1.3% which is rather high by contemporary standards on the permutation-invariant task), and results for CIFAR10 are quite far from the current state of the art, making it difficult to judge the contribution in light of other innovations. The largest benchmark considered is SVHN where the reported accuracies are quite bad indeed; SOTA for single net performance has been less than half the reported error rates for 3-4 years now. It's unclear what conclusions can be drawn about how this would help (or even hurt) in a better-tuned setting.  I have remaining reservations about data hygiene, namely reporting minimum test loss/maximum test accuracy rather than an unbiased method for model selection (minimum validation set error, for example). Relatedly, the regularization potential of early stopping on a validation set is not considered. See, e.g. the protocol in Goodfellow et al (2013).",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo muestra un estudio de aplicación de Algoritmos Genéticos para resolver un sistema de ecuaciones en imágenes ópticas de detección de tumores y seguimiento de tratamientos oncológicos.  El trabajo está bien escrito y tiene un alto nivel de detalle técnico. Sin embargo, no muestra explícitamente cuáles son sus principales contribuciones. En este sentido sería conveniente ampliar la Sección de Introducción para entregar al lector un detalle de las principales contribuciones del trabajo y además incluir en esta sección (o en una sección de Trabajo Relacionados o Estado del Arte) un mayor detalle de otros trabajos previos que estén relacionados con la propuesta de los autores.  En el ámbito de aplicación de Algoritmos Genéticos para resolución de sistemas de ecuaciones, este trabajo no presenta un aporte novedoso, ya que existen varios trabajos previos orientados a este tipo de solución. Respecto al análisis de imágenes y reconocimiento de patrones, hay trabajos previos que ya utilizan Algoritmos Genéticos para este tipo de propuestas, tales como Dourdan, 2015.  Sería conveniente haber tenido una comparativa con otros métodos de Machine Learning que se han aplicado ampliamente al reconocimiento de imágenes tales como k-means o PCA.  Menores: - En la figura 10 no se visualiza bien la serie Solución AG por la cantidad de puntos graficados. - Último párrafo de Conclusiones. \" ... la ventaja de trabajar con heurísticas como el algoritmo genéticos...\" debiera ser \"... la ventaja de trabajar con heurísticas como los algoritmos genéticos...\". - Último párrafo de Conclusiones. \"... es factible que el AG de buena aproximación...\" creo que se debe cambiar la redacción, no se entiende en la primera lectura. -- Referencias. Las referencias a trabajos de Pattern Recognition es antigua 1997, creo que hay referencias más actualizadas y hay mayor cantidad de trabajos donde se aplican diversas técnicas de machine learning para reconocimiento de patrones, desde supervised a unsupervised métodos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta un análisis teórico sobre sistemas SCADA.  No hay evidencia sobre la aplicación en un caso de estudio.  El Resumen no es adecuado, tampoco la introducción.  La sección de Resultados y la sección de Conclusiones  no presentan aportes para un artículo científico o que muestre experiencias empresariales en aplicaciones de TICs.  Las Referencias [3], [5] y [7] son  del mismo autor, mismo título y misma fecha. Lo mismo pasa con las Referencias [4] y [6].  La Referencia [1] no es utilizada en el texto.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Es un artículo que presenta un tema novedoso en el área de la Ingeniería de Software. El artículo está muy bien documentado y fundamentado. Las tecnologías utilizadas en el desarrollo del prototipo son de interés actual.  Como lo describe el artículo, se trata de un primer paso en una línea de investigación y del desarrollo de un prototipo de una aplicación meta-case. Queda es este sentido, poco clara cual es el nivel de madurez actual, tanto de la investigación como de la aplicación desarrollada.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This is a well-conducted and well-written study on the prediction of medication from diagnostic codes. The authors compared GRUs, LSTMs, feed-forward networks and random forests (making a case for why random forests should be used, instead of SVMs) and analysed the predictions and embeddings.  The authors also did address the questions of the reviewers.  My only negative point is that this work might be more relevant for a data science or medical venue rather than at ICLR.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta un trabajo de recolección de información, su agregación y análisis, en el ámbito de educción de requisitos.  1. Creo que, además de la búsqueda en revistas y bases de datos científicas, debe incorporarse también experiencias prácticas en proyectos reales, los cuales usualmente no se reportan en medios científicos. En este sentido, una encuesta hacia profesionales de larga trayectoria podría aportar elementos adicionales y robustez al estudio.  2. Dentro del artículo se presentan numerosas figuras y gráficos. No obstante, usualmente se hace una descripción narrativa de la información en los gráficos, pero sin elaborar alguna hipótesis o conjetura del porqué de las distribuciones que se muestran en estos gráficos. Por ejemplo, Fig. 7.  3. Dentro de las conclusiones se afirma: \"Moreover, there is great variability among metrics and / or constructs  proposed in the primary studies.\" Sin embargo, no hay un análisis cuantitativo de la variabilidad mencionada (sustentar el uso de \"gran variabilidad\").",
            "output": [
                "es"
            ]
        },
        {
            "input": "-\tEl tema de adopción de sistemas ERP se ha desarrollado los últimos 15 años, y en particular la revisión de factores que impliquen su éxito es un tema de investigación relevante. -\tEn el trabajo se desarrolló un análisis de la literatura ERP sobre el tema que aborda   factores críticos de éxito, metodologías de adopción y tamaño de la organización. -\tSi bien es un error indicar que \"últimamente se  ha generado un tercer tipo...\" en relación a asociar fases del proyecto y FCE, pues hace más de 12 años esto se ha realizado, ver Cita [36] del mismo trabajo, no es un tema cerrado. -\tPropongo a los autores el definir que es \"éxito de adopción ERP\", pues existe literatura en relación a ello muy interesante para sus fines últimos (ver trabajos de la profesora Markus). -\tMetodológicamente existen tres limitaciones importantes a superar con miras a avanzar en una publicación científica de impacto. Primero, no se ha considerado el factor de impacto de la publicaciones, con lo cual se ha desestimado el desarrollo asociado a este tipo de revisiones, mezclando trabajos de alto impacto (ejemplo, artículos de revistas ISIs factor de impacto >2, como MISQ) con trabajos sin una revisión de calidad (ejemplo, lo que Scholar \"lanza\" sólo por coincidir en la búsqueda). Segundo, se dice que se tomarán referencias del 2008 en adelante prioritariamente, pero muchas de sus referencias  son de antes de esa fecha, y eso no es raro, pues entre 2001 y 2004 hay una explosión de trabajos en este ámbito específico. Tercero, no se han incluido explícitamente trabajos de conferencias del área de alto impacto en la comunidad científica como AMCIS o ECIS (la primera tiene una base de datos privada, no accesible por google y la segunda es libre). -\tLas limitaciones antes expuestas restringen los alcances de los interesantes  resultados expuestos en el trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo promete presentar un método para medir la calidad del desarrollo de software en SCRUM.  Considero la propuesta interesante y relevante, sin embargo el trabajo tiene debilidades en su construcción.  La promesa del título se diluye en eL abstract y la introducción, con la “introducción” de SPEM como herramienta. Luego en el cuerpo de artículo no queda clara la vinculación entre SPEM y el método de medición de calidad propuesto.  Tampoco queda claro el caso de estudio sobre el que están basando su trabajo. El modelado en SPEM es sobre SCRUM en forma teórica en sobre el caso de estudio. La evaluación del método no parece medir la calidad del software, sino los criterios de los involucrados con respecto al apego al proceso modelado. Y en todo caso, siempre mide documentos intermedios del proceso y no defectos o atributos primeros de la calidad del software producido.  Comentarios menores: - Revisar la construcción de las referencias - El modelado de SCRUM no incluye la reunión de retrospectiva. Si se está modelando una implementación particular de SCRUM aclararlo en el cuerpo del paper. De lo contrario es un error importante de modelado. - Por que utilizan un proceso tradicional para modelar un proceso ágil? No podría haberse usado uno de estos últimos? - En la primera hoja, al final de la primera columna, cambia el tipo de letra.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Desde el punto de vista de las redes Bayesianas, el trabajo no hace más que una aplicación directa de la implementación en Genie del algoritmo K2 (Cooper y Hervokits, 1992). No queda claro para que se va a utilizar la potencialidad de este modelo gráfico probabilístico a nivel de inferencia o clasificación. Las referencias incluidas en la lista debe de ser refinadas (no tiene sentido incluir referencias de los años 90 en las que aparezcan la coletilla de \"enviado\").",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo describe una comparación de dos herramientas que se utilizan en aplicaciones de big data.  El contenido se seguir sin mayores inconvenientes y sigue un orden lógico.  No obstante, se identificaron las siguientes falencias:  - Las pruebas realizadas se hacen en base a un conjunto de datos (grafo) de tamaño reducido, contraviniendo el hecho de que se tratar de comparar herramientas que se utilizan con big data. - El caso de prueba para su solución requiere de mucho cómputo, pero no es un ejemplo de big data. Esto se infiere por el hecho de que el conjunto de datos es un grafo de 31 vértices y 82 nodos.  - En las conclusiones se afirma que se detectó que en Chile el nivel de conocimiento respecto a los problemas generados por big data es exiguo. Esto se sustenta en dos referencias, pero no hay un trabajo propio que sustente esta afirmación, como podría ser una encuesta al mercado nacional.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Es una buena aplicación, que usa los recursos de desarrollo disponibles para tecnologías móviles.. El valor que tiene es su clara presentación y explicación de las herramientas que utiliza hasta este instante. Se encuentra aún en fase de desarrollo, porque presenta servicios ya bastante explotados, por ejemplo, podría asistir al usuario en buscar rutas óptimas para llegar al estacionamiento u otras factibles donde ya hay herramientas que pueden servir para brindar otros servicios. Lo novedoso  al parecer es  el uso en tecnología móvil para ambos sistemas operativos IOS y Android.   Debe corregir lo siguiente:  Página 1\tresumen\tUsa paper para describir el trabajo. No define nemotécnicos, ejemplo, GPS.  Página 1\tintroducción\tNo referencia la figura 1 y no la explica  Página 1 y 2\tTrabajos previos\tNo analiza literatura especializada  y realiza una tabla comparativa de las aplicaciones.. esto debería ser parte de un análisis comparativo de su aplicación con las existentes..  Página 2 Fuera de formato la referencia, en Ingeniare no se permite conferenciar con et al., o su equivalente y otros  Página 3 Sin referencia Las figuras 3 y 4, tampoco son referenciadas en el texto  Página 4 y 5 \tFiguras sin referencias\tFiguras 5, 6  y 7 tampoco son referenciadas",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposed a hardware accelerator for DNN. It utilized the fact that DNN are very tolerant to low precision inference and outperforms a state-of-the-art bit-parallel accelerator by 1.90x without any loss in accuracy while it is 1.17x more energy efficient. TRT requires no network retraining. It achieved super linear scales of performance with area.  The first concern is that this paper doesn't seem very well-suited to ICLR. The circuit diagrams makes it more interesting for the hardware or circuit design community.   The second concern is the \"take-away for machine learning community\", seeing from the response, the take-away is using low-precision to make inference cheaper. This is not novel enough. In last year's ICLR, there were at least 4 papers discussing using low precision to make DNN more efficient. These ideas have also been explored in the authors' previous papers.",
            "output": [
                "en"
            ]
        },
        {
            "input": "*** Paper Summary ***  This paper simplify matching network by considering only a single prototype per class which is obtained as the average of the embedding of the training class samples. Empirical comparisons with matching networks are reported.  *** Review ***  The paper reads well and clearly motivate the work. This work of learning metric learning propose to simplify an earlier work (matching network) which is a great objective. However, I am not sure it achieve better results than matching networks. The space of learning embeddings to optimize nearest neighbor classification has been explored before, but the idea of averaging the propotypes is interesting (as a non-linear extension of Mensink et al 2013). I would suggest to improve the discussion of related work and to consolidate the results section to help distinguish between the methods you outperform and the one you do not.   The related work section can be extended to include work on learning distance metric to optimize a nearest neighbor classification, see Weinberger et al, 2005 and subsequent work. Extensions to perform the same task with neural networks can be found in Min et al, 09 that purse a goal very close to yours. Regarding approaches pursuing similar goals with a different learning objective, you cite siamese network with pairwise supervision. The learning to rank (for websearch) litterature with triplet supervision or global ranking losses is also highly relevant, ie. one example \"the query\" defines the class and the embedding space need to be such that positive/relevant document are closer to the query than the others. I would suggest to start with Chris Burges 2010 tutorial. One learning class   I am not sure the reported results correctly reflect the state of the art for all tasks. The results are positive on Omniglot but I feel that you should also report the better results of matching networks on miniImageNet with fine tuning and full contextual embeddings. It can be considered misleading not to report it. On Cub 200, I thought that the state-of-the-art was 50.1%, when using features from GoogLeNet (Akata et al 2015), could you comment on this?  Overall, paper could greatly be improved, both in the discussion of related work and with a less partial reporting of prior empirical results.  *** References ***  Large Margin Nearest Neighbors. Weinberger et al, 2005 From RankNet to LambdaRank to LambdaMART: An Overview, Chris J.C. Burges, June 23, 2010 A Deep Non-linear Feature Mapping for Large-Margin kNN Classification, Min et al, 09",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper shows how policy gradient and Q-Learning may be combined together, improving learning as demonstrated in particular in the Atari Learning Environment. The core idea is to note that entropy-regularized policy gradient leads to a Boltzmann policy based on Q values, thus linking pi & Q together and allowing both policy gradient and Q-Learning updates to be applied.  I think this is a very interesting paper, not just for its results and the proposed algorithm (dubbed PGQ), but mostly because of the links it draws between several techniques, which I found quite insightful.  That being said, I also believe it could have done a better job at clearly exposing these links: I found it somewhat difficult to follow, and it took me a while to wrap my head around it, even though the underlying concepts are not that complex. In particular: - The notation \\tilde{Q}^pi is introduced in a way that is not very clear, as \"an estimate of the Q-values\" while eq. 5 is an exact equality (no estimation) - It is not clear to me what section 3.2 is bringing exactly, I wonder if it could just be removed to expand some other sections with more explanations. - The links to dueling networks (Wang et al, 2016) are in my opinion not explicit and detailed enough (in 3.3 & 4.1): as far as I can tell the proposed architecture ends up being very similar to such networks and thus it would be worth telling more about it (also in experiments my understanding is that the \"variant of asynchronous deep Q-learning\" being used is essentially such a dueling network, but it is not clearly stated). I also believe it should be mentioned that PGQ can also be seen as combining Q-Learning with n-step expected Sarsa using a dueling network: this kind of example helps better understand the links between methods - Overall I wish section 3.3 was clearer, as it draws some very interesting links, but it is hard to see where this is all going when reading the paper for the first time. One confusing point is w.r.t. to the relationship with section 3.2, that assumes a critic outputting Q values while in 3.3 the critic outputs V. The \"mu\" distribution also comes somewhat out of nowhere.  I hope the authors can try and improve the readability of the paper in a final version, as well as clarify the points raised in pre-review questions (in particular related to experimental details, the derivation of eq. 4, and the issue of the discounted distribution of states).  Minor remarks: - The function r(s, a) used in the Bellman equation in section 2 is not formally defined. It looks a bit weird because the expectation is on s' and b' but r(s, a) does not depend on them (so either it should be moved out of the expectation, or the expectation should also be over the reward, depending on how r is defined) - The definition of the Boltzmann policy at end of 2.1 is a bit confusing since there is a sum over \"a\" of a quantity that does not depend (clearly) on \"a\" - I believe 4.3 is for the tabular case but this is not clearly stated - Any idea why in Fig. 1 the 3 algorithms do not all converge to the same policy? In such a simple toy setting I would expect it to be the case.  Typos: - \"we refer to the classic text Sutton & Barto (1998)\" => missing \"by\"? - \"Online policy gradient typically require an estimate of the action-values function\" => requires & value - \"the agent generates experience from interacting the environment\" => with the environment - in eq. 12 (first line) there is a comma to remove near the end, just before the dlog pi - \"allowing us the spread the influence of a reward\" => to spread - \"in the off-policy case tabular case\" => remove the first case - \"The green line is Q-learning where at the step an update is performed\" => at each step - In Fig. 2 it says A2C instead of A3C  NB: I did not have time to carefully read Appendix A",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo expone la aplicación del framewok CakePHP a un problema específico.  Expone en forma clara la utilización del patrón MVC mediante CakePHP.  La introducción es muy general y pone énfasis en elementos (calidad, tiempo y RAD) que no son desarrollados o demostrados en profundidad en el trabajo.  Presenta el caso de estudio en CakePHP, sin realizar una comparación específica a partir de los elementos que sean mediables (tiempo, costo) con otros frameworks.  Posee faltas ortográficas (Universiades).  Se menciona la utilización de la técnica de programación extrema, sin embargo, no se específica de que forma fue desarrollada por los autores.  Se presenta código SQL sin especificar como se encuentra relacionado con el framework CakePHP.  No se identifica de manera clara el aporte de los screenshots presentados.  Sería deseable una introducción más detallada el problema específico resuelto. No queda claro cuáles son los beneficios de utilizar CakePHP para el desarrollo de esta aplicación.  Las conclusiones son muy generales y distan de ser específicas para el trabajo desarrollado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "I reviewed the manuscript as of December 6th.  Summary: The authors build upon generative adversarial networks for the purpose of steganalysis -- i.e. detecting hidden messages in a payload. The authors describe a new model architecture in which a new element, a 'steganalyser' is added a training objective to the GAN model.  Major Comments: The authors introduce an interesting new direction for applying generative networks. That said, I think the premise of the paper could stand some additional exposition. How exactly would a SGAN method be employed? This is not clear from the paper. Why does the model require a generative model? Steganalysis by itself seems like a classification problem (i.e. a binary decision if there a hidden message?) Would you envision that a user has a message to send and does not care about the image (container) that it is being sent with? Or does the user have an image and the network generates a synthetic version of the image as a container and then hide the message in the container? Or is the SGAN somehow trained as a method for detecting hidden codes performed by any algorithm in an image? Explicitly describing the use-case would help with interpreting the results in the paper.  Additionally, the experiments and analysis in this paper is quite light as the authors only report a few steganalysis performance numbers in the tables (Table 1,2,3). A more extensive analysis seems warranted to explore the parameter space and provide a quantitative comparison with other methods discussed (e.g. HUGO, WOW, LSB, etc.) When is it appropriate to use this method over the others? Why does the seed effect the quality of results? Does a fixed seed correspond realistic scenario for employing this method?  Minor comments: - Is Figure 1 necessary? - Why does the seed value effect the quality of the predictive performance of the model?",
            "output": [
                "en"
            ]
        },
        {
            "input": "The idea of universality that is independent of input distribution and dimension, depending only on the algorithm is an appealing one. However, as an empirical study, this paper comes up somewhat short:  1. Exactly one algorithm is shown for the deep learning example. It would have been more convincing to compare distributions with one or more algorithms.   2. The definition (1),  and much of the work of Section 2.1 seems to have already been covered in Deift (2014), Section 1.3. In that paper, a number of different algorithms for the solution of linear systems are considered, and then the concept of universality becomes more plausible. I do not see enough of such algorithmic comparisons in this paper (same problem setup, different algorithms).  3.  It seems to me that what practitioners might care about in practice are both the mean and variance in running times; these quantities are buried in (1). So I question how useful the distribution itself might be for algorithm tuning.   At the least, many more empirical comparisons should be provided to convince me that the universality holds across a broad range of algorithms.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: A nice, solid piece of work that builds on previous studies in a productive way. Well-written and clear.   - Weaknesses:   Very few--possibly avoid some relatively \"empty\" statements:  191 : For example, if our task is to identify words used similarly across contexts, our scoring function can be specified to give high scores to terms whose usage is similar across the contexts.  537 : It is educational to study how annotations drawn from the same data are similar or different.  - General Discussion: In the first sections I was not sure that much was being done that was new or interesting, as the methods seemed very reminiscent of previous methods used over the past 25 years to measure similarity, albeit with a few new statistical twists, but conceptually in the same vein. Section 5, however, describes an interesting and valuable piece of work that will be useful for future studies on the topic. In retrospect, the background provided in sections 2-4 is useful, if not necessary, to support the experiments in section 5.   In short, the work and results described will be useful to others working in this area, and the paper is worthy of presentation at ACL.  Minor comments:  Word, punctuation missing? 264 : For word annotations, we used PPMI, SVD, and SGNS (skipgram with negative sampling from Mikolov et al. (2013b)) word vectors released by Hamilton et al. (2016).  Unclear what \"multiple methods\" refers to : 278 : some words were detected by multiple methods with CCLA",
            "output": [
                "en"
            ]
        },
        {
            "input": "Falta un poco de claridad en la presentación del tema. En las conclusiones falta mostrar cual es el aporte del trabajo y motivo de la investigación",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo tiene como objetivo brindar una arquitectura de referencia y solución al problema de integración e interoperabilidad entre sistemas de salud.   Algunas observaciones son: - Falta nombre del paper en español - Cambiar \"Index Terms\" por \"keywords\" - Falta Resumen y Palabras Clave en español - No usar color en figuras (según formato) - Poner acento a \"se diseño\" - Falta una sección de Conclusiones",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes a design principle for computation blocks in convolutional networks based on repeated application of expand and join operations resulting in a fractal-like structure.   This paper is primarily about experimental evaluation, since the objective is to show that a residual formulation is not necessary to obtain good performance, at least on some tasks.  However, in my opinion the evaluations in the paper are not convincing. The primary issue is lack of a proper baseline, against which the improvements can be clearly demonstrated by making isolated changes. I understand that for this paper such a baseline is hard to construct, since it is about a novel architecture principle. This is why more effort should be put into this, so that core insights from this paper can be useful even after better performing architectures are discovered. The number of parameters and amount of computation should be used to indicate how fair the comparisons are between architectures. Some detailed comments:  - In Table 1 comparisons to Resnets, the resnets from He et al. 2016b and Wide Resnets should be compared to FractalNet (in lieu of a proper baseline). The first outperforms FractalNet on CIFAR-100 while the second outperforms it on both. The authors compare to other results without augmentation, but did not perform additional experiments without augmentation for these architectures.  - The 40 layer Fractal Net should not be compared to other models unless the parameter reduction tricks are utilized for the other models as well.  - A proper comparison to Inception networks should also be performed for these networks. My guess is that the reason behind a seemingly 'ad-hoc' design of Inception modules is to reduce the computational footprint of the model (which is not a central motivation of fractal nets). Since this model is directly related to the Inception module due to use of shorter and longer paths without shortcuts, one can easily simplify the Inception design to build a strong baseline e.g. by converting the concatenation operation to a mean operation among equally sized convolution outputs. As an aside, note that Inception networks have already shown that residual networks are not necessary to obtain the best performance [1].  - It should be noted that Residual/Highway architectures do have a type of anytime property, as shown by lesioning experiments in Srivastava et al and Viet et al.  - The architecture specific drop-path regularization is interesting, but is used along with other regularizers such as dropout, batch norm and weight decay and its benefit on its own is not clear.  Overall, it's not clear to me that the experiments clearly demonstrate the utility of the proposed architecture.   [1] Szegedy, Christian, Sergey Ioffe, and Vincent Vanhoucke. \"Inception-v4, inception-resnet and the impact of residual connections on learning.\" arXiv preprint arXiv:1602.07261 (2016).",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es un trabajo difícil de catalogar, presenta un tema usualmente asociado a bases de datos deductivas (reparación), donde deben existir reglas o restricciones de integridad que han sido violadas, adaptado al tema de inconsistencia producida por nuevos hechos en un DW que no se ajustan correctamente a sus dimensiones. Esto, normalmente es tratado en este ámbito mediante el uso de Slowly Changing Dimensions (SCD), algo que extrañamente no es nombrado en el artículo.  Aun así, y asumiendo que el problema realmente existe y tiene aplicabilidad, es presentado muy superficialmente, y termina finalmente en una propuesta informal que no es descrita rigurosamente como un algoritmo en sí. Me parece que es una propuesta que aún se encuentra en un estado muy inicial y cuya problemática no logra convencerme como tal.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta un algoritmo para problema de Job Shop Scheduling, mediante el enfoque de inmunidad de selección clonal. Se realiza una adecuada revisión de la literatura relacionada y de la metodología propuesta para resolver el problema. En lo relativo a los resultados y su discusión, se midió el desempeño del algoritmo propuesto sobre varios problemas de distintos tamaños y se comparó su rendimiento con otros algoritmos de la literatura.  El artículo está bien estructurado y la presentación es clara y sigue un orden lógico.  Presenta algunos problemas menores de forma que se deben resolver:  - incorrecta enumeración de las figuras y no sigue el orden de aparición. - referencia 2 es incompleta  Según lo expuesto, el algoritmo propuesto supera a otros algoritmos de la literatura en cuanto a porcentaje de BKS alcanzado. No obstante, no se discute el factor error relativo promedio % y el hecho que el esquema propuesto supera a 2 esquemas de la literatura pero es superado por 5 otros (esto se menciona en las conclusiones pero sin discusión). Sería conveniente introducir una discusión respecto a esto último y trabajo futuro en este sentido.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes a neural architecture for answering non-factoid questions. The author's model improves over previous neural models for answer sentence selection. Experiments are conducted on a Japanese love advice corpus; the coolest part of the paper for me was that the model was actually rolled out to the public and its answers were rated twice as good as actual human contributors!   It was hard for me to determine the novelty of the contribution. The authors mention that their model \"fills the gap between answer selection and generation\"; however, no generation is actually performed by the model! Instead, the model appears to be very similar to the QA-LSTM of Tan et al., 2015 except that there are additional terms in the objective to handle conclusion and supplementary sentences. The structure of the answer is fixed to a predefined template (e.g., conclusion --> supplementary), so the model is not really learning how to order the sentences. The other contribution is the \"word embedding with semantics\" portion described in sec 4.1, which is essentially just the paragraph vector model except with \"titles\" and \"categories\" instead of paragraphs.   While the result of the paper is a model that has actually demonstrated real-life usefulness, the technical contributions do not strike me as novel enough for publication at ICLR.  Other comments: - One major issue with the reliance of the model on the template is that you can't evaluate on commonly-used non-factoid QA datasets such as InsuranceQA. If the template were not fixed beforehand (but possibly learned by the model), you could conceivably evaluate on different datasets.  - The examples in Table 4 don't show a clear edge in answer quality to your model; QA-LSTM seems to choose good answers as well. - Doesn't the construction model have an advantage over the vanilla QA-LSTM in that it knows which sentences are conclusions and which are supplementary? Or does QA-LSTM also get this distinction?",
            "output": [
                "en"
            ]
        },
        {
            "input": "Los autores describen una metodología para desarrollar, en forma colaborativa, tesis y memorias usando tecnologías que se usan habitualmente en desarrollo de software. Asimismo, describen herramientas concretas y sus bondades como, por ejemplo, Latex y Git. Finalmente, proponen un flujo de trabajo para el desarrollo de proyectos de esta naturaleza.  El valor principal del artículo radica en la aplicación de conocimientos que los estudiantes  ya dominan -es decir, técnicas y herramientas de desarrollo de software- a una problemática diferente como es el caso de las tesis y memorias. Todo ello, con el afán de hacer más eficiente el proceso.  1.- El énfasis del artículo está la solución sin hacer un análisis detallado del problema que se pretende resolver. En otras palabras, no hay respuestas a las siguientes preguntas:  a.- ¿cuál es exactamente el problema? b.- ¿qué impactos genera este problema? c.- ¿por qué es importante resolver el problema? d.- ¿qué soluciones se han implementado hasta la fecha? e.- ¿qué ventajas tiene la solución propuesta respecto de las anteriores?   2.- En mi opinión, el artículo debiera enfatizar más la metodología y el flujo de trabajo. Por ejemplo, añadir un diagrama -utilizando un lenguaje visual- que permita, por un lado, comprender el proceso general de desarrollo de tesis y, por otro, distinguir los roles, las actividades y las tecnologías asociadas en cada fase de la memoria.  3.- Se deben cuidar algunos aspectos del lenguaje y el rigor de ciertas afirmaciones como, por ejemplo: \"(dada la más bien atroz ortografía de que gozan los ingenieros)\". ¿Los autores disponen de algún respaldo empírico para respaldar esta afirmación? ¿Es necesario recurrir a un lenguaje tan prosaico para justificar la conveniencia de usar una determinada herramienta tecnológica? A propósito, recomiendo revisar las expresiones: \"no es publico\" (punto 3.1) y \"El tener acceso directamente...\" (punto 3.2)",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta la propuesta para un modelo de calidad para software de banca por Internet.  El trabajo presenta varias debilidades: - El objetivo del trabajo no está claramente especificado, y aparece descrito en forma diferente en varias secciones. - La metodología de investigación no está clara. --> Los elementos constitutivos de la propuesta (Dromey, ISO 25010, MOSCA...). No se describe la motivación de por qué fueron seleccionados. Ni se describe el sesgo que esta selección puede tener en el modelo. --> Se describe el uso de una metodología de Investigación/Acción, pero no se describe el fenómeno que se ha estudiado para consolidar el modelo.  --> La Secciones de marco teórico, también parecen estar sesgadas, y no se describe las fuentes que dieron lugar a la selección de referencias.  Otros comentarios menores: - La traducción del abstract a inglés debe ser revisada. - La bibliográfica de calidad de software, sale de libros de texto, y puede ser actualizada. - El alcance hacia a tributos de calidad, es a la vez, introducido como parte del marco metodológico, y expuesto como conclusiones. No puede ser las dos. Al orientar la investigación hacia owasp, el constructo se orienta hacia atributos de seguridad, por tanto la conclusión: \"En el mismo sentido se establece que la calidad de un sistema para Banca por Internet debe considerar la seguridad como punto obligatorio, además de la funcionalidad\" Es resultado del diseño de su investigación, y no puede extraerse del trabajo.  - La referencia 6 y la 11 es la misma.",
            "output": [
                "es"
            ]
        },
        {
            "input": "En este trabajo se realiza una revisión sistemática de literatura sobre el tema de gestión de requisitos software en empresas pequeñas.  El trabajo resulta relevante para la comunidad dada la poca información existente en esta temática. Como correcciones menores se recomienda trabajar más la sección de resultados añadiendo la síntesis de la revisión así como discutir los resultados de acuerdo a la pegunta de investigación planteada, por último se recomienda quitar la referencia que aparece en el resumen.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta una aplicación de técnicas de reconocimiento de patrones a la clasificación de tipos de maderas basada en registros de audio.  En los aspectos de forma:  El artículo presenta varios problemas de sintaxis del lenguaje español, los cuales son fácilmente subsanables. El resumen se debería revisar y mejorar.  También se presentan algunos términos en inglés que deberían ser reemplazados por su significado en español (e.g. test).  Las ecuaciones 4 y 5 contienen errores y deben ser mejor explicadas. También ajustar el tamaño de la letra (font size).  La tabla 1 contiene información redundante, pues las cantidades que se presentan parecen ser independientes del método.  Mejorar la resolución y aumentar el tamaño de la figura 5 (que ocupe las 2 columnas), pues no se logra apreciar bien los distintos puntos y clusters que se comentan.  En los aspectos de fondo:  La revisión del estado del arte es débil, debiendo incorporarse más referencias actuales relevantes  relacionadas al reconocimiento de patrones en base a datos de audio (aunque no necesariamente sean en el dominio de las maderas).  La versión del algoritmo KNN cuyo pseudocódigo se muestra, esta incorrecto. Se debe revisar y corregir. No se aprecia que trabaje para un K determinado. Tampoco se aprecia la recursión.  Se requiere mayor información y detalle de los datos y de las características derivadas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "-\tLa propuesta es una buena iniciativa práctica, sin embargo existe una carencia en la revisión de la literatura en la que se basa y la evaluación por expertos debe ser ampliada para ser considerada como significativa. -\tDebe modificar el formato de citas (es ordenado de [1] a...[n]) y el listado de referencias indicando volumen y número, etc. Este es un ejemplo: [1] K. Nusair, H.G. Parsa and C. Cobanoglu. \"Building a model of commitment for Generation Y: An empirical study on e-travel retailers\". Tourism Management. Vol. 32, Issue 4, pp. 833-843. 2011. -\tDebe indicar a que moneda se refiere en los párrafos introductorios (¿pesos colombianos? ¿pesos chilenos?. -\tDebe ajustar el formato de las tablas. -\tSe recomienda fuertemente mejorar la redacción, de modo de hacer más breve y menos coloquial la explicación del trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper describes a method for training neural networks with ternary weights. The results are solid and have a potential for high impact on how networks for high-speed and/or low-power inference are trained.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The authors explore the idea of deep-learning a static analyzer. They do it with a toy programming language and a very simplified analysis problem -- just checking if all variables are initalized.  While the idea is interesting and might be developped into a tool in the future, the toy task presented in this paper is too simple to warrant an ICLR submission. Just detecting whether a variable is initialized in a string is a toy algorihtmic task, similar to the ones solved in a number of paper in recent years by models such as the Neural Turing Machine, Stack RNNs, Neural GPU, or Differentiable Neural Computer. All these architectures perform almost perfectly on a number of algorithmic tasks, so it is highly probable that they would also solve this one. Unluckily, the authors only compare to much more basic models, such as HMMs. Since the code for many of the above-mentioned models is available online, a paper without these baselines is not ready for ICLR. Moreover, there is a risk that existing models already solve this problem very well, making the contribution unclear.",
            "output": [
                "en"
            ]
        },
        {
            "input": "While the overall direction is promising, there are several serious issues with the paper which affect the novelty and validity of the results:  1. Incorrect claims about related work affecting novelty:    - This work is not the first to explore a deep learning approach to automatic code completion: “Toward Deep Learning Software Repositories”, MSR’15 also uses deep learning for code completion, and is not cited.    - “Code Completion with Statistical Language Models”, PLDI’14 is cited incorrectly -- it also does code completion with recurrent neural networks.    - PHOG is independent of JavaScript -- it does representation learning and has been applied to other languages (e.g., Python, see OOPSLA’16 below).     - This submission is not the only one that “can automatically extract features”. Some high-precision (cited) baselines do it.    - “Structured generative models of natural source code” is an incorrect citation. It is from ICML’14 and has more authors. It is also a log-linear model and conditions on more context than claimed in this submission.   2. Uses a non-comparable prediction task for non-terminal symbols: The type of prediction made here is simpler than the one used in PHOG and state-of-the-art (see OOPSLA’16 paper below) and thus the claimed 11 point improvement is not substantiated. In particular, in JavaScript there are 44 types of nodes. However, a PHOG and OOPSLA’16 predictions considers not only these 44 types, but also whether there are right siblings and children of a node. This is necessary for predicting tree fragments instead of a sequence of nodes. It however makes the prediction harder than the one considered here (it leads to 150+ labels, a >3x increase).   3. Not comparing to state-of-the-art: the state-of-the-art however is not the basic PHOG cited here, but “Probabilistic Model for Code with Decision Trees”, (OOPSLA 2016) which appeared before the submission deadline for ICLR’17:",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper applies RFN for biclustering to overcome the drawbacks in FABIA. The proposed method performs best among 14 biclustering methods, However, my first concern is that from the methodological point of view, the novelty of the proposed method seems small. The authors replied to the same question which another reviewer gave, but the replies were not so convincing.   This paper was actually difficult for me to follow. For instance, in Figure 1, a bicluster matrix is constructed as an outer product of $h$ and $w$. $h$ is a hidden unit, but what is $w$? I could not find any definition. Furthermore, I could not know how $h$ is estimated in this method. Therefore, I do NOT understand how this method performs biclustering.   Totally, I am not sure that this paper is suitable for publication.   Prons: Empirical performance is good.  Cons: Novelty of the proposed method Some description in the paper is unclear.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Thank you for an interesting read on an approach to choose computational models based on kind of examples given.  Pros - As an idea, using a meta controller to decide the computational model and the number of steps to reach the conclusion is keeping in line with solving an important practical issue of increased computational times of a simple example.   - The approach seems similar to an ensemble learning construct. But instead of random experts and a fixed computational complexity during testing time the architecture is designed to estimate hyper-parameters like number of ponder steps which gives this approach a distinct advantage.   Cons - Even though the metacontroller is designed to choose the best amongst the given experts, its complete capability has not been explored yet. It would be interesting to see the architecture handle more than 2 experts.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Problemas de Fondo: Los autores presentan los resultados de un proyecto de interoperabilidad entre plataformas, definen los estándares para la creación de contenido, sin embargo, los argumentos utilizados para seleccionar el modelo carecen de validación.  Se esperaría al menos la validación de dos o más plataformas antes de definir y concluir que lo propuesto es la mejor selección.  La encuesta aplicada a 50 personas no describe en que plataformas se realizó y a qué tipo de público objetivo.   Problemas de Forma: - Palabras sin tilde: último, validó, módulo. - Inicio de frases sin mayúsculas. - No se respeta el márgen en la tabla. - Los títulos de las figuras se encuentran en páginas diferentes. - La enumeración de los dispositivos es confusa y sin formato.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El documento refleja que el equipo de trabajo cuenta con cierto dominio en la tecnología necesaria para alcanzar los objetivos planteados, sin embargo no está bien redactado, carece de sustento en trabajos previos, la aplicación no está bien descrita. Se recomienda también cuidar la redacción, concretar las ideas y cuidar la estructura en el documento. Se recomienda además una revisión profunda buscando la síntesis y profundizar en los detalle de la propuesta software que describen, y también se recomienda aplicar una metodología, describirla y describir la validación de la herramienta descrita (generar por ejemplo casos de prueba y describir la validación).",
            "output": [
                "es"
            ]
        },
        {
            "input": "Los autores presentan el trabajo de la construcción y evaluación de una herramienta visual como ayuda al proceso de minería de datos. Se muestra los resultados de utilizar la misma sobre un grupo de usuarios y sobre una tarea específica.  Sugerencias: - En las conclusiones se menciona la oportunidad de construir otras herramientas de apoyo, sin embargo, no se mencionan cuáles podrían ser. - No se menciona la razón de seleccionar WEKA como herramienta base para la construcción del software propuesto. - Se debería agregar como anexo el detalle del experimento realizado, indicando el modelo utilizado, resultados obtenidos, etc.   Forma: - El segundo párrafo de la introducción no deja clara cuál es la intención del mismo, debería ser redactado nuevamente. - Se hace uso extensivo de siglas, las cuales confunden y dificultan la lectura del trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Encouraging orthogonality in weight features has been reported useful for deep networks in many previous works. The authors present a explicit regularization cost to achieve de-correlation among weight features in a layer and encourage orthogonality. Further, they also show why and how negative correlations can and should be avoided for better de-correlation.   Orthogonal weight features achieve better generalization in case of large number of trainable parameters and less training data, which usually results in over-fitting. As also mentioned by the authors biases help in de-correlation of feature responses even in the presence of correlated features (weights). Regularization techniques like OrthoReg can be more helpful in training deeper and leaner networks, where the representational capacity of each layer is low, and also generalize better.  Although the improvement in performances is not significant the direction of research and the observations made are promising.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presentado, describe someramente los estudios realizados y decisiones adoptadas, que permiten dotar de una infraestructura de alta capacidad a los observatorios ESO Paranal y Cerro Armazones, ubicados en el desierto de atacama.  Se presentan las diversas etapas involucradas en el desafío por dotar de un gran ancho de banda a los mencionados observatorios ubicados en aéreas no pobladas (pleno desierto) para su conexión expedita con diversas redes académicas y la comunidad astronómica europea lo cual constituye un buen desafío desde el punto de vista tecnológico.  Sería importante destacar porqué de la necesidad de contar con grandes anchos de banda, es decir describir en mayor detalle el tipo de tráfico que lo justifica, por ejemplo monitoreo, control y operación remota, etc.  Aún no está en operación el enlace",
            "output": [
                "es"
            ]
        },
        {
            "input": "A few issues with this paper: 1- I find finding #2 trivial and unworthy of mention, but the author don't seem to agree with me that it is. See discussions. 2- Finding #1 relies on Fig #4, which appears very noisy and doesn't provide any error analysis. It makes me question how robust this finding is. One would have naively expected the power usage trend to mirror Fig #3, but given the level of noise, I can't convince myself whether the null hypothesis of there being no dependency between batch size and power consumption is more likely than the alternative. 3- Paper is unfriendly to colorblind readers (or those with B/W printers)  Overall, this paper is a reasonable review of where we are in terms of SOTA vision architectures, but doesn't provide much new insight. I found most interesting the clear illustration that VGG models stand out in terms of being a bad tradeoff in resource-constrained environments (too many researchers are tempted to benchmark their model compression algorithm on VGG-class models because that's always where one can show 10x improvements without doing much.)",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper presents an interesting incremental approach for exploring new convolutional network hierarchies in an incremental manner after a baseline network has reached a good recognition performance.  The experiments are presented for the CIFAR-100 and ImageNet benchmarks by morphing various ResNet models into better performing models with somewhat more computation.  Although the baselines are less strong than those presented in the literature, the paper claims significant error reduction for both ImageNet and CIFAR-100.  The main idea of the paper is to rewrite convolutions into multiple convolutions while expanding the number of filters. It is quite unexpected that this approach yields any improvements over the baseline model at all.  However, for some of the basic tenets of network morphing, experimental evidence is not given in the paper. Here are some fundamental questions raised by the paper: - How does the quality of morphed networks compares to those with the same topology trained from scratch? - How does the incremental training time after morphing relate to that of the network trained from scratch? - Where is the extra computational cost of the morphed networks come from? - Why is the quality of the baseline ResNet models lag behind those that are reported in the literature and github? (E.g. the github ResNet-101 model is supposed to have 6.1% top-5 recall vs 6.6 reported in the paper) More evidence for the first three points would be necessary to evaluate the validity of the claims of the paper.  The paper is written reasonably well and can be understood quite well, but the missing evidence and weaker baselines make it looks somewhat less convincing.  I would be inclined to revise up the score if a more experimental evidence were given for the main message of the paper (see the points above).",
            "output": [
                "en"
            ]
        },
        {
            "input": "*** Paper Summary ***  The paper proposes to a new neural network architecture. The layer weights of a classical network are computed as a function of a latent representation associated with the layer. Two instances are presented (i) a CNN where each layer weight is computed from a lower dimensional layer embedding vector; (ii) an RNN where each layer weight is computed from a secondary RNN state.  *** Review Summary ***  Pros:  - I like the idea of bringing multiplicative RNNs and their predecessors back into the spotlight.  - LM and MT results are excellent.  Cons:   - The paper could be better written. It is too long for the conference format and need refocussing.  - On related work, the relation with multiplicative RNN and their generic tensor product predecessor (Order 2 networks, wrt C. Lee Giles definition) should be mentioned in the related work section and the differences with earlier research need to be explained and motivated (by the way it is better to say that something is revisiting an old idea or training it at modern scale/on modern tasks than ommitting it). - on focus, it is not clear if your goal is to achieve better performance or more compact networks. In the RNN section you lean toward the former, in the CNN section you seem to lean toward the latter.  I would suggest to make the paper shorter and clearer possibly leaving the CNN results for latter publication. The relation with multiplicative/order 2 networks and eventual differences need to be explained.  *** Detailed Review ***  Multiplicative networks are an extremely powerfull architecture and bringing them back into the spotlight is excellent. This paper has excellent results but suffer poor presentation, lack of a clear focus. It spends time on details and ommit important points. In its current form, it is much too long to long and his not self contained without the appendices.  Spending more time on multiplicative RNNs, order 2 networks at the begining of the paper would be excellent. This will let you highlight the difference between this paper and earlier work. It would also be necessary to spend a little time on why multiplicative RNN were less used than gated RNN: it seems that the optimization problem their training involve is tricker and it would be helpful to explain whether you had a harder time tweaking optimization parameters or whether you needed longer training sessions compared to LSTMs, regular CNN. On name, I am not sure that \"hypernetwork\" help the reader understand better what the proposed architecture compared to multiplicative interactions.  In section 3.2, you seem to imply that there are different settings of hypernetworks that allow to vary from an RNN to a CNN, this is not clear to me, maybe you could show how this would work on a simple temporal problem with equations.   The work on CNN and RNN are rather disconnected to me: for CNN, you seem to be interested in a low rank structure of the weights, showing that similar performance can be achieved with less weights. It is not clear to me why to pursue that goal. Do you expect speedups? less memory for embedded applications? In that case you should compare with alternative strategies, e.g. model compression (Caruana et al 2006, aka Dark Knowledge, Hinton et al 2014) or hashed networks (Chen et al 2015).   For RNN, you seem to target better perplexity/BLEU and model compactness is not a priority. Instead of making the weights have a simpler structure, you make them richer, i.e. dependent over time. It seems in that case models might be bigger and take longer to train. You might want to comment on training time, inference time, memory requirement in that case, as you highlight it might be an important goal in the CNN section. Overall, I am not sure it helps to have this mixed message. I would rather see the paper fit in the conference format with the RNN results alone and a clearer explanation and defers the publications of the CNN results when a proper comparison with memory concerned methods is performed.  Some of the discussions are not clear to me, I am not sure what message the reader should get from Figure 2 or from the discussion on saturation statistics (p10, Figure 5). Similarly, I am not sure if Figure 4 is showing anything: everything should change more drastically at word boundaries even in a regular LSTM (states, gates units should look very different before/after a space); without such a comparison it is hard to see if this is unique to your network.  The results on handwriting generation are harder to compare for me. Log-loss are hard to understand, I have no sense whether the difference between models is significant (what would be the variance in this metric under boostrap sampling of the training set?). I am not sold either on qualitative metric were human can assess quality but human cannot evaluate if the network is repeating the training set. Did you thing at precision/recall metric for ink, possibly with some spatial tolerance ? (e.g. evaluation of segmentation tasks in vision).  The MT experiments are insufficiently discussed in the main text.  Overall, I would suggest to make the paper shorter and clearer possibly leaving the CNN results for latter publication. You need to properly discuss the relation to multiplicative/order 2 networks and highlight the differences. Unclear discussion can be eliminated to make the experimental setup and the results presentation clearer in the main text.  *** References ***  M.W. Goudreau, C.L. Giles, S.T. Chakradhar, D. Chen, \"First-Order Vs. Second-Order Single Layer Recurrent Neural Networks,\"IEEE Trans. on Neural Networks, 5 (3), p. 511, 1994.  Cristian Bucila, Rich Caruana, and Alexandru Niculescu-Mizil, \"Model Compression,\" The Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-2006), August 2006, pp. 535-541.  Dark knowledge, G Hinton, O Vinyals, J Dean 2014  W. Chen, J. Wilson, S. Tyree, K. Weinberger and Y. Chen, Compressing Neural Networks with the Hashing Trick, Proc. International Conference on Machine Learning (ICML-15)",
            "output": [
                "en"
            ]
        },
        {
            "input": " It has recently come to my attention that the objective proposed by the authors in this paper has in fact already been studied in the literature under the name 'reward-weighted regression', from e.g. ICML 2007 [1]. This has spawned several other works using the same objective (e.g. [2]). One can examine for instance the objective proposed in Section 3.4 from [2], from ICANN 2008.  While this paper has already been accepted to ICLR, it would be beneficial for the authors to at least cite these works (and other related works) so that readers are aware of the previous origins of this idea.  [1] ",
            "output": [
                "en"
            ]
        },
        {
            "input": "El tema del artículo es novedoso y necesario en la literatura de modelamiento de procesos  El trabajo en general presenta un desarrollo pobre en lo teórico. Para llevar a efecto la comparación entre las técnicas de modelamiento de procesos se debe construir una metodología que muestre efectivamente las ventajas de un método por sobre el otro.  La comparación efectuada entre los métodos debe ser presentada para un caso general, dado que en ninguna parte la metodología explica que se va a aplicar a una  situación particular.  La metodología del artículo no explicita adecuadamente la forma en la cual se desarrolló la comparación, sólo expone los criterios de decisión utilizados en su construcción, lo cual no permite evaluar adecuadamente los resultados obtenidos.  No se expone con claridad la pregunta de investigación y los objetivos del estudio efectuado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo es interesante, tanto en la aplicación de la teoría de control como de robótica móvil. requiere de una revisión completa de redacción, ortografía y puntuación.  Adjunto el archivo revisado con algunas anotaciones para mejorar la presentación, sin embargo los autores deben volver a revisar completamente el documento.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Interesante paper que muestra el desarrollo de un observatorio astronómico virtual con posibles importantes implicaciones para la comunidad informática nacional. A este respecto sería deseable que durante la presentación se aclarasen aspectos como ¿Está abierta la participación a otras universidades a colaborar en los desafíos que se deriven de este proyecto? ¿Está pensado trabajar con más observatorios en el futuro? ¿Qué lecciones o guías se pueden extraer de la experiencia en la implementación de los otros observatorios virtuales alrededor del mundo, y del provecho que de estos han sacado los investigadores de las ciencias de la computación?",
            "output": [
                "es"
            ]
        },
        {
            "input": "Comentarios generales: • Se habla de una plantilla, sin embargo en ninguna parte del artículo aparece esta plantilla • Se recomienda pueda ser incluida un ejemplo de recopilación de datos en la plantilla • El agregar gráficos de datos analizados puede apoyar en una mejor comprensión del análisis que se realizó. • Revisar todo el escrito ya que hay muchas inconsistencias en el escrito por ejemplo: artículos de más o faltan palabras • Revisar el espaciado de los párrafos • Se tiene muy poca bibliografía • Revisar que las sangrías utilizadas como inicio de párrafo estén acordes con el formato del congreso • Revisar el formato delas referencias bibliográficas  Comentarios por secciones Palabras clave: • Revisar las palabras clave: …caso de estudio, ISO 9126 Introducción • General….? → Generalmente o En general C. ISO 9126 • Se recomienda revisar la traducción realizada en la sección del ISO 9126, además de tener cuidado en las sub características que menciona y en lo que realmente luego describe ya que en más de una ocasión no coinciden los nombres. • La eficiencia no está descrita como lo viene haciendo con otros atributos de calidad • Revisar las sub características incluidas en el atributo de portabilidad, en especial en las sub características de efectividad, productividad, seguridad física y satisfacción, poner referencia de donde extrajo esa información Desarrollo de la plantilla • Entiendo que el primer bullet “Al interactuar…” una breve descripción del momento en el que debes de contestar la pregunta asociada “¿Existe…”, recomiendo utilizar distintos bullets ya que así como lo tienes causa confusión… así en todos los apartados que aplique esta situación Aplicación del caso práctico • Se recomienda una mejor descripción de los porcentajes por ejemplo agregar una tabla en la que se mencionen número total de preguntas asociadas a cada atributo y el porcentaje asociado",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors describe a dataset of proof steps in higher order logic derived from a set of proven theorems. The success of methods like AlphaGo suggests that for hard combinatorial style problems, having a curated set of expert data (in this case the sequence of subproofs) is a good launching point for possibly super-human performance. Super-human ATPs are clearly extremely valuable. Although relatively smaller than the original Go datasets, this dataset seems to be a great first step. Unfortunately, the ATP and HOL aspect of this work is not my area of expertise. I can't comment on the quality of this aspect.  It would be great to see future work scale up the baselines and integrate the networks into state of the art ATPs. The capacity of deep learning methods to scale and take advantage of larger datasets means there's a possibility of an iterative approach to improving ATPs: as the ATPs get stronger they may generate more data in the form of new theorems. This may be a long way off, but the possibility is exciting.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Interesante trabajo que trata de la simulación de entornos urbanos para simular accidentes y medir los efectos de intervenciones urbanas que ayuden en su prevención. El trabajo es un aporte tanto desde el punto de vista del objetivo de la misma, como de la descripción detallada que realiza sobre el proceso de integración de tecnologías que permitieron llevarla a cabo, lo cual se puede replicar para proyectos que utilicen la tecnología 3d con otros objetivos, así como de las estrategias usadas para refinar el modelo a través de globos aerostáticos. Se echa de menos, eso sí, una revisión de trabajos similares para haber establecido una comparación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Un trabajo muy claro, preciso y del alto nivel",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo está bien preparado técnicamente. Su estructura y redacción facilita su seguimiento. No obstante, tengo dudas acerca de su contribución científica ya que es la aplicación de modelamiento a un caso de estudio. No se establece claramente cuál es el problema a solucionar. Las metodologías orientadas a aspectos tienen ya algún tiempo aplicándose con éxito y tampoco se entrega información de trabajos previos para atacar el gap. Creo que se debe distinguir por qué es necesaria la aplicación de UML (y no de otras técnicas) para resolverlo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Some of the key details in this paper are very poorly explained or not even explained at all. The model sounds interesting and there may be something good here, but it should not be published in it's current form.   Specific comments:  The description of the R_l,pi convolutions in Section 2.1 was unclear. Specifically, I wasn't confident that I understood what the labels pi represented.  The description of the SAEN structure in section 2.2 was worded poorly. My understanding, based on Equation 1, is that the 'shift' operation is simply a summation of the representations of the member objects, and that the 'aggregate' operation simply concatenates the representations from multiple relations.  In the 'shift' step, it seems more appropriate to average over the object's member's representations h_j, rather than sum over them.  The compression technique presented in Section 2.3 requires that multiple objects at a level have the same representation. Why would this ever occur, given that the representations are real valued and high-dimensional? The text is unintelligible: \"two objects are equivalent if they are made by same sets of parts for all the pi-parameterizations of the R_l,pi decomposition relation.\"   The 'ego graph patterns' in Figure 1 and 'Ego Graph  Neural Network' used in the experiments are never explained in the text, and no references are given. Because of this, I cannot comment on the quality of the experiments.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El paper describe el proceso de evaluación de una aplicación móvil a partir de un conjunto de índices pre-definidos. En las dos primeras páginas se expone el tipo de aplicación móvil y la justificación a la selección de índices. Luego un análisis de los índices, indicando la muestra realizada y la metodología.  * Se extraña una presentación formal de la aplicación móvil, más allá de simplemente expresar su funcionalidad. * La búsqueda de correlaciones entre los distintos índices son obvias y están asociadas claramente a la evaluación por parte de los usuarios. * Desconozco la necesidad de plantear la diferencia entre sexo de la población muestral, no es un dato significativo. * El cuestionario seleccionado * Es poco significativo el encontrar a partir de los datos que la variable que más aporta a la predicción de calidad es la \"usabilidad\". Este punto es obvio en una aplicación móvil debido a su naturaleza. * Las conclusiones no aportan al trabajo realizado, se debería plantear una posible extensión de la evaluación a dispositivos móviles de tamaño mayor, por ejemplo: tables.  El proceso de medición de calidad que se propone sólo puede ser evaluado en su aplicación en distintas aplicaciones móviles, no solamente en una para mejorar la gestión de pago de los impuestos federales.  Con respecto a la ortografía, es muy común la falta de tilde en varias palabras: solicitó, explicó,  especificó, elaboró, proporcionó, etc.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper presents a hierarchical DRL algorithm that solves sequences of navigate-and-act tasks in a 2D maze domain. During training and evaluation, a list of sub-goals represented by text is given to the agent and its goal is to learn to use pre-learned skills in order to solve a list of sub-goals. The authors demonstrate that their method generalizes well to sequences of varying length as well as to new combinations of sub-goals (i.e., if the agent knows how to pick up a diamond and how to visit an apple, it can also visit the diamond).   Overall, the paper is of high technical quality and presents an interesting and non-trivial combination of state-of-the-art advancements in Deep Learning (DL) and Deep Reinforcement Learning (DRL). In particular, the authors presents a DRL agent that is hierarchical in the sense that it can learn skills and plan using them. The skills are learned using a differential temporally extended memory networks with an attention mechanism. The authors also make a novel use of analogy making and parameter prediction.   However, I find it difficult to understand from the paper why the presented problem is interesting and why hadn't it bee solved before. Since the domain being evaluated is a simple 2D maze, using deep networks is not well motivated. Similar problems have been solved using simpler models. In particular, there is a reach literature about planning with skills that had been ignored completely by the authors. Since all of the skills are trained prior to the evaluation of the hierarchical agent, the problem that is being solved is much more similar to supervised learning than reinforcement learning (since when using the pre-trained skills the reward is not particularly delayed). The generalization that is demonstrated seems to be limited to breaking a sentence (describing the subtask) into words (item, location, action).   The paper is difficult to read, it is constantly switching between describing the algorithm and giving technical details. In particular, I find it to be overloaded with details that interfere with the general understanding of the paper. I suggest moving many of the implementation details into the appendix. The paper should be self-contained, please do not assume that the reader is familiar with all the methods that you use and introduce all the relevant notations.   I believe that the paper will benefit from addressing the problems I described above and will make a better contribution to the community in a future conference.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- La herramienta APARD - La temática asociada a requerimientos y fábrica de software es interesante  - No está detallado el caso práctico que considere el uso APARD con sus ventajas y limitaciones - La sección que explica la implementación de la solución APARD debe ser mejorada - Mejorar conclusiones - La presentación:  con errores ortográficos y de redacción, escrito en primera persona, figuras con letras muy pequeñas, color blanco de letras en figuras la hacen poco legible, referencias escritas de diferente forma, etc. - Se recomienda no utilizar Wikipedia como referencia para un artículo científico. - Falta autor en referencias 6, falta nombre de tema en referencia 13 - Referencia 7 está escrita con autor de manera diferente a las otras y con título antes de autor. - Cambiar “Palabras claves” por “Palabras clave”. - De acuerdo a formato, poner como mínimo 5 palabras clave. - Pone referencia en otro formato, ejemplo, Greenfield y Short(2003) - Hay mucho detalle de tecnologías y herramientas y productos detallados en la sección Especificación Tecnológica de APARD - ¿Qué significa IQNET[z]? - Sugiero poner en Introducción las secciones que componen el paper.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este articulo presenta un \"estado del arte\" en sistemas cooperativos con múltiples robots. Desde esta perspectiva, es un artículo de divulgación escrito adecuadamente y que desde el punto de vista de la bibliografía incluye referencias actuales.  Resulta complejo realizar una evaluación de un artículo de este tipo por su aporte, aunque hubiese sido adecuado proporcionar algún subproducto final, como una tabla comparativa o alguna evaluación (¿áreas de aplicación?) basada en el trabajo de investigación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper describes a network architecture for inverse problems in computer vision. Example inverse problems considered are image inpainting, computing intrinsic image decomposition and foreground/background separation. The architecture is composed of (i) a generator that produces target (latent) output (such as foreground / background regions),  (ii) renderer that composes that latent output back to the image that can be compared with the input to measure reconstruction error,  and (iii) adversarial prior that ensures the target output (latent) image respects a certain image statistics.  Strong  points. - The proposed architecture with memory database is interesting and appears to be novel.   Weak points: - Experimental results are only proof-of-concept in toy set-ups and do not clearly demonstrate benefits of the proposed architecture. - It is unclear whether the memory retrieval engine that retrieves images based on L2 distance on pixel values is going generalize to other more realistic scenarios.  - Clarity. The clarity of explanation can be also improved (see below).   Detailed evaluation.  Originality: - The novelty of this work lies in the (iii) adversarial prior that places an adversarial loss between the generated latent output and a single image retrieved from a large unlabelled database of target output examples (called memory). The adversarial prior has a convolutional form matching local image statistics, rather than the entire image.  The particular form of network architecture with the memory-based fully convolutional adversarial loss appears to be novel and potentially interesting.  - Motivation for the Architecture. The weakest point of the proposed architecture is the \"Memory retrieval engine\" R (section 2.4), where images are retrieved from the memory by measuring L2 distance on pixel intensities. While this maybe ok for simple problems considered in this work, it is unclear how this can generalize to other more complicated datasets and problems.   This should be better discussed, better justified and ideally results in some more realistic set-up shown (see below).   Quality: - Experiments. Results are shown for inpainting of MNIST digits, intrinsic image decomposition on the MIT intrinsic image database, and figure/ground layer extraction on the synthesized dataset of 3D chairs rendered onto background from real photographs.    The experimental validation of the model is not very strong and proof-of-concept only. All the experiments are performed in simplified toy set-ups. The MNIST digit inpainting is far from current state-of-the-art on image inpainting in real photographs (see e.g. Pathak et al., 2016). The foreground background separation is done on  only synthetically generated test data. Even for intrinsic image demposition problem there is now relatively large-scale dataset of (Bell et al., 2014), see the citation below.    While this is probably ok for the ICLR paper, it diminishes the significance of the work. Is this model going to be useful in a real settings? One possibility to address this would be to focus on one of the problems and show results on a challenging state-of-the-art data. It would be great to see the benefits of the memory database.   S. Bell, K. Bala, and N. Snavely. Intrinsic images in the wild. ACM Transactions on Graphics, 33(4):159, 2014.  Clarity: - The clarity of the writing can be improved. I found some of the terminology of the paper, specially the “imagination” and “memory” confusing. From figure 2, it is not clear how the “memories” for the given input image are obtained, which also took me some time to understand.  - To help understand the proposed architecture, it would be useful to draw an illustration of what is happening in the \"feature space”, similar in spirit e.g. to figure 2 in",
            "output": [
                "en"
            ]
        },
        {
            "input": "Es un excelente trabajo de investigación de aplicación tecnológica, vinculada con una empresa de la zona, artículo muy apropiado para Infonor  Tiene fallas con respecto a un artículo tradicional, no hay trabajos relacionados, citaciones, referencias, etc. Tiene problemas de redacción, pero es claro en lo que presenta. Tiene frases largas y hay problemas de puntuación. Habría que adaptarlo para que pase la revisión de la revista.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths: This paper presents an extension of many popular methods for learning vector representations of text.  The original methods, such as skip-gram with negative sampling, Glove, or other PMI based approaches currently use word cooccurrence statistics, but all of those approaches could be extended to n-gram based statistics.  N-gram based statistics would increase the complexity of every algorithm because both the vocabulary of the embeddings and the context space would be many times larger.  This paper presents a method to learn embeddings for ngrams with ngram context, and efficiently computes these embeddings.  On similarity and analogy tasks, they present strong results.  - Weaknesses: I would have loved to see some experiments on real tasks where these embeddings are used as input beyond the experiments presented in the paper.  That would have made the paper far stronger.  - General Discussion: Even with the aforementioned weakness, I think this is a nice paper to have at ACL.  I have read the author response.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper extends PixelCNN to do text and location conditional image generation. The reviewers praise the diversity of the generated samples, which seems like the strongest result of the paper. On the other hand, they are concerned with their low resolution. The authors made an effort of showing a few high-resolution samples in the rebuttal, which indeed look better. Two reviewers mention that the work with respect to PixelCNN is very incremental, and the AC agrees. Overall, this paper is very borderline. While all reviewers became slightly more positive, none was particularly swayed. The paper will make a nice workshop contribution.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo presenta un report sobre aspectos de seguridad del producto software dependiendo de las tecnologías utilizadas para su desarrollo. Creo que falta rigor científico en la búsqueda de información. De hecho no es claramente explicado cómo se obtuvo la información por lo que queda como una monografía o marco teórico de un tema a investigar. No obstante, el estudio está bien presentado y su estructura es de calidad técnica. Creo que con una búsqueda en artículo de investigación puede ser mejorado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta el proceso de construcción de un almacén de datos para implementar OLAP sobre datos de explotación de recursos marinos en las costas de Chile.  El problema está claramente delimitado y tiene aplicación práctica relevante para el país.  El trabajo presentado corresponde a un caso de uso muy completo y detalladamente documentado de técnicas bien conocidas de minería de datos.  El ABSTRACT debe ser editado para que represente una traducción apropiada y legible del RESUMEN.  No es evidente el aporte original del trabajo.  Las conclusiones originales del artículo dicen relación con el dominio de la aplicación (estadísticas de explotación de recursos marinos) y no con temas relevantes a la conferencia.  Debería completarse la información faltante en la bibliografía.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper describes a novel technique to improve the efficiency of computation graphs in deep learning frameworks. An impressive speedup can be observed in their implementation within TensorFlow. The content is presented with sufficient clarity, although some more graphical illustrations could be useful. This work is relevant in order to achieve highest performance in neural network training.   Pros:  - significant speed improvements through dynamic batching - source code provided   Cons:  - the effect on a large real-world (ASR, SMT) would allow the reader to put the improvements better into context - presentation/vizualisation can be improved",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo es especialmente válido como una guía de implementación de un data center. Su nivel teórico no es relevante, sin embargo su aplicabilidad le hace de interés.  El artículo está bien escrito y documentado.  Se debe insistir que se trata de un caso y este caso está desarrollado completo siguiendo las normas TIA propuestas como referencia.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Los autores presentan una propuesta de herramienta para la medición de valor y trazabilidad, sin embargo, a raíz de los errores de forma y redacción, no queda claro el aporte a la disciplina.  Sería deseable la exposición de la aplicación de la herramienta propuesta, pero sobre actividades de la disciplina.   Forma: - Falta el abstract en inglés. - La tabla 1 se encuentra cortada entre páginas. - El formato posee mucho margen entre el texto y el borde de la página. - No se cita correctamente las figuras. - La introducción es MUY extensa, se puede reducir el número de párrafos y mantener la claridad de lo expuesto. - Las variables definidas en el documento: Expectativas, Calidad, etc. deberían ser enumeradas. - La enumeración de los capítulos tienen distinta fuente. - \".. se validó la el modelo..\" ?",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper delves into the mathematical properties of the skip-gram model, explaining the reason for its success on the analogy task and for the general superiority of additive composition models. It also establishes a link between skip-gram and Sufficient Dimensionality Reduction.  I liked the focus of this paper on explaining the properties of skip-gram, and generally found it inspiring to read. I very much appreciate the effort to understand the assumptions of the model, and the way it affects (or is affected by) the composition operations that it is used to perform. In that respect, I think it is a very worthwhile read for the community.  My main criticism is however that the paper is linguistically rather naive. The authors' use of 'compositionality' (as an operation that takes a set of words and returns another with the same meaning) is extremely strange. Two words can of course be composed and produce a vector that is a) far away from both; b) does not correspond to any other concept in the space; c) still has meaning (productivity wouldn't exist otherwise!) Compositionality in linguistic terms simply refers to the process of combining linguistic constituents to produce higher-level constructs. It does not assume any further constraint, apart from some vague (and debatable) notion of semantic transparency. The paper's implication (l254) that composition takes place over sets is also wrong: ordering matters hugely (e.g. 'sugar cane' is not 'cane sugar'). This is a well-known shortcoming of additive composition.   Another important aspect is that there are pragmatic factors that make humans prefer certain phrases to single words in particular contexts (and the opposite), naturally changing the underlying distribution of words in a large corpus. For instance, talking of a 'male royalty' rather than a 'king' or 'prince' usually has implications with regard to the intent of the speaker (here, perhaps highlighting a gender difference). This means that the equation in l258 (or for that matter the KL-divergence modification) does not hold, not because of noise in the data, but because of fundamental linguistic processes. This point may be addressed by the section on SDR, but I am not completely sure (see my comments below).  In a nutshell, I think the way that the authors present composition is flawed, but the paper convinces me that this is indeed what happens in skip-gram, and I think this is an interesting contribution.   The part about Sufficient Dimensionality Reduction seems a little disconnected from the previous argument as it stands. I'm afraid I wasn't able to fully follow the argument, and I would be grateful for some clarification in the authors' response. If I understand it well, the argument is that skip-gram produces a model where a word's neighbours follow some exponential parametrisation of a categorical distribution, but it is unclear whether this actually reflects the distribution of the corpus (as opposed to what happens in, say, a pure count-based model). The fact that skip-gram performs well despite not reflecting the data is that it implements some form of SDR, which does not need to make any assumption about the underlying form of the data. But then, is it fair to say that the resulting representations are optimised for tasks where geometrical regularities are important, regardless of the actual pattern of the data? I.e. there some kind of denoising going on?  Minor comments:  - The abstract is unusually long and could, I think, be shortened.  - para starting l71: I think it would be misconstrued to see circularity here. Firth observed that co-occurrence effects were correlated with similarity judgements, but those judgements are the very cognitive processes that we are trying to model with statistical methods. Co-occurrence effects and vector space word representations are in some sense 'the same thing', modelling an underlying linguistic process we do not have direct observations for. So pair-wise similarity is not there to break any circularity, it is there because it better models the kind of judgements humans known to make.  - l296: I think 'paraphrase' would be a better word than 'synonym' here, given that we are comparing a set of words with a unique lexical item.  - para starting l322: this is interesting, and actually, a lot of the zipfian distribution (the long tail) is fairly uniform.  - l336: it is probably worth pointing out that the analogy relation does not hold so well in practice and requires to 'ignore' the first returned neighbour of the analogy computation (which is usually one of the observed terms).  - para starting l343: I don't find it so intuitive to say that 'man' would be a synonym/paraphrase of anything involving 'woman'. The subtraction involved in the analogy computation is precisely not a straightforward composition operation, as it involves an implicit negation.   - A last, tiny general comment. It is usual to write p(w|c) to mean the probability of a word given a context, but in the paper 'w' is actually the context and 'c' the target word. It makes reading a little bit harder... Perhaps change the notation?  Literature:  The claim that Arora (2016) is the only work to try and understand vector composition is a bit strong. For instance, see the work by Paperno & Baroni on explaining the success of addition as a composition method over PMI-weighted vectors:  D. Paperno and M. Baroni. 2016. When the whole is less than the sum of its parts: How composition affects PMI values in distributional semantic vectors. Computational Linguistics 42(2): 345-350.  *** I thank the authors for their response and hope to see this paper accepted.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Se presentan los siguientes problemas de forma:  - Figura 1: el texto de la figura no es legible y además se encuentra deformado. - Figura 2: no representa la problemática expuesta en el trabajo, además no se encuentra referenciada. - Ortografía: \".. del uso de La tecnologia NFC ..\", debe ser: \".. del uso de la tecnología NFC ..\". - Faltan puntos a parte. - Ortografía: \".. aplicaciones com relacion al uso ..\" debe ser: \".. aplicaciones con relación al ..\". - Tabla 1: Título incorrecto y tabla cortaba en su final. - Cambio de tamaño de letra después de la tabla 1 - Tabla 2: Texto deformado. - A lo largo del texto no posee referencias a las afirmaciones: \"es muy difícil intervenir una comunicación NFC\". - Las etapas del proceso de transacción deben estar enumeradas. - Las tablas se encuentran mal numeradas. - Las páginas no se encuentran numeradas. - La descripción de indicadores (sección 7) no aporta al trabajo propuesto.   Problemas de fondo:  - No presenta una solución formal al pago vía tecnología NFC, a pesar que es el punto central del trabajo. - Las interfaces gráficas presentadas no se encuentran definidas en conformidad con las normas gráficas de aplicaciones móviles. - Las conclusiones no arrojan luz sobre la problemáticas planteada.  El trabajo desarrollado no es claro sobre la problemática planteada, debería incluir un análisis más detallado de tecnologías ya implementadas: UberTaxi, etc.",
            "output": [
                "es"
            ]
        },
        {
            "input": "• Los títulos no van con “.” • Resumen   o“El objetivo de este documento es intentar recolectar…” --> sugiero quitar la palabra intentar •Abstract   oRevisar la gramática ya que se encuentran falta de artículos y algunas frases mal redactadas por ejemplo:    -\tThe images emerging technologies -->  the images technology emerging    -\tsuch as machine vision systems and scanning --> such as the machine vision systems and the scanning…    -\t…The objective of this paper is to try to collect… --> The objective of this paper is to try to collect    -\t the state of the art processing for 3d point cloud processing, going from the filters to the segmentation --> the state of the art of  processing the 3d point for the cloud processing going from the filters to the segmentation   oTexto en general revisar la falta de acentos y las palabras duplicadas, entre otros:    -Introducción: máquinas    -Trabajo realizado:       •\t…que en general, que --> segundo que sobra       •\tTrabajo realizado   oSimplificación de puntos, la segunda vez que pone la referencia [3] sobra    - La primera vez que aparecen unas siglas se deben incluir su significado RANSAC?       •\tSegmentación   o...Muchas investigaciones --> cuáles? Incluir referencia de ese conjunto de muchas investigaciones   oExiste la palabra convolución? En la RAE no   oPresen-tan --> presentan       • Conclusiones   oFormato de las conclusiones       •\tReferencias   oCompletar la referencias: 2,3,4,5,6,7 y 11       •\tEl artículo se queda en una recopilación de los trabajos enfocados en filtrado y documentación de la nube de puntos, recomiendo ir más allá, esto es hacer un mapeo de los trabajos que mencionas, el primero de los de simplificación y el segundo de los de segmentación basado en las características, alcance, debilidades y oportunidades de mejora identificadas, esto para que realmente hagas una aportación con tu artículo",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper describes a correction technique to combine updates from multiple SGD to make it statistically equivalent to sequential technique. Comments 1) The proposed method is novel and interesting to allow update to be corrected even when the update is delayed. 2) The proposed theory can only be applied to square loss setting (with linear update rule), making it somewhat limited. This paper would be much more interesting to ICLR community, if the technique is applicable to general objective function and settings of deep neural networks. 3) The resulting technique requires book-keeping of a dimensional reduced combiner matrix, which causes more computation in terms of complexity. The authors argue that the overhead can be canceled with SIMD support for symbolic update. However, the normal update of SGD might also benefit from SIMD, especially when the dataset is dense.  Overall, even though the practical value of this work is limited by 2) and 3), the technique(specifically the correction rule) proposed in the paper could be of interest to people scaling up learning. I would encourage the author to extend the method to the cases of non-linear objective function which could make it more interesting to the ICLR community",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: The idea of hard monotonic attention is new and substantially different from others.  - Weaknesses: The experiment results on morphological inflection generation is somewhat mixed. The proposed model is effective if the amount of training data is small (such as CELEX). It is also effective if the alignment is mostly monotonic and less context sensitive (such as Russian, German and Spanish).  - General Discussion:  The authors proposed a novel neural model for morphological inflection generation which uses \"hard attention\", character alignments separately obtained by using a Bayesian method for transliteration. It is substantially different from the previous state of the art neural model for the task which uses \"soft attention\", where character alignment and conversion are solved jointly in the probabilistic model.  The idea is novel and sound. The paper is clearly written. The experiment is comprehensive. The only concern is that the proposed method is not necessarily the state of the art in all conditions. It is suitable for the task with mostly monotonic alignment and with less context sensitive phenomena. The paper would be more convincing if it describe the practical merits of the proposed method, such as the ease of implementation and computational cost.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo presenta una investigación en desarrollo relacionada con el costo que tiene la contratación de servicios de TI para las organizaciones, específicamente se propone un caso de estudio en la Industria Minera de Chile. El trabajo está enfocado en un caso de negocios, sin embargo aunque el documento hace énfasis en la recopilación teórica de los conceptos asociados a los aspectos financieros y de costos de los servicios contratados de TI, el caso de estudio no está claro y el artículo parece incompleto. La estructura del documento genera confusión debido a que en la introducción se establecen objetivos asociados al caso de estudio pero al finalizar el documento los resultados no se presentan porque la investigación está en desarrollo. Se sugiere acotar el artículo y estructurarlo mejor, de tal forma que se puedan presentar los resultados preliminares obtenidos hasta el punto en el que se encuentra el proyecto de investigación, es decir una revisión conceptual de aspectos financieros para Servicios de TI, sin generar expectativas frente al desarrollo de estadísticas o análisis de costos que todavía no se han calculado. Para tener un fuerte énfasis en la revisión de conceptos, el artículo tiene pocas referencias. Se recomienda mejorar los conceptos y la base conceptual a partir de una revisión de literatura amplia que permita fundamentar la investigación y presentar resultados parciales de la revisión de conceptos. Existen deficiencias acentuadas en la redacción del documento. Desde el resumen faltan letras y los signos de puntuación no son claros. En párrafos como el primero de la segunda columna de la página 3 es difícil de entender la idea y eso hace difícil la lectura del documento. En apartados de definición de conceptos tales como Costos de TI (pag 3) es necesario referenciar las afirmaciones conceptuales (base fundamental del artículo). Se recomienda tener en cuenta los términos en inglés unificar la forma de citar términos o conceptos. Algunos no pueden ser traducidos, pero es recomendable manejar conceptos en un solo idioma. Además, es recomendable definir el objetivo del artículo y enfocarlo a un solo fin. Es decir, si se quiere presentar la metodología paras el diseño de la investigación se debe hacer énfasis en ella. O bien, si lo que se quiere es hacer énfasis en los cálculos establecidos o diseñados por medio de la herramienta enfocar entonces el artículo en este objetivo. Como recomendación general se sugiere enfocar el artículo en una revisión conceptual de Costos financieros de la contratación de Servicios de TI en las empresas de Chile, teniendo en cuenta que la investigación está en una etapa inicial.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Un buen tema, en términos de convocar a la sociedad en las utilidades y aplicaciones de las TICs   Se dice en la propuesta que: \"se desarrollaran\" métodos, \"se proporcionará\" una arquitectura de apoyo a la toma de decisiones, \"se podrá\" medir la receptividad, \"se desarrollará\" un inventario de las TICs. Desgraciadamente, nada de lo anterior se pudo concretar con estudios que sustenten lo anterior. Se hacen juicios de valor sin tener el respaldo suficiente. No se menciona en la introducción la información de organismos internacional en el contexto de la propuesta, como OECD o World Economic Forum, entre otros. Además, no se fundamenta la diferencia, aporte e innovación de la presente propuesta con la que se presentó al Proceedings of the 3rd International Conference on Theory and Practice of Electronic Governance.Bogota Noviembre 2009.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper introduces pointer-network neural networks, which are applied to referring expressions in three small-scale language modeling tasks: dialogue modeling, recipe modeling and news article modeling. When conditioned on the co-reference chain, the proposed models outperform standard sequence-to-sequence models with attention.  The proposed models are essentially variants of pointer networks with copy mechanisms (Gulcehre et al., 2016; Gu et al., 2016; Ling et al., 2016), which have been modified to take into account reference chains. As such, the main architectural novelty lies in 1) restricting the pointer mechanism to focus on co-referenced entities, 2) applying pointer mechanism to 2D arrays (tables), and 3) training with supervised alignments. Although useful in practice, these are minor contributions from an architectural perspective.  The empirical contributions are centred around measuring perplexity on the three language modeling tasks. Measuring perplexity is typical for standard language modeling tasks, but is really an unreliable proxy for dialogue modeling and recipe generation performance. In addition to this, both the dialogue and recipe tasks are tiny compared to standard language modeling tasks. This makes it difficult to evaluate the impact of the dialogue and recipe modeling results. For example, if one was to bootstrap from a larger corpus, it seems likely that a standard sequence-to-sequence model with attention would yield performance comparable to the proposed models (with enough data, the attention mechanism could learn to align referring entities by itself). The language modeling task on news article (Gigaword) seems to yield the most conclusive results. However, the dataset for this task is non-standard and results are provided for only a single baseline. Overall, this limits the conclusions we can draw from the empirical experiments.   Finally, the paper itself contains many errors, including mathematical errors, grammatical errors and typos: - Eq. (1) is missing a sum over $z_i$. - \"into the a decoder LSTM\" -> \"into the decoder LSTM\" - \"denoted as his\" -> \"denoted as\" - \"Surprising,\" -> \"Surprisingly,\" - \"torkens\" -> \"tokens\" - \"if follows that the next token\" -> \"the next token\" - In the \"COREFERENCE BASED LANGUAGE MODEL\" sub-section, what does $M$ denote? - In the sentence: \"The attribute of each column is denoted as $s_c, where $c$ is the c-th attribute\". For these definitions to be make sense, $s_c$ has to be a one-hot vector. If yes, please clarify this in the text. - \"the weighted sum is performed\" -> \"the weighted sum is computed\" - \"a attribute\" -> \"an attribute\" - In the paragraph on Pointer Switch, change $p(z_{i,v} |s_{i,v}) = 1$ -> $p(z_{i,v} |s_{i,v}) = 0$. - In the \"Table Pointer\" paragraph, I assume you mean outer-product instead of cross-product? Otherwise, I don't see how the equations add up.   Other comments: - For the \"Attention based decoder\", is the attention computed using the word embeddings themselves or the hidden states of the sentence encoder? Also, it applied only to the previous turn of the dialogue or to the entire dialogue history? Please clarify this. - What's the advantage of using an \"Entity state update\" rule, compared to a pointer network or copy network, which you used in the dialogue and recipe tasks? Please elaborate on this. - In the Related Work section, the following sentence is not quite accurate: \"For the task oriented dialogues, most of them embed the seq2seq model in traditional dialogue systems while our model queries the database directly.\". There are task-oriented dialogue models which do query databases during natural language generation. See, for example, \"A Network-based End-to-End Trainable Task-oriented Dialogue System\" by Wen et al.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper is a well written paper. This paper can be divided into 2 parts: 1.Adversary training on ImageNet  2.Empirical study of label leak, single/multiple step attack, transferability and importance of model capacity  For part [1], I don’t think training without clean example will not make reasonable ImageNet level model. Ian’s experiment in “Explaining and Harnessing Adversarial Examples” didn't use BatchNorm, which may be important for training large scale model. This part looks like an extension to Ian’s work with Inception-V3 model. I suggest to add an experiment of training without clean samples.  For part [2], The experiments cover most variables in adversary training, yet lack technical depth.  The depth, model capacity experiments can be explained by regularizer effect of adv training;  Label leaking is novel; In transferability experiment with FGSM, if we do careful observe on some special MNIST FGSM example, we can find augmentation effect on numbers, which makes grey part on image to make the number look more like the other numbers. Although this effect is hard to be observed with complex data such as CIFAR-10 or ImageNet, they may be related to the authors' observation \"FGSM examples are most transferable\".    In this part the authors raise many interesting problems or guess, but lack theoretical explanations.   Overall I think these empirical observations are useful for future work.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta una implementación del caso de una \"red espacial\" en el sistema administrador de bases de datos espacial PostGIS. El artículo se centra en el modelamiento de caso planteado, lo cual resulta en un modelo clásico de bases de datos. Lamentablemente, hay  pocas luces sobre la posterior implementación y el trabajo de \"procesar consultas en redes espaciales en bases de datos espaciales\" como indica el artículo. Hay poca o nula información sobre los resultados obtenidos. Claramente se trata de un trabajo en desarrollo, del cual aún faltan aspectos esenciales para su real valorización.  La figura 2. tiene problemas, aparece corrida en la versión pdf, vista desde Acrobat Reader.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo expone de manera clara y con buenos argumentos un análisis de la colaboración entre distintos investigadores e instituciones. Es interesante el aporte realizado, primero como identificación de las oportunidades de mejora en el trabajo conjunto, y segundo, como análisis de la publicación local.  Sería interesante aplicar la misma metodología sobre otros congresos del área, ya sea Chilenos o latino-americanos y ver los resultados obtenidos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths:  - this article puts two fields together: text readability for humans and machine comprehension of texts  - Weaknesses:  - The goal of your paper is not entirely clear. I had to read the paper 4 times and I still do not understand what you are talking about! - The article is highly ambiguous what it talks about - machine comprehension or text readability for humans - you miss important work in the readability field - Section 2.2. has completely unrelated discussion of theoretical topics. - I have the feeling that this paper is trying to answer too many questions in the same time, by this making itself quite weak. Questions such as “does text readability have impact on RC datasets” should be analyzed separately from all these prerequisite skills.  - General Discussion:  - The title is a bit ambiguous, it would be good to clarify that you are referring to machine comprehension of text, and not human reading comprehension, because “reading comprehension” and “readability” usually mean that. - You say that your “dataset analysis suggested that the readability of RC datasets does not directly affect the question difficulty”, but this depends on the method/features used for answer detection, e.g. if you use POS/dependency parse features. - You need to proofread the English of your paper, there are some important omissions, like “the question is easy to solve simply look..” on page 1. - How do you annotate datasets with “metrics”?? - Here you are mixing machine reading comprehension of texts and human reading comprehension of texts, which, although somewhat similar, are also quite different, and also large areas. - “readability of text” is not “difficulty of reading contents”. Check this: DuBay, W.H. 2004. The Principles of Readability. Costa Mesa, CA: Impact information.  - it would be good if you put more pointers distinguishing your work from readability of questions for humans, because this article is highly ambiguous. E.g. on page 1 “These two examples show that the readability of the text does not necessarily correlate with the difficulty of the questions” you should add “for machine comprehension” - Section 3.1. - Again: are you referring to such skills for humans or for machines? If for machines, why are you citing papers for humans, and how sure are you they are referring to machines too? - How many questions the annotators had to annotate? Were the annotators clear they annotate the questions keeping in mind machines and not people?",
            "output": [
                "en"
            ]
        },
        {
            "input": "In this paper a well known soft mixture of experts model is adapted for, and applied to, a specific type of transfer learning problem in reinforcement learning (RL), namely transfer of action policies and value functions between similar tasks. Although not treated as such, the experimental setup is reminiscent of hierarchical RL works, an aspect which the paper does not consider at length, regrettably. One possible implication of this work is that architecture and even learning algorithm choices could simply be stated in terms of the objective of the target task, rather than being hand-engineered by the experimenter. This is clearly an interesting direction of future work which the paper illuminates.   Pros: The paper diligently explains how the network architecture fits in with various widely used reinforcement learning setups, which does facilitate continuation of this work. The experiments are good proofs of concept, but do not go beyond that i.m.h.o.  Even so, this work provides convincing clues that collections of deep networks, which were trained on not entirely different tasks, generalize better to related tasks when used together rather than through conventional transfer learning (e.g. fine-tuning).  Cons: As the paper well recounts in the related work section, libraries of fixed policies have long been formally proposed for reuse while learning similar tasks. Indeed, it is well understood in hierarchical RL literature that it can be beneficial to reuse libraries of fixed (Fernandez & Veloso 2006) or jointly learned policies which may not apply to the entire state space, e.g. options (Pricop et. al). What is not well understood is how to build such libraries, and this paper does not convincingly shed light in that direction, as far as I can tell. The transfer tasks have been picked to effectively illustrate the potential of the proposed architecture, but the paper does not tackle negative transfer or compositional reuse in well known challenging situations outlined in previous work (e.g. Parisotto et. al 2015, Rusu el. al 2015, 2016). Since the main contributions are of an empirical nature, I am curious how the results shown in figures 6 & 7 look plotted against wall-clock time, since relatively low data efficiency is not a limitation for achieving perfect play in Pong (see Mnih. et al, 2015). It would be more illuminating to consider tasks where final performance is plausibly limited by data availability. It would also be interesting if the presented results were achieved with reduced amounts of computation, or reduced representation sizes compared to learning from scratch, especially when one of the useful source tasks is an actual policy trained on the target task. Finally, it is perhaps underwhelming that it takes a quarter of the data required for learning Pong from scratch just to figure out that a perfect Pong policy is already in the expert library. Simply evaluating each expert for 10 episodes and using an  average-score-weighted majority vote to mix action choices would probably achieve the same final performance for a smaller fraction of the data.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper is well structured. It follows a logical sequence of sections.  The paper does not fix to the Infonor conference template.  The english grammar is poor. It makes the paper difficult to read and follow. Either:  a) rewrite the paper in spanish, or b) make the paper reviewed by a professional traslator  Most of the references are not recent (2005-2010). No new work since 2003? Some references do not indicate year.  Problems with equations, fonts, etc.  Figures 5-17 are not referenced/discussed/explained. It may be better to present these figures as a table.  Both, result analysis and conclusions, declare that GA CHC is better than Pearson´s correlation Algorithm. However, this analysis and conclusion is not supported for a wide variety of situations and conditions. Therefore, a true validation work is missing.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Quality, Clarity: There is no consensus on this, with the readers having varying backgrounds, and one reviewer commenting that they found it to be unreadable.     Originality, Significance:   The reviews are mixed on this, with the high score (7) acknowledging a lack of expertise on program induction.  The paper is based on the published TerpreT system, and some think that it marginal and contradictory with respect to the TerpreT paper. In the rebuttal, point (3) from the authors points to the need to better understand gradient-based program search, even if it is not always better. This leaves me torn about a decision on this paper, although currently it does not have strong support from the most knowledgeable reviewers.  That said, due to the originality of this work, the PCs are inclined to invite this work to be presented as a workshop contribution.",
            "output": [
                "en"
            ]
        },
        {
            "input": "In this paper, the authors propose a Bayesian variant of the skipgram model to learn word embeddings. There are two important variant compared to the original model. First, aligned sentences from multiple languages are used to train the model. Therefore, the context words of a given target word can be either from the same sentence, or from an aligned sentence in a different language. This allows to learn multilingual embedding. The second difference is that each word is represented by multiple vectors, one for each of its different senses. A latent variable z models which sense should be used, given the context.  Overall, I believe that the idea of using a probabilistic model to capture polysemy is an interesting idea. The model introduced in this paper is a nice generalization of the skipgram model in that direction. However, I found the paper a bit hard to follow. The formulation might probably be simplified (e.g. why not consider a target word w and a context c, where c is either in the source or target language. Since all factors are independent, this should not change the model much, and would make the presentation easier). The performance of all models reported in Table 2 & 3 seem pretty low.  Overall, I like the main idea of the paper, which is to represent word senses by latent variables in a probabilistic model. I feel that the method could be presented more clearly, which would make the paper much stronger. I also have some concerns regarding the experimental results.  Pros: Interesting extension of skipgram to capture polysemy. Cons: The paper is not clearly written. Results reported in the paper seems pretty low.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta una descripción de la integración entre CMMI y métodos ágiles de desarrollo. Un énfasis que hacen los autores es que esta integración es recomendable para PYME. El desarrollo de software para las más pequeñas empresas es un desafío aun no resuelto. Como tal, los autores toman un tema que es interesante y justifican bien la idea del tema. Sin embargo, creo que no logran desarrollar su punto en la forma que se esperaría desde un punto de vista científico. Aunque los autores indican que hacen una revisión de la literatura, esta no es lograda adecuadamente, ya que no se observa una metodología de revisión sistemática propia de esta meta. Por otra parte, el artículo en mi opinión hace un resumen adecuado para personas que no pertenecen al área pero están familiarizados con algunos conceptos claves descritos en el paper. Vale mencionar que me parece un artículo bien escrito y planteado, en general, con una estructura fácil de entender. Además, otra crítica que haría es que si bien las ideas de CMMI y desarrollo ágil me parecen bien descritas, no pasa lo mismo respecto a justificar adecuadamente su aplicación concreta en PYMEs. Pienso que el artículo podría ser mejorado sustancialmente. Una sugerencia que haría para ello sería la presentación de un caso que dé fuerza al argumento central del artículo, es decir, CMMI y desarrollo ágil son compatibles y especialmente útiles para PYMEs. De esa forma, podría darse menor énfasis a la revisión (que me parece insuficiente en ese sentido) y se alzaría la relevancia práctica del argumento. Si así fuera, el artículo podría tener una interesante proyección. Además, deberían mejorarse la inclusión de referencias ya que existen una gran cantidad de argumentos que merecen ser aclarados si pertenecen a una opinión de los autores o son extraídos de la teoría existente. Existen muy pequeños errores ortográficos y gramáticos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper presents an approach to learn to generate programs. Instead of directly trying to generate the program, the authors propose to train a neural net to estimate a fix set of attributes, which then condition a search procedure. This is an interesting approach, which make sense, as building a generative model of programs is a very complex task.  Faster computation times are shown in the experimental section with respect to baselines including DFS, Enumeration, etc. in a setup with very small programs of length up to 5 instructions have to be found.  It is not clear to me how the proposed approach scales to larger programs, where perhaps many attributes will be on. Is there still an advantage?  The authors use as metric the time to find a single program, whose execution will result in the set of 5 input-output pairs given as input. However, as mentioned in the paper, one is not after a generic program but after the best program, or a rank list of all programs (or top-k programs) that result in a correct execution. Could the authors show experiments in this setting? would still be useful to have the proposed approach? what would the challenges be in this more realistic scenario?  In the second experiment the authors show results where the length of the program at training time is different than the length at test time. However, the results are shown when only 20% of the programs are finished. Could you show results for finding all programs?   The paper is missing an analysis of the results. What type of programs are difficult? how often is the NNet wrong? how does this affect speed? what are the failure modes of the proposed method?  The authors proposed to have a fix-length representation of the each input-output pair, and then use average pooling to get the final representation. However, why would average pooling make sense here? would it make more sense to combine the predictions at the decoder, not the encoder?  Learning from only 5 executions seems very difficult to me. For programs so small it might be ok, but going to more difficult and longer programs this setting does not seem reasonable.   In summary an interesting paper. This paper tackles a problem that is outside my area of expertise so I might have miss something important.",
            "output": [
                "en"
            ]
        },
        {
            "input": "SUMMARY  This paper discusses how data from a special type of low dimensional structure (monotonic chain) can be efficiently represented in terms of neural networks with two hidden layers.   PROS  Interesting, easy to follow view on some of the capabilities of neural networks, highlighting the dimensionality reduction aspect, and pointing at possible directions for further investigation.   CONS  The paper presents a construction illustrating certain structures that can be captured by a network, but it does not address the learning problem (although it presents experiments where such structures do emerge, more or less).   COMMENTS  It would be interesting to study the ramifications of the presented observations for the case of deep(er) networks.  Also, to study to what extent the proposed picture describes the totality of functions that are representable by the networks.   MINOR COMMENTS  - Figure 1 could be referenced first in the text.   - ``Color coded'' where the color codes what?  - Thank you for thinking about revising the points from my first questions. Note: Isometry on the manifold.  - On page 5, mention how the orthogonal projection on S_k is realized in the network.  - On page 6 ``divided into segments'' here `segments' is maybe not the best word.  - On page 6 ``The mean relative error is 0.98'' what is the baseline here, or what does this number mean?",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este artículo presenta una interesante aplicación de algoritmos inmunes para  la programación de tareas.  Los resultados son de interés práctico.  Observaciones:  1.\tLos autores hacen uso frecuente de términos en inglés, sin  la necesaria definición de los mismos o substitución por un término en español.  2.\tHay inúmeros errores de redacción que deben ser corregidos. A modo de ejemplo citamos la frase “Mientras la tecnología computacional avanza a pasos agigantados es importante en estos días optimizar la programación de una mejor manera con el fin de obtener mejores resultados, es por esto que se ha dado el uso de algoritmos inspirados en sistemas biológicos, dado que presentan una mayor optimización que el uso de heurísticas convencionales”;  3.\tUn gran número de referencias está incompleta. Por ejemplo: 2, 3, 6 ......  Estas correcciones son necesarias  para la aceptación del trabajo",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper considers the problem of model-based policy search. The authors  consider the use of Bayesian Neural Networks to learn a model of the environment and advocate for the $\\alpha$-divergence minimization rather than the more usual  variational Bayes.   The ability of alpha-divergence to capture bi-modality however  comes at a price and most of the paper is devoted to finding tractable approximations.  The authors therefore use the approach of Hernandez-Lobato et al. (2016) as proxy to the alpha-divergence .   The environment/system dynamics is clearly defined as a well as the policy parametrization  (section 3) and would constitute a useful reference point for other researchers.  Simulated roll-outs, using the learned model, then provide samples of the expected  return. Since a model of the environment is available, stochastic gradient descent  can be performed in the usual way, without policy gradient estimators, via automatic  differentiation tools.   The experiments demonstrate that alpha-divergence is capable of capturing multi-model  structure which competing methods (variational Bayes and GP) would otherwise struggle with. The proposed approach also compares favorably in a real-world batch setting.  The paper is well-written, technically rich and combines many recent tools  into a coherent algorithm. However, the repeated use of approximations to original  quantities seems to somehow defeat the benefits of the original problem formulation.  The scalability and computational effectiveness of this approach is also questionable  and I am uncertain if many problem would warrant such complexity in their solution.  As with other Bayesian methods, the proposed approach would probably shine in low-samples  regime and in this case might be preferable to other methods in the same class (VB, GP).",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo, según los revisores, no es una contribución científica, pero el tema resulta particularmente interesante de discutir en nuestro congreso. Es por ello que se recomienda aceptar el artículo para su presentación en el Workshop de aplicaciones empresariales en lugar de paper regular.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Se aprecia un trabajo extenso que se valora, sin embargo se observan varias inconsistencias a lo largo del trabajo.  Se observa en la página 4 figura 1 la indicación de un modelo conceptual siendo este del tipo copo de nieve, sin embargo lo correcto sería indicar que es un esquema de diseño lógico y no de diseño conceptual de DW. Además un esquema conceptual correcto no debe indicar el tipo de dato. También en este aspecto se hace referencia a una bibliografía de esquema estrella. Faltó investigación sobre modelos conceptuales para DW para evitar lo anterior.  Mucha redundancia en problemas técnicos que no deberían ser de importancia para el artículo.  Se habla de inteligencia de negocios pero en un sentido estricto si se aplica inteligencia de negocios se necesita un  analista “experto” que sea capaz de tomar decisiones con las tendencias encontradas en el estudio, lo cual no se presenta en el artículo.  Faltan referencias de trabajos relacionados, pues solo se referencian  libros. Una revisión a trabajos relacionados habría sido muy útil en el sentido de estructurar mejor el artículo.  Existen metodologías para esquematizar el proceso ETL que habrían permitido mejorar este aspecto descrito en el artículo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This one is a tough call, because I do think that there are some important, salvageable technial results in here (notably the parsing algorithm), but the paper as a whole has very little cohesion.        It is united around an overarching view of formal languages in which a language being \"probabilistic\" or not is treated as a formal property of the same  variety as being closed under intersection or not.  In my opinion, what it  means for a formal language to be probabilistic in this view has not been  considered with sufficient rigor for this viewpoint to be compelling.  I should note, by the way, that the value of the formal results provided mostly does not depend on the flimsiness of the overarching story.  So what we have here is not bad research, but a badly written paper.  This needs  more work.  I find it particulary puzzling that the organization of the paper leaves so little space for elucidating the parsing result that soundness and completeness are relegated to a continuation of the paper in the form of supplementary notes.  I also find the mention of probabilistic languages in the title of the paper to be very disingenuous --- there is in fact no probabilistic reasoning in this submission.  The sigificance of the intersection-closure result of section 3 is also being somewhat overstated, I think.  Unless there is something I'm not understanding about the restrictions on the right-hand sides of rules (in which case, please elaborate), this is merely a matter of folding a finite intersection into the set of non-terminal labels.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El  trabajo está bien presentado, es consistente y trata de un problema  relevante. Los resultados presentados  aún son incipientes,  debido  que el estudio de caso es simple y no incorpora complejidades mayores. Aún así, considero que este trabajo presenta elementos suficientes  para su aceptación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes a new Bayesian neural network architecture for predicting the values of learning curves during the training of machine learning models. This is an exploratory paper, in that the ultimate goal is to use this method in a Bayesian optimization system, but for now the experiments are limited to assessing the quality of the predictions. This builds on previous work in Domhan, 2015, however in this work the model incorporates information from all tested hyperparameter settings rather than just extrapolating from a single learning curve. This paper also explores two MCMC methods for inference: SGLD and SGHMC, but I couldn’t tell if either of these were tested in Domhan, 2015 as well.  The performance seems overall positive, particularly in the initial phase of each curve where there is very little information. In this case, as expected, sharing knowledge across curves helps. One regime which did not seem to be tested, but might be very informative, is when some curves in the training set have been mostly, or fully observed. This might be a case where sharing information really helps.  Something that concerns me about this approach is the timing. The authors stated that to train the network takes about 20-60 seconds. In the worst case, with 100 epochs, this results in a little over 1.5 hours spent training the Bayesian network. This is a non-trivial fraction of the several hours it takes to train the model being tuned.  The Bayesian network makes many separate predictions, as shown in Figure 2. It would be interesting to see how accurate some of these individual pieces are. For example, did you bound the asymptotic value of the learning curve, since you mostly predicted accuracy? If not, did the value tend to lie in [0,1]?  Below are some minor questions/comments.  Figure 1 axes should read “validation accuracy” Figure 6 can you describe LastSeenValue (although it seems self-explanatory, it’s good to be explicit) in the bottom left figure, and why isn’t it used anywhere else as a baseline? Figure 7 and Table 1 are you predicting just the final value of the curves? Or every value along each curve, conditioned on the previous values? Why do you only use 5 basis functions? Does this sufficiently capture all of the flexibility of these learning curves? Would more basis functions help or hurt?",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes a new kind of generative model based on an annealing process, where the transition probabilities are learned directly to maximize a variational lower bound on the log-likelihood. Overall, the idea is clever and appealing, but I think the paper needs more quantitative validation and better discussion of the relationship with prior work.  In terms of prior work, AIS and RAISE are both closely related algorithms, and share much of the mathematical structure with the proposed method. For this reason, it’s not sufficient to mention them in passing in the related work section; those methods and their relationship to variational walkback need to be discussed in detail. If I understand correctly, the proposed method is essentially an extension of RAISE where the transition probabilities are learned rather than fixed based on an existing MRF. I think this is an interesting and worthwhile extension, but the relationship to existing work needs to be clarified.  The analysis of Appendix D seems incorrect. It derives a formula for the ratios of prior and posterior probabilities, but this formula only holds under the assumption of constant temperature (in which case the ratio is very large). When the temperature is varied, the analysis of Neal (2001) applies, and the answer is different.   One of the main selling points of the method is that it optimizes a variational lower bound on the log-likelihood; even more accurate estimates can be obtained using importance sampling. It ought to be easy to report log-likelihood estimates for this method, so I wonder why such estimates aren’t reported. There are lots of prior results to compare against on MNIST. (In addition, a natural baseline would be RAISE, so that one can check if the ability to learn the transitions actually helps.)  I think the basic idea here is a sound one, so I would be willing to raise my score if the above issues are addressed in a revised version.   Minor comments:  “A recognized obstacle to training undirected graphical models… is that ML training requires sampling from MCMC chains in the inner loop of training, for each example.” This seems like an unfair characterization, since the standard algorithm is PCD, which usually takes only a single step per mini-batch.  Some of the methods discussed in the related work are missing citations.  The method is justified in terms of “carving the energy function in the right direction at each point”, but I’m not sure this is actually what’s happening. Isn’t the point of the method that it can optimize a lower bound on the log-likelihood, and therefore learn a globally correct allocation of probability mass?",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta un sistema de control de flota que integra diversas tecnologías.  Se presenta una solución compleja que integra distintos sistemas de hardware y software.  La presentación describe el sistema a nivel de módulos principales (gestión y control de trenes, SMS, autorizaciones de vía, detectores de desrielo, y cambios radiales) pero no profundiza en ninguno.  Se presenta la solución como una alternativa de bajo costo comparable a referentes mundiales, sin embargo no se aportan datos al respecto. Así mismo, no se proporciona respaldo para las afirmaciones hechas respecto de escalablidad y otros beneficios de la solución (ver Conclusiones y las dos secciones precedentes).",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes an idea of looking n-steps backward when modelling sequences with RNNs. The proposed RNN does not only use the previous hidden state (t-1) but also looks further back ( (t - k) steps, where k=1,2,3,4 ). The paper also proposes a few different ways to aggregate multiple hidden states from the past.   The reviewer can see few issues with this paper.  Firstly, the writing of this paper requires improvement. The introduction and abstract are wasting too much space just to explain unrelated facts or to describe already well-known things in the literature. Some of the statements written in the paper are misleading. For instance, it explains, “Among various neural network models, recurrent neural networks (RNNs) are appealing for modeling sequential data because they can capture long term dependency in sequential data using a simple mechanism of recurrent feedback” and then it says RNNs cannot actually capture long-term dependencies that well. RNNs are appealing in the first place because they can handle variable length sequences and can model temporal relationships between each symbol in a sequence. The criticism against LSTMs is hard to accept when it says: LSTMs are slow and because of the slowness, they are hard to scale at larger tasks. But we all know that some companies are already using gigantic seq2seq models for their production (LSTMs are used as building blocks in their systems). This indicates that the LSTMs can be practically used in a very large-scale setting.   Secondly, the idea proposed in the paper is incremental and not new to the field. There are other previous works that propose to use direct connections to the previous hidden states [1]. However, the previous works do not use aggregation of multiple number of previous hidden states. Most importantly, the paper fails to deliver a proper analysis on whether its main contribution is actually helpful to improve the problem posed in the paper. The new architecture is said that it handles the long-term dependencies better, however, there is no rigorous proof or intuitive design in the architecture that help us to understand why it should work better. By the design of the architecture, and speaking in very high-level, it seems like the model maybe helpful to mitigate the vanishing gradients issue by a linear factor. It is always a good practice to have at least one page to analyze the empirical findings in the paper.   Thirdly, the baseline models used in this paper are very weak. Their are plenty of other models that are trained and tested on word-level language modelling task using Penn Treebank corpus, but the paper only contains a few of outdated models. I cannot fully agree on the statement “To the best of our knowledge, this is the best performance on PTB under the same training condition”, these days, RNN-based methods usually score below 80 in terms of the test perplexity, which are far lower than 100 achieved in this paper.   [1] Zhang et al., “Architectural Complexity Measures of Recurrent Neural Networks”, NIPS’16",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper introduces a hierarchical clustering method using learned CNN features to build 'the tree of life'. The assumption is that the feature similarity indicates the distance in the tree. The authors tried three different ways to construct the tree: 1) approximation central point 2) minimum spanning tree and 3) multidimensional scaling based method. Out of them, MDS works the best. It is a nice application of using deep features. However, I lean toward rejecting the paper because the following reasons:  1) All experiments are conducted in very small scale. The experiments include 6 fish species, 11 canine species, 8 vehicle classes. There are no quantitative results, only by visualizing the generated tree versus the wordNet tree. Moreover, the assumption of using wordNet is not quite valid. WordNet is not designed for biology purpose and it might not reflect the true evolutionary relationship between species.  2) Limited technical novelty. Most parts of the pipeline are standard, e.g. use pretrained model for feature extraction, use previous methods to construct hierarchical clustering. I think the technical contribution of this paper is very limited.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Strengths  - interesting to explore the connection between ReLU DNN and simplified SFNN - small task (MNIST)  is used to demonstrate the usefulness of the proposed training methods experimentally - the proposed, multi-stage training methods are simple to implement (despite lacking theoretical rigor)   Weaknesses  -no results are reported on real tasks with large training set  -not clear exploration on the scalability of the learning methods when training data becomes larger  -when the hidden layers become stochastic, the model shares uncertainty representation with deep Bayes networks or deep generative models (Deep Discriminative and Generative Models for Pattern Recognition , book chapter in “Pattern Recognition and Computer Vision”, November 2015, Download PDF). Such connections should be discussed, especially wrt the use of uncertainty representation to benefit pattern recognition (i.e. supervised learning via Bayes rule) and to benefit the use of domain knowledge such as “explaining away”.  -would like to see connections with variational autoencoder models and training, which is also stochastic with hidden layers",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo consiste en un artículo tipo survey o estudio de la temática sobre redes y vehículos sub-acuáticos, revisión bibliográfica y de tecnología relacionadas muy interesante y completa a mi juicio. Sugiero que pudiera entregar una contribución tomando como base de este estudio, por ejemplo proporcionando una taxonomía de las características de las tecnologías requeridas para este tipo de par problemas-soluciones, y agregando una propuesta mediante una metodología de implementación y prueba. Lo anterior lo señala como entrega en trabajo futuro, quizás al menos debió entregar una tabla comparativa de las tecnologías asociadas y descritas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo muestra el trabajo desarrollado para la construcción de una aplicación Web orientada a una interfaz móvil (tablet). La descripción del trabajo desarrollado no es detallada y deja muchas dudas sobre su implementación.   Problemas de fondo encontrados:  - Se describe la metodología RUP y BPM, sin embargo, no se detalle la razón de ello y el aporte asociado al trabajo más allá de las 2 figuras mostradas. - Se menciona la utilización de GPS para registro/tracking de mascotas, pero no se entregan detalles técnicos de la solución propuesta. Esto hace dudar de la propuesta realizada. - No se realiza el análisis de la calidad de interface humano-computador, por lo menos debería incluir una encuesta de usabilidad. - Se menciona la utilización del lenguaje PHP y MySQL como base de datos, sin embargo, no se dan detalles de la implementación utilizada (Patrones, SQL, ORM, etc). - No muestra evidencias de la implementación de la aplicación: diagrama de clases, diagrama de base de datos, contratos, patrones utilizados (DAO, Active Record, etc.).   Problemas de forma identificados en el trabajo:  - Las capturas de pantalla no son claros y pierden mucho espacio al utilizar como marco la interface de un tablet. - La figura 7 se encuentra sobrepuesta sobre texto, el cual es ilegible. - La figura 11 hace referencia a la aplicación Google Maps y no se ve clara la asociación con la aplicación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths:  -- A well-motivated approach, with a clear description and solid results.  - Weaknesses:  -- Nothing substantial other than the comments below.   - General Discussion:  The paper describes a new method called attention-over-attention for reading comprehension. First layers of the network compute a vector for each query word and document word, resulting in a |Q|xK matrix for the query and a |D|xK for the document. Since the answer is a document word, an attention mechanism is used for assigning weights to each word, depending on their interaction with query words. In this work, the authors deepen a traditional attention mechanism by computing a weight for each query word through a separate attention and then using that to weight the main attention over document words. Evaluation is properly conducted on benchmark datasets, and various insights are presented through an analysis of the results as well as a comparison to prior work. I think this is a solid piece of work on an important problem, and the method is well-motivated and clearly described, so that researchers can easily reproduce results and apply the same techniques to other similar tasks.  - Other remarks:  -- p4, Equation 12: I am assuming i is iterating over training set and p(w) is referring to P(w|D,Q) in the previous equation? Please clarify to avoid confusion.  -- I am wondering whether you explored/discussed initializing word embeddings with existing vectors such as Google News or Glove? Is there a reason to believe the general-purpose word semantics would not be useful in this task?  -- p6 L589-592: It is not clear what the authors are referring to when they say 'letting the model explicitly learn weights between individual attentions'? Is this referring to their own architecture, more specifically the GRU output indirectly affecting how much attention will be applied to each query and document word? Clarifying that would be useful. Also, I think the improvement on validation is not 4.1, rather 4.0 (72.2-68.2).  -- p7 Table 5: why do you think the weight for local LM is relatively higher for the CN task while the benefit of adding it is less? Since you included the table, I think it'll be nice to provide some insights to the reader.  -- I would have liked to see the software released as part of this submission.  -- Typo p2 L162 right column: \"is not that effective than expected\" --> \"is not as effective as expected\"?  -- Typo p7 L689 right column: \"appear much frequent\" --> \"appears more frequently\"?  -- Typo p8 L719-721 left column: \"the model is hard to\" --> \"it is hard for the model to\"? & \"hard to made\" --> \"hard to make\"?",
            "output": [
                "en"
            ]
        },
        {
            "input": "Un buen trabajo que está en sintonía con el INFONOR. De hecho este trabajo da continuidad a uno presentado en el INFONOR 2012. Mi única ponderación es que la referencia [13] debería ser el artículo publicado y presentado en el INFONOR en vez de la página del INFONOR.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta una revisión general de la seguridad de software enfocado en las tecnologías del desarrollo de software y cumple función como trabajo recopilatorio. El contenido se encuentra claramente explicado, no se ven problemas de redacción y puntuación. La bibliografía presenta numerosas referencias a artículos en línea y textos de seguridad informática. Sería interesante que se incluyeran más artículos científicos de ser posible.  Si bien el texto establece como trabajo futuro la realización de un estudio empírico para la selección de tecnologías de seguridad, hubiese sido interesante contar con información preliminar de este enfoque para dar mayor valor al trabajo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este es un trabajo interesante, donde el autor quiere mostrar a las Honeynets como medida de seguridad alternativa, para aprendizaje del  modo de operar de intrusos y así crear nuevas formas de protección.  Observaciones:  - El nombre del único autor debe estar centralizado en el artículo. - Palabras y figuras en inglés. El artículo está en español. - Las referencias están inadecuadas: hay  un único artículo citado y con referencia incompleta. Mejorar la revisión bibliográfica, citando artículos y libros  actuales.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este trabajo propone una parte de un, sistema no concluido, para reconocer e interpretar el movimiento ocular como herramienta de apoyo a un psicólogo.  Es un tema interesante.  Aunque es un tema interesante no queda bien explicado el problema a resolver ni se muestra los resultados de la interpretación del movimiento ocular. Podría haber utilizado más hojas para explicar esto. Faltó una parte de análisis de resultados.  Problemas de formato (problemas de redacción, ortografía, hay ecuaciones en las cuales no explica los términos, debe redactar en tercera persona)  La modalidad de presentación era en 4 o 10 páginas, sin embargo presenta sólo 3 páginas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Si bien este artículo deja ver una buena cantidad de trabajo, está escrito crípticamente y es muy difícil ver hacia donde apunta.  Hay problemas de redacción en:  Resumen (1): \"falta de llaves y relaciones entre tablas y datos sino y por el contrario se genera rendimiento\"  Fase 2 (8): \"En este punto se realizaron los montajes de la base de datos en los dos (2) SGBD NoSQL en la nube. Y se montó el sistema gestor de bases de datos móvil que va a estar en comunicación con los montados en la nube.\"  Comportamiento... (9): \"Para el caso de MongoDB, existe un ODBC desarrollado por estudiantes que está siendo desarrollado por estudiantes, y, otro ODBC desarrollado por Simba Technologies\"  El artículo, en todo caso es muy difícil de seguir...  Comprensión: El título habla de una comparación..., sin embargo nunca se ve tal comparación.  \"manejan el teorema CAP\"... el teorema dice que hay tres características que no pueden darse simultáneamente, por lo que \"manejan\" no tiene sentido.  \"desnormalizar los datos, es decir las propiedades ACID (atomicidad, consistencia, aislamiento y durabilidad) son sacrificadas por cuestión de rendimiento...\", no veo una relación directa entre desnormalizar (un aspecto de diseño) con las propiedades acid (un conjunto de propiedades de las transacciones).  Se dice en un momento \"Se eligieron dos sistemas gestores de bases de datos NoSQL alojados en la nube que son MongoDB y CouchDB; bases de datos a partir de las cuales se hacen las pruebas de transaccionalidad con el gestor de bases de datos móvil Ultralite\", finalmente nunca se ven estas pruebas ni sus resultados.  Se dice \"sin embargo las soluciones ODBC ya no son tan populares...\" En que se sustenta esto???  Finalmente, se habla del uso de un middleware \"Mobilink de Sybase\" sin embargo, posteriormente se habla de problemas con contar con un odbc para los sabd noSQL (que requeriría Mobilink)... y de ultralite y la comparación no se sabe que paso...????",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este es un tema que no ha sido abordado suficientemente y que por lo mismo es bueno el tratarlo en forma \"seria\".  Justamente por lo planteado anteriormente, es que a esta temática se le puede \"sacar mayor partido\". A pesar que considero adecuada la clasificación deducida, creo que podría haberse profundizado un poco más.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Un buen aporte y mirada al futuro. La redacción presenta algunas dificultades, revisar. Falta dar un ejemplo para algún tipo de dispositivo, habría sido ideal.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Thanks for the response. I look forward to reading about the effect of incentives and the ambiguity of the language in the domain.  Review before author response: The paper proposes a way to build natural language interfaces by allowing a set of users to define new concepts and syntax. It's an (non-trivial) extension of S. I. Wang, P. Liang, and C. Manning. 2016. Learning language games through interaction  Questions: - What is the size of the vocabulary used  - Is it possible to position this paper with respect to previous work on inverse reinforcement learning and imitation learning ?  Strengths: - The paper is well written - It provides a compelling direction/solution to the problem of dealing with a large set of possible programs while learning natural language interfaces.   Weaknesses: - The authors should discuss the effect of the incentives on the final performance ? Were other alternatives considered ?  - While the paper claims that the method can be extended to more practical domains, it is not clear to me how straightforward it is going to be. How sensitive is the method to the size of the vocabulary required in a domain ? Would increased ambiguity in natural language create new problems ? These questions are not discussed in the current experiments. - A real-world application would definitely strengthen the paper even more.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The authors have recently made several connections between deep learning and tensor algebra. While their earlier works dealt with supervised learning, the current work analyzes generative models through the lens of tensor algebra.   The authors show propose a tensorial mixture model over local structures where the mixture components are expressed as tensor decompositions. They show that hierarchical tensor decomposition is exponentially more expressive compared to the shallow models.   The paper makes original contributions in terms of establishing expressivity of deep generative models. The connections with tensor algebra could lead to further innovations, e.g. in training algorithms.  However, the paper can be improved in two aspects:   (1) It will be nice if the authors make a connection between the algebraic view presented here with the geometric view presented by: ",
            "output": [
                "en"
            ]
        },
        {
            "input": "I like the setting presented in this paper but I have several criticism/questions:  (1) What are the failure model of this work? As richness of behaviors get complex, I expected this approach to have issues with the diversity of skills that could be discovered.  (2) Looking at Sec 5.3 -- \" let X be a random variable denoting the grid in which the agent is currently situated\" -- is the space discretized? And if so why and what happens if it isn't.   (3) Expanding on the first point, does the approach work with more complicated embodiment? Say a 5-link swimmer instead of 2? I think this is important to assess the generality of this approach  (4) Authors claim that \"Recently, Heess et al. (2016) have independently proposed to learn a range of skills in a pre-training environment that will be useful for the downstream tasks, which is similar to our framework. However, their pre-training setup requires a set of goals to be specified. In comparison, we use intrinsic rewards as the only signal to the agent during the pre-training phase, the construction of which only requires very minimal domain knowledge.\"  I don't entirely agree with this. The rewards that this paper proposes are also quite hand-crafted and specific to a seemingly limited set of control tasks.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta un trabajo comparativo entre el uso de un SABD relacional clásico y un SABD temporal (la traducción al inglés temporary parece no adecuada: temporal o time oriented parece más correcto).  El ejemplo planteado en el artículo es interesante y motivador, esta adecuadamente sustentado y da pie a la comparación, como se indica \"es necesario definir un escenario de pruebas donde exista una aplicación concreta que pueda ser evaluada con la implementación de los paradigmas a comparar\".  Hay dos aspectos que en que el artículo no es claro, y que le restan peso:  1) La tecnología sabd temporal: pgFoundry, se indica que es una extensión a PostgreSql. Sin embargo, no se da mayor información... al buscarla parece un proyecto cerrado??? ¿cómo se trabajó con esta extensión?  2) La tabla 3 debería ser el centro del artículo, sin embargo no se describe como se realizaron muchas de las comparaciones. Quedando esto como una caja negra. ¿Qué criterios se utilizaron en las comparaciones? En las conclusiones hay algunas pistas, pero hay frases poco claras como: \"Se puede encontrar una mayor flexibilidad de entrada de datos en el SGBDR, puesto que existen más tipos de fuentes para poblar las bases de datos.\" ¿Qué se quiere decir con esto?",
            "output": [
                "es"
            ]
        },
        {
            "input": "Pros :  - New representation with nice properties that are derived and compared with a mathematical baseline and background - A simple algorithm to obtain the representation  Cons : - The paper sounds like an applied maths paper, but further analysis on the nature of the representation could be done, for instance, by understanding the nature of each layer, or at least, the first.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo presenta una propuesta de Reparación de Inconsistencias en Data Warehouses usando restricciones que tienen sentido semántico. Se proponen restricciones de prioridad y seguras, además de usar heurísticas previamente definidas en \"Repairing dimensions hierarchies under inconsistent reclassification\" para la computación de las r-reparaciones.  Los ejemplos que se utilizan para explicar la propuesta son claros. El artículo está bien escrito.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Es un estudio realizado bajo una metodología formal (técnica de emparrillado). El objetivo tras el estudio es mejorar la preparación de estrategias para la formación en técnicas de educción de requisitos, lo cual es un aporte dada la relevancia de la Ingeniería de Requisitos en el desarrollo de software. El estudio cubre una amplia variedad de técnicas de educción, entre las cuales se incorporan las más utilizadas en la práctica.  El estudio se aplicó a personas que pertenecen a una única institución (Universidad Politécnica de Madrid), sin duda esto es una limitante ya que todos tienen exactamente la misma formación, sería interesante aplicar el estudio a ingenieros noveles con diferentes formaciones. Las conclusiones obtenidas del estudio no son novedosas, confirman lo que por lógica se podía esperar.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper presents an approach for tackling the instability problem that is present in generative adversarial networks. The general idea is to allow the generator to \"peek ahead\" at how the discriminator will evolve its decision boundary over-time with the premise that this information should prevent the generator from collapsing to produce only samples from a single mode of the data distribution.  This is a very well written paper that clearly motivates its attack on an important open issue. The experiments are well carried out and strongly support the presented idea. The pursued approach is substantially more elegant than current existing \"hacks\" that are commonly used to make GANs work in practice. I however have three main issues that let me partly doubt the success of the method. If these can be resolved this paper is a clear candidate for acceptance.  1) I am not entirely convinced that the same effect cannot be obtained by the following procedure: simply train the discriminator for an extended number of K steps when updating the generator (say a number equivalent to the unrolling steps used in the current experiments) then, after the generator was updated undo the K updates to the discriminator and do 1 new update step instead. I only briefly glanced at your response to Reviewer2 which seems to imply you now tried something similar to this setup by stopping gradient flow at an appropriate point (although I think this is not exactly equivalent). 2) I tried to reproduce the simple MNIST example but using a fully connected network instead of an RNN generator without much success. Even when unrolling the discriminator for 30-40 steps the generator still engages in mode seeking behavior or does not train at all. This could either be because of a bug in my implementation or because of some peculiarities of the RNN generator or because I did not use batch normalization anywhere. If it is one of the latter two this would entail a dependence of the proposed approach on specific forms of the discriminator and generator and should be discussed. My code can be found here",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo realiza una revisión a los tipos de datos abiertos en Chile, si bien es un trabajo que debe haber tomado un tiempo considerable no veo un aporte directo a las líneas de investigación del congreso.  Por otro lado el trabajo futuro que se  indica en la conclusión sobre desarrollar una herramienta que permita visualizar los datos de transparencia activa si es interesante y será de seguro un aporte sobretodo en la contingencia actual del país.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Buena práctica para garantizar calidad en la educción de requisitos  - El resumen está mal redactado, no debería haber explicaciones teóricas - La traducción del resumen es pésima - El artículo no está escrito en tercera persona - La Sección POKA YOKE debería ir antes de la sección VARIABILIDAD DE LOS REQUISITOS Y COSTO DE CALIDAD. - Hay varios errores de ortografía",
            "output": [
                "es"
            ]
        },
        {
            "input": "De alto perfil técnico, es un aporte a la temática.  Demasiado conciso, podría extenderse en el cómo (sobretodo desde el aporte fuzzy).",
            "output": [
                "es"
            ]
        },
        {
            "input": "No hay contribución científica interesante ya que es la aplicación de una tecnología ya conocida a un caso de estudio. A pesar de que el trabajo está bien escrito técnicamente y es fácil de seguir no veo cuál es la pregunta de investigación que pretende responder. No se identifica un problema científico a solucionar y la propuesta es simple y poco original..",
            "output": [
                "es"
            ]
        },
        {
            "input": "No existen hipótesis en la investigación!  No se aprecia la contribución del trabajo  Varios problemas conceptuales en la introducción (ej. \"SVM son clasificadores no-lineales\"  .. son lineales.. lo que pasa que se pueden extender a problemas no separables linealmente mapeando a dimensiones mayores usando funciones de kernel!! , etc ).  No es claro el objetivo de los experimentos. Que se está tratando de probar? que se puede decir de los resultados (accuracy, etc) obtenidos? porque los resultados son diferentes (mejores/peores, etc) que los otros métodos que se mencionan?",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta una evaluación de técnicas de algoritmos genéticos para la ingeniería inversa en línea de productos de software. La mayor parte del trabajo se enfoca en presentar y explicar detalladamente la Ingeniería de Líneas de Productos de Software (ILPS) y la aplicación de Ingeniería inversa sobre este paradigma. La explicación asociada a ILPS y a Ingeniería Reversa es detallada en la Introducción del artículo, incluso para ingeniería reversa se entregan más dos definiciones para el mismo concepto. Sin embargo, en la misma sección no se hace referencia alguna a Algoritmos Genéticos que también es parte de este trabajo.  En general el trabajo es interesante pero carece de un alto impacto innovador respecto a trabajos asociados a Algoritmos Genéticos.  En la sección de Resultado y Evaluación se muestra un detalle de Tablas de Resultados, sin embargo la discusión y explicación de resultados solo se entrega en 1 párrafo. Se esperaría una explicación más clara respecto al significado de cada una de las columnas de la tabla y resultados correspondientes.  En la sección de referencias hay 3 referencias [11], [12], [13] para establecer una definición, se esperaría tener mayor referencias a trabajos similares, quizás que se pudiera incluir una sección de Related Work.  Menores. -- En general se recomienda revisar la redacción de algunas frases. Solo como ejemplo recomiendo revisar la última frase del Resumen. Otro ejemplo es el párrafo de AGRADECIMIENTOS. -- En figura 2 no se visualiza correctamente la serie \"Con LPS\" en impresión Blanco/Negro -- En pág. 8 penúltimo párrafo hay un \".\" que es del párrafo anterior en una línea en blanco. -- La tabla 2 tiene un formato de Fuente más grande y al parecer de otro tipo al del resto del artículo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Cuál es la contribución del trabajo?  No es muy exhaustica la discusión de experimentos y resultados.  Cuál es la hipótesis del trabajo?  No es claro el objetivo a comparar pues existen confusiones entre medir aspectos de \"eficiencia\" (ej. tiempo) versus \"efectividad\" (manejo de ruido y resultados obtenidos al procesar imágenes).  La organización del trabajo es un poco confusa.  En muchas partes, el trabajo está más enfocado en describir \"sistemas\" y la \"aplicación\" en vez de la contribución y el modelo propiamente tal.  Contra que se compara el algoritmo propuesto??",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este trabajo describe de manera práctica, una comunicación del como introducirse a la utilización de un robot en particular, bajo un ambiente de prueba libre, que trabaja con este tipo de aplicación. Si bien está bien escrito, solo aporta como tutorial, en vez de resultado de una investigación. Se nota que se está trabajando muy bien, pero es un trabajo preliminar.  Se debe revisar la escrita, porque el resumen es muy introductorio, no indicando lo relevante de lo que presenta el trabajo, también se utilizan nemónicos de los cuales no se describen antes. En el resumen y palabras claves se usan nemónicos que no se describen en el texto anteriormente. Tiene  la particularidad de que es un buen trabajo, pero es preliminar.  No presenta la arquitectura de lo realizado, imágenes que den cuenta de las simulaciones, resultados logrados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo me ha resultado interesante y me ha parecido un artículo muy atractivo de leer. Sin embargo, mi principal cuestión por la que he aconsejado su rechazo es porque realmente no considero que lo presentado sea investigación. El artículo presenta una experiencia en el uso de un aplicativo móvil para el pago de impuestos pero esto es algo que ya lleva ejecutándose en otros entornos. ¿Qué aporta esto de nuevo? Igual existe alguna novedad respecto a este desarrollo pero no ha quedado reflejada en el paper. Incluso, los planteamientos de trabajos futuros de investigación planteados, yo los entiendo como evolutivos o nuevas aplicaciones. El paper sería adecuado para una track section pero no para un congreso de investigación bajo mi punto de vista.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Contribución a la disciplina, valor como referencia, originalidad, claridad del contenido, etc. El artículo presentado ofrece una novedosa solución correspondiente a una arquitectura multiagente abierta, dividida en tres secciones: interacción, comunicación y semántico. El trabajo está bien redactado en general, salvo algunos errores menores que son recogidos al final de este documento. La bibliografía es aceptable, si bien se considera que debe ser actualizada a trabajos recientes – la última referencia es de 2007, y existen trabajos en la literatura sobre arquitecturas MAS abiertas que no han sido recogidos en esta contribución. El artículo presenta secciones muy extensas en detrimento de secciones importantes como las de resultados o comparativas. De hecho, es sustancialmente curioso observar cómo la parte de DISEÑO Y PRUEBAS (sección VIII) no está claramente redactada ni se puede observar el valor añadido de esta contribución. De la misma forma, la sección IX, Conclusiones, debería resumir con mayor claridad estos resultados obtenidos. Destaca también la sección III, donde se habla de los sistemas de transporte de pasajeros con bastante extensión, si bien luego no existe ninguna otra referencia a este capítulo ni a este problema concreto en la sección de descripción de la arquitectura propuesta. Por todo lo anterior, no considero especialmente relevante el trabajo presentado.  NOTA:   2\tSección IIA Error gramatical: entre sí (en lugar de entre si) 2\tSección IIA\tMA --> MAS  4\tSección V, segunda columna\tError gramatical: … toda su vida, os --> los  5\tAntes de la figura, columna izquierda\tIMA no está definido qué significa  5 \tImagen 4\tMejorar calidad  6\tPrimer párrafo\tMensajes[XX] (incluir referencia)  7\tAl final de la primera columna\tError gramatical: Esto son: --> Estos son: Éstos -->",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este trabajo hace una presentación de trabajos relacionados con el control de acceso de personas a determinadas instalaciones. Describe algunas tecnologías que se pueden emplear para implementar este control. Sin embargo, se queda en una propuesta que trata de adaptar soluciones a un problema local. Falta más desarrollo de modelos y sustento teórico para presentar una solución original, que aporte al avance en esta área. OBSERVACIONES DE FORMA: 1) Indicar las referencias usadas en el texto con corchetes []. 2) Mejorar la redacción del texto, uso de conectivos, prenombres, acentos ortográficos, puntos, comas, etc. Por ejemplo: \"El alumno, simplemente al acercar el móvil al libro, recibirá en su terminal la información Correspondiente al texto sin ninguna intervención.\"  3) El título: \"1. Otras Secciones.\"",
            "output": [
                "es"
            ]
        },
        {
            "input": "Combining storage and processing capabilities is an interesting research topic because data transfer is a major issue for many machine learning tasks. The paper itself is well-written, but unfortunately addresses a lot of things only to medium depth (probably due length constraints). My opinion is that a journal with an in-depth discussion of the technical details would be a better target for this paper.  Even though the researchers took an interesting approach to evaluate the performance of the system, it's difficult for me to grasp the expected practical improvements of this approach. With such a big focus on GPU (and more specialized hardware such as TPUs), the one question that comes to mind: By how much does this - or do you expect it to - beat the latest and greatest GPU on a real task?  I don't consider myself an expert on this topic even though I have some experience with SystemC.",
            "output": [
                "en"
            ]
        },
        {
            "input": "-\tNo existen bases científicas explicitas en este trabajo y su aporte a la práctica es muy limitado. -\tAdicionalmente, se debe revisar cuidadosamente su redacción y la lógica de la redacción. Por ejemplo se dice \"altura\" cuando se debería decir magnitud. -\tEs necesario que los datos revisados sean evaluados en relación al contexto, les recomiendo a los autores leer sobre análisis similares en reino unido para que puedan explicar sus resultados. -\tSi es mejorado podría ser presentado en workshop de aplicaciones empresariales.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presentado, describe  cómo modelar un sistema multiagente de acuerdo a la metodología orientada a agentes “GAIA” para modelar la trazabilidad de requisitos.  La propuesta de GAIA  para modelar la trazabilidad de los requisitos mediante Sistemas multiagente parece ser novedosa.  La presentación del artículo es bastante confusa, el documento presenta algunos errores ortográficos, de redacción y  de estructuración, se referencia a tablas que son figuras, se presentan tablas no referenciadas, no existe la figura 6, el ítem “resultados” debe ser cambiado o descrito en otro lugar del documento. Conclusiones insuficientes.",
            "output": [
                "es"
            ]
        },
        {
            "input": "I reviewed this paper earlier, when it was an ACL 2016 short paper draft. At that point, it had a flaw in the experiment setup, which is now corrected.  Since back then I suggested I'd be willing to accept the draft for another *ACL event provided that the flaw is corrected, I now see no obstacles in doing so.  Another reviewer did point out that the setup of the paper is somewhat artificial if we focus on real low-resource languages, relating to the costs of *finding* vs. *paying* the annotators. I believe this should be exposed in the writeup not to oversell the method.  There are relevant lines of work in annotation projection for extremely low-resource languages, e.g., Johannsen et al. (2016, ACL) and Agic et al. (2015, ACL). It would be nice to reflect on those in the related work discussion for completeness.  In summary, I think this is a nice contribution, and I vote accept.  It should be indicated whether the data is made available. I evaluate those parts in good faith now, presuming public availability of research.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Se presenta un modelo de optimización con restricciones de asignación de tripulaciones de trenes y su implementación en Java.  El problema está claramente delimitado y tiene aplicación práctica.  La solución propuesta parece apropiada.  La presentación extremadamente breve (dos páginas de contenido) no permite evaluar la calidad técnica ni la relevancia del trabajo.  No se incluye discusión de trabajo relacionado ni de los aportes del trabajo mismo.  No se proporcionan detalles del modelo, ni del software, ni de los resultados experimentales.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este trabajo muestra la clasificación de género basado en descriptores locales, compara los resultados utilizando un modelo basado en apariencia y modelos SIFT y SURF. El trabajo muestra con claridad el procedimiento llevado a cabo y los resultados, tiene una adecuada bibliografía y es novedoso en cuanto a la aplicación de los algoritmos en clasificación de género. Tiene una buena redacción, existiendo algunos pequeños errores de ortografía.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Summary: In this paper, the authors study ResNets through a theoretical formulation of a spin glass model. The conclusions are that ResNets behave as an ensemble of shallow networks at the start of training (by examining the magnitude of the weights for paths of a specific length) but this changes through training, through which the scaling parameter C (from assumption A4) increases, causing it to behave as an ensemble of deeper and deeper networks.  Clarity: This paper was somewhat difficult to follow, being heavy in notation, with perhaps some notation overloading. A summary of some of the proofs in the main text might have been helpful.  Specific Comments: - In the proof of Lemma 2, I'm not sure where the sequence beta comes from (I don't see how it follows from 11?)  - The ResNet structure used in the paper is somewhat different from normal with multiple layers being skipped? (Can the same analysis be used if only one layer is skipped? It seems like the skipping mostly affects the number of paths there are of a certain length?)  - The new experiments supporting the scale increase in practice are interesting! I'm not sure about Theorems 3, 4 necessarily proving this link theoretically however, particularly given the simplifying assumption at the start of Section 4.2?",
            "output": [
                "en"
            ]
        },
        {
            "input": "No queda claro si el artículo presenta una propuesta propia de evaluación de procesos (basada en CMMI o ISO), una adaptación de conceptos presentes en las normas a un proceso concreto o un estudio de caso sobre un plan de desarrollo.  La combinación de los modelos CMMI e ISO ha sido ampliamente discutida en la literatura. Sin embargo, no se incluyen referencias bibliográficas sobre este tema. Tampoco se explica en el artículo cuál es el enfoque utilizado para combinar los conceptos de ambos. Es necesario incluir nuevas referencias bibliográficas sobre este tema y otros relativos a los modelos de calidad y procesos.  La definición de fases y productos del proceso parecen arbitrarias y no están justificadas en el artículo. Las fases que se presentan no siempre concuerdan con las propuestas en el estado de la práctica de ingeniería de software. Los autores deben dar, al menos, una explicación de cómo se obtienen.  El artículo tiene varios problemas de formato no uniforme, algunos párrafos presentan un interlineado distinto, algunos títulos de sección están en negrita y otros no.  El estudio no aporta resultados interesantes con respecto de la aplicación de estos conceptos de calidad y procesos en el caso del INAPI.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors develop a way learn subspaces of multiple views such that data point neighborhoods are similar in all of the views.  This similarity is measured between distributions of neighbors in pairs of views. The motivation is that this is a natural criterion for information retrieval.  I like the idea of preserving neighborhood relationships across views for retrieval tasks. And it is nice that the learned spaces can have different dimensionalities for different views.  However, the empirical validation seems preliminary.  The paper has been revised from the authors' ICLR 2016 submission, and the revisions are welcome, but I think the paper still needs more work in order to be publishable.  In its current form it could be a good match for the workshop track.  The experiments are all on very small data sets (e.g. 2000 examples in each of train/test on the MNIST task) and not on real tasks.  The authors point out that they are not focusing on efficiency, and presumably computation requirements keep them from considering larger data sets.  However, it is not clear that there is any conclusion that can be drawn that would apply to more realistic data sets.  Considering the wealth of work that's been done on multi-view subspace learning, with application to real tasks, it is very hard to see this as a contribution without showing that it is applicable in such realistic settings.  On a more minor point, the authors claim that no other information retrieval based approaches exist, and I think this is a bit overstated.  For example, the contrastive loss of Hermann & Blunsom \"Multilingual models for compositional distributed semantics\" ACL 2014 is related to information retrieval and would be a natural one to compare against.  The presentation is a bit sloppy, with a number of vague points and confusing wordings.  Examples: - the term \"dependency\" gets used in the paper a lot in a rather colloquial way.  This gets confusing at times since it is used in a technical context but not using its technical definition. - \"an information retrieval task of the analyst\": vague and not quite grammatical - \"the probability that an analyst who inspected item i will next pick j for inspection\" is not well-defined - In the discussion of KL divergence, I do not quite follow the reasoning about its relationship to the \"cost of misses\" etc.  It would help to make this more precise (or perhaps drop it?  KL divergence is pretty well motivated here anyway). - Does C_{Penalty} (7) get added to C (6), or is it used instead?  I was a bit confused here. - It is stated that CCA \"iteratively finds component pairs\".  Note that while CCA can be defined as an iterative operation, it need not (and typically is not) solved that way, but rather all projections are found at once. - How is PCA done \"between X_i^1 and X_i^2\"? - \"We apply nonlinear dimensionality algorithm\": what is this algorithm? - I do not quite follow what the task is in the case of the image patches and stock prices.  Other minor comments, typos, etc.: - The figure fonts are too small. - \"difference measures\" --> \"different measures\" - \"...since, hence any two...\": not grammatical - \"between feature-based views and views external neighborhoods\": ?",
            "output": [
                "en"
            ]
        },
        {
            "input": "The idea of combining many modalities for product recommendation is a good one and well worth exploring. However, the approach presented in this paper is unsatisfying, as it involves combining several pre-trained models, in a somewhat ad hoc manner. Overall a nice problem, but the formulation and results are not presented clearly enough.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper tackles the problem of compressing trained convnets with the goal of reducing memory overhead and speeding up the forward pass. As I understand it, the main contribution of this work is to develop fast convolution routines for sparse conv weights int he case of general sparsity (as compared with structured sparsity). They evaluate their method on both AlexNet and GoogLeNet as well as on various platforms. The authors make code available online. The paper is well written and does a good job of putting this work in the context of past model reduction techniques.  My main request of the authors would be to provide a concise summary of the speedup/memory gains achievable with this new work compared with previously published work. The authors do show the various sparsity level obtained with various methods of pruning but it is unclear to me how to translate the information given in the paper into an understanding of gains relative to other methods.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper introduces SampleRNN, a hierarchical recurrent neural network model of raw audio. The model is trained end-to-end and evaluated using log-likelihood and by human judgement of unconditional samples, on three different datasets covering speech and music. This evaluation shows the proposed model to compare favourably to the baselines.  It is shown that the subsequence length used for truncated BPTT affects performance significantly, but interestingly, a subsequence length of 512 samples (~32 ms) is sufficient to get good results, even though the features of the data that are modelled span much longer timescales. This is an interesting and somewhat unintuitive result that I think warrants a bit more discussion.  The authors have attempted to reimplement WaveNet, an alternative model of raw audio that is fully convolutional. They were unable to reproduce the exact model architecture from the original paper, but have attempted to build an instance of the model with a receptive field of about 250ms that could be trained in a reasonable time using their computational resources, which is commendable.  The architecture of the Wavenet model is described in detail, but it found it challenging to find the same details for the proposed SampleRNN architecture (e.g. which value of \"r\" is used for the different tiers, how many units per layer, ...). I think a comparison in terms of computational cost, training time and number of parameters would also be very informative.  Surprisingly, Table 1 shows a vanilla RNN (LSTM) substantially outperforming this model in terms of likelihood, which is quite suspicious as LSTMs tend to have effective receptive fields of a few hundred timesteps at best. One would expect the much larger receptive field of the Wavenet model to be reflected in the likelihood scores to some extent. Similarly, Figure 3 shows the vanilla RNN outperforming the Wavenet reimplementation in human evaluation on the Blizzard dataset. This raises questions about the implementation of the latter. Some discussion about this result and whether the authors expected it or not would be very welcome.  Table 1 and Figure 4 also show the 2-tier SampleRNN outperforming the 3-tier model in terms of likelihood and human rating respectively, which is very counterintuitive as one would expect longer-range temporal correlations to be even more relevant for music than for speech. This is not discussed at all, I think it would be useful to comment on why this could be happening.  Overall, this an interesting attempt to tackle modelling very long sequences with long-range temporal correlations and the results are quite convincing, even if the same can't always be said of the comparison with the baselines. It would be interesting to see how the model performs for conditional generation, seeing as it can be more easily be objectively compared to models like Wavenet in that domain.    Other remarks:  - upsampling the output of the models is done with r separate linear projections. This choice of upsampling method is not motivated. Why not just use linear interpolation or nearest neighbour upsampling? What is the advantage of learning this operation? Don't the r linear projections end up learning largely the same thing, give or take some noise?  - The third paragraph of Section 2.1.1 indicates that 8-bit linear PCM was used. This is in contrast to Wavenet, for which an 8-bit mu-law encoding was used, and this supposedly improves the audio fidelity of the samples. Did you try this as well?  - Section 2.1 mentions the discretisation of the input and the use of a softmax to model this discretised input, without any reference to prior work that made the same observation. A reference is given in 2.1.1, but it should probably be moved up a bit to avoid giving the impression that this is a novel observation.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este trabajo propone un nuevo enfoque para el apoyo de la priorización de requisitos a través de un proceso de transformación de los Casos de Uso en un grafo de dependencia a través de la aplicación de técnicas de IR, redes bayesianas y evaluación del experto en el dominio. El enfoque se presenta como un interesante aporte para la priorización de requisitos y muestra su aplicación a un caso real. El documento está bien escrito y muy bien soportado por referencias. Los resultados son robustos según el enfoque utilizado y se presentan trabajos futuros bien direccionados.  Algunos errores tipográficos o de redacción pueden ser encontrados en la página 5 (párrafo 1 y 2). Confusión por el uso de k y K en la página 5 (o error tipográfico). Puede que no quede claro la utilización del conocimiento de la priorización realizada en el caso base de prueba con respecto a la realizada semi-automáticamente por su enfoque, salvo que se utiliza el conocimiento del experto. Quizás una comparación objetiva entre las dos priorizaciones sería adecuado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper investigates three simple weight-pruning techniques for NMT, and shows that pruning weights based on magnitude works best, and that retraining after pruning can recover original performance, even with fairly severe pruning.  The main strength of paper is that the technique is very straightforward and the results are good. Itâs also clearly written and does a nice job covering previous work.  A weakness is that the work isnât very novel, being just an application of a known technique to a new kind of neural net and application (namely NMT), with results that arenât very surprising.   Itâs not clear to me what practical significance these results have, since to take advantage of them you would need sparse matrix representations, which are trickier to get working fast on a GPU - and after all, speed is the main problem with NMT, not space. (There may be new work that changes this picture, since the field is evolving fast, but if so you need to describe it, and generally do a better job explaining why we should care about pruning.)  A suggestion for dealing with the above weakness would be to use the pruning results to inform architecture changes. For instance, figure 3 suggests that you might be able to reduce the number of hidden layers to two, and also potentially reduce the dimension of source and target embeddings.  Another suggestion is that you try to make a link between pruning+retraining and dropout (eg âA Theoretically Grounded Application of Dropout in Recurrent Neural Networksâ, Gal, arXiv 2016).  Detailed comments:  Line 111: âsoftmax weightsâ - âoutput embeddingsâ may be a preferable term  S3.2: Itâs misleading to call n the âdimensionâ of the network, and specify all parameter sizes as integer multiples of this number as if this were a logical constraint.  Line 319: You should cite Bahdanau et al here for the attention idea, rather than Luong for their use of it.  S3.3: Class-uniform and class-distribution seem very similar (and naturally get very similar results); consider dropping one or the other.  Figure 3 suggestion that you could hybridize pruning: use class-blind for most classes, but class-uniform for the embeddings.  Figure 4 should show perplexity too.  What pruning is used in section 4.2 & figure 6?  Figure 7: does loss pertain to training or test corpora?  Figure 8: This seems to be missing softmax weights. I found this diagram somewhat hard to interpret; it might be better to give relevant statistics, such as the proportion of each class that is removed by class-blind pruning at various levels.  Line 762: You might want to cite Le et al, âA Simple Way to Initialize Recurrent Networks of Rectified Linear Unitsâ, arXiv 2015.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo describe los conceptos de minería de datos y los pasos que un proceso KDD lleva a cabo en general, y esto último lo asocia a redes sociales y en particular a Facebook presentándolos como una adaptación propia, lo cual carece de fundamento y lógica. Por ejemplo, menciona las redes sociales donde los usuarios manifiestan gustos, sentimientos y otros estados, lo cual por lo general se presentan en texto, y por el contrario no señala nada respecto al tratamiento de texto para determinar la frecuencia de palabras y con esto lograr determinar los temas de conversación de un grupo de usuarios en la red. También describe algunas técnicas de minería de datos y mezcla la minería del web, quizás tratando de combinar diferentes métodos de minería que sería lo más lógico si se quiere abarcar diferentes aspectos de las redes sociales, es decir contenidos de texto se debiera utilizar el proceso KDT y no KDD, para el manejo de asociaciones o vínculos minería de la estructura de la web, etc. En la página 9 señala que utilizó la técnica de representación icónica para visualizar resultados, sin embargo no hay evidencias de esta experimentación en todo el trabajo. Finalmente en la conclusiones habla de una guía desarrollada la cual no se explícita en ninguna parte del artículo. También se debe señalar que tiene algunos errores de redacción, repetición de artículos y palabras.",
            "output": [
                "es"
            ]
        },
        {
            "input": "RESUMEN. El trabajo describe los pasos a seguir para aplicar conceptos de lógica difusa en dispositivos móviles. Para ejemplificar los pasos a seguir, el autor usó un robot móvil llamado AMADEUS (similar a los robots limpiadores comercializados en Japón [1]). Para aplicar los conceptos de lógica difusa, se usó módulo Mamdani.  Evaluación General. El tema es suma interesante y muy recurrente últimamente. Dispositivos que usen lógica difusa para operar es puente muy interesante y novedoso entre Inteligencia Artificial y \"pervasive computing\". Sin embargo, este trabajo tiene al menos una debilidad importante que debería ser resuelta:  1) En el trabajo no muestra porque es realmente importante usar lógica difusa. Un ejemplo de aplicación es fuertemente recomendable para el trabajo ¿En que ayudaría usar lógica difusa en dispositivos móviles?  2) En el trabajo no me queda muy claro si el uso de lógica difusa en dispositivos móviles es algo nuevo en esta área. Si no es algo nuevo, tal vez el trabajo podría llegar convertirse solamente en una repetición de otro trabajo. Si es algo nuevo, por favor, mencionarlo.  Comentarios Menores: - En las conclusiones, se menciona la frase \"se demostró\"; se sugiere cambiar a \"se mostró\". - Cuidar los usos de puntuaciones (ej. \"...\", \".\") y  el uso mayúsculas. - Al final de la introducción, se sugiere mencionar la estructura del documento.  [1] Auto Mee: www.yumeki.org/comercilizaran-pequeno-robot-limpiador-de-dispositivos-tactiles",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper introduces a number of ideas / heuristics for learning and interpreting deep generative models of text (tf-idf weighting, a combination of using an inference networks with direct optimization of the variational parameters, a method for inducing context-sensitive word embeddings). Generally, the last bit is the most novel, interesting and promising one, however, I agree with the reviewers that empirical evaluation of this technique does not seem sufficient.     Positive:  -- the ideas are sensible   -- the paper is reasonably well written and clear    Negative  -- most ideas are not so novel  -- the word embedding method requires extra analysis / evaluation, comparison to other methods for producing context-sensitive embeddings, etc",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper attempts to combine Variational Auto-Encoders with the Stick-Breaking process. The motivation is to tackle the component collapsing and have a representation with stochastic dimensionality. To demonstrate the merit of their approach, the authors test this model on MNIST and SVHN in an unsupervised and semi-supervised fashion. After reading the paper in more detail, I find that the claim that the dimensionality of the latent variable is stochastic does not seem quite correct: all latent variables are \"used\" (which actually enable backpropagation) but the latent variables are parametrized differently (into $\\pi$) and the decoding process is altered as to give the impression of sparsity. The way all these latent variables are used does not involve any marginalization but is very similar to the common soft-gating mechanism already used in LSTM or attentional model. With respect to the Figure 5b showing the decoder input weights: component collapsing probably does not have the same effect as Gaussian prior. $\\pi$ is positive therefore having a very small average value might mean that its value is close to zero most of the time, not requiring any update on the weight. For the standard Gaussian prior, component collapsing means having a very noisy input with no signal involved, which forces the decoder to shut down this channel, i.e. have small incoming weights from this collapsed variable. Adding a histogram of the latent variables in addition to that might help decide if the associated weights are relatively large because they are actually used or if it's because the inputs are zero anyway. The semi-supervised results are better than a weaker version of the model used in (Kingma et al., 2014), but as to have a fairer comparison, the results should be compared with the M1+M2 model in that paper, even if that requires also using two VAEs.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo es un mero anuncio del trabajo de investigación que será realizado en una etapa posterior. Escasamente muestra el resumen del marco teórico, con sólo algunas referencias y un insuficiente estudio del estado del arte sobre el tema en cuestión. Por consiguiente no hay resultados en base a los cuales establecer juicios. El título del artículo no guarda relación a lo presentado en el cuerpo del informe. Presenta una gran cantidad de errores de redacción, ortográficos y gramaticales, figuras ilegibles, referencia a figuras inexistentes, título de una tabla en otra columna, etc.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Validación cualitativa de UTAUT, Evidencias desde un estudio de investigación acción es un  trabajo que aporta un interesante ejemplo de investigación acción. Sin embargo, existen algunas posibilidades de mejoras. Primero, sugiero a los autores mejorar la conceptualización de \"comportamiento de uso\" pasando de un \"adopto/no adopto\" (dicotómico), a un \"nivel de uso\" para probar H4 y H5. Por otra parte, y en relación a las conclusiones, creo que si bien en UTAUT 2 FC es un antecedente de BI, esto es sólo en el contexto de tecnologías de consumo, y no creo que sea una comparación útil en el contexto e-learning, sugiero buscar referencias en ese contexto. Finalmente, creo que los autores deberían profundizar seriamente en las diferencias del contenido de los cursos que adoptaron y  los que no lo hicieron, ¿es posible que este contenido condicione el  uso de herramientas de evaluaciones electrónicas? Se sabe que algunos contenidos son más fácil de evaluar con herramientas electrónicas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper motivates the combination of autoregressive models with Variational Auto-Encoders and how to control the amount the amount of information stored in the latent code. The authors provide state-of-the-art results on MNIST, OMNIGLOT and Caltech-101. I find that the insights provided in the paper, e.g. with respect to the effect of having a more powerful decoder on learning the latent code, the bit-back coding, and the lossy decoding are well-written but are not novel. The difference between an auto-regressive prior and the inverse auto-regressive posterior is new and interesting though. The model presented combines the recent technique of PixelRNN/PixelCNN and Variational Auto-Encoders with Inverse Auto-Regressive Flows, which enables the authors to obtain state-of-the-art results on MNIST, OMNIGLOT and Caltech-101. Given the insights provided in the paper, the authors are also able to control the amount of information contained in the latent code to an extent. This paper gather several insight on Variational Auto-Encoders scattered through several publications in a well-written way. From these, the authors are able to obtain state-of-the-art models on small complexity datasets. Larger scale experiments will be necessary.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This manuscript addresses an interesting solution based in machine learning techniques to classify spectra legacy data of the Hubble Space Telescope in order to publish the results and \"good\" spectra in Internet to scientific community. The manuscript is well-written and results are robust. Experiment is sound and the manuscript seems acceptable in the current form. The work can be short, but very interesting to the Infonor and JCC community.  The main problem of the paper is that it is difficult to compare results for the classifiers utilized. A confusion matrix and parameters for each classifier could clarify results.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo no refleja cabalmente lo indicado en el título \"Revisión de técnicas de extracción de información en redes sociales sobre bases de datos NoSQL\", ya que sólo se trata de una mirada general a las redes sociales y a los sistemas de persistencia de datos que utilizan (basado en sabd noSQL). Más que técnicas de extracción, se hace revisión al conocido proceso ETL utilizado en Datawarehouse, proponiendo su uso en redes sociales. El principal aporte, lo constituye una propuesta de seis pasos para la extracción de información desde redes sociales, los que se centran en tópicos conocidos, obviando los principales problemas que esto involucra, entre los que se encuentra el acceso a los datos.  Redacción (revisar numeración de páginas): (página 2) \"del mundo del de los datos\"  (página 5) \"que aunque sean gratuitos con la finalidad principal de recolectar datos personales de los usuarios\"",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo describe una propuesta de arquitectura para sistemas abiertos en el contexto de agentes inteligentes. Aborda el aspecto teórico un determinado tipo de agentes en forma adecuada, dejando fuera el tipo de agentes recomendadores. La propuesta está bien descrita, detallada, y formalizada, lo que deja de manifiesto un trabajo interesante para ser presentado. EL detalle va solamente por el lado de la evaluación, quizás muy acotada y con poco desarrollo, considero que probar la arquitectura con un número reducido (50) requerimientos es muy poco para tener una evaluación empírica ad-hoc de su desempeño. En la forma, hay pequeños detalles ortográficos, puntuación y la figura 1 no es referenciada en al artículo. También hay títulos en inglés como el II b y el II a. Finalmente, llama la atención la sección de agradecimientos que está en inglés y da a a entender que el trabajo está inserto en un proyecto financiado por Conicyt.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este artículo describe una propuesta de implementación de una red espacial representada en el SGBD PostgreSQL, específicamente en la extensión PostGIS.  El artículo solo presenta información de modelado y diseño, pero no de implementación. A consecuencia de ello, no se presentan resultados experimentales.  El artículo tiene aceptable redacción en general. Sin embargo, es un trabajo del cual todavía no se obtienen resultados que permitan evaluar su aporte.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper explores the use of Open Bigrams as a target representation of words, for application to handwriting image recognition.   Pros: - The use of OBs is novel and interesting. - Clearly written and explained.  Cons: - No comparison to previous state of the art, only with author-generated results.  - More ablation studies needed -- i.e. fill in Table3 with rnn0,1 rnn0,1,2 rnn0,1' etc etc. It is not clear where the performance is coming from, as it seems that it is single character modelling (0) and word endings (') that are actually beneficial. - While the use of Open bigrams is novel, there are works which use bag of bigrams and ngrams as models which are not really compared to or explored. E.g.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper combines variational RNN (VRNN) and domain adversarial networks (DANN) for domain adaptation in the sequence modelling domain.  The VRNN is used to learn representations for sequential data, which is the hidden states of the last time step.  The DANN is used to make the representations domain invariant, therefore achieving cross domain adaptation.  Experiments are done on a number of data sets, and the proposed method (VRADA) outperforms baselines including DANN, VFAE and R-DANN on almost all of them.  I don't have questions about the proposed model, the model is quite clear and seems to be a simple combination of VRNN and DANN.  But a few questions came up during the pre-review question phase:  - As the authors have mentioned, DANN in general outperforms MMD based methods, however, the VFAE method which is based on MMD regularization on the representations seems to outperform DANN across the board.  That seems to indicate VRNN + MMD should also be a good combination.  - One baseline the authors showed in the experiments is R-DANN, which is an RNN version of DANN.  There are two differences between R-DANN and VRADA: (1) R-DANN uses deterministic RNN for representation learning, while VRADA uses variational RNN; (2) on target domain R-DANN only optimizes adversarial loss, while VRADA optimizes both adversarial loss and reconstruction loss for feature learning.  It would be good to analyze further where the performance gain comes from.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este artículo tiene como objetivo identificar la incidencia de las competencias de negocio TI en la percepción del éxito profesional. Se presenta el problema, el modelo de análisis, la hipótesis y la metodología de investigación.  Es un tema interesante, pero la autora indica que la investigación se  encuentra en la fase de recolección de datos y que faltan unos 7 meses para  obtener los resultados finales.  Sin embargo, el análisis teórico realizado es  bastante importante.  La Figura 3 es muy simple. Sugiero que el modelo propuesto aporte mayor información. Para ello, puede unir en una sola figura las Figuras 3,  4 y 2.  Utiliza referencias numéricas y referencias en formato APA (debe usar solamente referencias numéricas y de manera correcta).  Hay 2 páginas con número de página 3.  En página 5 aparece la Figura 4, en página 6 aparece la Figura 2 ¿? ¿Existe la Figura 3?  En Referencia [11] no indica el nombre de la conferencia, Referencia [15] no tiene fecha, la Referencia [30] ¿es un libro?, la Referencia [34] tiene su título escrito totalmente en mayúsculas, Referencia [45] dice solamente “Quinta”, Referencia [46] dice “Segunda”.  En Conclusiones, cambiar “tesis q del” por “tesis del”. Cambiar “se mostrara” por “se mostrará”.  Las Referencias [8] y [46] no son utilizadas en el texto.  El nombre del autor e institución debería ser anónimo (según normas del congreso).  En página 5, debe revisar que el texto esté justificado a la derecha.  En página 8, cambiar “se capaces” por “ser capaces”.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Evaluación general  El trabajo es interesante pero está mal planteado, faltan referencias importantes. Se sugiere revisar las referencias que se indican y extender el artículo mejorando su calidad en cuanto a la “forma” de plantear la comparativa, además de mostrar más ejemplos de los casos de estudio que le den mayor peso al artículo, con esto también podrá incorporar los trabajos futuros que son muchos y actualmente no aparece nada.  Correcciones de Formato  Las referencias no están en el formato que pide la revista Ingeniare, revisar formato y modificar.  La figura 1 es una ecuación y está fuera del formato que pide la revista Ingeniare.  Correcciones de Contenido  En la página 3 se hace referencia a [8] que es una tesis de grado, ¿qué tipo de grado?. Sería mejor referenciar a una metodología de artículo científico y eso daría  más \"peso\" al artículo. Cuando se habla de HL7/CDA se debería indicar una referencia para mayor información. No queda claro el uso de PGFOUNDRY  que es una extensión de postgreSql, ¿ se usó con Mysql?. Se debería haber sacado más provecho del uso de PGFOUNDRY. En el diseño del caso de estudio en la figura 5 hay errores graves en las relaciones entre las tablas Consulta y Paciente, entre las tablas Medicamento_Sintoma y Medicamento. No se indica en el artículo que el atributo duración es de tipo PERIOD, eso es importante. En los ejemplos de consultas hay un error en la consulta SGBDT, figura 7, ya que se indica el atributo periodo y el atributo es duración. Las conclusiones son muy evidentes y no plantean trabajos futuros que puedan ser interesantes de realizar. (Existe potencial y bastante que hacer) Faltan referencias importantes como por ejemplo: 1.\tA review of temporal database research and its use in GIS applications. International Journal of Geographical Information Systems. Volume 3, Issue 3, 1989. 2.\tTemporal Data and the Relational Model: A Detailed Investigation Into the ... Escrito por C. J. Date,Hugh Darwen,Nikos A. Lorentzos. 3.\tA generalized model for a relational temporal database  Proceeding SIGMOD '88 Proceedings of the 1988 ACM SIGMOD international conference on Management of data… 4.\tA glossary of temporal database concepts…",
            "output": [
                "es"
            ]
        },
        {
            "input": "Desarrollar investigación asociada al tema de visión artificial es interesante de conocer, aún bajo condiciones que no son las óptimas, particularmente en los recursos de hardware.  En la sección de pruebas de luminosidad hay cierto desorden en la presentación de los resultados (por ejemplo, la figura 10. debería titularse Prueba Botella Cloro y no Prueba Caja). Lo que hace difícil su seguimiento. Las referencias bibliográficas podrían ser más actuales y de mejor nivel.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper presents a clear hierarchical taxonomy of transfer learning methods as applicable to sequence tagging problems. This contextualizes and unifies previous work on specific instances of this taxonomy. Moreover, the paper shows that previously unexplored places in this taxonomy are competitive with or superior to the state of the art in key benchmark problems.  It'd be nice to see this explored further, such as highlighting what is the loss as you move from the more restrictive to the less restrictive transfer learning approaches, but I believe this paper is interesting and acceptable as-is.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes a new kind of expert model where a sparse subset of most reliable experts is chosen instead of the usual logarithmic opinion pool of a PoE. I find the paper very unclear. I tried to find a proper definition of the joint model p(x,z) but could not extract this from the text. The proposed “EM-like” algorithm should then also follow directly from this definition. At this point I do not see if such as definition even exists. In other words, is there is an objective function on which the iterates of the proposed algorithm are guaranteed to improve on the train data? We also note that the “product of unifac models” from Hinton tries to do something very similar where only a subset of the experts will get activated to generate the input:",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este artículo presenta un  Sistema de Reservas de Productos Turísticos mediante Servicios WEB y Dispositivos Móviles. Son utilizadas herramientas de dominio público y el desempeño es verificado  usando simulación. Considerando que los modelos no son perfectos, sobre todo  por la dificultad de modelar el comportamiento  humano, la realización de un estudio de caso (un piloto en escala reducida), donde se pueda medir el beneficio real de la herramienta propuesta.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes to initialize the weights of a deep neural network layer-wise with a marginal Fisher analysis model, making use of potentially the similarity metric.   Pros:  There are a lot of experiments, albeit small datasets, that the authors tested their proposed method on.  Cons: lacking baseline such as discriminatively trained convolutional network on standard dataset such as CIFAR-10. It is also unclear how costly in computation to compute the association matrix A in equation 4.  This is an OK paper, where a new idea is proposed, and combined with other existing ideas such as greedy-layerwise stacking, dropout, and denoising auto-encoders. However, there have been many papers with similar ideas perhaps 3-5 years ago, e.g. SPCANet.   Therefore, the main novelty is the use of marginal Fisher Analysis as a new layer. This would be ok, but the baselines to demonstrate that this approach works better is missing. In particular, I'd like to see a conv net or fully connected net trained from scratch with good initialization would do at these problems.  To improve the paper, the authors should try to demonstrate without doubt that initializing layers with MFA is better than just random weight matrices.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes an alternative to Conditional Variational Auto-Encoders and Conditional MultiModal Auto-Encoders to perform inference of missing modalities in dataset with multiple modalities. The proposed approach is a Variational Auto-Encoder jointly on all the modalities  with additional KL divergence penalties between the approximate posterior given all the modalities and the approximate posterior given a subset of the modalities. The approach is named Joint Multimodal Variational Auto-Encoder. The authors make a connection between this approach and the Variation of Information. It is unclear why the authors chose the JMVAE approach instead of a more elegant Variation of Information approach. Another unaddressed issue is the scalability of the method. As far as I can tell (given that no code is provided and the specification of the encoder is missing), this approach requires a new encoder per subset of missing modalities. Right now this approach seems to scale since there are only two modalities. The fact that the estimating the log-likelihood log(p(x)) using multiple modalities provide a lower value than with just one in Table 1 is a bit odd. Could you explain that ? The comparison with between the representation learned by JMVAE and CVAE might be unfair given that the representation of CVAE is learned conditionally, on the label in the case of MNIST, and should therefore not consider the label in this representation. Intuitively, this representation could represent \"style\" as shown in (Kingma et al., 2014) in their conditional generation figure. For CelebA, comparing log-likelihood on models that use GANs is probably not significant since GAN does not optimizes log-likelihood.  Overall this is an interesting problem and there are also interesting ideas worth exploring further, but the execution of the paper requires more work.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The authors present a new version of the coreference task tailored to Wikipedia. The task is to identify the coreference chain specifically corresponding to the entity that the Wikipedia article is about.  The authors annotate 30 documents with all coreference chains, of which roughly 25% of the mentions refer to the \"main concept\" of the article. They then describe some simple baselines and a basic classifier which outperforms these. Moreover, they integrate their classifier into the Stanford (rule-based) coreference system and see substantial benefit over all state-of-the-art systems on Wikipedia.  I think this paper proposes an interesting twist on coreference that makes good sense from an information extraction perspective, has the potential to somewhat revitalize and shake up coreference research, and might bridge the gap in an interesting way between coreference literature and entity linking literature.  I am sometimes unimpressed by papers that dredge up a new task that standard systems perform poorly on and then propose a tweak so that their system does better. However, in this case, the actual task itself is quite motivating to me and rather than the authors fishing for a new domain to run things in, it really does feel like \"hey, wait, these standard systems perform poorly in a setting that's actually pretty important.\"  THE TASK: Main concept resolution is an intriguing task from an IE perspective.  I can imagine many times where documents revolve primarily around a particular entity (biographical documents, dossiers or briefings about a person or event, clinical records, etc.) and where the information we care about extracting is specific to that entity. The standard coreference task has always had the issue of large numbers of mentions that would seemingly be pretty irrelevant for most IE problems (like generic mentions), and this task is unquestionably composed of mentions that actually do matter.  From a methodology standpoint, the notion of a \"main concept\" provides a bit of a discourse anchor that is useful for coreference, but there appears to still be substantial overhead to improve beyond the baselines, particularly on non-pronominal mentions. Doing coreference directly on Wikipedia also opens the doors for more interesting use of knowledge, which the authors illustrate here. So I think this domain is likely to be an interesting testbed for ideas which would improve coreference overall, but which in the general setting would be more difficult to get robust improvements with and which would be dwarfed by the amount of work dealing with other aspects of the problem.  Moreover, unlike past work which has carved off a slice of coreference (e.g. the Winograd schema work), this paper makes a big impact on the metrics of the *overall* coreference problem on a domain (Wikipedia) that many in the ACL community are pretty interested in.  THE TECHNIQUES: Overall, the techniques are not the strong point of this paper, though they do seem to be effective. The features seem pretty sensible, but it seems like additional conjunctions of these may help (and it's unclear whether the authors did any experimentation in this vein).  The authors should also state earlier in the work that their primary MC resolution system is a binary classifier; this is not explicitly stated early enough and the model is left undefined throughout the description of featurization.  MINOR DETAILS:  Organization: I would perhaps introduce the dataset immediately after \"Related Works\" (i.e. have it be the new Section 3) so that concrete results can be given in \"Baselines\", further motivating \"Approach\".  When Section 4 refers to Dcoref and Scoref, you should cite the Stanford papers or make it clear that it's the Stanford coreference system (many will be unfamiliar with the Dcoref/Scoref names).  The use of the term \"candidate list\" was unclear, especially in the following:  \"We leverage the hyperlink structure of the article in order to enrich the list of mentions with shallow semantic attributes. For each link found within the article under consideration, we look through the candidate list for all mentions that match the surface string of the link.\"  Please make it clear that the \"candidate list\" is the set of mentions in the article that are possible candidates for being coreferent with the MC.        I think most readers will understand that this module is supposed to import semantic information from the link structure of Wikipedia (e.g. if a mention is hyperlinked to an article that is female in Freebase, that mention is female), so try to keep the terminology clear.  Section 6.1 says \"we consider the union of WCR mentions and all mentions predicted by the method described in (Raghunathan et al., 2010).\" However, Section 4.1 implies that these are the same? I'm missing where additional WCR mentions would be extracted.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes a method for evaluating topic quality based on using word embeddings to calculate similarity (either directly or indirectly via matrix factorisation), achieving impressive results over standard datasets.  The proposed method represents a natural but important next step in the evolutionary path of research on topic evaluation. The thing that troubled me most with the results was that, while you achieve state-of-the-art results for all three datasets, there are large inconsistencies in which methods perform and which methods perform less well (below the state of the art). In practice, none of the proposed methods consistently beats the state of the art, and the SVD-based methods perform notably badly over the genomics dataset. For someone who wants to take your method off the shelf and use it over any arbitrary dataset, this is a considerable worry. I suspect that the lower results for SVD over genomics relate to the proportion of OOV terms (see comment below), and that it may be possible to automatically predict which method will perform best based on vocab match with GloVe etc., but there is no such discussion in the paper.  Other issues:  - the proposed method has strong similarities with methods proposed in the   lexical chaining literature, which I would encourage the authors to read up   on and include in any future version of the paper  - you emphasis that your method has no parameters, but the word embedding   methods have a large number of parameters, which are implicit in your   method. Not a huge deal, but worth acknowledging  - how does your method deal with OOV terms, e.g. in the genomics dataset   (i.e. terms not present in the pretrained GloVe embeddings)? Are they simply   ignored? What impact does this have on the method?  Low-level issues:  - in your description of word embeddings in Section 2.1, you implicitly assume   that the length of the vector is unimportant (in saying that cosine   similarity can be used to measure the similarity between two vectors). If   the vectors are unit length, this is unproblematic, but word2vec actually   doesn't return unit-length vectors (the pre-trained vectors have been   normalised post hoc, and if you run word2vec yourself, the vector length is   certainly not uniform). A small detail, but important.  - the graphs in Figure 1 are too small to be readable",
            "output": [
                "en"
            ]
        },
        {
            "input": "Interesante propuesta en un ambiente de desarrollo de software que es bastante pobre en aspectos metodológicos de desarrollo.  Falta un poco de trabajo relacionado o quizás discutirlo mejor en la introducción con referencias para fundamentar la interesante propuesta. Revisar redacción. No está en formato pedido por Infonor. Se sugiere no agregar links de páginas web en el texto del artículo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta el desarrollo de una aplicación móvil para realizar denuncias, avisar de algún acto criminal y crear un mapa del delito propio. El artículo requiere de una mejor redacción y mejorar su estructura técnica como artículo de investigación. Por ejemplo, no presenta el resumen en español.  Al ser una aplicación software, su contribución a la investigación es limitada. Sugiero postular a track o workshop de aplicaciones empresariales.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Variational auto-encoders, adversarial networks, and kernel scoring rules like MMD have recently gained popularity as methods for learning directed generative models and for other applications like domain adaptation. This paper gives an additional method along the scoring rules direction that uses the matching of central moments to match two probability distributions. The technique is simple, and in the case of domain adaptation, highly effective.  CMD seems like a very nice and straightforward solution to the domain adaptation problem. The method is computationally straightforward to implement, and seems quite stable with respect to the tuning parameters when compared to MMD. I was skeptical reading through this, especially given the fact that you only use K=5 in your experiments, but the results seem quite good. The natural question that I have now is: how will this method do in training generative models? This is beyond the scope of this paper, but it’s the lowest hanging fruit.  Below I give more detailed feedback.  One way to speed up MMD is to use a random Fourier basis as was done in “Fastmmd: Ensemble of circular discrepancy for efficient two-sample test” by Zhao and Meng, 2015. There are also linear time estimators, e.g., in “A Kernel Two-Sample Test“ by Gretton et al., 2012. I don’t think you need to compare against these approaches since you compare to the full MMD, but they should be cited.  The paper “Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy” by Sutherland et al. submitted to ICLR 2017 as well, discusses techniques for optimizing the kernel used in MMD and is worth citing in section 3.  How limiting is the assumption that the distribution has independent marginals?  The sample complexity of MMD depends heavily on the dimensionality of the input space - do you have any intuitions about the sample complexity of CMD? It seems like it's relatively insensitive based on the results in Figure 4, but I would be surprised if this were the case with 10,000 hidden units. I mainly ask this because with generative models, the output space can be quite high-dimensional.  I’m concerned that the central moments won’t be numerically stable at higher orders when backpropagating. This doesn’t seem to be a problem in the experimental results, but perhaps the authors could comment a bit on this? I’m referring to the fact that ck(X) can be very large for k >= 3. Proposition 1 alleviates my concerns that the overall objective is unstable, I’m referring specifically to the individual terms within.  Figure 3 is rather cluttered, and aside from the mouse class it’s not clear to me from the visualization that the CMD regularizer is actually helping. It would be useful to remove some of the classes for the purpose of visualization.  I would like some clarification about the natural geometric interpretations of K=5. Do you mean that the moments up to K=5 have been well-studied? Do you have any references for this? Why does K >= 6 not have a natural geometric interpretation?  Figure 4 should have a legend",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper provides a first study of customized precision hardware for large convolutional networks, namely alexnet, vgg and googlenet. It shows that it is possible to achieve larger speed-ups using floating-point precision (up to 7x) when using fewer bits, and better than using fixed-point representations.   The paper also explores predicting custom floating-point precision parameters directly from the neural network activations, avoiding exhaustive search, but i could not follow this part. Only the activations of the last layer are evaluated, but on what data ? On all the validation set ? Why would this be faster than computing the classification accuracy ?  The results should be useful for hardware manufacturers, but with a catch. All popular convolutional networks now use batch normalization, while none of the evaluated ones do. It may well be that the conclusions of this study will be completely different on batch normalization networks, and fixed-point representations are best there, but that remains to be seen. It seems like something worth exploring.  Overall there is not a great deal of novelty other than being a useful study on numerical precision trade-offs at neural network test time. Training time is also something of interest. There are a lot more researchers trying to train new networks fast than trying to evaluate old ones fast.   I am also no expert in digital logic design, but my educated guess is that this paper is marginally below the acceptance threshold.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper presents a Stack LSTM parser based on the work of Henderson et al. (2008, 2013) on joint syntactic/semantic transition-based parsing and Dyer et al. (2015) on stack LSTM syntactic parsing. The use of the transition system from the former and the stack LSTM from the latter shows interesting results compared to the joint systems on the CoNLL 2008 and 2009 shared tasks.  I like this paper a lot because it is well-written, well-explained, the related work is good and the results are very interesting. The methodology is sound (with a minor concern regarding the Chinese embeddings, leading me to believe than very good embeddings can be more informative than a very clever model...).  Moreover, the description of the system is clear, the hyperparameters are justified and the discussion is interesting.  The only thing I would say is that the proposed system lacks originality in the sense that the work of Henderson et al. puts the basis of semi-synchronised joint syntax-semantic transition-based parsing several years ago and Dyer et al. came up with the stack LSTM last year, so it is not a new method, per say. But in my opinion, we were waiting for such a parser to be designed and so I'm glad it was done here.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposed to use RL and RNN to design the architecture of networks for specific tasks. The idea of the paper is quite promising and the experimental results on two datasets show that method is solid. The pros of the paper are: 1. The idea of using RNN to produce the description of the network and using RL to train the RNN is interesting and promising. 2. The generated architecture looks similar to what human designed, which shows that the human expertise and the generated network architectures are compatible.  The cons of the paper are: 1. The training time of the network is long, even with a lot of computing resources.  2. The experiments did not provide the generality of the generated architectures. It would be nice to see the performances of the generated architecture on other similar but different datasets, especially the generated sequential models.  Overall, I believe this is a nice paper. But it need more experiments to show its potential advantage over the human designed models.",
            "output": [
                "en"
            ]
        },
        {
            "input": "26: An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge  This paper presents an approach for factoid question answering over a knowledge graph (Freebase), by using a neural model that attempts to learn a semantic correlation/correspondence between various \"aspects\" of the candidate answer (e.g., answer type, relation to question entity, answer semantic, etc.) and a subset of words of the question. A separate correspondence component is learned for each \"aspect\" of the candidate answers. The two key contributions of this work are: (1) the creation of separate components to capture different aspects of the candidate answer, rather than relying on a single semantic representation, and (2) incorporating global context (from the KB) of the candidate answers.  The most interesting aspect of this work, in my opinion, is the separation of candidate answer representation into distinct aspects, which gives us (the neural model developer) a little more control over guiding the NN models towards information that would be more beneficial in its decision making. It sort of harkens to the more traditional algorithms that rely on feature engineering. But in this case the \"feature engineering\" (i.e., aspects) is more subtle, and less onerous. I encourage the authors to continue refining this system along these lines.  While the high-level idea is fairly clear to a reasonably informed reader, the devil in the details would make it hard for some audience to immediately grasp key insights from this work. Some parts of the paper could benefit from more explanation... Specifically:  (1) Context aspect of candidate answers (e_c) is not clearly explained in the paper. Therefore, the last two sentences of Section 3.2.2 seem unclear.  (2) Mention of OOV in the abstract and introduction need more explanation. As such, I think the current exposition in the paper assumes a deep understanding of prior work by the reader.  (3) The experiments conducted in this paper restrict comparison to IR-based system -- and the reasoning behind this decision is reasonable. But it is not clear then why the work of Yang et al. (2014) -- which is described to be SP-based -- is part of the comparison. While, I am all for including more systems in the comparison, there seem to be some inconsistencies in what should and should not be compared. Additionally, I see not harm in also mentioning the comparable performance numbers for the best SP-based systems.  I observe in the paper that the embeddings are learned entirely from the training data. I wonder how much impact the random initialization of these embeddings has on the end performance. It would be interesting to determine (and list) the variance if any. Additionally, if we were to start with pre-trained embeddings (e.g., from word2vec) instead of the randomly initialized ones, would that have any impact?  As I read the paper, one possible direction of future work that occurred to me was to possibly include structured queries (from SP-based methods) as part of the cross-attention mechanism. In other words, in addition to using the various aspects of the candidate answers as features, one could include structured queries that generate the produce that candidate answer as an additional aspect of the candidate answer. An attention mechanism could then also focus on various parts of the structured query, and its (semantic) matches to the input question as an additional signal for the NN model. Just a thought.  Some notes regarding the positioning of the paper:  I hesitate to call the model proposed here \"attention\" models, because (per my admittedly limited understanding) attention mechanisms apply to \"encoder-decoder\" situations, where semantics expressed in one structured form (e.g., image, sentence in one language, natural language question, etc.) are encoded into an abstract representation, and then generated into another structured form (e.g., caption, sentence in another language, structured query, etc.). The attention mechanism allows the \"encoder\" to jump around and attend to different parts of the input (instead of sequentially) as the output is being generated by the decoder. This paper does not appear to fit this notion, and may be confusing to a broader audience.  ------  Thank you for clarifications in the author response.",
            "output": [
                "en"
            ]
        },
        {
            "input": "La publicación tiene como objetivo mostrar las bondades que tienen las estructuras métricas para la recuperación de imágenes. Este trabajo es la continuación de varios trabajos ya presentados, como por ejemplo. [1] \"Estructuras métricas paralelas en la recuperación de imágenes\", Peña- Jaramillo, E. (Referenciado en el paper) [2] \"Definición de un recuperador de Imágenes basado en Contenidos sobre Espacios Métricos\", Eduardo Peña-Jaramillo, et al. (No referenciado). [3] \"Estructuras Métricas Paralelas en la Recuperación de Imágenes en la Web\", Eduardo Peña-Jaramillo, et al. (No referenciado).  Sobre la referencia número [1] no ha sido posible obtener una copia electrónica, y desde las publicaciones antes citadas [2] y [3], se puede decir que hay un nuevo aporte en los experimentos realizados sobre estructuras GNAT y Spaghetis. Se debe explicar en la publicación que el trabajo no es original desde el punto de vista del autor, y que su extensión se basa en los trabajos [1], [2], [3] u otro que tenga directa relación con el trabajo presentado.  - El texto está bien estructurado y se entiende con facilidad lo que se desea exponer. - Bien en la presentación, no hay problemas graves. Solo mejorar las figuras de las gráficas, sobre todo las tildes, en matlab se puede agregar texto en latex para evitar ese tipo de problemas. La palabra \"más\" aparece en un par de ocasiones sin tilde.  - En la sección de \"Introducción\" si bien se presenta el trabajo en forma general creo que sería importante señalar cual es el estado del arte en estas materias. ¿Hay trabajos relacionados?, ¿Hay referencias importantes?, ¿Cuál es el aporte del trabajo sobre el estado del arte?, etc. Falta una revisión bibliográfica más exhaustiva. - En la sección de \"Extracción de características\" he encontrado algunos detalles como:  - Me ha costado encontrar una definición sobre la técnica de layout ya que solo hay una referencia [1], por lo que intuyo que se ha considerado las características obtenidas de cada sub-imagen como una señal las cuales son mezcladas para obtener el vector que represente a la imagen total, tal como dice en el texto: \"La unión de todas las características extraídas nos da como resultado...\", donde no queda claro el tipo \"unión\" que se realiza.  - También sucede lo mismo cuando se referencia el discriminante de Fisher, nuevamente se hace referencia a [1]. Se debería agregar una fuente más relevante para este punto. - No se explica con detalle el tipo de base de datos utilizada. ¿Es de dominio público o privada?. Qué tipo de imágenes o grupos de imágenes contiene. ¿Cuantas hay por clase?, ¿Hay imágenes repetidas?. Calidad de las imágenes. La idea es disponer de un marco de referencia para que cualquier persona que desee comparar sus algoritmos con los suyos los haga en igualdad de condiciones. - Desde las imágenes mostradas en la figura 2, puedo deducir que base de datos (espero estar equivocado) tiene imágenes repetidas lo que puede producir un sesgo a la hora de calcular los valores de precisión, sensibilidad y especificidad de las imágenes recuperadas. Creo que la base de datos ideal para poder medir de forma correcta la calidad de la recuperación debería contar con imágenes distintas aunque sean de la misma apariencia, pero nunca la misma. Ya que al recuperar un conjunto de imágenes sobre una de consulta, si están repetidas, la cantidad de verdaderos positivos será proporcional a las repetidas lo que se traducirá en un sesgo sobre el cálculo de las métricas.  Recomendaciones  - En el texto se menciona (sección de conclusiones) que las soluciones no son del todo satisfactorias. Creo que en la actualidad existen proyectos como [Link] images.googlelabs.com/, [Link] [Link] entre otros; que muestran un gran avance en este campo y sería bueno ser revisados.  - Por otro lado, sobre el conjunto de características utilizados recomiendo revisar otro tipos de características que han demostrado ser invariantes a la escala y la rotación. [4] \"Distinctive Image Features from Scale-Invariant Keypoints\". David G. Lowe. International Journal of Computer Vision, 2004. como también su mejora [5] \"SURF: Speeded Up Robust Features\", Computer Vision and Image Understanding (CVIU). Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool. Vol. 110, No. 3, pp. 346--359, 2008.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este trabajo muestra un enfoque de segmentación de imágenes de tejido mamario para la clasificación binaria de pixels de una imagen mediante SVM, para determinar la presencia o ausencia de la tinción de las membranas de las células cancerígenas Este trabajo es interesante y valorable, debido a la dificultad de la obtención de este tipo de imágenes y por el enfoque interdisciplinario, presentando además un interesante trabajo futuro. Se encuentra bien escrito y los resultados mostrados aunque parciales parecen correctos y justificados.  Verificar redacción y tipografía de la página 4 en sus párrafos primero y penúltimo. La principal debilidad de este trabajo puede ser la baja cantidad de imágenes de prueba y la falta de comparación con otros métodos. También sería deseable mostrar resultados generales de la clasificación y no sólo del proceso de validación. Además, las propiedades explicadas en  la tabla de puntaje (completitud e intensidad) no son utilizadas directamente en el proceso de clasificación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths: i. Well organized and easy to understand ii. Provides detailed comparisons under various experimental settings and shows the state-of-the-art performances  - Weaknesses: i. In experiments, this paper compares previous supervised approaches, but the proposed method is the semi-supervised approach even if the training data is enough to train.  - General Discussion: This paper adopts a pre-training approach to improve Chinese word segmentation. Based on the transition-based neural word segmentation, this paper aims to pre-train incoming characters with external resources (punctuation, soft segmentation, POS, and heterogeneous training data) through multi-task learning. That is, this paper casts each external source as an auxiliary classification task. The experimental results show that the proposed method achieves the state-of-the-art performances in six out of seven datasets.   This paper is well-written and easy to understand. A number of experiments prove the effectiveness of the proposed method. However, there exist an issue in this paper. The proposed method is a semi-supervised learning that uses external resources to pre-train the characters. Furthermore, this paper uses another heterogeneous training datasets even if it uses the datasets only for pre-training. Nevertheless, the baselines in the experiments are based on supervised learning. In general, the performance of semi-supervised learning is better than that of supervised learning because semi-supervised learning makes use of plentiful auxiliary information. In the experiments, this paper should have compared the proposed method with semi-supervised approaches.  POST AUTHOR RESPONSE  What the reviewer concerned is that this paper used additional “gold-labeled” dataset to pretrain the character embeddings. Some baselines in the experiments used label information, where the labels are predicted automatically by their base models as the authors pointed out. When insisting superiority of a method, all circumstances should be same. Thus, even if the gold dataset isn’t used to train the segmentation model directly, it seems to me that it is an unfair comparison because the proposed method used another “gold” dataset to train the character embeddings.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: The paper broadens the applicability of readability scores to an additional language, and produces a well-validated applicability score for Vietnamese.   - Weaknesses: The greatest weaknesses, with respect to ACL are that 1) readability scores are of limited interest within the field of computational linguistics. While they are somewhat useful in educational and public communication fields, their impact on the progress of computational linguistics is limited.  A minor weakness is in the writing: the paper has numerous minor grammatical errors. Although the discussion compares the performance of the PDS1 and PDW1 features from the previous work, it is unclear how poorly the previous readability measures perform, relevant to the one developed here, for practical purposes.  - General Discussion: This paper would be a stronger candidate for inclusion if the corpus (and importantly, labels developed) were released. It could be used more widely than the development of scalar readability metrics, and would enable (e.g.) investigation of application of more powerful feature-selection methods.",
            "output": [
                "en"
            ]
        },
        {
            "input": "CONTRIBUTIONS When training LSTMs, many of the intermediate gradients are close to zero due to the flat shape of the tanh and sigmoid nonlinearities far from the origin. This paper shows that rounding these small gradients to zero results in matrices with up to 80% sparsity during training, and that training character-level LSTM language models with this sparsification does not significantly change the final performance of the model. The authors argue that this sparsity could be exploited with specialized hardware to improve the energy efficiency and speed of recurrent network training.  NOVELTY Thresholding gradients to induce sparsity and improve efficiency in RNN training is a novel result to my knowledge.  MISSING CITATIONS Prior work has explored low-precision arithmetic for recurrent neural network language models:  Hubara et al, “Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations”,",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo cumple con el requisito de presentar una experiencia empresarial en aplicaciones de TIC’s con énfasis en la minería, por lo tanto, la evaluación no se hará teniendo en consideración alguna propuesta innovativa en un artículo de carácter científico.  Este artículo describe una experiencia exitosa en el uso de BPMN para modelar el proceso de negocio del área de Ingeniería y Proyectos de una empresa minera peruana. Se usó un pequeño y simple conjunto de elementos de BPMN para modelar el proceso de negocio. Esta experiencia es válida, pero es una solución ad hoc para el proceso de negocio escogido. La solución tendría mayor valoración si se hubiese presentado un modelo pequeño que pudiese ser validado y que pudiese solucionar un conjunto determinado de procesos de negocio asociados a la minería.  Algunas observaciones y/o comentarios menores: - No cumple con el requisito de presentar los artículos como anónimos de autores e institución. - En Resumen, cambiar “control sus procesos” por “control de sus procesos”. - En Introducción, cambiar “beneficios BPMNs” por “beneficios de BPMN”. - En página 3 y otras, utiliza las palabras “figura” y “Figura” en el texto. - En página 5, cambiar “La figura 2 se ha incluido” por “En la Figura 2 se han incluido”. - La referencia a algunas figuras 3 y 4 (mostradas en página 6) solamente se mencionan al final de la página 7. Lo ideal es referenciarla primero y después mostrar la figura. - En página 7, cambiar “el agrupa las tareas” por “agrupa las tareas”. - En Referencia [5] cambiar “BPMNModeling” por “BPMN Modeling”. - La Referencia [7] debe ser completada, la Referencia [12] debe incluir el año.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper introduces the concept of fuzzy paraphrases to aid in the learning of distributed word representations from a corpus augmented by a lexicon or ontology. Sometimes polysemy is context-dependent, but prior approaches have neglected this fact when incorporating external paraphrase information during learning. The main idea is to introduce a function that essentially judges the context-sensitivity of paraphrase candidates, down-weighting those candidates that depend strongly on context. This function is inferred from bilingual translation agreement.  The main argumentation leading to the model selection is intuitive, and I believe that the inclusion of good paraphrases and the elimination of bad paraphrases during training should in principle improve word representation quality. However, the main questions are how well the proposed method achieves this goal, and, even if it achieves it well, whether it makes much difference in practical terms.  Regarding the first question, I am not entirely convinced that the parameterization of the control function f(x_ij) is optimal. It would have been nice to see some experiments investigating different choices, in particular some baselines where the effect of f is diminished (so that it reduces to f=1 in the limit) would have been interesting. I also feel like there would be a lot to gain from having f be a function of the nearby word embeddings, though this would obvious incur a significant slowdown. (See for example 'Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space' by Neelakantan et al, which should probably be cited.) As it stands, the experimental results do not clearly distinguish the fuzzy paraphrase approach from prior work, i.e. tables 3 and 4 do not show major trends one way or the other.  Regarding the second question, it is hard to draw many conclusions from analogy tasks alone, especially when effects unrelated to good/bad paraphrasing such as corpus size/content, window size, vocabulary size, etc., can have an outsize effect on performance.   Overall, I think this is a good paper presenting a sensible idea, but I am not convinced by the experiments that the specific approach is achieving its goal. With some improved experiments and analysis, I would wholeheartedly recommend this paper for acceptance; as it stands, I am on the fence.",
            "output": [
                "en"
            ]
        },
        {
            "input": "The responses to the pre-review questions are not strong; especially w.r.t. the question about dataset density and why the dataset had to be subsampled, the authors responded that subsampling is common in recommender systems work, including the papers cited. This isn't a particularly strong justification of why subsampling is a good idea, and in particular doesn't answer the question of \"how would the results look without subsampling,\" which I think is a question that could easily have been answered directly.  Especially given that the goal of dealing with the cold-start issue is so heavily emphasized in the paper, in seems odd to sample the data to reduce sparsity.  Other than that, the pre-review questions seem to have been answered satisfactorily.  The contribution of the paper is to propose user and item embedding methods, as a means of learning complex non-linear interactions between users and items. This is fairly similar to recent work on deep RS, though the network formulation has some differences.  Overall this is an reasonably put together paper that makes a contribution in an important area, though there are still some shortcomings that should be addressed, namely: 1) The evaluation is unusual. Recall@M is the only result reported, though this is not usually an evaluation seen in recommender systems research. At the very least other performance measures (rmse or AUC) should be reported for completeness, even if the results are not strong 2) Given that the contribution is fairly simple (i.e., the \"standard\" recommender systems task, but with a new model) it's a shame that unusual data samples have to be taken. This should be a case where it's possible to report results against competing methods using *exactly* the same data they used, and exactly the same error measure, for the fairest comparison possible.  Without the above it's hard to tell how much the performance improvements are really due to the method being better, versus the choice of datasets and the choice of loss functions.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este artículo presenta los resultados de un experimento donde se evidencia que las técnicas de  co-creación aplicadas a través de las redes sociales y haciendo uso de dispositivos móviles pueden potenciar la creatividad de los participantes. Es un tema interesante y que considero que puede ser aporte al congreso.  Se debe mejorar la forma de presentación del artículo.  Algunas observaciones y/o comentarios: - Los dos primeros párrafos de la Introducción es casi la totalidad del Resumen. - En página 4, cambiar “cada que” por “cada vez”. - En página 5, Paso 3, no cierra paréntesis en dos ocasiones. - Sugiero agrandar la Figura 2. - Considero excesivo utilizar una página para una sola figura. - En la Referencia [11] , corregir “Conference on the, 2009” - El número de  página 3 se repite tres veces. - Después de la página 7, sigue con la página 3. - Referencia [4] dice “2004b”",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors propose to combine a CCA objective with a downstream loss.  This is a really nice and natural idea.  However, both the execution and presentation leave a lot to be desired in the current version of the paper.  It is not clear what the overall objective is.  This was asked in a pre-review question but the answer did not fully clarify it for me.  Is it the sum of the CCA objective and the final (top-layer) objective, including the CCA constraints?  Is there some interpolation of the two objectives?    By saying that the top-layer objective is \"cosine distance\" or \"squared cosine distance\", do you really mean you are just minimizing this distance between the matched pairs in the two views?  If so, then of course that does not work out of the box without the intervening CCA layer:  You could minimize it by setting all of the projections to a single point.  A better comparison would be against a contrastive loss like the Hermann & Blunsom one mentioned in the reviewer question, which aims to both minimize the distance for matched pairs and separate mismatched ones (where \"mismatched\" ones can be uniformly drawn, or picked in some cleverer way).  But other discriminative top-layer objectives that are tailored to a downstream task could make sense.  There is some loose terminology in the paper.  The authors refer to the \"correlation\" and \"cross-correlation\" between two vectors.  \"Correlation\" normally applies to scalars, so you need to define what you mean here.  \"Cross-correlation\" typically refers to time series.  In eq. (2) you are taking the max of a matrix.  Finally I am not too sure in what way this approach is \"fully differentiable\" while regular CCA is not -- perhaps it is worth revisiting this term as well.  Also just a small note about the relationship between cosine distance and correlation:  they are related when we view the dimensions of each of the two vectors as samples of a single random variable.  In that case the cosine distance of the (mean-normalized) vectors is the same as the correlation between the two corresponding random variables.  In CCA we are viewing each dimension of the vectors as its own random variable.  So I fear the claim about cosine distance and correlation is a bit of a red herring here.  A couple of typos:  \"prosed\" --> \"proposed\" \"allong\" --> \"along\"",
            "output": [
                "en"
            ]
        },
        {
            "input": "The paper presents a medical test based on images of tissue sections. The approach proposed to cancer cells segmentation (membrane localisation) is based on local pixel features and SVM classification.  The paper describes quite well the practical problem it deals with (cancer cells segmentation on images) and it is generally well written.  - The paper approach described in the paper seems a first try on the problem and follows others in a quite similar (but new) problem. Moreover, the paper concludes that the proposed approach is not good enough.  - The features used for classification lacks of frequency information around each pixel (although it used the first derivative with sobel). Most texture descriptors in the literature use frequency information from gabor wavelets, fourier coefficients, DCT, etc. Why not use this kind of information? Why you have chosen this 7 features and not other ones? The paper lacks of experimental evaluation on different features sets.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes joint CTC-attention end-to-end ASR, which utilizes both advantages in training and decoding.   - Strengths: It provides a solid work of hybrid CTC-attention framework in training and decoding, and the experimental results showed that the proposed method could provide an improvement in Japanese CSJ and Mandarin Chinese telephone speech recognition task.   - Weaknesses: The only problem is that the paper sounds too similar with Ref [Kim et al., 2016] which will be officially published in the coming IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), March 2017. Kim at al., 2016, proposes joint CTC-attention using MTL for English ASR task, and this paper proposes joint CTC-attention using MTL+joint decoding for Japanese and Chinese ASR tasks. I guess the difference is on joint decoding and the application to Japanese/Chinese ASR tasks. However, the difference is not clearly explained by the authors. So it took sometimes to figure out the original contribution of this paper.  (a) Title:  The title in Ref [Kim et al., 2016] is “Joint CTC- Attention Based End-to-End Speech Recognition Using Multi-task Learning”, while the title of this paper is “Joint CTC-attention End-to-end Speech Recognition”. I think the title is too general. If this is the first paper about \"Joint CTC-attention\" than it is absolutely OK. Or if Ref [Kim et al., 2016] will remain only as pre-published arXiv, then it might be still acceptable. But since [Kim et al., 2016] will officially publish in IEEE conference, much earlier than this paper, then a more specified title that represents the main contribution of this paper in contrast with the existing publication would be necessary.   (b) Introduction: The author claims that “We propose to take advantage of the constrained CTC alignment in a hybrid CTC-attention based system. During training, we attach a CTC objective to an attention-based encoder network as a regularization, as proposed by [Kim at al., 2016].“ Taking advantage of the constrained CTC alignment in a hybrid CTC-attention is the original idea from [Kim at al., 2016]. So the whole argument about attention-based end-to-end ASR versus CTC-based ASR, and the necessary of CTC-attention combination is not novel. Furthermore, the statement “we propose … as proposed by [Kim et al, 2016]” is somewhat weird. We can build upon someone proposal with additional extensions, but not just re-propose other people's proposal. Therefore, what would be important here is to state clearly the original contribution of this paper and the position of the proposed method with respect to existing literature  (c) Experimental Results: Kim at al., 2016 applied the proposed method on English task, while this paper applied the proposed method on Japanese and Mandarin Chinese tasks. I think it would be interesting if the paper could explain in more details about the specific problems in Japanese and Mandarin Chinese tasks that may not appear in English task. For example, how the system could address multiple possible outputs. i.e., Kanji, Hiragana, and Katakana given Japanese speech input without using any linguistic resources. This could be one of the important contributions from this paper.  - General Discussion: I think it would be better to cite Ref [Kim et al., 2016] from the official IEEE ICASSP conference, rather than pre-published arXiv: Kim, S., Hori, T., Watanabe, S., \"Joint CTC- Attention Based End-to-End Speech Recognition Using Multi-task Learning\", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), March 2017, pp. to appear.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper presents a method for embedding data instances into a low-dimensional space that preserves some form of similarity.  Although the paper presents this notion as new, basically every pre-trained embedding (be it auto-encoders or word2vec) has been doing the same: representing items in a low-dimensional space that inherently encodes their similarities. Even when looking at the specific case of word/context embeddings, the method is not novel either: this method is almost identical to one of the similarity functions presented in \"A Simple Word Embedding Model for Lexical Substitution\" (Melamud et al., 2015). The novelty claim must be more accurate and position itself with respect to existing work.  In addition, I think the evaluation could be done better. There are plenty of benchmarks for word embeddings in context, for example:  *",
            "output": [
                "en"
            ]
        },
        {
            "input": "Vanishing and exploding gradients makes the optimization of RNNs very challenging. The issue becomes worse on tasks with long term dependencies that requires longer RNNs. One of the suggested approaches to improve the optimization is to optimize in a way that the transfer matrix is almost orthogonal. This paper investigate the role of orthogonality on the optimization and learning which is very important. The writing is sound and clear and arguments are easy to follow. The suggested optimization method is very interesting. The main shortcoming of this paper is the experiments which I find very important and I hope authors can update the experiment section significantly. Below I mention some comments on the experiment section:  1- I think the experiments are not enough. At the very least, report the result on the adding problem and language modeling task on Penn Treebank.  2- I understand that the copying task becomes difficult with non-lineary. However, removing non-linearity makes the optimization very different and therefore, it is very hard to conclude anything from the results on the copying task.  3- I was not able to find the number of hidden units used for RNNs in different tasks.  4- Please report the running time of your method in the paper for different numbers of hidden units, compare it with the SGD and mention the NN package you have used.  5- The results on Table 1 and Table 2 might also suggest that the orthogonality is not really helpful since even without a margin, the numbers are very close compare to the case when you find the optimal margin. Am I right?  6- What do we learn from Figure 2? It is left without any discussion.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper presents a new technique for adapting a neural network to a new task for which there is not a lot of training data. The most widely used current technique is that of fine-tuning. The idea in this paper is to instead learn a network that learns features that are complementary to the fixed network. Additionally, the authors consider the setting where the new network/features are “stitched” to the old one at various levels in the hieararchy, rather that it just being a parallel “tower”.   This work is similar in spirit (if not in some details) to the Progressive Nets paper by Rusu et al, as already discussed. The motivations and experiments are certainly different so this submission has merit on its own.  The idea of learning a “residual” with the stitched connnections is very similar in spirit to the ResNet work. It would be nice to compare and contrast those approaches.  I’ve never seen a batch being used 5 times in a row during training, does this work better than just regular SGD?  In Figure 5 it’d be nice to label the y-axis. That Figure would also benefit from not being a bar chart, but simply emulating Figure 4, which is much more readable!  Figure 5 again: what is an untrained model? It’s not immediately obvious why this is a good idea at all. Is TFT-1 simply fine-tuning one more layer than “Retrain Softmax”?  I think that the results at the end of section 3 are a bit weak because of usage of a big network. I would definitely like to see how the results change if using a smaller net.  The authors claim throughout the paper that the purpose of the added connections and layers is to learn *complementary* features and they show this with some figures. The latter are a convinving evidence, but not proof or guarantee that this is what is actually happening. I suggest the authors consider adding an explicit constraint in their loss that encourages that, e.g. by having a soft orthogonality constraing (assuming one can project intermediate features to some common feature dimensionality). The usage of very small L2 regularization maybe achieves the same thing, but there’s no evidence for that in the paper (in that we don’t have any visualizations of what happens if there’s no L2 reg.).  One of the big questions for me while reading the paper was how would an ensemble of 2 pre-trained nets would do on the tasks that the authors consider. This is especially relevant in the cars classification example, where I suspect that a strong baseline is that of fine-tuning VGG on this task, fine-tuning resnet on this task, and possibly training a linear combination of the two outputs or just averaging them naively.  Disappointing that there are no results in figure 4, 5 and 8 except the ones from this paper. It’s really hard to situate this paper if we don’t actually know how it compares to previously published results.   In general, this was an interesting and potentially useful piece of work. The problem of efficiently reusing the previously trained classifier for retraining on a small set is certainly interesting to the community. While I think that this paper takes a good step in the right direction, it falls a bit short in some dimensions (comparisons with more serious baselines, more understanding etc).",
            "output": [
                "en"
            ]
        },
        {
            "input": "En mi opinión, siendo la propuesta de muy alto nivel, no se puede apreciar su grado de relevancia y utilidad.  En algunos pasajes la redacción hace difícil la lectura. Esto ocurre a lo largo de todo el documento.  Presenta una revisión de los conceptos de data warehouse y data mining muy básica, que no está basada en una revisión de literatura relevante.  Carece de elementos concretos que puedan utilizar para desarrollar una solución a un problema concreto.  La bibliografía, tal cual se presenta, está fuera de toda norma utilizada en artículos científicos.  Se sugiere ya sea reenfocar el estudio hacia algo más concreto, o bien proveer evidencias que permitan evaluar de mejor forma la propuesta.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Es una aplicación interesante, sólo que hay medidas como promedios que no son aditivas, por lo que el diseño debe ser corregido, pues los resultados del sistema pueden ser erróneos (no usar para tomar decisiones hasta eliminar los promedios, estos deben construirse en cada nivel de rol up).",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposed a very interesting idea of using cognitive features for sentiment analysis and sarcasm detection. More specifically, the eye-movement patterns of human annotators are recorded to derive a new set of features. The authors claim that this is the first work to include cognitive features into the NLP community.   Strength:  1. The paper is generally well written and easy to follow 2. Very interesting idea which may inspire research in other NLP tasks.  Weakness: 1. The motivation of using cognitive features for sentiment analysis is not very well justified. I can imagine these features may help reflect the reading ease, but I don't see why they are helpful in detecting sentiment polarities. 2. The improvement is marginal after considering cognitive features by comparing Sn+Sr+Gz with Sn+Sr. 3. Although the authors discussed about the feasibility of the approach in Section 7, but I'm not convinced, especially about the example given in section 7.2, I don't see why this technique is helpful in such a scenario.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Trata de aplicar una nueva estrategia a la gestión de requerimientos  No se respalda ni considera la aplicabilidad de técnicas propias de procesos de manufactura a procesos de software. Si bien es cierto hay autores como Demming que plantean que es posible hacerlo, existen otros autores como Sommerville que plantean que por las características propias del desarrollo de software, las técnicas de procesos de manufactura no son aplicables al software. Los autores de este artículo no entregan respaldo en relación a la validez de este aspecto. El artículo comienza planteando que la propuesta es para mejorar la educción de requerimientos, sin embargo, luego se deriva en que lo que se mejora es la generación de la SRS. La educción y la generación del documento de requerimientos son aspectos distintos. En el caso de experimentación que se presenta, no se ve por ninguna parte que se solucionen problemas ni en la educción, ni en la generación de la SRS, son más bien problemas de la implementación. Los errores detectados son aspectos básicos que cualquier programador con un mínimo de experiencia sabe cómo solucionarlos, sin necesidad que en la SRS se explicite el tipo de validaciones mínimas que se debe realizar como parte de las pruebas del sistema. La propuesta carece de guías prácticas que ayuden en su aplicación ¿cómo se deben realizar estas revisiones POKA-YOKE? ¿En qué aspectos hay que fijarse? ¿Existen artefactos que guíen la revisión? Hay errores de edición en el texto (palabras repetidas) Existen problemas de ortografía (acentuación de palabras)",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper introduces a simulator and a set of synthetic tasks for evaluating a dialogue agent's ability to learn from user feedback. For solving these tasks, the paper uses memory networks (Sukhbaatar et al., 2015) learned through previously proposed supervised learning and reinforcement learning methods. In this setup, it is demonstrated that the agent learning from feedback (e.g. through question asking or question clarification) performs better.  The motivation for the paper is excellent; dialogue agents which learn directly from unstructured human feedback (as opposed to reward signals alone) could be very useful in real-world applications. However, the paper falls short on the execution. All the numerous experiments presented are based on the synthetic dialogue simulator, which is highly artificial and different from real-world dialogues. The simulator is based on a simple factoid question-answering framework, which normally is not considered dialogue and which appears to be solvable with a few hand-crafted rules. The framework also assumes that the user's feedback is always correct and is given in one of a handful of forms (e.g. paraphrase of original question without typos) and that the agent can learn from examples of another agent asking questions or making clarifications, which simplifies the task even further.  Because of the artificial setting and limited scope of the experiments, it seems difficult to draw conclusions about how to learn from unstructured user feedback. To test the hypothesis that it is possible to learn from such user feedback, I would strongly recommend the authors to continue working on this project by carrying out experiments with real human users (even in the factoid question answering domain, if necessary). This would provide much stronger evidence that a dialogue agent can learn from such feedback.   Other comments: - The abstract uses the phrase \"interactive dialogue agents\". What is meant by \"interactive\" dialogue agents? All dialogue agents interact with the user, so isn't it redundant to call them interactive? - A major limitation of the experiments is that the questions the agent can ask are specified a priori. If I understand correctly, in the supervised learning setting the agent is trained to imitate the questions of another rule-based agent. While in the RL setting, the paper states \"For each dialogue, the bot takes two sequential actions $(a_1 , a_2)$: to ask or not to ask a question (denoted as a_1 ); and guessing the final answer (denoted as a_2)\". This means the agent learns *when* to ask questions but not *what* questions to ask. - Related to the previous comment, in the sub-section \"ONLINE REINFORCEMENT LEARNING (RL)\" the paper states \"We also explored scenarios where the student learns the ability to decide when to ask a question and what to ask.\". Please clarify this by removing the part \"what to ask\". - The paper presents an overwhelming amount of results. I understand the benefit of synthetic tasks is precisely the ability to measure many aspects of model performance, but in this case it confuses the reader to present so many results. For example, what was the reason for including the \"TrainAQ(+FP)\" and \"TrainMix\" training settings? How do these results help validate the original hypothesis? If they don't, they should be taken out or moved to the appendix. - Since the contribution of the paper lies in the tasks and evaluation, it might be better to move either the vanilla-MemN2N (Table 2) to the appendix or to move the Cont-MemN2N results (Table 3) to the appendix.  --- UPDATE ---  Following the discussion below and the additional experiments provided by the authors, I have increased my score to 8.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Sin duda en este campo se pueden realizar muchos aportes de tipo innovativos (y este trabajo lo es).  En él artículo se debió destacar más fuertemente los aportes informáticos y no tan sólo destacarlos débilmente. Tampoco se ve con claridad el \"cómo se va a ahondar\" en las reglas del negocio y se menciona sólo genéricamente esbozos metodológicos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "RESUMEN: El trabajo relata los pasos seguidos para usar el software ERP SAP en Embonor, una productora y  distribuidora de productos Coca-cola.  Antes de reportar esta experiencia, esta empresa ya contaba con algunos módulos SAP implementados (Financieros, FI-CO, Logistica, Recursos Humanos).  Evaluación General. Aunque el trabajo no presenta una estructura científica de un artículo, es sumamente interesante (en mi opinión) escuchar en más detalle de esta experiencia en infonor 2013. Tal vez, recomendaría agregar/presentar un poco más acerca de las evaluaciones esta implantación (en su conclusión, mencionan esto como un trabajo futuro).  Comentarios menores: - Principalmente cuidar los espaciados entre palabras y puntos. - Figura 1 es muy poco nítida. - Figura 4 dice: \"Menús de la tabla xx (estándar en cada pantalla SAP)\" xx?",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes SEM, a simple large-size multilabel learning algorithm which models the probability of each label as softmax(sigmoid(W^T X) + b), so a one-layer hidden network. This in and of itself is not novel, nor is the idea of optimizing this by adagrad. Though it's weird that the paper explicitly derives the gradient and suggests doing alternating adagrad steps instead of the more standard adagrad steps; it's unclear whether this matters at all for performance. The main trick responsible for increasing the efficiency of this model is the candidate label sampling, which is done in a relatively standard way by sampling labels proportionally to their frequency in the dataset.  Given that neither the model nor the training strategy is novel, it's surprising that the results are better than the state-of-the-art in quality and efficiency (though non-asymptotic efficiency claims are always questionable since implementation effort trades off fairly well against performance). I feel like this paper doesn't quite meet the bar.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Hay importantes aportes, la combinación de procesamiento Digital de imágenes en geología y específicamente en la identificación de de Fracturas en Imágenes de Pozos es un aporte novedoso (en mi opinión).  Un aporte fundamental al trabajo tiene que ver con el la propuesta del método automático de identificación de líneas base y parametrización de fracturas, basado en técnicas de procesamiento de imágenes y un proceso de votación implementado por medio de la transformada de Hough.  en el archivo adjunto se incluyen más observaciones.",
            "output": [
                "es"
            ]
        },
        {
            "input": "No hay contribución científica interesante ya que es la aplicación de modelamiento a un caso de estudio. A pesar de que el trabajo está bien escrito técnicamente y es fácil de seguir no veo cómo es la misma notación la que permite detectar los cuellos de botella. Es el análisis del BPMN por parte del autor quien los detecta.  Otras correcciones: pag 1\ttítulo\tCreo que puede ser mejorado: “Uso de BPMN para detectar cuellos de botella: un caso de estudio” pag 1\tAbstract línea 2\tgestión y control de sus procesos  pag 2\tTitulo BPMN Creo que es mejor nombrar la sección como background o marco teórico pag 3\tFigura 1\tLa cita de la figura 1 debería aparecer antes que ella (revisar todas las figuras)",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo trata sobre la aplicación de BPMN para la comprensión de un proceso de negocio en una empresa minera de Perú.  El documento se encuentra bien estructurado y su lectura es fácil. Se observan pocos errores de redacción. Además su formato es el exigido por el congreso.  En relación al tema del artículo, al ser un aplicación de BPMN, no es novedoso. A partir del caso, creo que era posible realizar un mayor aporte, quizás proponiendo una metodología para abordar la revisión de procesos de negocios, considerando que los actores internos y externos de la empresa, generalmente priorizan la optimización de sus procesos productivos más que la revisión de otros procesos. Por último y no menos importante, el énfasis del artículo es la revisión (auditoría) del proceso con BPMN, alejándose de las temáticas del congreso. Se podría dar mayor énfasis aplicaciones asociados al congreso, tales como análisis de requerimientos a partir de BPMN, implementación de SOA desde BPMN, monitoreo de procesos con BAM y BPMN, etc.  En algunas figuras, a pesar que se mencionan a los contratistas como una entidad externa, no se utiliza un “lane” para representarlos y así observar la interacción con el proceso en revisión.  El trabajo futuro planteado está relacionado con los resultados obtenidos de las mejoras implementadas a partir del análisis realizado en este trabajo. Creo que más que seguir las mejoras implementadas es conveniente hacer un seguimiento a la forma en que se aborda la revisión de un procesos en un ambiente que no prioriza este tipo de tareas o es complejo de realizarlas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta un plan de investigación que propone combinar los constructos teóricos de competencias para la gestión de tecnología (con el modelo BTM) y la precepción de éxito profesional (con un modelo propuesto que combina varios factores de diversas fuentes).  La capacidad de gestión de TI es un elemento clave para los profesionales del área y no solo sus competencias tecnológicas. Parece relevante estudiar como impactan estas competencias en el éxito profesional, o, al menos, en la precepción subjetiva de dicho éxito.  El estudio contiene referencias a fuentes relevantes, aunque se sugiere reducir el número y priorizar para el caso de los artículos en revistas o congresos.  Si bien el tema es relevantes existen algunos riesgos en la definición de los constructos que no son analizados. ¿Cuáles son los límites entre la percepción de éxito profesional y personal? ¿Se puede hacer un estudio de la percepción del éxito profesional solo considerando el modelo BTM y dejando fuera las competencias tecnológicas? ¿El estudio aplica a todos los profesionales de TI o solo a los que gestionan proyectos tecnológicos como CIOs?  La principal debilidad de la investigación es que se identifica como un método experimental, cuando en realidad la encuesta no tiene el grado de control sobre el objeto de estudio para clasificarse de esta manera. También se habla de estudio de causalidad, pero la encuesta solo permitiría un estudio de co-relación.  Sobre la encuesta se explica cuáles son los factores evaluados y la escala Lickert. Sin embargo, faltan ejemplos de preguntas concretas y explicar como van a ser respondidas por los sujetos. Por ejemplo: ¿Es viable que una persona evalúe su compromiso o liderazgo? Aunque se esté evaluando la relación en términos generales y no propios, convendría realizar primero una validación del modelo y luego de la propia encuesta con un grupo de expertos o gestores de profesionales de TI.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper proposes an approach to sequence transduction for the case when a monotonic alignment between the input and the output is plausible. It is assumed that the alignment can be provided as a part of training data, with Chinese Restaurant process being used in the actual experiments.   The idea makes sense, although its applicability is limited to the domains where a monotonic alignment is available. But as discussed during the pre-review period, there has been a lot of strongly overlapping related work, such as probabilistic models with hard-alignment (Sequence Transduction With Recurrent Neural Network, Graves et al, 2012) and also attempts to use external alignments in end-to-end models (A Neural Transducer, Jaitly et al, 2015). That said, I do not think the approach is sufficiently novel.   I also have a concern regarding the evaluation. I do not think it is fair to compare the proposed model that depends on external alignment with the vanilla soft-attention model that learns alignments from scratch. In a control experiment soft-attention could be trained to match the external alignment. Such a pretraining could reduce overfitting on the small dataset, the one on which the proposed approach brings the most improvement. On a larger dataset, especially SIGMORPHON, the improvements are not very big and are only obtained for a certain class of languages.  To sum up, two main issues are (a) lack of novelty (b) the comparison of a model trained with external alignment and one without it.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Generales: - Recomiendo un cambio en el título del artículo para que realmente refleje el contenido del mismo, ya que el título es \"Costo Total de Propiedad para Servicios TI en la Industria Minera de la Segunda Región de Chile.\" sin embargo, lo que haces es recopilar el estado del arte de costos, metodologías, tipos de catálogos de servicios y el alcance se queda en la definición de la metodología que se va a utilizar para formalizar  el TCO para servicios...entendiéndose que están estableciendo las bases para algo que está en desarrollo, no que ya estés mostrando el TCO desarrollado.  - ser coherente con el uso de referencias a lo largo de todos el artículo Resumen:  - Costo Total de Propiedad (TCO)-->(TCO, por sus siglas en inglés) - el artículo dará cuenta --> a que te refieres con se dará cuenta  Abtract: Revisar detalladamente la gramática y lo que se quiere expresar.  - which allows to identify, monitor and compare -->  allows identifying, monitoring and comparing - .. would be an important addition --> it would be an important addition - where categorical thematic analysis for the interviews that we will realize the cost management process will be performed will be performed; --> what???????? - will realize importance and relevance --> will realize the importance and the relevance -ending with the methodology --> Finally, we present the methodology...  Introducción: - Define las siglas AMSA  Análisis Teórico Gestión financiera - Figura 1 no se entiende, está muy pequeña hay que hacerla más grande y mejorar la calidad de la misma  Costos TI -gatos? -Categorización de costos --> hay que incluir las referencias de las fuentes de donde extrajo la información. - revisar falta de palabras como: d, cotos,...  Costo Total de Propiedad -Tabla aparece sin título y fuera de lugar, esto es debe de aparecer después del texto que hace referencia a ella, además no estas manejando porcentajes en la tabla como lo mencionas \"dentro de los cuales se puede observar que el mayot porentaje de costo\" -revisar falta de palabras como:...con esta herramienta tener, mayaria  Metodologías TCO -revisar falta de palabras como: buna las ilustraciones 5 y 10 no aparecen, además si estan manejando el término \"figura\" estandariza en todos lados este término. - mejorar figura 2 (agrandar y mejorar calidad) y revisar la concordancia con el párrafo al que hace referencia a ella  Referencias: La referencia [8] no se encuentra",
            "output": [
                "es"
            ]
        },
        {
            "input": "Taking into account the loss in the binarization step through a proximal Newton algorithm is a nice idea. This is at least one approach to bringing in the missing loss in the binarization step, which has recently gone from a two step process of train and binarize to a single step simultaneous train/compress. Performance on a few small tasks show the benefit. It would be nice to see some results on substantial networks and tasks which really need compression on embedded systems (a point made in the introduction). Is it necessary to discuss exploding/vanishing gradients when the RNN experiments are carried out by an LSTM, and handled by the cell error carousel? We see the desire to tie into proposition 2, but not clear that the degradation we see in the binary connect is related. Adam is used in the LSTM optimization, was gradient clipping really needed, or is the degradation of binary connect simply related to capacity? For proposition 3.1, theorem 3.1 and proposition 3.2 put the pointers to proofs in appendix.",
            "output": [
                "en"
            ]
        },
        {
            "input": "-          De valor dada la relevancia de la temática en la actualidad.  -          Entrega antecedentes empíricos respecto de la intensidad de la relación de las variables en estudio.  -          Define claramente una vía para futuras investigaciones.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The present submission discusses a \"causal regularizer\", which promotes the use of causal dependencies (X -> Y, where X is a feature of the learning problem, and Y is the target variable) in predictive models. Similarly, such causal regularizer penalizes the use of non-causal dependencies, which can arise due to reverse causation (Y -> X) or confounding (X <- Z -> Y, where Z is a hidden confounder).  + Overall, this submission tackles one of the most important problems in machine learning, which is to build causal models. The paper discusses and addresses this issue effectively when applied to a dataset in heart disease. In their experiments, the authors correctly identify some of the common causes of heart disease by virtue of their causal regularizer.  - The authors do not discuss the robustness of their approach with respect to choice of hyper-parameters (both describing the neural network architecture and the generative model that synthesizes artificial causal data). This seems like a crucial issue, in particular when dealing with medical data.  - The conclusions of the experimental evaluation should be discussed in greater length. On the one hand, Figure 4.a shows that there are no differences between L1 and causal regularization in terms of predictive performance, but it is difficult to conclude if this result is statistically significant without access to error-bars. On the other hand, Table 3 describes the qualitative differences between L1 and causal regularization. However, this table is hard to read: How were the 30 rows selected? What does the red highlighting mean? Are these red rows some true causal features that were missed? If so, this is related to precision. What about recall? Did the causal regularization pick up many non-causal features as causal?  - Regarding causal classifiers, this paper should do a much better job at reviewing previous work. For instance, the paper \"Towards a Learning Theory of Cause-Effect Inference\" from Lopez-Paz et al. is missing from the references. However, this prior work studies many of the aspects that are hinted as novel in this submission. In particular, the prior work of Lopez-Paz 1) introduces the concept of Mother distribution (referred as Nature hyper-prior in this submission) which explicitly factorizes the distribution over causes and mechanisms, 2) circumvented intractable likelihoods by synthesizing and training on causal data, 3) tackled the confounding case (compare Figure 1 of this submission and Appendix C of Lopez-Paz), and 4) dealt with discrete data seamlessly (such as the ChaLearn data from Section 5.3 in Lopez-Paz).  On a positive note, this is a well-written paper that addresses the important, under-appreciated problem of incorporating causal reasoning into machine learning. On a negative note, the novelty of the technical contributions is modest and the qualitative evaluation of the results could be greatly extended. In short, I am leaning slightly towards acceptance.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- El artículo aborda un problema contingente y muy relevante, e incluye tanto un diagnóstico nacional de uso de buenas prácticas como una solución (buenas prácticas concretas). - El lenguaje es adecuado.  - El artículo se siente como la concatenación de tres artículos diferentes: (1) resultados de una encuesta, (2) buenas prácticas de seguridad, (3) incorporación de buenas prácticas. - El orden de las secciones sería mejor si refleja este orden (la versión revisada es #2, #1, #3). - El artículo no tiene validación de ningún tipo, ni siquiera por evaluación de expertos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Building on earlier work on a model called NICE, this paper presents an approach to constructing deep feed-forward generative models. The model is evaluated on several datasets. While it does not achieve state-of-the-art performance, it advances an interesting class of models. The paper is mostly well written and clear.  Given that inference and generation are both efficient and exact, and given that this represents a main advantage over other models, it would be great if the authors could provide some motivating example applications where this is needed/would be useful.  The authors claim that “unlike both variational autoencoders and GANs, our technique is able to learn a semantically meaningful latent space which is as high dimensional as the input space.” Where is the evidence for this claim? I didn’t see any analysis of the semantic meaningfulness of the latent space learned by real NVP. Stronger evidence that the learned representations are actually useful for downstream tasks would be nice.  I still think the author’s intuitions around the “fixed reconstruction cost of L2” are very vague. The factorial Gaussian assumption itself does not limit the generative model, it merely smoothes an otherwise arbitrary distribution, and to a degree which can be arbitrarily small, p(x) = \\int p(z) N(x | f(z), \\sigma^2) dz. How a lose lower bound plays into this is not clear from the paper.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths:  This paper presents a step in the direction of developing more challenging corpora for training sentence planners in data-to-text NLG, which is an important and timely direction.   - Weaknesses:  It is unclear whether the work reported in this paper represents a substantial advance over Perez-Beltrachini et al.'s (2016) method for selecting content.  The authors do not directly compare the present paper to that one. It appears that the main novelty of this paper is the additional analysis, which is however rather superficial.  It is good that the authors report a comparison of how an NNLG baseline fares on this corpus in comparison to that of Wen et al. (2016).  However, the BLEU scores in Wen et al.'s paper appear to be much much higher, suggesting that this NNLG baseline is not sufficient for an informative comparison.  - General Discussion:  The authors need to more clearly articulate why this paper should count as a substantial advance over what has been published already by Perez-Beltrachini et al, and why the NNLG baseline should be taken seriously.  In contrast to LREC, it is not so common for ACL to publish a main session paper on a corpus development methodology in the absence of some new results of a system making use of the corpus.  The paper would also be stronger if it included an analysis of the syntactic constructions in the two corpora, thereby more directly bolstering the case that the new corpus is more complex.  The exact details of how the number of different path shapes are determined should also be included, and ideally associated with the syntactic constructions.  Finally, the authors should note the limitation that their method does nothing to include richer discourse relations such as Contrast, Consequence, Background, etc., which have long been central to NLG. In this respect, the corpora described by Walker et al. JAIR-2007 and Isard LREC-2016 are more interesting and should be discussed in comparison to the method here.  References  Marilyn Walker, Amanda Stent, François Mairesse, and Rashmi Prasad. 2007. Individual and domain adaptation in sentence planning for dialogue. Journal of Artificial Intelligence Research (JAIR), 30:413–456.  Amy Isard, 2016. “The Methodius Corpus of Rhetorical Discourse Structures and Generated Texts” , Proceedings of the Tenth Conference on Language Resources and Evaluation (LREC 2016), Portorož, Slovenia, May 2016.  --- Addendum following author response:  Thank you for the informative response.  As the response offers crucial clarifications, I have raised my overall rating.  Re the comparison to Perez-Beltrachini et al.: While this is perhaps more important to the PC than to the eventual readers of the paper, it still seems to this reviewer that the advance over this paper could've been made much clearer.  While it is true that Perez-Beltrachini et al. \"just\" cover content selection, this is the key to how this dataset differs from that of Wen et al.  There doesn't really seem to be much to the \"complete methodology\" of constructing the data-to-text dataset beyond obvious crowd-sourcing steps; to the extent these steps are innovative or especially crucial, this should be highlighted.  Here it is interesting that 8.7% of the crowd-sourced texts were rejected during the verification step; related to Reviewer 1's concerns, it would be interesting to see some examples of what was rejected, and to what extent this indicates higher-quality texts than those in Wen et al.'s dataset.  Beyond that, the main point is really that collecting the crowd-sourced texts makes it possible to make the comparisons with the Wen et al. corpus at both the data and text levels (which this reviewer can see is crucial to the whole picture).  Re the NNLG baseline, the issue is that the relative difference between the performance of this baseline on the two corpora could disappear if Wen et al.'s substantially higher-scoring method were employed.  The assumption that this relative difference would remain even with fancier methods should be made explicit, e.g. by acknowledging the issue in a footnote.  Even with this limitation, the comparison does still strike this reviewer as a useful component of the overall comparison between the datasets.  Re whether a paper about dataset creation should be able to get into ACL without system results:  though this indeed not unprecedented, the key issue is perhaps how novel and important the dataset is likely to be, and here this reviewer acknowledges the importance of the dataset in comparison to existing ones (even if the key advance is in the already published content selection work).  Finally, this reviewer concurs with Reviewer 1 about the need to clarify the role of domain dependence and what it means to be \"wide coverage\" in the final version of the paper, if accepted.",
            "output": [
                "en"
            ]
        },
        {
            "input": "1) Summary  This paper investigates the usefulness of decoupling appearance and motion information for the problem of future frame prediction in natural videos. The method introduces a novel two-stream encoder-decoder architecture, MCNet, consisting of two separate encoders -- a convnet on single frames and a convnet+LSTM on sequences of temporal differences -- followed by combination layers (stacking + convolutions) and a deconvolutional network decoder leveraging also residual connections from the two encoders. The architecture is trained end-to-end using the objective and adversarial training strategy of Mathieu et al.  2) Contributions  + The architecture seems novel and is well motivated. It is also somewhat related to the two-stream networks of Simonyan & Zisserman, which are very effective for real-world action recognition. + The qualitative results are numerous, insightful, and very convincing (including quantitatively) on KTH & Weizmann, showing the benefits of decoupling content and motion for simple scenes with periodic motions, as well as the need for residual connections.  3) Suggestions for improvement  Static dataset bias: In response to the pre-review concerns about the observed static nature of the qualitative results, the authors added a simple baseline consisting in copying the pixels of the last observed frame. On the one hand, the updated experiments on KTH confirm the good results of the method in these conditions. On the other hand, the fact that this baseline is better than all other methods (not just the authors's) on UCF101 casts some doubts on whether reporting average statistics on UCF101 is insightful enough. Although the authors provide some qualitative analysis pertaining to the quantity of motion, further quantitative analysis seems necessary to validate the performance of this and other methods on future frame prediction. At least, the results on UCF101 should be disambiguated with respect to the type of scene, for instance by measuring the overall quantity of motion (e.g., l2 norm of time differences) and reporting PSNR and SSIM per quartile / decile. Ideally, other realistic datasets than UCF101 should be considered in complement. For instance, the Hollywood 2 dataset of Marszalek et al would be a good candidate, as it focuses on movies and often contains complex actor, camera, and background motions that would make the \"pixel-copying\" baseline very poor. Experiments on video datasets beyond actions, like the KITTI tracking benchmark, would also greatly improve the paper.  Additional recognition experiments: As mentioned in pre-review questions, further UCF-101 experiments on action recognition tasks by fine-tuning would also greatly improve the paper. Classifying videos indeed requires learning both appearance and motion features, and the two-stream encoder + combination layers of the MCNet+Res architecture seem particularly adapted, if they indeed allowed for unsupervised pre-trainining of content and motion representations, as postulated by the authors. These experiments would also contribute to dispelling the aforementioned concerns about the static nature of the learned representations.  4) Conclusion  Overall, this paper proposes an interesting architecture for an important problem, but requires additional experiments to substantiate the claims made by the authors. If the authors make the aforementioned additional experiments and the results are convincing, then this paper would be clearly relevant for ICLR.  5) Post-rebuttal final decision  The authors did a significant amount of additional work, following the suggestions made by the reviewers, and providing additional compelling experimental evidence. This makes this one of the most experimentally thorough ones for this problem. I, therefore, increase my rating, and suggest to accept this paper. Good job!",
            "output": [
                "en"
            ]
        },
        {
            "input": "Hoy en día los artículos de \"revisión\" son de mucha utilidad, y la forma de concebirlo es toda una discusión. Por tal motivo, es relevante saber la metodología de búsqueda y recuperación de la información (por años, temas, revistas, journal, etc) para con ello, conseguir una buena redacción técnica que le permita hacer llegar a los lectores los conocimientos que se quieren transmitir.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo propone en forma general una arquitectura basada en la  plataforma Windows Azure para desarrollar aplicaciones para Cloud Computing, el cual es un paradigma muy actual en las tecnologías de la computación.  Se apreciaría algunos indicadores o comparaciones de porqué usar Windows Azure y no otras plataformas para aplicaciones en Cloud Computing.  El uso de Windows Azure para el desarrollo de una aplicación para Cloud Computing no me parece muy original y la arquitectura planteada se basa en MVC, el cual es ampliamente usado en el área de desarrollo de aplicaciones.  El artículo describe en forma muy general los conceptos de Cloud Computing, MVC, Web Services y REST.  El tema de Cloud Computing es un paradigma actual de la computación, y desde ese punto de vista, el artículo es relevante.  Se apreciaría definir los acrónimos al menos una vez, definir si se hablará de \"la cloud\" o \"el cloud\", referencias en la sección de \"Arquitectura Propuesta\" y algunas figuras que mostraran la arquitectura propuesta.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Muchos son los estudios sobre el efecto de las redes sociales, las oportunidades que pueden generar y de influencia en el comportamiento del consumidor. Quizás la más grande contribución de las redes sociales sean recriar la realidad en un Universo que puede ser mejor observable. Sin embargo mucho antes de las redes sociales, de la Internet y de los últimos avances tecnológicos, el comportamiento del consumidor ya era observado e investigado por diferentes áreas del conocimiento. Así, estudiar el marketing boca a boca, uno de los registros más antiguos y fiables aplicados a las redes sociales es de gran importancia. Entender las redes sociales y su múltiple variedad es posibilitar ampliar los estudios a través de otras dimensiones. El uso de las correlaciones y el modelo adoptado abre la posibilidad de su uso en otras realidades, otros países. Por estos motivos me parece conveniente recomendar el artículo según el criterio de \"fuertemente aceptado\" al cumplir con el rigor metodológico, ampliar las cuestiones, probar un modelo y despertar interés para otros investigadores.",
            "output": [
                "es"
            ]
        },
        {
            "input": "All reviewers viewed the paper favourably, although there were some common criticisms. In particular, the demonstration would be more convincing on a more difficult task, and this seems like an intermediate step on the way to an end-to-end solution. There were also questions of being able to reproduce the results. I would strongly recommend that the authors take this suggestions into account.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El manuscrito involucra el uso de GPU, tecnología que desde hace un par de años cada vez tiene más que decir en el área de HPC. El documento tiene estructura relativamente buena, se realizan comparaciones y hay algunos gráficos interesantes.  El documento tiene algunas falencias que lo hacen confuso, por ejemplo, la pagina 7 es un completo desorden, la Figura 7 no está bien explicada, las tablas se tratan como figuras, hay diferencia entre lo que representa una imagen y un gráfico, por lo cual deben ser tratadas de forma independientes. Hay un texto que explica la Figura 6, que por cierto es una tabla, ese texto no es parte del cuerpo del paper, o si?, es muy difícil leer esa página. Yo no soy experto en el algoritmo SIFT, por lo cual al leer el paper no me queda claro si usaron el código SiftGPU creado por Changchang Wu o lo tomaron como base y le aplicaron unas modificaciones.  Por otro lado, hubiera sido interesante saber por qué la implementación en CUDA, la implementación en multicore y la serial podrían arrojar resultados diferentes, si al fin y al cabo los tres enfoques son el algoritmo SIFT. Hace más de 12 años que programo aplicaciones paralelas y para un mismo algoritmo nunca que observado resultados diferentes, si al fin y al cabo el algoritmo es el mismo, ahora, cuando se introducen variantes al algoritmo original con el fin de forzar el paralelismo, se tienen resultados diferentes, pero ya deja de ser el algoritmo original.  Leyendo otros papers sobre el tema, no encuentro tanta originalidad, el documento tampoco ayuda mucho para sacar conclusiones.  El paper tiene datos de corridas y compara distintos enfoques, pero me queda la gran duda del por qué un mismo algoritmo con un enfoque secuencial y otro paralelo con GPU puedan arrojar resultados distintos.  GPU es un asunto que tiene sus gracias, sobre todo por el ahorro en dinero que implica su uso en el largo plazo, por lo podría ser bueno divulgar este trabajo para divulgar esta tecnología.  El documento esta desordenado, falta diferenciar lo que es una figura, de un gráfico y de una tabla, además la pagina 7 es muy difícil de leer y la explicación de las tablas de datos se confunde con el cuerpo del paper.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Los autores hacen un análisis comparativo   entre diversas tecnologias para automación industrial. El análisis me pareció razonablemente profundo y amplio, pero lo califique como \"weak accept\" por no tener contribuciones científicas fuertes.  El texto necesita ser revisado, hay frases largas (por ejemplo la segunda del segundo parágrafo de la introducción tiene 11 líneas) y puntuaciones faltando o colocadas incorrectamente. La primera frase del segundo parágrafo de la introducción.  Incluir también el significado de las siglas PLC y PC.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Resulta interesante el desarrollo de un web framework para la gestión de cámaras IP. Un tema que es, para mí, novedoso y que puede ser extendido en su utilidad.  Hay problemas de redacción y presentación (por ejemplo, \"cuenta con una cámara IP las cuales pueden ...\"). Además, queda poco claro si se han desarrollado aplicaciones sobre el framework y si estas tienen un funcionamiento adecuado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta un estudio sobre las tecnologías que pueden influenciar o afectar la seguridad del Software, abarcando los tópicos generalmente tratados en literatura asociada a seguridad informática. El enfoque que se presenta en el artículo, en lo que respecta a seguridad del software es correcto.  El artículo comienza con referencias a varios tópicos y aspectos primordiales de seguridad, sin embargo no se logra asociar claramente la relación entre los conceptos que fundamentan el estudio con el análisis posteriormente realizado referente a la influencia que tiene la tecnología en la Seguridad.  Adicionalmente, hay aspectos que debieran profundizarse (e.g., en la Figura 4 se muestra una distribución a nivel de uso de sistemas operativos, sin embargo, no se dan mayores detalles o implicaciones que podría tener dicha distribución en lo que respecta a Seguridad).  Las conclusiones no dan un real aporte de parte del autor referente al análisis que se pueda concluir después del estudio realizado.  Las referencias bibliográficas en su mayoría corresponden a textos de seguridad informática, pero se recomienda respaldar la revisión bibliográfica con mayor cantidad artículos científicos actuales.",
            "output": [
                "es"
            ]
        },
        {
            "input": "RESUMEN. Este trabajo describe tres de actividades docentes en un curso electivo de la Universidad de La Serena. Desarrollar intérpretes usando la herramienta ANTLR en Android es la principal conexión de estas actividades. La primera actividad implementa un parser/interprete para una calculadora. La segunda actividad incorpora la habilidad de ordenar listas en el intérprete. La última actividad incorpora el servicio de reconocimiento de voz usando una librería de Google. De acuerdo al trabajo, el resultado de estas actividades permitió a los alumnos comprender de mejor manera los conceptos de lenguajes formales.  Evaluación General: El trabajo describe de manera muy clara como se realizaron las actividades en el curso electivo. Sin embargo, desde mi punto de vista, el trabajo presenta dos grandes debilidades:  1) La principal motivación del trabajo es que el uso de las herramientas ANTLR son útiles para los cursos de lenguajes formales. No obstante, nunca se ofrece una muestra de por qué es cierta esta afirmación, solamente se detallan como implementar los software de las actividades. Es fuertemente recomendable dar reales señales (ej. justificaciones, experimentos, etc) de por qué estas herramientas ayudan a la docencia de estos tópicos.  2) Este punto es la causa del punto anterior. No una hay motivación o problema que claramente muestre la necesidad de usar estas herramientas para un curso de lenguajes. Si los autores logran encontrar una motivación clara y medible, el punto 1) puede ser resuelto.  Finalmente, el trabajo no logra convencer con su conclusión.  Comentarios menores: 1) El trabajo excede el número de máximo exigido de páginas (9 (>8) páginas). 2) En la conclusión se afirma que con el uso de ANTLR en Android y el conocimiento de lenguajes formales se puede igualar las herramientas de Siri (Apple) & Google Now. En mi opinión, esa afirmación no es verdadera, porque para resolver las actividades usan las APIs de Google, significando que sin los productos de Google, estas actividades no pueden llevarse a cabo. En resumen, ANTLR y el conocimiento de lenguajes formales no son suficientes para construir Google Now.   3) Sería agradable usar las referencias canónicas de DSLs en cambio de las usadas en el trabajo:  @article{vanDeursen:2000:DLA:352029.352035,  author = {van Deursen, Arie and Klint, Paul and Visser, Joost},  title = {Domain-specific languages: an annotated bibliography},  journal = {SIGPLAN Not.},  issue_date = {June 2000},  volume = {35},  number = {6},  month = jun,  year = {2000},  issn = {0362-1340},  pages = {26--36},  numpages = {11},  url = {[Link]},  doi = {10.1145/352029.352035},  acmid = {352035},  publisher = {ACM},  address = {New York, NY, USA}, }  @article{Mernik:2005:DDL:1118890.1118892,  author = {Mernik, Marjan and Heering, Jan and Sloane, Anthony M.},  title = {When and how to develop domain-specific languages},  journal = {ACM Comput. Surv.},  issue_date = {December 2005},  volume = {37},  number = {4},  month = dec,  year = {2005},  issn = {0360-0300},  pages = {316--344},  numpages = {29},  url = {[Link]},  doi = {10.1145/1118890.1118892},  acmid = {1118892},  publisher = {ACM},  address = {New York, NY, USA},  keywords = {Domain-specific language, application language, domain analysis, language development system}, }  4) El texto asociado a la memoria de título no aporta mucho al trabajo. 5) Pequeños errores de ortografías deberían ser corregidos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Contributions The paper presents an adaptation of batch normalization for RNNs in the case of LSTMs, along the horizontal depth. Contrary to previous work from (Laurent 2015; Amodei 2016), the work demonstrates that batch-normalizing the hidden states of RNNs can improve optimization, and argues with quantitative experiments that the key factor to making this work is proper initialization of parameters, in particular gamma. Experiments show some gain in performance over vanilla LSTMs on Sequential MNIST, PTB, Text8 and CNN Question-Answering.  Novelty+Significance Batch normalization has been key for training deeper and deeper networks (e.g. ResNets) and it seems natural that we would want to extend it to RNNs.  The paper shows that it is possible to do so with proper initialization of parameters, contrary to previous work from (Laurent 2015; Amodei 2016). Novelty comes from where to batch norm (i.e. not in the cell update) and in the per-time step statistics.   Adding batch normalization to LSTMs incurs additional computational cost and bookkeeping; for training speed comparisons (e.g. Figure 2) the paper only compares LSTM and BN-LSTM by iteration count; given the additional complexity of the BN-LSTM I would have also liked to see a wall-clock comparison.  As RNNs are used across many tasks, this work is of interest to many.  However, the results gains are generally minor and require several tricks to work in practice. Also, this work doesn’t address a question about batch normalization that it seems natural that it helps with faster training, but why would it also improve generalization?   Clarity The paper is overall very clear and well-motivated. The model is well described and easy to understand, and the plots illustrate the points clearly.  Summary Interesting though relatively incremental adaptation, but shows batch normalization to work for RNNs where previous works have not succeeded. Comprehensive set of experiments though it is questionable if the empirical gains are significant enough to justify the increased model complexity as well as computational overhead.  Pros - Shows batch normalization to work for RNNs where previous works have not succeeded - Good empirical analysis of hyper-parameter choices and of the activations - Experiments on multiple tasks - Clarity  Cons - Relatively incremental - Several ‘hacks’ for the method (per-time step statistics, adding noise for exploding variance, sequence-wise normalization) - No mention of computational overhead - Only character or pixel-level tasks, what about word-level?",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo tiene dos contribuciones principales: una discusión sobre la utilidad de los controles SCADA sobre dispositivos móviles, una descripción de algunas de las aplicaciones concreta que implementan esta función en celulares o tablets.  Hay varios errores de escritura a lo largo del artículo. Por ejemplo se utilizan separadores al final de frase _, pero no en forma consistente. La primera y última oración del abstract parecen mal redactadas. En los párrafos finales de la introducción las listas no son claramente explicadas.  Si bien es relevante para la conferencia hacer una revisión de aplicaciones SCADA para móviles, no se define un mecanismo de búsqueda, ni un criterio para compararlas. ¿Cuáles son sus diferencias? ¿Cuál es adecuada en cada caso?  Se sugiere incluir una tabla comparativa de sus prestaciones, y más importante, definir criterios de comparación para poder aportar nuevos datos al lector. Las conclusiones retoman la introducción pero no responden qué aplicaciones convendría usar para el contexto de industria minera.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper presents a software tool that is useful in the context of software engineering. The authors do a good job describing the technical details of the tool. However, there is little information about the novel aspects of the proposed tool, How the proposal compares to other existing tools (if any)?",
            "output": [
                "en"
            ]
        },
        {
            "input": "The authors extend GANs by an inference path from the data space to the latent space and a discriminator that operates on the joint latend/data space. They show that the theoretical properties of GANs still hold for BiGAN and evaluate the features learned unsupervised in the inference path with respect to performance on supervised tasks after retraining deeper layers.  I see one structural issue with this paper: Given that, as stated in the abstract, the main purpose of the paper is to learn unsupervised features (and not to improve GANs), the paper might spent too much space on detailing the relationship to GANs and all the theoretical properties. It is not clear whether they actually would help with the goal of learning good features. While reading the paper, I actually totally forgot about the unsupervised features until they reappeared on page 6. I think it would be helpful if the text of the paper would be more aligned with this main story.  Still, the BiGAN framework is an elegant and compelling extension to GANs. However, it is not obvious how much the theoretical properties help us as the model is clearly not fully converged. To me, especially Figure 4 seems to suggest that G(E(x)) might be doing not much more than some kind of nearest neighbour retrival (and indeed one criticism for GANs has always been that they might just memorize some samples). By the way, it would be very interesting to know how well the discriminator actually performs after training.  Coming back to the goal of learning powerful features: The method does not reach state-of-the-art performance on most evaluated tasks (Table 2 and 3) but performs competitive and it would be interesting to see how much this improves if the BiGAN training (and the convolutional architecture used) would be improved.  The paper is very well written and provides most necessary details, although some more details on the training (learning rates, initialization) would be helpful for reproducing the results.  Overall I think the paper provides a very interesting framework for further research, even though the results presented here are not too impressive both with respect to the feature evaluation (and the GAN learning).  Minor: It might be helpful to highlight the best performance numbers in Tables 2 and 3.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Se propone un modelo CityCA, basado en autómata celulares para distribución.  El paper está bien escrito y bien distribuido, tal vez ordenar un poco el abstracta se entendería mejor.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo, según los revisores, no presenta una contribución científica directa en el área de robótica o sistemas difusos, sin embargo es una aplicación muy interesante a ser presentada en el Workshop de Robótica de INFONOR 2013. Es por ello que se recomienda aceptar el artículo para su presentación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Tema bien tratado técnicamente y en forma clara.  El tema solo muestra un manejo técnico sobre una herramienta, y no aporta algo novedoso. Se recomienda hacer una comparación en complejidad sobe las SQL con datos primitivos versus a datos XML, y abarcar otros aspectos como por ejemplo la mejora, etc.",
            "output": [
                "es"
            ]
        },
        {
            "input": "As you noted for Figure 5 Left, sometimes it seems sufficient to tune learning rates. I see your argument for Figure 6 Right,  but  1) not for all good learning rates make Adam fail, I guess you selected the one where it did (note that Adam was several times faster than Eve in the beginning) 2) I don't buy \"Eve always converges\" because you show it only for 0.1 and since Eve is not Adam, 0.1 of Adam is not 0.1 of Eve because of d_t.   To my understanding, you define d_t over time with 3 hyperparameters. Similarly, one can define d_t directly. The behaviour of d_t that you show is not extraordinary and can be parameterized. If Eve is better than Adam, then looking at d_t we can directly see whether we underestimated or overestimated learning rates. You could argue that Eve does it automatically but you do tune learning rates for each problem individually anyway.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este es un trabajo que muestra la experiencia de incorporación de un robot para realizar soldaduras en una empresa de Antofagasta.  La incorporación de tecnología es importante en la Empresa y me parece importante que las empresas confíen en las Universidades para hacerlo. Es un tema importante de revisar en las jornadas.  Revisar aspectos de formato (redacción en tercera persona, ortografía, algunas imágenes no son claras, contiene 7 páginas y sólo eran consideradas 6 o 10) No queda clara si la Empresa utiliza robot y soldadores o sólo robots. No hay una evaluación de los beneficios en cuanto a dinero percibidos por la utilización del robot.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Abstract  •This paper presents a study of the security of software products, life cycle, risks and costs associated --> This paper presents a study of the security of software products, the life cycle, the risks and the associated costs  •This article is part of a research postgraduate --> This article is a part of a postgraduate research  •in turn to the people --> an at the same time its affects the people….  •The fundamental purpose of this article rests on whether --> The fundamental purpose of this paper rests on determining whether  •Left open the possibility of an empirical study --> Left open the possibility of  performing an empirical study  Introducción  •“Los errores en un software pueden provocar daños irreversibles como la pérdida de vidas humanas” --> si bien esto es cierto depende del tipo de software y el entorno en el cual esté funcionando, por lo que recomiendo especificar en qué entornos y/o situaciones el software puede causar la pérdida de vidas humanas  Desarrollo de Software Seguro  •Mejorar la calidad de la Figura 1  •Recomiendo modificar la Figura 2, ya que su único objetivo es mostrar el  ciclo de vida, por lo que es suficiente incluir las fases, ya las actividades de cada fase de describen en la Tabla 1  Riesgos y costos asociados a la ausencia de seguridad  •[29]--> la referencia se lista por orden de aparición en este caso le corresponde el número 10  •Definir: Cm, Cs y Cn  Análisis de la tecnología y su influencia en la seguridad  •Revisar la Figura 3: (1) ¿será que están intercambiadas los títulos de las columnas de los años?; (2) recomiendo dar una explicación a los elementos de la tabla; (3) a que te refieres con change y los símbolos de la columna  •Recomiendo agregar en la sección de sistemas operativos y tecnología de autenticación algo sobre las vulnerabilidades encontradas en esta tecnología. Seguridad y tecnología  •Revisar la tabla 3: (1) título de columna: posibilidad de incorporación --> posibilidad de incorporación al ciclo de seguridad  •En la tabla 2 mencionas tecnología, momento de decisión y etapa de uso, que luego no concuerda con lo la Tabla 3 o al menos eso entiendo, por lo que recomiendo hacer una descripción justificando los valores que asignaste en la tabla, para resaltar la aportación  Referencia  •No date = (nd)  •Revisar referencia 16 -->”la Casa”?  •Referencia 20 y 22 está repetida",
            "output": [
                "es"
            ]
        },
        {
            "input": "SUMMARY  This paper studies the expressive power of deep neural networks under various related measures of expressivity.  It discusses how these measures relate to the `trajectory length', which is shown to depend exponentially on the depth of the network, in expectation (at least experimentally, at an intuitive level, or theoretically under certain assumptions).  The paper also emphasises the importance of the weights in the earlier layers of the network, as these have a larger influence on the represented classes of functions, and demonstrates this in an experimental setting.   PROS  The paper further advances on topics related to the expressive power of feedforward neural networks with piecewise linear activation functions, in particular elaborating on the relations between various points of view.   CONS  The paper further advances and elaborates on interesting topics, but to my appraisal it does not contribute significantly new aspects to the discussion.   COMMENTS - The paper is a bit long (especially the appendix) and seems to have been written a bit in a rush.  Overall the main points are presented clearly, but the results and conclusions could be clearer about the assumptions / experimental vs theoretical nature.  The connection to previous works could also be clearer.   - On page 2 one finds the statement ``Furthermore, architectures are often compared via ‘hardcoded’ weight values -- a specific function that can be represented efficiently by one architecture is shown to only be inefficiently approximated by another.''   This is partially true, but it neglects important parts of the discussion conducted in the cited papers.  In particular, the paper [Montufar, Pascanu, Cho, Bengio 2014] discusses not one hard coded function, but classes of functions with a given number of linear regions.  That paper shows that deep networks generically* produce functions with at least a given number of linear regions, while shallow networks never do.  * Generically meaning that, after fixing the number of parameters, any function represented by the network, for parameter values form an open, positive -measure, neighbourhood, belongs to the class of functions which have at least a certain number of linear regions.  In particular, such statements can be directly interpreted in terms of networks with random weights.   - One of the measures for expressivity discussed in the present paper is the number of Dichotomies. In statistical learning theory, this notion is used to define the VC-dimension. In that context, a high value is associated with a high statistical complexity, meaning that picking a good hypothesis requires more data.   - On page 2 one finds the statement ``We discover and prove the underlying reason for this – all three measures are directly proportional to a fourth quantity, trajectory length.''  The expected trajectory length increasing exponentially with depth can be interpreted as the increase (or decrease) in the scale by a composition of the form a*...*a x, which scales the inputs by a^d. Such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions. Here it seems that at least the assumptions on the considered types of trajectories also play an important role.  This is probably related to another observation from page 4: ``if the variance of the bias is comparatively too large... then we no longer see exponential growth.''  OTHER SPECIFIC COMMENTS  In Theorem 1  - Here it would be good to be more specific about ``random neural network'', i.e., fixed connectivity structure with random weights, and also about the kind of one-dimensional trajectory, i.e., finite in length, closed, differentiable almost everywhere, etc.   - The notation ``g \\geq O(f)'' used in the theorem reads literally as |g| \\geq \\leq k |f| for some k>0, for large enough arguments. It could also be read as g being not smaller than some function that is bounded above by f, which holds for instance whenever g\\geq 0.  For expressing asymptotic lower bounds one can use the notation \\Omega (see",
            "output": [
                "en"
            ]
        },
        {
            "input": "The starting point of this work is the understanding that by having decorrelated neurons (e.g. neurons that only fire on background, or only on foreground regions) one provides independent pieces of information to the subsequent decisions. As such one gives \"complementary viewpoints\" of the input to the subsequent layers, which can be thought of as performing ensembling/expert combination within the model, rather than using an ensemble of networks.   For this, the authors propose a sensible method to decorrelate the activations of intermediate neurons, with the aim of delivering complementary inputs to the final classification layers: they split intermediate neurons to a \"foreground\" and a \"background\" subset, and append side-losses that force them to be zero on background and foreground pixels respectively.   They demonstrate that this can improve classification on a mid-scale classification example (a fraction of imagenet, and a ResNet with 18, rather than 150 layers), when compared to a \"vanilla\" baseline that does not use these losses.  I enjoyed reading the paper because the idea is simple, smart, and seems to be effective.  But there are a few concerns; -firstly, the way of doing this seems very particular to vision. In vision one knows that masking the features (during both training and testing) helps, e.g.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Strengths: *- Task *- Simple model, yet the best results on SQuAD (single model0 *- Evaluation and comparison  - Weaknesses: *- Analysis of errors/results (See detailed comments below)  - General Discussion: In this paper the authors present a method for directly querying Wikipedia to answer open domain questions. The system consist of two components - a module to query/fetch wikipedia articles and a module to answer the question given the fetched set of wikipedia articles.   The document retrieval system is a traditional IR system relying on term frequency models and ngram counts.  The answering system uses a feature representation for paragraphs that consists of word embeddings, indicator features to determine whether a paragraph word occurs in a question, token-level features including POS, NER etc and a soft feature for capturing similarity between question and paragraph tokens in embedding space. A combined feature representation is used as an input to a bi-direction LSTM RNN for encoding. For questions an RNN that works on the word embeddings is used.  These are then used to train an overall classifier independently for start and end spans of sentences within a paragraph to answer questions.  The system has been trained using different Open Domain QA datasets such as SQuAD and WebQuestions by modifying the training data to include articles fetched by the IR engine instead of just the actual correct document/passage.  Overall, an easy to follow interesting paper but I had a few questions: 1) The IR system has a Accuracy@5 of over 75 %, and individually the document reader performs well and can beat the best single models on SquAD. What explains the significant drop in Table 6. The authors mention that instead of the fetched results, if they test using the best paragraph the accuracy reaches just 0.49 (from 0.26) but that is still significantly below the 0.78-79 in the SQuAD task.  So, presumably the error is this large because the neural network for matching isnt doing as good a job in learning the answers when using the modified training set (which includes fetched articles) instead of the case when training and testing is done for the document understanding task. Some analysis of whats going on here should be provided. What was the training accuracy in the both cases? What can be done to improve it? To be fair, the authors to allude to this in the conclusion but I think it still needs to be part of the paper to provide some meaningful insights.  2) I understand the authors were interested in treating this as a pure machine comprehension task and therefore did not want to rely on external sources such as Freebase which could have helped with entity typing        but that would have been interesting to use. Tying back to my first question -- if the error is due to highly relevant topical sentences as the authors mention, could entity typing have helped?  The authors should also refer to QuASE (Sun et. al 2015 at WWW2015) and similar systems in their related work. QuASE is also an Open domain QA system that answers using fetched passages - but it relies on the web instead of just Wikipedia.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo aborda un tema de interés como lo es el manejo de grandes datos y su estructura en base a metadatos para su procesamiento en la era de la web semántica.  El artículo presenta serias deficiencias léxicas e incluso semánticas. La traducción del título y el abstract en inglés presentan errores graves. En el aspecto semántico, en la introducción mencionan como problema que las bases de datos relacionales no tengan problemas de adaptación. Como error léxico, escriben A un, en lugar de Aún. En forma errónea se utiliza el término Apropósito, en lugar de A propósito. Las conclusiones no permiten centrar una propuesta. Hay buena utilización de las referencias bibliográficas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths:  This is the first neural network-based approach to argumentation mining. The proposed method used a Pointer Network (PN) model with multi-task learning and outperformed previous methods in the experiments on two datasets.  - Weaknesses:  This is basically an application of PN to argumentation mining. Although the combination of PN and multi-task learning for this task is novel, its novelty is not enough for ACL long publication. The lack of qualitative analysis and error analysis is also a major concern.  - General Discussion:  Besides the weaknesses mentioned above, the use of PN is not well-motivated. Although three characteristics of PN were described in l.138-143, these are not a strong motivation against the use of bi-directional LSTMs and the attention mechanism. The authors should describe what problems are solved by PN and discuss in the experiments how much these problems are solved.  Figures 2 and 3 are difficult to understand. What are the self link to D1 and the links from D2 to E1 and D3/D4 to E2? These are just the outputs from the decoder and not links. The decoder LSTM does not have an input from e_j in these figures, but it does in Equation (3). Also, in Figure 3, the abbreviation \"FC\" is not defined.  Equation (8) is strange. To calculate the probability of each component type, the probability of E_i is calculated.  In the experiments, I did not understand why only \"PN\", which is not a joint model, was performed for the microtext corpus.  It is not clear whether the BLSTM model is trained with the joint-task objective.  There are some studies on discourse parsing using the attention mechanism. The authors should describe the differences from these studies.  Minor issues:  l.128: should related -> should be related  l.215: (2015) is floating  l.706: it able -> it is able  I raised my recommendation score after reading the convincing author responses. I strongly recommend that the authors should discuss improved examples by PN as well as the details of feature ablation.",
            "output": [
                "en"
            ]
        },
        {
            "input": "- Propuesta innovadora de aplicación de una metodología de ingeniería industrial, al campo de ingeniería de requisitos.  - No presenta unificación de términos a lo largo del documento, relacionado con la fase de ingeniería de requisitos: ‘educción’, ‘elicitación'... Debe utilizarse siempre el mismo término. - No se evidencia cómo se cuantifica las ‘mejoras’ graduales del proceso de educción, y la ‘mejoría’ en la calidad de la documentación.. cómo miden esa mejora?? - Hay errores de redacción y ortográficos, particularmente en el uso del acento (tildes) y de signos de puntuación (uso de la coma y punto y coma).  El artículo propone la utilización de una filosofía de trabajo de otra área de ingeniería, para mejorar los niveles de calidad de los documentos de requisitos generados en un proceso de educción de requisitos.  Considero que desde el punto de vista técnico sería importante que sustentaran el análisis de resultados que plantean en una medición o comparación cuantificada, que permita por medio de un método más formal que el descriptivo generar las conclusiones de 'mejora' en la calidad de los productos asociados al proceso de ingeniería de requisitos.  No se evidencia cómo llegan a las conclusiones generadas, en qué se basan para decir que es mejor o no, en que tiene menos errores o no ??  Es una propuesta interesante que puede ser aplicado en casos reales de procesos de ingeniería de requisitos. Actualmente aporta a disminuir la crisis asociada a esta fase de desarrollo de productos software.  La organización del documento se puede mejorar considerablemente. Considero que dedican gran parte del artículo a expresar el marco conceptual asociado, y menos a la aplicación de la técnica en el caso de estudio y al análisis de resultados, apartados en los que se puede sustentar más la propuesta presentada. Así mismo, hay errores ortográficos y de redacción que, si se evitan, pueden darle mayor valor a la presentación del artículo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo propone y evalúa una aplicación desarrollada para representar de mejor forma los resultados de algoritmos de reglas de asociación. En general el artículo me parece bien escrito y estructurado. Tal vez, para mejorar, la estructura del documento agregaría una sección especial dedicada a la metodología y describiría ésta más detalladamente. Los autores evalúan cualitativamente el rendimiento de la interfaz en términos de la facilidad de interpretación de la información que entrega. Para ello exponen la información a un grupo de usuarios. El método de evaluación por usuarios es uno conocido y validado. No obstante, el artículo explica muy superficialmente el proceso de validación de usuarios usado. Por otra parte, los resultados de la evaluación presentados son sólo descriptivos. Podría haberse usado técnicas estadísticas de medición de consensos de intérpretes como el índice de Kappa u otros para analizar la calidad de la coincidencia entre los evaluadores. En síntesis, me parece un buen artículo con una idea bien elaborada pero que metodológicamente debería ser mejorado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo es DEMASIADO preliminar: no existen experimentos y por tanto sin resultados ni análisis.  El trabajo solo se enfoca en realizar una discusión de métodos de optimización para el problema en cuestión. Posteriormente, solo define formalismos conocidos y genéricos para el problema.   El paper es MUY débil, requiere aún MUCHO trabajo para ser un manuscrito con alguna relevancia!",
            "output": [
                "es"
            ]
        },
        {
            "input": "This paper proposes a neural network architecture that represent structural linguistic knowledge in a memory network for sequence tagging tasks (in particular, slot-filling of the natural language understanding unit in conversation systems). Substructures (e.g. a node in the parse tree) is encoded as a vector (a memory slot) and a weighted sum of the substructure embeddings are fed in a RNN at each time step as additional context for labeling.  -----Strengths-----  I think the main contribution of this paper is a simple way to \"flatten\" structured information to an array of vectors (the memory), which is then connected to the tagger as additional knowledge. The idea is similar to structured / syntax-based attention (i.e. attention over nodes from treeLSTM); related work includes Zhao et al on textual entailment, Liu et al. on natural language inference, and Eriguchi et al. for machine translation. The proposed substructure encoder is similar to DCNN (Ma et al.): each node is embedded from a sequence of ancestor words. The architecture does not look entirely novel, but I kind of like the simple and practical approach compared to prior work.  -----Weaknesses-----  I'm not very convinced by the empirical results, mostly due to the lack of details of the baselines. Comments below are ranked by decreasing importance.  -  The proposed model has two main parts: sentence embedding and substructure embedding. In Table 1, the baseline models are TreeRNN and DCNN, they are originally used for sentence embedding but one can easily take the node/substructure embedding from them too. It's not clear how they are used to compute the two parts.  - The model uses two RNNs: a chain-based one and a knowledge guided one. The only difference in the knowledge-guided RNN is the addition of a \"knowledge\" vector from the memory in the RNN input (Eqn 5 and 8). It seems completely unnecessary to me to have separate weights for the two RNNs. The only advantage of using two is an increase of model capacity, i.e. more parameters. Furthermore, what are the hyper-parameters / size of the baseline neural networks? They should have comparable numbers of parameters.  - I also think it is reasonable to include a baseline that just input additional knowledge as features to the RNN, e.g. the head of each word, NER results etc.  - Any comments / results on the model's sensitivity to parser errors?  Comments on the model:  - After computing the substructure embeddings, it seems very natural to compute an attention over them at each word. Is there any reason to use a static attention for all words? I guess as it is, the \"knowledge\" is acting more like a filter to mark important words. Then it is reasonable to include the baseline suggest above, i.e. input additional features.  - Since the weight on a word is computed by inner product of the sentence embedding and the substructure embedding, and the two embeddings are computed by the same RNN/CNN, doesn't it means nodes / phrases similar to the whole sentence gets higher weights, i.e. all leaf nodes?  - The paper claims the model generalizes to different knowledge but I think the substructure has to be represented as a sequence of words, e.g. it doesn't seem straightforward for me to use constituent parse as knowledge here.  Finally, I'm hesitating to call it \"knowledge\". This is misleading as usually it is used to refer to world / external knowledge such as a knowledge base of entities, whereas here it is really just syntax, or arguably semantics if AMR parsing is used.  -----General Discussion-----  This paper proposes a practical model which seems working well on one dataset, but the main ideas are not very novel (see comments in Strengths). I think as an ACL paper there should be more takeaways. More importantly, the experiments are not convincing as it is presented now. Will need some clarification to better judge the results.  -----Post-rebuttal-----  The authors did not address my main concern, which is whether the baselines (e.g. TreeRNN) are used to compute substructure embeddings independent of the sentence embedding and the joint tagger. Another major concern is the use of two separate RNNs which gives the proposed model more parameters than the baselines. Therefore I'm not changing my scores.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Authors propose a competitive learning architecture that learn different RNN predictors independently, akin to a committee of experts which are chosen with a hard switch at run-time. This work is applied to the task of predictive different driving behaviors from human drivers, and combines behaviors at test time, often switching behaviors within seconds. Prediction loss is lower than the similar but non-competitive architecture used as a baseline. It is not very clear how to interpret the results, what is the real impact of the model. If behaviors switch very often, can this really be seen as choosing the best driving mode for a given situation? Maybe the motivation needs to be rephrased a little to be more convincing? The competitive approach presented is interesting but not really novel, thus the impact of this paper for a conference such as ICLR may be limited.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo compara cuatro arquitecturas de navegación autónoma para robots móviles, las arquitecturas reactivo puro, redes neuronales, lógica difusa y una arquitectura hibrida neuro-difusa.  EL trabajo está bien planteado, el trabajo experimental parece replicable y los resultados presentados suenan coherenten.  El principal aspecto a mejorar sería el análisi/discusion de los resultados, el cual se puede desarrollar más.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Nice idea but not complete, model size is not reduced by the large factors found in one of your references (Song 2016), where they go to 5 bits, but this is ontop of pruning which gives overall 49X reduction in model size of VGG (without loss of accuracy). You may achieve similar reductions with inclusion of pruning (or better since you go to 4 bits with no loss) but we should see this in the paper, so at the moment it is difficult to compare",
            "output": [
                "en"
            ]
        },
        {
            "input": "The authors propose a method to investigate the predictiveness of intermediate layer activations. To do so, they propose training linear classifiers and evaluate the error on the test set.  The paper is well motivated and aims to shed some light onto the progress of model training and hopes to provide insights into deep learning architecture design.  The two main reasons for why the authors decided to use linear probes seem to be: - convexity - The last layer in the network is (usually) linear  In the second to last paragraph of page 4 the authors point out that it could happen that the intermediate features are useless for a linear classifier. This is correct and what I consider the main flaw of the paper. I am missing any motivation as to the usefulness of the suggested analysis to architecture design. In fact, the example with the skip connection (Figure 8) seems to suggest that skip connections shouldn't be used. Doesn't that contradict the recent successes of ResNet?  While the results are interesting, they aren't particularly surprising and I am failing to see direct applicability to understanding deep models as the authors suggest.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper provides a number of performance enhancements inspired by domain knowledge. Taken together, these produce a compelling system that has shown itself to be the best-in-class as per the related competition.  Experts agree that the authors do a good job at justifying the majority of the design decisions.    pros:  - insights into the SOTA Doom player    cons:  - lack of pure technical novelty: the various elements have existed previously    This paper comes down to a matter of taste in terms of appreciation of SOTA systems or technical novelty.  With the code being released, I believe that this work will have impact as a benchmark, and as a guidebook  as to how features can be combined for SOTA performance on FPS-style scenarios.",
            "output": [
                "en"
            ]
        },
        {
            "input": "La publicación trata sobre un sistema de reconstrucción de superficies a través de un escaneo, utilizando para ello una cámara de vídeo convencional, un motor y un láser. Bajo este esquema, se desarrolla un sistema de bajo coste, con las ventajas y limitaciones propias de la proposición.  - Creo que el sistema propuesto parte de una premisa interesante que es su bajo coste. Los sistemas comerciales para este tipo de desarrollos pueden ser, en la mayoría de las ocasiones, de costes muy elevados, dependiendo del tipo de elementos que se utilicen. - A pesar de la simpleza de la arquitectura propuesta, creo que el sistema es mejorable. Por ahora, creo que falta un camino por recorrer (de acuerdo a lo leído en el paper) en lo que refiere a su uso más allá del laboratorio.  Es por eso que en ORIGINALIDAD (ORIGINALITY) se califica con nota 4 (good)  - Una de las primeras debilidades encontradas en la publicación es su introducción. Esta peca, a mi parecer, de dos problemas: El primer problema es que su contenido es demasiado general, en toda su extensión se habla de qué es la visión por computador, en general,  pero no se detallan aspectos interesantes como el estado del arte en esta materia y una bibliografía relevante. Solo se dice a rasgos generales: \"En trabajos realizados relacionados con este tema, generalmente es el objeto el que se mueve en forma milimétrica...\". A partir de esto me surgen dudas como: ¿Hay otras formas de reconstruir superficies?, ¿Hay trabajos similares?, ¿En qué se diferencia esta técnica a otras?, ¿Cuál es el aporte de vuestro trabajo?, ¿Por qué no utilizar visión estéreo (quizás los costes sean similares)?.  El segundo problema encontrado es consecuencia del primero, ya que al tratar de explicar lo que es visión por computador a quedado demasiado larga (un poco más de tres columnas), y demasiado general. Quizás si se hubiera centrado la atención en el estado de arte esto no lo vería como problema.  - En el aspecto técnico veo que vuestra aproximación puede funcionar en un ambiente muy controlado, donde no hayan grandes cambios de iluminación y la superficie de los objetos escaneados sean de colores que no sean muy similares al fondo y/o haz de láser utilizados. La resta de fondo para entornos controlados puede funcionar pero en exteriores dudo que su sistema sea tan estable. Creo que en el texto se podrían haber enumerado los distintos métodos utilizados para la segmentación. En la página 4 se hace referencia pero no se profundiza (\"Para la segmentación se probaron distintos métodos, de los cuales se seleccionó el método de resta de imágenes...\"). Quizás sería bueno aprovechar algún espacio de color (RBG, YUV, etc.) y utilizar la distancia de Mahalanobis (obtener una muestra de un haz de láser o varios) para obtener una mejor segmentación de la luz láser.  - Sobre la presentación, he encontrado algunos errores que sería bueno mejorar:  - La figura 2 y figura 3 tienen el mismo título, creo que hay un error con el título de la figura 3.  - La figura 2 tiene algunos errores y que puede inducir a error. \"Proyector de luz\", la \"de\" está subrayada. Y \"b\" puede confundir ya que aparece con un guión bajo.  - Algunos detalles:   - Página 5: \"Lo anterior les genera...\"   - Página 6: \"las cuales obtienes mejores...\"   - La palabra láser aparece sin tilde en algunas ocasiones. Revisar el título que acompaña cada página.   - entre otros.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Authors present a parameterized variant of ELU and show that the proposed function helps to deal with vanishing gradients in deep networks in a way better than existing non-linearities. They present both a theoretical analysis and practical validation for presented approach.   Interesting observations on statistics of the PELU parameters are reported. Perhaps explanation for the observed evolution of parameters can help better understand the non-linearity. It is hard to evaluate the experimental validation presented given the difference in number of parameters compared to other approaches.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper proposes to use an encoder-decoder framework for keyphrase generation. Experimental results show that the proposed model outperforms other baselines if supervised data is available.  - Strengths: The paper is well-organized and easy to follow (the intuition of the proposed method is clear). It includes enough details to replicate experiments. Although the application of an encoder-decoder (+ copy mechanism) is straightforward, experimental results are reasonable and support the claim (generation of absent keyphrases) presented in this paper.  - Weaknesses: As said above, there is little surprise in the proposed approach. Also, as described in Section 5.3, the trained model does not transfer well to new domain (it goes below unsupervised models). One of the contribution of this paper is to maintain training corpora in good quantity and quality, but it is not (explicitly) stated.  - General Discussion: I like to read the paper and would be pleased to see it accepted. I would like to know how the training corpus (size and variation) affects the performance of the proposed method. Also, it would be beneficial to see the actual values of p_g and p_c (along with examples in Figure 1) in the CopyRNN model. From my experience in running the CopyNet, the copying mechanism sometimes works unexpectedly (not sure why this happens).",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo realiza un estudio bibliográfico interesante sobre la tecnología IA aplicada en el campo de la fertirrigación y dosificación de nutrientes para cultivos sin suelo. No establece ni describe el diseño de una solución sobre un caso de estudio, y sólo se queda en el estudio preliminar. Por lo que el título “Diseño y Construcción de un Sistema Automático….”  No corresponde, y tendría que orientarse a lo que describe, es decir algo así como: “Análisis y estudio de los sistemas automáticos…”  Es un artículo tipo survey interesante pero se contradice con el título y la introducción, las conclusiones también no son acorde a este tipo de trabajos, debieran ser más ad-hoc con variables comparativas.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper proposes a neural approach to learning an image compression-decompression scheme as an auto-encoder. While the idea is certainly interesting and well-motivated, in practice, it turns out to achieve effectively identical rates to JPEG-2000.  Now, as the authors argue, there is some value to the fact that this scheme was learned automatically rather than by expert design---which means it has benefits beyond the compression of natural images (e.g., it could be used to automatically learning a compression scheme for signals for which we don't have as much domain knowledge). However, I still believe that this makes the paper unsuitable for publication in its current form because of the following reasons---  1. Firstly, the fact that the learned encoder is competitive---and not clearly better---than JPEG 2000 means that the focus of the paper should more be about the aspects in which the encoder is similar to, and the aspects in which it differs, from JPEG 2000. Is it learning similar filters or completely different ones ? For what kinds of textures does it do better and for what kinds does it do worse (the paper could show the best and worst 10 patches at different bit-rates) ?  2. Secondly, I think it's crucial that the paper demonstrate that the benefits come from a better coding scheme (as opposed to just a better decoder), as suggested in my initial pre-review question. How would a decoder trained on JPEG-2000 codes (and perhaps also on encoded random projections) do worse or better ?  3. Finally, I think the fact that it does as well/worse than JPEG-2000 significantly diminishes the case for using a 'deep' auto-encoder. JPEG-2000 essentially uses a wavelet transform, which is a basis that past studies have shown could be recovered using a simple sparse dictionary algorithm like K-SVD. This is why I feel that the method needs to clearly outperform JPEG-2000, or show comparisons to (or atleast discuss) a well-crafted traditional/generative model-based baseline.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper introduces a novel extension of the variational autoencoder to arbitrary tree-structured outputs. Experiments are conducted on a synthetic arithmetic expression dataset and a first-order logic proof clause dataset in order to evaluate its density modeling performance.  Pros: + The paper is clear and well-written. + The tree-structure definition is sufficiently complete to capture a wide variety of tree types found in real-world situations. + The tree generation and encoding procedure is elegant and well-articulated. + The experiments, though limited in scope, are relatively thorough. The use of IWAE to obtain a better estimate of log likelihoods is a particularly nice touch.  Cons: - The performance gain over a baseline sequential model is marginal. - The experiments are limited in scope, both in the datasets considered and in the evaluation metrics used to compare the model with other approaches. Specifically: (a) there is only one set of results on a real-world dataset and in that case the proposed model performs worse than the baseline, and (b) there is no evaluation of the learned latent representation with respect to other tasks such as classification. - The ability of the model to generate trees in time proportional to the depth of the tree is proposed as a benefit of the approach, though this is not empirically validated in the experiments.  The procedures to generate and encode trees are clever in their repeated use of common operations. The weight sharing and gating operations seem important for this model to perform well but it is difficult to assess their utility without an ablation (in Table 1 and 2 these modifications are not evaluated side-by-side). Experiments in another domain (such as modeling source code, or parse trees conditioned on a sentence) would help in demonstrating the utility of this model. Overall the model seems promising and applicable to a variety of data but the lack of breadth in the experiments is a concern.  * Section 3.1: \"We distinguish three types\" => two * Section 3.6: The exposition of the variable-sized latent state is slightly confusing because the issue of how many z's to generate is not discussed. * Section 4.2-4.3: When generating the datasets, did you verify that the test set is disjoint from the training set? * Table 1: Is there a particular reason why the variable latent results are missing for the depth 11 trees?",
            "output": [
                "en"
            ]
        },
        {
            "input": "El trabajo no presenta nada novedoso ni contribuye al estado del arte. Los métodos de clasificación que utiliza son muy básicos, hay muchas técnicas más efectivas.  Tampoco se discuten las técnicas populares y mejores en la literatura.  No existen hipótesis claras.  Que se está tratando de \"probar\" en los experimentos? No se aprecia la contribución.  Problemas de organización del paper  EL trabajo está muy enfocado a describir \"funcionalidades\" de un sistema, y no el aporte propiamente tal en comparación al estado del arte.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Se realiza un trabajo de modelamiento de encriptación cuántica novedosa  No veo aspectos negativos",
            "output": [
                "es"
            ]
        },
        {
            "input": "- Strengths: 1. The idea of assigning variable-length document segments with dependent topics is novel. This prior knowledge is worth incorporated in the LDA-based framework. 2. Whereas we do not have full knowledge on recent LDA literature, we find the part of related work quite convincing. 3. The method proposed for segment sampling with O(M) complexity is impressive. It is crucial for efficient computation.   - Weaknesses: 1. Compared to Balikas COLING16's work, the paper has a weaker visualization (Fig 5), which makes us doubt about the actual segmenting and assigning results of document. It could be more convincing to give a longer exemplar and make color assignment consistent with topics listed in Figure 4. 2. Since the model is more flexible than that of Balikas COLING16, it may be underfitting, could you please explain this more?  - General Discussion: The paper is well written and structured. The intuition introduced in the Abstract and again exemplified in the Introduction is quite convincing. The experiments are of a full range, solid, and achieves better quantitative results against previous works. If the visualization part is stronger, or explained why less powerful visualization, it will be more confident. Another concern is about computation efficiency, since the seminal LDA work proposed to use Variational Inference which is faster during training compared to MCMC, we wish to see the author’s future development.",
            "output": [
                "en"
            ]
        },
        {
            "input": "I agree with the other reviewer that the application areas are limited in the paper. I agree with the overall sentiment of the paper to evaluate effectiveness of some of the more recent techniques in this area, in conjunction with the recurrent networks.   The paper advertises itself as a method (or a list of methods) of improving the recurrent baselines when performing experiments, however fails (or not shown) to generalize to other tasks. Effectiveness of these methods need to be shown across a wide variety of tasks if we intend to replace traditional baselines in general, rather than a specific subset of applications.  I like the desire to evaluate many of the recent techniques and having many replications of experiments towards this end (which is a strong point of the paper). However, whether there are synergies of some of the enhancements with sentiment analysis or not, we cannot see from these results. It would be interesting to see whether some of these results generalize across a wide variety of tasks.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Observaciones de fondo:  El control de navegación de robots móviles o aéreos constituye en la actualidad una interesante veta de investigación, merito del trabajo presentado, sobre todo si el UAV tiene incorporado un brazo el cual modifica su dinámica  haciendo más complejo su control.  El trabajo  tiene por título “Control de un manipulador móvil basado en un quadrotor con un efector final tipo pinza” y en su resumen en la primera línea indica “Este trabajo describe el diseño y control de un manipulador móvil basado en un robot quadrotor y un efector final tipo pinza acoplado”, en efecto el artículo describe la estructura y diseño del UAV con un manipulador de dos grados de libertad incorporado, sin embargo los resultados presentados a nivel de simulación, solo muestran el control de navegación del mismo y no el control del efector final.  Al final del párrafo de conclusiones se indica “como trabajo futuro se implantará el controlador en el sistema de manipulador móvil diseñado”.  Se menciona que el control utilizado es uno de tipo PD (ec. 9, debe ser revisada) debe justificarse esta decisión.  Observaciones de forma:  Mejorar la legibilidad de las figuras. Revisar el texto y corregir errores gramaticales, corte de palabras al final de una línea, etc.",
            "output": [
                "es"
            ]
        },
        {
            "input": "this work investigates a joint learning setup where tasks are stacked based on their complexity. to this end, experimental evaluation is done on pos tagging, chunking, dependency parsing, semantic relatedness, and textual entailment. the end-to-end model improves over models trained solely on target tasks.  although the hypothesis of this work is an important one, the experimental evaluation lacks thoroughness:  first, a very simple multi-task learning baseline [1] should be implemented where there is no hierarchy of tasks to test the hypothesis of the tasks should be ordered in terms of complexity.  second, since the test set of chunking is included in training data of dependency parsing, the results related to chunking with JMT_all are not informative.   third, since the model does not guarantee well-formed dependency trees, thus, results in table 4 are not fair.   minor issue: - chunking is not a word-level task although the annotation is word-level. chunking is a structured prediction task where we would like to learn a structured annotation over a sequence [2].  [1]",
            "output": [
                "en"
            ]
        },
        {
            "input": "El artículo describe una interesante aplicación en el ámbito de la capacitación y que entrega herramientas de gran utilidad para la empresa en el mejoramiento de los procesos del aprendizaje de los trabajadores. El artículo identifica las ventajas que este tipo de plataformas entrega a las empresas que las utilizan.  El artículo no define adecuadamente el propósito del mismo y establece en su inicio que este objetivo es \"dar a conocer\", lo cual no es un propósito adecuado para estas investigaciones.  El artículo se denomina plataforma para la gestión del conocimiento, sin embargo el artículo no define el marco teórico adecuado a esta temática. (no hay autores relevantes en la gestión del conocimiento y los procesos asociados a esta).  El artículo no justifica adecuadamente en la literatura la relevancia de estas plataformas en los proceso de aprendizaje y experiencias internacionales en el tema  No existe un apartado que presente la metodología de investigación seleccionada por los autores, más bien los autores describen una aplicación y sus componentes. Falta claramente el diseño de la investigación.  Las conclusiones del artículo se relacionan con la importancia de estas plataformas para la empresa, pero no se enfocan en los resultados obtenidos en la empresa que implementa, no hay recomendaciones para futuros estudios y no existe reconocimiento de las limitaciones del mismo",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este trabajo aborda una temática interesante, pero está muy mal presentado.  Partiendo por el resumen, que finaliza con un párrafo realmente incomprensible: \"Todo resultado es posible al buen modelamiento de los datos para luego ejecutar el proceso ETL y así finalizar explotándolos con una herramienta OLAP\".  La Introducción no mejora; se inicia con un \"Nace así...\", lo que es la primera frase, que no corresponde, ya que por el estilo parece ser la continuación de otra idea.  El punto II, Temática, aparece como una buena oportunidad para dar cuenta del estado del arte, pero se utiliza para agrupar un conjunto de definiciones, sin que quede claro que forman parte de un todo que el autor utilizará como base para desarrollar su propuesta.  El punto II, Análisis de la problemática, se reduce al tratamiento de los datos.  El autor una vez más pierde una oportunidad de plantear el problema y resaltar el impacto de su propuesta.  El texto contiene una importante cantidad de errores ortográficos, que no dificultan la comprensión del escrito, pero que demuestran una falta de prolijidad en la escritura.  En VI Explotación de indicadores, se destina espacio importante al primer indicador: promedio de edades...  Siendo los valores obtenidos bastante cercanos en todas las regiones, ¿para qué sirve realmente ese dato?  Se requiere revisiones más precisas de un texto que no cumple con los estándares de calidad esperados.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper proposes using quantization schemes to compress the weights of a neural network. The paper carries out a methodical study of first deriving the objective function for optimizing the quantization, and then uses various quantization schemes. Experiments show competitive performance in terms of compression and accuracy tradeoff.    I am happy to go with the reviewers' recommendations to accept the paper.    A minor comment:  It is important to mention other frameworks that compress neural networks, e.g.   ",
            "output": [
                "en"
            ]
        },
        {
            "input": "En este trabajo se muestra un Entorno visual interactivo para análisis exploratorio de modelos en minería de datos. Existe un trabajo denominado 'Modelo aumentado de árbol de decisión utilizando mapas autoorganizados', aceptado el año 2014 en revista Ingeniare, que muestra una metodología muy parecida a la propuesta en este trabajo.  Al respecto este trabajo tiene figuras del trabajo anterior que no referencia. De hecho la figura 1 de este trabajo la presenta gráficamente diferente a la figura 1 del trabajo de Ingeniere, siendo el mismo modelo. Aun cuando al parecer las encuestas son aplicadas a alumnos diferentes (no se especifica) los resultados y frases son muy parecidos al proyecto anterior.  Por lo tanto, se debe especificar el aporte o diferencia de este trabajo con el anterior con mucha más claridad, si es que existe.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The paper presents a way to \"learn\" approximate data structures. They train neural networks (ConvNets here) to perform as an approximate abstract data structure by having an L2 loss (for the unrolled NN) on respecting the axioms of the data structure they want the NN to learn. E.g. you NN.push(8), NN.push(6), NN.push(4), the loss is proportional to the distance with what is NN.pop()ed three times and 4, 6, 8 (this example is the one of Figure 1).  There are several flaws:  - In the case of the stack: I do not see a difference between this and a seq-to-seq RNN trained with e.g. 8, 6, 4 as input sequence, to predict 4, 6, 8.  - While some of the previous work is adequately cited, there is an important body of previous work (some from the 90s) on learning Peano's axioms, stacks, queues, etc. that is not cited nor compared to. For instance [Das et al. 1992], [Wiles & Elman 1995], and more recently [Graves et al. 2014], [Joulin & Mikolov 2015], [Kaiser & Sutskever 2016]...  - Using MNIST digits, and not e.g. a categorical distribution on numbers, is adding complexity for no reason.  - (Probably the biggest flaw) The experimental section is too weak to support the claims. The figures are adequate, but there is no comparison to anything. There is also no description nor attempt to quantify a form of \"success rate\" of learning such data structures, for instance w.r.t the number of examples, or w.r.t to the size of the input sequences. The current version of the paper (December 9th 2016) provides, at best, anecdotal experimental evidence to support the claims of the rest of the paper.  While an interesting direction of research, I think that this paper is not experimentally sound enough for ICLR.",
            "output": [
                "en"
            ]
        },
        {
            "input": "El tema de la participación ciudadana es hoy uno de los temas a nivel de gobierno  que interesa a los gobiernos y a los ciudadanos. Los autores presentan una aplicación que aplica estos conceptos en ámbito de gobierno local.  El objetivo del artículo no es claro. Los autores declaran que el proyecto asociado a este artículo tiene como objetivo desarrollar métodos que den soporte social a la participación de los ciudadanos de Monteria en los procesos y/o decisiones de gobierno.... Por otro lado ellos declaran que el objetivo  es proporcionar una arquitectura de apoyo  a la toma de decisiones grupales y de comunicaciones, que facilite la participación ciudadana en aquellos proceso públicos relacionados con la toma de decisiones , promover su empleo en decisiones importantes y explorar los aspectos políticos-legales asociados al mismo.  Sin embargo estos objetivos se refieren al proyecto ya que ellos no se desarrollan en el artículo. Los autores deben dejar claro el objetivo del artículo y este debe estar circunscrito a lo que se presenta en él.  El artículo también presenta aspectos negativos relacionados fundamentalmente con la revisión del estado del arte o de la literatura en el tema y en el desarrollo metodológico.  En relación a la revisión de la literatura los autores no presentan los principales estudios en el ámbito de la participación  ciudadana en el mundo. Existe un importante número de publicaciones que abordan este tema en los Estados Unidos y en Europa. Los modelos de madurez del gobierno electrónico abordan claramente este ámbito. Los autores deben  revisar en forma exhaustiva la literatura referente al tema.  El aspecto metodológico del artículo es incompleto ya que no establece un diseño de la investigación que identifique con claridad las herramientas a utilizar en cada etapa y la justificación de las mismas (comparativamente), solo se mencionan dos alternativas pero se desconoce las razones de su eliminación.   Dado que el trabajo se encuentra aún en su etapa de implementación es difícil determinar los beneficios finales de la implementación por lo cual los autores deben destacar esta limitación.",
            "output": [
                "es"
            ]
        },
        {
            "input": "Si bien es cierto el trabajo se encuentra bien estructurado y da muestras de una metodología adecuada, no queda clara la utilidad del estudio realizado. Los resultados obtenidos y presentados, se basan en un periodo de estudio muy reducido, lo cual quita confianza a las conclusiones. Se observan algunos pequeños errores de edición y redacción en el texto. Se recomienda ampliar el conjunto de datos de entrada del estudio.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The aim of this paper is to show that distributional information stored in word vector models contain information about POS labels. They use a version of the BNC annotated with UD POS and in which words have been replaced by lemmas. They train word embeddings on this corpus, then use the resulting vectors to train a logistic classifier to predict the word POS. Evaluations are performed on the same corpus (using cross-validation) as well as on other corpora. Results are clearly presented and discussed and analyzed at length.  The paper is clear and well-written. The main issue with this paper is that it does not contain anything new in terms of NLP or ML. It describe a set of straightforward experiments without any new NLP or ML ideas or methods. Results are interesting indeed, in so far that they provide an empirical grounding to the notion of POS. In that regard, it is certainly worth being published in a (quantitative/emprirical) linguistic venue.  On another note, the literature on POS tagging and POS induction using word embeddings should be cited more extensively (cf. for instance Lin, Ammar, Duer and Levin 2015; Ling et al. 2015 [EMNLP]; Plank, SÃ¸gaard and Goldberg 2016...).",
            "output": [
                "en"
            ]
        },
        {
            "input": "Paper Summary This paper proposes an unsupervised learning model in which the network predicts what its state would look like at the next time step (at input layer and potentially other layers).  When these states are observed, an error signal is computed by comparing the predictions and the observations. This error signal is fed back into the model. The authors show that this model is able to make good predictions on a toy dataset of rotating 3D faces as well as on natural videos. They also show that these features help perform supervised tasks.  Strengths - The model is an interesting embodiment of the idea of predictive coding   implemented using a end-to-end backpropable recurrent neural network architecture. - The idea of feeding forward an error signal is perhaps not used as widely as it could   be, and this work shows a compelling example of using it.  - Strong empirical results and relevant comparisons show that the model works well. - The authors present a detailed ablative analysis of the proposed model.  Weaknesses - The model (esp. in Fig 1) is presented as a generalized predictive model   where next step predictions are made at each layer. However, as discovered by running the experiments, only the predictions at the input layer are the ones that actually matter and the optimal choice seems to be to turn off the error signal from the higher layers. While the authors intend to address this in future work, I think this point merits some more discussion in the current work, given the way this model is presented. - The network currently lacks stochasticity and does not model the future as a   multimodal distribution (However, this is mentioned as potential future work).  Quality The experiments are well-designed and a detailed analysis is provided in the appendix.  Clarity The paper is well-written and easy to follow.  Originality Some deep models have previously been proposed that use predictive coding. However, the proposed model is most probably novel in the way it feds back the error signal and implements the entire model as a single differentiable network.  Significance This paper will be of wide interest to the growing set of researchers working in unsupervised learning of time series. This helps draw attention to predictive coding as an important learning paradigm.  Overall Good paper with detailed and well-designed experiments. The idea of feeding forward the error signal is not being used as much as it could be in our community. This work helps to draw the community's attention to this idea.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Este trabajo ofrece un análisis comparativo del uso de tecnología cableada y tecnología programada.  El ámbito de \"trabajo relacionado\" presentado en el documento es inexistente. En este contexto, no es posible determinar si los criterios de comparación sugeridos en el trabajo son, efectivamente, los pertinentes para realizar una evaluación.  Los criterios de comparación de tecnologías son en algunos casos objetivos y en otros casos subjetivos. En este sentido, el trabajo no sugiere cómo enfrentar la valoración de cada criterio para finalmente efectuar una comparación (por ejemplo, en el ítem \"seguridad\" o en el ítem \"programación\").  Existen problemas gramaticales (por ejemplo, \"alto tiempo). Adicionalmente, el trabajo está pobremente ordenado, dificultando la comprensión por el bajo esfuerzo en localizar el contenido de las tablas de una manera legible.  No se visualiza un aporte real de este trabajo. En numerosas oportunidades se cita a \"Rexroth Bosch Group\", sin agregar mucho más en cada punto. El impacto y relevancia  de este trabajo, en cuanto a la novedad, no es observable.",
            "output": [
                "es"
            ]
        },
        {
            "input": "In the § Related work: \"deeplearning4j 2 provides distributed computing of deep learning framework that runs on the distributed computing Hadoop. However, Hadoop must be installed in all computing nodes, thereby imposing high deployment and maintenance costs.\"  This is inexact, Deeplearning4j's most basic mode of operation is on a single machine, with Java installed. A GPU is used if available but is not a requirement (Deeplearning4j documentation: ",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper introduces UCCA as a target representation for semantic parsing and also describes a quite successful transition-based parser for inference into that representation. I liked this paper a lot. I believe there is a lot of value simply in the introduction of UCCA (not new, but I believe relatively new to this community), which has the potential to spark new thinking about semantic representations of text. I also think the model was well thought out. While the model itself was fairly derivative of existing transition-based schemes, the extensions the authors introduced to make the model applicable in this domain were reasonable and well-explained, at what I believe to be an appropriate level of detail.  The empirical evaluation was pretty convincing -- the results were good, as compared to several credible baselines, and the authors demonstrated this performance in multiple domains. My biggest complaint about this paper is the lack of multilingual evaluation, especially given that the formalism being experimented with is exactly one that is supposed to be fairly universal. I'm reasonably sure multilingual UCCA corpora exist (in fact, I think the \"20k leagues\" corpus used in this paper is one such), so it would be good to see results in a language other than English.  One minor point: in section 6, the authors refer to their model as \"grammarless\", which strikes me as not quite correct. It's true that the UCCA representation isn't derived from linguistic notions of syntax, but it still defines a way to construct a compositional abstract symbolic representation of text, which to me, is precisely a grammar. (This is clearly a quibble, and I don't know why it irked me enough that I feel compelled to address it, but it did.)  Edited to add: Thanks to the authors for their response.",
            "output": [
                "en"
            ]
        },
        {
            "input": "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure.   With the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantly, they also provide a way to avoid such difficulties by introducing perturbation. I believe this paper will inspire more principled research in this direction.   I am very interested in the perturbation trick to avoid the gradient instability and vanishment. In fact, this is quite related to dropout trick in where the perturbation can be viewed as Bernoulli distribution. It will be great if the connection can be discussed.  Besides the theoretical analysis, is there any empirical study to justify this trick? Could you please add some experiments like Fig 2 and 3 for the perturbated GAN for comparison?",
            "output": [
                "en"
            ]
        },
        {
            "input": "el trabajo mostrado en este paper esta muy bien documentado.  presentan un modelo de extracción de información para la planificación de búsquedas en web.  para ello con algunos casos que prueba el modelo propuesto",
            "output": [
                "es"
            ]
        },
        {
            "input": "Este trabajo propone un nuevo enfoque basado en [25] para apoyar la recomendación de los RS mediante la evolución de los pesos de las características de los usuarios a través de dos enfoques de utilización de algoritmos genéticos. El trabajo parece técnicamente correcto y la propuesta presenta resultados robustos de acuerdo a lo presentado en el documento.  El documento posee una serie de errores al parecer tipográficos que inducen a confusión, donde se cambian los nombres de variables, abreviaciones o formato de presentación de variables  subíndices, etc. Por ejemplo: ecuación 2, función w, abreviación CF, figura 3, figura 6. El enfoque aparentemente utiliza solo una parte de la BD por motivos de eficiencia, sería bueno utilizar alguna técnica de indexado para apoyar este proceso.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This work proposes a model that can learn short binary codes via paragraph vectors to allow fast retrieval of documents. The experiments show that this is superior to semantic hashing. The approach is simple and not very technically interesting. For a code size of 128, the loss compared to a continuous paragraph vector seems moderate.  The paper asks the reader to refer to the Salakhutdinov and Hinton paper for the baseline numbers but I think they should be placed in the paper for easy reference. For simplicity, the paper could show the precision at 12.5%, 25% and 50% recall for the proposed model and semantic hashing. It also seems that the semantic hashing paper shows results on RCV2 and not RCV1. RCV1 is twice the size of RCV2 and is English only so it seems that these results are not comparable. It would be interesting to see how many binary bits are required to match the performance of the continuous representation. A comparison to the continuous PV-DBOW trained with bigrams would also make it a more fair comparison.  Figure 7 in the paper shows a loss from using the real-binary PV-DBOW. It seems that if a user needed high quality ranking after the retrieval stage and they could afford the extra space and computation, then it would be better for them to use a standard PV-DBOW to obtain the continuous representation at that stage.  Minor comments: First line after the introduction: is sheer -> is the sheer 4th line from the bottom of P1: words embeddings -> word embeddings In table 1: What does code size refer to for PV-DBOW? Is this the number of elements in the continuous vector? 5th line from the bottom of P5: W -> We 5th line after section 3.1: covers wide -> covers a wide",
            "output": [
                "en"
            ]
        },
        {
            "input": "RESUMEN. El artículo busca mostrar las aplicaciones de Sistemas Inmune Biológico en la computación. Para ello, el artículo comienza describiendo la teoría sobre el Sistema Inmune Biológico de los vertebrados, el cual define, además de explicar su funcionamiento. A continuación describe los modelos biológicos como revisión teórica de la materia. Finalmente describe las características de los sistemas inmunes artificiales y detalla los distintos campos de aplicación.  Evaluación General. El tema del artículo es sumamente interesante, y poco veces visto (al menos por mi). Tal cual postula el artículo, hace una revisión bibliográfica de la teoría y entrega una descripción sobre la variedad de aplicaciones que tiene este campo de estudio. Logra resumir estos conceptos que pueden servir efectivamente como marco de referencia dentro de la literaria. Sin embargo, el artículo posee algunas debilidades:   1) La gran debilidad del artículo es su estructura. El artículo no sigue el formato estándar del trabajo de un artículo científico. Acá presento algunos ejemplos. a) En la introducción no se presenta la estructura que sigue el artículo, ni una idea general de lo que quieren lograr los autores. b) No hay un lineamiento de las ideas de cada sección, ni una introducción por sección. Esto se traduce en que no existe una propuesta clara por parte de los autores y que lo intentan proponer se ve solamente en la última página.   2) Otra debilidad es que no establece ninguna forma de evaluar y comparar las distintas aplicaciones de la materia con el fin de conectarlas con la teoría y presentar una contribución del artículo. Por esto, no cumple con lo establecido en su abstract: \" . . . para establecer lineamientos en la aplicación de estas técnicas en las diferentes áreas del conocimiento.\"  3) Otro problema es que no establece ningún tipo de conclusión ni de las implicancias que tiene el artículo, el cual termina con la descripción de una aplicación en optimización combinatoria.  Otros comentarios. Problemas menores de redacción: a) \"...y las moléculas pertenecientes a antígenos externos (no propias),  que en últimas son las que constituyen una amenaza para el organismo...\" Se entiende que falta una palabra luego de “últimas”. b) \"describe características básicas de una respuesta inmunológica\" Esta frase no establece una definición. c) \"células innatas inmunes especializadas células dendríticas\" Aquí también faltan palabras.",
            "output": [
                "es"
            ]
        },
        {
            "input": "En su forma, tiene algunos problemas, por ejemplo en la página 5, en la descripción del laboratorio implementado, se describe, la estructura propuesta con seis cámaras para localizar los robots en el campo durante un juego de futbol, señalando que esto es mostrado anteriormente y aparece [9], donde figura ni referencia existen. Por otro lado, en medio de las referencias bibliográficas, aparece la figura 14, que no es referenciada en el documento.  En su contenido, sobre el 50% del artículo está dedicado, al análisis de técnicas de captura de posición y movimiento por triangulación de imágenes, tratadas reiteradamente en la literatura técnica y que no aporta valor desde el punto de vista científico. Es solo una recopilación bibliográfica de técnicas de visión. Por otro lado, la descripción de los resultados no son un aporte al tema del artículo que es el  uso de técnica de visión para la determinación de robots dedicados a futbol.  Finalmente creo que el autor del artículo fue muy poco riguroso al escribirlo, donde al menos debía haberlo revisado antes de enviarlo.",
            "output": [
                "es"
            ]
        },
        {
            "input": "The authors propose to sample from VAEs through a Markov chain [z_t ~ q(z|x=x_{t-1}), x_t ~ p(x|z=z_t)]. The paper uses confusing notation, oversells the novelty, ignoring some relevant previous results. The qualitative difference between regular sampling and this Gibbs chain is not very convincing, judging from the figures. It would be a great workshop paper (perhaps more), if the authors fix the notation, fix the discussion to related work, and produce more convincing (perhaps simply upscaled?) figures.  Comments:   - Rezende et al's (2014) original VAE paper already discusses the Markov chain, which is ignored in this paper  - Notation is nonstandard / confusing. At page 1, it’s unclear what the authors mean with “p(x|z) which is approximated as q(x|z)”. - It’s also not clear what’s meant with q(z). At page 2, q(z) is called the learned distribution, while p(z) can in general also be a learned distribution. - It’s not true that it’s impossible to draw samples from q(z): one can sample x ~ q(x) from the dataset, then draw z ~ q(z|x). - It's not explained whether the analysis only applies to continuous observed spaces, or also discrete observed spaces - Figures 3 and 4 are not very convincing.",
            "output": [
                "en"
            ]
        },
        {
            "input": "Lo que se propone \"es interesante como una aplicación\" pero no es un trabajo científico.  Ya no es interesante la aplicación de un Datamart desde el punto de vista de aplicación de herramientas (OLAP) a un problema. Dado que se vuelve un trabajo técnico que se realiza en empresas actualmente, pero que no implica un desafío científico ni de investigación.  Hay errores de diseño en la tabla de hechos.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El artículo presenta el diseño e implementación de un esquema de base de datos espacial.  El artículo muestra la implementación sobre un SGBD relacional con una extensión que soporta modelos espaciales (PostGIS).  Específicamente se presenta el modelo Entidad-Relación y modelo Relacional del Sistema de Gestión de Base de Datos.  En general el artículo explica claramente el trabajo realizado, sin embargo, muestra algunas deficiencias en la redacción y ortografía de algunas palabras. La figura 2 no se visualiza correctamente.  No se comprende ¿por qué se diseña bajo metodología Relacional si lo que se busca es modelar una Base de Datos Espacial que es basada en Objetos y además en este caso PostGIS es object-oriented? Por qué no usar un diseño orientado a objetos?.  Sería recomendable revisar el artículo de Worboys: \"Object-Oriented Data Modelling for Spatial Databases\"  El artículo no muestra una evaluación y resultados de la investigación realizada.  Hay muchas referencias de sitios WEB de aplicaciones, pero muy pocas referencias a artículos científicos actuales asociados al tema presentado.",
            "output": [
                "es"
            ]
        },
        {
            "input": "This work proposes to apply dilated convolutions for sequence tagging (specifically, named entity recognition). It also introduces some novel ideas (sharing the dilated convolution block, predicting the tags at each convolution level), which I think will prove useful to the community. The paper performs extensive ablation experiments to show the effectiveness of their approach. I found the writing to be very clear, and the experiments were exceptionally thorough.  Strengths:   - Extensive experiments against various architectures (LSTM, LSTM + CRF)        - Novel architectural/training ideas (sharing blocks)    Weaknesses:   - Only applied to English NER--this is a big concern since the title of the paper seems to reference sequence-tagging directly.   - Section 4.1 could be clearer. For example, I presume there is padding to make sure the output resolution after each block is the same as the input resolution.  Might be good to mention this.   - I think an ablation study of number of layers vs perf might be interesting.  RESPONSE TO AUTHOR REBUTTAL:  Thank you very much for a thoughtful response. Given that the authors have agreed to make the content be more specific to NER as opposed to sequence-tagging, I have revised my score upward.",
            "output": [
                "en"
            ]
        },
        {
            "input": "En la práctica realiza una comunicación utilizando un esquema de distribución de procesos y datos no declarados, para lograr solucionar el problema de ruido, no indica el método de procesamiento de imagen, tampoco la estrategia utilizada, hace un manejo de información a modo de introducción al tema CPU-GPU.  Claramente es un trabajo que ataca un procesamiento de imagen preliminar, simple, donde debe mostrarse el método a paralizar y la estrategia a utilizar para su paralelización en GPU o en CPU-GPU.  Desde el punto de vista de procesamiento de imágenes es un tema poco original, pero es interesante que se comience a trabajar en paralelismo en CPU-GPU's,lo que no es novedad, pero lo interesante son las estrategias de paralelización, el como particionar los procesos y datos, el cómo utilizar las grillas, bloques e hilos, el cómo armar una topología si es posible, para dar una solución que minimice el tiempo de ejecución.  Especificar claramente que es un trabajo de procesamiento de imágenes, filtros que se utiliza, método y estrategia de paralelización.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El nombre del artículo es “¿Cómo afecta ….”, e indica en su Resumen “… aplicado a través de un estudio de caso a dos mineras de la región de Antofagasta y a una empresa de tipo proveedora”. Sin embargo, el artículo no presenta una sección con el estudio de caso indicado, lo cual indica que no es posible responder a la pregunta expresada en el título del artículo. Por lo tanto, son buenas intenciones lo expresado, pero no hay evidencia empírica.  El tema es muy importante, la forma de solución también es adecuada, pero todo está expresado en términos teóricos. Se indica que “la investigación se encuentra actualmente en la etapa de realización de entrevistas”, por lo expresado, no se ha realizado análisis de los datos ni resultados y conclusiones.  La sección Resultados no presenta resultados.  Va a ser un artículo interesante cuando se cumpla con todas las etapas de la metodología planteada.  Algunas observaciones y/o comentarios menores: - Las Referencias [6] y [13] no fueron usadas en el texto. - El primer párrafo del Estado del Arte es una repetición del segundo párrafo de la Introducción. - En página 3, cambiar “actividades claves” por “actividades clave”. - La Figura de la página 6 no tiene título.",
            "output": [
                "es"
            ]
        },
        {
            "input": "El trabajo presenta un estudio del estado del arte en lo que respecta a sistemas de robótica cooperativa de multi-robots. El foco de la revisión es la arquitectura de control presente en aquellos sistemas.  El abstract en inglés debe ser revisado en su redacción, en especial el uso de palabras, como \"giving\"->\"providing\", \"panoramic\"->\"general\", etc.  La introducción no entrega un mayor aporte a la estructura del documento. Se habla un poco de la investigación asociada al tema, pero con un uso muy bajo en referencias y la sección termina abruptamente sin explicar metodología o contribuciones del trabajo.  El trabajo entrega un \"planteamiento del problema\" muy poco claro y que no provee mayor relevancia. Más aun, además de identificar algunas aproximaciones al contexto, el trabajo no plantea ninguna solución, alternativa, categorización, marco de trabajo o aporte en general al (poco claro) problema presentado.  En resumen, el trabajo realiza una recopilación relativamente adecuada de información respecto a sistemas de robótica cooperativa de multi-robots, sin embargo, más allá de eso, no se revela un real aporte o relevancia desde el punto de vista científico al trabajo. Si estos puntos fueran más claros, si se presentara de forma directa la metodología, y si se presentara un producto concreto de investigación, este trabajo podría ser aceptado, pero en su estado actual no se recomienda.",
            "output": [
                "es"
            ]
        },
        {
            "input": "1) Summary  This paper proposes an end-to-end hybrid architecture to predict the local linear trends of time series. A temporal convnet on raw data extracts short-term features. In parallel, long term representations are learned via a LSTM on piecewise linear approximations of the time series. Both representations are combined using a MLP with one hidden layer (in two parts, one for each stream), and the entire architecture is trained end-to-end by minimizing (using Adam) the (l2-regularized) euclidean loss w.r.t. ground truth local trend durations and slopes.   2) Contributions  + Interesting end-to-end architecture decoupling short-term and long-term representation learning in two separate streams in the first part of the architecture. + Comparison to deep and shallow baselines.  3) Suggestions for improvement  Add a LRCN baseline and discussion: The benefits of decoupling short-term and long-term representation learning need to be assessed by comparing to the popular \"long-term recurrent convolutional network\" (LRCN) of Donahue et al (",
            "output": [
                "en"
            ]
        }
    ],
    "Reasoning": []
}